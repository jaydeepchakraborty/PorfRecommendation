MIST: Missing Person Intelligence Synthesis Toolkit
Elham Shaabani, Hamidreza Alvari, and
Paulo Shakarian

J.E. Kelly Snyder
Find Me Group
Chandler, AZ 85249

Arizona State University
Tempe, AZ 85281

kelly@findmegroup.org

{shaabani, halvari, shak}@asu.edu

ABSTRACT

cases examined in our experiments (on real-world data provided by FMG), we found our approach to be able to reduce
total search area by a total of 31 square miles for standard
searches and by 19 square miles when dog team assets obtain
a detection. This reduction is significant for the following
reasons:

Each day, approximately 500 missing persons cases occur
that go unsolved/unresolved in the United States. The nonprofit organization known as the Find Me Group (FMG),
led by former law enforcement professionals, is dedicated to
solving or resolving these cases. This paper introduces the
Missing Person Intelligence Synthesis Toolkit (MIST) which
leverages a data-driven variant of geospatial abductive inference. This system takes search locations provided by a
group of experts and rank-orders them based on the probability assigned to areas based on the prior performance of
the experts taken as a group. We evaluate our approach
compared to the current practices employed by the Find Me
Group and found it significantly reduces the search area leading to a reduction of 31 square miles over 24 cases we
examined in our experiments. Currently, we are using MIST
to aid the Find Me Group in an active missing person case.

• Reduction in time to locate missing persons.
In cases where baseline provided 20 square miles or
more (the most difficult cases), we achieved reduction
in search area of 7 to 56 square miles. As 3-5 square
miles are searched on a typical day (terrain dependent), such a reduction can potentially increase the
chance of a missing person being found alive.
• Reduction in direct costs. During a search, FMG
spends approximately $2200 per day. In all tests, our
approach reduced the search area in the majority of
cases which can be interpreted as a reduction in direct
costs.

Keywords
Geospatial abduction; abductive inference; law enforcement;
missing person

1.

• Reduction in indirect costs. FMG relies extensively on volunteers to augment searches. During searches,
these individuals often lose earnings from their day job
or small business. As many volunteers also perform
consulting or other services to law enforcement, longer
searches lead to loss of revenue and opportunity. In
one case, a volunteer estimated a loss of $15K. Again,
our approach leads to a consistent reduction in search
area - hence reducing these indirect costs.

INTRODUCTION

Each day, approximately 500 missing persons cases occur
that go unsolved/unresolved in the United States. The nonprofit organization known as the Find Me Group (FMG),
led by former law enforcement professionals, is dedicated
to solving or resolving these cases. This non-profit operates with limited resources - so it must use its volunteer assets in a highly efficient manner. This paper introduces the
Missing Person Intelligence Synthesis Toolkit (MIST) which
leverages a data-driven variant of geospatial abductive inference [24]. This system takes search locations provided by
a group of experts and rank-orders them based on the probability assigned to areas based on the prior performance of
the experts taken as a group. We evaluate our approach
compared to the current practices employed by the FMG
and found it significantly reduces the search area. In 24

Specifically, we contribute an extension to geospatial abduction [24] that leverages historical data of individual experts. We also create new algorithms to learn parameters
of a geospatial abduction model from data based on integer
programming. We then evaluate these algorithms on realworld data provided by the FMG under a variety of different
settings. This approach learns pattern of each reporter independently and is able to overcome outliers if any. It also
does well on the limited data. This work has prepared us
in our ongoing deployment of the software. At the time of
this writing, we have provided results of MIST to support
an active case with FMG. Figure 1 shows an example output of MIST where it rank-orders search locations. FMG is
currently using this information to support their operations.
They found the result consistent with their experiences.
The rest of the paper is organized as follows. In Section 2,
we present the background of the missing person problem.
Next, we provide the technical preliminaries. We discuss
our data-driven extension in Section 4. In Section 5, we

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

CIKM ’16, October 24–28, 2016, Indianapolis, IN, USA.
c 2016 ACM. ISBN 978-1-4503-4073-1/16/10. . . $15.00

DOI: http://dx.doi.org/10.1145/2983323.2983346

1843

In this paper, we formulate the problem of “finding missing person” with respect to information provided by FMG’s
experts, formally as a variant of the geospatial abduction
problem (GAP) [22]. To account for the key nuances of
“finding missing person” problem though, we extended the
GAP framework to better suite this domain. In particular,
we extend the GAP formalism with a data driven model accounting for the previous performance of experts aiding in
the missing person cases. We list the unique characteristics
of our framework here. Later in the next section, we provide
our technical approach to each.
1. Explanation Size. One key difference “finding missing person” problem has from other GAP instances, is
that the explanation (the result of a GAP inference algorithm) only consists of a single related location (i.e.,
the location of the missing person) corresponding to
the phenomenon under study. This differs from returning a set of k locations in the previously-introduced
GAP formalisms. Consequently, here, an explanation
will consist of a single point, which in turn led us to
explore a non-deterministic version of the original explanation.

Figure 1: Mapping of ordered grids by MIST (green squares)
and current searched area by FMG (red square).
detail our algorithmic approach. We introduce our dataset
and conduct data analysis in Section 6. Next, we discuss
the experimental results in Section 7. We review the related
work in Section 8. We conclude the paper presenting future
research directions.

2.

BACKGROUND

2. Distance Constraints. In the original GAP formalism, each observed geospatial phenomenon is related
to unobserved “partner” points through a distance constraint - (α,β) where α is the minimum distance between an observation and partner and β is the maximum distance. As described, this pair of constraints
was the same for all observations. However, in the
missing persons problem, each observation corresponds
to a different domain expert - and hence has a different (α,β) constraint pair. Further, we study how this
is best learned from data, as well as “soften” the constraint - assigning a probability of the partner point
being less than α, between distances α and β, and
greater than distance β from an observation.

Missing persons cases have been on the rise in the USA
for the past twenty years. Currently, approximately 4000
people go missing each and every day. Approximately 3500
of those cases are solved or resolved (i.e., cases solved by
only providing accurate information to the authorities and
without physical involvement), which leaves an astounding
number of victims that are never located. In the case of
missing adults 13 years of age and older, the police are not
required or obligated to conduct an investigation or search
unless there are extenuating circumstances such as suicide, a
potential for violence, medical reasons, etc. This leaves families and friends without professional assistance in locating
their loved ones. The Find Me Group (FMG) was founded
by retired U.S. Drug Enforcement Agency (DEA) Special
Agent J.E. “Kelly” Snyder in 2002. The group consists of
current and retired law enforcement officers with a widerange of investigative expertise, including but not limited
to linguistics, handwriting analysis, body language, missing person/homicide experience and search-and-rescue field
management skills. The FMG has trained experts/sources
that provide detailed location information where missing individuals can be found. Many of these experts have the
ability to provide GPS coordinates to locate missing persons
with a varying levels of success. The FMG focus/goal is to
provide accurate location information in a timely manner
and minimize the potential of finding the victim deceased.
Thirty canine handlers certified in tracking, scent and cadaver complements the FMG and has led to many instances
where the person in questions was located.
Equally disturbing nationwide is the rise in human trafficking, which aligns within the missing person category.
This type of crime has long-term and devastating results.
The work of this paper is also the first step toward an allencompassing methodology of identifying locations of missing persons who were victims of human trafficking. Another
important related crime is homicide. Many missing persons
and human trafficking victims are found deceased due to this
crime. This work represents initial progress in aiding toward
crimes of this nature as well.

3. Uncertainty. As we learn the (α,β) distance constraints for each observation and associate corresponding probabilities from historical data, it makes sense
that the inference step is treated probabilistically which differs from the original deterministic GAP framework. Further, this enables us to rank the potential
partner locations (again, as an explanation consists of
one point, ranking search locations is more useful in a
practical sense).
4. Independent Observations. In the original GAP
framework, independence amongst the observations was
not an assumption in the framework. However, FMG
compartmentalizes the information from their law enforcement experts from one another in a manner to
obtain independent reporting. Hence, we make this
assumption in this paper and it is supported by our
experimental results.
FMG currently uses a simple heuristic to rank-order potential search locations for a missing person (we describe this
later in Section 5). Once ranked, FMG leverages a variety of assets. Figure 2 depicts a recently searched area for
a case. It represents a screen shot of the tracks from the
GPS units that the dogs wear as well as the handheld units
that the searchers wear. This shows several dog tracks and

1844

the human tracks. The green, dark blue, magenta represent
three dogs, the grey and red represent two human searchers.
The teal track is a trailing dog, ascertaining a direction of
travel. The straight lines tend to be humans and the rapidly
changing direction lines are dogs as they grid around the humans. Figure 3 shows real-world examples of how the FMG
practices in an undisclosed location.

mally, each GAP consists of three major elements [22]: (1)
observations: a set of observations that explain the locations associated with the event under study (e.g., in this
application, the locations reported by the domain experts),
(2) distance constraints: a pair (α, β) ∈ R corresponding to
lower and upper bounds on the distances between observation and partner location and, (3) feasibility predicate: this
allows to specify whether an area on the map is a potential
location for a partner.
Next, we present the notations and definitions used throughout the paper, and review the geospatial abduction framework of [22]. In the next section, we describe specialized
extensions that were necessary to study our problem. First,
without loss of generality, we assume throughout the paper
that a map (resp. space) is represented by a discrete two
dimensional grid of size M × N , defined as follows:
Definition 3.1. (Space). Given natural numbers M ,
N , the space S is the set [1, . . . , M ] × [1, . . . , N ].
Associated with the space is a distance function d : S ×
S → R+ that satisfies the normal distance axioms: d(pi , pi ) =
0, d(pi , pj ) = d(pj , pi ), and d(pi , pj ) ≤ d(pi , pq ) + d(pq , pj ).
Note that we use o to represent the observer (source of information) and po to represent the location he/she reported
(which differs slightly from the original framework). From
these observations (reports), the corresponding unobserved
phenomenon is the actual location of the missing person.
In the original framework, the explanation consisted of geographic locations that were located at least distance α and
no more than distance β away from each observation. In
this work, we generalize this notion by providing α,β pair
for each observer - denoted αo ,βo .

Figure 2: Screen shot of the tracks from the GPS units.

3.

TECHNICAL PRELIMINARIES

In this section, we briefly explain geospatial abductive inference [24], and introduce our new (introduced in this paper) data-driven probabilistic extension. We show how this
extension was used to address the unique characteristics of
the missing person location problem.
In general, abduction or abductive inference [12] refers to
a type of logic or reasoning to derive plausible explanations
for a given set of facts [13]. Abduction has been extensively
studied in medicine [13, 14], fault diagnosis [3], belief revision [11], database updates [8, 4] and AI planning [5]. Two
major existing theories of abduction include logic-based abduction [6] and set-covering abduction [2]. Though none of
the above papers takes into account spatial inference, [25]
presents a logical formalism dealing with objects’ spatial occupancy, while [18] describes the construction of a qualitative spatial reasoning system based on sensor data from a
mobile robot.
Geospatial abduction problem (GAP) [22], on the other
hand, refers to the problem of identifying unobserved partner locations (i.e., the location of a missing person) that
best explain a set of observed phenomenon with known geographic locations. Geospatial abduction was first introduced
in [23] and later extended in [24, 21, 20, 19]. More for-

(a)

Definition 3.2. (Feasibility Function). A feasibility
function feas is defined as feas : S → {True, False}.
A key use for the feasibility function here is for an initial
reduction of the search space by the FMG. This is due to the
fact that missing person reports often span a large area and
an initial reduction is necessary for practical reasons. An
obvious future direction would be to utilize a probabilistic
variant of the feasibility function - which would assign a prior
probability to a location for a missing person. However, in
this application, it is unclear where such a distribution would
come from. Further, as the search space is relatively large
when compared to FMG resources, the deterministic version
of this definition is more appropriate for operational reasons.
Due to resource constraints and the generally large areas
over which reports are spread, FMG typically only searches
areas for which there is a report. As we shall describe in
Section 5, they search a 1 × 1 mile square surrounding a
location reported by an observer. As such is the case, we
shall assume the following feasibility function throughout
this paper:
(
True
if p ∈ O
feas(p) =
(1)
False otherwise
Unless otherwise noted, we shall assume the above function is used for feasibility and hence the subset of the space
considered will be the points in O.
We now come to the important definition of an explanation. Intuitively, for a given set of points {p1 , . . . , p|O| }
reported by observers in O, an explanation is a set of points

(b)

Figure 3: (a) Picture of the search area taken from the plane.
(b) Search team.

1845

E such that every point in this set is feasible and for every
observation, there is a point in E that is at least α units
away from the observation, but no more than β units from
the observation.

distance constraint (β) for sake of brevity - though this idea
can be extended for multiple distance constraints (as per
characteristic 2 from Section 2). In fact, we leverage multiple distance constraints in our optimization procedure for
parameter selection introduced later. Hence, by distance
primacy, we have the following relationships.
^
^ β
P r(Pp |
Oo = po ) = P r(Pp |
Rp,po )
(2)

Definition 3.3. ((α,β) Explanation). Suppose O is
the set of observations, E is a finite set of points in S, and
0 ≤ α, β ≤ 1 are two real numbers. E is said to be an (α, β)
explanation of O iff:

o∈O

By Bayes’ Theorem, this is equivalent to the following.
V
P r(Pp ) × P r( o∈O Rβp,po |Pp )
(3)
V
P r( o∈O Rβp,po )

• p ∈ E implies that feas(p) = True, i.e., all points in E
are feasible.
• (∀o ∈ O)(∃p ∈ E) α ≤ d(p, o) ≤ β, i.e., every observation is neither too close nor too far from some point
in E.

However, by characteristic 4, we assume that the observers
report information independently, which gives us the following.
Q
P r(Pp ) × o∈O P r(Rβp,po |Pp )
(4)
V
P r( o∈O Rβp,po )

Thus, an (α,β) explanation is a set of points. Each point
must be feasible and every observation must have an analogous point in the explanation which is neither too close nor
too far.
Again, we note that here an explanation will consist of a
single point - the location of the missing person. Hence, this
deterministic definition of an explanation will not suffice as in practice there will often not exist an explanation for
a given problem instance. As such is the case, we extended
this framework using a data-driven approach.

4.

o∈O

Due to our application, we will not consider the prior probability P r(Pp ) as each missing person case occurs in a different geographic location - and due to the wide range of
cases that span multiple countries, data supporting a realistic, informed prior is highly sparse. As such, we consider a
uninformed prior. Further, for notational simplicity, we shall
use the notation ρβo for the quantity P r(Rβp,po = True|Pp =
True). Therefore, we can rank points in the space based
on the explanation distribution by simply considering their
log-likelihood computed as follows:
X
X
log(ρβo ) +
log(1 − ρβo )
(5)

DATA-DRIVEN EXTENSIONS

In this section, we describe our data-driven probabilistic
extension to the original GAP formalism. The framework
extensions in this section were not previously introduced and
are new in this paper. In order to do so, we first introduce
some preliminary notation. For point p ∈ S, the random
variable Pp denotes that the missing person was found at
point p, so this is either true or false. We will use Pp as
shorthand for Pp = True. For observer o ∈ O the random
variable Oo can be assigned to one of the points in p. Based
on this notation, we define an explanation distribution.

o∈O
d(p,po )≤β

o∈O
d(p,po )>β

Hence, the inference step for this problem is straightforward provided we know the values β and ρβo for each
observer o ∈ O (or similar parameters if considering more
than one distance constraint). If we know the value β we
can then compute ρβo based on a corpus of historical data
concerning the accuracy of reporter o. Given a corpus of
previous cases for the observer Co where the found location
was pc and the location reported by the observer was pco , we
can compute ρβo as follows:

Definition 4.1 (Explanation Distribution). Given
a set of observers O and a set of reported locations by each
observer p1 , . . . , po , . . . , p|O| , an explanation distribution
is a probability distribution over all points in S - directly addressing characteristic 3 of this application (see Section 2).
This distribution assigns the probability of a missing person
being located at each point conditioned on the observers reporting V
their respective locations. Formally, it is written as
P r(Pp | o∈O Oo = po ).

ρβo =

|{c ∈ Co s.t. d(pc , pco ) ≤ β}|
|Co |

(6)

Hence, we also adjust ρβo to account for volume of the reporter’s history to provide the effect of regularization. Considering ηo as the portion of total number of cases in which
observer o has participated, to the total number of cases,
and  as a non-negative parameter, we define ρβ,
as follows:
o

The key intuition is that if we are able to compute an explanation distribution, we can then rank-order points in the
space by probability - and hence conserve search resources.
Note that the explanation distribution is over all points implying that there is precisely one location. While generalizations that allow for more than one location are possible
in such a probabilistic framework, we keep the size at one
due to the first characteristic of our problem (as described
in Section 2).
In this paper, we make an assumption of distance primacy
meaning the distance constraints (αo , βo ) relate the Pp with
V
o∈O Oo = po . Hence, we introduce another random vari0
o
able, Rβp,p
0 which is true if d(p, p ) ≤ βo and false otherwise.
Note that in the remainder of this section, we will use one

ρβ,
= ρβo −  × (1 − ηo )
o

(7)

The situation is further complicated with multiple distance constraints. We propose an optimization approach to
this problem in the next section.

5.

ALGORITHMIC APPROACH

In this section, we present our algorithmic approach to
special case of geospatial abductive inference. First, we explain the method that FMG currently uses. Then, we provide our proposed optimization approach to solve the problem.

1846

5.1

Existing Method

Therefore, the objective function we seek to optimize is

The FMG uses the following method to explore the missing person location. Given the reported locations provided
by different observers, FMG initially creates a search area
(grid) as follows. First, they draw building blocks (or boxes)
of size 1×1 mile centered at each reported location (note that
depending on the situation, these boxes may overlap). Then,
they search the entire grid in the following order. First, they
search the larger areas created of the overlapping boxes, and
if the missing person was not found, they explore the remaining boxes in the order of the observers’ history (how
well they did in the past). The whole process is repeated
by extending the size of boxes to 2×2 miles, if the missing
person was not located. Note that, we use the same grid in
our proposed methods.

5.2

L1 = max(F1 − F2 )

Theorem 5.1. Number of variables in single-distance constraint integer program is O(avg(|Co |) · |O|).
We extend the previous formulation by allowing the objective function to find a pair of distance constraints for each
reporter. We have experimentally found diminishing returns
on performance (and in many cases increased complexity)
with more than two constraints. This will give us the double
distance constraint integer program as follows:
XX X X h
F10 =
δα (pc , pco ) × log ρα,
× Xo,α,β
o
c∈C o∈O α∈[βo ]β∈[βo ]
β≥α

Proposed Methods





α,
+ 1 − δα (pc , pco ) × δβ (pc , pco ) × log ρβ,
× Xo,α,β +
o − ρo


i
(1 − δβ (pc , pco )) × log 1 − ρβ,
× Xo,α,β
o

As described, for simplicity, we first elaborate on the required steps to calculate the best βo for each observer. Then,
we extend the idea for multiple distance constraints. Let
[βo ] be the set of possible error radii. Note that for Co cases
where observer reported a location, there are at most |Co |
possible values for βo . Hence, our goal is to select as a set
of these distance constraints - one for each observer. We do
this through an integer program - where for each observer
o ∈ O and each associated distance constraint βo ∈ [βo ]
we have an indicator variable Xo,βo that is 1 if we use that
value and zero otherwise. We shall refer to this as the single
constraint integer program. Hence, we find an assignment of
values to these indicator variables in order to maximize the
following quantity:
XX X h
F1 =
δβ (pc , pco ) × log ρβo × Xo,β +

subject to the following constraints:

∀o,

Likewise, we use the following objective function, to avoid
bias toward selecting the largest β’s.
L2 = max(F10 − F20 )
where F20 is defined as follows:
XX X X h X
F20 =

(15)

0

δα (p, pco ) × log ρoα, × Xo,α,β +

c
c∈C o∈O α∈[βo ]β∈[βo ] p∈{S\p }
β≥α

(1 − δβ (pc , pco )) × log(1 − ρβo ) × Xo,β

i

(8)



1 − δα (p, pco ) × δβ (p, pco )×

(9)

log(ρoβ, − ρoα, ) × Xo,α,β +




i
0
1 − δβ (p, pco ) × log 1 − ρoβ, × Xo,α,β

subject to the following constraints:

0

∀Xo,β ∈ {0, 1}
X

Xo,β ≤ 1

(10)

X X

Xo,β = k

(11)

where k is a cardinality that limits the number of reporters
(which is set to a natural number in the range 1, . . . , |O|),
and δβ (x, y) is defined as:
(
1 if d(x, y) ≤ β
δβ (x, y) =
(12)
0 if d(x, y) > β
However, this equation will result in tendency toward selecting the largest distance constraints. This has the effect of not only maximizing the probability of the locations
where the missing person was found, but also can increase
the probability of other locations. Intuitively, we want to
also minimize the following quantity:
XX X
X h
0
F2 =
δβ (p, pco ) × log ρoβ × Xo,β
c∈C o∈O p∈{S\pc } β∈[βo ]
0

i

(16)

While we obtained a significant reduction in the area searched
by setting the cardinality constraint k = O, we found that
varying it would often lead to further improvement. We
gradually increased the number of observers from one to the
total number of observers and each time, we learned the
distance constraints for the last added observers. In this
method of optimization, we may choose a specific number
of points in each iteration. The number of points added
with each iteration can be determined based on available
resources.
We also defined two heuristic to discriminate points with
the same probability. In each iteration, we chose the point
with highest probability. If there were more than one point,
we applied following heuristics: (1) we chose the points
which had most of the reported locations in its 1 × 1 mile.
(2) we chose the point which had the maximum summation
of the priors of the reporters in its 1 × 1 mile.
Algorithm 1 is a specific variant of restricted model. In
this algorithm, in each iteration one point (i.e., representative of a 1 × 1 mile) is selected. Though we note that this

β∈[βo ]

+ (1 − δβ (p, pco )) × log(1 − ρoβ ) × Xo,β

0

Theorem 5.2. Number of variables in double distance constraint integer program is O(avg(|Co |)2 · |O|).

β∈[βo ]

o

∀Xo,α,β ∈ {0, 1}
X
Xo,α,β ≤ 1
α,β∈[βo ]

c∈C o∈O β∈[βo ]

∀o,

(14)

(13)

1847

Table 1: Description of the dataset
Value
12
76
41
47
9
39
40

can easily be adjusted in practice. If the area size we are
able to search is larger than number of observers, we sort
the representatives based on their probabilities. Then, we
apply two heuristics to rank them (similar to Lines 11-19 ).

10

Northeast

West

5

Figure 4: Distribution of the cases across different regions
of the US and international.

30
25
20
15
10

Foul play

Undetermined

Accidental

Runaway

Self-inflicted

Overview

Natural

0

MISSING PERSON DATASET

Bipolar

5
Staged

Number of cases

35

Reasons

Our dataset includes cases (i.e., missing persons), found
status (alive/deceased), found location (latitude and longitude), age and reason for disappearance as well as the potential locations (latitude and longitude) associated with the
reporters/experts. The description of this dataset is summarized in Table 1. Note that in some cases, we are aware of
reports, but do not have the found location (pco ). In this
work, we only have 29 cases with the known found locations
used for the experiments. However, for the data analysis,
the entire dataset is applied.

6.2

15

Regions

In this section, we describe our dataset and briefly discuss
the observation made from our initial data analysis.

6.1

20

0

Theorem 5.3. The time complexity of the algorithm (1)
is O(|C|·avg(|Co |)2 · avg(|Oc |)3 ).

6.

25

South

1: procedure Opt-Point-By-Point(A, c, S, ρ) . Train
set A, Test case c
2:
List R = ∅
. Output
3:
for k ∈ [1, |Oc |] do
. k is a constant value of the
constraint
4:
Find assignment of variables that optimize (15)
w.r.t. (9 - 11)
5:
RP ← Order by (5)
. Ranked points RP
6:
RP ← RP \ R
7:
Pick P ⊆ RP with largest probabilities
8:
if P includes one point then
9:
R=R∪P
10:
else
11:
p ← Heuristic(P )
12:
R = R ∪ {p}
13:
return R

30

Midwest

Algorithm 1 Iterative Search Resource Allocation

35

International

Number of cases

40

Drowning

Name
Found Status
Alive
Deceased
Gender
Male
Female
Age
Under 13
13 to 30
30 and older

northeast and south, according to the United States Census
Bureau. We further grouped together all cities outside the
U.S. into one single category, namely, international. The
distribution of cases across different regions is demonstrated
in Figure 4. Though we did not explicitly show in the figure,
the west is dominated by Arizona and California, due to the
large focus of FMG on these two states.
There are several known reasons of disappearance associated with the cases in our dataset including, accidental,
bipolar, drowning, foul play, natural, runaway, self-inflicted,
staged and undetermined. According to Figure 5, ‘foul play’
is the dominant reason for disappearance. There are also different number of reporters for each case. The distribution of
reporters with respect to the number of cases in which they
participated is shown in Figure 6.

Figure 5: Distribution of the cases with respect to the probable reasons.
For the rest of our data analysis, we need to introduce
some preliminary notation. We use the random variable gA
to denote if the missing person is found alive or not, so it is
either true or false. We shall use P r(gA = True|o stated Alive)
to denote the confidence of the observer o in reporting Alive.
This confidence value shows the portion of the cases for
which o has reported the missing person is Alive and he/she
was found Alive, to the total number of cases for which o has
reported Alive. Likewise, we compute the confidence of o in

Data Analysis

The dataset consists of cases distributed all over the world.
We split the U.S. based cases into 4 regions, west, midwest,

1848

18	

40	

16	

35	

Number	of	Reporters	

Number	of	Reporters	

45	

30	
25	
20	
15	
10	
5	
0	
1	

2	

3	

4	

5	
6	
7	 10	 13	
Frequency	of	Par=cipa=on	

15	

16	

17	

10	
8	
6	
4	
0	
0	

1	

2	

3	

4	
rA

5	

6	

7	

8	

180	

reporting Deceased. The distribution of the reporters with
respect to their confidence values is demonstrated in Figure 7. According to the figure, most reporters’ confidence
values belong to the ranges of [0.3,0.4) for alive and [0.8,0.9)
for deceased statuses.

Number	of	Reporters	

160	

alive	
deceased	

140	
120	
100	
80	
60	
40	
20	
0	
0.7	

0.9	
rD

1.1	

1.3	

Figure 8: The distributions of the reporters with respect to
rA and rD .

[0.9,	1]	

[0.8,	0.9)	

[0.7,	0.8)	

[0.6,	0.7)	

[0.5,	0.6)	

[0.4,	0.5)	

[0.3,	0.4)	

[0.2,	0.3)	

[0.1,	0.2)	

0.5	

[0,	0.1)	

Number	of	Reporters	

12	

2	

Figure 6: Distribution of frequency of participation.

18	
16	
14	
12	
10	
8	
6	
4	
2	
0	

14	

Conﬁdence	

baseline. Figure 9 shows the reduction of area based on our
approach (double distance constraint integer program with
Algorithm 1 and  = 0.1) when compared to the baseline.
We examine this with grid squares of 1×1 miles and 2×2
miles. In the 19 cases where the missing person was located,
our approach achieved area reduction in 11 cases - reducing
the search area by an average by 3 square miles. In the 2
cases where our method caused the search area to increase,
the increase was only 1 square mile in each case. This contrasts with the cases where the area was reduced - reducing
the search area by up to 9 square miles. For the 11 cases
where reduction was experienced, the average reduction was
1.63 miles (t(19) = 1.25, p <0.11).
We also examined cases where the size of the grid squares
was 2×2 miles. In the 19 cases, the area reduction achieved
by our method was in 14 cases, and by an average by 8.5
square miles. Further, in the 6 cases, our method caused
an increase in the search area, however, the increase was 3
square miles on average. Further, for the cases that baseline needs to search areas larger than 20 square miles, our
approach reduced the area from 7 to 56. Our method outperformed the baseline in area reduction with an average of
4.21 mile square (t(20) = 1.19, p <0.13).

Figure 7: Distribution of all reporters with respect to their
confidence values.
We also define the ratio rA as follows:
rA =

P r(gA = True|observer o stated Alive)
P r(gA = True)

(17)

This ratio demonstrates how much the observer o outperformed the prior probability P r(gA = True) on Alive. Similarly, we use rD for Deceased cases. The distributions of the
reporters with respect to rA and rD are shown in Figure 8.
We note that as most are found dead, it is harder for the
reporters to outperform the prior on Deceased compared to
the Alive.

7.

EXPERIMENTAL RESULTS

This section reports on the experiments conducted to validate our approach. We note that the individual cases themselves are not related - hence we are justified in using leaveone-out cross validation in our experiments. Specifically, for
each case in the experiments, we learn a different model
using all of the other cases. We first compare the methods for restricted (without dog) and unrestricted (with dog)
searches and then discuss the sensitivity of the parameter.

7.1

7.2

Consideration of Dog Team Detections

The experiments of the previous section illustrated how
our approach could reduce the search area over the baseline
for standard grid settings. However, in the events that a dog
team detects evidence of the missing person, it may lead to a

Area Reduction

In this section, we examine how our approach can be used
to reduce the area searched by the Find Me Group over the

1849

18

18
Baseline
Algorithm 1

14

14

12

12

10
8
6

8
6
4

2

2
0

2

4

6

8

10

12 14
Cases

16

18

20

0

22

(a) Search area with 1 × 1 mile per observation

2

4

6

8

10

12 14
Cases

16

18

20

22

60
Baseline
Algorithm 1

50

Baseline
Algorithm 1

50

Searched Area

40
30
20
10
0

0

(a) Search area with 1 × 1 mile per observation

60

Searched Area

10

4

0

Baseline
Algorithm 1

16

Searched Area

Searched Area

16

40
30
20
10

0

2

4

6

8

10

12 14
Cases

16

18

20

0

22

(b) Search area with 2 × 2 miles per observation

0

2

4

6

8

10

12 14
Cases

16

18

20

22

(b) Search area with 2 × 2 miles per observation

Figure 9: Searched area until the missing person is located
(baseline and Algorithm 1).

Figure 10: Searched area with dogs allowed to explore 1 mile
beyond the grid (baseline and Algorithm 1).

continued search outside of the assigned grid square. These
searches can lead to FMG personnel examining up to a mile
outside a designated location. In this section, we consider a
grid square settings in the last section, but also allow for an
additional mile outside the square to mimic the effect of the
dog search team following such a lead. Figure 10 demonstrates the reduction of area based on our approach (double
distance constraint integer program with Algorithm 1 and
 = 0.1) when compared to the baseline. We investigate the
area reduction with grid squares of 1×1 miles and 2×2 miles.
According to Figure 10a, in the 22 cases where the missing
person was located, our approach achieved area reduction in
12 cases - reducing the search area by 2 square miles on average. In the 2 cases where our method caused the search area
to increase, the increase was only 3 square miles on average.
This contrasts with the cases where the area was reduced
- reducing the search area by up to 9 square miles. Our
method outperformed the baseline in area reduction with
an average of 0.86 mile square (t(22) = 0.8, p <0.22).
We examined cases where the size of the grid squares was
2×2 miles. In the 24 cases, the area reduction achieved by
our method was in 21 cases, and on average by 8.85 square
miles. In the 3 cases where our method caused the search
area to increase, the increase was 4.3 square miles on average. This contrasts with the cases with the reduced search

area by up to 56 square miles. Our method outperformed
the baseline in area reduction with an average of 7.2 mile
square (t(24) = 1.95, p <0.05).

7.3

Parameter Sensitivity

We compare different values of  in both double distance
constraint integer programs (iterative search resource allocation and non-iterative program). The impact of changing
the parameter  is shown in Figure 11. To do so, we plot the
fraction of area searched by our method over the baseline,
against the , for both sizes of 1 × 1 and 2 × 2. We note that
while the extreme values of  (i.e. 0.0 and 0.5) negatively
effected the performance of both approaches, we achieved
relatively stable results for intermediate values - noting that
the best performance was to set  equal to 0.1 - which we
used in the experiments.
We also studied the performance of our optimization approach without algorithm 1 (i.e. prioritize locations by equation 5 after selecting the values for βo through optimization
of 19 with regards to Lines 9-11). The results are depicted
in Figure 12. The behavior of the algorithm for different
settings of  were similar to that found with Algorithm 1,
the reduction in search area was generally less - and in some
cases (i.e. 1x1 mile grid square with use of the dogs) it
performed worse.

1850

1.4

1.6

Without Dog
With Dog
Fraction of Searched Area

Fraction of Searched Area

1.6

1.2
1.0
0.8
0.6
0.4
0.2
0.0

1.4

Without Dog
With Dog

1.2
1.0
0.8
0.6
0.4
0.2

0.1

0.2

0.3

0.4

0.5

0.0

0.1

0.2

²
(a) Search area with 1 × 1 mile per observation (Algorithm 1)

1.4

Without Dog
With Dog

1.6

1.2
1.0
0.8
0.6
0.4
0.2
0.0

0.1

0.2

0.4

0.5

(a) Search area with 1×1 mile per observation not using Algorithm
1

Fraction of Searched Area

Fraction of Searched Area

1.6

0.3

²

0.3

0.4

1.4

Without Dog
With Dog

1.2
1.0
0.8
0.6
0.4
0.2

0.5

²

0.0

0.1

0.2

0.3

0.4

0.5

²
(b) Search area with 2 × 2 miles per observation (Algorithm 1)
(b) Search area with 2 × 2 miles per observation not using Algorithm 1

Figure 11: Fraction of total area searched across all cases
with the iterative search resource allocation approach over
the baseline.

8.

Figure 12: Fraction of total area searched across all cases
by the double distance constraint integer programming approach (not using Algorithm 1) over the baseline.

RELATED WORK

Recently, there has been some work [19, 20, 21, 23, 9] dealing with geospatial abductive inference introduced in [24].
In [19] for example, authors studied the case of geospatial
abduction where there is an explicit adversary who is interested in ensuring that the agent does not detect the partner
locations in an attempt to simulating the real-world scenario of insurgents who conduct IED (improvised explosive
device) attacks. Another work [20], has adopted geospatial
abduction to develop a software tool which applies geospatial
abduction to the environment of Afghanistan, to look for insurgent high-value targets, supporting insurgent operations.
The work of [21] introduced a variant of the GAPs called
region-based GAPs (RGAPs) which deals with the multiple
possible definitions of the subregions of the map. Finally,
spatial cultural abductive reasoning engine which solves spatial abductive problems was developed in [23]. Aside from
introducing GAP, the work of [24] demonstrated the accuracy of proposed framework on real-world dataset of insurgent IED attacks against US forces in Iraq. Further, the
work of [9], proposed a technique to reduce the computational cost of point-based GAPs. They presented an exact
algorithm for the natural optimization problem of pointbased GAPs. Geospatial abduction problems are related
to facility location [26] and sensor placement problems [10]
in that they identify a set of geo-locations to optimize a
cost or reward function. However, there are key differences
amongst these various frameworks that arise from the dif-

ference between explanation and optimization. See [22] for
further discussion on this topic.
Similarly, [1] presents a specific aspect of the well-known
qualification problem, namely spatial qualitative reasoning
approach, which aims at investigating the possibility of an
agent being present at a specific location at a certain time
to carry out an action or participate in an event, given
its known antecedents. This work is different from both
above papers and our study, as it takes on purely logical approach to formalizing spatial qualifications, while our work
and other aforementioned studies use geometric and probabilistic techniques. Further, the framework of this paper is
tailored specifically for the missing person problem.
Looking beyond geospatial abduction, recent research has
demonstrated that GPS (positional) data could be used to
learn rich models of human activity [16, 15, 17, 7]. For example, [16, 15, 17], modeled the human interactions and intentions in a fully relational multi-agent setting. They used
raw GPS data from a real-world game of capture the flag and
Markov logic- a statistical-relational language. Whereas [7]
developed a model to simulate the behaviors associated with
insurgent attacks, and their relationship with geographic locations and temporal windows.
At first glance, one may think our work is similar to [10],
in that they identify a set of geo-locations to optimize a
cost or reward function. However, as described, there are

1851

key differences amongst these various frameworks that arise
from the difference between explanation and optimization.
[11]

9.

CONCLUSION

In this paper, we have introduced the Missing Person Intelligence Synthesis Toolkit (MIST) which leverages a datadriven variant of geospatial abductive inference. MIST can
rank-order the set of search locations provided by a group
of experts. The experimental results showed that our approach is able to reduce the total search area by a total of 31
square miles for standard searched and by 19 square miles
when dog team assets obtain a detection. This reduction
will make FMG locating missing persons faster while saving in direct and indirect cost. At the time of this writing,
we have initiated support to FMG with MIST for an active
case. FMG will use MIST’s ranking of search locations for
this ongoing operation.
Our future plans include utilizing a probabilistic variant
of the feasibility function, applying other features such as
missing person’s region, age, gender to the model and extending our toolkit to be able to solve other problems such
as human trafficking.

[12]

[13]

[14]

[15]

[16]

Acknowledgement

[17]

This work was funded by the Find Me Group.

10.

[18]

REFERENCES

[1] B. Akinkunmi and P. C. Bassey. A Logic of Spatial
Qualification Using Qualitative Reasoning Approach.
International Journal of Artificial Intelligence &
Applications, 4(2):45, 2013.
[2] T. Bylander, D. Allemang, M. C. Tanner, and J. R.
Josephson. The Computational Complexity of
Abduction. Artif. Intell., 49(1-3):25–60, 1991.
[3] L. Console, L. Portinale, and D. T. Dupré. Focussing
Abductive Diagnosis. AI Commun., 4(2/3):88–97,
1991.
[4] L. Console, M. L. Sapino, and D. T. Dupré. The Role
of Abduction in Database View Updating. J. Intell.
Inf. Syst., 4(3):261–280, 1995.
[5] S. do Lago Pereira and L. N. de Barros. Planning with
abduction: A logical framework to explore extensions
to classical planning. In Brazilian Symposium on
Artificial Intelligence, pages 62–72. Springer, 2004.
[6] T. Eiter and G. Gottlob. The complexity of
logic-based abduction. Journal of the ACM, 42:3–42,
1995.
[7] S. George, X. Wang, J. Lin, B. Qu, and J.-C. Liu.
MECH: Algorithms and Tools for Automated
Assessment of Potential Attack Locations. Technical
report, Texas A & M University, College Station, 2015.
[8] A. C. Kakas and P. Mancarella. Database updates
through abduction. In VLDB, volume 90, pages
650–661, 1990.
[9] A. Koutsioumpas. Abductive reasoning in 2d
geospatial problems. In Applications of Mathematics
and Informatics in Science and Engineering, pages
333–347. Springer, 2014.
[10] A. Krause, J. Leskovec, C. Guestrin, J. Vanbriesen,
and C. Faloutsos. Efficient sensor placement
optimization for securing large water distribution

[19]

[20]

[21]

[22]

[23]

[24]

[25]
[26]

1852

networks. Journal of Water Resources Planning and
Management, 2008.
M. Pagnucco. The Role of Abductive Reasoning within
the Process of Belief Revision. PhD thesis, Basser
Department of Computer Science, University of
Sydney, 1996.
C. S. Peirce. Philosophical writings of Peirce, selected
and edited with an introd. by Justus Buchler. Dover
Publications New York, 1955.
Y. Peng and J. Reggia. Abductive inference models for
diagnostic problem-solving. Symbolic computation.
Springer-Verlag, New York, 1990.
Y. Peng and J. A. Reggia. Plausibility of Diagnostic
Hypotheses: The Nature of Simplicity. In Proceedings
of the 5th National Conference on Artificial
Intelligence. Philadelphia, PA, August 11-15, 1986.
Volume 1: Science., pages 140–147, 1986.
A. Sadilek and H. Kautz. Modeling Success, Failure,
and Intent of Multi-Agent Activities Under Severe
Noise.
A. Sadilek and H. Kautz. Location-based Reasoning
About Complex Multi-agent Behavior. J. Artif. Int.
Res., 43(1):87–133, Jan. 2012.
A. Sadilek and H. A. Kautz. Recognizing multi-agent
activities from gps data. In AAAI, volume 39, page
109, 2010.
P. Santos and M. Shanahan. Hypothesising object
relations from image transitions. In ECAI, pages
292–296, 2002.
P. Shakarian, J. P. Dickerson, and V. Subrahmanian.
Adversarial geospatial abduction problems. ACM
Transactions on Intelligent Systems and Technology
(TIST), 3(2):34, 2012.
P. Shakarian, M. K. Nagel, B. E. Schuetzle, and
V. Subrahmanian. Abductive inference for combat:
using scare-s2 to find high-value targets in
afghanistan. Technical report, DTIC Document, 2011.
P. Shakarian and V. Subrahmanian. Region-based
Geospatial Abduction with Counter-IED Applications.
In U. K. Wiil, editor, Counterterrorism and Open
Source Intelligence. Springer, 2010.
P. Shakarian and V. Subrahmanian. Geospatial
Abduction: Principles and Practice. SpringerLink :
Bücher. Springer New York, 2011.
P. Shakarian, V. Subrahmanian, and M. L. Spaino.
SCARE: A Case Study with Baghdad. In Proceedings
of the Third International Conference on
Computational Cultural Dynamics. AAAI, 2009.
P. Shakarian, V. Subrahmanian, and M. L. Spaino.
GAPs: Geospatial Abduction Problems. ACM
Transactions on Intelligent Systems and Technology,
2010.
M. Shanahan. Noise and the Common Sense
Informatic Situation for a Mobile Robot.
J. F. Stollsteimer. A working model for plant numbers
and locations. Journal of Farm Economics,
45(3):631–645, 1963.

Mining for Causal Relationships: A Data-Driven Study of
the Islamic State
Andrew Stanton, Amanda Thart, Ashish Jain, Priyank Vyas, Arpan Chatterjee, Paulo Shakarian∗
Arizona State University
Tempe, AZ 85287

{dstanto2, althart, ashish.jain.1, pvyas1, achatt14, shak} @asu.edu
ABSTRACT

which perhaps may be the source of its success. We have
meticulously encoded and recorded 2200 incidents of military activity conducted by ISIS and forces that oppose it
(including Iraqi, Syrian, and the American-led coalition) in
a relational database. Our goal was to achieve a better understanding of how this group operates - which can lead to
new strategies for mitigating ISIS’s operations. Specifically,
we sought to analyze the behavior of ISIS using concepts
from logic programming (in particular APT logic [14, 15])
and causal reasoning [10, 18]. By combining ideas from these
fields, we have been able to conduct a thorough search for
rules whose precondition consists of multiple atomic propositions, and we provide evidence of causality by comparing
rules with the same consequence. So, in addition to considering the probability of a rule (p), we also study a measure
of its causality denoted avg (previously introduced in [10]) –
which, informally, can be thought of as the average increase
in probability a rule’s precondition provides when considered
with each of the comparable rules. Using this approach, we
have found interesting relationships - consider the following:

The Islamic State of Iraq and al-Sham (ISIS) is a dominant
insurgent group operating in Iraq and Syria that rose to
prominence when it took over Mosul in June, 2014. In this
paper, we present a data-driven approach to analyzing this
group using a dataset consisting of 2200 incidents of military activity surrounding ISIS and the forces that oppose
it (including Iraqi, Syrian, and the American-led coalition).
We combine ideas from logic programming and causal reasoning to mine for association rules for which we present
evidence of causality. We present relationships that link
ISIS vehicle-bourne improvised explosive device (VBIED)
activity in Syria with military operations in Iraq, coalition
air strikes, and ISIS IED activity, as well as rules that may
serve as indicators of spikes in indirect fire, suicide attacks,
and arrests.

Categories and Subject Descriptors
J.4 [Social and Behavioral Sciences]: Sociology

• Weeks where ISIS conducts infantry operations in Iraq
that are accompanied by indirect fire are indicative of
vehicle-bourne improvised explosive device (VBIED)
operations in Syria in the following week (p = 1.0,
avg = 0.92).

General Terms
Security

Keywords
Rule learning, causality, security informatics

1.

• Weeks in which ISIS conducts operations in Tikrit
and conducts a significant number of executions are
followed by a large spike in improvised explosive device (IED) usage in Iraq and Syria combined (p =
1.0, avg = 0.97)

INTRODUCTION

Since its rise to prominence in Iraq and Syria in June,
2014, The Islamic State of Iraq and al-Sham (ISIS) – also
known as The Islamic State of Iraq and the Levant (ISIL)
or simply the Islamic State, has controlled numerous cities
in Sunni-dominated parts of Iraq and Syria. ISIS has displayed a high level of sophistication and discipline in its military operations in comparison to similar insurgent groups,

• Air strikes by the Syrian government are followed by
mass arrests by ISIS in the following week (avg =
0.91, p = 0.67), and such massive arrests were always
proceeded by Syrian air strikes in our dataset.

∗

Paulo Shakarian is also affiliated with ASU Center on the
Future of War.

• In the week after coalition air strikes are conducted
against Mosul while ISIS is conducting operations in
Al-Anbar province, ISIS greatly increases its IED activity in Iraq (p = 0.67, avg = 0.97). However, if
there are also significant ISIS operations occurring in
Syria, the increase in IED usage experienced there is
(p = 0.67, avg = 0.79).

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
KDD ’15, August 11 - 14, 2015, Sydney, NSW, Australia.
c 2015 ACM. ISBN 978-1-4503-3664-2/15/08 ...$15.00.

DOI: http://dx.doi.org/10.1145/2783258.2788591.

Our findings have also led us to several interesting theories
about ISIS behavior that we have developed as a result of
this data mining effort. These include the following:

2137

• For f = f 0 ∧f 00 , Th[t] |= f iff Th[t] |= f 0 and Th[t] |= f 00

• ISIS may employ suicide VBIED operations in Baghdad prior to significant infantry operations in other locations to prevent the deployment of Iraqi army/police
reinforcements.

• For f = f 0 ∨ f 00 , Th[t] |= f iff Th[t] |= f 0 or Th[t] |= f 00
We also note that based on how often a given formula occurs within a thread, we can obtain a prior probability for
that formula. For instance, consider formula g. We can compute its prior probability (w.r.t. thread Th) as the fraction
of time points where g is satisfied:

• ISIS tends to leverage indirect fire (IDF) as a precursor
to infantry operations - more in keeping with a traditional military force as opposed to a primary use of
IDF for harassment purposes (as was typically seen by
insurgent groups during Operation Iraqi Freedom).

ρ=

• As we found relationships between coalition air operations and an increase in ISIS usage of IEDs - and
not other, larger weapons systems (i.e. VBIEDs), this
may indicate that ISIS resorts to more distributed,
insurgent-style tactics in the aftermath of such operations.
To our knowledge, this study represents both the first publiclyavailable, data-driven study of ISIS as well as the first combination of APT logic with the causality ideas of [10]. The
rest of the paper is organized as follows. In Section 2, we describe our approach and recall key concepts from APT logic
and causal reasoning. This is followed by a description of
our corpus of military events surrounding the actions of ISIS
from June-December, 2014 in Section 3. In Section 4, we describe our implementation and discuss our results. Finally,
related work is reviewed in Section 5.

2.

TECHNICAL APPROACH

2.1

APT Logic

We now present a subset of our previously-introduced
APT logic [14, 15]. Our focus here is on the syntax of the
language utilized with an alternate semantics that is based
on the rule-learning approach described in [14]. This is due
to the fact that we are only concerned with learning the
rules in this paper and determining their level of causality
– we leave problems relating to deduction (i.e. the entailment problem studied in [15]) to future work. APT logic
considers a two-part semantic structure: threads (sequences
of events) and interpretations (probability distributions over
such sequences). Initially, we focus on a semantics restricted
to threads.
We assume the existence of a set of ground atoms, A which
in this case correspond with events over time and use the
symbol n to denote the size of this set. We shall partition
the ground atoms into two subsets: action atoms Aact and
environmental atoms Aenv . Action atoms describe actions
of certain actors, and environmental atoms describe aspects
of the environment. We will use nact , nenv to denote the
quantity of ground atoms in Aact , Aenv , respectively. We
can connect atoms using ¬, ∧, ∨ to create formulas in the
normal way. A world is a subset of atoms that are considered
to be true. A thread is a series of worlds, each corresponding
to a discrete time-point, which are represented by simple
natural numbers in the range 1, . . . , tmax . We shall use Th[t]
to refer to the world specified by Th at time t. A thread
(Th) at time t satisfies a formula f (denoted Th[t] |= f ) by
the following recursive definition:

|{t|Th[t] |= g}|
tmax

(1)

Note that we use the notation | · | for the cardinality of a set.
Our goal in this section is for some event g to identify previously occurring event c such that the conditional probability
of g occurring given c is greater than pg . In this paper, we
shall only look at finding APT rules where c occurs in the
time period right before g. The case where multiple time periods elapse between c and g is left to future work. Hence, we
introduce an APT rule of the following form: c ;p g, which
intuitively means that “c is followed by g in one time-step
with probability p.” We shall refer to c as the precondition
and g as the consequence. We say thread Th |= c ;p g iff:
p=

|{t s.t. Th[t] |= c and Th[t + 1] |= g}|
|{t s.t. Th[t] |= c}|

(2)

This alternate definition of semantics is not new: it is a variant of rule satisfaction with the existential frequency function of [14] and also of “trace semantics” used for a PCTL
variant in [9]. In this paper, we are focused on learning rules
where c is a conjunction of positive atoms and g is a single
positive atom. The number of atoms in the conjunction c is
referred to as the “dimension” of the rule c ;p g. We will
also be concerned with two other measures of a given rule:
the “negative probability” (used to describe the probabilistic
rules of [17]) and the notion of support (a standard concept
in association rule learning). First, we define “negative probability” – denoted p∗ – for a given rule of the aforementioned
format.
|{t s.t. Th[t] |= g and Th[t − 1] 6|= c}|
(3)
p∗ =
|{t s.t. Th[t] |= g}|
Simply put, p∗ is the number of times that the consequence
of a rule occurs without the head occurring prior. We can
think of p as a measure of precision of a given rule while p∗
is more akin to a measure of recall. Next, we formally define
the notion of support (s) as follows.
s = |{t s.t. Th[t] |= c}|

(4)
pr , p∗r , sr ,

For a given rule r, we shall use the notation
respectively. We will also use the notation ρr to denote the
prior probability of the consequence. When it is obvious
from context which rule we are referring to (as in the experimental results section), we will drop the subscript.

2.2

Determining Causality

Next, we describe how for a given action, g, we identify
potential causes based on a set of rules for which g is the
consequence. In considering possible causes, we must first
identify a set of prima facie causes for g [10, 18]. We present
the definition in terms of APT logic below.
Definition 2.1 (Prima Facie Cause [10, 18]). Given
APT logic formulas c, g and thread Th, we say c is a prima
facie cause for g w.r.t. Th if:

• For some a ∈ A, Th[t] |= a iff a ∈ Th[t]
• For f = ¬f 0 , Th[t] |= f iff Th[t] |= f 0 is false

2138

1. There exists time t such that Th[t] |= g (g occurs with
a probability greater than zero)

r is not present. Hence, a number closer to 1 likely indicates that r is more causal. By using multiple causality
measurements, we can have a better determination of more
significant causality relationships.

2. There exists t, t0 where t < t0 such that Th[t] |= c and
Th[t0 ] |= g (c occurs before g)

2.3

3. For r ≡ c ;p g where Th |= r, we have p > ρr (the
probability of the consequence occurring after the precondition is greater than the prior probability of the
consequence)
As we will assume the existence of a single thread, Th
(which is our historical corpus of data), we will often use the
language “prima facie causal rule” or “PF-rule” to describe
a rule c ;p g where c is a prima facie cause for g w.r.t. Th.
Next, we adopt the method of [10] to determine if an APT
rule is causal. First, in determining if a given PF-rule is
causal, we must consider other, related PF-rules. Intuitively,
a given rule r ≡ c ;p g explains why some instances of g
occur within a thread. Another rule r0 ≡ c0 ;p0 g is related
if it also explains why some of those same instances occur.
Formally, we say r and r0 are related if there exists t such
that Th[t] |= c ∧ c0 and Th[t + 1] |= g. Hence, we will define
related PF-rules (for a given rule r ≡ c ;p g) as follows.

• We reduce the run-time of the algorithm considerably
over APT-Extract. As APT-Extract explores all possible combinations ofatoms up to size M axDim, it runs
env
). However, PF-Rule-Extract only
in time O( M naxDim
examines combinations of atoms that occur in a given

maxt (nt )
time period – hence, reducing run-time to O( M
)
axDim
where nt is the number of atoms in Aenv true at time
t. We find in practice that maxt (nt ) << nenv .
• We further reduce the run-time by not considering elements of Aenv that occur less than the lower bound
on support - as they would never appear in a rule.

R(r) = {r0 s.t. r0 6≡ r and r, r0 are related}
Next, we will look at how to compare two related rules.
The key purpose from [10] behind doing so is to study how
the probability of the rule changes in cases where both preconditions co-occur in comparison to the probability where
exactly one of the preconditions occurs. So, given rules r, r0
as defined above, we have the following notation: pr,r0 and
p¬r,r0 , which are defined as the point probabilities that will
cause the following two rules to be satisfied by Th.

• We guarantee that all rules returned by PF-Rule-Extract
are PF-rules.
Algorithm 1 PF-Rule-Extract
Require: Thread Th, sets of atoms Aact , Aenv , positive natural numbers M axDim, SuppLB, real number
minP rob
Ensure: Set of rules R

c ∧ c0 ;pr,r0 g
¬c ∧ c0 ;p¬r,r0 g

1: Set R = ∅
2: for g ∈ {a ∈ Aact s.t. ∃t where Th[t] |= a} do
3:
preCond(g) = ∅
4:
for t ∈ {1, . . . , tmax s.t. Th[t + 1] |= g} do
5:
Let X be the set of all combinations of size
M axDim (or less) of elements in Th[t] ∩ Aenv that
occur at least SuppLB times.
6:
preCond(g) = preCond(g) ∪ X
7:
end for
8:
for c ∈ preCond(g) do
9:
Compute ρ, p, s, as per Equations 1,2, and 4
10:
if (s ≥ SuppLB) ∧ (p > ρ) ∧ (p ≥ minP rob) then
11:
R = R ∪ {r}
12:
end if
13:
end for
14: end for
15: return Set R

So, pr,r0 is the probability that g occurs given both preconditions, and p¬r,r0 is the probability that g occurs given just
the precondition of the second rule and not of the first. The
idea is that if pr,r0 − p¬r,r0 > 0, then there is something
about the precondition of r that causes g to occur that is
not present in r0 . Following directly from [10], we measure
the average of this quantity to determine how causal a given
rule is as follows:
P
0
0
r 0 ∈R(r) pr,r − p¬r,r
avg =
|R(r)|
Intuitively, avg (r) measures the degree of causality exhibited by rule r. Additionally, using this same intuition, we
find it useful to include a few other related measures when
examining causality. First, we define min , defined below:
min

=

min (pr,r0 − p¬r,r0 )

r 0 ∈R(r)

Note that APT-Extract allows for multiple time periods
between preconditions and consequences – PF-Rule-Extract
can also be easily modified to find rules of this sort through a
simple modification of line 4. Next, we provide some formal
results to show that PF-Rule-Extract finds rules that meet
the requirements of Definition 2.1 and show that it explores
all possible combinations up to size M axDim that are supported by the data that meet the requirement for minimum
support even with our efficiency improvements.

This tells us the “least causal” comparison of r with all related rules. Another measure we will use is f rac , defined as
follows:
f rac (r)

=

Algorithms

Next, given a thread, we provide a variant of the APTExtract algorithm [14] that we call PF-Rule-Extract. Essentially, this algorithm generates all possible Aenv up to a
certain size (specified by the argument M axDim) and then
searches for correlation. It returns rules whose precondition occurs a specified number of times (a lower bound on
support for a rule) - specified with the argument SuppLB.
We make several modifications specific to our application to
support reasoning.

|{r0 s.t. (pr,r0 − p¬r,r0 ) ≥ 0}|
|R(r)|

This provides a fraction of the related rules whose probability remains the same or decreases if the precondition of

2139

3.

Proposition 2.1. Given thread Th as input, PF-RuleExtract produces a set of rules R such that each r ∈ R is a
prima facie causal rule.
Proof. The first requirement for a prima facie cause is
met by line 2 of PF-Rule-Extract, as the algorithm only considers consequences that have occurred at least once in Th –
hence, they have a prior probability greater than zero. The
second requirement is met by line 4, as we only consider
atoms that occurred immediately before the consequence
when constructing the precondition. Finally, the third condition is met by the if statement at line 10 which will only
select rules whose probability is greater than the prior probability of the consequence.
Proposition 2.2. PF-Rule-Extract finds all PF-rules whose
precondition is a conjunction of size M axDim or a size containing fewer atoms and where both the precondition occurs
at least SuppLB times in Th and the probability is greater
than minP rob.
Proof. By Proposition 2.1, every consequence that could
be used in a PF-rule is considered, so we need only to consider the precondition. Suppose that there is a PF-rule
whose precondition occurs at least SuppLB times that has a
size of M axDim or smaller. Hence, the precondition is comprised of m ≤ M axDim atoms: a1 , . . . , am . Clearly, as this
precondition occurs at least SuppLB times in Th, each of
a1 , . . . , am must also occur SuppLB times by line 5 - so that
the precondition must be considered at that point. The only
condition that would prevent the rule from being returned
is line 10, but again, clearly these are met by the statement
of the proposition. Hence, we have a contradiction.

ISIS DATASET

We collected data on 2200 military events that occurred
from June 8th through December 31st, 2014 that involved
ISIS and forces opposing ISIS. Events were classified into one
of 159 event types - and these events were used as predicates
for APT logic atoms. We list a sampling of the predicates
we used in Table 1. Many predicates are unary because
they correspond with ISIS actions (i.e. armedAtk) while
those dealing with operations by other actors (i.e. airOp)
and predicates denoting spikes in activity (i.e. VBIEDSpike)
accept more than one argument. Nearly every predicate has
one argument that corresponds to the location in which the
associated event took place. See Figure 1 for a sampling of
locations in the ISIS dataset.
We obtained our data primarily from reports published by
the Institute for the Study of War (ISW) [5], and we augmented it with other reputable sources including MapAction
[4, 6], Google Maps [3], and Humanitarian Response [2]. We
devised a code-book as well as coding standards for events,
and one of our team members functioned as a quality-control
to reduce errors in human coding.
Figure 1: Map illustrating cities associated with events in
the ISIS dataset.

Once we have identified the PF-rules using PF-Rule-Extract,
we must then compare related rules with each other. The algorithm PF-Rule-Compare returns the top k rules for each
consequence. Again, here we take advantage of our specific application to reduce the run-time of this comparison.
In particular, for a given rule, we need not compare it to
all the rules returned by PF-Rule-Extract; we only need to
compare it to those that share the consequence. By sorting
the rules by consequence - a linear time operation (line 3),
we are able to reduce the cost of the quadratic operation
for the rule comparisons (a brute-force method would take
O(|R|2 ) while this method requires O((maxg |Rg |)2 + |R|) –
and we have observed that maxg |Rg | << |R|).
Algorithm 2 PF-Rule-Compare
Require: Set of rules R, natural number k
Ensure: Set of rules R0
1: Set R0 = ∅.
2: for g ∈ Aact do
3:
Set Rg = {c ;p g ∈ R}
4:
for r ∈ Rg do
5:
Calculate avg for rule r (Equation 5 by comparing
it to all related rules in Rg \ {r})
6:
end for
7:
From the set Rg , add the top k rules by avg to the
set R0
8: end for
9: return Set R0

4.
4.1

RESULTS AND DISCUSSION
Experimental Setup

We implemented our PF-Rule-Extract and PF-Rule-Compare
in Python 2.8x and ran it on a commodity machine equipped
with an Intel Core i5 CPU (2.7 GHz) with 16 GB of RAM
running Windows 7. The time periods we utilized were
weeks - hence, we had 30 time periods in our thread. We had
980 distinct environmental atoms (Aenv ). Our action atoms
(Aact ) corresponded to weeks where the number of incidents
for certain activity rose to or past one or two moving standard deviations (denoted 1 × σ, 2 × σ respectively, computed
based on the previous 4 weeks) above the four-week moving
average (computed based on the previous 4 weeks). We refer to these atoms as “spikes” and show some sample atoms
denoting such spikes in Table 1. The spikes are designated
for three locations: Iraq, Syria, or both theaters combined.
We also included these spikes in the set of environmental
atoms as well (Aact ⊂ Aenv ).
We set the parameters of PF-Rule-Extract as follows:
M axDim = 3, SuppLB = 3, minP rob = 0.5. For PF-Rule-

2140

Table 1: A sampling of predicate symbols used to describe
events in the ISIS Dataset
Predicate
Intuition
airOp(X, Y )

Actor X (typically “Coalition,”
“Syrian Government,” or “U.S.”)
conducts an air campaign against
ISIS in the vicinity of city Y .

armedAtk(X)

ISIS conducts an armed attack
(a.k.a. infantry operation) in city
X.

IED(X)

ISIS conducts an attack using an
improvised explosive device (IED)
in city X.

indirectFire(X)

ISIS conducts an indirect fire operation (i.e. mortars) near city X.

VBIED(X)

ISIS conducts an attack using a
vehicle-bourne improvised explosive device (VBIED or car-bomb) in
city X.

armedAtkSpike(X, Y )

There is a spike in ISIS armed
attacks in country X that is Y
amount over the 4-month moving
average (Y is expressed in terms of
moving standard deviations).

VBIEDSpike(X, Y )

There is a spike in ISIS VBIEDs in
country X that is Y amount over
the 4-month moving average (Y is
expressed in terms of moving standard deviations).

Table 2: Improvement in Algorithm Efficiency
Technique
Atoms Combinations
Explored
APT-Extract [14]
980
182, 122, 025
maxt (nt )
93
8, 853, 042
maxt (nt ) and consider
49
1, 296, 834
only atoms that occur more
than SuppLB times

4.3

ISIS Military Tactics

In this section, we investigate rules that provide insight
into ISIS’s military tactics – in particular, we found interesting and potentially casual relationships that provide insight into their infantry operations, use of terror tactics (i.e.
VBIEDs), and decisions to employ roadside bombs and to
launch suicide operations.

Compare, we did not set a particular k value. Instead, we
used avg to rank the rules by causality for a given consequence. In this paper, we report the top causal rules (in
terms of avg ) for some of the consequences. We also note
that the number of related rules provides insight into that
rule’s significance - we discuss this quantity in our analysis. We examine some of the top rules in terms of avg and
describe the military insights that they provide. Our team
includes a former military officer with over a decade of experience in military operations that includes two combat tours
in Operation Iraqi Freedom. In addition to avg , we also examined the rule’s probability (p) - the fraction of times the
consequence follows the precondition, the negative probability (p∗ ) - the fraction of times the consequence is not
proceeded by the precondition, the prior probability of the
consequence (ρ), and the additional causal measures introduced in this paper - min , f rac . The relationship specified
in the rule can be considered more significant if p >> ρ, p∗
is closer to 0, min ≥ 0, and avg , f rac are close to 1. These
measures are discussed in more detail in Section 2.

4.2

were conjunctions of atoms of up to size 3 in our experiments). First, we limited the number of atoms to be used
in such combinations based on the weeks in which they occurred. Even though we had 980 environmental atoms, no
more than 93 occurred during any given week (this is the
value maxt (nt ) from Section 2). Further, by eliminating
atoms that occurred less than the SuppLB from consideration, this lowered it further to 49 atoms per week at the
most. This directly leads to fewer combinations of atoms
generated for the precondition. A comparison is shown in
Table 2. Note that the values for APT-Extract are exact,
while the remaining are upper bounds. Again, this substantial, multiple-order-of-magnitude savings in the number
of rules explored is a result of the relative sparseness of our
dataset and the fact that our preconditions consisted of conjunctions of positive atoms. This efficiency is primarily what
enabled us to find and compare rules in a matter of minutes
on a commodity system.

Table 3: Causal Rules for Spikes in Armed Attacks (Iraq
and Syria Combined)
No.

Precondition

avg

p

p∗

1.

indirectFire(Baiji)∧

0.81

0.67

0.50

0.81

0.67

0.50

armedAtk(Balad)
2.

indirectFire(Baiji)∧
armedAtk(Balad)∧
VBIED(Baghdad)

Armed Attacks. The prior probability of large spikes
(2 × σ) (see figure 2) for ISIS armed attacks for Iraq and
Syria was 0.154. However, for our two most causal rules
for this spike (Table 3), we derived this probability as 0.67.
Such spikes likely indicate major infantry operations by the
Islamic State. Rule 1 states that indirect fire at Baiji (attributed to ISIS) along with an armed attack in Balad leads
to a spike in armed attacks by the group in the next week
while rule 2 mirrors rule 1 but adds VBIED activity in Baghdad as part of the precondition. We note the relatively high
p∗ (0.5 in this case), which indicates that each spike in armed

Algorithm Efficiency

In Section 2, we described some performance improvements that we utilized in PF-Rule-Extract (which is based
on APT-Extract [14]) that are specific to this application.
The first performance improvement was the reduction in the
number of atoms used to generate the preconditions (which

2141

attacks of this type are not necessarily proceeded by this precondition, despite the relatively high value for avg , hinting
at causality (each of these rules was compared with 265 related rules and had f rac = 1 and min = 0 – showing little
indication of a related rule being more causal). We believe
that the strong causality and the high value for p∗ indicate
that these rules may well be “token causes” – causes for a
specific event - in this case, we think it is likely ISIS offensive
operations in Baiji. This makes sense, as a common military
tactic is to prepare the battlefield with indirect fire (which it
seems ISIS did in the prior week). It is unclear if the VBIED
incidents in Baghdad are related due to the co-occurrence.
That said, it is notable that VBIED operations are often
used as “terror” tactics as opposed to part of a sustained
operation. If so, this may have been part of a preparatory
phase (that included indirect fire in Baiji), and the purpose
of the VBIED events in Baghdad was to prevent additional
Iraqi Security Force deployment from Baghdad to Baiji. We
note in one case supporting this rule (on July 25th, 2014)
that ISIS also conducted IED attacks on power-lines that
support Baghdad - which may have also been designed to
hinder deployment of reinforcements. Here, it is also important to note the ongoing Infantry operations in Balad
(specified in the precondition) - which would consume ISIS
resources and perhaps make it more difficult to respond to
further deployment of government security forces. Though
this is likely a token cause, this may be indicative of ISIS
tactics when preparing to concentrate force on certain objectives (in this case Baiji) while maintaining ongoing operations (Balad), as a spike in armed attacks likely indicates a surge of light infantry-style soldiers into the area (a
manpower-intensive operation).

Table 4: Causal Rules for Spikes in VBIED Incidents in
Iraq and Syria Combined
No.

Precondition

avg

p

p∗

3.

armedAtk(Balad)∧

0.95

1.00

0.25

indirectFire(Baiji)

is only 0.25 - which means that most of the VBIED spikes
we observed were related to operations in Balad and Baiji.
This highlights the strategic importance of these two cities
to ISIS: Baiji is home to a major oil refinery while Balad is
near a major Iraqi air base. We also found solid evidence of
causality for this rule - based on 209 related rules, we found
min = 0.5 which means adding a second precondition to
this rule increases the probability of the second rule by at
least 0.5
Figure 3: Spikes in ISIS VBIED Activity in Iraq and
Syria per Week
18

VBIEDs
Moving Average + 2σ

Number of Events

16
14
12
10

8
6
4
2
0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

Figure 2: ISIS Spikes in Armed Attacks in Iraq and
Syria per Week
35

30

Number of Events

Spikes in IED Incidents. Improvised explosive device
(IED) incidents have been a common tactic used by Iraqi insurgents throughout the U.S.-led Operation Iraqi Freedom.
Though the IED comprises a smaller weapons system normally employed by local insurgent cells, spikes in such activity could be meaningful. For instance, it may indicate
action ordered by a strategic-level command that is being
carried out on the city level, or it may indicate improved
logistic support to provide local cells the necessary munitions to carry out such operations in larger numbers. Such
spikes only occur with a prior probability of 0.19. In Table 5,
we show a rather strong precondition for such attacks that
consist of infantry operations in Tikrit and a spike in executions. In this Table, rule 4 states that infantry operations
in Tikrit, when accompanied by a spike in executions, lead
to a spike (1 × σ) (see figure 4) in Iraq and Syria combined
- with a probability of 1.0 - much higher than the prior of
the consequence. With avg of 0.97 (based on a comparison with 1180 other rules), this relationship appears highly
causal (f rac = 1.0, min = 0.0) although 40% of 1 × σ IED
spikes were not accounted for by this precondition.

Armed Attacks
Moving Average + 2σ

25

20
15
10
5
0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

Spikes in VBIED Incidents. VBIED incidents have been
a common terror tactic used by religious Sunni extremist
insurgent groups in Iraq in the past – including Al Qaeda
in Iraq, Ansar al Sunnah, Ansar al Islam, and now ISIS.
We found two relationships that are potentially causal for
spikes in VBIED activity in Iraq and Syria combined, shown
in Table 4.
Rule 3 states that if infantry operations in Balad accompanied by indirect fire operations in Baiji occur, we should
expect a major (2 × σ) spike in VBIED activity (see figure 3) by ISIS (Iraq and Syria combined). We believe this
rule provides further evidence of the use of VBIEDs to pull
security forces away from other parts of the operational theater. It is interesting to note that the negative probability

4.4

Relationships between Iraqi and Syrian Theaters

ISIS has clearly leveraged itself as a force operating in
both Iraq and Syria, and the identification of relationships
between incidents in relation to the two theaters may indicate some sophisticated operational coordination on their

2142

Figure 4: Spikes in ISIS IEDs in Iraq and Syria per
Week
10

IEDs

4.5

8

Number of Events

VBIEDs
Moving Average + σ

4

Moving Average + σ
Number of Events

9

Figure 5: Spikes in ISIS VBIEDs in Syria per Week

7
6
5
4
3

3.5

3
2.5
2

1.5
1

2

0.5

1

0
1

0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

29

Week

Figure 6: Comparison of ISIS Armed Attacks and
VBIEDs in Syria per Week

Table 5: Causal Rules for Spikes in IED Incidents in Iraq
and Syria Combined

7

Precondition

avg

p

p

4.

armedAtk(T ikrit)∧

0.97

1.00

0.40

Number of Events

No.

Armed Attacks

VBIEDs

6

∗

executionSpike(T otal, 2σ)

5
4

3
2
1

part. We have found some evidence of these cross-theater
relationships with regard to suicide operations in Iraq (potentially affected by other events in Syria) and VBIED operations in Syria (potentially affected by other operations in
Iraq).

0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

Table 6: Causal Rules for Spikes in VBIED Operations in
Syria

VBIED Spikes in Syria. Table 6 shows our most causal
rules whose consequence is a 1×σ spike (over the four-month
moving average) (see figures 5, 6) in ISIS VBIED events in
Syria. Rule 5 provides a precondition of a spike in armed
attacks in Iraq that includes a major spike in indirect fire
activity while rule 6 has the same precondition but includes
an additional VBIED event in Baghdad. We believe that
the spike in armed attacks indicates major ISIS operations
in Iraq and the inclusion of indirect fire events also indicates that ISIS soldiers specializing in weapon systems such
as mortars may also be concentrated in Iraqi operations.
Taken together, this may indicate a shift in ISIS resources
toward Iraq - which may mean that operations have shifted
away from Syria. Hence, VBIED attacks, which once prepared, are less manpower-intensive, nevertheless provide a
show-of-force in the secondary theater. We also note that
the probability of these rules (1.00) is significantly higher
than the prior of these spikes (0.19) and that the causality
value is also high for each of the 983 related rules, as the
probability either remains the same or increases when considering one of these preconditions (in other words, f rac = 1
and min = 0).

No.

Precondition

avg

p

p∗

5.

armedAtkSpike(Iraq, σ)∧

0.92

1.00

0.20

0.92

1.00

0.20

indirFireSpike(Iraq, 2σ)
6.

armedAtkSpike(Iraq, σ)∧
indirFireSpike(Iraq, 2σ)∧
VBIED(Baghdad)

significant indirect fire operations in Syria (that occur with a
prior probability of 0.08). As discussed earlier, indirect fire is
normally used to “prepare the battlefield” for infantry operations, so this rule may be indicative of a shift in manpower
toward Syria - and the use of a VBIED tactic in Baghdad
(less manpower-intensive but very sensational) seems to always proceed a major (2 × σ over the moving average) spike
in indirect fire activity in Syria in our data (hence, a negative
probability of 0.0).

Table 7: Causal Rules for Spikes in Indirect Fire Operations in Syria

Operations Shifting to Syria. In rules 5 and 6 of Table 6, we saw how increased operations in Iraq led to the
use of VBIEDs in Syria – perhaps due to a focus on more
manpower-heavy operations in Iraq. Interestingly, rule 7
shown in Table 7 indicates that less manpower-intensive
operations in Iraq that have a terror component seem to
have a causal relationship (based on avg = 0.97, f rac =
1.0, min = 0.5 found by comparing to 95 related rules) with

No.

Precondition

avg

p

p∗

7.

IED(Baghdad)∧

0.97

0.67

0.00

VBIED(Ramadi)

2143

4.5

ISIS Activities Related to Opposition Air
Strikes

Table 8: Causal Rules for Spikes in Arrests (Iraq and Syria
Combined)
No.

Precondition

avg

p

p∗

8.

airStrike(SyrianGov, Damascus)

0.91

0.67

0.00

Reaction to Syrian Government Air Strikes. Rule 8,
shown in Table 8, tells us that a 2 × σ spike in arrests (see
figure 7) was always (p∗ = 0.0) proceeded by an air strike
conducted by the Syrian government. The prior probability
for such a spike in arrests is 0.08. Further, we found evidence
of causality - the actions of the Syrian government raised the
probability of each of 33 related rules by at least 0.5. One
potential reason to explain why arrests follow Syrian air operations is that unlike western nations, Syria generally lacks
advanced technical intelligence-gathering capabilities to determine targets, and Syria likely relies on extensive human
intelligence networks - especially within Iraq and Syria. Successful targeting from the air by the Syrian government may
then indicate that ISIS’s counter-intelligence efforts (activities designed to locate spies within its ranks) may have failed
and so the organization perhaps then decides to conduct
massive arrests.

Figure 8: Spikes in ISIS Suicide Operations in Iraq
per Week
4.5

Number of Events

Number of Events

3

2.5
2
1.5
1

0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

Table 10: Causal Rules for Major Spikes in IED Operations
in Iraq

Moving Average + 2σ

3

Moving Average + 2σ

3.5

0.5

Arrests

3.5

Suicide Attacks

4

Figure 7: Spikes in ISIS Arrests in Iraq and Syria
per Week
4

presented thus far, it has a value for min of 0.3 - the minimum increase in probability afforded to any of the 82 related
rules to which we add the precondition of rule 9. The precondition indicates that ISIS may have recently expended a
VBIED (expensive in terms of equipment) while it has ongoing infantry operations in Balad (expensive in terms of
personnel) - hence, it may seek a more economical attack
(in terms of both manpower and equipment) that still has
a significant terror component - and it would appear that a
suicide attack provides a viable option to respond to such
air strikes.

No.

Precondition

avg

p

p∗

10.

airStrike(Coalition, M osul)∧

0.97

0.67

0.33

2.5

armedAtk(F allujah)

2
1.5
1

Table 11: Causal Rules for Major Spikes in IED Operations
in Syria

0.5

0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

No.

Precondition

avg

p

p∗

11.

airStrike(Coalition, M osul)∧

0.79

0.67

0.33

armedAtk(Ramadi)∧
armedAtkSpike(Syria, σ)

Table 9: Causal Rules for Major Spikes in Suicide Operations in Iraq
No.

Precondition

avg

p

p∗

9.

airStrike(IraqGovt, Baiji)∧

0.71

0.67

0.60

Reaction to Air Strikes by the U.S.-led coalition.
Rules 10 (f rac = 1.0, min = 0.5, 562 related rules) and
11 (f rac = 1.0, min = 0.38, 81 related rules) - shown in
Tables 10 and 11 - illustrate two different outcomes from
coalition air operations in Mosul. In both cases, ISIS has
active operations in the Al-Anbar province – both Ramadi
and Fallujah have similar demographics. Hence, the major
difference is that the precondition of rule 11 also includes
significant infantry operations in Syria. So, even though
both rules result in an increase in IED activity (2 × σ above
average, a spike that in both cases occurs with a prior probability of 0.12) (see figures 9, 10) - the increase occurs in Iraq
for rule 10 and Syria for rule 11. It may be the case that
ISIS is increasing IED activity in response to coalition air

armedAtk(Balad)∧
VBIED(Baghdad)
Reaction to Iraqi Government Air Strikes. In Table 9,
rule 9 tells us that a 2 × σ spike (see figure 8) in suicide operations in Iraq is related to a precondition involving Iraqi
aerial operations in Baiji, ISIS infantry operations in Balad,
and a VBIED in Baghdad. The rule shows that these spikes
in suicide operations are 3.5 times more likely with this precondition. Though avg is lower than some of the other rules

2144

strikes in the location of their main effort. Further, the relatively low negative probability (0.33) along with relatively
high values for min may indicate that coalition air strikes
in Mosul are likely viewed as important factors contributing
to ISIS decisions to increase IED activity. We may also note
that the use of IED activity in the aftermath of coalition
air strikes could also be due to the size of the weapon. An
IED can be fairly small, easily disassembled and stored in
an innocuous location - hence, it is weapon system that the
coalition cannot sense and target from the air.

logic representation for understanding group behaviors and
reasoning about the types of actions a group may take. In recent years, this system has been used to better understand
terror groups like Hamas [12] and Hezbollah [11] through
probabilistic rules. However, it can also be used with cultural, religious, and political groups - as it has been demonstrated with other groups in the Minorities at Risk Organizational Behavior (MAROB) dataset [1]. The work on
SOMA was followed by an adoption of APT-Logic [14, 15],
which extended AP-rules with a temporal component. APT
logic was also applied to the groups of the MAROB dataset
as well as Shi’ite Iraqi insurgent groups circa 2007 (present
during the American-led Operation Iraqi Freedom) [15] 1 .
Perhaps most significantly, APT-Logic was applied to another dataset for the study of the terror groups Lashkar-eTaiba (LeT) and Indian Mujahideen (IM) in two comprehensive volumes that discuss the policy implications of the
behavioral rules learned in these cases [17, 16]. The main
similarity between the previous work leveraging SOMA, APrules, and/or APT-logic and this paper is that both leverage
probabilistic rule learning. However, all of the aforementioned rule-learning approaches only discover correlations,
while this work is focused on rules that are not only of high
probability, but also have a likely casual relationship. We
also note that none of this previous work studies ISIS but
rather other terrorist and insurgent groups.

Figure 9: Spikes in ISIS IEDs in Iraq per Week
12

IEDs

Moving Average + 2σ

Number of Events

10
8
6
4
2
0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

Analysis of insurgent military tactics. We also note
that the previous rule-learning approaches to understanding
terrorist and insurgent behavior have primarily focused on
analyzing political events and how they affect the actions of
groups such as LeT and IM. However, with the exception
of some of the work on APT-Logic which studies Shi’ite
Iraqi insurgents [14], the aforementioned work is generally
not focused on tactical military operations - unlike this paper. However, there have been other techniques introduced
in the literature that have been designed to better account
for ground action. Previously, a statistical-based approach
leveraged leaked classified data [19] 2 to predict trends of violent activity during the American-led Operation Enduring
Freedom in Afghanistan. However, this work was primarily
focused on prediction and not identifying causal relationships of interest to analysis as in this work. We also note
that this work does not rely on the use of leaked classified
data, but rather on open-source information. Another interesting approach is the model-based approach of [7], in which
subject matter experts create models of insurgent behavior
using a combination of fuzzy cognitive maps and complex
networks to run simulations and study “what-if” scenarios.
However, unlike this paper, the work of [7] is not as datadriven an approach.

Figure 10: Spikes in ISIS IEDs in Syria per Week
3

IEDs
Moving Average + 2σ

Number of Events

2.5
2
1.5
1
0.5
0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

5.

RELATED WORK

To the best of our knowledge, this paper represents the
first purely data-driven study of ISIS, and it is also the first
to combine the causality framework of [10] with APT-Logic.
However, there has been a wealth of research conducted
where rule-based systems have been applied to terrorist and
insurgent groups, as well as other work on modeling insurgent actions. Here, we review this related work and also
discuss other approaches to causal reasoning.

Causal reasoning. The comparison of rules by avg as a
measure of causality was first introduced in [10] and further
studied in [9]. It draws on the philosophical ideas of [18].
However, this work has primarily looked at preconditions as
single atomic propositions. Further, it did not explore the
issue of efficiency. As we look to identify rules whose precondition consists of more than one atomic proposition, we

Rule-based systems. Previously, there has been a variety of research on modeling the actions of terrorist and insurgent groups. Perhaps most well-known is the Stochastic
Opponent Modeling Agents (SOMA) [11, 12], which was developed with the goal of better understanding different cultural groups along with their behaviors. This is also based on
a rule-based framework known as action-probabilistic (AP)
rules [8], which is a predecessor of APT-logic used in this
paper [14, 15]. The SOMA system produces a probabilistic

1
ISIS is a Sunni group and did not exist in its present form
in 2007.
2
Resulting from WikiLeaks in 2010.

2145

introduce a rule-learning approach. Further, moving beyond
previous rule-learning approaches such as that introduced in
[8] and [14], we show practical techniques to improve efficiencies of such algorithms. Further, we also improve upon the
efficiency of computing avg - a practical issue not discussed
in [10, 9]. We note that neither this previous work on causality nor APT-logic makes independence assumptions. This
differs substantially from earlier work on causality such as
[13], which relies on graphical models that make relatively
strong independence assumptions. Our goal was to avoid
such structures in order to provide a more purely data-driven
approach. A key aspect of this work as opposed to previous studies on causality is that we leverage the intuitions
of APT logic and AP rules, in which the rule-learning algorithm searches for combinations of atomic propositions that
are related to a given consequence.

6.

[7] P. Giabbanelli. Modelling the spatial and social
dynamics of insurgency. Security Informatics, 3:2,
2014.
[8] S. Khuller, M. V. Martinez, D. Nau, A. Sliva, G. I.
Simari, and V. S. Subrahmanian. Computing most
probable worlds of action probabilistic logic programs:
scalable estimation for 1030,000 worlds. Annals of
Mathematics and Artificial Intelligence,
51(2-4):295–331, 2007.
[9] S. Kleinberg. A logic for causal inference in time series
with discrete and continuous variables. In IJCAI 2011,
Proceedings of the 22nd International Joint Conference
on Artificial Intelligence, Barcelona, Catalonia, Spain,
July 16-22, 2011, pages 943–950, 2011.
[10] S. Kleinberg and B. Mishra. The temporal logic of
causal structures. In UAI 2009, Proceedings of the
Twenty-Fifth Conference on Uncertainty in Artificial
Intelligence, Montreal, QC, Canada, June 18-21,
2009, pages 303–312, 2009.
[11] A. Mannes, M. Michael, A. Pate, A. Sliva, V. S.
Subrahmanian, and J. Wilkenfeld. Stochastic
opponent modeling agents: A case study with
Hezbollah. First International Workshop on Social
Computing, Behavioral Modeling, and Prediction,
April 2008.
[12] A. Mannes, A. Sliva, V. S. Subrahmanian, and
J. Wilkenfeld. Stochastic opponent modeling agents:
A case study with Hamas. Proceedings of the Second
International Conference on Computational Cultural
Dynamics (ICCCD), September 2008.
[13] J. Pearl. Causality: Models, Reasoning, and Inference.
Cambridge University Press, 2000.
[14] P. Shakarian, A. Parker, G. I. Simari, and V. S.
Subrahmanian. Annotated probabilistic temporal
logic. ACM Transactions on Computational Logic,
2011.
[15] P. Shakarian, G. I. Simari, and V. S. Subrahmanian.
Annotated probabilistic temporal logic: Approximate
fixpoint implementation. ACM Transactions on
Computational Logic, 2012.
[16] V. S. Subrahmanian, A. Mannes, A. Roul, and R. K.
Raghavan. Indian Mujahideen - Computational
Analysis and Public Policy, volume 1 of Terrorism,
Security, and Computation. Springer, 2013.
[17] V. S. Subrahmanian, A. Mannes, A. Sliva,
J. Shakarian, and J. P. Dickerson. Computational
Analysis of Terrorist Groups: Lashkar-e-Taiba.
Springer, 2013.
[18] P. Suppes. A probabilistic theory of causality.
North-Holland Pub. Co., 1970.
[19] A. Zammit-Mangion, M. Dewar, V. Kadirkamanathan,
and G. Sanguinetti. Point process modelling of the
afghan war diary. Proceedings of the National
Academy of Sciences, 109(31):12414–12419, 2012.

CONCLUSION

In this paper, we conducted a data-driven study on the insurgent group ISIS using a combination of APT-logic, rule
learning, and causal reasoning to identify cause-and-effect
behavior rules concerning the group’s actions. We believe
our approach is of significant utility for both military decision making and the creation of policy. In the future, we
look to extend this work in several ways: first, we look to
create non-ground rules that generalize some of the preconditions further. This would allow us to understand the circumstances in which ISIS conducts general operations (as
opposed to operations specific to a given city or to a geographic area). We also look to study more complex temporal
relationships – possibly using a more fine-grain resolution for
time and studying rules where the cause is followed by the
effect in more than one unit of time. We also look to leverage
additional variables about the environment, including data
about weather, information (including social media operations), and the political situation to find more interesting
relationships.

7.

REFERENCES

[1] V. Asal, C. Johnson, and J. Wilkenfeld. Ethnopolitical
violence and terrorism in the middle east. In J. J.
Hewitt, J. Wilkenfeld, and T. R. Gurr, editors, Peace
and Conflict 2008. Paradigm Publishers, 2007.
[2] Districts of iraq. United Nations Office for the
Coordination of Humanitarian Affairs, 2014.
http://www.humanitarianresponse.info/operations/
iraq/search?search=governorate+district.
[3] Google maps. Google Inc., 2014.
https://www.google.com/maps/.
[4] Iraq - district reference maps. MapAction, 2014.
http://www.mapaction.org/component/search/
?searchword=iraq+map&ordering=newest&
searchphrase=all&limit=100&areas[0]=maps.
[5] Situation reports. Institute for the Study of War,
2014. http://understandingwar.org/.
[6] Syria: Governorate and district reference maps.
MapAction, 2014. http://www.mapaction.org/
district-reference-maps-of-syria.html.

2146

Product Offerings in Malicious Hacker Markets
Ericsson Marin, Ahmad Diab and Paulo Shakarian
Arizona State University
Tempe, Arizona
{ericsson.marin, ahmad.diab, shak}@asu.edu

Abstract—Marketplaces specializing in malicious hacking
products - including malware and exploits - have recently become
more prominent on the darkweb and deepweb. We scrape 17
such sites and collect information about such products in a
unified database schema. Using a combination of manual labeling
and unsupervised clustering, we examine a corpus of products
in order to understand their various categories and how they
become specialized with respect to vendor and marketplace. This
initial study presents how we effectively employed unsupervised
techniques to this data as well as the types of insights we gained
on various categories of malicious hacking products.

not trivial, including effort to answer questions, solve puzzles,
mathematical equation or CAPTCHA.
Most related work on darkweb markets such as [3] focus
on a single market and do not restrict their study to malicious
hacking products. Our previous work on markets [4] focused
on a game theoretic analysis of a small subset of the data in
this paper - and did not attempt to categorize the products for
sale. Additionally, there is a complementary lines of work on
malicious hacking forums (i.e. [5], [6], [7], [8], [9], [10], [11],
[12]) - which is a related but different topic from this paper.

I. I NTRODUCTION
Websites on the deepweb and darkweb specializing in
the sale of malicious hacking products - such as malware
platforms, software exploits and botnet rental - have become
the venue of choice for online purchase of these items by cyber
criminals. In this paper, we leverage unsupervised learning
to categorize and study the product offerings of 17 of these
online markets. Specifically, we describe how we used manual labeling combined with clustering techniques to identify
product categories (Section II), and then we analyze the results
both quantitatively and qualitatively (Section III). We identify
categories of products that are highly specialized with respect
to particular vendors and markets. We also highlight other
interesting facets of this ecosystem - for instance, vendors
who habitually cross-list products on multiple sites and nearly
identical products for sale by multiple vendors.
Background and Related Work. The darkweb refers to the
anonymous communication provided by crypto-network tools
such as ”The Onion Router” (Tor), which is free software
dedicated to protect the privacy of its users by obscuring traffic
analysis as a form of network surveillance [1]. On the other
hand, the deepweb refers to sites not indexed by common
search engines due to a variety of reasons (e.g. password
protections), that not necessarily rely on additional protocols.
The sites on the darkweb and deepweb explored in this
study comprise marketplaces [2]. In these websites, vendors
advertise and sell their goods and services relating to malicious
hacking, drugs, pornography, weapons and software services.
Products are most often verified before any funds are released
to the seller. The main engine of these environments is trust.
If a seller is misleading or fails to deliver the appropriate item,
he is banned from the site. Similarly, buyers can be banned
for not complying with the transaction rules. Basically, all
marketplaces in darkweb require a registration and a valid
account to get access. Sometimes, this registration process is

978-1-5090-3865-7/16/$31.00 ©2016 IEEE

II. M ALICIOUS H ACKING P RODUCT C ATEGORIZATION
In this section, we describe our malicious hacker product
dataset and our use of clustering to identify malicious hacker
product categories. We examined 17 malicious hacker marketplaces crawled over a 6 month period. The crawled information
was then parsed and stored in a relational database. Relevant
tables record the marketplaces themselves, the existing vendors
and the items/products for sale. Each item is associated with
a vendor and a marketplace, allowing for join queries. Some
of the more relevant fields for marketplace items include the
price, title, description, rating, posting date. In this work, we
primarily use the product title/name to generate features.
We note that many items are cross-posted and are nearly
identical. Fig. 1(a) shows the distribution of vendors who use
the same screen-name across multiple marketplaces. These are
the ones responsible for the duplicated (cross-posted) products,
reported on the size of our dataset in Table I. Note that only
56.4% of products are distinct by simple comparison methods.
In addition, as we collect data from different sites, there is
inconsistency as to how products are categorized on each site
- if such non-trivial categorization even exists for a given site.
Furthermore, there is a clear absence of a standardized method
for vendors to register their products. As a consequence, the
great majority of the distinct products are unique when compared with simple matching or regular expression technique. It
is valid even in the case where a pair of vendors with different
screen names post what a human would determine to be the
same product. Fig. 1(b) shows the distribution of products
and number of vendors shared among them. The distribution
follows a power-law. From the 9,093 distinct products, about
77% are unique (exclusive), not shared between vendors.
Clustering approach. Using product names, we engineer
features that represent each product as a vector. A set of
pilot experiments suggests that word and character n-grams

187

TABLE I
S CRAPED DATA FROM M ARKETPLACES IN DARKWEB .
Marketplaces
Products (Total)
Products (Distinct)
Vendors
10000

50

Number of Products

Number of Shared Vendors

60

17
16,122
9,093
1,332

40
30
20
10

1000

100

10

1

0
0

2

4

6

8

0 2 4 6 8 10 12 14 16 18 20 22 24

10 12 14 16 18

Markets

Number of Shared Vendors

(a)

(b)

Fig. 1. Distribution of (a) Shared Vendors over Markets. (b) Products over
Shared Vendors.

Table II shows the performance of each TF-IDF vectorization using Rand-index and entropy, when K-means starts
with the 34 fixed centroids. For Rand-index, character ngrams in the range from 3 to 4, 3 to 5, and 3 to 6, when Kmeans used cosine similarity reached a high best performance
(0.986). In addition, we also found the best entropy (0.067)
when K-means uses the same specification. This way, K-means
configuration with character n-grams in the range from 3 to
6 for vectorization, cosine similarity for distance function and
the 34 points for the starting centroids was our natural choice
to produce the clusters in the entire dataset.
We also examined the performance of our approach using
random centroids. As expected, it performs worse than using
the centroids derived from products. Additionally, we examined products (from the full dataset) with a cosine similarity
of less than 0.1 from the calculated centroids. There were 410
such distinct products (4.51% of the dataset). These were then
manually examined and most were found to be irrelevant to
our target domain - and we did not consider them further.
III. A NALYSTS ’ I NTERPRETATION OF P RODUCT C LUSTERS

would provide more pure clusters compared with other feature
engineering methods, such as meta-data or domain-specific
keywords. These features were valued using standard term
frequency - inverse document frequency (TF-IDF), after the
elimination of stopping words and the execution of steaming.
We evaluated word n-gram feature vectors of length up to 1
and up to 2 words and many character n-gram features in the
ranges from 3 to 7 and from 4 to 7. This gave us 10 different
feature vectors in all. To verify which of these strategies could
reach the best performance in our dataset, we evaluated the
effect of the different types of feature vectors on the accuracy
and purity of clusters produced by the K-means algorithm.
To determine the best feature vector, we manually labeled
500 samples using 34 labeled groups (listed in Table III). We
used 400 of the samples to determine centroids for each of
the 34 groups, and then we evaluated the resulting clustering
on the remaining 100 samples. We examined the accuracy
of the different approaches when compared to ground truth
using the Rand-index method [13]. This method is defined as
the number of pairs correctly considered in the sameclass or
correctly considered in different classes divided by n2 , where
n is the number of samples. In addition, we used standard
entropy measurements to examine the purity of the clusters.
Entropy measures the amount of disorder in a cluster. A zerovalue for this metric means the clusters are formed by just one
class. The formal definition is as follows:
entropy(Di ) = −

k
X

P ri (cj ) log2 P ri (cj ),

(1)

i=1

where P ri (cj ) is the proportion of class cj data points in
cluster i or Di . The total entropy (considering all clusters) is:
entropytotal (D) =

k
X
|Di |
i=1

|D|

x entropy(Di )

(2)

In this section, we examine the results of clustering based
on character n-grams in the range 3 to 6 using initial centroids
determined from the labeled data. In order to analyze the
information of these clusters, we calculated their entropy with
respect to two different criteria: marketplaces and vendors.
We also checked in the database the number of distinct
marketplaces and vendors inside each cluster. The idea was
to understand the diversity of the clusters regarding these
two facets. A low marketplace entropy for a given cluster
would mean its products were mainly found in a particular
marketplace. Similarly, low vendor entropy would mean the
cluster’s products were mainly sold by a particular vendor.
Table III presents the results.
As shown in Table III, Links holds the lowest entropy when
we analyzed the marketplaces, suggesting the great majority
of products come from the same market. In this cluster, 80%
of products came from only 2 markets. However, when we
check the vendor entropy for this same cluster, we can observe
a higher value, suggesting that many vendors are actually
offering products related to Links. It is possible that many
markets discourage the re-selling of lists of links, as much of
this information can be found on darkweb Wiki’s for free.
Similarly, Hacking Tools holds the lowest entropy for the
vendor criteria. This suggest that only a few vendors are
present in that cluster. Specifically, only 2 vendors author
416(50%) of this type of products. At first glance, this may be
surprising as this appears to be a very general group. However,
upon inspection of the contents, we find that many authors of
these products are actually organizations. These organizations
use similar language in their product description in an effort to
brand their wares. This could indicate the presence of hackingcollectives that author products as well as the limitations of our
text-based approach - which can potentially cluster products
branded in a similar fashion. We also note one of the most

188

TABLE II
K- MEANS E VALUATION (F IXED C ENTROIDS ).

Cosine
Euclidean

word(1,1)
0.986
0.986

word(1,2)
0.985
0.977

char(3,4)
0.986
0.976

char(3,5)
0.986
0.973

Cosine
Euclidean

0.075
0.224

0.079
0.110

0.067
0.153

0.067
0.156

Rand-index
char(3,6)
char(3,7)
0.986
0.985
0.973
0.974
Entropy
0.067
0.075
0.156
0.141

Cluster Name
Carding
PayPal-related
Cashing Credit Cards
PGP
Netflix-related
Hacking Tools - General
Dumps - General
Linux-related
Email Hacking Tools
Network Security Tools
Ebay-related
Amazon-related
Bitcoin
Links (Lists)
Banking
Point of Sale
VPN
Botnet
Hacking Groups Invitation
RATs
Browser-related
Physical Layer Hacking
Password Cracking
Smartphone - General
Wireless Hacking
Phishing
Exploit Kits
Viruses/Counter AntiVirus
Network Layer Hacking
RDP Servers
Android-related
Keyloggers
Windows-related
Facebook-related

No of
Products
1263
1103
867
865
846
825
749
561
547
539
472
456
443
422
384
375
272
257
251
249
249
237
230
223
222
218
218
210
205
191
156
143
119
119

No of
Markets
16
16
16
15
14
15
12
16
13
15
15
16
15
12
13
15
12
12
14
15
12
13
13
14
13
13
14
14
14
12
11
13
12
15

Market
Entropy
0.320
0.340
0.351
0.347
0.270
0.331
0.289
0.372
0.335
0.366
0.385
0.391
0.360
0.211
0.349
0.384
0.413
0.291
0.387
0.453
0.380
0.408
0.434
0.408
0.389
0.403
0.413
0.413
0.459
0.405
0.429
0.496
0.464
0.501

No of
Vendors
315
335
256
203
351
132
280
117
196
117
163
197
201
221
186
181
130
110
143
99
134
122
100
110
56
111
91
60
60
124
60
77
50
67

char(4,5)
0.985
0.975

char(4,6)
0.984
0.977

char(4,7)
0.982
0.971

Random
0.933
0.933

0.072
0.134

0.079
0.134

0.088
0.137

0.088
0.175

0.423
0.423

hacking products with respect to vendor and marketplace, and
finally, we identified several interesting characteristics of how
the products were grouped. Currently, we are examining other
methods for grouping these products using matrix factorization
and supervised techniques. Additionally, we are studying the
underlying social network of vendors through relationships
based on similar product offerings.

TABLE III
C LUSTERS E NTROPY (14486).
Rank
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34

char(4,4)
0.985
0.975

Vendor
Entropy
0.720
0.754
0.738
0.696
0.805
0.516
0.777
0.758
0.738
0.621
0.772
0.825
0.823
0.838
0.840
0.841
0.827
0.796
0.865
0.797
0.857
0.856
0.781
0.816
0.601
0.849
0.795
0.684
0.716
0.895
0.770
0.862
0.717
0.876

Acknowledgments. Some of the authors were supported by the
Office of Naval Research (ONR) Neptune program, the Arizona State
University Global Security Initiative (ASU GSI), and CNPq-Brazil.

R EFERENCES

prominent vendor in this cluster was itself a marketplace which is also reflected in the low marketplace entropy.
In our analysis of the Facebook and Keylogger clusters, we
can see that they point to the other direction. They have high
values for both entropy, a clear sign about the diversity with
respect to both vendors and markets. For example, in cluster
Facebook, there were 119 products and 67 vendors, and the
most prolific vendor for this cluster authored only 8 products.
In the same cluster, products were also spread across 15
markets - and the most well-represented market was associated
with 30 products. This analysis also indicates widespread
prevalence of keyloggers - which is not surprising as it is
a well established hacking technique. However, observing the
similar trend for the Facebook cluster could be indicative of
an increase in demand for Facebook-directed social media
hacking products and information.
Conclusion and Future Work. In this paper, we conducted
an initial examination of malware products from 17 malicious hacker markets through unsupervised learning. Using
manually-labeled data, we studied the effect of feature vector
on cluster purity using text-based features. We then analyzed
the impurity of clusters in our corpus of over 8, 000 malicious

[1] R. Dingledine, N. Mathewson, and P. Syverson, “Tor: The Secondgeneration Onion Router,” in Proceedings of the 13th Conference on
USENIX Security Symposium - Volume 13, ser. SSYM’04. Berkeley,
CA, USA: USENIX Association, 2004, pp. 21–21.
[2] V. Ciancaglini, M. Balduzzi, R. McArdle, and M. Rösler, “Below the
Surface: Exploring the Deep Web,” 2015.
[3] N. Christin, “Traveling the silk road: A measurement analysis of a
large anonymous online marketplace,” in Proceedings of the 22Nd
International Conference on World Wide Web, ser. WWW ’13. New
York, NY, USA: ACM, 2013, pp. 213–224.
[4] J. Robertson, V. Paliath, J. Shakarian, A. Thart, and P. Shakarian,
“Data Driven Game Theoretic Cyber Threat Mitigation,” in Proc. 28th
Innovative Applications of Artificial Intelligence (IAAI-16), 2016.
[5] C. C. Yang, X. Tang, and X. Gong, “Identifying dark web clusters with
temporal coherence analysis,” in Intelligence and Security Informatics
(ISI), 2011 IEEE International Conference on, July 2011, pp. 167–172.
[6] V. Benjamin, W. Li, T. Holt, and H. Chen, “Exploring threats and
vulnerabilities in hacker web: Forums, irc and carding shops,” in
Intelligence and Security Informatics (ISI), 2015 IEEE International
Conference on, May 2015, pp. 85–90.
[7] M. Macdonald, R. Frank, J. Mei, and B. Monk, “Identifying digital
threats in a hacker web forum,” in Proceedings of the 2015 IEEE/ACM
International Conference on Advances in Social Networks Analysis and
Mining 2015, ser. ASONAM ’15. New York, NY, USA: ACM, 2015,
pp. 926–933.
[8] Z. Zhao, G.-J. Ahn, H. Hu, and D. Mahi, “SocialImpact: Systematic
Analysis of Underground Social Dynamics.” in ESORICS, ser. Lecture
Notes in Computer Science, S. Foresti, M. Yung, and F. Martinelli, Eds.,
vol. 7459. Springer, 2012, pp. 877–894.
[9] H. Chen, “Dark web: Exploring and mining the dark side of the
web,” in Intelligence and Security Informatics Conference (EISIC), 2011
European, Sept 2011, pp. 1–2.
[10] J. Shakarian, P. Shakarian, and A. Ruef, “Cyber attacks and public embarrassment: A survey of some notable hacks,” Elsevier SciTechConnect,
2015.
[11] P. Shakarian and J. Shakarian, “Socio-cultural modeling for cyber threat
actors,” in AAAI Workshop on Artificial Intelligence and Cyber Security
(AICS), 2016.
[12] J. Shakarian, A. Gunn, and P. Shakarian, “Exploring malicious hacker
forums,” in Cyber Deception: Building the Scientific Foundation, S. Jajodia, V. Subrahmanian, V. Swarup, and C. Wang, Eds. Springer, 2016.
[13] W. M. Rand, “Objective Criteria for the Evaluation of Clustering
Methods,” Journal of the American Statistical Association, vol. 66, no.
336, pp. 846–850, Dec. 1971.

189

MIST: Missing Person Intelligence Synthesis Toolkit
Elham Shaabani, Hamidreza Alvari, and
Paulo Shakarian∗
Arizona State University
Tempe, AZ 85281

J.E. Kelly Snyder
Find Me Group
Chandler, AZ 85249

kelly@findmegroup.org

{shaabani, halvari, shak}@asu.edu

ABSTRACT
Each day, approximately 500 missing persons cases occur
that go unsolved/unresolved in the United States. The nonprofit organization known as the Find Me Group (FMG),
led by former law enforcement professionals, is dedicated to
solving or resolving these cases. This paper introduces the
Missing Person Intelligence Synthesis Toolkit (MIST) which
leverages a data-driven variant of geospatial abductive inference. This system takes search locations provided by a
group of experts and rank-orders them based on the probability assigned to areas based on the prior performance of
the experts taken as a group. We evaluate our approach
compared to the current practices employed by the Find Me
Group and found it significantly reduces the search area leading to a reduction of 31 square miles over 24 cases we
examined in our experiments. Currently, we are using MIST
to aid the Find Me Group in an active missing person case.

Keywords
Geospatial abduction; abductive inference; law enforcement;
missing person

1.

INTRODUCTION

Each day, approximately 500 missing persons cases occur
that go unsolved/unresolved in the United States. The nonprofit organization known as the Find Me Group (FMG),
led by former law enforcement professionals, is dedicated
to solving or resolving these cases. This non-profit operates with limited resources - so it must use its volunteer assets in a highly efficient manner. This paper introduces the
Missing Person Intelligence Synthesis Toolkit (MIST) which
leverages a data-driven variant of geospatial abductive inference [24]. This system takes search locations provided by
a group of experts and rank-orders them based on the probability assigned to areas based on the prior performance of
∗
U.S. Provisional Patent 62/345,193. Contact shak@asu.edu for
licensing information.

the experts taken as a group. We evaluate our approach
compared to the current practices employed by the FMG
and found it significantly reduces the search area. In 24
cases examined in our experiments (on real-world data provided by FMG), we found our approach to be able to reduce
total search area by a total of 31 square miles for standard
searches and by 19 square miles when dog team assets obtain
a detection. This reduction is significant for the following
reasons:
• Reduction in time to locate missing persons.
In cases where baseline provided 20 square miles or
more (the most difficult cases), we achieved reduction
in search area of 7 to 56 square miles. As 3-5 square
miles are searched on a typical day (terrain dependent), such a reduction can potentially increase the
chance of a missing person being found alive.
• Reduction in direct costs. During a search, FMG
spends approximately $2200 per day. In all tests, our
approach reduced the search area in the majority of
cases which can be interpreted as a reduction in direct
costs.
• Reduction in indirect costs. FMG relies extensively on volunteers to augment searches. During searches,
these individuals often lose earnings from their day job
or small business. As many volunteers also perform
consulting or other services to law enforcement, longer
searches lead to loss of revenue and opportunity. In
one case, a volunteer estimated a loss of $15K. Again,
our approach leads to a consistent reduction in search
area - hence reducing these indirect costs.
Specifically, we contribute an extension to geospatial abduction [24] that leverages historical data of individual experts. We also create new algorithms to learn parameters
of a geospatial abduction model from data based on integer
programming. We then evaluate these algorithms on realworld data provided by the FMG under a variety of different
settings. This approach learns pattern of each reporter independently and is able to overcome outliers if any. It also
does well on the limited data. This work has prepared us
in our ongoing deployment of the software. At the time of
this writing, we have provided results of MIST to support
an active case with FMG. Figure 1 shows an example output of MIST where it rank-orders search locations. FMG is
currently using this information to support their operations.
They found the result consistent with their experiences.

Figure 1: Mapping of ordered grids by MIST (green squares)
and current searched area by FMG (red square).
The rest of the paper is organized as follows. In Section 2,
we present the background of the missing person problem.
Next, we provide the technical preliminaries. We discuss
our data-driven extension in Section 4. In Section 5, we
detail our algorithmic approach. We introduce our dataset
and conduct data analysis in Section 6. Next, we discuss
the experimental results in Section 7. We review the related
work in Section 8. We conclude the paper presenting future
research directions.

2.

BACKGROUND

Missing persons cases have been on the rise in the USA
for the past twenty years. Currently, approximately 4000
people go missing each and every day. Approximately 3500
of those cases are solved or resolved (i.e., cases solved by
only providing accurate information to the authorities and
without physical involvement), which leaves an astounding
number of victims that are never located. In the case of
missing adults 13 years of age and older, the police are not
required or obligated to conduct an investigation or search
unless there are extenuating circumstances such as suicide, a
potential for violence, medical reasons, etc. This leaves families and friends without professional assistance in locating
their loved ones. The Find Me Group (FMG) was founded
by retired U.S. Drug Enforcement Agency (DEA) Special
Agent J.E. “Kelly” Snyder in 2002. The group consists of
current and retired law enforcement officers with a widerange of investigative expertise, including but not limited
to linguistics, handwriting analysis, body language, missing person/homicide experience and search-and-rescue field
management skills. The FMG has trained experts/sources
that provide detailed location information where missing individuals can be found. Many of these experts have the
ability to provide GPS coordinates to locate missing persons
with a varying levels of success. The FMG focus/goal is to
provide accurate location information in a timely manner
and minimize the potential of finding the victim deceased.
Thirty canine handlers certified in tracking, scent and cadaver complements the FMG and has led to many instances
where the person in questions was located.
Equally disturbing nationwide is the rise in human trafficking, which aligns within the missing person category.
This type of crime has long-term and devastating results.
The work of this paper is also the first step toward an allencompassing methodology of identifying locations of missing persons who were victims of human trafficking. Another

important related crime is homicide. Many missing persons
and human trafficking victims are found deceased due to this
crime. This work represents initial progress in aiding toward
crimes of this nature as well.
In this paper, we formulate the problem of “finding missing person” with respect to information provided by FMG’s
experts, formally as a variant of the geospatial abduction
problem (GAP) [22]. To account for the key nuances of
“finding missing person” problem though, we extended the
GAP framework to better suite this domain. In particular,
we extend the GAP formalism with a data driven model accounting for the previous performance of experts aiding in
the missing person cases. We list the unique characteristics
of our framework here. Later in the next section, we provide
our technical approach to each.
1. Explanation Size. One key difference “finding missing person” problem has from other GAP instances, is
that the explanation (the result of a GAP inference algorithm) only consists of a single related location (i.e.,
the location of the missing person) corresponding to
the phenomenon under study. This differs from returning a set of k locations in the previously-introduced
GAP formalisms. Consequently, here, an explanation
will consist of a single point, which in turn led us to
explore a non-deterministic version of the original explanation.
2. Distance Constraints. In the original GAP formalism, each observed geospatial phenomenon is related
to unobserved “partner” points through a distance constraint - (α,β) where α is the minimum distance between an observation and partner and β is the maximum distance. As described, this pair of constraints
was the same for all observations. However, in the
missing persons problem, each observation corresponds
to a different domain expert - and hence has a different (α,β) constraint pair. Further, we study how this
is best learned from data, as well as “soften” the constraint - assigning a probability of the partner point
being less than α, between distances α and β, and
greater than distance β from an observation.
3. Uncertainty. As we learn the (α,β) distance constraints for each observation and associate corresponding probabilities from historical data, it makes sense
that the inference step is treated probabilistically which differs from the original deterministic GAP framework. Further, this enables us to rank the potential
partner locations (again, as an explanation consists of
one point, ranking search locations is more useful in a
practical sense).
4. Independent Observations. In the original GAP
framework, independence amongst the observations was
not an assumption in the framework. However, FMG
compartmentalizes the information from their law enforcement experts from one another in a manner to
obtain independent reporting. Hence, we make this
assumption in this paper and it is supported by our
experimental results.
FMG currently uses a simple heuristic to rank-order potential search locations for a missing person (we describe this

later in Section 5). Once ranked, FMG leverages a variety of assets. Figure 2 depicts a recently searched area for
a case. It represents a screen shot of the tracks from the
GPS units that the dogs wear as well as the handheld units
that the searchers wear. This shows several dog tracks and
the human tracks. The green, dark blue, magenta represent
three dogs, the grey and red represent two human searchers.
The teal track is a trailing dog, ascertaining a direction of
travel. The straight lines tend to be humans and the rapidly
changing direction lines are dogs as they grid around the humans. Figure 3 shows real-world examples of how the FMG
practices in an undisclosed location.

in [23] and later extended in [24, 21, 20, 19]. More formally, each GAP consists of three major elements [22]: (1)
observations: a set of observations that explain the locations associated with the event under study (e.g., in this
application, the locations reported by the domain experts),
(2) distance constraints: a pair (α, β) ∈ R corresponding to
lower and upper bounds on the distances between observation and partner location and, (3) feasibility predicate: this
allows to specify whether an area on the map is a potential
location for a partner.
Next, we present the notations and definitions used throughout the paper, and review the geospatial abduction framework of [22]. In the next section, we describe specialized
extensions that were necessary to study our problem. First,
without loss of generality, we assume throughout the paper
that a map (resp. space) is represented by a discrete two
dimensional grid of size M × N , defined as follows:
Definition 3.1. (Space). Given natural numbers M ,
N , the space S is the set [1, . . . , M ] × [1, . . . , N ].

Figure 2: Screen shot of the tracks from the GPS units.

3.

TECHNICAL PRELIMINARIES

In this section, we briefly explain geospatial abductive inference [24], and introduce our new (introduced in this paper) data-driven probabilistic extension. We show how this
extension was used to address the unique characteristics of
the missing person location problem.
In general, abduction or abductive inference [12] refers to
a type of logic or reasoning to derive plausible explanations
for a given set of facts [13]. Abduction has been extensively
studied in medicine [13, 14], fault diagnosis [3], belief revision [11], database updates [8, 4] and AI planning [5]. Two
major existing theories of abduction include logic-based abduction [6] and set-covering abduction [2]. Though none of
the above papers takes into account spatial inference, [25]
presents a logical formalism dealing with objects’ spatial occupancy, while [18] describes the construction of a qualitative spatial reasoning system based on sensor data from a
mobile robot.
Geospatial abduction problem (GAP) [22], on the other
hand, refers to the problem of identifying unobserved partner locations (i.e., the location of a missing person) that
best explain a set of observed phenomenon with known geographic locations. Geospatial abduction was first introduced

(a)

(b)

Figure 3: (a) Picture of the search area taken from the plane.
(b) Search team.

Associated with the space is a distance function d : S ×
S → R+ that satisfies the normal distance axioms: d(pi , pi ) =
0, d(pi , pj ) = d(pj , pi ), and d(pi , pj ) ≤ d(pi , pq ) + d(pq , pj ).
Note that we use o to represent the observer (source of information) and po to represent the location he/she reported
(which differs slightly from the original framework). From
these observations (reports), the corresponding unobserved
phenomenon is the actual location of the missing person.
In the original framework, the explanation consisted of geographic locations that were located at least distance α and
no more than distance β away from each observation. In
this work, we generalize this notion by providing α,β pair
for each observer - denoted αo ,βo .
Definition 3.2. (Feasibility Function). A feasibility
function feas is defined as feas : S → {True, False}.
A key use for the feasibility function here is for an initial
reduction of the search space by the FMG. This is due to the
fact that missing person reports often span a large area and
an initial reduction is necessary for practical reasons. An
obvious future direction would be to utilize a probabilistic
variant of the feasibility function - which would assign a prior
probability to a location for a missing person. However, in
this application, it is unclear where such a distribution would
come from. Further, as the search space is relatively large
when compared to FMG resources, the deterministic version
of this definition is more appropriate for operational reasons.
Due to resource constraints and the generally large areas
over which reports are spread, FMG typically only searches
areas for which there is a report. As we shall describe in
Section 5, they search a 1 × 1 mile square surrounding a
location reported by an observer. As such is the case, we
shall assume the following feasibility function throughout
this paper:
(
True
if p ∈ O
feas(p) =
(1)
False otherwise
Unless otherwise noted, we shall assume the above function is used for feasibility and hence the subset of the space
considered will be the points in O.
We now come to the important definition of an explanation. Intuitively, for a given set of points {p1 , . . . , p|O| }

reported by observers in O, an explanation is a set of points
E such that every point in this set is feasible and for every
observation, there is a point in E that is at least α units
away from the observation, but no more than β units from
the observation.
Definition 3.3. ((α,β) Explanation). Suppose O is
the set of observations, E is a finite set of points in S, and
0 ≤ α, β ≤ 1 are two real numbers. E is said to be an (α, β)
explanation of O iff:
• p ∈ E implies that feas(p) = True, i.e., all points in E
are feasible.
• (∀o ∈ O)(∃p ∈ E) α ≤ d(p, o) ≤ β, i.e., every observation is neither too close nor too far from some point
in E.
Thus, an (α,β) explanation is a set of points. Each point
must be feasible and every observation must have an analogous point in the explanation which is neither too close nor
too far.
Again, we note that here an explanation will consist of a
single point - the location of the missing person. Hence, this
deterministic definition of an explanation will not suffice as in practice there will often not exist an explanation for
a given problem instance. As such is the case, we extended
this framework using a data-driven approach.

4.

DATA-DRIVEN EXTENSIONS

In this section, we describe our data-driven probabilistic
extension to the original GAP formalism. The framework
extensions in this section were not previously introduced and
are new in this paper. In order to do so, we first introduce
some preliminary notation. For point p ∈ S, the random
variable Pp denotes that the missing person was found at
point p, so this is either true or false. We will use Pp as
shorthand for Pp = True. For observer o ∈ O the random
variable Oo can be assigned to one of the points in p. Based
on this notation, we define an explanation distribution.
Definition 4.1 (Explanation Distribution). Given
a set of observers O and a set of reported locations by each
observer p1 , . . . , po , . . . , p|O| , an explanation distribution
is a probability distribution over all points in S - directly addressing characteristic 3 of this application (see Section 2).
This distribution assigns the probability of a missing person
being located at each point conditioned on the observers reporting V
their respective locations. Formally, it is written as
P r(Pp | o∈O Oo = po ).
The key intuition is that if we are able to compute an explanation distribution, we can then rank-order points in the
space by probability - and hence conserve search resources.
Note that the explanation distribution is over all points implying that there is precisely one location. While generalizations that allow for more than one location are possible
in such a probabilistic framework, we keep the size at one
due to the first characteristic of our problem (as described
in Section 2).
In this paper, we make an assumption of distance primacy
meaning
the distance constraints (αo , βo ) relate the Pp with
V
o∈O Oo = po . Hence, we introduce another random vari0
o
able, Rβp,p
0 which is true if d(p, p ) ≤ βo and false otherwise.

Note that in the remainder of this section, we will use one
distance constraint (β) for sake of brevity - though this idea
can be extended for multiple distance constraints (as per
characteristic 2 from Section 2). In fact, we leverage multiple distance constraints in our optimization procedure for
parameter selection introduced later. Hence, by distance
primacy, we have the following relationships.
^
^ β
P r(Pp |
Oo = po ) = P r(Pp |
Rp,po )
(2)
o∈O

o∈O

By Bayes’ Theorem, this is equivalent to the following.
V
P r(Pp ) × P r( o∈O Rβp,po |Pp )
(3)
V
P r( o∈O Rβp,po )
However, by characteristic 4, we assume that the observers
report information independently, which gives us the following.
Q
P r(Pp ) × o∈O P r(Rβp,po |Pp )
(4)
V
P r( o∈O Rβp,po )
Due to our application, we will not consider the prior probability P r(Pp ) as each missing person case occurs in a different geographic location - and due to the wide range of
cases that span multiple countries, data supporting a realistic, informed prior is highly sparse. As such, we consider a
uninformed prior. Further, for notational simplicity, we shall
use the notation ρβo for the quantity P r(Rβp,po = True|Pp =
True). Therefore, we can rank points in the space based
on the explanation distribution by simply considering their
log-likelihood computed as follows:
X
X
log(ρβo ) +
log(1 − ρβo )
(5)
o∈O
d(p,po )≤β

o∈O
d(p,po )>β

Hence, the inference step for this problem is straightforward provided we know the values β and ρβo for each
observer o ∈ O (or similar parameters if considering more
than one distance constraint). If we know the value β we
can then compute ρβo based on a corpus of historical data
concerning the accuracy of reporter o. Given a corpus of
previous cases for the observer Co where the found location
was pc and the location reported by the observer was pco , we
can compute ρβo as follows:
ρβo =

|{c ∈ Co s.t. d(pc , pco ) ≤ β}|
|Co |

(6)

Hence, we also adjust ρβo to account for volume of the reporter’s history to provide the effect of regularization. Considering ηo as the portion of total number of cases in which
observer o has participated, to the total number of cases,
and  as a non-negative parameter, we define ρβ,
as follows:
o
ρβ,
= ρβo −  × (1 − ηo )
o

(7)

The situation is further complicated with multiple distance constraints. We propose an optimization approach to
this problem in the next section.

5.

ALGORITHMIC APPROACH

In this section, we present our algorithmic approach to
special case of geospatial abductive inference. First, we ex-

plain the method that FMG currently uses. Then, we provide our proposed optimization approach to solve the problem.

also minimize the following quantity:
XX X
X h
0
F2 =
δβ (p, pco ) × log ρoβ × Xo,β
c∈C o∈O p∈{S\pc } β∈[βo ]

5.1

Existing Method

0

The FMG uses the following method to explore the missing person location. Given the reported locations provided
by different observers, FMG initially creates a search area
(grid) as follows. First, they draw building blocks (or boxes)
of size 1×1 mile centered at each reported location (note that
depending on the situation, these boxes may overlap). Then,
they search the entire grid in the following order. First, they
search the larger areas created of the overlapping boxes, and
if the missing person was not found, they explore the remaining boxes in the order of the observers’ history (how
well they did in the past). The whole process is repeated
by extending the size of boxes to 2×2 miles, if the missing
person was not located. Note that, we use the same grid in
our proposed methods.

5.2

Proposed Methods

As described, for simplicity, we first elaborate on the required steps to calculate the best βo for each observer. Then,
we extend the idea for multiple distance constraints. Let
[βo ] be the set of possible error radii. Note that for Co cases
where observer reported a location, there are at most |Co |
possible values for βo . Hence, our goal is to select as a set
of these distance constraints - one for each observer. We do
this through an integer program - where for each observer
o ∈ O and each associated distance constraint βo ∈ [βo ]
we have an indicator variable Xo,βo that is 1 if we use that
value and zero otherwise. We shall refer to this as the single
constraint integer program. Hence, we find an assignment of
values to these indicator variables in order to maximize the
following quantity:
XX X h
F1 =
δβ (pc , pco ) × log ρβo × Xo,β +

+ (1 − δβ (p, pco )) × log(1 − ρoβ ) × Xo,β

(1 − δβ (p

, pco ))

× log(1 −

ρβo )

× Xo,β

i

(8)

subject to the following constraints:
∀Xo,β ∈ {0, 1}
∀o,

X

(13)

Therefore, the objective function we seek to optimize is
L1 = max(F1 − F2 )

(14)

Theorem 5.1. Number of variables in single-distance constraint integer program is O(avg(|Co |) · |O|).
We extend the previous formulation by allowing the objective function to find a pair of distance constraints for each
reporter. We have experimentally found diminishing returns
on performance (and in many cases increased complexity)
with more than two constraints. This will give us the double
distance constraint integer program as follows:
XX X X h
F10 =
δα (pc , pco ) × log ρα,
× Xo,α,β
o
c∈C o∈O α∈[βo ]β∈[βo ]
β≥α





α,
× Xo,α,β +
+ 1 − δα (pc , pco ) × δβ (pc , pco ) × log ρβ,
o − ρo


i
(1 − δβ (pc , pco )) × log 1 − ρβ,
× Xo,α,β
o
subject to the following constraints:

∀o,

∀Xo,α,β ∈ {0, 1}
X
Xo,α,β ≤ 1
α,β∈[βo ]

Likewise, we use the following objective function, to avoid
bias toward selecting the largest β’s.
L2 = max(F10 − F20 )
where

c∈C o∈O β∈[βo ]
c

i

F20 =

F20

is defined as follows:
X

XX X X h

(15)

0

δα (p, pco ) × log ρoα, × Xo,α,β +

c
c∈C o∈O α∈[βo ]β∈[βo ] p∈{S\p }
β≥α



1 − δα (p, pco ) × δβ (p, pco )×
(9)

Xo,β ≤ 1

(10)

Xo,β = k

(11)

0

0

log(ρoβ, − ρoα, ) × Xo,α,β +




i
0
1 − δβ (p, pco ) × log 1 − ρoβ, × Xo,α,β

(16)

β∈[βo ]

X X
o

β∈[βo ]

where k is a cardinality that limits the number of reporters
(which is set to a natural number in the range 1, . . . , |O|),
and δβ (x, y) is defined as:
(
1 if d(x, y) ≤ β
δβ (x, y) =
(12)
0 if d(x, y) > β
However, this equation will result in tendency toward selecting the largest distance constraints. This has the effect of not only maximizing the probability of the locations
where the missing person was found, but also can increase
the probability of other locations. Intuitively, we want to

Theorem 5.2. Number of variables in double distance constraint integer program is O(avg(|Co |)2 · |O|).
While we obtained a significant reduction in the area searched
by setting the cardinality constraint k = O, we found that
varying it would often lead to further improvement. We
gradually increased the number of observers from one to the
total number of observers and each time, we learned the
distance constraints for the last added observers. In this
method of optimization, we may choose a specific number
of points in each iteration. The number of points added
with each iteration can be determined based on available
resources.
We also defined two heuristic to discriminate points with
the same probability. In each iteration, we chose the point
with highest probability. If there were more than one point,

Table 1: Description of the dataset

we applied following heuristics: (1) we chose the points
which had most of the reported locations in its 1 × 1 mile.
(2) we chose the point which had the maximum summation
of the priors of the reporters in its 1 × 1 mile.
Algorithm 1 is a specific variant of restricted model. In
this algorithm, in each iteration one point (i.e., representative of a 1 × 1 mile) is selected. Though we note that this
can easily be adjusted in practice. If the area size we are
able to search is larger than number of observers, we sort
the representatives based on their probabilities. Then, we
apply two heuristics to rank them (similar to Lines 11-19 ).

Name
Found Status
Alive
Deceased
Gender
Male
Female
Age
Under 13
13 to 30
30 and older

Algorithm 1 Iterative Search Resource Allocation

6.1

30
25
20
15
10

Overview

6.2

Data Analysis

The dataset consists of cases distributed all over the world.
We split the U.S. based cases into 4 regions, west, midwest,
northeast and south, according to the United States Census
Bureau. We further grouped together all cities outside the
U.S. into one single category, namely, international. The
distribution of cases across different regions is demonstrated
in Figure 4. Though we did not explicitly show in the figure,
the west is dominated by Arizona and California, due to the
large focus of FMG on these two states.
There are several known reasons of disappearance associated with the cases in our dataset including, accidental,

West

South

Midwest

International

Northeast

5

MISSING PERSON DATASET

Our dataset includes cases (i.e., missing persons), found
status (alive/deceased), found location (latitude and longitude), age and reason for disappearance as well as the potential locations (latitude and longitude) associated with the
reporters/experts. The description of this dataset is summarized in Table 1. Note that in some cases, we are aware of
reports, but do not have the found location (pco ). In this
work, we only have 29 cases with the known found locations
used for the experiments. However, for the data analysis,
the entire dataset is applied.

9
39
40

35

Theorem 5.3. The time complexity of the algorithm (1)
is O(|C|·avg(|Co |)2 · avg(|Oc |)3 ).

In this section, we describe our dataset and briefly discuss
the observation made from our initial data analysis.

41
47

40

0

6.

12
76

bipolar, drowning, foul play, natural, runaway, self-inflicted,
staged and undetermined. According to Figure 5, ‘foul play’
is the dominant reason for disappearance. There are also different number of reporters for each case. The distribution of
reporters with respect to the number of cases in which they
participated is shown in Figure 6.

Number of cases

1: procedure Opt-Point-By-Point(A, c, S, ρ) . Train
set A, Test case c
2:
List R = ∅
. Output
3:
for k ∈ [1, |Oc |] do
. k is a constant value of the
constraint
4:
Find assignment of variables that optimize (15)
w.r.t. (9 - 11)
5:
RP ← Order by (5)
. Ranked points RP
6:
RP ← RP \ R
7:
Pick P ⊆ RP with largest probabilities
8:
if P includes one point then
9:
R=R∪P
10:
else
11:
p ← Heuristic(P )
12:
R = R ∪ {p}
13:
return R

Value

Regions

Figure 4: Distribution of the cases across different regions
of the US and international.
For the rest of our data analysis, we need to introduce
some preliminary notation. We use the random variable gA
to denote if the missing person is found alive or not, so it is
either true or false. We shall use P r(gA = True|o stated Alive)
to denote the confidence of the observer o in reporting Alive.
This confidence value shows the portion of the cases for
which o has reported the missing person is Alive and he/she
was found Alive, to the total number of cases for which o has
reported Alive. Likewise, we compute the confidence of o in
reporting Deceased. The distribution of the reporters with
respect to their confidence values is demonstrated in Figure 7. According to the figure, most reporters’ confidence
values belong to the ranges of [0.3,0.4) for alive and [0.8,0.9)
for deceased statuses.
We also define the ratio rA as follows:
rA =

P r(gA = True|observer o stated Alive)
P r(gA = True)

(17)

This ratio demonstrates how much the observer o outperformed the prior probability P r(gA = True) on Alive. Similarly, we use rD for Deceased cases. The distributions of the
reporters with respect to rA and rD are shown in Figure 8.
We note that as most are found dead, it is harder for the

16	
Number	of	Reporters	

18	

30
25
20
15
10

Foul play

Undetermined

Accidental

Self-inflicted

Runaway

Natural

Bipolar

0

Staged

5
Drowning

Number of cases

35

14	
12	
10	
8	
6	
4	
2	
0	
0	

1	

2	

3	

4	
rA

5	

6	

7	

8	

180	

Reasons

160	
Number	of	Reporters	

Figure 5: Distribution of the cases with respect to the probable reasons.
45	
Number	of	Reporters	

40	
35	
30	

140	
120	
100	
80	
60	
40	

25	

20	

20	

0	

15	

0.5	

0.7	

10	

0.9	
rD

1.1	

1.3	

5	
0	
1	

2	

3	

4	

5	
6	
7	 10	 13	
Frequency	of	Par=cipa=on	

15	

16	

Figure 8: The distributions of the reporters with respect to
rA and rD .

17	

[0.9,	1]	

[0.8,	0.9)	

[0.7,	0.8)	

[0.6,	0.7)	

[0.5,	0.6)	

[0.4,	0.5)	

[0.3,	0.4)	

[0.2,	0.3)	

alive	
deceased	

[0.1,	0.2)	

18	
16	
14	
12	
10	
8	
6	
4	
2	
0	

[0,	0.1)	

Number	of	Reporters	

Figure 6: Distribution of frequency of participation.

Conﬁdence	

Figure 7: Distribution of all reporters with respect to their
confidence values.

reporters to outperform the prior on Deceased compared to
the Alive.

7.

EXPERIMENTAL RESULTS

This section reports on the experiments conducted to validate our approach. We note that the individual cases themselves are not related - hence we are justified in using leaveone-out cross validation in our experiments. Specifically, for
each case in the experiments, we learn a different model
using all of the other cases. We first compare the methods for restricted (without dog) and unrestricted (with dog)
searches and then discuss the sensitivity of the parameter.

7.1

Area Reduction

In this section, we examine how our approach can be used
to reduce the area searched by the Find Me Group over the
baseline. Figure 9 shows the reduction of area based on our
approach (double distance constraint integer program with
Algorithm 1 and  = 0.1) when compared to the baseline.
We examine this with grid squares of 1×1 miles and 2×2
miles. In the 19 cases where the missing person was located,
our approach achieved area reduction in 11 cases - reducing
the search area by an average by 3 square miles. In the 2
cases where our method caused the search area to increase,
the increase was only 1 square mile in each case. This contrasts with the cases where the area was reduced - reducing
the search area by up to 9 square miles. For the 11 cases
where reduction was experienced, the average reduction was
1.63 miles (t(19) = 1.25, p <0.11).
We also examined cases where the size of the grid squares
was 2×2 miles. In the 19 cases, the area reduction achieved
by our method was in 14 cases, and by an average by 8.5
square miles. Further, in the 6 cases, our method caused
an increase in the search area, however, the increase was 3
square miles on average. Further, for the cases that baseline needs to search areas larger than 20 square miles, our
approach reduced the area from 7 to 56. Our method outperformed the baseline in area reduction with an average of
4.21 mile square (t(20) = 1.19, p <0.13).

7.2

Consideration of Dog Team Detections

The experiments of the previous section illustrated how
our approach could reduce the search area over the baseline
for standard grid settings. However, in the events that a dog

18

18
Baseline
Algorithm 1

14

14

12

12

10
8
6

8
6
4

2

2
0

2

4

6

8

10

12 14
Cases

16

18

20

0

22

(a) Search area with 1 × 1 mile per observation

2

4

6

8

10

12 14
Cases

16

18

20

22

60
Baseline
Algorithm 1

50

Baseline
Algorithm 1

50

Searched Area

40
30
20
10
0

0

(a) Search area with 1 × 1 mile per observation

60

Searched Area

10

4

0

Baseline
Algorithm 1

16

Searched Area

Searched Area

16

40
30
20
10

0

2

4

6

8

10

12 14
Cases

16

18

20

0

22

(b) Search area with 2 × 2 miles per observation

0

2

4

6

8

10

12 14
Cases

16

18

20

22

(b) Search area with 2 × 2 miles per observation

Figure 9: Searched area until the missing person is located
(baseline and Algorithm 1).

Figure 10: Searched area with dogs allowed to explore 1 mile
beyond the grid (baseline and Algorithm 1).

team detects evidence of the missing person, it may lead to a
continued search outside of the assigned grid square. These
searches can lead to FMG personnel examining up to a mile
outside a designated location. In this section, we consider a
grid square settings in the last section, but also allow for an
additional mile outside the square to mimic the effect of the
dog search team following such a lead. Figure 10 demonstrates the reduction of area based on our approach (double
distance constraint integer program with Algorithm 1 and
 = 0.1) when compared to the baseline. We investigate the
area reduction with grid squares of 1×1 miles and 2×2 miles.
According to Figure 10a, in the 22 cases where the missing
person was located, our approach achieved area reduction in
12 cases - reducing the search area by 2 square miles on average. In the 2 cases where our method caused the search area
to increase, the increase was only 3 square miles on average.
This contrasts with the cases where the area was reduced
- reducing the search area by up to 9 square miles. Our
method outperformed the baseline in area reduction with
an average of 0.86 mile square (t(22) = 0.8, p <0.22).
We examined cases where the size of the grid squares was
2×2 miles. In the 24 cases, the area reduction achieved by
our method was in 21 cases, and on average by 8.85 square
miles. In the 3 cases where our method caused the search
area to increase, the increase was 4.3 square miles on aver-

age. This contrasts with the cases with the reduced search
area by up to 56 square miles. Our method outperformed
the baseline in area reduction with an average of 7.2 mile
square (t(24) = 1.95, p <0.05).

7.3

Parameter Sensitivity

We compare different values of  in both double distance
constraint integer programs (iterative search resource allocation and non-iterative program). The impact of changing
the parameter  is shown in Figure 11. To do so, we plot the
fraction of area searched by our method over the baseline,
against the , for both sizes of 1 × 1 and 2 × 2. We note that
while the extreme values of  (i.e. 0.0 and 0.5) negatively
effected the performance of both approaches, we achieved
relatively stable results for intermediate values - noting that
the best performance was to set  equal to 0.1 - which we
used in the experiments.
We also studied the performance of our optimization approach without algorithm 1 (i.e. prioritize locations by equation 5 after selecting the values for βo through optimization
of 19 with regards to Lines 9-11). The results are depicted
in Figure 12. The behavior of the algorithm for different
settings of  were similar to that found with Algorithm 1,
the reduction in search area was generally less - and in some

1.4

1.6

Without Dog
With Dog
Fraction of Searched Area

Fraction of Searched Area

1.6

1.2
1.0
0.8
0.6
0.4
0.2
0.0

1.4

Without Dog
With Dog

1.2
1.0
0.8
0.6
0.4
0.2

0.1

0.2

0.3

0.4

0.5

0.0

0.1

0.2

²
(a) Search area with 1 × 1 mile per observation (Algorithm 1)

1.4

Without Dog
With Dog

1.6

1.2
1.0
0.8
0.6
0.4
0.2
0.0

0.1

0.2

0.4

0.5

(a) Search area with 1×1 mile per observation not using Algorithm
1

Fraction of Searched Area

Fraction of Searched Area

1.6

0.3

²

0.3

0.4

0.5

²

1.4

Without Dog
With Dog

1.2
1.0
0.8
0.6
0.4
0.2
0.0

0.1

0.2

0.3

0.4

0.5

²
(b) Search area with 2 × 2 miles per observation (Algorithm 1)

Figure 11: Fraction of total area searched across all cases
with the iterative search resource allocation approach over
the baseline.

(b) Search area with 2 × 2 miles per observation not using Algorithm 1

Figure 12: Fraction of total area searched across all cases
by the double distance constraint integer programming approach (not using Algorithm 1) over the baseline.

cases (i.e. 1x1 mile grid square with use of the dogs) it
performed worse.

8.

RELATED WORK

Recently, there has been some work [19, 20, 21, 23, 9] dealing with geospatial abductive inference introduced in [24].
In [19] for example, authors studied the case of geospatial
abduction where there is an explicit adversary who is interested in ensuring that the agent does not detect the partner
locations in an attempt to simulating the real-world scenario of insurgents who conduct IED (improvised explosive
device) attacks. Another work [20], has adopted geospatial
abduction to develop a software tool which applies geospatial
abduction to the environment of Afghanistan, to look for insurgent high-value targets, supporting insurgent operations.
The work of [21] introduced a variant of the GAPs called
region-based GAPs (RGAPs) which deals with the multiple
possible definitions of the subregions of the map. Finally,
spatial cultural abductive reasoning engine which solves spatial abductive problems was developed in [23]. Aside from
introducing GAP, the work of [24] demonstrated the accuracy of proposed framework on real-world dataset of insurgent IED attacks against US forces in Iraq. Further, the
work of [9], proposed a technique to reduce the computational cost of point-based GAPs. They presented an exact
algorithm for the natural optimization problem of pointbased GAPs. Geospatial abduction problems are related
to facility location [26] and sensor placement problems [10]
in that they identify a set of geo-locations to optimize a

cost or reward function. However, there are key differences
amongst these various frameworks that arise from the difference between explanation and optimization. See [22] for
further discussion on this topic.
Similarly, [1] presents a specific aspect of the well-known
qualification problem, namely spatial qualitative reasoning
approach, which aims at investigating the possibility of an
agent being present at a specific location at a certain time
to carry out an action or participate in an event, given
its known antecedents. This work is different from both
above papers and our study, as it takes on purely logical approach to formalizing spatial qualifications, while our work
and other aforementioned studies use geometric and probabilistic techniques. Further, the framework of this paper is
tailored specifically for the missing person problem.
Looking beyond geospatial abduction, recent research has
demonstrated that GPS (positional) data could be used to
learn rich models of human activity [16, 15, 17, 7]. For example, [16, 15, 17], modeled the human interactions and intentions in a fully relational multi-agent setting. They used
raw GPS data from a real-world game of capture the flag and
Markov logic- a statistical-relational language. Whereas [7]
developed a model to simulate the behaviors associated with
insurgent attacks, and their relationship with geographic locations and temporal windows.
At first glance, one may think our work is similar to [10],
in that they identify a set of geo-locations to optimize a

cost or reward function. However, as described, there are
key differences amongst these various frameworks that arise
from the difference between explanation and optimization.
[11]

9.

CONCLUSION

In this paper, we have introduced the Missing Person Intelligence Synthesis Toolkit (MIST) which leverages a datadriven variant of geospatial abductive inference. MIST can
rank-order the set of search locations provided by a group
of experts. The experimental results showed that our approach is able to reduce the total search area by a total of 31
square miles for standard searched and by 19 square miles
when dog team assets obtain a detection. This reduction
will make FMG locating missing persons faster while saving in direct and indirect cost. At the time of this writing,
we have initiated support to FMG with MIST for an active
case. FMG will use MIST’s ranking of search locations for
this ongoing operation.
Our future plans include utilizing a probabilistic variant
of the feasibility function, applying other features such as
missing person’s region, age, gender to the model and extending our toolkit to be able to solve other problems such
as human trafficking.

Acknowledgement

[12]

[13]

[14]

[15]

[16]

[17]

This work was funded by the Find Me Group.

10.

REFERENCES

[1] B. Akinkunmi and P. C. Bassey. A Logic of Spatial
Qualification Using Qualitative Reasoning Approach.
International Journal of Artificial Intelligence &
Applications, 4(2):45, 2013.
[2] T. Bylander, D. Allemang, M. C. Tanner, and J. R.
Josephson. The Computational Complexity of
Abduction. Artif. Intell., 49(1-3):25–60, 1991.
[3] L. Console, L. Portinale, and D. T. Dupré. Focussing
Abductive Diagnosis. AI Commun., 4(2/3):88–97,
1991.
[4] L. Console, M. L. Sapino, and D. T. Dupré. The Role
of Abduction in Database View Updating. J. Intell.
Inf. Syst., 4(3):261–280, 1995.
[5] S. do Lago Pereira and L. N. de Barros. Planning with
abduction: A logical framework to explore extensions
to classical planning. In Brazilian Symposium on
Artificial Intelligence, pages 62–72. Springer, 2004.
[6] T. Eiter and G. Gottlob. The complexity of
logic-based abduction. Journal of the ACM, 42:3–42,
1995.
[7] S. George, X. Wang, J. Lin, B. Qu, and J.-C. Liu.
MECH: Algorithms and Tools for Automated
Assessment of Potential Attack Locations. Technical
report, Texas A & M University, College Station, 2015.
[8] A. C. Kakas and P. Mancarella. Database updates
through abduction. In VLDB, volume 90, pages
650–661, 1990.
[9] A. Koutsioumpas. Abductive reasoning in 2d
geospatial problems. In Applications of Mathematics
and Informatics in Science and Engineering, pages
333–347. Springer, 2014.
[10] A. Krause, J. Leskovec, C. Guestrin, J. Vanbriesen,
and C. Faloutsos. Efficient sensor placement

[18]

[19]

[20]

[21]

[22]

[23]

[24]

[25]
[26]

optimization for securing large water distribution
networks. Journal of Water Resources Planning and
Management, 2008.
M. Pagnucco. The Role of Abductive Reasoning within
the Process of Belief Revision. PhD thesis, Basser
Department of Computer Science, University of
Sydney, 1996.
C. S. Peirce. Philosophical writings of Peirce, selected
and edited with an introd. by Justus Buchler. Dover
Publications New York, 1955.
Y. Peng and J. Reggia. Abductive inference models for
diagnostic problem-solving. Symbolic computation.
Springer-Verlag, New York, 1990.
Y. Peng and J. A. Reggia. Plausibility of Diagnostic
Hypotheses: The Nature of Simplicity. In Proceedings
of the 5th National Conference on Artificial
Intelligence. Philadelphia, PA, August 11-15, 1986.
Volume 1: Science., pages 140–147, 1986.
A. Sadilek and H. Kautz. Modeling Success, Failure,
and Intent of Multi-Agent Activities Under Severe
Noise.
A. Sadilek and H. Kautz. Location-based Reasoning
About Complex Multi-agent Behavior. J. Artif. Int.
Res., 43(1):87–133, Jan. 2012.
A. Sadilek and H. A. Kautz. Recognizing multi-agent
activities from gps data. In AAAI, volume 39, page
109, 2010.
P. Santos and M. Shanahan. Hypothesising object
relations from image transitions. In ECAI, pages
292–296, 2002.
P. Shakarian, J. P. Dickerson, and V. Subrahmanian.
Adversarial geospatial abduction problems. ACM
Transactions on Intelligent Systems and Technology
(TIST), 3(2):34, 2012.
P. Shakarian, M. K. Nagel, B. E. Schuetzle, and
V. Subrahmanian. Abductive inference for combat:
using scare-s2 to find high-value targets in
afghanistan. Technical report, DTIC Document, 2011.
P. Shakarian and V. Subrahmanian. Region-based
Geospatial Abduction with Counter-IED Applications.
In U. K. Wiil, editor, Counterterrorism and Open
Source Intelligence. Springer, 2010.
P. Shakarian and V. Subrahmanian. Geospatial
Abduction: Principles and Practice. SpringerLink :
Bücher. Springer New York, 2011.
P. Shakarian, V. Subrahmanian, and M. L. Spaino.
SCARE: A Case Study with Baghdad. In Proceedings
of the Third International Conference on
Computational Cultural Dynamics. AAAI, 2009.
P. Shakarian, V. Subrahmanian, and M. L. Spaino.
GAPs: Geospatial Abduction Problems. ACM
Transactions on Intelligent Systems and Technology,
2010.
M. Shanahan. Noise and the Common Sense
Informatic Situation for a Mobile Robot.
J. F. Stollsteimer. A working model for plant numbers
and locations. Journal of Farm Economics,
45(3):631–645, 1963.

Early Identification of Violent Criminal Gang Members
John Bertetto

Elham Shaabani∗, Ashkan Aleali∗ , and
Paulo Shakarian

Chicago Police Department
Chicago, IL

Arizona State University
Tempe, AZ

john.bertetto@chicagopolice.org

{shaabani, aleali, shak}@asu.edu

ABSTRACT

be involved in violence, allowing for a more focused policing
with respect to patrols and intelligence gathering. Our key
aim is to significantly reduce the population of potential violent gang members which will lead to more efficient policing.
In this paper, we introduce our method for identifying
potentially violent gang members that leverages features derived from the co-arestee social network of criminal gangs in
a classifier to identify potentially violent individuals. We
note that this classification problem is particularly difficult
due to not only data imbalances, but also due to the fact that
many violent crimes are conducted due to heightened emotions - and hence difficult to identify. Though we augment
our network-based features with some additional meta-data
from the arrest records, our approach does not leverage features concerning the race, ethnicity, or gender of individuals
in the social network. We evaluate our method using realworld offender data from the Chicago Police Department.
This paper makes the following contributions:

Gang violence is a major problem in the United States accounting for a large fraction of homicides and other violent crime. In this paper, we study the problem of early
identification of violent gang members. Our approach relies on modified centrality measures that take into account
additional data of the individuals in the social network of
co-arrestees which together with other arrest metadata provide a rich set of features for a classification algorithm. We
show our approach obtains high precision and recall (0.89
and 0.78 respectively) in the case where the entire network
is known and out-performs current approaches used by lawenforcement to the problem in the case where the network
is discovered overtime by virtue of new arrests - mimicking real-world law-enforcement operations. Operational issues are also discussed as we are preparing to leverage this
method in an operational environment.
Categories and Subject Descriptors: J.4 [Computer
Applications]: Sociology
General Terms: Security; Experimentation
Keywords: Social Network Analysis; Criminology

1.

• We discuss how centrality measurements such as degree, closeness, and betweenness when modified to account for metadata about past offenses such as the
type of offense and whether the offense was classified
as “violent” can serve as robust features for identifying
violent offenders.

INTRODUCTION

Gang violence is a major problem in the United States [1,
2] - accounting for 20 to 50 percent of homicides in many
major cities [10]. Yet, law enforcement actually has existing data on many of these groups. For example the underlying social network structure is often recorded by lawenforcement and has previously been shown useful in enabling “smart policing” tactics [17] and improving law
-enforcement’s understanding of a gang’s organizational structure [19]. In this paper we look to leverage this gang social
network information to create features that allows us to classify individuals as potentially violent. While the results of
such a classifier are insufficient to lead to arrests, it is able
to provide the police leads to individuals who are likely to
∗

These authors contributed equally to this work.

• We show how the network features, combined with
other feature categories provide surprisingly robust performance when the entire offender is known in terms of
both precision (0.89) and recall (0.78) using cross-fold
validation.
• We then test our methods in the case where the network is exposed over time (by virtue of new arrests)
which mimics an operational situation. Though precision and recall are reduced in this case, we show that
our method significantly outperforms the baseline approach currently in use by law-enforcement - on average increasing precision and recall by more than two
and three times respectively.
In addition to these main results, we also present some side
results on the structure and nature of the police dataset we
examine. The paper is organized as follows. In Section 2 we
motivate this difficult problem within the law-enforcement
community. This is followed by a description of our dataset
along with technical notation in Section 3. There, we also
describe some interesting aspects of the gang arrest dataset
and our co-arrestee network. In Section 4 we formally define our problem, describe existing approaches, and then describe the features we use in our approach. Then we present

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
KDD’15, August 10-13, 2015, Sydney, NSW, Australia.
c 2015 ACM. ISBN 978-1-4503-3664-2/15/08 ...$15.00.

DOI: http://dx.doi.org/10.1145/2783258.2788618.

2079

our results in Section 5 for both cases where we assume the
underlying network is known and when we discover the network over time (mimicking an operational scenario). Finally,
related work is discussed in Section 6.

2.

needing coverage. Blanketing violence reduction strategies
that saturate geographic areas with law enforcement agents
and rely on direct contact with large numbers of criminal
network members are inefficient and resource consuming.
Focusing efforts on those individuals most likely to engage in
violence allows law enforcement to focus on smaller groups
of people and smaller geographic areas (those areas within
which those individuals identified are known to frequent).
Therefore, our approach can significantly improve such efforts to identify violent individuals. In this paper, we see
how our method not only out-performs the current social
network heuristic used by police, but also that it provides
a much smaller and more precise list of potentially violent
offenders than simply listing those with a violent criminal
record.

BACKGROUND

A recent study shows that the network for gunshot victimization is denser than previously believed [16]. According
to the authors, within the city of Chicago over 70% of all
gunshot victims are contained within only 6% of the total
population These findings validate what has been considered common knowledge among police for decades: who you
hang out with matters, and if you hang out with those who
engage in or are victims of violence you are more likely to
become an offender or victim yourself.

3.

Identifying potential offenders of gun violence has also
been a staple practice for most law enforcement agencies
as an attempt to curtail future victimization. When gang
conflicts get “hot,” it’s common for law enforcement agents
to put together a list of known “shooters”: those known
gang members with an existing criminal history for gun violence and a predilection for engaging in such illegal activity. Law enforcement agents then attempt to make contact
with these individuals with the expectation that such direct
contact might prevent violence. For most law enforcement
agencies, however, this practice is performed in a very adhoc manner. Identifying these individuals for intervention
has relied primarily on the ability of law enforcement agents
to remember and identify at-risk individuals. While feasible
for small or discreet networks, the ability to recall multiple
individuals in large networks that cross large geographic regions and interact with multiple networks becomes increasing difficult. This difficulty increases significantly as relationships between networks change, known individuals leave
the network, and new individuals enter it. In particular,
the practice is less than idea because it requires officers to
attempt to recall criminal history and network association
data that varies between network members. For example,
a subject who has been arrested on multiple occasions for
carrying a gun or has been arrested for shooting another individual is easy to recall, but recalling and quantifying the
risk for a subject with multiple arrests for non-gun violence
and a direct association with several offenders and victims
of gun violence can be much more difficult. In short, identifying a known “shooter” is relatively straightforward: they
are known. The approach in this paper synthesizes network
connectivity other attributes of the subject to identify those
individuals at risk that law enforcement might not yet know.

GANG CO-OFFENDER NETWORK

In this section, we introduce the necessary basic notation
to describe our co-offender network and then provide details of our real-world criminal dataset and study some of
its properties.

3.1

Technical Preliminaries

Throughout this paper we shall represent an offender network as an undirected graph G = (V, E) where the nodes
correspond with previous offenders and an undirected edge
exists between offenders if they were arrested together. We
will use τ to denote the set of timepoints (dates). We also
have three sets of labels for the nodes: V, S, gang which
are the sets of violent crimes, non violent crimes, and gangs.
For each time point t and each node v, the binary variable
arrtv ∈ {true, false} denotes if v was arrested at time t and
distrtv , beattv , gangtv to denote the district, beat, and gang affiliation of v at time t (we will assume that time is fine-grain
enough to ensure that at each time unit an individual is arrested no more than once). If we drop the t superscript for
these three symbols, it will denote the most recent district,
beat, and gang associated with v in the knowledgebase. We
shall use the sets Vvt and Svt to denote the set of violent and
non violent offenses committed by v at time t respectively.
Note if arrtv = false then Vvt = ∅. We will drop the superscript t for this symbol to denote the union of labels at any
time t in the historical knowledgebase. We also note that
the edges in the graph also depend on time, but for sake of
readability, we shall state with words the duration of time
considered for the edges.
For a given violent crime c ∈ V∪S, we will use the notation
Vct = {v ∈ V s.t. c ∈ Vvt } (intuitively, the subset of the
population who have committed crime c at time t). Again,
we will drop the superscript t if v could have committed
crime c at any time in the historical knowledgebase. For
a set of labels C ⊆ V ∪ S, we will extend this notation:
VCt = {v ∈ V s.t. C ∩ Vvt 6= ∅}. We will slightly abuse
notation here: V∅t = V . We will use similar notation for
denoting a subset of the population that are members of a
certain gang. For instance, Vgangv refers to the set of nodes
who are in the same gang as node v. Likewise, we shall use
the same notation for subgraphs: GtC is the subgraph of G
containing only nodes in VCt and their adjacent edges. We
will use the function d : V × V → N to denote the distance
between two nodes - which for this paper will be the number
of links in the shortest path. For a given node v, the set
Nvi = {v 0 ∈ V s.t. d(v, v 0 ) = i} – the set of nodes that are

Using this information, law enforcement agents may not
only more reliably and consistently identify those individuals
most likely to engage in acts of violence or become victims
of violence due to their personal associations with it, but
also to more effectively manage agency resources. Intervention strategies may include service providers outside law enforcement, such as family members, social service providers,
current or former educators, and clergy. This diversity in
approach not only delivers a more powerful “stop the violence” message but provides a kind of force multiplier for
law enforcement, increasing the number of persons involved
in the effort to prevent violence. Identifying specific individuals for intervention also allows for a more targeted effort by
law enforcement in terms of personnel and geographic areas

2080

Table 1: Summary of arrest data.
Name
Value
Number of records
64466
Violent offense
4450
Homicide
312
Criminal sexual assault
153
Robbery
1959
Aggravated assault
1441
Aggravated battery
896
Non violent offense
60016

Table 2: Network properties.
Name
Values
Vertices
9373
Edges
17197
Average degree
3.66
Average clustering
0.5
Transitivity
0.62
Connected components
1843
Largest connected component di36
ameter
Largest connected component aver12.22
age path length
Largest connected component aver0.63
age clustering

Figure 1: The gang co-offender network. Each color corresponds with a different gang.
rests for non violent crimes vs. arrests for violent crimes
(60016 vs. 4450).
Network Properties. From the arrest data, we were able
to construct the co-offender network. In this network, the
isolated vertices are eliminated due to the lack of structural
information. A visualization of the network is depicted in
Figure 1 and we have included summary statistics in Table 2.
In studying this network, we studied its degree distribution
(Figure 2). Unlike the degree distribution for other scale free
social networks, the degree distribution for the offender network is exponential rather than power law. However, despite
the degree distribution being similar to that of a random (ER) or small world network topology [27], we noticed other
characteristics that indicate differently. The co-offender network has a much higher average clustering coefficient than in
a random network and does not follow the properties of the
small world topology due to the relative high diameter and
average shortest path (computed for the largest connected
component.)

whose shortest path is exactly i hops from v. For two nodes
v, v 0 , we will use the notation σ(v, v 0 ) to be the number of
shortest paths between v and v 0 . For nodes u, v, v 0 , σu (v, v 0 )
will be the number of shortest paths between v and v 0 that
pass through u.
For a given subgraph G0 of G, we shall use C(G0 ) to denote the largest connected component of G0 and for node
v ∈ G0 , we will use the notation Cv (G0 ) to denote the connected component of G0 to which v belongs. If we apply a
community finding algorithm to subgraph G0 , we will use
the notation Pv (G0 ) to denote the partition of G0 to which
v belongs. We will use the notation |·| to denote the size of
a set or the number of nodes in a subgraph.

3.2

Overview of Network Data

In this section we describe our police dataset and the associated co-offender network as well as some interesting characteristics that we have noticed.

Repeat Offenders. There are many instances of repeated
offenses from the same offender. Figure 3 shows the distribution of the repeated arrests for each individual in the
dataset. This indicates that arrest records have utility in
identifying future offenders.

Police Dataset. Our dataset consists of gang-related arrest incidents gathered from August 2011 - August 2014 in
Chicago as well as their immediate associates. This data set
includes locations, dates, the links between the joint arrests,
and the gang affiliation of the offenders. In Table 1, we summarize some of the important characteristics of the dataset.

Seasonality of Crime. There is also a higher chance of
criminal activities in different months of the year. Figure 4
demonstrates some of these variations. As per police observations, both violent and non-violent crime incidents are
lower in the winter months (Dec.-Feb.).

Violent Crimes. In our dataset, the set V consists of the
following crimes have been identified by the Chicago Police
as violent crimes: homicide (first or second degree murder),
criminal sexual assault, robbery, aggravated assault, and aggravated battery. All aforementioned offenses are also FBI
“index” crimes as well. A key aspect about the violent crimes
is that the dataset is highly imbalanced with much more ar-

4.

IDENTIFYING VIOLENT OFFENDERS

In this section, we describe our problem, some of the existing practical approaches used by law-enforcement, and our
approach based on supervised learning with features primarily generated by the network topology.

2081

180	
  

Number	
  of	
  violent	
  individuals	
  

Number	
  of	
  Ver+ces(Hundreds	
  )	
  

40	
  
35	
  
30	
  
25	
  
20	
  
15	
  
10	
  
5	
  
0	
  

140	
  
120	
  
100	
  
80	
  
60	
  
40	
  
20	
  
0	
  
Aug	
   Sep	
   Oct	
   Nov	
   Dec	
   Jan	
   Feb	
   Mar	
   Apr	
   May	
   Jun	
   Jul	
  

Degree	
  

Month	
  
Number	
  of	
  non	
  violent	
  individuals	
  

1	
   3	
   5	
   7	
   9	
   11	
  13	
  15	
  17	
  19	
  21	
  23	
  25	
  27	
  29	
  31	
  33	
  35	
  37	
  39	
  41	
  43	
  45	
  47	
  49	
  

Figure 2: Network degree distribution. The exponential
function fits to the distribution (R2 = 0.77).
Number	
  of	
  individuals(Thousands	
  )	
  

160	
  

6	
  
5	
  
4	
  
3	
  
2	
  

2500	
  
2000	
  
1500	
  
1000	
  
500	
  
0	
  
Aug	
   Sep	
   Oct	
   Nov	
   Dec	
   Jan	
   Feb	
   Mar	
   Apr	
   May	
   Jun	
   Jul	
  

Month	
  
2011-­‐2012	
  

1	
  
0	
  

2012-­‐2013	
  

2013-­‐2014	
  

Figure 4: Seasonality of crime.

2	
   4	
   6	
   8	
   10	
   12	
   14	
   16	
   18	
   20	
   22	
   24	
   26	
   28	
   31	
   38	
  

Number	
  of	
  arrests	
  

∆t days. We note in practice, if police also have records of
those who are incarcerated, and such individuals would be
removed from the list (due to the different jurisdictions of
police and corrections in the Chicago area, we did not have
access to incarceration data - however discussed re-arrests
observed in the data in the previous section).

Figure 3: Repeated arrests. 12866 instances of one-time
arrests have been removed.

4.1

Problem Statement

Given a co-offender network, G = (V, E) and for each
historical timepoint t ∈ τ = {1, . . . , tmax } and v ∈ V , we
have the values of arrtv , distrtv , beattv and elements of the
sets Vvt , gangtv , we wish to identify set {v ∈ V s.t. ∃t >
tmax where |Vvt |> 0}. In other words, we wish to find a set
of offenders in our current co-offender network that commit
a violent crime in the future.

4.2

Two-Hop Heuristic (THH). The two-hop heuristic is
based on the result of [17] which investigated a social network of gunshot victims in Boston and found an inverse relationship between the probability of being a gunshot victim
and the shortest path distance on the network to the nearest
previous gunshot victim. Hence, THH returns all neighbors
one and two hops away from previous violent criminals (see
Algorithm 1 for details on the version we used in our experiments - which was the best-performing variant for our
data). The Chicago Police have adopted a variant of this
method to identify potential gang victims using a combination of arrest and victim data - the co-arrestee network of
criminal gang members includes many individuals who are
also victims of violent crime (this is a direct result of gang
conflict). We note that victim information did not offer a
significant improvement to our approach, except the trivial
case that a homicide victim cannot commit any crime in the
future.

Existing Methods

Here we describe two common techniques often used by
law-enforcement to predict violent offenders. The first is
a simple heuristic based on violent activities in the past.
The second is a heuristic that was based on the findings of
[17] which was designed to locate future victims of violent
crime. Both of these approaches are ad-hoc practical approaches that have become “best practices” for predicting
violent offenders. However, we are not aware of any datadriven, formal evaluation of these methods in the literature.
Past Violent Activities (PVA). The first ad-hoc approach is quite simple: if an offender has committed a violent crime in the past, we claim that he will commit a
violent crime in the future. An obvious variant of this approach is to return the set of violent offenders from the last

4.3

Supervised Learning Approach

We evaluated many different supervised learning approaches
including Naive Bayes (NB), Linear Regression (LR), Decision Tree (DT), Random Forest (RF), Neural Network (NN),

2082

Algorithm 1 Two-Hop Heuristic
1: procedure TwoHop(G)
. Offender network G.
2:
R ← {}
. Identified violent offenders.
3:
V ICT IM S ← {u ∈ G|is homicide victim(u)}
4:
for v ∈ V ICT IM S do
5:
N ← Nv1 ∪ Nv2
. Immediate neighbors
6:
R ← R ∪ {u ∈ N s.t. Vu = ∅}
7:
return R

Table 3: Neighborhood-Based Features

and support vector machines (SVM) on the same set of features for the nodes in the network that we shall describe in
this section. We also explored combining these approaches
with techniques for imbalanced data such as SMOTE [4] and
Borderline SMOTE [9], however we do not report the results
of Borderline SMOTE as it provided no significant difference
from SMOTE. We group our features into four categories:
(1.) neighborhood-based (having to do with the immediate neighbors of a given node), (2.) network-based (features
that require the consideration of more than a nodes immediate and nearby neighbors), (3.) temporal characteristics,
and (4.) geographic characteristics.

4.3.1

Neighborhood-Based Features

Neighborhood-based features are the features computed
using each node and its first and/or second level neighbors
in G – often with respect to some C ⊆ V. The simplest such
measure is the degree of vertex v – corresponding to the
number of offenders arrested with v. We can easily extend
this for some set of crimes of interest (C) where we look at
all the neighbors of v who have committed a crime in C.
This generalizes degree (as that is the case where C = ∅).
In our experiments, we found the most useful neighborhood
features to be in the case where C = V though standard
degree (C = ∅) was also used. We also found that using
combinations of the following booleans based on the below
definition also proved to be useful:
majv (C, i)

=

|{u|u ∈

(∪i Nvi )

∩ VC }|≥ 0.5 ×

Definition

Degree (w.r.t. C)

|{u|u ∈ Nv1 ∩ VC }|

Fraction of 1-hop
neighbors committing a crime
in C

|{u|u ∈ Nv1 ∩ VC }|/|Nv1 |

Fraction of 2-hop
neighbors committing a crime
in C

|{u|u ∈ Nv2 ∩ VC }|/|Nv2 |

Majority of 1-hop
and 2-hop neighbors committing
a crime in C

majv (C, 1) ∧ majv (C, 2)

Minority of 1-hop
and majority of
2-hop neighbors
comitting a crime
in C

¬majv (C, 1) ∧ majv (C, 2)

Table 4: Network-Based Features (Community)

|(∪i Nvi )|

Intuitively, majv (C, i) is true if at least half of the nodes
within a network distance of i from node v have committed
a crime in C and false otherwise. Using these intuitions, we
explored the space of variants of these neighborhood-based
features and list those we found to be best-performing in
Table 3.

4.3.2

Description

Network-Based Features

Network-based features fall into two sub-categories that
we shall describe in this section: community-based and pathbased.
Network-based community features. We use several
notions of a node’s community when engineering features:
the connected component to which a node belongs, the gang
to which a node belongs, and what we will refer to as an individual’s group. The connected component is simply based
on the overall network structure, while the gang is simply the subgraph induced by the individuals in the network who belong to the same gang (the social network of
node v’s gang is denoted Ggangv . A nodes group is defined
as the partition he/she belongs to based on a partition of

Description

Definition

Component
size when v is
removed

|C(Cv (G) \ {v})|

Largest component size with a
violent node after
v is removed

maxv0 ∈C(Cv (G){v}∩VV |Xv0 |
where Xv0 = Cv0 (Cv (G){v})

Group size

|Pv (Ggangv )|

Relationships
within the group

|{(u, v)
∈
Pv (Ggangv )}|

Number of violent members in
the group

|{v 0 ∈ Pv (Ggangv ) s.t. Vv 6= ∅}|

Triangles
group

in

No. of triangles within subgraph Pv (Ggangv )

Transitivity
group

of

E s.t. u, v

∈

No. of triangles in Pv (Ggangv )
No. of “∨”’s in Pv (Ggangv )

Group-to-group
connections

|{u ∈ Pv (Ggangv ) s.t. ∃(u, w) ∈
E where w ∈
/ Pv (Ggangv )}|

Gang-to-gang
connections

|{u ∈ Ggangv s.t. ∃(u, w) ∈ E
where w ∈
/ Ggangv }|

Ggangv found using the Louvain algorithm [5]. We found
in our previous work [19] and ensuing experience with the
Chicago Police that the groups produced in this method
were highly relevant operationally. In this work, we also
examined other community finding methods (i.e. Infomap,
and Spectral Clustering) and found we obtained the best re-

2083

Table 6: Geographic Features

Table 5: Network-Based Features (Path)
Description
Betweenness
(w.r.t. C)

Name

Definition
P
σv (u,w)
u,w∈VC

District
quency

σ(u,w)

P

Closeness (w.r.t.
C)

(|VC |−1)/

Shell
Number
(w.r.t. C)

shellC (v) (see appendix for further details)

Propagation
(w.r.t. C)

1 if v ∈ Γκ (VV ), 0 otherwise.
(see appendix for further details)

u∈VC

d(u, v)

|{(t, v 0 ) s.t. arrvt 0 = true ∧
0
∃t0 s.t. distrvt 0 = distrvt }|
|{(t, v 0 ) s.t. arrvt 0 = true ∧
0
∃t0 s.t. beattv0 = beattv }|

Beat Violence

|{(t, v 0 ) s.t. arrvt 0 = true ∧ Vvt 0 6=
0
∅ ∧ ∃t0 s.t. beattv0 = beattv }|

District Violence

|{(t, v 0 ) s.t. arrvt 0 = true ∧ Vvt 0 6=
0
∅ ∧ ∃t0 s.t. distrvt 0 = distrvt }|

Temporal Features

We considered couple of temporal features: average interval month and number of violent groups. Average interval
time considers the average time duration of consecutive arrests of the offender. The other feature, which we examine,
is number of violent groups appeared over time in the environment. We examined that the number of violent groups
has been an important temporal aspect for identifying the
violent criminals. The key intuition here is, if at least one
member of the offender’s groups (formed over time) is violent then we consider the offender as a part of that violent
group. For an individual v, we define the partially ordered
set tvC = {t s.t. arrtv = true ∧ VCt 6= ∅} (intuitively the set
of the time points where v has committed at least on of the
crimes in C.) We also define ∆vi (C) = tvi − tvi−1 for each
tvi ∈ tvC . Considering these definitions, we formally define
the temporal features in Table 7.

Network-based path features. We looked at several features that leveraged the paths in the network by adopting
three common node metrics from the literature: betweenness, closeness [6], and shell-number [23] as well as a propagation process based on a deterministic tipping model [8].
The features are listed in Table 5. We examined our modified definitions of closeness, betweenness, and shell number
where C was a single element of V, where C = V and where
C = ∅ (which provides the standard definitions of these
measures). Our intuition was that individuals nearer in the
network to other violent individuals would also tend to be
more violent - and we found several interesting relationships
such as that for closeness (where C = VV ) discussed in section 5.1 when we run the classifier on each feature group.
Shell number and the propagation process were used to capture the idea of the spread of violence (as shell number was
previously shown to correspond with “spreaders” in various
network epidemic models [11]). For the propagation process,
we set the threshold (κ) equal to two, three, four, five, and
six. Further details on shell number and the propogation
process can be found in the appendix.

4.3.3

Fre-

Beat Frequency

4.3.4

sults by using the Louvain algorithm. We provide our best
performing network-based community features that we used
in Table 4. Of particular interest, we found for individual
v that features relating to the size of the largest connected
component resulting v 0 removal of his/her connected component was useful. Another interesting pair of features we
noted for both group and gang were the number of edges
from members of that group/gang to a different group or
gang. We hypothesize that the utility of these features is a
result of conflicts between groups/gangs they are connected
to as well as the spread of violence amongst different groups
(i.e. if two groups are closely connected, one may conduct
violent activities on behalf of the other).

Definition

Table 7: Temporal Features
Name
Average interval
time (w.r.t. C)
Number of violent groups

Definition
P v
v
i ∆i (C)/|tC |
|{t s.t. arrvt = true ∧
∃v 0 s.t. arrvt 0 = true ∧
Vvt 6= ∅ ∧
v 0 ∈ Nvt }|

5.

EXPERIMENTAL RESULTS

In this section, we review the results of our experiments.
We looked at two types: experiments where the entire cooffender network is known before-hand (Section 5.1) and experiments where the network is discovered over time (Section 5.2). The intuition behind the experiments where the
co-offender network is known is that the police often have
additional information to augment co-arrestee data. This
information can include informant reporting, observed individuals interacting by patrolmen, intelligence reporting, and
information discovered on social media and the Internet. In
our second type of experiment we discover the network over
time in an effort to mimic real-world operations - however,

Geographic Features

Geographic features capture the information related to
the location of a crime incident. The intuition is that the
individuals who commit crimes in violent districts are more
likely to become violent than the others. We found that the
beat the individual has committed a crime in is an important feature for our problem. This is in accordance with
previous well known literature in criminology [3, 21] which
studies spatio-temporal modeling of criminal behavior. The
complete list is shown in Table 6.

2084

1	
  
0.9	
  
0.8	
  
0.7	
  
0.6	
  
0.5	
  
0.4	
  
0.3	
  
0.2	
  
0.1	
  
0	
  

we also show that this makes the problem more difficult as
it reduces the power of neighborhood-based and networkbased features. Based on our discussions with the Chicago
Police, we believe that real-world results will most likely fall
somewhere between these two experiments. Operationally,
we will not have full arrest data, but the aforementioned
augmenting data sources are available (even though we did
not have access to them for our experiments).

5.1

Known Co-Offender Network

Neighborhood-­‐ Network-­‐Based	
   Geographic	
  
Based	
  
Features	
  	
  

In this experiment we assume that the entire offender network is known. In other words, to compute the features for
each vertex v, we assume that the set Vv is unknown while
the rest of the network is observable. In here we compared
our approach with THH but not with the PVA as we do not
utilize time. In each of the experiments described in this section, we conduct 10-fold cross validation. We consider the
result of each approach as a set of nodes that the approach
considers to be a set of potentially violent individuals. Our
primary metrics are precision (fraction of reported violent
individual who were actually violent in the dataset), recall
(fraction of violent individuals in the dataset reported by the
approach), F1 (the harmonic mean of precision and recall)
and area under the curve. We conduct two types of experiments: first, we study classification performance using only
features within a given category (neighborhood, network,
temporal, and geographic), then we study the classification
performance when the entire feature set is used but with
various different classification algorithms and compare the
result to THH.

Precision	
  

Recall	
  

Temporal	
  

F1	
  

Figure 5: Precision, recall, and F1 comparison between
each group of features.
1	
  

1	
  

0.9	
  

0.9	
  

0.8	
  

0.8	
  

0.7	
  

0.7	
  

0.6	
  

0.6	
  

0.5	
  

0.5	
  

0.4	
  

0.4	
  

0.3	
  

0.3	
  

0.2	
  

0.2	
  

0.1	
  

0.1	
  

0	
  

0	
  
Precision	
  

Recall	
  

F1	
  

Precision	
  

(a)
1	
  

1	
  

0.9	
  

0.9	
  

0.8	
  

0.8	
  

F1	
  

0.7	
  

0.7	
  

0.6	
  

0.6	
  

0.5	
  

0.5	
  

Classification using single feature categories. Here
we describe classification results using single feature categories. In this set of experiments, we use a random forest
classifier (which we will later show provides the best performance of the classifiers that we examined). Figure 5 shows
the performance of RF for the described categories. The
network-based features are highly-correlated to violent behavior with average F1 value of 0.72 compared to 0.63 for
neighborhood, 0.21 for geographic, and 0.03 for temporal
features. In Figure 6, we show the performance of a feature
from each category to classify violent vs. non violent crimes;
the performance of each example is a good indicator of the
performance of its category.

Recall	
  

(b)

0.4	
  

0.4	
  

0.3	
  

0.3	
  

0.2	
  

0.2	
  

0.1	
  
0	
  

0.1	
  

Precision	
  

0	
  
Precision	
  

Recall	
  

Recall	
  

Violent	
  

F1	
  

(c)

F1	
  

Non	
  violent	
  

(d)

Figure 6: Example features from each category. (a)
Neighborhood-based: Minority of 1-hop and majority of 2-hop neighbors committing a crime in C.
(b) Network-based: Closeness (w.r.t. V). (c) Geographic: Beat violence. (d) Temporal: Average
interval months.

True	
  posi*ve	
  

Classification comparison. Table 8 shows the performance of different classification algorithms. According to
Table 8, RF provides the best performance (F1=0.83); we
also note that using SMOTE for RF, did not improve this
result. Figure 8 shows that our algorithm outperforms THH.
The performance of our features are also illustrated in Figure 7. The area under the curve (AUC) of applying all
features is 0.98 – a higher overall accuracy. The AUC for
network-based, neighborhood-based, geographic, and temporal categories are 0.92, 0.91, 0.65, and 0.7 respectively.
This indicates the importance of network features for this
classification task.

1	
  
0.9	
  
0.8	
  
0.7	
  
0.6	
  
0.5	
  
0.4	
  
0.3	
  
0.2	
  
0.1	
  
0	
  
0	
  

0.2	
  

0.4	
  

0.6	
  

0.8	
  

1	
  

False	
  posi*ve	
  
Network-­‐Based	
  

Neighborhood-­‐Based	
  	
  

Geographic	
  

Temporal	
  

All	
  

5.2

Co-Offender Network Emerges Over Time

Figure 7: ROC curve for each feature set.

In this section, we present a more difficult experiment where the co-arrestee network is discovered over time (by
virtue of arrests). To simulate this phenomenon, we split

2085

In these experiments, we compared our approach using
random forests with the full feature set to THH and PVA.
We measure precision, recall, F1, number of true positives,
and number of false positives and display the results in Figures 10 and 11. In FRF (Filtered Random Forest) we filter the offenders who have not committed any crime in the
last 200 days. This simple heuristic increase the precision
drastically while preserving the recall. The main advantage
of our method, besides the high precision, is its ability to
significantly reduce the population of potentially violent offenders when compared to PVA - which for each month had
between 1813 and 3571 false positives. Figure 11 compares
the number of true and false positives instances for all the
approaches for each month except PVA (PVA was omitted
due to readability because of the large amount of false positives). While the F1 measure for PVA is higher than that of
the others, the large number of false positives prevents the
law enforcement from using it effectively in practice. Furthermore, as time progresses, PVA likely rises in recall due
to the drop in the number of violent criminals to predict.

Table 8: K-fold cross validation.
Method
Precision Recall F1
RF
0.89
0.78
0.83
RF w. SMOTE 0.86
0.78
0.82
NB
0.45
0.49
0.47
LR
0.68
0.49
0.57
DT
0.71
0.66
0.68
NN
0.64
0.57
0.6
SVM
0.73
0.2
0.31
1	
  
0.9	
  
0.8	
  
0.7	
  
0.6	
  
0.5	
  
0.4	
  
0.3	
  
0.2	
  

6.

0.1	
  
0	
  
THH	
  

RF	
  

Precision	
  

Recall	
  

F1	
  

Figure 8: Performance comparison between THH and RF
in K-fold cross validation.

Frac%on	
  of	
  full	
  dataset	
  

our data into two disjoint sets: the first set for learning
and identification, and the second one for measuring the
performance. We do monthly split and start from February
2013. To illustrate the difficulty of this test, we show the
number of nodes, edges, and violent individuals per month in
Figure 9. We note that in the early months, we are missing
much of the graphical data (over 40% of nodes and edges in
the first two months) - hence making many of our features
less effective. However, as the months progress, there are less
violent individuals to identify (due to the temporal nature of
the dataset) - hence amplifying the data imbalance as time
progresses.

1	
  
0.9	
  
0.8	
  
0.7	
  
0.6	
  
0.5	
  
0.4	
  
0.3	
  
0.2	
  
0.1	
  
0	
  

Month	
  
Edges	
  

Nodes	
  

RELATED WORK

Though we believe that the prediction of violent offenders
using co-offender social networks is new, there has previously
been work on both co-offender networks in general as well
as crime forecasting. In this section, we briefly review some
of the relevant contributions in both of these areas.
There has been much previous work on co-offender networks. The earlier work that studied these special social
networks primarily came from the criminology literature.
For instance, [14] utilizes social network analysis techniques
to study several case studies where the social network of the
criminal organization was known. In [13], the authors study
the stability of these networks change over time. More recently, graphical features derived from networks comprised
of both offenders and victims has been shown to be related
to the the probability of an individual becoming a victim
of a violent crime [17, 16]. Previous work has also looked
at the relationship between network structure and geography [18] and has leveraged both network and geographic
features to predict criminal relationships [25] as well as influence gang members to dis-enroll [24]. There have also
been several software tools developed for conducting a widerange of analysis on co-offender networks including CrimeFighter [20], CrimeLink [22], and ORCA [19]. However, our
work departs from this is that we are looking to leverage
the network topology and other features to identify violent
offenders - which was not studied in any of the previous
work.
There has also been a large amount of work on crime forecasting (i.e. [7, 12]) though historically, this work has relied
on spatio-temporal modeling of criminal behavior [3, 21] or
was designed to identify suspects for specific crimes [26, 15].
None of this previous work was designed to identify future
violent offenders nor did it leverage social network structure.

7.

Violent	
  individuals	
  

CONCLUSION

In this paper we explored the problem of identifying repeat offenders who will commit violent crime. We showed
a strong relationship between network-based features and
whether a criminal will commit a violent offense providing

Figure 9: Number of nodes, edges, and violent individuals
over time. More training data, less offenders to identify.

2086

90	
  

Number	
  of	
  true	
  posi.ve	
  

0.4	
  
0.35	
  

Recall	
  

0.3	
  
0.25	
  
0.2	
  
0.15	
  
0.1	
  

80	
  
70	
  
60	
  
50	
  
40	
  
30	
  
20	
  
10	
  
0	
  

13
	
  
Ap
r-­‐1
3	
  
Ju
n-­‐
13
	
  
Au
g-­‐
13
	
  
Oc
t-­‐1
3	
  
De
c-­‐
13
	
  
Fe
b-­‐
14
	
  
Ap
r-­‐1
4	
  
Ju
n-­‐
14
	
  

0.05	
  

13
	
  
Ap
r-­‐1
3	
  
Ju
n-­‐
13
	
  
Au
g-­‐
13
	
  
Oc
t-­‐1
3	
  
De
c-­‐
13
	
  
Fe
b-­‐
14
	
  
Ap
r-­‐1
4	
  
Ju
n-­‐
14
	
  

Fe
b-­‐

0	
  

Fe
b-­‐

Month	
  

Month	
  

FRF	
  

0.2	
  
0.15	
  
0.1	
  
0.05	
  

1000	
  
800	
  
600	
  
400	
  
200	
  
0	
  

13
	
  

Ap
r-­‐1
3	
  
Ju
n-­‐
13
	
  
Au
g-­‐
13
	
  
Oc
t-­‐1
3	
  
De
c-­‐
13
	
  
Fe
b-­‐
14
	
  
Ap
r-­‐1
4	
  
Ju
n-­‐
14
	
  

Precision	
  

THH	
  

1200	
  

Number	
  of	
  false	
  posi/ve	
  

0.25	
  

RF	
  

13
	
  
Ap
r-­‐1
3	
  
Ju
n-­‐
13
	
  
Au
g-­‐
13
	
  
Oc
t-­‐1
3	
  
De
c-­‐
13
	
  
Fe
b-­‐
14
	
  
Ap
r-­‐1
4	
  
Ju
n-­‐
14
	
  

Fe
b-­‐

0	
  

Fe
b-­‐

Month	
  

Month	
  

FRF	
  

RF	
  

THH	
  

0.18	
  

Figure 11: Number of true and false positive instances.

0.16	
  
0.14	
  

F1	
  

0.12	
  

is the set of nodes in core k but not in any higher core. A
node’s shell number is k value of the shell to which that node
belongs. For a given node v and C ⊆ V, we define shellC (v)
as the shell number of node v on the subgraph consisting
of v and all nodes v 0 where C ∩ Vv 6= ∅. We slightly abuse
notation and define shell∅ (v) as the shell number of v on the
full network.

0.1	
  
0.08	
  
0.06	
  
0.04	
  
0.02	
  

Fe
b-­‐

13
	
  
Ap
r-­‐1
3	
  
Ju
n-­‐
13
	
  
Au
g-­‐
13
	
  
Oc
t-­‐1
3	
  
De
c-­‐
13
	
  
Fe
b-­‐
14
	
  
Ap
r-­‐1
4	
  
Ju
n-­‐
14
	
  

0	
  

Month	
  
THH	
  

FRF	
  

RF	
  

Propogation Process. For a given node v and the set of
activated nodes V 0 , we define v’s active neighbors as follows:

PVA	
  

actv (V 0 ) = {u|u ∈ Nv1 ∩ V 0 }
Figure 10: Precision, recall, and F1 over time.

We now define an activation function A that, given an initial
set of active nodes, returns a set of active nodes after one
time step.

an unbiased F1 score of 0.83 in our cross-validation experiment where we assumed that the underlying network was
known. When we moved to the case where the network
was discovered over time, our method significantly outperformed baseline approaches significantly increasing precision
and recall. We are currently discussing ways to operationalize this technology with the Chicago Police as well as design
strategies to best deploy police assets to areas with higher
concentrations of potentially violent offenders. We are also
working with the police to identify other sources of data to
build a more complete social network of the offenders.

Aκ (V 0 ) = V 0 ∪ {v ∈ V s.t. |actv (V 0 )|≥ κ}
We also note that the activation function can be applied
iteratively, to model a diffusion process. Hence, we shall use
the following notation to signify multiple applications of A
(for natural numbers t > 1).

Aκ (V 0 )
if t = 1
Atκ (V 0 ) =
0
Aκ (At−1
κ (V )) otherwise
0
Clearly, when AtG,κ (V 0 ) = At−1
G,κ (V ) the process has converged. Further, this always converges in no more than |V |
steps, since the process must activate at least one new node
in each step prior to converging. Based on this idea, we
define the function Γ which returns the set of all nodes activated upon the convergence of the activation function. We

Appendix
Shell Number. For a given graph, the k-core is the largest
subgraph where each node has at least degree k. The k-shell

2087

define Γκ (V 0 ) = Aκ (V 0 ) where t is the least value such that
0
Atκ (V 0 ) = At−1
κ (V ).

8.

[16] A. Papachristos, C. Wildeman, and E. Roberto. Tragic, but
not random: The social contagion of nonfatal gunshot injuries.
Social Science and Medicine, page 139.
[17] B. A. H. D. Papachristos, A. Social networks and the risk of
gunshot injury. J. Urban Health, 2012.
[18] H. D. B. A. Papachristos, A. The corner and the crew: The
influence of geography and social networks on gang violence.
American Sociological Review, 2013.
[19] D. Paulo, B. Fischl, T. Markow, M. Martin, and P. Shakarian.
Social network intelligence analysis to combat street gang
violence. In Proceedings of the 2013 IEEE/ACM
International Conference on Advances in Social Networks
Analysis and Mining, ASONAM ’13, pages 1042–1049, New
York, NY, USA, 2013. ACM.
[20] R. R. Petersen and U. K. Wiil. Crimefighter investigator: A
novel tool for criminal network investigation. In EISIC, pages
197–202. IEEE, 2011.
[21] D. K. Rossmo and S. Rombouts. Geographic Profiling. In
R. Wortley and L. Mazerolle, editors, Enviromental
Criminology and Crime Analysis, pages 136–149. 2008.
[22] J. Schroeder, J. Xu, and H. Chen. Crimelink explorer: Using
domain knowledge to facilitate automated crime association
analysis. In H. Chen, R. Miranda, D. Zeng, C. Demchak,
J. Schroeder, and T. Madhusudan, editors, Intelligence and
Security Informatics, volume 2665 of Lecture Notes in
Computer Science, pages 168–180. Springer Berlin Heidelberg,
2003.
[23] S. B. Seidman. Network structure and minimum degree. Social
Networks, 5(3):269 – 287, 1983.
[24] P. Shakarian, J. Salmento, W. Pulleyblank, and J. Bertetto.
Reducing gang violence through network influence based
targeting of social programs. In Proceedings of the 20th ACM
SIGKDD International Conference on Knowledge Discovery
and Data Mining, KDD ’14, pages 1829–1836, New York, NY,
USA, 2014. ACM.
[25] M. A. Tayebi, M. Ester, U. Glässer, and P. L. Brantingham.
Spatially embedded co-offence prediction using supervised
learning. In Proceedings of the 20th ACM SIGKDD
International Conference on Knowledge Discovery and Data
Mining, KDD ’14, pages 1789–1798, New York, NY, USA,
2014. ACM.
[26] M. A. Tayebi, M. Jamali, M. Ester, U. Glässer, and R. Frank.
Crimewalker: A recommendation model for suspect
investigation. In Proceedings of the Fifth ACM Conference on
Recommender Systems, RecSys ’11, pages 173–180, New York,
NY, USA, 2011. ACM.
[27] D. J. Watts and S. H. Strogatz. Collective dynamics of
“small-world” networks. nature, 393(6684):440–442, 1998.

REFERENCES

[1] J. Bertetto. Countering criminal street gangs: Lessons from
the counterinsurgent battlespace. Law Enforcement Executive
Forum, 12(3):43, 2012.
[2] A. Braga, D. Hureau, and A. Papachristos. Deterring
gang-involved gun violence: Measuring the impact of boston’s
operation ceasefire on street gang behavior. Journal of
Quantitative Criminology, pages 1–27, 2013.
[3] P. Brantingham and P. Brantingham. Crime Pattern Theory.
In R. Wortley and L. Mazerolle, editors, Enviromental
Criminology and Crime Analysis, pages 78–93. 2008.
[4] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P.
Kegelmeyer. Smote: synthetic minority over-sampling
technique. Journal of artificial intelligence research,
16(1):321–357, 2002.
[5] P. Expert, T. S. Evans, V. D. Blondel, and R. Lambiotte.
Uncovering space-independent communities in spatial
networks. Proceedings of the National Academy of Sciences,
108(19):7663–7668, 2011.
[6] L. C. Freeman. A set of measures of centrality based on
betweenness. Sociometry, 40(1):pp. 35–41, 1977.
[7] W. Gorr and R. Harries. Introduction to crime forecasting.
International Journal of Forecasting, 19(4):551 – 555, 2003.
[8] M. Granovetter. Threshold models of collective behavior. The
American Journal of Sociology, (6):1420–1443.
[9] H. Han, W.-Y. Wang, and B.-H. Mao. Borderline-smote: a new
over-sampling method in imbalanced data sets learning. In
Advances in intelligent computing, pages 878–887. Springer,
2005.
[10] J. C. Howell. Gangs in America’s Communities. Sage, 2012.
[11] M. Kitsak, L. K. Gallos, S. Havlin, F. Liljeros, L. Muchnik,
H. E. Stanley, and H. A. Makse. Identification of influential
spreaders in complex networks. Nat Phys, 6(11):888–893, Nov.
2010.
[12] H. Liu and D. E. Brown. Criminal incident prediction using a
point-pattern-based density model. International Journal of
Forecasting, 19(4):603–622, Oct. 2003.
[13] J. M. Mcgloin, C. J. Sullivan, A. R. Piquero, and S. Bacon.
Investigating the stability of co-offending and co-offenders
among a sample of youthful offenders. Criminology,
46(1):155–188, 2008.
[14] C. Morselli. Inside Criminal Networks. Springer, 2009.
[15] C. Overall and G. Day. The Hammer Gang: an exercise in
spatial analyis of an armed robbery series using the probability
grid method. In S. Chainey and L. Tompson, editors, Crime
Mapping Case Studies, pages 55–62. 2008.

2088

ABSTRACT

Title of dissertation:

SPATIO-TEMPORAL REASONING
ABOUT AGENT BEHAVIOR
Paulo Shakarian, Doctor of Philosophy, 2011

Dissertation directed by:

Professor V.S. Subrahmanian
Department of Computer Science

There are many applications where we wish to reason about spatio-temporal
aspects of an agent’s behavior. This dissertation examines several facets of this type
of reasoning.
First, given a model of past agent behavior, we wish to reason about the probability that an agent takes a given action at a certain time. Previous work combining
temporal and probabilistic reasoning has made either independence or Markov assumptions. This work introduces Annotated Probabilistic Temporal (APT) logic
which makes neither assumption. Statements in APT logic consist of rules of the
form “Formula G becomes true with a probability [L,U] within T time units after
formula F becomes true” and can be written by experts or extracted automatically
from historical data. In this dissertation, we explore the problem of entailment,
specifically what is the probability that an agent performs a given action at a certain time based on a set of such rules. We show this problem to be coNP-hard
(in the complexity class coNP under some natural assumptions) and present several
sets of linear constraints for solving this problem exactly. We then develop a sound,

but incomplete fixpoint operator as a heuristic for such queries. This approach was
implemented and tested on 23 different models automatically generated from several
datasets. The operator quickly converged to produce tight probability bounds for
the queries.
Second, agent behavior often results in “observations” at geospatial locations
that imply the existence of other, unobserved, locations we wish to find (“partners”). In this dissertation, we formalize this notion with “geospatial abduction
problems” (GAPs). GAPs try to infer a set of partner locations for a set of observations and a model representing the relationship between observations and partners
for a given agent. This dissertation presents exact and approximate algorithms for
solving GAPs as well as an implemented software package for addressing these problems called SCARE (the Spatio-Cultural Abductive Reasoning Engine). We tested
SCARE on counter-insurgency data from Iraq, attempting to locate enemy weapons
caches (partners) based on attacks (observations). On average, SCARE was able
to locate weapons caches within 690 meters of actual sites. Additionally, we have
considered a variant of the problem where the agent wishes to abduce regions that
contain partner points. This problem is also NP-hard. To address this issue, we
develop and implement a greedy approximation algorithm that finds small regions
which contain partner points - on average containing 4 times as many partners as
the overall area.
We then provide an adversarial extension to GAPs as follows: given a fixed set
of observations, if an adversary has probabilistic knowledge of how an agent were to
find a corresponding set of partners, he would place the partners in locations that

minimize the expected number of partners found by the agent. In a complementary
problem, the agent has probabilistic knowledge of how an adversary locates his partners and wishes to maximize the expected number partners found. We show that
both of these problems are NP-hard and design schemes to find approximate solutions - often with theoretical guarantees. With our implementation, we demonstrate
that these algorithms often obtain excellent solutions.
We also introduce a class of problems called geospatial optimization problems
(GOPs). Here the agent has a set of actions that modify attributes of a geospatial region and he wishes to select a limited number of such actions (with respect
to some budget) in a manner that either causes some goal to be true (goal-based
GOPs) and/or maximizes a benefit function (benefit-maximizing GOPs). Additionally, there are certain combinations of actions that cannot be combined. We show
NP-hardness (membership in NP under reasonable assumptions) as well as provide
limits of approximation for these problems. We then develop sets of integer constraints that provide an exact solution and provide an approximation algorithm with
a guarantee.
While we look to optimize certain geospatial properties in GOPs, we note
that for some real-world applications, such as epidemiology, there is an underlying
diffusion process that also affect geospatial proprieties. Assuming the structure of
a social network - a directed graph with weighted and labeled vertices and edges
- we study optimization with respect to such diffusion processes in social network
optimization problems (SNOPs). We show that many well-known social network
diffusion process can be embedded into generalized annotated programs [86]. Hence,

a SNOP query seeks to find a set of vertices, that if given some initial property,
optimize an aggregate with respect to such a diffusion process. We show this class
of problems is also NP-hard (NP-complete under certain assumptions). We develop
a greedy heuristic that obtains an approximation guarantee for a large class of such
queries. We implemented this algorithm and evaluated it on a real-world data-set
consisting of a graph of 103,000 edges.

SPATIO-TERMPORAL REASONING
ABOUT AGENT BEHAVIOR

by
Paulo Shakarian

Dissertation submitted to the Faculty of the Graduate School of the
University of Maryland, College Park in partial fulfillment
of the requirements for the degree of
Doctor of Philosophy
2011

Advisory Committee:
Professor V.S. Subrahmanian, Chair/Advisor
Professor Stuart S. Antman, Dean’s Representative
Professor Samir Khuller
Professor Dana Nau
Professor James A. Reggia

Dedication
To my son, Carter.

ii

Acknowledgments
Above all, I would like to thank my wife, Jana, for her love and understanding
throughout my graduate experience. I do not think I could have done this without
her constant support.

I would like to thank my advisor, Prof. V.S. Subrahmanian, who since 2007,
has mentored and guided me throughout this entire process.

I would also like to thank my committee, Prof. Dana Nau, Prof. Samir Khuller,
Prof. James Reggia, and Prof. Stuart Antman who have also been supportive.

Additionally, I would like to thank the following people who have all contributed to my success in graduate school (in no particular order): Gerardo Simari,
Dan LaRocque, Austin Parker, Patrick Roos, John Dickerson, Geoff Stoker, Prof.
Maria Luisa Sapino, and Matthias Broecheler.

Finally, I would like to thank the U.S. Army Advanced Civil Schooling (ACS)
program and the U.S. Military Academy (USMA/West Point) instructor’s program
(Department of Electrical Engineering and Computer Science - EECS) for funding
my Ph.D. studies at the University of Maryland. In particular, COL Eugene Ressler,
who made it possible for me to earn the degree.

iii

Contents

List of Abbreviations

xix

1 Introduction
1.1 Temporal Reasoning about an Agent’s Actions . . .
1.2 Inferring Geospatial Aspects of an Agents Behavior
1.3 Geospatial Abduction under Adversarial Conditions
1.4 Optimal Selection of Agent Actions . . . . . . . . .
1.5 Applications . . . . . . . . . . . . . . . . . . . . . .
1.6 Summary of Major Contributions . . . . . . . . . .
1.7 Related Work . . . . . . . . . . . . . . . . . . . . .

.
.
.
.
.
.
.

1
1
2
4
4
6
8
11

2 Annotated Probabilistic Temporal Logic: Sound and Complete Algorithms for Reasoning
2.1 Chapter Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 APT-Logic Programs . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.2 Semantics of APT-logic programs . . . . . . . . . . . . . . . .
2.2.3 Frequency Functions . . . . . . . . . . . . . . . . . . . . . . .
2.2.4 Satisfaction of Rules and Programs . . . . . . . . . . . . . . .
2.3 Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.1 Complexity of Consistency Checking . . . . . . . . . . . . . .
2.3.2 Linear Constraints for Consistency Checking . . . . . . . . . .
2.3.3 World Equivalence . . . . . . . . . . . . . . . . . . . . . . . .
2.3.4 Frequency Equivalence . . . . . . . . . . . . . . . . . . . . . .
2.3.5 Combining World and Frequency Equivalence . . . . . . . . .
2.4 Entailment by APT-logic programs . . . . . . . . . . . . . . . . . . .
2.4.1 Linear Constraints for Entailment . . . . . . . . . . . . . . . .
2.5 Applications of APT Logic . . . . . . . . . . . . . . . . . . . . . . . .
2.6 Chapter 2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . .
2.6.1 Markov Decision Processes . . . . . . . . . . . . . . . . . . . .
2.6.2 Comparison with Probabilistic Computation Tree Logic (PCTL)
2.7 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . .

15
16
26
26
29
32
38
42
42
47
51
59
67
70
72
74
77
79
89
91

iv

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

3 Annotated Probabilistic Temporal Logic: Approximate Algorithms 94
3.1 Chapter Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
3.2 Technical Background . . . . . . . . . . . . . . . . . . . . . . . . . . 101
3.2.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
3.2.2 Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
3.3 Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
3.4 A Sound but Incomplete Fixpoint-Computation Algorithm: The Ground
Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
3.4.1 Bounding Frequency Function Values . . . . . . . . . . . . . . 113
3.4.2 Theorems for Syntactic Manipulation . . . . . . . . . . . . . . 116
3.4.3 The Fixpoint-Based Heuristic . . . . . . . . . . . . . . . . . . 120
3.4.4 Using Γ for Consistency Checking . . . . . . . . . . . . . . . . 127
3.5 Consistency and Entailment Algorithms for Non-Ground Programs . 130
3.5.1 Consistency Checking for Non-Ground Programs . . . . . . . 131
3.5.2 Entailment for the Non-Ground Case . . . . . . . . . . . . . . 136
3.6 Experimental Results . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
3.6.1 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . 140
3.6.2 Run Time Evaluation . . . . . . . . . . . . . . . . . . . . . . . 142
3.7 Chapter 3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . 149
3.7.1 Work in Verification and PRISM . . . . . . . . . . . . . . . . 150
3.8 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
4 Geospatial Abduction
4.1 Chapter Introduction . . . . . . . . . . . . . . . . . . . . . . .
4.1.1 Geospatial Abduction Problem (GAP) Definition . . . .
4.2 Complexity of GAP Problems . . . . . . . . . . . . . . . . . .
4.3 Exact Algorithm for GAP Problems . . . . . . . . . . . . . . .
4.3.1 Naive Exact Algorithm . . . . . . . . . . . . . . . . . .
4.3.2 An Exact Set-Cover Based Approach . . . . . . . . . .
4.3.3 An Exact Dominating Set Based Approach . . . . . . .
4.3.4 An Exact Integer Linear Programming based Approach
4.4 Greedy Heuristics for GAP Problems . . . . . . . . . . . . . .
4.4.1 A Linear Time Greedy Approximation Scheme . . . . .
4.4.2 Greedy Observation Selection . . . . . . . . . . . . . .
4.5 Implementation and Experiments . . . . . . . . . . . . . . . .
4.5.1 A Simple Heuristic to Improve Accuracy . . . . . . . .
4.6 Chapter 4 Related Work . . . . . . . . . . . . . . . . . . . . .
4.7 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . .
5 Abducing Regions
5.1 Chapter Introduction . . . . . . . . . . .
5.2 Technical Preliminaries . . . . . . . . . .
5.3 Complexity . . . . . . . . . . . . . . . .
5.4 Algorithms . . . . . . . . . . . . . . . . .
5.4.1 Exact and Approximate Solutions
v

. . . . . . . .
. . . . . . . .
. . . . . . . .
. . . . . . . .
by Reduction

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

156
. 156
. 159
. 166
. 169
. 169
. 171
. 174
. 177
. 182
. 182
. 186
. 191
. 197
. 200
. 207

.
.
.
.
.

210
. 210
. 211
. 221
. 223
. 224

5.5

5.6
5.7

5.4.2 Approximation for a Special Case . . . . . .
5.4.3 Practical Considerations for Implementation
Experimental Results . . . . . . . . . . . . . . . . .
5.5.1 Experimental Set-Up . . . . . . . . . . . . .
5.5.2 Running Time . . . . . . . . . . . . . . . . .
5.5.3 Area of Returned Regions . . . . . . . . . .
5.5.4 Regions that Contain Caches . . . . . . . .
5.5.5 Partner Density . . . . . . . . . . . . . . . .
Chapter 5 Related Work . . . . . . . . . . . . . . .
Chapter Summary . . . . . . . . . . . . . . . . . .

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

230
234
237
239
242
244
246
251
255
256

6 Adversarial Geospatial Abduction
257
6.1 Chapter Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
6.2 Overview of GAPs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
6.3 Geospatial Abduction as a Two-Player Game . . . . . . . . . . . . . 262
6.3.1 Incorporating Mixed Strategies . . . . . . . . . . . . . . . . . 267
6.4 Selecting a Strategy for the Adversary . . . . . . . . . . . . . . . . . 269
6.4.1 The Complexity of Finding an Optimal Adversarial Strategy . 271
6.4.2 Pre-Processing and Naive Approach . . . . . . . . . . . . . . . 273
6.4.3 Mixed Integer Linear Programs for OAS under wrf, crf, frf . 275
6.4.4 Correctly Reducing the Number of Variables for crf . . . . . . 279
6.5 Finding a Counter-Adversary Strategy . . . . . . . . . . . . . . . . . 288
6.5.1 The Complexity of Finding a Maximal Counter-Adversary
Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
6.5.2 MCA in the General Case: Exact and Approximate Algorithms292
6.5.3 Finding a Maximal Counter-Adversary Strategy, the Monotonic Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
6.6 Implementation and Experiments . . . . . . . . . . . . . . . . . . . . 299
6.6.1 OAS Implementation . . . . . . . . . . . . . . . . . . . . . . . 300
6.6.2 MCA Implementation . . . . . . . . . . . . . . . . . . . . . . 305
6.7 Chapter 6 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . 311
6.8 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312
7 Geospatial Optimization
7.1 Chapter Introduction . . . . . . . . . . . .
7.2 GOPs Formalized . . . . . . . . . . . . . .
7.3 Complexity Results . . . . . . . . . . . . .
7.4 Integer Programs for Solving GOPs . . . .
7.5 Correct Variable Reduction for GBGOP-IP
7.6 The BMGOP-Compute Algorithm . . . . .
7.7 Chapter 7 Related Work . . . . . . . . . .
7.8 Chapter Summary . . . . . . . . . . . . .

vi

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

315
315
317
322
325
328
330
335
336

8 Social Network Optimization Problems
8.1 Chapter Introduction . . . . . . . . . . . . . . . . . . . .
8.2 Technical Preliminaries . . . . . . . . . . . . . . . . . . .
8.2.1 Social Networks Formalized . . . . . . . . . . . .
8.2.2 Generalized Annotated Programs: A Recap . . .
8.3 Social Network Optimization (SNOP) Queries . . . . . .
8.3.1 Basic SNOP Queries . . . . . . . . . . . . . . . .
8.3.2 Special Cases of SNOP Queries . . . . . . . . . .
8.3.3 Properties of SNOPs . . . . . . . . . . . . . . . .
8.3.4 The Complexity of SNOP Queries . . . . . . . . .
8.3.5 Counting Complexity of SNOP-Queries . . . . . .
8.3.6 The SNOP-ALL Problem . . . . . . . . . . . . .
8.4 Applying SNOPs to Real Diffusion Problems . . . . . . .
8.4.1 Tipping Diffusion Models . . . . . . . . . . . . .
8.4.2 Cascading Diffusion Models . . . . . . . . . . . .
8.4.3 Homophilic Diffusion Models . . . . . . . . . . . .
8.5 Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . .
8.5.1 Naive Algorithm . . . . . . . . . . . . . . . . . .
8.5.2 A Non-Ground Algorithm in the Monotonic Case
8.5.3 Approximation Algorithms: GREEDY-SNOP . .
8.6 Scaling GREEDY-SNOP . . . . . . . . . . . . . . . . . .
8.7 Implementation and Experiments . . . . . . . . . . . . .
8.7.1 Experimental Setting . . . . . . . . . . . . . . . .
8.7.2 Experimental Results . . . . . . . . . . . . . . . .
8.8 Chapter 8 Related Work . . . . . . . . . . . . . . . . . .
8.8.1 Related Work in Logic Programming . . . . . . .
8.8.2 Work in Social Networks . . . . . . . . . . . . . .
8.9 Chapter Summary . . . . . . . . . . . . . . . . . . . . .

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

337
338
341
342
344
348
348
351
356
361
363
364
366
367
371
377
379
380
380
386
391
409
409
412
415
415
417
418

9 Future Work

421

10 Conclusion

425

A Appendix for Chapter 2
A.1 Additional Results . . . . . . . . . . . . . . . . . . . . . .
A.1.1 Frequency Equivalence under the PCD Restriction .
A.1.2 The ALC-ENT Algorithm for Entailment . . . . . .
A.1.3 An Example Comparing PCTL to APT-rules . . . .
A.2 Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A.2.1 Proof of Lemmas 2.12 and 2.14 . . . . . . . . . . .
A.2.2 Proof of pfr Property 5 . . . . . . . . . . . . . . . .
A.2.3 Proof of Proposition 2.15 . . . . . . . . . . . . . . .
A.2.4 Proof of Proposition 2.17 . . . . . . . . . . . . . . .
A.2.5 Proof of Lemma 2.19 . . . . . . . . . . . . . . . . .
A.2.6 Proof of Theorem 2.20 . . . . . . . . . . . . . . . .
vii

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

429
429
429
434
436
440
440
441
441
444
445
445

A.2.7
A.2.8
A.2.9
A.2.10
A.2.11
A.2.12
A.2.13
A.2.14
A.2.15
A.2.16
A.2.17
A.2.18
A.2.19
A.2.20
A.2.21
A.2.22
A.2.23
A.2.24
A.2.25
A.2.26
A.2.27
A.2.28

Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof

of
of
of
of
of
of
of
of
of
of
of
of
of
of
of
of
of
of
of
of
of
of

Lemma 3.1 . . .
Theorem 3.2 . .
Lemma 3.3 . . .
Theorem 3.4 . .
Lemma 3.6 . . .
Theorem 3.7 . .
Proposition 3.9
Lemma 3.13 . .
Proposition 3.15
Theorem 3.17 .
Proposition 3.19
Theorem 3.21 .
Proposition 3.23
Theorem 58 . .
Corollary 15 . .
Corollary 16 . .
Proposition 3.25
Theorem 4.2 . .
Proposition 4.3
Proposition 81 .
Theorem 6.5 . .
Corollary 6.6 .

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

B Appendix for Chapter 3
B.1 Complexity Proofs (Section 3.3) . . . . . .
B.1.1 Small-Model Lemma for APT-Logic
B.1.2 Proof of Theorem 10 . . . . . . . .
B.1.3 Proof of Theorem 11 . . . . . . . .
B.1.4 Proof of Theorem 12 . . . . . . . .
B.2 Supplementary Information for Section 3.4
B.2.1 Proof of Proposition 3.4.1 . . . . .
B.2.2 Proof of Proposition 14 . . . . . . .
B.2.3 Proof of Theorem 8 . . . . . . . . .
B.2.4 Proof of Theorem 13 . . . . . . . .
B.2.5 Proof of Corollary 2 . . . . . . . .
B.2.6 Proof of Theorem 14 . . . . . . . .
B.2.7 Proof of Proposition 15 . . . . . . .
B.2.8 Proof of Proposition 16 . . . . . . .
B.2.9 Proof of Proposition 17 . . . . . . .
B.2.10 Proof of Proposition 18 . . . . . . .
B.2.11 Proof of Lemma 9 . . . . . . . . . .
B.2.12 Proof of Lemma 10 . . . . . . . . .
B.2.13 Proof of Lemma 11 . . . . . . . . .
B.2.14 Proof of Theorem 15 . . . . . . . .
B.2.15 Proof of Lemma 12 . . . . . . . . .
viii

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

446
447
449
450
451
452
454
454
455
456
456
457
458
459
459
461
463
464
465
466
467
467

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

470
. 470
. 470
. 471
. 472
. 472
. 476
. 476
. 476
. 476
. 477
. 480
. 480
. 482
. 483
. 483
. 484
. 484
. 485
. 486
. 486
. 486

B.2.16 Proof of Theorem 4 . . . . . .
B.2.17 Proof of Proposition 19 . . . .
B.2.18 Proof of Proposition 20 . . . .
B.2.19 Proof of Propositon 21 . . . .
B.2.20 Proof of Proposition 22 . . . .
B.3 Proofs for Section 3.5 . . . . . . . . .
B.3.1 Proof of Lemma 13 . . . . . .
B.3.2 Proof of Theorem 16 . . . . .
B.3.3 Proof of Corollary 5 . . . . .
B.3.4 Proof of Proposition 23 . . . .
B.3.5 Proof of Proposition 24 . . . .
B.3.6 Proof of Lemma 14 . . . . . .
B.3.7 Proof of Lemma 15 . . . . . .
B.3.8 Proof of Theorem 17 . . . . .
B.3.9 Proof of Lemma 16 . . . . . .
B.3.10 Proof of Theorem 18 . . . . .
B.4 Supplemental Information for Section
B.4.1 Proof of Proposition 25 . . . .
B.4.2 Proof of Proposition 26 . . . .
B.4.3 Proof of Proposition 27 . . . .
B.4.4 Proof of Proposition 28 . . . .
C Appendix for Chapter 4
C.1 Proofs . . . . . . . . . . . . .
C.1.1 Proof of Theorem 19 .
C.1.2 Proof of Corollary 6 .
C.1.3 Proof of Corollary 7 .
C.1.4 Proof of Theroem 20 .
C.1.5 Proof of Proposition 29
C.1.6 Proof of Proposition 30
C.1.7 Proof of Theorem 21 .
C.1.8 Proof of Proposition 31
C.1.9 Proof of Proposition 32
C.1.10 Proof of Proposition 33
C.1.11 Proof of Theorem 22 .
C.1.12 Proof of Proposition 34
C.1.13 Proof of Proposition 35
C.1.14 Proof of Proposition 36
C.1.15 Proof of Proposition 37
C.1.16 Proof of Proposition 38
C.1.17 Proof of Proposition 39
C.1.18 Proof of Proposition 40
C.1.19 Proof of Theorem 23 .
C.1.20 Proof of Proposition 41

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

ix

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

. .
. .
. .
. .
. .
. .
. .
. .
. .
. .
. .
. .
. .
. .
. .
. .
3.6
. .
. .
. .
. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

487
487
488
489
489
489
489
490
492
492
492
493
493
493
494
494
497
497
497
498
498

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

499
. 499
. 499
. 502
. 503
. 503
. 505
. 506
. 507
. 508
. 508
. 509
. 509
. 510
. 511
. 512
. 512
. 513
. 513
. 516
. 516
. 518

D Appendix for Chapter 5
D.1 Proofs . . . . . . . . . . . . .
D.1.1 Proof of Lemma 17 . .
D.1.2 Proof of Theorem 24 .
D.1.3 Proof of Theorem 25 .
D.1.4 Proof of Corollary 8 .
D.1.5 Proof of Corollary 9 .
D.1.6 Proof of Theorem 26 .
D.1.7 Proof of Proposition 42
D.1.8 Proof of Proposition 43
D.1.9 Proof of Proposition 44
D.1.10 Proof of Proposition 45
D.1.11 Proof of Proposition 10
D.1.12 Proof of Proposition 46
D.1.13 Proof of Proposition 11
D.1.14 Proof of Proposition 48

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

E Appendix for Chapter 6
E.1 MCA where the Solution is an Explanation
E.2 Proofs . . . . . . . . . . . . . . . . . . . .
E.2.1 Proof of Lemma 19 . . . . . . . . .
E.2.2 Proof of Theorem 27 . . . . . . . .
E.2.3 Proof of Proposition 49 . . . . . . .
E.2.4 Proof of Proposition 50 . . . . . . .
E.2.5 Proof of Proposition 51 . . . . . . .
E.2.6 Proof of Proposition 52 . . . . . . .
E.2.7 Proof of Proposition 53 . . . . . . .
E.2.8 Proof of Theorem 28 . . . . . . . .
E.2.9 Proof of Theorem 29 . . . . . . . .
E.2.10 Proof of Theorem 30 . . . . . . . .
E.2.11 Proof of Proposition 55 . . . . . . .
E.2.12 Proof of Proposition 56 . . . . . . .
E.2.13 Proof of Proposition 54 . . . . . . .
E.2.14 Proof of Proposition 57 . . . . . . .
E.2.15 Proof of Proposition 58 . . . . . . .
E.2.16 Proof of Porposition 59 . . . . . . .
E.2.17 Proof of Theorem 31 . . . . . . . .
E.2.18 Proof of Theorem 32 . . . . . . . .
E.2.19 Proof of Lemma 20 . . . . . . . . .
E.2.20 Proof of Lemma 21 . . . . . . . . .
E.2.21 Proof of Proposition 60 . . . . . . .
E.2.22 Proof of Proposition 61 . . . . . . .
E.2.23 Proof of Theorem 33 . . . . . . . .
E.2.24 Alternate Proof of Theorem 33 . .
E.2.25 Proof of Theorem 34 . . . . . . . .
x

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

519
519
519
520
521
522
523
523
524
524
525
525
528
528
529
529

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

530
. 530
. 534
. 534
. 536
. 536
. 537
. 537
. 538
. 540
. 541
. 543
. 543
. 544
. 544
. 544
. 545
. 546
. 546
. 547
. 548
. 549
. 549
. 550
. 551
. 551
. 553
. 555

E.2.26
E.2.27
E.2.28
E.2.29
E.2.30
E.2.31
E.2.32
E.2.33
E.2.34
E.2.35

Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof
Proof

of
of
of
of
of
of
of
of
of
of

Theorem 35 .
Theoerm 36 .
Proposition 62
Proposition 63
Corollary 12 .
Proposition 64
Corollary 13 .
Theoerem 37
Corollary 18 .
Theorem 60 .

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

556
556
557
557
557
558
558
559
562
562

F Appendix for Chapter 7
F.1 Proofs . . . . . . . . . . . . .
F.1.1 Proof of Theorem 38 .
F.1.2 Proof of Theorem 39 .
F.1.3 Proof of Theorem 40 .
F.1.4 Proof of Theorem 41 .
F.1.5 Proof of Theorem 42 .
F.1.6 Proof of Theorem 43 .
F.1.7 Proof of Theorem 44 .
F.1.8 Proof of Theorem 45 .
F.1.9 Proof of Lemma 22 . .
F.1.10 Proof of Proposition 66

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

565
565
565
567
569
569
570
570
571
573
573
574

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

575
. 575
. 575
. 575
. 576
. 576
. 577
. 582
. 586
. 589
. 589
. 595
. 596
. 598
. 598
. 599
. 600
. 600
. 601
. 603
. 603

G Appendix for Chapter 8
G.1 Proofs for Section 8.3 . . . . .
G.1.1 Proof of Proposition 70
G.1.2 Proof of Proposition 71
G.1.3 Proof of Lemma 23 . .
G.1.4 Proof of Lemma 24 . .
G.1.5 Proof of Theorem 47 .
G.1.6 Proof of Theorem 48 .
G.1.7 Proof of Theorem 49 .
G.1.8 Proof of Theorem 50 .
G.1.9 Proof of Theorem 51 .
G.1.10 Proof of Theorem 52 .
G.1.11 Proof of Theorem 53 .
G.2 Proofs for Section 8.5 . . . . .
G.2.1 Proof of Proposition 72
G.2.2 Proof of Theorem 54 .
G.2.3 Proof of Proposition 73
G.2.4 Proof of Theorem 55 .
G.2.5 Proof of Proposition 74
G.2.6 Proof of Lemma 25 . .
G.2.7 Proof of Lemma 26 . .

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

xi

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

G.2.8
G.2.9
G.2.10
G.2.11
G.2.12
G.2.13
G.2.14
G.2.15
G.2.16

Proof of Proposition 75 . . . . . . . . . . .
Proof of Proposition 76 . . . . . . . . . . .
Proof of Corollary 14 . . . . . . . . . . . .
Proof of Proposition 77 . . . . . . . . . . .
Proof of Theorem 57 . . . . . . . . . . . .
Proof of Proposition 78 . . . . . . . . . . .
Proof of Proposition 79 . . . . . . . . . . .
Algorithm for Finding Disjoint Node Sets .
Proof of Proposition 80 . . . . . . . . . . .

xii

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

604
604
604
605
605
606
606
609
609

List of Tables
2.1
2.2
2.3

Summary of APT Complexity Results . . . . . . . . . . . . . . . . . 20
Comparison of Linear Constraints for APT Consistency Checking . . 25
Comparison of Linear Constraints for APT Entailment Checking . . . 25

3.1

APT-logic programs used in the run time evaluations. Programs K1 −
K13 are based on the ISW data-set. . . . . . . . . . . . . . . . . . . . 144
APT-logic programs used in the run time evaluations. The programs
in this table are based on the MAROB data-set. . . . . . . . . . . . . 145

3.2
4.1
4.2
4.3
4.4
4.5
4.6

key values and related observations for observations in the sun bear
scenario introduced in Example 4.1.3. . . . . . . . . . . . . . . . . .
k-SEP Algorithm Results - Solution Size . . . . . . . . . . . . . . .
k-SEP Algorithm Results - Distances to Actual Cache Sites . . . .
k-SEP Algorithm Performance Results . . . . . . . . . . . . . . . .
The Tie-Breaker heuristic on GREEDY-KSEP-OPT2 - Solution Size .
The Tie-Breaker heuristic on GREEDY-KSEP-OPT2 - Distances to
Actual Cache Sites . . . . . . . . . . . . . . . . . . . . . . . . . . .

.
.
.
.
.

189
194
195
197
199

. 199

5.1

Locations and dimensions of areas considered

. . . . . . . . . . . . . 241

6.1

The set L partitioned by consti and supported observations. . . . . . 285

8.1
8.2
8.3
8.4
8.5
8.6
8.7

Special cases of SNOP queries . . . . . . . . . . . . . . . . . . . . . . 352
Properties that can be proven given certain assumptions . . . . . . . 357
How the various properties are leveraged in the Algorithms . . . . . . 357
Comparison between straightforward and linear Jackson-Yariv Models 372
First iteration of the greedy algorithm. . . . . . . . . . . . . . . . . . 389
Incremental Increases for Both Iterations of GREEDY-SNOP. . . . . . 390
(up)
Calculating inc2 (v5 ). . . . . . . . . . . . . . . . . . . . . . . . . . . 396

C.1 Quantities for the Greedy-Approach in the DomSet reduction. . . . 511

xiii

List of Figures
2.1

2.2

2.3

2.4

2.5
2.6
2.7

Kstock , a toy APT-Logic Program modeling the behavior to reactions
of stock-related news feeds. As all of these rules are constrained, this
is a constrained program. The English translation of each rule is also
provided. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A real-world set of rules extracted by APT-Extract from the Hezbollah dataset. The atoms in the rules are represented as a variable and
its value. A plain English explanation of each rule is also provided.
Ktrain a toy APT-Logic Program modeling rail transit. Items 1-3
are APT-Rules while items 4-5 are annotated formulas. The English
translation of each rule is also provided. . . . . . . . . . . . . . . .
Kpower a toy APT-Logic Program modeling a power grid. Items 1-4
are APT-Rules, while item 5 is an annotated formula. The English
translation of each rule is also provided. . . . . . . . . . . . . . . .
Example thread for the train scenario from Figure 2.3, where only
one train is present. . . . . . . . . . . . . . . . . . . . . . . . . . . .
Example thread, Th with worlds Th(1), . . . , Th(8). This figure shows
each world that satisfies formula F or formula G. . . . . . . . . . .
For a set of atoms consisting of scandal, and tmax of 3 time points, the
above chart shows the pfr for all possible threads based on a program

. 21

. 22

. 23

. 24
. 31
. 33

pfr

consisting only of rule scandal ֒→ ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]
from Figure 2.1. Figure 2.8 groups these threads in frequency equivalence classes based on pfr . . . . . . . . . . . . . . . . . . . . . . . . 60
2.8

2.9

3.1
3.2

pfr

For a program consisting only of rule scandal ֒→ ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]
from Figure 2.1, we have frequency equivalence classes E1 and E2
based on the pfr for all possible threads seen in Figure 2.7. . . . . . . 61
Left: Unrolled MDP in an attempt to create an MDP that satisfies interpretation I in the text. Notice how the sequence h{a}, {}, {a}, {a}i
must be assigned a non-zero probability. Right: A standard representation of the MDP on the left. Notice that the MDP must allow
for non-zero probability of threads that are given a zero probability
in interpretation I. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
Kstock , a toy APT-Logic Program about stocks. . . . . . . . . . . . . . 98
KISW a real-world APT-Logic Program extracted from counterinsurgency data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

xiv

3.3
3.4

3.5

3.6
3.7
4.1

4.2

4.3

4.4

4.5
4.6

5.1

KMAROB a real-world APT-Logic Program extracted from Minorities
at Risk Organizational Behavior data. . . . . . . . . . . . . . . . .
Ktrain , a toy APT-Logic Program modeling rail transit. Items 1-2
are non-ground APT-Rules, the formulas in 3 are probabilistic temporal formulas, and items 4-5 are annotated formulas. The English
translation of each rule is also provided. . . . . . . . . . . . . . . .
Number of ground rules vs. run time (Left: ISW, Right: MAROB).
Note these run-times include the full computation of the fixed point
of the Γ operator. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Number of ground rules vs. run time for entailment checking (Left:
ISW, Right: MAROB). . . . . . . . . . . . . . . . . . . . . . . . . .
Attributes of ptf’s entailed by the different logic programs (ISW
dataset) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

. 100

. 105

. 143
. 146
. 147

A space. Red dots denote observations. Yellow squares denote infeasible locations. Green stars show one (0,3) explanation, while pink
triangles show another (0,3) explanation. . . . . . . . . . . . . . . . . 160
Left: Points {o1 , o2 , o3 } indicate locations of evidence of the Malayan
sun bear (we shall refer to these as set O). Points {p1 , p2 , . . . , p8 } indicate feasible dwellings for the bear. The concentric rings around
each element of O indicate the distance α = 1.7km and β = 3.7km.
Right: Points {p1 , p2 , p3 } are feasible for crime-scenes {o1 , o2 }. {p1 , p2 }
are safe-houses within a distance of [1, 2] km. from crime scene o1 and
{p2 , p3 } are safe-houses within a distance of [1, 2] km. from crime
scene o2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164
Results of KSEP-TO-DOMSET based on data seen in Figure 4.2 (right).
Note that {p1 , p2 , p′1 , p′2 } form a complete graph and {p2 , p3 , p′′2 , p′3 }
also form a complete graph. Note that {p2 } is a dominating set of
size 1. Hence, {p2 } is a 1-sized simple (α, β) explanation for O, as
depicted in Figure 4.2 (right). . . . . . . . . . . . . . . . . . . . . . . 176
Left: GREEDY-KSEP-OPT1 accesses the list pointed to by M [p1 ]
thus considering all observations available to p1 . Right: GREEDYKSEP-OPT1 accesses the list pointed to by M [p2 ] and finds it has
more active observations than it found in the list pointed to by M [p1 ]. 184
GREEDY-KSEP-OPT1 considers the observations available to p7 . The
X’s on o1 and o2 signify that OBS[o1 ] and OBS[o2 ] are set to FALSE. . 185
Left: GREEDY-KESP-OPT2 considers all observations that can be
partnered with p2 . Notice that in this figure by each observation we
show a box that represents the key of the observation in the Fibonacci
heap. Right: GREEDY-KSEP-OPT2 removes o1 from the heap, and
iterates through the elements in REL OBS[o1 ], causing it to decrease
the key of o2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
Locations of illegal drug sales and suspected support zones {ra , rb , rc , rd , re , rf , rg }.
The β distance for each observation is shown with a dashed circle. . . 214
xv

5.2
5.3
5.4

5.5

5.6
5.7
5.8
5.9

5.10
5.11

5.12
5.13
5.14

5.15

5.16
6.1
6.2
6.3

Space S and the regions in set RO . . . . . . . . . . . . . . . . . . . . 218
A set of regions in S created based on the distance β = 5km as well
as restricted areas (shown in black). . . . . . . . . . . . . . . . . . . . 221
Given the instance of I-REP-MCZ for Example 5.4.4 as input for
circle-covering, a circle-covering algorithm returns points p1 , p2 , p3
(points are denoted with an “x”, dashed circles are the area of 3km
from the point). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
REGION-GEN applied to the paleontology example (Example 5.4.4).
First, it identifies observations associated with grid points (top). It
then creates minimally-enclosing rectangles around points that support the same observations (bottom). . . . . . . . . . . . . . . . . . . 236
The run-time of GREEDY-MC2 in ms compared with the number of
regions considered. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
A comparison between analytical (O( g12 )) and experimental results
for the run-time of REGION-GEN compared with grid spacing (g). . . 245
Average areas for solutions provided by REGION-GEN/GREEDY-MC2
for Baghdad and Sadr City. . . . . . . . . . . . . . . . . . . . . . . . 246
Results from two runs of GREEDY-MC2 - g = 100m (top), g = 1000m
(bottom). Pinpoint-regions are denoted with plus-signs. Notice that
the average areas of the results are comparable. . . . . . . . . . . . . 247
Average caches enclosed per region for Baghdad and Sadr City for
various grid-spacing settings. . . . . . . . . . . . . . . . . . . . . . . . 248
The output of GREEDY-MC2 for Baghdad with g = 100m compared
with the locations of actual cache sites (denoted with a “C”). Notice
that regions A-E do not contain any cache sites while regions G-I all
contain numerous cache sites. . . . . . . . . . . . . . . . . . . . . . . 249
Regions in the output that enclose at least one partner (cache) and
total number of regions returned for Baghdad and Sadr City. . . . . . 250
Distance to nearest cache vs. grid spacing. . . . . . . . . . . . . . . . 251
Cache density of outputs produced by GREEDY-MC2 for Baghdad and
Sadr City compared with overall cache density and linear-regression
analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252
Close-up of region F from Figure 5.11. While region F contains 1
cache, there are 4 other caches < 250m from the boundary of that
region. The area-quadrupling metric helps us account for such scenarios.253
Area quadrupled cache density of output produced by GREEDY-MC2
with linear-regression analysis. . . . . . . . . . . . . . . . . . . . . . . 254
Map of poppy fields for Example 6.2.1. For each labeled point pi , the
“p” is omitted for readibility. . . . . . . . . . . . . . . . . . . . . . . . 261
Dashed circles encompass all feasible points within 100 meters from
explanation {p40 , p45 }. . . . . . . . . . . . . . . . . . . . . . . . . . . 265
Set L of all possible partners for our drug laboratory location example.274

xvi

6.4

6.5

6.6

6.7

6.8

6.9

The size of the reduced partner set L∗ (left) and the time required to
compute this reduction (right). Regardless of parameters chosen, we
see a 99.6% decrease in possible partners—as well as integer variables
in our linear program—in under 3 minutes. . . . . . . . . . . . . . . . 302
Expected detriment of the optimal adversarial strategy (left, lower
is better) and the runtime of the integer linear program required
to produce this strategy in milliseconds (right). Note the smooth
decrease toward zero detriment as k increases, corresponding with a
near-linear increase in total runtime. . . . . . . . . . . . . . . . . . . 304
The average size of the strategy recommended by MCA-LS decreases
as the distance cutoff increases. For these experiments, the minimum
cardinality for a given explanation E considered is exfd was 14, which
gives us a natural lower bound on the expected size of a strategy.
Note the convergence to this bound at cutoff distances at and above
300 meters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
The runtime of MCA-LS decreases as the penalizing cutoff distance
is relaxed. Note the relation to Figure 6.6; intuitively, larger recommended strategies tend to take longer to compute. . . . . . . . . . . . 308
Expected benefit of the strategy returned by MCA-GREEDY-MONO
as the budget increases, with |exfd| = 10 (left) and |exfd| = 100
(right). Note the decrease in expected benefit due to the increase in
|exfd|. Similarly, note the increase in expected benefit given a larger
cutoff distance. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
Runtime of MCA-GREEDY-MONO as the budget increases, with |exfd| =
10 (left) and |exfd| = 100 (right). Note the increase in runtime due
to the extra determinism of a larger exfd. . . . . . . . . . . . . . . . . 311

7.1
7.2

Locations in a district - contingency groups and unpopulated areas. . 316
|ICs0 | vs. approximation ratio. . . . . . . . . . . . . . . . . . . . . . . 334

8.1
8.2
8.3

Example cellular network. . . . . . . . . . . . . . . . . . . . . . . . .
Social Network for the painting company. . . . . . . . . . . . . . . . .
Social network corresponding with Example 8.5.1 concerning disease
spread. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Social network of individuals sharing photographs. Shaded vertices
are professional photographers. All edges are directional share edges.
Left: Sample network for disease spread. Right: annotated atoms
entailed after each application of TΠSIR (maximum, non-zero annotations only). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Search tree for Example 8.5.2. . . . . . . . . . . . . . . . . . . . . . .
Effect on overall approximation given an incremental approximation
factor. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Left: spread graph after iteration 1. Right: spread graph after iteration 2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8.4
8.5

8.6
8.7
8.8

xvii

343
356
360
370

375
384
397
403

8.9

Top: Social Network for the painting company with vertex spread
(ǫ)
shown as shaded ovals. Bottom: Spread graph GS1 (REM0 ) for the
painting company example. . . . . . . . . . . . . . . . . . . . . . .
8.10 Runtimes of GREEDY-SNOP for different values of α and k = 5 in
both diffusion models . . . . . . . . . . . . . . . . . . . . . . . . . .
8.11 Runtimes of GREEDY-SNOP for different values of k and α = 0.2 in
both diffusion models . . . . . . . . . . . . . . . . . . . . . . . . . .
8.12 Time per iteration of GREEDY-SNOP for α = 0.2 in both diffusion
models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

xviii

. 407
. 412
. 413
. 413

List of Abbreviations
#P
α
β

Sharp-P
alpha
beta

AI
ALC-ENT
APT Logic
ATS
BMGOP
BMGOP-IP
crf
CoNP
DomSet
efr
exfd
FLOT
FPRAS
FPTAS
fr
frf
GAP

Artificial Intelligence
Entailment using Alternative Linear Constraints
Annotated Probabilistic Temporal
Associated Thread Subset
Benefit-Maximizing Geospatial Optimization Problem
BMGOP Integer Program
Cutoff Reward Function
Complement of Non-deterministic Polynomial Time
Dominating Set
Existential Frequency Function
Explanation Function Distribution
Front Line of Trace
Fully Polynomial Randomized Approximation Scheme
Fully Polynomial Time Approximation Scheme
Frequency Function
Fall-off Reward Function
Geospatial Abduction Problem (spatial chapters)
or Generalized Annotated Program (social network chapters)
GBGOP
Goal-Based Geospatial Optimization Problem
GBGOP-IP GBGOP Integer Program
GCD
Geometric Covering by Discs
GOP
Geospatial Optimization Problem
HSD
Honest Significant Difference
In-#P
Membership in the complexity class #P
In-coNP
Membership in the complexity class coNP
In-NP
Membership in the complexity class NP
IP
Integer Program
IPB
Intelligence Preparation of the Battlefield
I-REP
Induced Region Explanation Problem
I-REP-MCZ I-REP Minimum Cardinality with a lower distance bound of zero
ISW
Institute for the Understanding of War
JY
Jackson-Yariv model
KEDS
Kansas Event Data System
k-SEP
k-sized Spatial Explanation Problem
lfp
Least Fixed-Point
LP
Logic Program or Linear Program (context-dependent)
MAROB
Minorities as Risk Database
MCA
Maximal Counter-Adversary Strategy
MCA-Exp
Maximal Counter-Adversary Strategy - Explaining
MC
Minimal Cardinality
xix

MCA-LS
MDP
ME
MILP
NAI
NP
OAS
PCD
PCTL
pdf
pfr
PITF
PRISM
PTIME
qfr
REP
rf
SAT
SC
SCARE
SEC
SEP
SLC
SLC-ENT
SNOP
SOMA
SPM
st
TD-SEP
tp
wrf
wrt
WT-SEP

Maximal Counter-Adversary Strategy - Local Search
Markov Decision Process
Maximum Explaining
Mixed Integer Linear Program
Named Area of Interest
Non-deterministic Polynomial Time
Optimal Adversarial Strategy
Pre-Condition Disjoint
Probabilistic Computational Tree Logic
Probability Distribution Function
Point Frequency Function
Political Instability Task Force
Probabilistic Symbolic Model Checker
Polynomial Time
Query Frequency Function
Region Explanation Problem
Reward Function
Satisfiability
Set-Cover Problem
Spatio-Cultural Abductive Reasoning Engine
Securities Exchange C omission
Spatial Explanation Problem
Straightforward Linear Constraints
Entailment Using SLC
Social Network Optimization Problem
Stochastic Opponent Modeling Agents
Sequence Probability Measure
Such That
Total Distance Spatial Explanation Problem
Temporal-Probabilistic
Weighted Reward Function
With Respect To
Weighted Spatial Explanation Problem

xx

Chapter 1
Introduction

There are many applications where we wish to reason about spatio-temporal
aspects of an agent’s behavior. This dissertation examines several facets of this type
of reasoning.

1.1

Temporal Reasoning about an Agent’s Actions
Given a model of past agent behavior, we wish to reason about the probabil-

ity that an agent takes a given action at a certain time. Previous work combining
temporal and probabilistic reasoning has made either independence or Markov assumptions. This work introduces Annotated Probabilistic Temporal (APT) logic
which makes neither assumption. Statements in APT logic consist of rules of the
form “Formula G becomes true with a probability [L,U] within T time units after
formula F becomes true” and can be written by experts or extracted automatically

1

from historical data. A set of such statements is referred to as an APT logic program. In Chapter 2, we introduce this framework and explore two key problems:
consistency and entailment. The consistency problem for APT logic mirrors the
consistency problem of probabilistic logic introduced in [131]. The complementary
problem of entailment can be used to determine the probability that an agent performs a given action at a certain time based on an APT program. We study the
computational complexity of these two problems and determine that consistency
is NP-hard while entailment is coNP-hard. Under some natural assumptions, we
are also able to show a matching upper bound on the complexity for both problems (membership in the class NP for consistency and coNP for entailment). We
then introduce several sets of linear constraints for solving this problem exactly.
In Chapter 3, we develop a sound, but incomplete fixpoint operator as a heuristic
for such queries. This operator runs in polynomial time in the size of the APT
logic program. This approach was implemented and tested on 23 different models
automatically generated from several datasets. The operator quickly converged to
produce tight probability bounds for the queries.

1.2

Inferring Geospatial Aspects of an Agents Behavior
Some agent behavior often results in “observations” at geospatial locations

that imply the existence of other, unobserved, locations we wish to find (“part-

2

ners”). In Chapter 4, we formalize this notion with “geospatial abduction problems”
(GAPs). GAPs try to infer a set of partner locations for a set of observations and a
model representing the relationship between observations and partners for a given
agent. We shall refer to a set of partner locations as an “explanation.” Given a
set of observations and a model of the agent, finding an explanation of a certain
size is NP-hard and in-NP under some reasonable assumptions. We provide an
enumeration-based algorithm that can find an explanation of size k - if one exists
- as well as show reductions to several well-known combinatorial problems - specifically set-cover, dominating-set, and integer programming. These reductions allow
us to leverage several known algorithms to find explanations of a cardinality within
a certain factor of the minimum. We then develop a new greedy algorithm that
achieves the same approximation ratio as the classic greedy approach to set-cover
(see [136]) but allows a software designer to use one of a variety of heuristics which
do not affect the guarantee. We implement and experimentally evaluate several of
these heuristics in a software package called SCARE (the Spatio-Cultural Abductive Reasoning Engine). We tested SCARE on counter-insurgency data from Iraq,
attempting to locate enemy weapons caches (partners) based on attacks (observations). On average, SCARE was able to locate weapons caches within 690 meters
of actual sites. We then present a variant of the problem in Chapter 5 where the
agent wishes to abduce regions that contain partner points. This problem is also
NP-hard (NP-complete under some natural assumptions). To address this issue, we
develop and implement a greedy approximation algorithm that finds small regions
which contain partner points - on average containing 4 times as many partners as
3

the overall area.

1.3

Geospatial Abduction under Adversarial Conditions
In Chapter 6, we provide an adversarial extension to GAPs as follows: given

a fixed set of observations, if an adversary has probabilistic knowledge of how an
agent were to find a corresponding set of partners, he would place the partners in
locations that minimize the expected number of partners found by the agent. In a
complementary problem, the agent has probabilistic knowledge of how an adversary
locates his partners and wishes to maximize the expected number partners found.
We note that the manner in which the explanation of the adversary is compared
to that of the agent can differ based on domain. As such, we axiomatically define
a “reward function” and prove results for these two problems with respect to this
generalization. We show that these problems are both NP-hard, and in-NP under
some natural conditions. We also design schemes to find approximate solutions often with theoretical guarantees. With our implementation, we demonstrate that
these algorithms often obtain excellent solutions.

1.4

Optimal Selection of Agent Actions
In Chapter 7, we introduce a class of problems called geospatial optimization

problems (GOPs). Here the agent has a set of actions that modify attributes of
4

a geospatial region and he wishes to select a limited number of such actions (with
respect to some budget) in a manner that either causes some goal to be true (goalbased GOPs) and/or maximizes a benefit function (benefit-maximizing GOPs). Additionally, there are certain combinations of actions that cannot be performed together. We show NP-hardness (membership in NP under reasonable assumptions)
as well as provide limits of approximation for these problems. We then develop sets
of integer constraints that provide an exact solution and provide an approximation
algorithm with a guarantee.
While we look to optimize certain geospatial properties in GOPs, we note that
for some real-world applications, such as some epidemiological phenomena, there
is an underlying diffusion process that also affect geospatial proprieties. Assuming the structure of a social network - a directed graph with weighted and labeled
vertices and edges - we study optimization with respect to such diffusion processes
in Chapter 8 where we introduce social network optimization problems (SNOPs).
We show that many well-known social network diffusion process can be embedded
into generalized annotated programs [86]. These diffusion processes were previously
studied in a variety of different contexts including economics [150][73], epidemiology [5][67], social media [20][167], and business [177]. In a SNOP query, we seek to
find a set of vertices, that if given some initial property, optimize an aggregate with
respect to such a diffusion process. We show this class of problems is also NP-hard
(NP-complete under certain assumptions). We also leverage the results of [46] to
provide a limit of the ability to approximate an optimal solution to such problems.
For a large class of such queries, we then develop an greedy algorithm that provides
5

the best possible approximation guarantee unless P=NP as well as techniques for
scaling it. We implemented this algorithm and evaluated it on a real-world data-set
consisting of a graph of 103,000 edges.

1.5

Applications
The various frameworks for reasoning about an agent’s behavior presented in

this dissertation are sufficiently general to solve difficult problems from a variety of
domains. Our discussion of APT logic in Chapters 2-3 include examples illustrating
how that framework can be used to reason about power-grids, the stock market,
and transportation services. Likewise, we provide examples of geospatial-abduction
and its adversarial extension of Chapters 4-6 applied to counter-drug, naturalist,
criminology, and paleontology domains. Finally, in Chapters 7 and 8 where we look
to optimally select actions for an agent, we provide examples relating to a political
campaign, disease-spread, and cell-phone usage.
In addition to the aforementioned problem domains, we note that much of this
work can be used to improve military intelligence analysis for counter-insurgency
applications. Traditionally, military intelligence practices in the US Army rely on a
process known as “Intelligence Preparation of the Battlefield” [170]. In this process,
an intelligence analyst studies terrain and cultural factors along with the capabilities of an adversary in order to predict the actions of an enemy combatant on
the battlefield. Since the 9/11 attacks, this process has been modified to handle
counter-terrorism and counter-insurgency situations as well [171]. However, unlike

6

traditional military situations, these contemporary environments are often more
complex for a variety of reasons. Consider the following real-world problems:
1. In a counter-insurgency operation, enemy reconnaissance of a target may not
always be indicative of a pending attack on said target (as in a traditional
military conflict). Such activity may be designed to elicit a response from
local security forces (for evaluation) or to lull security forces into a sense of
complacency.
2. There is no “front line” or “FLOT” as in a traditional battlefield. In a conventional conflict, a combatant force conducts logistic operations behind the front
line. By contrast, in a counter-insurgency situation, insurgent forces manage
logistics through systems of caches used to store weapons, ammunition, and
supplies to support their operations.
3. In a traditional military environment, the structure of a combatant is usually
well-defined and hierarchical - this is the standard military structure seen
throughout the militaries of the world. An insurgent force, by contrast, is
often de-centralized and its structure can resemble a social network which can
have a variety of different topologies. Such networks are often very survivable
- even if the leadership is killed or captured.
The above three aspects of a counter-insurgency can all be addressed with the research presented in this dissertation. For instance, APT logic, introduced in Chapters 2-3 can be used to help determine the probability that a given reconnaissance
event implies a pending attack. Using the abductive reasoning of GAPs introduced
7

in Chapter 4, we have created software that has been shown to be useful in locating
enemy weapons cache sites. With SNOPs, introduced in Chapter 8, we show that
annotated programs can be leveraged to find which members of a social network
cause the spread of a certain phenomenon – this can allow an analyst to select
targets whose neutralization will have the greatest impact on the insurgent forces.
Again, we would also like to point out that these three aspects of counter-insurgency
are not the only problems that can be addressed with this research. There are many
other applications of this work – both civilian and military – that will be discussed
throughout this dissertation.

1.6

Summary of Major Contributions

Chapters 2-3
• Introduced the framework of APT logic.
• Identified the complexity class of consistency and entailment problems for APT
logic as NP-complete.
• Introduced three sound and complete algorithms based on linear programming
for solving consistency and entailment problems for APT logic.
• Introduced a sound, but incomplete fixed-point operator for approximately solving
consistency and entailment problems for ground APT programs.
• Introduced a sound, but incomplete algorithms for approximately solving consistency and entailment problems for non-ground APT programs while avoiding a
8

full grounding of the program.
• Implemented the ground fixed-point operator and evaluated it using a real-world
data set.
Chapters 4-6
• Introduced a framework for studying geospatial abduction problems (GAPs ).
• Identified the complexity class of several geospatial abduction problems.
• Developed several exact and approximate approaches to solving GAPs based on
reductions to known combinatorial problems.
• Implemented a software package for solving GAPs called SCARE (Spatio-Cultural
Abductive Reasoning Engine) and evaluated experimentally showing it to be able
to locate weapons cache sites in Baghdad.
• Created a variant of GAPs where we look to abduce regions, proved this problem
to be NP-complete under some natural assumptions.
• Developed and implemented an approximation algorithm to abduce regions.
• Extended GAPs to the case where partner locations are place adversarily based
on probabilistic knowledge of the agent, as well as the complementary problem.
Proved these problems to be NP-complete under natural assumptions.
• Developed approximation algorithms for the adversarial problems - often with
guarantees. Showed viability of such algorithms with an implementation.

9

Chapters 7-8
• Introduced geospatial optimization problems, GOPs, in which the agent attempts
to optimally select a set of actions to cause some goal to occur and/or maximize
some function of the resulting geospatial properties.
• Proved two variants of GOPs to be NP-complete and established theoretical limits
on approximation.
• Developed integer constraints for GOPs as well as an approximation algorithm
with a guarantee.
• Introduced social network optimization problems, SNOPs, where we attempt to
optimize an agents selection of vertices with respect to an aggregate of the result
of some diffusion process.
• Proved SNOPs to be NP-complete, explored the limits of approximation and other
properties of these problems.
• Illustrated how many known diffusion processes can be embedded into SNOPs.
• Developed exact and approximate approaches to solving SNOPs. For a large class
of SNOPs, our approximation algorithm attains the best guarantee unless P=NP.
• Experimentally evaluated our approach to SNOPs on a real-world data-set.

10

1.7

Related Work
We now provide a brief overview of work related to this dissertation. Addition-

ally, in each chapter, we also provide a related work section to give a more in-depth
look at how specific contributions relate to other work.
APT logic, introduced in Chapters 2-3, is a logic-programming framework
for reasoning about time and probability together without making independence
assumptions. Perhaps the most well-known method to reason about time and probability together is the Markov Process [140] - a stochastic process where states are
labeled with atomic propositions with a transition function that, given two states
s1 , s2 , returns the probability that s1 transitions to s2 . A Markov Process assumes
what is known as the “Markov Property” which means that each transition probability only depends on the current state, and no previous state [146]. Hence, the
transition probability from state s1 to s2 is always the same, regardless of which
states preceded s1 . The Markov Property yields independence among transitions.
For example, given function p which returns a transition probability for any two
states, we know that p(s1 , s2 ) is independent of p(s2 , s3 ). Hence, with a Markov
Process starting in state s1 , we can calculate the probability of sequence s1 , s2 , s3
as p(s1 , s2 ) · p(s2 , s3 ). However, in many real-world scenarios, this may not be the
case. With APT logic, we can reason about the probability of events that may
depend on previous or future events - as there are no independence assumptions
among different time points. Further, for a Markov Process where each state has
a unique atomic label, we demonstrate that it is possible to create an equivalent

11

APT program, while proving that the relationship in the opposite direction is not
possible.1
Geospatial abduction, described in Chapters 4-6 uses a model of an agent, as
well as observed geospatial phenomenon, to infer unobserved “partner” locations –
a set of which is termed an explanation. Facility location [161] is a related problem
where an agent searches for a subset of “supply points” in a plane to service a set
of “demand points” in such a manner that optimizes a certain objective function.
Most facility location problems reduce to an instance of convex geometric covering
- i.e. find a small set of convex shapes centered on supply points that cover all
demand points. Geospatial abduction problems, by contrast, reduces to a geometric
problem where the shapes are irregular - i.e. they have non-uniform holes.2 The
irregular shape of the covers in geospatial abduction adds another layer of complexity
not inherent in a facility location problem. We note that this holds true for the
geospatial optimization problems introduced in Chapter 7 as well. To illustrate the
difficulty of non-convex covering, [115] shows that for the simple problem of covering
by uniformly non-convex shapes in just one dimension is NP-complete and does not
admit a fully-polynomial time approximation scheme (FPTAS).
Another problem that resembles geospatial abduction is the k -means clustering
problem [116]. In this problem, sets of points on a plane are grouped into k disjoint
1

We explore these relationships in detail in Chapter 2, Section 2.6.1 on page 79.

2

Note that this still holds true even for the case of region-based geospatial abduction (Chapter 5)

as the covers in such a problem are not the regions, but rather the set of points associated with
the region, based on the agent model.

12

sets such that the mean distance between any two points in a given disjoint set is
minimized. Additionally, there is a constrained variant described in [176]. However,
this work merely groups points together, and does not make any inference with
regard to unobserved phenomenon based on an agent model. For a very simple,
restricted agent model, one can naively apply a clustering algorithm as a heuristic
for a geospatial abduction problem by returning a central point in each cluster as
a partner. However, this heuristic provides no approximation guarantee and in our
tests, was outperformed by the algorithms introduced in this dissertation.
Finally, our work on social network optimization problems (SNOPs) introduced in Chapter 8 seeks to find a set of vertices in a social network that optimize
an aggregate function with respect to a diffusion process. Some simple approaches
to this type of problem use a degree-maximizing or centrality measure to find the
set of vertices. It is important to note that these measures do not consider any type
of diffusion process - therefore cannot normally provide a guarantee with respect to
optimality. For example, the work of [6] describes two diffusions processes and prove
that their optimality criteria is proportional to vertex degree in the first diffusion
process, while inversely proportional to vertex degree in the second. Further, with
these approaches, it is unclear how they apply to graphs with multiple vertex and
edge labels as the ones considered in SNOPs.
The classic work of [81] is perhaps the best-known generalized framework for
finding the most “influential vertices” in a social network given some diffusion process. However, there are some key differences. With SNOPs, the social network
can have weights and labels on the vertices and edges, whereas this is not part of
13

the framework of [81]. Further, [81] does not allow complex aggregate functions
as SNOPs does. Finally, the approximation guarantees of [81] are dependent on
an approximation guarantee associated with their encoding of the diffusion process.
This encoding was shown to be #P-hard in [23] by a reduction from the counting
version of S-T connectivity, which has no known approximation algorithm. SNOPs,
by contrast, determines the result of a diffusion process by the calculation of the
fixed-point operator of [86] - which can be accomplished in polynomial time - which
make our conditions for approximation guarantees reasonable.

14

Chapter 2
Annotated Probabilistic Temporal Logic:
Sound and Complete Algorithms for
Reasoning

Chapters 2-3 investigate reasoning about an agent’s behavior in time. The
main contribution of these chapters is Annotated Probabilistic Temporal (APT)
logic, a logic-based framework for this type of reasoning that does not make independence or Markovian assumptions. In this chapter, we introduce the framework,
present a suite of complexity and algorithmic results for consistency and entailment
problems, and perform a detailed comparison with other frameworks for reasoning
about time and probability together.1
1

This chapter is based on [155] which was completed in cooperation with Gerardo Simari, Austin

Parker, and V.S. Subrahmanian.

15

2.1

Chapter Introduction
There are numerous applications where we need to make statements of the

form “Formula G becomes true with 50 − 60% probability 5 time units after formula
F became true.” We now give four examples of how such statements might be
applied.
Stock Market Prediction There is ample evidence [53] that reports in newspapers and blogs [33] have an impact on stock market prices. For instance, major
investment banks invest a lot of time, effort and money attempting to learn
predictors of future stock prices by analyzing a variety of indicators together
with historical data about the values of these indicators. As we will show later
in Figure 2.1, we may wish to write rules such as “The probability that the
stock of company C will drop by 10% at time (T + 2) is over 70% if at time
T , there is a news report of a rumor of an SEC investigation of the company
and (at time T ) there is a projected earnings increase of 10%.” It is clear that
such rules can be learned from historical data using standard machine learning
algorithms. Financial companies have the means to derive large sets of such
rules and make predictions based on them.
Reasoning about Terror Groups The Laboratory for Computational Cultural
Dynamics at the University of Maryland has extensively dealt with historical
data on over 40 terrorist groups from the Minorities at Risk project [181] and
has published detailed analyses of some of these groups’ behaviors (Hezbollah [118] and Hamas [119]). The SOMA Terror Organization Portal [120]
16

has registered users from over 12 US government agencies and contains thousands of (automatically) extracted rules about the behaviors of these groups.
For such groups, we might want to say: “Hezbollah targets domestic government security institutions/lives with a probability of 87 to 97% within 3 years
(time periods) of years when their major organizational goals were focused
on eliminating ethnic discrimination and when representing their interests to
government officials was a minor part of their strategy.” Figure 2.2 provides
a list of such rules associated with Hezbollah. Clearly, analysts all over the
world engaged in counter-terrorism efforts need to be able to reason with such
rules and make appropriate forecasts; in separate work, we have also done
extensive work on making such forecasts [121, 122].
Reasoning about Trains All of us want to reason about train schedules and plane
schedules. More importantly, railroad companies, airlines, and shipping companies have an even more urgent need to do such reasoning as it directly
impacts their planning process. In such settings, a railroad company may
learn rules of the form “If train 1 is at station A at time T , then it will be
at station B at time (T + 4) with over 85% probability.” Once such rules are
learned from historical data, various types of reasoning need to be performed
in order for the railroad company to make its plans. Figure 2.3 shows a small
toy example of rules associated with trains.
Reasoning about a Power Grid Utility companies need to reason constantly
about power grids. Decisions about which lines and transformers should be
17

repaired next are based not only on the costs of these repairs, but also when
these components are likely to fail, and many other factors. Thus, for example, a power company may derive rules of the form “if the transformer tr and
power line ln are functioning at time T , then there is a probability of over 95%
that they will continue to be functioning at time (T + 3). Figure 2.4 shows a
small toy example of rules associated with power grids.
The examples above illustrate the syntax of an APT-logic program; we will
give the formal details as we develop the technical material in this chapter. While it
is possible for designers to write such programs manually, we expect that machine
learning programs can be used to automatically learn such programs from historical
data using standard machine learning algorithms, as done in previous work on apprograms [83]. Though this is not claimed as a contribution of this dissertation,
in order to show that it is possible to automatically learn APT-programs, we have
developed a simple algorithm called APT-Extract and used it to learn models of
certain behaviors exhibited by several terror groups.
This chapter proceeds as follows. In Section 2.2 we introduce the syntax and
semantics of APT-logic programs, including a quick treatment of our notion of a
frequency function, a structure unique to APT-logic. In Section 2.3 we introduce
several methods to check consistency of APT-logic programs, along with appropriate complexity analysis. We introduce several algorithms for consistency checking:
one that straightforwardly applies the semantics, one that exploits the relationships
between formulas in the heads and bodies of APT-rules, and one that works only on

18

specific sorts of APT-rules but often offers substantial speedup when it is possible.
These techniques can also be applied to the problem of entailment, which is covered
in Section 2.4. In Section 2.5, we explore some applications of APT-logic programs
and finally, we spend a great deal of effort in Section 2.6 distinguishing this work
from other frameworks for reasoning about time and probability together. In particular, we examine the relationship between APT-logic programs and Markov Decision
Processes (MDPs for short) [140], showing that one can create APT-logic programs
“equivalent” to a given MDP and policy, but under natural assumptions, there is no
MDP “equivalent” to certain APT-logic programs. We further address the relationship between APT-logic and a well known logic called Probabilistic Computation
Tree Logic (PCTL for short) [64] and provide examples demonstrating that PCTL
cannot express various things expressible in APT-logic programs.
The entire set of complexity results for APT-logic programs derived in this
chapter is summarized in Table 2.1. Consistency of APT-logic programs is determined by solving certain linear programs. In this chapter, we develop successively
more sophisticated linear programs that try to use different types of “equivalence
classes” to collapse multiple variables in the linear program into one variable; Table 2.2 summarizes the main results related to linear program size reduction for
consistency checking. Table 2.2 also provides an analogous summary related to
reduction of size of the linear program when considering entailment by APT-logic
programs.

19

APT Complexity Results
Problem

Complexity

Reference

Consistency of Single Unconstrained Rule

NP-complete

Thm 2

Consistency of Single Constrained Rule

NP-complete

Thm 3

Consistency of a mixed PCD Program with

Guaranteed

Thm 4

additional restrictions on lower probability bounds

consistent

Entailment of an annotated formula by an program

coNP-hard

Thm 7

Table 2.1: Summary of APT Complexity Results

20

pfr

1. scandal ֒→ ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]
For a given sequence of events, if there is a scandal in the headlines,
this will be followed by there not being a scandal in 1 time unit
with probability [0.89, 0.93].
2. sec rumor

∧

earn incr(10%)

pfr

֒→

stock decr(10%)

:

[2, 0.65, 0.97, 0.7, 1.0]
For a given sequence of events, if there is a rumor of an SEC
investigation and an earnings increase of 10%, then the stock
price will decrease by 10% in exactly 2 time units frequency range
[0.7, 1.0] and probability [0.65, 0.97].
pfr

3. sec rumor ∧ earn incr(10%) ֒→ stock decr(10%) ∧ cfo resigns :
[2, 0.68, 0.95, 0.7, 0.8]
For a given sequence of events, if there is a rumor of an SEC investigation and an earnings increase of 10%, this will be followed by
a stock price decrease of 10% and the CFO resigning in exactly 2
time units with a frequency range [0.7, 0.8] and probability bounds
[0.68, 0.95].

Figure 2.1: Kstock , a toy APT-Logic Program modeling the behavior to reactions of
stock-related news feeds. As all of these rules are constrained, this is a constrained
program. The English translation of each rule is also provided.

21

efr

1. (INTERORGCON = 1) ; (ARMATTACK = 1) : [2, 0.85, 0.95]
Armed attacks are carried out within two years of inter-organizational
conflicts arising, with probability between 0.85 and 0.95.
efr

2. (DIASUP = 0) ∧ (MILITIAFORM = 2) ; (KIDNAP = 1) : [3, 0.68, 0.78]
Kidnappings are carried out within three years when no support from
diaspora is received, and Hezbollah has a standing military wing, with
probability between 0.68 and 0.78.
efr

3. (ORGST2 = 1) ∧ (ORGDOMGOALS = 1) ; (DSECGOV = 1) :
[3, 0.87, 0.97]
Domestic government/state lives and security are targets of terrorism
within three years if Hezbollah represents interests to officials as a minor
strategy, and its major organizational goals are focused on eliminating
discrimination, with probability between 0.87 and 0.97.
4. (ORGST4 = 1) ∧ (INTERORGCON = 1) ∧ (MILITIAFORM = 1)
efr

; (BOMB = 0) : [1, 0.56, 0.66]

Hezbollah does not carry out bombings within the following year if it solicits external support as a minor strategy, there are inter-organizational
conflicts, and its military wing is being created, with probability between
0.56 and 0.66.

Figure 2.2: A real-world set of rules extracted by APT-Extract from the Hezbollah
dataset. The atoms in the rules are represented as a variable and its value. A plain
English explanation of each rule is also provided.

22

efr

1. at station(train1, stnA) ; at station(train1, stnB) : [4, 0.85, 1]
If train 1 is at station A, train 1 will be at station B within 4 time
units with a probability bounded by [0.85, 1.00]
pfr

2. at station(train1, stnB) ; at station(train1, stnC) : [2, 0.75, 0.9]
If train 1 is at station B, train 1 will be at station C in exactly 2
time units with a probability bounded by [0.75, 0.90]
pfr

3. at station(train1, stnA) ; at station(train2, stnB) : [1, 0.95, 1]
If train 1 is at station A, train 2 will be at station B in exactly 1
time units with a probability bounded by [0.95, 1.00]
4. at station(train1, stnA) : [1, 0.5, 0.5]
For a given sequence of events, train 1 will be at station A at time
period 1 with a probability of 0.50.
5. at station(train2, stnA) : [2, 0.48, 0.52]
For a given sequence of events, train 2 will be at station A at time
period 2 with a probability bounded by [0.48, 0.52].

Figure 2.3: Ktrain a toy APT-Logic Program modeling rail transit. Items 1-3 are
APT-Rules while items 4-5 are annotated formulas. The English translation of each
rule is also provided.

23

pfr

1. func(ln) ; ¬func(ln) : [1, 0.05, 0.1]
If the power line is functional, in exactly 1 time unit it will be
non-functional with a probability bounded by [0.05, 0.10]
efr

2. ¬func(ln) ; func(ln) : [2, 0.99, 1]
If the power line is not functional, within 2 time units it will
functional with a probability bounded by [0.99, 1.00]
pfr

3. func(tr) ∧ func(ln) ; ¬(func(tr) ∧ func(ln)) : [1, 0.025, 0.03]
If the transformer is functional and the line is functional, then in
exactly 1 time unit, at least one of them is not functional with a
probability bounded by [0.025, 0.030]
efr

4. ¬(func(tr) ∧ func(ln)) ; func(tr) ∧ func(ln) : [3, 0.95, 1]
If the transformer and/or the line is not functional, then within 3
time units, they both are functional with a probability bounded
by [0.95, 1.00]
5. func(tr) ∧ func(ln) : [1, 0.8, 0.95]
For a given sequence of events, the transformer and the power line
are functional at the first time point with a probability bounded
by [0.80, 0.95].

Figure 2.4: Kpower a toy APT-Logic Program modeling a power grid. Items 1-4 are
APT-Rules, while item 5 is an annotated formula. The English translation of each
rule is also provided.

24

Type of Linear

Number of

Number of

Cost of Identifying Equivalence Classes

Constraints

Constraints

Variables

SLC (Straightforward

2|K| + 1

2|BL |tmax

(equivalence classes not used)

2|K| + 1

22|K|tmax

!

O 22|K|+BL

2|K| + 1

2|K|

!

O 2|BL |tmax · F (tmax ) · |K|

2|K| + 1

2|K|

!

O 22|K|·tmax · tmax · |K| +

Linear Constraints)
WELC (World Equiv.
Linear Constraints)
FELC using BFECA
to identify classes
(Frequency Equiv.
Linear Constraints,
created via brute-force)
FELC using WEFE


!
O 22|K|+BL

to identify classes
(Frequency Equiv.
Linear Constraints,
created via world euqiv.)
FELC w.

2|K| + 1

2|K|

(equivalence classes guaranteed)

PCD restrictions on K
(Pre-Condition Disjoint)

Table 2.2: Comparison of Linear Constraints for APT Consistency Checking

Algorithm

Intuition

Reference

SLC-ENT

Determining both the minimization and maximization

Section 2.4

of a constraint wrt SLC
ALC-ENT

Determining both the minimization and maximization

Appendix A.1.2

of a constraint wrt FELC or WELC

Table 2.3: Comparison of Linear Constraints for APT Entailment Checking

25

2.2

APT-Logic Programs
In this section, we first define the syntax of APT-logic programs, and then

define the formal semantics.

2.2.1

Syntax

We assume the existence of a first order logical language L, with a finite set
Lcons of constant symbols, a finite set Lpred of predicate symbols, and an infinite set
Lvar of variable symbols. Each predicate symbol p ∈ Lpred has an arity (denoted
arity(p)). A (ground) term is any member of Lcons ∪ Lvar (resp. Lcons ); if t1 , . . . , tn
are (ground) terms, and p ∈ Lpred , then p(t1 , . . . , tn ) is a (resp. ground) atom. A
formula is defined recursively as follows.
Definition 1. A (ground) atom is a (ground) formula. If f1 and f2 are (ground)
formulas, then f1 ∧ f2 , f1 ∨ f2 , and ¬f1 are (ground) formulas.
We use BL to denote the Herbrand base (set of all ground atoms) of L. It is
easy to see that BL is finite.
We assume that all applications reason about an arbitrarily large, but fixed
size window of time, and that τ = {1, . . . , tmax } denotes the entire set of time points
we are interested in. tmax can be as large as an application user wants, and the user
may choose his granularity of time according to his needs. For instance, in the stock
market and power grid examples, the unit of time used might be days, and tmax may
be arbitrarily set to (say) 1,095 denoting interest in stock market and power grid
movements for about 3 years. In the case of the train example, however, the unit
26

of time might be seconds, and the application developer might set tmax to 93,600,
reflecting that we are only interested in reasoning about one day at a time, but at a
temporal resolution of one second. In the case of the terrorism application, on the
other hand, our temporal resolution might be one month, and tmax might be 360
reflecting an interest in events over a 30-year time span.
Definition 2 (Annotated Formula). If F is a formula, t ∈ τ is a time point, and
[ℓ, u] is a probability interval, then F : [t, ℓ, u] is an annotated formula.
Intuitively, F : [t, ℓ, u] says F will be true at time t with probability in [ℓ, u].2
Example 2.2.1. Let us reconsider the program Ktrain from Figure 2.3. The annotated formula at station(train1, stnB) : [4, 0.85, 1] says that the probability that train1
will be at station stnB at time point 4 is between 85 and 100%.
Throughout this chapter, we assume the existence of a finite set F of symbols
called frequency function symbols. Each of these symbols will denote a specific
“frequency function” to be defined later when we define our formal APT semantics.
We are now ready to define the syntax of Annotated Probabilistic Temporal (APT
for short) rules and logic programs which will form the main topic of study for this
chapter.
Definition 3 (APT Rule). Let F , G be two formulas, ∆t be a time interval, ℓ, u be
a probability interval, fr ∈ F be a frequency function symbol and α, β ∈ [0, 1].
2

Assumption: Throughout the chapter we assume, for both annotated formulas and APT-

rules, that the numbers ℓ, u can be represented as rationals a/b where a and b are relatively prime
and the length of the binary representations of a and b is fixed.

27

fr

1. F ; G : [∆t, ℓ, u] is called an unconstrained APT rule.
fr

2. F ֒→ G : [∆t, ℓ, u, α, β] is called a constrained APT rule.
An APT logic program is a finite set of APT rules and annotated formulas.
fr

Note that we use the symbol ‘;’ for unconstrained APT rules with frequency
fr

function symbol fr, while the symbol ‘֒→’ is used for constrained rules with frequency function fr. The formal semantics of these rules is quite complex and will
be explained shortly. But informally speaking, both types of rules try to check the
probability that a formula F is true ∆t units before a formula G becomes true.
Figures 2.1, 2.2, 2.3, and 2.4 respectively show the APT-logic programs associated with our stock market, counter-terrorism, trains, and power grid applications.
We now define three types of APT-logic programs.
Definition 4 (Types of APT-Logic Programs).
• An unconstrained APT-Logic Program consists only of unconstrained APT-rules.
• A constrained APT-Logic Program consists only of constrained APT-rules.
• A mixed APT-Logic Program consists both of constrained and unconstrained APTrules.
Consider the APTprograms from the introduction of this chapter, we see that
Kstock is a constrained APT-logic program, Ktrains , Kpower , and Kterror are unconstrained APT-logic programs.3
3

Notably absent from the types of APT-Logic Programs described above are annotated formulas.

28

2.2.2

Semantics of APT-logic programs

In this section, we will provide a formal declarative semantics for APT-logic
programs. As the syntax of these programs is quite complex, we will do this one
step at a time. We start with the well known definition of a world.
Definition 5. A world is any set of ground atoms.
The power set of BL (denoted 2BL ) is the set of all possible worlds. Intuitively,
a world describes a possible state of the (real) world or real world phenomenon being
modeled by an APT-logic program. The following are examples of worlds:
Example 2.2.2. Consider the atoms present in the program Ktrain from Figure 2.3. A few possible worlds are: {at station(train1, stnA), at station(train2, stnB)},
{at station(train1, stnB)}, and {}.
As worlds are just ordinary Herbrand interpretations [106], we use w |= F to
denote the standard definition of satisfaction of a ground formula F by world w as
expressed in [106].
Definition 6 (Satisfaction of a formula by a world). Let f be a ground formula and
w be a world. We say that w satisfies f (denoted w |= f ) iff:
• If f = a for some ground atom a, then a ∈ w.
• If f = ¬f ′ for some ground formula f ′ then w does not satisfy f ′ .
We will show later in Theorem 1 that APT-rules can be used to express annotated formulas and
hence there is no loss of expressive power.

29

• If f = f1 ∧ f2 for formulas f1 and f2 , then w satisfies f1 and w satisfies f .
• If f = f1 ∨ f2 for formulas f1 and f2 , then w satisfies f1 or w satisfies f2 .
We say a formula f is a tautology if for all w ∈ 2BL , w |= f . We say f is a
contradiction if for all w ∈ 2BL , w |= ¬f .
A thread, defined below, is nothing but a standard temporal interpretation [42,
96] in temporal logic.
Definition 7 (Thread). A thread is a mapping Th : {1, . . . , tmax } → 2BL .
Th(i) implicitly says that according to the thread Th, the world at time i will
be Th(i). We will use T to denote the set of all possible threads, and Th ∅ to denote
the “null” thread, i.e., the thread which assigns ∅ to all time points.
Example 2.2.3. Consider the train scenario shown in Figure 2.3 and the worlds
described in Example 2.2.2. Let τ = {0, . . . , 9} represent one-hour time periods in
a day from 9:00am to 6:00pm, i.e., 0 represents 9-10am, 1 represents 10-11am, and
so forth. Figure 2.5 shows a sample thread for this setting, where only one train is
present. According to this thread, the train is at station A at 9 o’clock; at 10 o’clock
the thread has an empty world, since the train is still between stations, reaching
station B at 12. The thread shows how the train moves throughout the rest of the
day.
A thread represents a possible way the domain being modeled (e.g., where the
train is) will evolve over all time points. A temporal probabilistic (tp) interpretation
gives us a probability distribution over all possible threads.
30

Th(1) = {at station(train1, stnA)},

Th(2) = {},

Th(3) = {},

Th(4) = {at station(train1, stnB)},

Th(5) = {},

Th(6) = {at station(train1, stnC)},

Th(7) = {},

Th(8) = {at station(train1, stnB)},

Th(9) = {},

Th(10) = {at station(train1, stnA)}

Figure 2.5: Example thread for the train scenario from Figure 2.3, where only one
train is present.
Definition 8 (Temporal-Probabilistic Interpretation). A temporal-probabilistic (tp)
interpretation I is a probability distribution over the set of all possible threads, i.e.,
P

th∈T

I(th) = 1.

Thus, a tp-interpretation I assigns a probability to each thread. This reflects
the probability that the world will in fact evolve over time in accordance with what
the thread says about the state of the world at various points in time.
Example 2.2.4. Consider once again the setting of Figure 2.3. A very simple example of a tp-interpretation is the probability distribution that assigns probability 1
to the thread from Figure 2.5 and 0 to every other possible thread. Another example
would be a distribution that assigns probability 0.7 to the thread from Figure 2.5
and 0.3 to the thread Th ′ defined as follows: hTh ′ (1) = {at station(train1, stnA)},
Th ′ (2) = {}, Th ′ (3) = {}, Th ′ (4) = {}, Th ′ (5) = {at station(train1, stnB)}, Th ′ (6) =
{at station(train1, stnC)}, Th ′ (7) = {}, Th ′ (8) = {at station(train1, stnB)}, Th ′ (9) =
{}, Th ′ (10) = {at station(train1, stnA)}i; this thread specifies that the train’s trip
from station A to station B takes one time unit longer than specified by the previous
31

thread (Th).
We now define what it means for a tp-interpretation to satisfy an annotated
formula.
Definition 9 (Satisfaction of an Annotated Formula). Let F : [t, ℓ, u] be an annotated formula, and I be a tp-interpretation. We say that I satisfies F : [t, ℓ, u],
written I |= F : [t, ℓ, u], iff ℓ ≤

P

Th∈T ,Th(t)|=F

I(Th) ≤ u.

Thus, to check if I satisfies F : [t, ℓ, u], we merely sum up the probabilities
assigned to those threads Th ∈ T which make F true at time t. If this sum is in
[ℓ, u] then I satisfies F : [t, ℓ, u].

2.2.3

Frequency Functions

When defining the syntax of APT-logic programs, we defined frequency function symbols. Each frequency function symbol denotes a frequency function. The
basic idea behind a frequency function is to represent temporal relationships within
a thread. For instance, we are interested in the frequency with which G will be true
∆t units after F is true. When we study this w.r.t. a specific thread Th, we need
to identify when F was true in thread Th, and whether G really was true ∆t units
after that. For instance, consider the thread shown in Figure 2.6. Here, F is true
at times 1, 3, 6, and 8. G is true at times 2, 4, 5, and 7. F and G should be true
at the times indicated above.
• The probability (within the thread of Figure 2.6) that G follows F in exactly two
units of time is 0.33 if we ignore the occurrence of F at time 8. If, on the other
32

Th(1) Th(2)

F

G

Th(3)

Th(4)

F

G

Th(5) Th(6)
G

F

Th(7)

Th(8)

G

F

Figure 2.6: Example thread, Th with worlds Th(1), . . . , Th(8). This figure shows
each world that satisfies formula F or formula G.
hand, we do count that occurrence of F at time 8 (even though no times beyond
that are possible), then the probability that G follows F in exactly two units of
time is 0.25.
• The probability that G follows F in at most 2 units of time is 100% if we ignore
the occurrence of F at time 8; otherwise it is 0.75.
Each of these intuitions leads to different ways to measure the frequency (within
a thread) with which G follows F . As we will show shortly, many other possibilities exist as well. To the best of our knowledge, no past work on reasoning with
time and uncertainty deals with frequencies within threads; as a consequence, past
works are not able to aggregate frequencies across multiple threads in T or w.r.t.
tp-interpretations. This capability, we will show, is key for the types of applications
described in the Introduction of this chapter.
We see above that there are many different ways to define this frequency from
a given body of historical data. Rather than make a commitment to one particular
way and in order to allow applications and users to select the frequency function
that best meets their application needs, we now define axioms that any frequency

33

function must satisfy. Later, we will define some specific frequency functions.4
Definition 10 (Frequency Function). Let Th be a thread, F and G be formulas,
and ∆t > 0 be an integer. A frequency function fr is one that maps quadruples of
the form (Th, F, G, ∆t) to [0, 1] such that it satisfies the following axioms:
(FF1) If G is a tautology, then fr(Th, F, G, ∆t) = 1.
(FF2) If F is a tautology and G is a contradiction, then fr(Th, F, G, ∆t) = 0.
(FF3) If F is a contradiction, fr(Th, F, G, ∆t) = 1.
(FF4) Under the following conditions, there exist threads Th 1 , Th 2 ∈ T such that
fr(Th 1 , F, G, ∆t) = 0 and fr(Th 2 , F, G, ∆t) = 1:
• F is not a contradiction
• G is not a tautology
• F or ¬G is not a tautology
Axiom FF1 says that if G is a tautology, then fr(Th, F, G, ∆t) must behave like
material implication and assign 1 to the result. Likewise, if F is a tautology and G
is a contradiction, then FF2 says that fr(Th, F, G, ∆t) must behave like implication
and have a value of 0 (A → B is false when A is a tautology and B is a contradiction).
Axiom FF3 requires fr(Th, F, G, ∆t) to be 1 when F is a contradiction, also mirroring
implication. Axiom FF4 ensures that in all cases not covered above, the frequency
4

Note: Throughout this chapter, we will assume that frequency function for a given thread

can be computed in polynomial time (i.e. O(|BL | · tmax )). Additionally, we shall assume that a
frequency function will return number that can be represented as a rational number a/b where a
and b are relatively prime and the length of the binary represenations of a and b is fixed.

34

function will be non-trivial by allowing at least one thread that perfectly satisfies
(probability 1) and perfectly contradicts (probability 0) the conditional. Note that
any function not satisfying Axiom FF4 can be made to do so as long as it returns
distinct values: simply map the lowest value returned to 0 and the highest value
returned to 1. We now give examples of two frequency functions.
Definition 11 (Point Frequency Function). Let Th be a thread, F and G be formulas, and ∆t ≥ 0 be an integer. A Point Frequency Function, denoted pfr(Th, F, G, ∆t),
is defined as:
pfr (Th, F, G, ∆t) =

|{t : Th(t) |= F ∧ Th(t + ∆t) |= G}|
|{t : (t ≤ tmax − ∆t) ∧ Th(t) |= F }|

If there is no t ∈ [0, tmax − ∆t] such that Th(t) |= F then we define pfr to be 1.
The point frequency function expresses a simple concept: it specifies how
frequently G follows F in ∆t time points. Mathematically, this is done by finding
all time points from [1, tmax − ∆t] at which F is true and of all such time points
t, then finding those for which G is true at time t + ∆t. The ratio of the latter
to the former is the value of pfr . The following lemma says that this is a valid
frequency function. Note that the denominator of the point frequency function does
not include times where the thread satisfies F after tmax − ∆t because the “end of
time” of our finite time model comes before ∆t units elapse after F becomes true.
Lemma 1. pfr satisfies Axioms FF1-FF4.
Example 2.2.5 (Point Frequency Function). Consider thread Th from Figure 2.5.
Suppose we want to calculate pfr (Th, at station(train1, stnB), at station(train1, stnC), 2).
35

In English, this is the ratio of time at station(train1, stnB) is followed by
at station(train1, stnC) in two units of time in thread Th.
We can see that at station(train1, stnB) is satisfied by two worlds: Th(4) and Th(8).
We also notice that Th(6) |= at station(train1, stnC) and Th(10) 6|= at station(train1, stnC).
Hence, the pfr is simply 0.5.
Our second type of frequency function, called an existential frequency function,
does not force G to occur exactly ∆t units of time after F is true. It can occur at
or before ∆t units of time elapse after F becomes true.
Definition 12 (Existential Frequency Function). Let Th be a thread, F and G be
formulas, and ∆t ≥ 0 be an integer. An Existential Frequency Function, denoted
efr(Th, F, G, ∆t), is defined as follows:5

efr (Th, F, G, ∆t) =

|{t : (t ≤ tmax

efn(Th, F, G, ∆t, 0, tmax )
− ∆t) ∧ Th(t) |= F }| + efn(Th, F, G, ∆t, tmax − ∆t, tmax )

If the denominator is zero (if there is no t ∈ [0, tmax − ∆t] such that Th(t) |= F
and efn(Th, F, G, ∆t, tmax − ∆t, tmax ) = 0) then we define efr to be 1.
Note that in the denominator of efr , after time tmax − ∆t, we only count
satisfaction of F if it is followed by satisfaction of G within [tmax − ∆t, tmax ].
Lemma 2. efr satisfies Axioms FF1-FF4.
The point frequency function expresses what is desired in situations where
there is a precise temporal relationship between events (i.e., if one drops an object
5

Where ef n(Th, F, G, ∆t, t1 , t2 ) = |{t : (t1 ≤ t ≤ t2 ) and Th(t) |= F and there exists t′ ∈

[t + 1, min(t2 , t + ∆t)] such that Th(t′ ) |= G}|.

36

from a height of 9.8 meters in a vacuum, it will hit the ground in exactly

√

2 seconds).

However, it can be very brittle. Consider mail delivery where one knows a package
will arrive in at most 5 business days 95% of the time. The existential frequency
function efr allows for the implied condition to fall within some specified period of
time rather than after exactly

√

2 seconds as before.

Example 2.2.6 (Existential Frequency Function). Consider thread Th ′ from Example 2.2.4. Suppose we want to calculate
efr (Th ′ , at station(train1, stnB), ¬at station(train1, stnC), 2).
In English, this is the ratio of times that at station(train1, stnB) is followed by
¬at station(train1, stnC) in two units of time in thread Th ′ .
We can see that formula at station(train1, stnB) is satisfied by two worlds: Th ′ (5) and
Th ′ (8). Consider world Th ′ (6), which occurs one time unit after world Th ′ (5). We
can easily see that Th ′ (6) 6|= ¬at station(train1, stnC). However, Th ′ (7), two units
later, does satisfy ¬at station(train1, stnC). As Th ′ (9) also satisfies ¬at station(train1, stnC),
we have a world within two time units after every world that satisfies at station(train1, stnB).
Hence, the efr is 1 in this case.
Properties of pfr : Because of the requirement for F2 to be satisfied after a specific ∆t, pfr has several properties (all formulas F1 , F2 below are assumed to be
satisfiable).
1. pfr (Th, F1 , F2 ∨ F3 , ∆t) ≥ max(pfr (Th, F1 , F2 , ∆t), pfr (Th, F1 , F3 , ∆t)) (valid
for efr as well)
37

2. pfr (Th, F1 , F2 ∧ ¬F3 , ∆t) = pfr (Th, F1 , F2 ∧ F3 , ∆t) − pfr (Th, F1 , F3 , ∆t)
3. pfr (Th, F1 , F2 , ∆t) ≤ pfr (Th, F1 ∧ F3 , F2 , ∆t) ⇒ pfr (Th, F1 ∧ ¬F3 , F2 , ∆t) ≤
pfr (Th, F1 , F2 , ∆t)
4. pfr (Th, F1 , F2 ∧ F3 , ∆t) ≤ min(pfr (Th, F1 , F2 , ∆t), pfr (Th, F1 , F3 , ∆t))
5. If pfr (Th, F1 , F2 , ∆t) = a and pfr (Th, F1 , F3 , ∆t) = b then
pfr (Th, F1 , F2 ∧ F3 , ∆t) ≥ a + b − 1.
Properties of efr : efr satisfies all the properties that pfr has above. In addition,
efr has the property that:
efr (T h, F1 , F2 , ∆t) ≥ efr (T h, F1 , F2 , ∆t − 1)
The following result provides some links between pfr and efr .
Proposition 1. Let Th be a thread, F and G be formulas,
1. Let ∆t1 and ∆t2 be two positive integers. If ∆t1 ≤ ∆t2 , then:
pfr (T h, F, G, ∆t1 ) ≤ efr (T h, F, G, ∆t2 ).
2. Let ∆t be a temporal interval. The following inequality always holds:
efr (T h, F, G, ∆t) ≤

2.2.4

∆t
X

pfr (T h, F, G, i)

i=1

Satisfaction of Rules and Programs

We are now ready to define satisfaction of an Annotated Probabilistic Temporal (APT) rule.
38

Definition 13 (Satisfaction of APT rules). Let r be an APT rule with frequency
function fr and I be a tp-interpretation.
fr

1. For r = F ; G : [∆t, ℓ, u], we say that I satisfies r (denoted I |= r) iff
ℓ≤

X

Th∈T

I(Th) · fr(Th, F, G, ∆t) ≤ u.

fr

2. For r = F ֒→ G : [∆t, ℓ, u, α, β], we say that I satisfies r (denoted I |= r), iff
ℓ≤

X

Th∈T ,
α≤fr(Th,F,G,∆t)≤β

I(Th) ≤ u.
fr

Intuitively, the unconstrained APT rule F ; G : [∆t, ℓ, u] evaluates the probability that F leads to G in ∆t time units as follows: for each thread, it finds the
probability of the thread according to I and then multiplies that by the frequency
(in terms of fraction of times) with which F is followed by G in ∆t time units according to frequency function fr. This product is a little bit like an expected value
computation in statistics where a value (frequency) is multiplied by a probability
(of the thread). It then sums up these products across all threads in much the same
way as an expected value computation.
On the other hand, in the case of constrained rules, the probability is computed
by first finding all threads such that the frequency of F leading to G in ∆t time units
is in the [α, β] interval, and then summing up the probabilities of all such threads.
This probability is the sum of probabilities assigned to threads where the frequency
with which F leads to G in ∆t time units is in [α, β]. To satisfy the constrained
fr

APT rule F ֒→ G : [∆t, ℓ, u, α, β], this probability must be within the probability
interval [ℓ, u].
39

Example 2.2.7. Coming back to the train scenario from Figure 2.3, the following
is an example of an unconstrained rule (r1 ) and a constrained rule (r2 ):
efr

r1 : at station(train1,stnC) ; at station(train1,stnB) : [2, 0.85, 1]
efr

r2 : at station(train1,stnB) ֒→ at station(train1,stnC) : [2, 0.9, 1, 0.5, 1]
Consider the second tp-interpretation from Example 2.2.4, which we will call I. By
analyzing the two threads considered possible by I, it is clear that I |= r1 , since both
threads have the property that after being at station C the train reaches station B
within two time units, and thus the probability of this event is 1. A similar analysis
leads us to confirm that I |= r2 , but we must now verify that the constraints placed by
the rule on the threads hold; these constraints require that at least half of the times
in which the train is at station B, station C be reached within 2 time units. This is
indeed the case, since the train stops twice at station B, once going towards C and
once going towards A on its way back. As before, the sum of probabilities of reaching
the station within 2 time units is 1. Finally, consider the rule:
efr

r3 : at station(train1,stnA) ; at station(train1,stnC) : [2, 0.5, 0.6]
Clearly, I 6|= r3 , since neither of the threads considered possible by the tp-interpretation
satisfy the condition that the train reaches station C within two time units of being
at station A.
The following proposition says that any tp-interpretation that satisfies certain
kinds of constrained or unconstrained APT-logic programs also satisfies a certain
APT rule that can be easily constructed from the APT-rules in the original APTlogic program.
40

Proposition 2. Let I be a temporal interpretation, F and G be formulas, and ∆t
be a temporal interval.
1. If I |=

S∆t n
i=1

fr

o
h
P
i
pfr
efr
∆t
F ; G : [i, ℓi , ui ] then I |= F ; G : ∆t, max(ℓi ), min
u
,
1
.
i=1 i

2. If I |= F ֒→ G : [∆t, ℓp , up , a, b] then ∀aℓ , bℓ , au , bu such that aℓ ≤ a ≤ au
fr

fr

and bℓ ≤ b ≤ bu we have I |= F ֒→ G : [∆t, ℓp , 1, aℓ , bu ] and I |= F ֒→ G :
[∆t, 0, up , au , bℓ ].
Note that in unconstrained APT-rules, the ℓ, u probability bounds account
for the frequency function as well. In the case of constrained APT-rules, the ℓ, u
probability bounds do not account for the frequency function. We now show that
using a special frequency function called a query frequency function, we can use
constrained and unconstrained rules to express annotated formulas.
Definition 14 (Query Frequency Function). Let Th be a thread, F and G be formulas, and ∆t ≥ 0 be an integer. A query frequency function, denoted qfr (Th, F, G, ∆t)
is defined as follows:
1. If G is a tautology then qfr (Th, F, G, ∆t) = 1
2. If F is a tautology and G is a contradiction, then qfr (Th, F, G, ∆t) = 0
3. If F is a contradiction then qfr (Th, F, G, ∆t) = 1
4. If Th(1) |= F and Th(∆t) |= G then qfr (Th, F, G, ∆t) = 1
5. Else, qfr (Th, F, G, ∆t) = 0
The following result shows that qfr is a valid frequency function.
41

Lemma 3. qfr satisfies Axioms FF1-FF4.
qfr allows us to construct constrained and unconstrained rules that are equivalent to arbitrary annotated formulas.
Theorem 1. Let q = Q : [t, ℓ, u] be an annotated formula, and I be an interpretation.
qfr

1. For constrained rule r = TRUE ֒→ Q : [t, ℓ, u, 1, 1], I |= q iff I |= r.
qfr

2. For unconstrained rule r = TRUE ; Q : [t, ℓ, u], I |= q iff I |= r.
The following is an example of how an annotated formula can be expressed as
a rule using qfr .
Example 2.2.8. Consider the train setting from Figure 2.3. One of the annotated formulas given in this example was at station(train1, stnA) : [1, 0.5, 0.5]. By
applying Theorem 1, this formula is equivalent to the constrained rule r1 and the
unconstrained rule r2 :
qfr

r1 : TRUE ֒→ at station(train1, stnA) : [1, 0.5, 0.5, 1, 1]
qfr

r2 : TRUE ; at station(train1, stnA) : [1, 0.5, 0.5]

2.3

Consistency

2.3.1

Complexity of Consistency Checking

We are now ready to study the complexity of the problem of checking consistency of APT-logic programs. We say that an APT-logic program K is consistent iff
42

there is a tp-interpretation I such that I |= K. Before stating complexity results,
we give results that hold for any frequency function and any APT-rule. The first
result follows from axioms FF1-FF4 on frequency functions.
fr

Lemma 4. Consider the APT-Program {r = F ; G : [∆t, ℓ, u]}.
1. If G is a tautology, then {r} is consistent iff u = 1.
2. If F is a tautology and G is a contradiction, then {r} is consistent iff ℓ = 0.
3. If F is a contradiction, then {r} is consistent iff u = 1.
4. If F is not a contradiction, G is not a tautology, and either F is not a tautology
or G is not a contradiction then {r} is consistent.
Using this lemma, we can show that for any unconstrained APT-rule, the
problem of determining if an APT-logic program consisting of just that APT-rule is
consistent using any frequency function is NP-complete.
Theorem 2. Deciding the consistency of an APT-logic program containing a single
unconstrained APT-rule is NP-complete in the size of BL .
The proof of hardness above is by reduction from the SAT problem, while
membership in NP relies on manipulating Lemma 4.
In deciding the consistency of a single constrained rule, we take a slightly different approach. The intuition is that if the lower probability bound is not zero,
we must have a thread whose frequency function value falls within [α, β]. Otherwise, there is no thread available that would ensure a non-zero probability mass
43

as per the definition of satisfaction. The idea of classifying threads in this manner
for constrained rules comes into play later when we present consistency-checking
algorithms in Section 2.3.4.
fr

Lemma 5. Let K = {r = F ֒→ G : [∆t, ℓ, u, α, β]} be a constrained APT-logic
program consisting of a single rule. K is consistent iff at least one of the following
conditions hold.
• u = 1 and there exists a thread Th in such that α ≤ fr(Th in , F, G, ∆t) ≤ β.
• ℓ = 0 and there exists a thread Th out such that either α > fr(Th out , F, G, ∆t) or
β < fr(Th out , F, G, ∆t).
• There exists a thread Th in such that α ≤ fr(Th in , F, G, ∆t) ≤ β and a thread
Th out such that either α > fr(Th out , F, G, ∆t) or β < fr(Th out , F, G, ∆t).
Lemma 5, used in conjunction with the frequency function axioms, allow us to
prove that deciding the consistency of a single constrained rule is also NP-complete.
Theorem 3. Deciding the consistency of an APT-logic program containing a single
constrained APT-rule is NP-complete in the size of BL .
The NP-hardness of consistency checking for APT programs (whether constrained, unconstrained, or mixed) with more than one rule follows trivially from
Theorems 2 and 3. In the next chapter, we show that the consistency-checking
problem is in the complexity class NP for general APTprograms (under some natural assumptions).

44

However, if we assume that certain conditions hold, we can show that consistency for an APT-logic program containing multiple APT-rules can be guaranteed.
These restrictions are termed Pre-Condition Disjoint, or PCD; intuitively, they refer
to an APT-Program such that there exists a unique world that satisfies exactly one
of the rule pre-conditions (the F formulas). Hence, we say that the pre-conditions
are “disjoint” from each other. Perhaps such conditions could be specified by a a
tool used to learn the rules from the data-set.
Definition 15 (Pre-Condition Disjoint (PCD) APT-Logic Program). Let K be an
fr

APT-Logic Program such that K = {r1 , . . . , rn }, where ri = Fi ; Gi : [∆ti , ℓi , ui ]
fr

or ri = Fi ֒→ Gi : [∆ti , ℓi , ui , αi , βi ]. K is Pre-Condition Disjoint (PCD) if the
following conditions hold true.
1. ∀i, if ri is constrained, then βi = 1.
2. ∀i, ∆ti ≥ 1.
3. ∀i there exists a world wi such that wi |= Fi and ∀j where j 6= i, wi 6|= Fj .
4. ∀i, fri is equal to either pfr , or efr .
5. tmax ≥ |K| · max(∆ti ) (where tmax is the length of each thread).
6. ∃ world w∅ such that ∀i w∅ 6|= Fi and w∅ 6|= Gi .
7. ∀ri ∈ K, ui = 1.
While somewhat limiting, this restriction still allows APT-Logic Programs that
are useful. Consider the following example.
45

Example 2.3.1. Consider the set of rules shown in Figure 2.3. These rules do not
constitute a PCD program for various reasons. For instance, the upper bound on the
probability of the second rule is not 1. Likewise, condition 3 is not satisfied since the
first and third rule have the same antecedent. However, the following set of rules
satisfies all of the conditions for being a PCD program:
efr

at stn(trn1, stnA) ∧ ¬at stn(trn1, stnB) ∧ ¬at stn(trn1, stnC) ;
at stn(trn1, stnB) : [4, 0.85, 1]
pfr

at stn(trn1, stnB) ∧ ¬at stn(trn1, stnA) ∧ ¬at stn(trn1, stnC) ;
at stn(trn1, stnC) : [2, 0.75, 1]
efr

at stn(trn1, stnC) ∧ ¬at stn(trn1, stnA) ∧ ¬at stn(trn1, stnB) ;
at stn(trn1, stnB) : [3, 0.9, 1]
Conditions 1, 2, 4, and 7 are trivially satisfied, and tmax can be easily chosen to
satisfy condition 5. Condition 3 can be seen to hold by noting that no two antecedents
of rules can be satisfied at once. Finally, condition 6 holds since the empty world
does not satisfy any of the formulas involved in the rules.
The useful feature in a PCD program is that (based on the axioms) we are
guaranteed threads with certain frequency function values for each rule. Consider
Lemma 6 below, where for any subset of a given APT-program, we are guaranteed
the existence of a thread whose frequency is 1 according to the rules in the subset
and is 0 according to the other rules.
fri

Lemma 6. Consider APT-Program K = {r1 , . . . , ri , . . . , rn } where ri = Fi ֒→
fri

Gi [∆ti , ℓi , ui , αi , βi ] or ri = Fi ; Gi : [∆ti , ℓi , ui ], depending on whether ri is
46

a constrained or unconstrained rule. If K is PCD, then for any disjoint partition of rules, K1 , K2 , there exists a thread Th such that for all rules ri ∈ K1 ,
fri (Th, Fi , Gi , ∆ti ) = 1 and for all rules ri ∈ K2 , fri (Th, Fi , Gi , ∆ti ) = 0.
The PCD conditions add a “one-tailed” requirement (the first requirement of
Definition 15) to the constrained rules so that β is always one. This allows us to
be guaranteed the existence of threads in the [α, β] bounds. As it turns out, if the
lower bounds on the probabilities are less than a certain amount, we can create an
interpretation to guarantee the consistency of the PCD program.
Theorem 4. For a mixed PCD APT-Program K = {r1 , . . . , ri , . . . , rn }, if for all ri ,
ℓi ≤

|K| − 1
then K is consistent.
|K|
In the appendix, we show how PCD assumptions can be leveraged for a sig-

nificant reduction in complexity for constrained APT-programs.

2.3.2

Linear Constraints for Consistency Checking

A straightforward algorithm to find a satisfying interpretation given an APTlogic program K is a brute-force approach that considers each thread. Given k atoms
and tmax timepoints, there are 2k possible worlds at each timepoint, and 2k·tmax
possible threads. For ease of notation, we shall refer to the number of threads as n.
Hence, note that a function that is linear in the number of threads is exponential in
the number of atoms.
Let T = {Th 1 , . . . , Th i , . . . , Th n } be the set of threads. In our linear program,
we will use the variables V = {v1 , . . . , vj , . . . , vn }. Each vi represents the (as yet
47

unknown) probability of thread Th i . We will design the linear program so that solutions of the linear program are in a one to one correspondence with interpretations
that satisfy the APT-logic program. Thus, if θ is a solution of the linear program,
we want to be sure that the tp-interpretation Iθ such that Iθ (Th i ) = θ(vi ) is an
interpretation that satisfies K.
Hence, given an APT-logic program K, we will construct a set of “straightforward” linear constraints SLC(K) over variables V = {v1 , . . . , vj , . . . , vn }, such that
the interpretation Iθ associated as above with any solution θ satisfies K. The set of
constraints are as follows:
Definition 16 (Straightforward Linear Constraints (SLC)). Let K be an APT-logic
program; the set of straightforward linear constraints contains exactly the following:
1.

Pn

j=1

vj = 1
fr

2. For each unconstrained rule Fi ;i Gi : [∆ti , ℓi , ui ] ∈ K
(a) ℓi ≤
(b) ui ≥

Pn

j=1

Pn

j=1

fri (Th j , Fi , Gi , ∆ti ) · vj
fri (Th j , Fi , Gi , ∆ti ) · vj
fri

3. For each constrained rule Fi ֒→ Gi : [∆ti , ℓi , ui , αi , βi ] ∈ K
(a) ℓi ≤
(b) ui ≥

P

Th j ∈T α ≤fr (Th ,F ,G ,∆t )≤β
i
i
j i
i
i
i

P

Th j ∈T α ≤fr (Th ,F ,G ,∆t )≤β
i
i
j i
i
i
i

We refer to this set as SLC(K).

48

vj
vj

The first constraint above says that the threads are exhaustive. The second
constraint is derived from the formula for satisfaction of an unconstrained rule, while
the third constraint is derived from the formula for satisfaction of a constrained rule.
Note that the coefficient of vj in constraints (2) and (3) above are both constants
(after the calculations are performed), so these constraints are all linear.
Example 2.3.2. Recall the program Kpower from Figure 2.4. In this simple example,
we supposed the power plant delivers power to a transformer (named tr), which is in
turn connected via a power line (named ln) to a home. Hence, the atoms func(tr) and
func(ln) denote that the various components are functioning, and the home receives
power only if both tr and ln are func. Therefore, we have four possible worlds:
w0 = {func(tr), func(ln)}, w1 = {func(tr)}, w2 = {func(ln)}, and w3 = ∅. If we set
the time limit to 4 days, then there are 44 = 256 possible threads (each world may
occur at each time point). We name these threads Th 0 , ..., Th 255 so that the world
at time point t of thread Th i is ((i/4t ) mod 4) (i.e. Th 25 is hw1 , w2 , w1 , w0 i) and
associate the variable vi with I(Th i ). We now show the constraints in SLC(Kpower ):
1.

Pi<256
i=0

vi = 1

2. 0.025 ≤

Pi<256
i=0

pfr (Th i , func(tr) ∧ func(ln), ¬(func(tr) ∧ func(ln)), 1) · vi ≤ 0.03

3. 0.95 ≤

Pi<256

efr (Th i , ¬(func(tr) ∧ func(ln)), func(tr) ∧ func(ln), 3) · vi ≤ 1

4. 0.05 ≤

Pi<256

pfr (Th i , func(ln), ¬func(ln), 1) · vi ≤ 0.1

5. 0.99 ≤

Pi<256

efr (Th i , ¬func(ln), func(ln), 2) · vi ≤ 1

i=0

i=0

i=0

Given a solution θ of these constraints, we can see immediately that Iθ satisfies K.

49

Algorithm 1 Compute consistency of K using SLC.
SLC-CONSISTENT(APT-Program K)
1. Construct SLC(K).
2. Attempt to solve SLC(K).
3. If solvable, return consistent, otherwise, inconsistent.

We provide the following proposition about correctness of the above procedure
for mixed programs.
Proposition 3. For mixed APT-Logic Program K, K is consistent iff SLC(K) has
a solution.
The size of the linear program for SLC follows immediately from the definition.
As each rule requires two linear constraints, and one linear constraint is required to
ensure the variables sum to 1, we have 2|K| + 1 constraints. The number of variables
is equal to the number of threads.
Remark 1. SLC contains 2|K| + 1 constraints and 2|BL |·tmax variables.
Using SLC we can create Algorithm 1, which is guaranteed to give a correct
answer to the question of consistency for any APT-Logic Program. However, the
linear program’s size is exponential in terms of |BL |·tmax , making it a very expensive
operation in many situations. There are several obvious ways to reduce this cost.
One such way would be to consider the set of atoms to be only the atoms present
in the rules. An obvious method to reduce the other factor in the exponent, tmax ,
would be to adjust the granularity of time used. For example, convert all time to
50

hours instead of minutes. However, this would only provide a correct result in terms
of the new granularity. This is an issue we intend to explore in future research.
It turns out that for arbitrary sets of rules and annotated formulas, one need
not use one variable for each of the 2|BL |·tmax threads. Some threads are equivalent,
and may in fact be considered together. We provide two such methods that consider
equivalent threads. One that reduces the number of worlds based on world equivalence and one that reduces the number of threads based on frequency equivalence.

2.3.3

World Equivalence

World equivalence uses the following intuition: when two worlds satisfy exactly the same formulas from the APT-program, they are identical from the APTprogram’s point of view. By partitioning the set of worlds into classes of identical
worlds, and working with the classes instead of the individual worlds, we can create
smaller linear programs by associating just one variable with each equivalence class
(rather than one variable with each world as is the case of SLC).
fr

Consider the rule F ֒→ G : [∆t, ℓ, u, α, β]. The four world-based equivalence
classes resulting from this rule would be the sets of worlds that satisfy F ∧G, F ∧¬G,
¬F ∧ G, and ¬F ∧ ¬G. We apply this concept to APT-Logic Programs and divide
the set of worlds accordingly. We can treat these resulting equivalence classes as
worlds and create world-based thread equivalence classes, and use them instead of
threads. This reduces the number of linear constraints for an algorithm similar to
SLC. One must note, however, that the equivalence classes must be computed first,

51

which we will show to be NP-complete.
As world equivalence for APT-Logic is based on the formulas found in APTRules and annotated formulas, we will formalize the set of formulas associated with
a program. We introduce the notation formula(K) to denote the set of all formulas
present in an APT-logic program:
fr

formula(K) = {F, G | F ֒→ G : [∆t, ℓ, u, α, β] ∈ K} ∪
fr

{F, G | F ; G : [∆t, ℓ, u] ∈ K}
Example 2.3.3. Recall the program Kpower from Figure 2.4. The set formula(Kpower )
is then
{func(ln), ¬func(ln), func(tr) ∧ func(ln), ¬(func(tr) ∧ func(ln))},
since these are the only formula appearing in Kpower .
The cardinality of formula(K) for a given APT-Logic Program is bounded by
2|K| since APT-Rules have two formulas, F and G. We notice that for each world
w in 2BL there is a subset of formula(K) that w satisfies and a disjoint subset of
formula(K) that w does not satisfy. Hence, with respect to a given set of formulas,
certain worlds are indistinguishable: that is, they satisfy exactly the same formulas
from the set. We call such worlds K-equivalent.
Definition 17 (World Equivalence). For APT-logic program K, a world w is Kequivalent to a world w′ (denoted w ≡K w′ ) iff for all F ∈ formula(K), w |= F iff
w′ |= F .

52

Example 2.3.4. Continuing with Kpower from Figure 2.4, recall the 4 worlds: w0 =
{func(tr), func(ln)}, w1 = {func(tr)}, w2 = {func(ln)}, and w3 = ∅ and the formula
from Kpower :
formula(Kpower ) = {func(ln), ¬func(ln), func(tr) ∧ func(ln), ¬(func(tr) ∧ func(ln))}.

Here w1 is Kpower -equivalent to w3 , since both w1 and w3 do not satisfy the first
formula, do satisfy the second formula, do not satisfy the third formula, and do
satisfy the fourth formula. However, w1 is not Kpower -equivalent to w2 since w1
satisfies ¬func(ln) (the second formula), while w2 does not.
The relation ≡K can be extended to threads in the obvious way.
Definition 18 (Thread Equivalence). For APT-logic program K, a thread Th 1 is
K-equivalent to a thread Th 2 (denoted Th 1 ≡K Th 2 ) iff for all time points t, the
world Th 1 (t) is K-equivalent to world Th 2 (t).
Example 2.3.5. In Example 2.3.4, we saw that w1 is Kpower -equivalent to w3 . Assuming four time points, then the thread Th = hw3 , w1 , w1 , w0 i will be equivalent
to Th ′ = hw1 , w3 , w3 , w0 i, since at every time point t, Th(t) is a world that is Kequivalent to world Th ′ (t).
The relation ≡K is an equivalence relation (i.e., it is transitive, reflexive, and
symmetric) both for threads and for worlds; therefore, it can be used to construct a
partitioning of threads into equivalence classes. Let T [≡K ] = {P1 , · · · , Pm } be that
partitioning. All threads in each Pi are K-equivalent. The following result states
that these partitions have the useful property that all threads in any partition Pi
have the same value for pfr , efr , or qfr for formulas in formula(K):
53

Lemma 7. For APT-logic program K, partitioning P1 , . . . , Pm of T induced by ≡K ,
for all threads Th, Th ′ ∈ Pi , all F, G ∈ formula(K), and all ∆t;
1. pfr (Th, F, G, ∆t) = pfr (Th ′ , F, G, ∆t)
2. efr (Th, F, G, ∆t) = efr (Th ′ , F, G, ∆t)
3. qfr (Th, F, G, ∆t) = qfr (Th ′ , F, G, ∆t)
Lemma 7 tells us that each partition Pi has a unique value for pfr , efr ,
and qfr (for each F , G, and ∆t). We introduce the notation pfr (Pi , F, G, ∆t),
efr (Pi , F, G, ∆t), and qfr (Pi , F, G, ∆t) to denote these values. For technical reasons,
we associate a label with each thread Th such that all threads in the same partition
Pi have the same label. To define the label, we first order the set formula(K) =
{F1 , · · · , Fn }. Then, for a thread Th, we assign label (Th) to be a length tmax · n
bitstring where bit t′ · i (1 ≤ t′ ≤ tmax and 1 ≤ i ≤ n) is 1 if Th(t′ ) |= Fi and 0 if
Th(t′ ) 6|= Fi .
Clearly, all Th, Th ′ in the same partition Pi have the same label. Also, all
partitions Pi have a unique label equivalent to the labels of the contained threads
and denoted label (Pi ). There are at most as many partitions as there are length
tmax · n bitstrings, and determining if there is a partition associated with a given
bitstring b can be done by checking if there is thread whose label is b.
Example 2.3.6. Using Kpower from Figure 2.4, we number formula(Kpower ) as follows:
{F1 = func(ln), F2 = ¬func(ln), F3 = func(tr) ∧ func(ln), F4 = ¬(func(tr) ∧ func(ln))}.

54

Here, the label for Th = hw3 , w1 , w1 , w0 i (worlds wi defined in Example 2.3.4) is
0101
|{z} 0101
|{z} 0101
|{z} 1010
|{z} .
w3

w1

w1

w0

To see this, consider the first four digits 0101 for world w3 . World w3 does not
satisfy F1 , hence the first 0. It does, however, satisfy F2 and F4 causing the second
and fourth digits to be 1.
The thread Th ′ = hw1 , w3 , w1 , w0 i has the same label: 0101010101011010; any
two threads which are Kpower -equivalent will have the same labels.
We immediately notice that the number of thread partitions is potentially
smaller than the number of threads. While there are 2BL ·tmax threads, there are
only 2|formula(K)|·tmax ≤ 22|K|·tmax partitions. Therefore, using these partitions, rather
than threads, is preferable in designing linear constraints. We can use Lemma 7
to construct smaller sets of linear constraints than SLC. For these constraints,
we introduce the variable v̂lbl , where lbl is a length tmax · |formula(K)| bitstring
(lbl ∈ {0, 1}|formula(K)|tmax ) representing the probability mass assigned to the set of
threads in the partition labeled lbl (v̂lbl =

P

Th∈Pi ,label(Pi )=lbl

I(Th)). We can now

define the world-equivalence linear constraints.
Definition 19 (World Equivalence Linear Constraints (WELC)). Let K be an APTlogic program that uses only the frequency functions pfr and efr ; the set of World
Equivalence Linear Constraints, WELC(K), contains exactly the following:
1.

P

i

v̂i = 1.
fr

2. For F ֒→ G : [∆t, ℓ, u, α, β]
55

(a)
(b)

P

P

lbl∈{l|α≤f r(Pi ,F,G,∆t)≤β∧l=label(Pi )}

v̂lbl ≥ ℓ

lbl∈{l|α≤f r(Pi ,F,G,∆t)≤β∧l=label(Pi )}

v̂lbl ≤ u

fr

3. For F ; G : [∆t, ℓ, u]
(a)
(b)

P

P

Pi

f r(Pi , F, G, ∆t)v̂label(Pi ) ≥ ℓ

Pi

f r(Pi , F, G, ∆t)v̂label(Pi ) ≤ u

4. For all lbl ∈ {0, 1}|formula(K)|·tmax for which there is no Pi such that lbl =
label (Pi ), v̂lbl = 0.
Example 2.3.7. WELC(Kpower ) (based on program Kpower from Figure 2.4) is constructed using variables v̂lbl for each of the 24·4 = 65, 536 possible labels. Due to
constraint 4, at most 256 of these variables will be non-zero, since there are 256
worlds to populate these 65, 536 possible equivalence classes. We will therefore be
able to eliminate all but at most 256 of the variables from the representation altogether, since they will be known to be zero in every possible solution. As such,
we only need to use the variables not eliminated via constraint 4 when constructing
WELC(Kpower ), and we will do so in this example. The only labels that will have
associated threads are those that are combinations of the labels for the worlds w0 ,
w1 , w2 , and w3 (defined in Example 2.3.2). With formula(Kpower ) being:
{F1 = func(ln), F2 = ¬func(ln), F3 = func(tr) ∧ func(ln), F4 = ¬(func(tr) ∧ func(ln))}
these labels are lbl(w0 ) = 1010, lbl(w1 ) = 0101, lbl(w2 ) = 1001 and lbl(w3 ) = 0101.
So, for any label lbl, each four digit sequence must be 1010, 0101, or 1001. Otherwise
there cannot possibly be a thread Th such that label (Th) = lbl. In fact, since there
56

are only 3 labels for the worlds (w1 and w2 , being Kpower -equivalent, share a label),
we know that when there are four time points, there are only 34 = 81 variables that
can be non-zero in our linear program (one label at each time point). So, leaving out
the zeroing constraints and supposing each sum

P

lbl

sums over those 81 variables

not known to be zero via the zeroing constraints, the set of linear constraints is:
WELC(Kpower ) =
1.

P

lbl v̂lbl

2. 0.025 ≤

=1
P

3. 0.95 ≤

P

4. 0.05 ≤

P

5. 0.99 ≤

P

lbl

pfr (Th i , func(tr) ∧ func(ln), ¬(func(tr) ∧ func(ln)), 1) · v̂lbl ≤ 0.03

lbl

efr (Th i , ¬(func(tr) ∧ func(ln)), func(tr) ∧ func(ln), 3) · v̂lbl ≤ 1

lbl

pfr (Th i , func(ln), ¬func(ln), 1) · v̂lbl ≤ 0.1

lbl

efr (Th i , ¬func(ln), func(ln), 2) · v̂lbl ≤ 1

Note that this set of linear constraints is substantially smaller than SLC(Kpower ),
which used 256 variables where WELC(Kpower ) uses only 81 variables and exactly the
same number of constraints (after removal of trivial zeroing constraints).
Proposition 4. For any APT-program K, WELC(K) is solvable iff K is consistent.
This approach can provide a substantial speedup. As we noted earlier, the
number of partitions is bounded by 22|K|·tmax which will often be much smaller than
the number of threads, 2|BL |·tmax . Further, the number of partitions is bound by the
number of threads, regardless of the size of K.
Proposition 5. WELC requires 2|K| + 1 constraints and at most 22|K|tmax variables.

57

Algorithm 2 Compute consistency of K using WELC.
WELC-CONSISTENT(APT-Program K)
1. Construct WELC(K).
2. Attempt to solve WELC(K).
3. If solvable, return consistent, otherwise, inconsistent.

This suggests Algorithm 2 for checking consistency of K. The complexity of Algorithm 2 comes from both creating and solving WELC. Proposition 5 gives the number of constraints required of a linear program to implement WELC-CONSISTENT.
Building WELC is also difficult: we have constraint 4, which requires the inclusion
of the constraint v̂lbl = 0 if there is no non-empty partition in T [≡K ] with label lbl.
Unfortunately, this is an NP-complete operation.
Theorem 5. For APT-Logic Program, K, and label lbl, determining if there is nonempty Pi ∈ T [≡K ] such that label (Pi ) = lbl is NP-complete.
To properly construct WELC, we must solve SAT for every subset of formula(K).
As formula(K) ≤ 2|K|, this amounts to O(22|K| ) calls to a SAT solver. Assuming O(2|BL | ) operations per SAT solution procedure, this operation will take time
O(22|K|+|BL | ). However, as for most linear program implementations, the running
time for WELC-CONSISTENT will be exponential in terms of 7|K|tmax [79], the generation of world equivalence classes will be dominated by WELC itself. Therefore,
in most cases, Algorithm 2 will have a better big-O run time than solving the set of
straightforward linear constraints.
58

2.3.4

Frequency Equivalence

For constrained rules it is possible to develop a different set of linear constraints. Rather than considering equivalent worlds, we develop a partition of the
set of threads based on the value of the frequency function with respect to each rule
in the program. We will then create a new set of linear constraints based on this
equivalence, as with WELC, in order to improve performance.
Therefore, the partitions will depend on the thread’s relationship to the probability interval [α, β], which we shall refer to as the frequency bounds for a given
rule. Due to the requirement of considering the frequency bounds, this type of
thread equivalence will be referred to as frequency equivalence and apply only to
constrained rules, though there are manipulations one can apply to include annotated formulas; we first define an equivalence relation over threads.
Definition 20 (Frequency Equivalence). For threads Th 1 and Th 2 , and constrained
fr

rule r = F ֒→ G : [∆t, ℓ, u, α, β], we say Th 1 is r-frequency-equivalent to Th 2
(denoted Th 1 ∼r Th 2 ) iff (α ≤ fr(Th 1 , F, G, ∆t) ≤ β ⇔ α ≤ fr(Th 2 , F, G, ∆t) ≤ β).
For APT-Logic Program K containing only constrained conditionals, we say Th 1
is K-frequency-equivalent to Th 2 (denoted Th 1 ∼K Th 2 ) iff for all rules r ∈ K,
Th 1 ∼r Th 2 .
pfr

Example 2.3.8. Consider rule scandal ֒→ ¬scandal : [1, 0.89, 0.93, 0.8, 1.0] from
Figure 2.1, where we used APT-Rules to represent the behavior of stock price based
on news reports. Let Kfr-ex be an APT-program containing exactly this rule. We will
consider the set of atoms to consist only of scandal and tmax to be 3. In Figure 2.7
59

Thread

pfr (Th, scandal,
¬scandal, 1)

hscandal, scandal, scandali

0

hscandal, scandal, ¬scandali

1/2

hscandal, ¬scandal, scandali

1

hscandal, ¬scandal, ¬scandali

1

h¬scandal, scandal, scandali

0

h¬scandal, scandal, ¬scandali

1

h¬scandal, ¬scandal, scandali

1

h¬scandal, ¬scandal, ¬scandali

1

Figure 2.7: For a set of atoms consisting of scandal, and tmax of 3 time points, the
above chart shows the pfr for all possible threads based on a program consisting
pfr

only of rule scandal ֒→ ¬scandal : [1, 0.89, 0.93, 0.8, 1.0] from Figure 2.1. Figure 2.8
groups these threads in frequency equivalence classes based on pfr .

60

pfr

Kfr-ex = {scandal ֒→ ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]}
T [∼Kfr-ex ] =

Figure 2.8:













hscandal, ¬scandal, scandali,
























hscandal,
¬scandal,
¬scandali,
















E
=
,
1


 h¬scandal, scandal, ¬scandali, 



















h¬scandal,
¬scandal,
scandali,



















h¬scandal,
¬scandal,
¬scandali
















hscandal, scandal, scandali, 















E
=

2
hscandal, scandal, ¬scandali, 

















 h¬scandal, scandal, scandali 





























































pfr

For a program consisting only of rule scandal ֒→ ¬scandal :

[1, 0.89, 0.93, 0.8, 1.0] from Figure 2.1, we have frequency equivalence classes E1 and
E2 based on the pfr for all possible threads seen in Figure 2.7.

61

we compute the pfr based on this single rule for all possible threads. In Figure 2.8 we
can then group these threads into two equivalence classes, those whose pfr is within
[0.8, 1] and those whose frequency is outside this range.
For instance, threads hscandal, scandal, scandali and hscandal, scandal, ¬scandali
both have a pfr less than 0.8. Therefore, we have that hscandal, scandal, scandali ∼Kfr-ex
h¬scandal, scandal, scandali.
The relation ∼K satisfies several common properties of relations.
Proposition 6. For any constrained APT-logic program K, ∼K is reflexive, symmetric, and transitive.
Therefore ∼K is an equivalence relation, and we can partition T (the set
of all possible threads) into equivalence classes according to a given ∼K . We let
T [∼K ] be this partitioning, where each set E ∈ T [∼K ] contains only K-frequencyequivalent threads. We then assign each set E a binary string str(E) of length m
(the number of constrained formulas in K) where digit i is 1 if for all Th ∈ E,
αi ≤ fr(Th, Fi , Gi , ∆ti ) ≤ βi , and 0 otherwise.
Example 2.3.9. In Figure 2.8 we see a partitioning of the threads T [∼Kfr-ex ] with
two partitions: E1 and E2 . The associated binary strings are: str(E1 ) = 1 and
str(E2 ) = 0. Notice that we only have two frequency equivalence classes of threads,
which is only 25% of the 8 threads we had originally.
In the following linear program, we introduce variables v̄b for each binary string
b of length |K|.
62

Definition 21 (Frequency-Equivalence Linear Constraints). For constrained APTLogic Program K, the set of Frequency-Equivalence Linear Constraints FELC(K)
contains only the following:
1.

P

E∈T [∼K ]

v̄str(E) = 1 (where str(E) is the binary number that labels frequency

equivalence class E)
2. For all length |K| binary strings b if there is no E ∈ T [∼K ] such that str(E) = b
then v̄b = 0
fr

3. For all Fi ֒→ Gi : [∆ti , ℓi , ui , αi , βi ] ∈ K, ℓi ≤

P

s∈[0,1]m ,si =1

v̄s ≤ ui

Theorem 6. For constrained APT-Logic Program K, K is consistent iff there is a
solution to FELC(K).
As FELC provides a correct result for consistency, we can use it to develop the
consistency-checking algorithm FELC-CONSISTENT shown below.
Algorithm 3 Compute consistency of K using FELC.
FELC-CONSISTENT(APT-Program K)
1. Construct FELC(K).
2. Attempt to solve FELC(K).
3. If solvable, return consistent, otherwise, inconsistent.

If the frequency equivalence classes of threads for a given program are known,
FELC also offers an improvement in complexity over SLC.
Proposition 7. FELC requires 2|K| + 1 constraints and 2|K| variables.
63

Example 2.3.10. Consider the APT-Program Kstock from Figure 2.1. Let BL be
the set of atoms seen in that program (hence |BL | = 5). We consider a tmax of 4.
From Proposition 1, we know that using SLC to determine the consistency of Kstock
would require 7 constraints and 220 = 1, 048, 576 variables. We show below a set of
linear constraints based on FELC below that requires 7 constraints and only 23 = 8
variables. For the program Kstock , we have the following linear constraints:
pfr

• For rule scandal ֒→ ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]
0.89 ≤ v̄001 + v̄011 + v̄101 + v̄111 ≤ 0.93
pfr

• For rule sec rumor ∧ earn incr(10%) ֒→ stock decr(10%) : [2, 0.65, 0.97, 0.7, 1.0]
0.65 ≤ v̄010 + v̄011 + v̄110 + v̄111 ≤ 0.97
• For rule
pfr

sec rumor ∧ earn incr(10%) ֒→ stock decr(10%) ∧ cfo resigns : [2, 0.68, 0.95, 0.7, 0.8]
0.68 ≤ v̄100 + v̄101 + v̄110 + v̄111 ≤ 0.95
• v̄000 + v̄001 + v̄010 + v̄011 + v̄100 + v̄101 + v̄110 + v̄111 = 1
The running time of consistency checking via FELC is independent of the number of atoms or time points or number of worlds. Thus, even though it runs in time
exponential in |K|, it will in many cases run faster than SLC, which runs in time
linear in |K| and exponential in the number of worlds or the number of time points.
Further, since the size of K, the number of worlds, and the number of time points
are all known in advance, one can tell which approach will be faster dynamically,
and dispatch the smaller, faster linear program.
64

However, as with WELC, significant computation cost is required to construct
the linear constraints, specifically in identifying the frequency equivalence classes
that are empty. We refer to the obvious, exhaustive, and exact method for identifying empty frequency equivalence classes as the Brute Force Frequency Equivalence
Class Algorithm or BFECA.
Algorithm 4 Find Frequency Equivalence Classes of Constrained Program K
BFECA(APT-Program K)
1. Generate all possible threads.
2. For each thread, Th, for all i, compute fri (Th, Fi , Gi , ∆ti ).
3. Determine for each thread, Th, for each rule, ri , if the associated frequency
function, fri for Th falls within the range [αi , βi ].
4. Based on the result of step 3, determine which frequency equivalence class Th
belongs to.
5. After all threads are generated, return EMPTY if there are no threads found
for a given frequency equivalence class is empty and OK otherwise.

As BFECA exhaustively considers all threads, we have the following trivial
proposition concerning correctness.
Proposition 8. For each frequency equivalence class C, if C is empty BFECA returns EMPTY; otherwise, if C contains at least one thread, BFECA returns OK.
For each thread, BFECA calculates the frequency function with regard to each
65

rule. Hence, for each of the 2|BL |tmax threads, it calculates |K| frequency functions.
This leads us to the complexity result below.
Proposition 9. The complexity of BFECA is:
O 2|BL |tmax · F (tmax ) · |K|



where F (tmax ) is defined as follows. Suppose timei is the time required to compute
fri (Th, Fi , Gi , ∆ti ). Then F (tmax ) equals maxi (timei ).
Note that if F (tmax ) is linear, then the complexity of finding the frequency
equivalence classes and then performing FELC is still better than SLC. The dominating term in the complexity of FELC has an exponent of |BL | · tmax when BFECA
is used. SLC, on the other hand, will have an exponent of 3.5 · |BL | · tmax for most
linear program solvers [79]. The following example shows how BFECA works.
Example 2.3.11. Consider the FELC constraints set up for Kstock in Example 2.3.10.
pfr

Look at rules sec rumor ∧ earn incr(10%) ֒→ stock decr(10%) : [2, 0.65, 0.97, 0.7, 1.0]
pfr

and sec rumor∧earn incr(10%) ֒→ stock decr(10%)∧cfo resigns : [2, 0.68, 0.95, 0.7, 0.8].
For a given thread, Th, consider the pfr ’s associated with those rules. Let p1 =
pfr (Th, sec rumor ∧earn incr(10%), stock decr(10%), 2) and p2 = pfr (Th, sec rumor ∧
earn incr(10%), stock decr(10%) ∧ cfo resigns, 2).
We note that p2 must be less than or equal to p1 as the G formula for both rules
differs only by one conjuncted atom. Therefore, there is no possible Th such that
p2 > p1 . Hence, variables v̄100 and v̄101 from the FELC constraints in Example 2.3.10
must be set to zero.
66

To find such variables, BFECA calculates the frequency function for all possible
threads. However, with SLC-CONSISTENT, the dominating term in this example
requires 270 operations, where BFECA requires only 220 operations. Note that the
complexity of BFECA often will dominate the complexity of FELC-CONSISTENT.
As suggested earlier, FELC can be used on programs that consist of both constrained rules and annotated formulas. We can include annotated formulas in our
constrained program by writing rules that are essentially equivalent to annotated
formulas, as described earlier through use of the Query Frequency Function in Definition 14.
Note that if the PCD conditions are met (Page 46), we can often be guaranteed
that all FELC equivalence classes will be non-empty, making the BFECA algorithm
unnecessary. See the Appendix for a complete discussion of this special case.

2.3.5

Combining World and Frequency Equivalence

We have introduced two improved methods for computing consistency: FELCCONSISTENT/BFECA and WELC-CONSISTENT. We now introduce a hybrid approach that uses the world-equivalence classes of WELC to ease the computation
necessary to compute the frequency-equivalence classes needed in FELC. Worldequivalence can be used to determine if a frequency equivalence class is empty or
not. The intuition is simple: we follow the approach of BFECA, generating the set
of threads and finding the frequency function for each one. However, rather than
generating the set of threads, we generate the set of world-based thread partitions

67

and find their frequency functions. As shown in the discussion of WELC, the number of world-based thread partitions can be considerably less than the number of
threads. Hence, we present world equivalence for finding frequency equivalence, or
WEFE.
Algorithm 5 World Equivalence for finding Frequency Equivalence Classes of Constrained Program K
WEFE(APT-Program K)
1. Find the world equivalence classes based on formula(K).
2. Generate all world-equivalence based thread partitions for K.
3. For each world-equivalence thread partition, P , for all i, compute
fri (P, Fi , Gi , ∆ti ).
4. For each rule, ri let INi be the set of thread partitions such that αi ≤
fri (P, Fi , Gi , ∆ti ) ≤ βi . For each rule, let OU Ti be all partitions not in INi .
5. For string s ∈ [0, 1]|K| let the set P CLASSs be defined as
T

si =0

	
OU Ti .

T

	
∩
IN
i
si =1

6. For each class cls return EMPTY if P CLASSs ≡ ∅ and OK otherwise.

As WEFE exhaustively considers all world equivalence based thread partitions,
and each thread belongs to exactly one partition, WEFE provides a correct answer.
Proposition 10. If a given frequency equivalence class is empty, WEFE returns
EMPTY. If there is a thread in a given frequency equivalence class, WEFE returns
68

OK.
The computational complexity of this algorithm is dependent upon the number of thread-partitions resulting from world-equivalence. As stated before, this is
22|K|·tmax . Further, the cost of calculating the frequency function for each thread is
only O(tmax ) as checking the satisfiability of the F and G formulas in a rule by a
world equivalence class is a trivial operation, since the satisfaction is pre-determined
when the world-equivalence classes are generated.
Proposition 11. The complexity of WEFE is
O 22|K|·tmax · tmax · |K|



when the set of world-equivalence classes for K is known.
WEFE/FELC-CONSISTENT is generally preferable for checking the consistency
of constrained programs: because it considers threads on a world-equivalence basis
rather than individually, it should generally have a shorter run time than BFECA
even taking into account the costs of constructing world-equivalence classes. We
illustrate this in the following example:
Example 2.3.12. Suppose we want to build FELC constraints for Kstock as we did
in Example 2.3.10 where tmax = 4. We note that formula(Kstock ) consists of the
following:
1. scandal
2. ¬scandal
69

3. sec rumor ∧ earn incr(10%)
4. stock decr(10%)
5. stock decr(10%) ∧ cfo resigns
Although the number of world equivalence classes, based on formula(Kstock ) would
be 25 , which is also the number of worlds due to there only being 5 atoms referenced
in the program, we note that many of the world equivalence classes are empty. For
example, we know that there can be no world that satisfies both of the first two formulas, which immediately reduces our number of world equivalence classes by a factor
of two. Further, there can be no world that does not satisfy stock decr(10%) but satisfies stock decr(10%) ∧ cfo resigns. Hence, the number of world equivalence classes
is 12 in this case, a significant reduction from the 32 worlds originally considered.
Therefore, WEFE only considers 124 = 20, 736 world-equivalent threads, as
opposed to BFECA, which considers 324 = 1, 048, 576 threads. Note that if the
world equivalence classes are known, this cost of WEFE may still dominate FELCCONSISTENT. This is a vast improvement over the 270 operations required by SLCCONSISTENT.

2.4

Entailment by APT-logic programs
Now that we have dealt with consistency, we can explore the issue of entail-

ment, which is defined in the usual way.
Definition 22 (Entailment). Let K be an APT-logic program, r be a rule, and af be
70

an annotated formula. We say that K entails af iff for all models I of K, I |= af ,
and that K entails r iff for all models I of K, I |= r.
Example 2.4.1 (Entailment). Recall that in Example 2.3.8 we presented the following APT-Program:
pfr

Kfr-ex = {scandal ֒→ ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]}
Suppose we form the following rule as a hypothesis.
pfr

rhyp = scandal ֒→ ¬scandal : [1, 0.88, 0.94, 0.8, 1.0]
Does Kfr-ex entail rhyp ? A quick examination of the only rule in the program and the
hypothesis tells us that except for the probability bounds, they are the same. Notice
that the rule in Kfr-ex has probability bounds [0.89, 0.93] and the probability bounds
of rhyp are a superset, [0.88, 0.94]. Therefore, we know that any interpretation in
which the sums of the probabilities of threads with a frequency ratio between [0.8, 1.0]
sum to a quantity in [0.89, 0.93], are also in [0.88, 0.94]. So, by the definitions of
satisfaction and entailment, we can say that Kfr-ex entails rhyp .
The following result shows that checking entailment of an annotated formula by an
APT-logic program is coNP-hard.
Theorem 7. Given an APT-logic program K and an annotated formula, af , deciding
if K entails af is coNP-hard in |BL | (the number of atoms).
In the next chapter, we prove a matching upper bound for the complexity of
this problem.
71

2.4.1

Linear Constraints for Entailment

We shall now provide algorithms for computing entailment based on the linear constraints SLC, WELC, and FELC. In all cases, the method is straightforward: we
determine the minimal and maximal probability for the annotated formula in interpretations satisfying the original knowledgebase by minimizing and maximizing
the appropriate sum subject to some set of linear constraints. Due to the fact that
any annotated formula can be viewed as a constrained rule, we will not describe the
entailment of annotated formulas in this section.
Algorithm 6 Entailment of Rule r by Program K with SLC
SLC-ENT(APT-Program K)
fr

fr

1. If r is unconstrained, (r = F ; G : [∆t, ℓ, u]), create rule r′ = F ; G :
[∆t, ℓ′ , u′ ] where ℓ′ , u′ are variables.
fr

fr

2. If r is constrained, (r = F ֒→ G : [∆t, ℓ, u, α, β]) create rule r′ = F ֒→ G :
[∆t, ℓ′ , u′ , α, β] where ℓ′ , u′ are variables.
3. Create set of linear constraints SLC(K ∪ {r′ }).
4. Let ℓ̄′ be the minimization of ℓ′ subject to SLC(K ∪ {r′ }).
5. Let ū′ be the maximization of u′ subject to SLC(K ∪ {r′ }).
6. If [ℓ̄′ , ū′ ] ⊆ [ℓ, u] return ENTAILS otherwise return NOT ENTAILS.

We can show Algorithm 6 to be correct and to take time exponential in |Bℓ |
(as expected due to Theorem 7).
72

Proposition 12 (Checking Entailment using SLC ). For unconstrained rule r =
fr

fr

F ; G : [∆t, ℓ, u] or constrained rule r = F ֒→ G : [∆t, ℓ, u, α, β] and program K,
SLC-ENT returns ENTAILS iff K entails r and returns NOT ENTAILS iff K does
not entail r
Proposition 13. SLC-ENT requires solving at most two linear programs. Each
linear program has 2|K| + 1 constraints and 2|BL ·|tmax variables.
We now give an example of how Algorithm 6 will run in practice.
Example 2.4.2. Consider APT-Program Kstock introduced in Figure 2.1 with tmax =
4. Suppose we want to see if Kstock entails the annotated formula query = earn decr(10%) :
[3, 0.50, 0.80].
qfr

First, we re-write the query as a rule using qf r. Hence, query rule = TRUE ֒→
qfr

earn decr(10%) : [3, 0.50, 0.80, 1, 1]. From this rule, we create query ′rule = TRUE ֒→
earn decr(10%) : [3, ℓ′ , u′ , 1, 1].
We now consider all possible threads given Kstock ∪{query ′rule } and tmax = 4. As
there are 6 atoms in the union of the program and query, we have 224 = 16, 777, 216
possible threads (|T | = 224 ). Hence, we set up the following linear constraints:
pfr

• For rule scandal ֒→ ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]
0.89 ≤
0.93 ≥

P

P

Th j ∈T 0.8≤pf r(Th ,scandal,¬scandal,1)≤1.0
j
Th j ∈T 0.8≤pf r(Th ,scandal,¬scandal,1)≤1.0
j

vj
vj

pfr

• For rule sec rumor ∧ earn incr(10%) ֒→ stock decr(10%) : [2, 0.65, 0.97, 0.7, 1.0]
0.65 ≤
0.97 ≥

P

P

Th j ∈T 0.7≤pf r(Th ,sec rumor∧earn incr(10%),stock decr(10%),2)≤1.0
j
Th j ∈T 0.7≤pf r(Th ,sec rumor∧earn incr(10%),stock decr(10%),2)≤1.0
j

73

vj
vj

• For rule
pfr

sec rumor ∧ earn incr(10%) ֒→ stock decr(10%) ∧ cfo resigns : [2, 0.68, 0.95, 0.7, 0.8]
0.68 ≤
0.95 ≥

P

P

Th j ∈T 0.7≤pf r(Th ,sec rumor∧earn incr(10%),stock decr(10%)∧cfo resigns,2)≤0.8
j
Th j ∈T 0.7≤pf r(Th ,sec rumor∧earn incr(10%),stock decr(10%)∧cfo resigns,2)≤0.8
j

vj
vj

qfr

• For rule query ′rule = TRUE ֒→ earn decr(10%) : [3, ℓ′ , u′ , 1, 1]
ℓ′ ≤
u′ ≥
•

P

Th j ∈T 1≤qf r(Th ,TRUE,earn decr(10%),3)≤1.0
j

P

Pj<224
j=0

Th j ∈T 1≤qf r(Th ,TRUE,earn decr(10%),3)≤1.0
j

vj
vj

vj = 1.

As it turns out, the minimization of ℓ′ is 0 and the maximization of u′ is 1. Since
[0, 1] 6⊂ [0.5, 0.8], we can say that Kstock does not entail query.
SLC-ENT uses the SLC set of linear constraints. However, one could easily
substitute WELC or FELC for SLC in SLC-ENT. We present an algorithm for alternate linear constraints, ALC-ENT, that mirrors SLC-ENT and leverages these other
constraints in the appendix.
There is a further improvement that can be made in practice: if we solve the
linear program once, and find that the minimization of ℓ′ is less than ℓ, we have
determined that the rule is not entailed by the program, and solving the linear
program again is not necessary to decide entailment.

2.5

Applications of APT Logic
APT-logic programs have many possible applications; in this section we will
74

Algorithm 7 The APT-Extract Algorithm.
APT-Extract(T , ActCond, MaxBody, ∆, SuppLB , σ,STAT-Test)

1. Rules := ∅;
2. for each combination (environment variable, value) choose 1, . . . , MaxBody {
3.

let Body be the current combination; supportBody:= 0; supportBoth:= 0;

4.

for t = 1 to maxTime(T ) {

5.

bodyHappened:= false;

6.

if Body is true at time t then

7.

bodyHappened:= true; actHappened:= false;

for d = 1 to ∆ {

8.

9.

if ActCond is true at time t + d then actHappened:= true;

10.

break for;

11.

}

12.

if bodyHappened then supportBody:= supportBody + 1;

13.

if bodyHappened and actHappened then supportBoth:= supportBoth + 1;

14.

}

15.

if supportBody <> 0 then confidence:= supportBoth / supportBody;

16.

else confidence:= 0;

17.

if (supportBoth > suppLB ) ∧ STAT TEST (Body, ActCond) then

18.

pfr

add Body ; ActCond : [∆, confidence − σ, confidence + σ] to Rules;

19. }
20. return Rules;

75

briefly describe an effort to learn conditions under which various terror groups took
various actions, in the form of APT-programs. We assume that the data is given
in the form of a table that contains two kinds of attributes: action and environment, and that each tuple represents the values of each of these attributes for a
certain time point. A good example of this kind of data is the “Minorities at Risk
Organizational Behavior” (MAROB) data set [181]. This data set has identified
around 150 parameters to monitor for about 300 groups around the world that are
either involved in terrorism or are at risk of becoming full-fledged terrorist organizations. The 150 attributes describe aspects of these groups, such as whether or not
the group engaged in violent attacks, if financial or military support was received
from foreign governments, and the type of leadership the group has. It was a simple task to divide the attributes into actions that could be taken by the group (i.e.,
bombings, kidnappings, armed attacks, etc.) and environmental conditions (i.e., the
type of leadership, the kind and amount of foreign support, whether the group has a
military wing, etc.). Values for these 150 parameters are available for up to 24 years
per group, though it is less for some groups (e.g., groups that have been around
for a shorter duration). For each group, MAROB provides a table whose columns
correspond to the 150 parameters and the rows correspond to the years. There are
many social science data sets that use such data. These include the KEDS data set
from the University of Kansas that tracks country stability data (rather than terror
group data) [151] and the Political Instability Task Force (PITF) data [57].
The APT-Extract algorithm provides a basic approach to extracting APT-

76

rules 6 . The inputs are: a table of historic data, a condition on an action variable
(variable name and value), a maximum size for the body, a value for ∆, a lower
bound for the support of the rule, and a real number σ ∈ [0, 1] that will determine
the width of the probability annotations for the extracted rules, and an arbitrary
statistical test (e.g., a t-test or something based on p-values in statistics) selected by
the user that measures the correlation between the values of the body of a possible
rule and the head. We use the standard measurements of support and confidence
from the literature on association rules: given table T , the support of a condition
C in T is the number of tuples for which C is true; given conditions C1 and C2 ,
the confidence in the fact that C1 is accompanied by C2 is the ratio of the support
of C1 ∧ C2 to the support of C1 . As an example of the kind of rules that can be
extracted by this algorithm, some of the rules extracted from the data for Hezbollah
are given in Figure 2.2.

2.6

Chapter 2 Related Work
In addition to past work on probabilistic logic programming [130, 129], proba-

bilistic logic programs were studied in [84], [86], and [93, 94, 95], who showed how to
introduce various probabilistic dependencies into probabilistic LPs. [111, 112] made
major contributions to bottom up computations of probabilistic LPs.
[98] and [66] were among the first to provide a logic to integrate time and prob6

Note that this algorithm is not a novel one, and simply performs calculations to capture

interesting relationships present in the data in order to build rules. More complex algorithms for
rule extraction are outside the scope of this dissertation.

77

ability. [78] also studied the integration of time and probability in order to facilitate
efficient planning. He was primarily interested in how the probability of facts and
events change over time. [62] developed a logic for reasoning about actions, probability and time using an interval time model. [30] developed methods to extend
possibilistic logic to handle temporal information. This logic associates, with each
formula of possibilistic logic, a set of time points describing when the formula has a
possibilistic truth value. [63] studied the semantics of reasoning about distributed
systems where uncertainty is present using a logic where a process has knowledge
about the probability of events for decision making by the process. [44, 43] developed logics of time and belief to model the behavior of distributed systems, while
[169] developed a framework that integrates beliefs, time, commitment, desires, and
multiple agents. [13] developed a language to reason about actions in a probabilistic
setting; their models use static and dynamic causal laws together with background
(unknown) variables whose values are determined by factors not in the model. Building on top of past work by [34], [36] introduce heterogeneous temporal probabilistic
agents to model agent behavior and develop a model theory and fixpoint semantics
focusing on agents built using legacy code.
Though there has been extensive work on temporal reasoning, the key difference between APT logic programs and past works in verification [96, 42, 173, 25, 56,
97] is the use of frequency functions in our work to define the frequency with which
a given formula G holds (some given time) after a given formula F holds. We show
that such a definition can be given in many different ways and, rather than committing to one such definition, we provide axioms that any frequency function should
78

satisfy. A result of our introduction of the frequency function is that the probability
an event occurs at time t is dependent on the events that occur in interval [1, t] and
interval [t, tmax ].
APT-Logic distinguishes itself from other temporal logics in the following ways:
1. It provides for reasoning about probability of events within a sequence of
events and probabilistic comparison between sequences of events.
2. Future worlds can depend on more than just the current world.
3. It provides bounds on probabilities rather than just a point probability.
4. It does not make any independence assumptions.

2.6.1

Markov Decision Processes

Many temporal logics, whether probabilistic or not, make use of some sort of
state transition system as an underlying structure. A state-transition system is said
to conform to the Markov Property if each transition probability only depends on the
current state [146]. We demonstrate that while APT-Logic Programs maintain much
of the expressiveness of most state-transition systems, they also have the ability of
expressing non-Markovian sequences of events. Specifically, the semantic structures
used in APT-Logic (worlds, threads, interpretations) can be represented by state
transition systems when the following restrictions are applied:
1. As APT-Logic only deals with finite temporal sequences, only the first tmax
states generated by an MDP will be considered.
79

2. By definition, each world represents a unique set of atoms. Therefore, a corresponding state transition system must have the restriction that each state
is uniquely labeled; i.e., each state in the MDP represents exactly one world.
3. Each transition in the MDP takes one unit of time.
Our notation for an MDP most resembles the reactive probabilistic labeled
transition system (RPLTS) [25, 56, 97]. Below, we will formally define an MDP
with respect to a set of actions Act, and a set of atomic propositions, BL . When
comparing MDPs to APT-Programs, we will assume that the APT-Program uses
the same set of ground atoms, and that each state in an MDP has a unique atomic
label. In this manner, we can equate MDP states with worlds in tp-interpretations.
Hence, an MDP is defined as follows:
Definition 23 (MDP). A Markov Decision Process (MDP) consists of a 4-tuple
L = (S, δ, P, lbl, s1 ) where:
• S is a finite set of states
• δ ⊆ S × Act × S is the transition relation
• P : δ → [0, 1] is the transition probability distribution, which satisfies:
• ∀s ∈ S, ∀a ∈ Act

P

s′ :(s,a,s′ )∈δ

P (s, a, s′ ) ∈ [0, 1]

• ∀s ∈ S, ∀a ∈ Act (∃s′ (s, a, s′ ) ∈ δ) ⇒

P

s′ :(s,a,s′ )∈δ

P (s, a, s′ ) = 1

• lbl : S → 2BL is the labeling of each state that specifies the set of propositions that
are true in a state. Each state has a unique set of propositions.
80

• s1 ∈ S is the initial state.
When an MDP is employed with policy π, it means that in state si , action
π(si ) is taken. An MDP that uses only a single policy is often referred to as a
Stochastic Process, or Markov Process. With the definition of an MDP and notion
of a policy, we can now state what it means for a tp-interpretation to satisfy an
MDP.
Definition 24. Let L be an MDP, π be a policy, I be a tp-interpretation, and tmax
be the maximum value of time. We say that I satisfies the pair (L, π) iff: for all
sequences of n = tmax states, seq ≡ s1 → . . . → si → . . . → sn , there exists a thread
Th such that:
• For every si in seq, a ∈ lbl(si ) iff a ∈ Th(i)
•

Qn−1
i=1

P (si , π(si ), si+1 ) = I(Th)

Further, we say that an interpretation I satisfies an MDP L and set of policies
POL iff there exists a policy π ∈ POL such that I |= (L, π).
We can extend the notion of entailment described earlier to MDP’s and describe entailment relationships between MDP’s and APT-Programs. Based on this
idea, we now can define a notion of equivalence between an MDP and an APTProgram as follows.
Definition 25 (Equivalence/Entailment). An MDP L and set of policies POL is
equivalent to APT-Program K when tp-interpretation I |= (L, POL) iff I |= K.
(L, POL) is said to entail K if for all tp-interpretations I, if I |= (L, POL) then
81

I |= K. Finally, K is said to entail (L, POL) if for all tp-interpretations I, if I |= K
then I |= (L, POL).
With this notion, given an MDP and policy, we can now create an APT-Logic
Program such that the set of satisfying interpretations for the MDP and policy is
the same as the set of satisfying interpretations for the APT-Logic Program. We
use these notions of entailment and equivalence to specify the semantic relationship
between APT-Logic: if for any APT-Program there is an equivalent MDP and a set
of policies, then we will consider APT-Logic to be no more expressive than MDPs.
Soon we will see this is not the case, and that APT-Logic is in fact more expressive
than MDPs.
First however, we provide the following formula notation. F is a mapping of
states to formulas such that F (s) ≡ (

V

a∈lbl(s) a) ∧ (

V

b∈lbl(s)
/

¬b). Second, we provide

the following probability measurement of a t-length sequence starting with state s1
and ending with state st . We use the notation s →t s′ to denote the set of sequences
of t transitions from s to s′ .
Definition 26 (Sequence Probability Measure). Let L be an MDP, π be a policy,
s1 , st be states, and t be a positive integer. The sequence probability measure, SP M
is defined as follows:
SP ML,π (st , t) =

X

s1 →t−1 st

! t−1
Y
i=1

P (si , π(si ), si+1 )

#

So, the SPM totals the probabilities of all sequences from the initial state to
st in t − 1 transitions.
82

Next, we will present Algorithm 8 that, given an MDP and set of policies
(L, POL), creates an APT-Program K such that (L, POL) entails K. This construction is guaranteed to be correct by the following theorem.
Algorithm 8 Generate APT-Program that is entailed by a given MDP and set of
policies.
MAKE-APT(MDP L, PolicySet POL)
1. Create annotated formula F (s1 ) : [1, 1, 1].
2. For each state s, and each time point t, there are |POL| SPM’s, one for each
policy. Let min(SP ML,π (s, t)) be the minimum such SPM.
3. For each state s, and each time point t, let max(SP ML,π (s, t)) be the maximum SPM.
4. For each time point t ∈ [1, tmax ], and each state si , create the following annotated formula: F (si ) : [t, min(SP ML,π (si , t)), max(SP ML,π (si , t))].

Theorem 8. If an interpretation I satisfies MDP L with set of policies L, then it
satisfies APT-Program K generated from MAKE-APT.
Clearly, if we restrict the MDP to a single policy, then we can create an APTProgram using MAKE-APT that is equivalent to the MDP and single policy.
Corollary 1. An interpretation I satisfies MDP L with policy π, iff it satisfies
APT-Program K generated from MAKE-APT.

83

It is interesting to note, however, that although we can create an APT-Logic
Program that is entailed by a given MDP and set of policies, we cannot always create
an APT-Logic Program that entails an MDP and a set of policies. The intuition is
that, in certain circumstances we are guaranteed that an APT-Logic Program has
an infinite number of satisfying interpretations. If an MDP and set of policies are
created such that these circumstances hold, then creating an APT-Program that
entails the given MDP and set of policies is impossible. Hence, we first make the
claim of the special circumstance that guarantees an infinite number of satisfying
interpretations. The claim is that for APT-Program K, if there exists satisfying
tp-interpretations for K, I1 , I2 , such that for threads Th 1 , Th 2 , I1 (Th 1 ) = 1 and
I2 (Th 2 ) = 1, then there is an infinite number of satisfying interpretations for K. We
describe why this is true in the following paragraph.
Let c ∈ (0, 1) and b ∈ (c, 1). Let I3 represent an infinite number of interpretations such that I3 (Th 1 ) = b and I3 (Th 2 ) = (1 − b). K is then satisfied by an infinite
number of interpretations if all possible I3 interpretations satisfy K. Suppose by
way of contradiction that some I3 does not satisfy K. We have two cases:
Case 1: There exists an unconstrained rule, r such that I3 6|= r.
fr

Let r = F ; G : [∆t, ℓ, u]. Let a1 = fr(Th 1 , F, G, ∆t) and a2 = fr(Th 2 , F, G, ∆t).
Let a1 ≤ a2 . By the definition of satisfaction, we know that [a1 , a2 ] ⊆ [ℓ, u]. By
the definition of satisfaction, we know that
or

P

Th∈T

P

Th∈T

I3 (Th)fr(Th, F, G, ∆t) < ℓ

I3 (Th)fr(Th, F, G, ∆t) > u as I3 6|= r. Therefore, b·a1 +(1−b)·a2 < ℓ

or b · a1 + (1 − b) · a2 > u. However, clearly, b · a1 + (1 − b) · a2 ⊆ (a1 , a2 ) which
84

implies b · a1 + (1 − b) · a2 ⊆ [ℓ, u]. Hence, we have a contradiction.

Case 2: There exists a constrained rule, r such that I3 6|= r.
fr

Let ri = F ֒→ G : [∆t, ℓ, u, α, β]. We have three cases:
Case 2.1: Th 1 , Th 2 ∈ ATSi
Then, ℓ ≤ 1 ≤ u and the probabilities of both threads summed together
must fall in this probability bounds. As I3 (Th 1 ) + I3 (Th 2 ) = 1, I3 then
must satisfy ri , so we have a contradiction.
Case 2.2: Either Th 1 ∈ ATSi or Th 2 ∈ ATSi
If ℓ 6= 1, then there exists c ∈ (0, 1) such that there is an infinite number
of interpretations as per the definition of I3 such that I3 |= ri . If ℓ = 1,
then either I1 or I2 does not satisfy ri . Hence, we have a contradiction.
Case 2.3: Th 1 , Th 2 ∈
/ ATSi
In this case, any interpretation that assigns probabilities only to Th 1 and
Th 2 satisfies ri . Therefore, I3 must satisfy ri .
Now we consider a very simple MDP with only two policies. We see that this MDP
causes the above mentioned circumstances to occur. Hence, we cannot construct an
APT-Program that entails the MDP and set of policies.
Let L be an MDP, the set of atoms, BL , be {a}, S = {s1 , s2 } be such that
lbl(s1 ) ≡ {a} and lbl(s2 ) ≡ ∅, Act = {x, y}, P (s1 , x, s1 ) = 1 and P (s1 , x, s2 ) = 0,
P (s1 , y, s1 ) = 0, and P (s1 , y, s2 ) = 1. We define the set of policies, POL = {π1 , π2 }
85

such that π1 (s1 ) = x and π2 (s1 ) = y. Let tmax = 2. We claim that it is impossible
to construct an APT-Program that entails (L, POL).
So, we can see why there does not exist an APT-Program that entails the
MDP described above. Assume by way of contradiction that we can create an APTLogic Program K such that all interpretations that satisfy (L, π1 ) or (L, π2 ) satisfy
K. As each MDP-policy tuple is satisfied by exactly one interpretation, we have
the following threads and interpretations based on the set of worlds W = {w1 , w2 }
where w1 ≡ lbl(s1 ) and w2 ≡ lbl(s2 ).
• Thread Th 1 ≡ hw1 , w2 i. Let I1 be an interpretation such that I1 (Th 1 ) = 1 and
sets the probability of all other threads to zero.
• Thread Th 2 ≡ hw1 , w1 i. Let I2 be an interpretation such that I2 (Th 2 ) = 1 and
sets the probability of all other threads to zero.
Hence, APT-Logic Program K must be satisfied by exactly I1 and I2 . However, by
the claim above, any program satisfied by these two interpretations is also satisfied
by an infinite number of interpretations, so we have a contradiction.
So, based on the earlier definition of equivalence, while we can construct an
equivalent APT-Program for an MDP and a single policy, we cannot do so for an
MDP and set of policies. However, is the opposite true? It is: it would be trivial to
construct an MDP that entails an APT-Program, since the null MDP can accomplish
this. This highlights a difference between MDPs and APT-Logic Programs: we
cannot have rules that say this relationship holds with probability p1 or probability
p2 . However, we can express ranges of probabilities.
86

While we cannot create an APT-Program that entails a given MDP and set
of policies, APT-Programs can be satisfied by tp-interpretations that cannot satisfy
any MDP. In other words, there are APT-programs and tp-interpretations that
satisfy those APT-programs where there is no MDP that is satisfied by that tpinterpretation. Consider the set of ground atoms BL = {a} and tmax = 4 and the
below APT-Logic Program, K:
• a : [1, 1, 1]
pfr

pfr

• a ; ¬a : [1, 0.5, 0.5] (or a ֒→ ¬a : [1, 0.5, 0.5, 1, 1])
We included an alternate second rule to illustrate that this type of expressiveness
result is true about both constrained and unconstrained programs. Consider worlds
w1 ≡ {a} and w2 ≡ ∅. Let I be an interpretation that assigns probabilities to the
threads below:
• Th 1 ≡ hw1 , w2 , w1 , w2 , i, I(Th 1 ) = 0.5
• Th 2 ≡ hw1 , w1 , w1 , w1 , i, I(Th 2 ) = 0.5
It is trivial to show that I |= K. We claim that it is impossible to build an MDP L
with set of policies POL such that tp-interpretation I |= (L, POL).
Let S = {s1 , s2 } such that lbl(s1 ) ≡ w1 and lbl(s2 ) ≡ w2 . Suppose by way of
contradiction that I |= (L, POL). Therefore, there exists a policy, π ∈ POL such
that I satisfies (L, π). Hence, the following must be true:
• P (s1 , π(s1 ), s2 ) · P (s2 , π(s2 ), s1 ) · (s1 , π(s1 ), s2 ) = I1 (th1 ) = 0.5
87

{a}
p
1-p
{a}

{}

1-p

{a}
r

r

p
1-p

{a}

{}

p

{a}

{}

Figure 2.9: Left: Unrolled MDP in an attempt to create an MDP that satisfies
interpretation I in the text. Notice how the sequence h{a}, {}, {a}, {a}i must be
assigned a non-zero probability. Right: A standard representation of the MDP on
the left. Notice that the MDP must allow for non-zero probability of threads that
are given a zero probability in interpretation I.
• P (s1 , π(s1 ), s1 ) · P (s1 , π(s1 ), s1 ) · (s1 , π(s1 ), s1 ) = I1 (th2 ) = 0.5
Refer to the left side of Figure 2.9 for a graphical representation of what follows. Let
P (s1 , π(s1 ), s2 ) = p. Then, by the definition of an MDP, P (s1 , π(s1 ), s1 ) = 1 − p. By
the above equalities, 1 − p > 0. Let P (s2 , π(s2 ), s1 ) = r. Therefore, p2 · r = 0.5. Now
consider the sequence seq ≡ s1 → s2 → s1 → s1 . The probability of this sequence
must be set to zero, by the definition of I. Then, P (seq) = p · r · (1 − p) = 0.
However, we know that p · r cannot be zero and we know that 1 − p > 0. Hence, we
have a contradiction.
The above discussion illustrates the differences between MDPs and APT-Logic.
One could argue that the use of policies is overly restrictive for an MDP, i.e., that
perhaps the action should be decided based on time, or a combination of time and
the current state. However, we can easily modify the above claim based on time or
88

actions based on time and current state and obtain the same result. We suspect that
it is not possible to have an MDP that replicates an APT-Logic Program without
breaking the Markov Property, or causing a massive increase in the number of states,
which also would change the assumption about the relationship between worlds and
states.

2.6.2

Comparison with Probabilistic Computation Tree Logic
(PCTL)

In this section, we show that APT-Logic rules differ significantly in meaning from similar structures presented in PCTL [12, 64], a well-known probabilistic
temporal logic.
A derived operator in LTL with an intuition similar to that of our APT-Rules
was introduced by Susan Owicki and Leslie Lamport in [132]. The operator, known
as leads-to and an equivalent LTL formula are shown below (p and q are state
formulas).
(p y q) ≡ G(p ⇒ F(q))
This formula intuitively says that if p is true in a state, then q must be true in the
same (or future) state. As Owicki and Lamport’s operator is based on LTL, it does
not describe the correlation between p and q with probabilities or with reference
to a specific time interval; q merely must happen sometime after (or with) p. A
probabilistic version of CTL, known as PCTL [12, 64] introduces another operator
based on a similar intuition; the authors refer to this operator as “leads-to” as well.

89

This derived operator, and the equivalent PCTL formula, are shown below (f1 and
f2 are state formulas).
 

≤t
f1 y≤t
≥p f2 ≡ G (f1 ⇒ F≥p f2 ) >1
Intuitively, this operator reads as “f2 follows f1 within t periods of time with a
probability of p or greater”. As PCTL formulas are satisfied by a Markov Process (an
MDP with a single policy), satisfaction is determined by the transition probabilities.
So, to determine if a Markov Process satisfies the above leads-to formula, we must
compute the minimum probability of all sequences that start in a state satisfying
f1 and satisfy f2 in t units of time or less. Note that this is determined by the
transition probabilities of the Markov Process; hence, whether a Markov Process
satisfies the lead-to operator depends on the interval between f1 and f2 , but not
on the total length of the sequence of states. So, if we limit the number of states
max
which PCTL provides to limit
being considered, using an operator such as G≤t
≥1

consideration to only the first tmax states, the Markov Process will satisfy the formula
max
placed at the head of the PCTL has
regardless of the value of tmax . Note that G≤t
≥1

no effect on the satisfaction of the formula as there is already a G path-quantifier
included at the beginning of the leads-to operator.
As previously described, the frequency function is often highly sensitive to tmax .
Our two primary examples of frequency functions, pfr and efr , are based on ratios
of numbers of worlds in a given thread. For example, if we create a thread Th on a
single atom a, we can see that for thread h{a}, {a}, {}i, the value of pfr (Th, a, ¬a, 1)
is much greater than if Th were h{a}, {a}, {}, {a}, {a}, {a}, {a}i. The fact that the
90

length of the thread has an effect on the frequency function further illustrates how
APT-Logic allows for reasoning beyond the restrictions of the Markov Property.
The limited thread length forces us to consider worlds before and after a timepoint we wish to reason about. If our probabilities were fixed, based on transition
probabilities, they would not, and we would conform to the Markov Property.
Even though there are syntactic similarities, in the Appendix we provide a
short example illustrating semantic differences between APT-rules and PCTL.

2.7

Chapter Summary
Statements of the form “Formula G is/was/will be true with a probability

in the range [ℓ, u] in/within ∆t units of time after formula F became true” are
common. In this chapter, we have provided examples from four domains (stock
markets, counter-terrorism, reasoning about trains, and power grids), but many
more examples exist. Further, the counter-terrorism logic program (described in
further detail in the next chapter) are more than mere examples – they are created
using an extraction algorithm and a real-world data-set. They could be used, for
instance, to describe when the health or environmental effects of industrial pollution
may arise after a polluting event occurred, to the time taken for a medication to
produce (with some probability) some effects. In the same way, they can be used in
domains as widely divergent as industrial control systems to effects of educational
investment on improved grades or graduation rates.
In this chapter, we have provided the concept of Annotated Probabilistic Tem-

91

poral (APT) logic programs within which such statements can be expressed. APTlogic programs consist of two kinds of rules: unconstrained and constrained rules
with an expected value style semantics and a more ordinary semantics. Both types
of rules are parameterized by the novel concept of a frequency function. Frequency
functions capture the probability that G follows F in exactly (or within) T time units
within a thread (temporal interpretation). We show that this notion of “follows”
can intuitively mean many different things, each leading to a different meaning.
We propose an axiomatic definition of frequency functions which is rich enough to
capture these differing intuitions and then provide a formal semantics for APT-logic
programs.
We then study the problems of consistency and entailment for APT-logic programs. We show that the consistency problem is computationally intractable and
is naturally solved via linear programming. We develop three successively more
sophisticated linear programs for consistency checking and show that they lead to
smaller linear programs (though not always). We also develop a suite of complexity
results characterizing the entailment problem and provide algorithms to solve the
entailment problem.
A natural question that arises in any probabilistic logic framework is “Where
do the probabilities come from?” In order to answer this question, we develop
the (straightforward) APT-Extract algorithm that shows how APT-logic programs
can be derived from certain types of databases. We have applied APT-Extract to
extract APT-rules about several terror groups (further details on these programs are
provided in the next chapter).
92

Last, but not least, we have developed a detailed comparison between our APTframework and two well known frameworks: Markov decision processes [140] and
probabilistic computation tree logic [64]. We show the former can be captured within
APT-logic program framework (but not vice versa). The latter has a more complex
relationship with APT-logic programs, but cannot express intra-thread properties of
the type expressed via APT-logic programs.
We note that the algorithms of this chapter all rely on the solution to a linear program with an exponential number of variables, which is not practical for a
real-world implementation. Additionally, our complexity results of NP and coNP
hardness for consistency and entailment checking suggest that this is an intractable
problem under the assumption that P6=NP. In the next chapter, we take a more
practical approach, resorting to approximation algorithms that provide sound, but
incomplete solutions to consistency and entailment problems for APT-logic.

93

Chapter 3
Annotated Probabilistic Temporal Logic:
Approximate Algorithms

In the previous chapter, we explored reasoning about an agent’s behavior with
respect to time by introducing APT logic. This framework allows us to reason about
the probability that an agent takes a certain action at a given time based on a model
consisting of probabilistic rules. In that chapter, we showed that the consistency
and entailment in APT logic are NP and coNP hard respectively. In that chapter, we
provided several sound and complete algorithms for these problems, but due to the
complexity of the problem, these approaches are not viable for a real-world system.
In this chapter, we take a more practical approach, creating sound, but incomplete
algorithms for the consistency and entailment problems.1
1

This chapter is based on [156] which was completed in cooperation with Gerardo Simari and

V.S. Subrahmanian.

94

3.1

Chapter Introduction
In the previous chapter, we have shown that there are numerous applications

where we need to make statements of the form “Formula G becomes true with
50 − 60% probability 5 time units after formula F became true.” Statements of this
kind arise in a wide variety of application domains.
This chapter takes a more practical approach to the problems associated with
Annotated Probabilistic Temporal (APT) logic already present in this dissertation.
Although the previous chapter presented algorithms for consistency and entailment
problems that are sound and complete, they are not practical for general problems.
This chapter takes a more practical approach. We develop a fixpoint operator for
APT-logic that we prove to be sound. We can use this operator to correctly identify
many inconsistent APT-programs – although we cannot guarantee a program to be
consistent by this means. Additionally, this operator can infer probability ranges
for queries, but we cannot guarantee that they are the tightest possible bounds.
Most importantly, finding the fixpoint of this operator is efficient to compute. We
also show that some of the techniques can also be adopted in a sound algorithm for
non-ground APT-programs, where we only require a partial grounding.
We also implement an algorithm for the ground case and perform experiments on two data sets — the well known Minorities at Risk Organization Behavior
(MAROB) data set [10] that tracks behaviors of numerous terror groups, and another real-world data counter-insurgency data from the Institute for the Study of
War [72] (ISW). We used the algorithm APT-EXTRACT from the previous chapter

95

to automatically learn 23 APT-logic programs — no bias exists in these APT-logic
programs as no one manually wrote them. We then conducted experiments using
those APT-logic programs and entailment problems were solved on an average in
under 0.1 seconds per ground rule, while in the other, it took up to 1.3 seconds per
ground rule. Consistency was also checked in a reasonable amount of time. To the
best of our knowledge, ours is the first implementation of a system for reasoning
simultaneously about logic, time, and probabilities without making independence or
Markovian assumptions.
The chapter is organized as follows. Section 3.2 extends the syntax and semantics of APT LPs from the last chapter to add integrity constraints (ICs) as well
as probabilistic time formulas (ptf’s) – a generalization of the “annotated formulas”
from the previous chapter (also seen in [34]). Section 3.3 shows that consistency
and entailment in APT-logic are in-NP and in-coNP, respectively, matching the
hardness results from the previous chapter (identifying these respective problems as
NP-complete and coNP-complete). Section 3.4 describes our approximate fixpoint
algorithm which is based on a sound (but not complete) fixpoint operator. The
operator works by syntactically manipulating the rules in the APT-program to iteratively tighten the probability bounds of the formula whose entailment is being
checked. We adapt the techniques for a consistency-checking and entailment algorithms for non-ground APT-programs in Section 3.5 (note that these algorithms do
not require a full grounding of a program). In Section 3.6 we present our implementation of the fixpoint approach to solving consistency and entailment problems for
ground programs. Finally, in Section 3.7, we provide an overview of related work.
96

Before continuing, we note that applications such as those above use automated rule learning (e.g. using the APT-Extract algorithm of the previous chapter) to automatically learn relationships and correlations between atoms. In particular, the existence of specific such relationships make independence and Markovian
assumptions invalid for these types of applications.

97

pfr

1. sec rumor ∧ earn incr(10%) ֒→ stock decr(10%) : [2, 0.65, 0.97, 0.7, 1.0]
An SEC rumor and a rumor of an earnings increase leads to a stock price decrease
of 10% in 2 days with probability [0.65, 0.97].
pfr

2. sec rumor ∧ earn incr(10%) ֒→ stock decr(10%) ∧ cfo resigns : [2, 0.68, 0.95, 0.7, 0.8]
An SEC rumor and a rumor of an earnings increase of 10% leads to the CFO
resigning in exactly 1 days with a probability [0.5, 0.95].
3. OCC(cfo resigns) : [0, 1]
The CFO resigns between 0 and 1 times (i.e., [lo, up] = [0, 1]).
4. BLK(sec rumor) :< 4
An SEC rumor cannot be reported more than 3 days in a row (i.e., blk = 4).
5. (¬sec rumor ∧ ¬rum incr(10%) ∧ ¬stock decr(10%) ∧ ¬cfo resigns) : 1∧
(sec rumor ∧ rum incr(10%) ∧ ¬stock decr(10%) ∧ ¬cfo resigns) : 2∧
(sec rumor ∧ ¬rum incr(10%) ∧ stock decr(10%) ∧ ¬cfo resigns) : 3∧
(sec rumor ∧ rum incr(10%) ∧ ¬stock decr(10%) ∧ cfo resigns) : 4 : [1, 1]
Based on events that have already occured, we can state things such as “at day
1 there was no SEC rumor, there is no rumor of a stock increase, the stock price
did not decrease, and the CFO did not resign.”

Figure 3.1: Kstock , a toy APT-Logic Program about stocks.

98

ef r

1. detainment distr(2) ∧ detainment relig(1) ; attack relig(1):[2, 0.0906, 0.1906]
A detainment in district 2 and detainment in an area where religion 1 dominates
is followed by an attack in an area where religion 1 dominates within 2 days with
a probablilty [0.0906, 0.1906].
ef r

2. attack neigh(28) ∧ attack relig(1) ; cache relig(1):[7, 0.6833, 0.7833]
An attack in neighborhood 28 and an attack in an area where religion 1 dominates
is followed by a cache being found in an area where religion 1 dominates within
7 days with a probablilty [0.6833, 0.7833].
ef r

3. cache distr(2) ; detainment relig(2):[10, 0.6559, 0.7558]
Cache being found in district 2 is followed by a a detainment in an area where
religion 2 dominates within 10 days with a probablilty [0.6559, 0.7558].
ef r

4. detainment distr(2) ; attack distr(7):[10, 0.1346, 0.2346]
A detainment in district 2 is followed by a an attack in district 7 within 10 days
with a probablilty [0.1346, 0.2346].
ef r

5. attack neigh(28) ; detainment distr(2):[9, 0.5410, 0.6500]
An attack in neighborhood 28 is followed by a detainment in district 2 within 9
days with a probablilty [0.5410, 0.6500].
ef r

6. cache distr(5) ; strike relig(1):[8, 0.2833, 0.3833]
A cache found in disrict 5 is followed by a precision strike conudcted in an area
domnated by religion 1 within 8 days with a probablilty [0.2833, 0.3833].

Figure 3.2: KISW a real-world APT-Logic Program extracted from counterinsurgency data.
99

ef r

1. orgst1(1)∧orgst11(2)∧domorgviolence(2) ; armattack(1):[2, 0.95, 1]
Whenever education and propaganda are used as a minor strategy, coalition
building is used as a major strategy, and the group is using domestic violence
regularly by targeting security personnel (but not government non-security personnel or civilians), the group carries out armed attacks within two time periods
with probability at least 0.95.
ef r

2. orgst1(1)∧orgst11(2)∧domorgviolence(2) ; dsecgov(1):[3, 0.95, 1]
This rule has the same antecedent as the previous one, but the consequent stands
for the group targeting people working for the government in security, or in nonstate armed militias.
ef r

3. violrhetrans(0)∧orgst5(0)∧drug(0) ; armattack(1):[2, 0.58, 0.68]
Whenever the group does not justify targeting transnational entities in public statements, uses non-coercive methods to collect local support (as a minor
strategy), and does not engage in drug production/traficking, armed attacks are
carried out within two time periods with probability between 0.58 and 0.68.
ef r

4. orgst1(1)∧orgst11(2)∧orgst8(2) ; dsecgov(1):[3, 0.9500, 1]
Whenever education and propaganda are used as a minor strategy, coalition
building is used as a major strategy, and insurgencies are used as a major strategy,
the group targets people working for the government in security, or in non-state
armed militias, within 3 time periods with probability at least 0.95.

Figure 3.3: KMAROB a real-world APT-Logic Program extracted from Minorities at
Risk Organizational Behavior data.
100

3.2

Technical Background
This section extends the syntax and semantics of APT LPs from the previous

chapter to include integrity constraints, probabilistic time formulas, and non-ground
semantics for all previously introduced constructs.

3.2.1

Syntax

We assume the existence of a logical language L as specified in the previous
chapter (see page 26). We also assume the existence of a finite set F whose members are called frequency function symbols (see the previous chapter, page 32). A
(ground) term, atom, and formula are defined as per the previous chapter.
Also as in the last chapter, we assume that all applications are interested
in reasoning about an arbitrarily large, but fixed size window of time, and that
τ = {1, . . . , tmax } denotes the entire set of time points we are interested in. tmax can
be as large as an application user wants, and the user may choose his granularity of
time according to his needs.
We now extend the syntax with the definition of a “time formula.”
Definition 27 (Time Formula). A time formula is defined as follows:
• If F is a (ground) formula and t ∈ [1, tmax ] then F : t is an (ground) elementary
time formula.
• If φ, ρ are (ground) time formulas, then ¬φ, φ ∧ ρ, and φ ∨ ρ are (resp. ground)
time formulas.

101

Example 3.2.1. Consider the ground atoms in the APT-program from Figure 3.1.
The expression (¬sec rumor ∧ ¬rum incr(10%) ∧ ¬stock decr(10%) ∧ ¬cfo resigns) : 1
is an elementary time formula.
Throughout, we will use Greek letters φ, ρ for time formulas and capital letters
F, G for regular formulas. We now extend a time formula to include a probability
annotation.
Definition 28. If φ is a (ground) time formula and [ℓ, u] ⊆ [0, 1], then φ : [ℓ, u] is
a (resp. ground) probabilistic time formula, or ptf for short.
Note that when considering ptf ’s of the form F : t : [ℓ, u], we will sometimes
abuse notation and write F : [t, ℓ, u].
Example 3.2.2. Item 5 in the APT-program from Figure 3.1 is a ptf.
Intuitively, φ : [ℓ, u] says time formula φ is true with a probability in [ℓ, u].2
Our next extension to the syntax of the previous chapter are integrity constraints.
Definition 29 (Integrity constraint). Suppose Ai ∈ BL and [loi , upi ] ⊆ [0, tmax ].
Then OCC(Ai ) : [loi , upi ] is called an occurrence IC. If blki ∈ [2, tmax + 1] is an
integer, then BLK(Ai ) :< blki is called a block-size IC. If Ai is ground then the
occurrence (resp. block-size) IC is ground – otherwise it is non-ground.
An occurrence IC OCC(Ai ) : [loi , upi ] says that A must be true at least loi
times and at most upi times. Likewise, the block-size IC says that A cannot be
2

Assumption: Throughout the chapter we assume, for both ptf’s and APT-rules, that the

numbers ℓ, u can be represented as rationals a/b where a and b are relatively prime integers and
the length of the binary representations of a and b is fixed.

102

consecutively true for blki or more time points. Figure 3.1 also contains an example
occurrence IC and an example block-size IC.
Example 3.2.3 (Integrity Constraints). Consider the ground atoms in the APTprogram from Figure 3.1 and tmax = 6. Suppose historical data indicates that for a
sequence of 6 days, there is never more than 1 day where the CFO resigns. Hence,
we should add the constraint OCC(cfo resigns) : [0, 1] to the program. There are
other types of integrity constraints that could be useful in this domain. For example,
a drastic stock price decrease may never occur more than a few times a quarter.
To see why block-size constraints are natural, consider the ground atom sec rumor.
Suppose there is never more than 3 days historically where an SEC rumor is reported.
This would make the constraint BLK(sec rumor) :< 4 appropriate. Other examples
of such constraints in this domain would be reports of profits, which only occur once
per quarter (i.e., we would have blk = 2 for such a case).
We have automatically extracted APT-programs from the ISW and MAROB
data sets mentioned earlier. In the case of the ISW data set, occurrence and blocksize constraints are needed because militant groups have constrained resources, i.e.,
a limited amount of personnel and munitions to carry out an attack. Hence, an
occurrence integrity constraint can limit the amount of attacks we believe they are
capable of in a given time period. Likewise, such groups often limit the amount of
consecutive attacks, as police and military often respond with heightened security.
Block-size constraints allow us to easily encode this into our formalism.
We now extend the definition of APT rules and programs from the previous
103

chapter to include non-ground versions of these syntactic elements.
Definition 30 (APT Rules and Programs). (i) Suppose F , G are (ground) formulas,
∆t is a time interval, [ℓ, u] is a probability interval, and fr ∈ F is a frequency function
fr

symbol. Then F ; G : [∆t, ℓ, u] is an (ground) APT rule.
(ii) An (ground) APT logic program is a finite set of (ground) APT rules, ptf ’s, and
integrity constraints.
(iii) Given a non-ground APT-logic program K(ng) , the set of ground instances of all
rules, ptf ’s, and IC’s in K(ng) is called the grounding of K(ng) .
Note: Unless specified otherwise, throughout this chapter, APT-logic programs,
rules, IC’s, and ptf’s are ground.
Example 3.2.4. Figure 3.1 shows a small APT LP dealing with the stock market,
together with an intuitive explanation of each rule.

3.2.2

Semantics

We now extend the semantics of APT LPs from the previous chapter to account
for the extended syntax and the non-ground case. The structures of worlds and
threads are defined exactly as in the previous chapter (see page 29). However, here
we define a notion of a thread satisfying a time formula or integrity constraint as
follows:
Definition 31. (i) Given thread Th and ground time formula φ, we say Th satisfies φ (written Th |= φ) iff:
104

efr

1. at station(T, S1 ) ∧ adjEast(S1 , S2 ) ; at station(T, S2 ) : [4, 0.85, 1]
If train T is at station S1 and the station adjacent to it to the East is S2 , T will
be at station S2 within 4 time units with a probability bounded by [0.85, 1].
efr

2. at station(T, S1 ) ∧ adjWest(S1 , S2 ) ; at station(T, S2 ) : [2, 0.6, 0.7]
If train T is at station S1 and the station adjacent to it to the West is S2 , T will
be at station S2 within 2 time units with a probability in the interval [0.6, 7].
3.

Vtmax
t=1

Vtmax
t=1

adjEast(stnA, stnB) : t : [1, 1],
adjWest(stnB, stnA) : t : [1, 1],

Vtmax

Vtmax
t=1

t=1

adjEast(stnB, stnC) : t : [1, 1],

adjWest(stnC, stnB) : t : [1, 1]

Probabilistic time formulas specifying that Station B is (always) adjacent to the
East of A, and C is adjacent to the East of B.
4. at station(train1, stnA) : 1 : [0.5, 0.5]
For a given sequence of events, train 1 will be at station A at time period 1 with
a probability of 0.50.
5. at station(train2, stnA) : 2 : [0.48, 0.52]
For a given sequence of events, train 2 will be at station A at time period 2 with
a probability bounded by [0.48, 0.52].

Figure 3.4: Ktrain , a toy APT-Logic Program modeling rail transit. Items 1-2 are
non-ground APT-Rules, the formulas in 3 are probabilistic temporal formulas, and
items 4-5 are annotated formulas. The English translation of each rule is also provided.

105

• φ ≡ F : t: Th |= φ iff Th(t) |= F
• φ ≡ ¬ρ: Th |= φ iff Th 6|= ρ
• φ ≡ ρ ∧ ρ′ : Th |= φ iff Th |= ρ and Th |= ρ′
• φ ≡ ρ ∨ ρ′ : Th |= φ iff Th |= ρ or Th |= ρ′
(ii) Given thread Th and ground occurrence IC OCC(Ai ) : [loi , upi ], we say Th satisfies OCC(Ai ) : [loi , upi ] iff |{i | Th(i) |= Ai }| ∈ [loi , upi ].
(iii) Given thread Th and block-size IC BLK(Ai ) :< blki , we say Th satisfies
BLK(Ai ) :< blki iff there does not exist an interval [i, i + blki − 1] such that for
all j ∈ [i, i + blki − 1], Th(j) |= Ai .
(iv) Th satisfies a non-ground formula or IC iff it satisfies all ground instances of
it.
Given a set T of threads and a set IC of integrity constraints, we use T (IC)
to refer to the set {Th ∈ T |Th |= IC}.
We use the symbol ‘|=’ to denote entailment between two time formulas.
Definition 32. Given time formulas φ, ρ, we say: φ |= ρ iff ∀Th ∈ T s.t. Th |= φ,
it is the case that Th |= ρ.
If we view time formulas as sets of threads, we can think of φ |= ρ, as equivalent
to φ ⊆ ρ.
As in the previous chapter, a temporal probabilistic (tp) interpretation gives
us a probability distribution over all possible threads. Thus, a tp-interpretation I
assigns a probability to each thread. This reflects the probability that the world will
106

in fact evolve over time in accordance with what the thread says. We now define
what it means for a tp-interpretation to satisfy a ptf or integrity constraint.
Definition 33. (i) Given interpretation I and ptf φ : [ℓ, u], we say I satisfies
φ : [ℓ, u] (written I |= φ : [ℓ, u]) iff:
ℓ≤

X

Th∈T
Th|=φ

I(Th) ≤ u

(ii) Given interpretation I and occurrence IC OCC(Ai ) : [loi , upi ], we say I satisfies
OCC(Ai ) : [loi , upi ] (written I |= OCC(Ai ) : [loi , upi ]) iff ∀Th ∈ T s.t. Th 6|=
OCC(Ai ) : [loi , upi ], it is the case that I(Th) = 0.
(iii) Given interpretation I and block-size IC BLK(Ai ) :< blki , we say I satisfies
BLK(Ai ) :< blki (written I |= BLK(Ai ) :< blki ) iff ∀Th ∈ T s.t. Th 6|= BLK(Ai ) :<
blki , it is the case that I(Th) = 0.
(iv) Interpretation I satisfies a non-ground formula or IC iff it satisfies all ground
instances of it.
With the above definition, we now define a special type of ptf that can be used
to specify a set of threads that start with the same worlds – the intuition is based
on the idea of a prefix in [25].
Definition 34. For n ≤ tmax , let F1 , . . . , Fi , . . . , Fn be formulas s.t. each Fi is
satisfied by exactly one world. Then, the following ptf:
F1 : 1 ∧ · · · ∧ Fi : i ∧ . . . ∧ Fn : n : [1, 1]
is called a prefix.
107

Example 3.2.5. Item 5 in the APT-program from Figure 3.1 is a prefix.
Intuitively, including a prefix in an APT-program forces the first n worlds of
every thread assigned a non-zero probability to satisfy certain formulas. Further,
we can use a prefix to force the first n worlds of every thread with a non-zero
probability to be the same. For example, if we want the i’th world of thread Th to
be set to world w, we would simply use the following formula as Fi in the prefix:
V



V
¬a
.
a
∧
a∈w
/
a∈w

The definition of a frequency function is also exactly the same as in the previous

chapter. For the sake of simplicity, in this chapter we only use the existential
frequency function (also defined in the previous chapter). Most techniques in this
chapter can be easily extended for use with other frequency functions. Now we
extend the definition of satisifaction of APT rules to account for the non-ground
case.
fr

Definition 35 (Satisfaction of APT rules). Let r = F ; G : [∆t, ℓ, u] be an APT
rule and I be a tp-interpretation.
(i) If r is a ground rule, interpretation I satisfies r (denoted I |= r) iff
ℓ≤

X

Th∈T

I(Th) · fr(Th, F, G, ∆t) ≤ u.

(ii) Interpretation I satisfies a non-ground rule r iff I satisfies all ground instances
of r.
Interpretation I satisfies an APT-program iff it satisfies all rules, ptf’s, and
IC’s in that program. Given an APT-program K, we will often refer to the set of
integrity constraints in K as simply IC.
108

fr

Intuitively, the APT rule F ; G : [∆t, ℓ, u] evaluates the probability that
F leads to G in ∆t time units as follows: for each thread, it finds the probability
of the thread according to I and then multiplies it by the frequency (in terms of
fraction of times) with which F is followed by G in ∆t time units according to
frequency function fr. This product is like an expected value in statistics where a
value (frequency) is multiplied by a probability (of the thread). It then sums up
these products across all threads.

3.3

Complexity
In the previous chapter, we showed that consistency and entailment in APT-

logic are NP-hard (consistency) and coNP-hard (entailment). In this section, we
prove that consistency is in the complexity class NP and entailment is in the complexity class coNP. The result is somewhat surprising, because the exact algorithms
presented in the previous chapter relied on the solution to linear programs with an
exponential number of variables. For example, consider the following linear program.
Definition 36 (CONS). Given an APT-logic program, K, where IC ⊂ K is the
set of integrity constraints in K, we can create the linear constraints CONS(K) as
follows:

109

For each Th j ∈ T (IC), variable vj denotes the probability of thread Th j .
(1)

P|T (IC)|
j=1

vj = 1

fr

(2) ∀Fi ;i Gi : [∆ti , ℓi , ui ] ∈ K (a) ℓi ≤
(b) ui ≥
(3) ∀φi : [ℓi , ui ] ∈ K

(a) ℓi ≤
(b) ui ≥

P|T (IC)|
j=1

P|T (IC)|
j=1

P

fri (Th j , Fi , Gi , ∆ti ) · vj
fri (Th j , Fi , Gi , ∆ti ) · vj

Th j ∈T (IC) Th |=φ
j
i

P

Th j ∈T (IC) Th |=φ
j
i

vj
vj

We proved in the previous chapter that there is a solution to CONS(K) iff K
is consistent and that, given ptf φ : [ℓ, u], let L be the minimization and U be the
maximization of

P

Th j ∈T (IC) Th |=φ
j

vj subject to CONS(K). Then φ : [ℓ, u] is entailed

by K iff [L, U ] ⊆ [ℓ, u]. See Proposoiton 3 (page 50) and Proposition 12 (page 73)
respectiely.
However, it turns out that we can be guaranteed a solution to the linear
program where only a polynomial number of the variables are set to a value other
than 0. Consider the following theorem from [24] and later used in [44] to show that
deciding the validity of a formula in the logic of [44] is NP-Complete.
Theorem 9 ([24, 44]). If a system of m linear equalities and/or inequalities has
a nonnegative solution, then it has a nonnegative solution with at most m positive
variables.
We can leverage the previous two results to guarantee the existence of an
interpretation that assigns a zero probability to all but a polynomial number of
threads, thus giving us a “small model” theorem.

110

Theorem 10. Deciding if APT-program K is consistent is NP-complete if |K| is a
polynomial in terms of |BL |.
Theorem 11. Deciding if APT-rule r is entailed by APT-program K is coNPcomplete if |K| is a polynomial in terms of |BL |.
One may wonder if APT-programs can be made more tractable if we assume
a single probability distribution over threads, that is a single tp-interpretation. Unfortunately, even if we assume a uniform probability distribution, this special case
is still not tractable.
Theorem 12. Given APT-program K, interpretation I, and ptf φ, determining the
maximum ℓ and minimum u such that φ : [ℓ, u] is entailed by K and is satisfied by
I is #P -hard. Furthermore, for constant ǫ > 0, approximating either the maximum
ℓ and/or minimum u within 2|BL |

1−ǫ

is NP-Hard.

The above theorem is proved using an interpretation that assigns a uniform
probability across all threads. The negative approximation result follows from a
result of [145].
Although it remains an open question if the APT-entailment problem (without
the single-interpretation requirement) can be approximated within a reasonable factor, the above result is not encouraging.3 Further, Definition 36 illustrates several
challenges relating the intractability of this problem. (i) First, we need to compute
T (IC), which is a challenge because T contains 2tmax ·card(BL ) possible threads and
3

As an aside, as the construction in the proof of Theorem 12 does not depend on multiple

time-points, this result holds for the probabilistic logic of [131] as well.

111

each must be examined to see if it satisfies IC; (ii) Second, the constraints in items

(1-2) may contain up to O 2tmax ·card(BL ) variables (this bound can be tightened), so

even though linear programming is polynomial [79], the input is exponential in the
size of tmax and BL . In practice, even if we consider tmax = 10 and BL to consist of
just 100 ground atoms, we are looking at the possibility of examining 21,000 threads
to find T (IC) and writing constraints containing exponentially large numbers of
variables. In practice, we will not be able to even write these constraints. With
these intractability results in mind, we proceed to develop heuristics in the next two
sections.

3.4

A Sound but Incomplete Fixpoint-Computation
Algorithm: The Ground Case
This section presents a heuristic algorithm based on a fixpoint operator Γ

which maps APT-programs to APT-programs and iteratively tightens the probability
bounds on rules and ptf’s in the program. To find probability bounds on some time
formula φ, we simply add the ptf φ : [0, 1] to the program, iteratively apply Γ until
a fixed point is reached, and then examine the bounds on the ptf formed with φ in
the resulting program. Our approach is sound – so, if the interval [ℓ, u] is assigned
to φ, then K entails φ : [ℓ, u] (provided, of course, that K is consistent). However,
there may exist some [ℓ′ , u′ ] ⊂ [ℓ, u] such that φ : [ℓ′ , u′ ] is also entailed.
Our algorithm requires that K contain at least one APT-rule of the form

112

F : [ℓ, u]. This is not really a restriction in most applications where a prefix would
exist (cf. Definition 34, Page 107). The rest of the section is organized as follows.
Section 3.4.1 describes how to find bounds on a frequency function given ptf ’s.
Section 3.4.2 describes how to use frequency bounds to syntactically manipulate
rules and ptf’s in APT-programs – which in turn allow us to tighten the probability
bounds. Section 3.4.3 performs various syntactic manipulations in the Γ operator
and shows that the operator has a least fixed point. Finally, Section 3.4.4 demonstrates how Γ can also be used to check the consistency of an APT logic program.
Again, such a consistency check is sound but not complete – Γ correctly identifies
inconsistent programs but does not guarantee consistency.

3.4.1

Bounding Frequency Function Values

In this chapter, we only use the efr frequency function. However, our techniques can be easily adapted to other frequency functions such as pfr from the previous chapter. Our first definition is a function, EF R, which returns tight bounds
on efr given F, G, and ∆t.
Definition 37. Suppose F, G are formulas, ∆t is a time point, and φ is a time
formula. We define EF R(F, G, ∆t, φ) = [αtight , βtight ] where
αtight = inf {ef r(Th, F, G, ∆t) | Th ∈ T ∧ Th |= φ}.
βtight = sup{ef r(Th, F, G, ∆t) | Th ∈ T ∧ Th |= φ}.
The intuition in the above definition is that αtight is the least value of ef r
(w.r.t. formulas F, G and time interval ∆t) for all threads satisfying φ. Likewise,
113

βtight is the greatest value of ef r (w.r.t. formulas F, G and time interval ∆t) for all
threads satisfying φ. We can easily approximate [αtight , βtight ] when we make certain
assumptions on φ. Consider the following special case of a ptf:
Definition 38. Suppose ET F ≡ {F1 : t1 , . . . , Fn : tn } is a set of elementary time
formulas, where n ≤ tmax and for any two such formulas, Fi : ti , Fj : tj ∈ ET F ,
ti 6= tj . Then F1 : t1 ∧ . . . ∧ Fn : tn is a time conjunction.
Example 3.4.1. Item 5 in the APT-program from Figure 2.1 is a time-conjunction.
We shall refer to this time-conjunction as φstock in later examples.
We notice right away that a prefix (Definition 34, Page 107) is simply a special
case of time conjunction annotated with probability [1, 1]. One useful property of
time conjunctions that we leverage in our operator is the following.
Observation 3.4.1. If F1 : t1 ∧ . . . ∧ Fn : tn ∧ Fn+1 : t′1 ∧ . . . ∧ Fn+m : t′m and
G1 : t1 ∧ . . . ∧ Gn : tn ∧ Gn+1 : t′′1 ∧ . . . ∧ Gn+k : t′′k are time conjunctions, then
(F1 ∧G1 ) : t1 ∧. . .∧(Fn ∧Gn ) : tn ∧Fn+1 : t′1 ∧. . .∧Fn+m : t′m ∧Gn+1 : t′′1 ∧. . .∧Gn+k : t′′k
is also a time conjunction.
We leverage the above property in the following way: if we know a bound for
EF R(F, G, ∆t, φ) and EF R(F, G, ∆t, φ ∧ ρ), we may be able to use this information
to find probability bounds on ρ. We will describe this further when we discuss
syntactic manipulation. Next, with a time conjunction in mind, we will show how
to find a tight bound on EF R. In this case, we introduce the following notation
and obtain a bound on EF R in Proposition 14.
114

Definition 39. For formulas F, G, time ∆t, and time conjunction φ, we define the
following:
• cnt(φ, F, G, ∆t) = |{t ∈ [1, tmax − ∆t]|∃t′ ∈ (t, t + ∆t] s.t. (φ |= F : t ∧ G : t′ )}|
• end(φ, F, G, ∆t) = |{t ∈ (tmax − ∆t, tmax )|∃t′ ∈ (t, tmax ] s.t. (φ |= F : t ∧ G : t′ )}|
• denom(φ, F, ∆t) = |{t ∈ [1, tmax − ∆t]|∃Th s.t. (Th |= φ) ∧ (Th |= F : t)}|
• poss(φ, F, G, ∆t) = |{t ∈ [1, tmax − ∆t]|∃t′ ∈ (t, t + ∆t] s.t. ∃Th s.t. (Th |=
φ) ∧ (Th |= F : t ∧ G : t′ )}|
• endposs(φ, F, G, ∆t) = |{t ∈ (tmax − ∆t, tmax )|∃t′ ∈ (t, tmax ] s.t. ∃Th s.t. (Th |=
φ) ∧ (Th |= F : t ∧ G : t′ )}|
The intuitions behind the components of Definition 39 are as follows. For a
given F, G, ∆t, cnt is simply the number of times in the first tmax − ∆t timesteps (of
all threads satisfying some ptf φ) where a world satisfying F is followed by a world
satisfying G within ∆t time units. Likewise, end performs this count for the last
∆t time units. Similarly, poss and endposs perform similar calculations, but rather
than considering all threads that satisfy φ, there must only exist a thread satisfying
φ where a world satisfying F is followed by a world satisfying G in ∆t time units.
The definition of denom captures the total number of times F is satisfied in the first
tmax − ∆t worlds (for all threads satisfying φ). Due to the boundary condition of
ef r (refer to Section 3.2 for details), we use end and endposs to perform this count
in the last tmax − ∆t worlds of the threads. Hence, in the below proposition, we are

115

able to show that EF R(F, G, ∆t, φ) is a subset of two fractions created from the
components we defined.
Proposition 14. For formulas F, G, time ∆t, and time conjunction φ,
EF R(F, G, ∆t, φ) ⊆


cnt(φ, F, G, ∆t) + end(φ, F, G, ∆t) poss(φ, F, G, ∆t) + endposs(φ, F, G, ∆t)
,
denom(φ, F, ∆t) + end(φ, F, G, ∆t) denom(φ, F, ∆t) + endposs(φ, F, G, ∆t)



Example 3.4.2. Consider the APT-program from Figure 2.1 that includes time
conjunction φstock (see Example 3.4.1). Consider the pre and post conditions of
rules 1-2; we shall refer to them as follows (in this and later examples):
F1 ≡

sec rumor ∧ rum incr(10%)

G1 ≡

stock decr(10%)

F2 ≡

sec rumor ∧ rum incr(10%)

G2 ≡ stock decr(10%) ∧ cfo resigns
Using Definition 39, we can determine that:
EFR(φstock , F1 , G1 , 2) ⊆ [0.5, 1.0]
and
EFR(φstock , F2 , G2 , 1) ⊆ [0.0, 0.667]

3.4.2

Theorems for Syntactic Manipulation

In the last section, we bounded the values that ef r can have for a thread
given some time formula φ. This section leverages that information to obtain tighter
116

bounds on ptf’s and APT-rules. First, we introduce a simple result that allows for
syntactic manipulation of ptf’s without these bounds.
Lemma 8. Let ρ : [ℓ′ , u′ ] be a ptf and I be an interpretation; then:
1. If I |= φ : [ℓ, u], then I |= φ ∧ ρ : [max(0, ℓ + ℓ′ − 1), min(u, u′ )]
2. If I |= φ : [ℓ, u], then I |= φ ∨ ρ : [max(ℓ, ℓ′ ), min(1, u + u′ )]
3. If I |= φ : [ℓ, u] and φ |= ρ then I |= ρ : [ℓ, 1]
4. If I |= φ : [ℓ, u] and ρ |= φ then I |= ρ : [0, u]
5. If I |= φ : [ℓ, u] then I |= ¬φ : [1 − u, 1 − ℓ]
Example 3.4.3. Suppose program Kstock entails ptf sec rumor : 6 : [0.3, 0.6]. Then,
it also entails ¬sec rumor : 6 : [0.4, 0.7].
We notice right away that syntactic manipulation sometimes identifies inconsistent APT-programs. For example, if φ : [0.7, 0.6] is entailed via Lemma 8, then
we know that K is not consistent. We explore this issue further in Section 3.4.4.
Next, we use the bounds on EF R to syntactically manipulate APT-rules, yielding
rules with tighter probability bounds – perhaps uncovering an inconsistent program.
Theorem 13 tightens the bound when the APT-program includes a ptf that happens
with probability 1. Its corollary tightens the lower bound given any ptf .
Theorem 13. Suppose I is an interpretation and φ is a time formula such that
ef r

I |= φ : [1, 1] and EF R(F, G, ∆t, φ) ⊆ [α, β]. Then I |= F ; G : [∆t, α, β].

117

Corollary 2. Suppose I is an interpretation and φ is a time formula such that
ef r

I |= φ : [ℓ, u] and EF R(F, G, ∆t, φ) ⊆ [α, β]. Then I |= F ; G : [∆t, α · ℓ, 1].
The above theorem and corollary are proved by showing that the lower probability bound of an APT-rule has to be at least as much as the lower bound on the
associated EF R for all threads.
Example 3.4.4. Consider the scenario from Example 3.4.2. By the result of that
example and Corollary 2, we know that Kstock must entail:
efr

sec rumor ∧ rum incr(10%) ; stock decr(10%) : [2, 0.5, 1.0] and
efr

sec rumor ∧ rum incr(10%) ; stock decr(10%) ∧ cfo resigns : [1, 0.0, 0.667]
Note that we can now find a tighter bound on rule 2, obtaining a probability bound
of [0.5, 0.667], that is substantially tighter than [0.5, 1] from the original rule using
just one syntactic manipulation.
We can use APT-rules, EF R, and Theorem 8 to further tighten the bounds
on ptf’s with the following theorem.
Theorem 14. Suppose F, G are formulas, φ, ρ are time formulas, I is an interpretation, and [α1 , β1 ], [α2 , β2 ] are intervals such that EF R(F, G, ∆t, φ) ⊆ [α1 , β1 ] and
ef r

EF R(F, G, ∆t, φ∧ρ) ⊆ [α2 , β2 ], I |= φ : [1, 1] (see note4 ) and I |= F ; G : [∆t, ℓ, u].
Then:
h

1. If β2 < β1 , then I |= ρ : 0, min
4



ℓ−β1
,1
β2 −β1

i

Note that Theorem 13 requires ℓ ≤ β1 and α1 ≤ u

118

i
h

1
,
1
2. If α2 > α1 , then I |= ρ : 0, min αu−α
2 −α1
From the above theorem, we can easily obtain the following corollary that can
be used with just one time formula (i.e., only ρ). Simply consider the case where φ
is TRUE : tmax and [α1 , β1 ] = [0, 1].
Corollary 3. Suppose F, G are formulas, ρ is a time formula, I is an interpretation,
ef r

and [α, β] is an interval such that EF R(F, G, ∆t, ρ) ⊆ [α, β] and I |= F ; G :
[∆t, ℓ, u]. Then:
ℓ−1
, 1)]
1. If β < 1 then I |= ρ : [0, min( β−1

2. If α > 0 then I |= ρ : [0, min( αu , 1)]
Example 3.4.5. Following from Example 3.4.4, consider the time-formula stock decr(10%) :
5. Using Definition 39, we find that EFR(φstock ∧ stock decr(10%) : 5, F1 , G1 , 2) ⊆
[1, 1]. Previously, we saw that EFR(φstock , F1 , G1 , 2) ⊆ [0.5, 1]. As the lower bound
on frequency increases (by conjuncting the new time formula), that is 1 > 0.5, we
apply part 2 of Theorem 14 (and/or Corollary 3) to obtain an upper probability
bound on stock decr(10%) : 5. Hence, this formula is no more probable than 0.94.
Finally, we show that we can also use integrity constraints to aid in syntactic
manipulation. For certain ptf’s with probability 1, a given IC may cause another ptf
(or multiple ptf’s) to be entailed with a probability of 0, which can also contribute
to bounding EF R.
Proposition 15. For atom Ai and program K where BLK(Ai ) :< blki ∈ K, if there
exists a ptf φ : [1, 1] ∈ K such that φ |= Ai : t−blki +1∧Ai : t−blki +2∧. . .∧Ai : t−1,
119

then K entails Ai : t : [0, 0].
Proposition 16. For atom Ai and program K where OCC(Ai ) : [loi , upi ] ∈ K, if
there exists a ptf φ : [1, 1] ∈ K such that there are numbers t1 , . . . , tupi ∈ {1, . . . , tmax }
where φ |= Ai : t1 ∧. . .∧Ai : tupi then for any t ∈
/ {t1 , . . . , tupi } K entails Ai : t : [0, 0].
Example 3.4.6. Consider Kstock from the previous examples. As this program includes OCC(cfo resigns) : [0, 1] and entails cfo resigns : 4 : [1, 1] (by the included
prefix), we can conclude that cfo resigns : 5 : [0, 0] and cfo resigns : 6 : [0, 0] are
entailed by this program.

3.4.3

The Fixpoint-Based Heuristic

We are now ready to use the results of the last section to create the Γ operator.
First, we present some preliminary definitions to tighten probability bounds for ptf’s
and rules. Note that the correctness of these bounds follows directly from the results
of the previous section. First we show how, given an APT-program, we can tighten
the lower and upper bound of a ptf.
Definition 40. Suppose K is an APT-program and φ is a time formula. We define:
l bnd(φ, K) = sup ( { 0 } ∪ { ℓ | ρ : [ℓ, u] ∈ K ∧ (ρ |= φ) }) .

120

u bnd(φ, K) is the inf of the set:
{

1

}∪

{

u

| ρ : [ℓ, u] ∈ K ∧ (φ |= ρ) } ∪

{

ef r

1
min( βℓ−β
, 1) | (F ; G : [∆t, ℓ, u], ρ : [1, 1] ∈ K ∪ {true : tmax : [1, 1]}) ∧
2 −β1

(EF R(F, G, ∆t, ρ) ⊆ [α1 , β1 ]) ∧
(EF R(F, G, ∆t, ρ ∧ φ) ⊆ [α2 , β2 ]) ∧ (β2 < β1 ) } ∪
ef r

1
{ min( αu−α
, 1) | (F ; G : [∆t, ℓ, u], ρ : [1, 1] ∈ K ∪ {true : tmax : [1, 1]}) ∧
2 −α1

(EF R(F, G, ∆t, ρ) ⊆ [α1 , β1 ]) ∧
(EF R(F, G, ∆t, ρ ∧ φ) ⊆ [α2 , β2 ]∧ (α2 > α1 ) }

This bound on a time formula is derived from its relationship with other time
formulas (by Lemma 8) or it relationship with rules (by Theorem 14 and/or Corollary 3). Below we show an example.
Example 3.4.7. Following from Example 3.4.5, consider, once again, the timeformula stock decr(10%) : 5. For program Kstock , we know that l bnd(stock decr(10%) :
5, Kstock ) = 0.0. This is due to the simple fact that there is no lower probability bound
assigned to the time formula stock decr(10%) : 5 by Kstock that is greater than 0.0.
Examining the upper bound, we consider the inf of set {1, 0.94} as 1 is the trivial
upper bound, there are no other upper probability bounds for stock decr(10%) : 5 seen
directly in Kstock and we have already used Example 3.4.5 to derive the upper bound
of 0.94 based on syntatic manipulation of rules in Kstock (which reflects the last two
121

parts of the u bnd definition). Hence, u bnd(stock decr(10%) : 5, Kstock ) = 0.94.
Note that for ptf’s we do not include any manipulation that relies on the
bounds of the negated time formula in the above definitions. We handle this type
of manipulation in the definition of the operator. The following are versions of
l bnd, u bnd for rules.
Definition 41. Suppose K is an APT-program, F, G are formulas, and ∆t > 0 is
an integer.
• The quantity l bnd(F, G, ∆t, K) is the sup of the following set:
{

0

}∪

{

ℓ

| F ; G : [∆t, ℓ, u] ∈ K } ∪

{

α·ℓ

ef r

| (φ : [ℓ, u], ρ : [1, 1] ∈ K ∪ {true : tmax : [1, 1]}) ∧
(EF R(F, G, ∆t, ρ ∧ φ) ⊆ [α, β]) } ∪

{ α · (1 − u) | (φ : [ℓ, u], ρ : [1, 1] ∈ K ∪ {true : tmax : [1, 1]}) ∧
(EF R(F, G, ∆t, ρ ∧ ¬φ) ⊆ [α, β]) }

• The quantity u bnd(F, G, ∆t, K) is the inf of the following set:
{

1

}∪

{

u | F ; G : [∆t, ℓ, u] ∈ K } ∪

{

β | (ρ : [1, 1] ∈ K) ∧ (EF R(F, G, ∆t, ρ) ⊆ [α, β]) }

ef r

122

Hence, the new probability bound assigned to a rule is based on how the
bounds on the frequency function are tightened given the ptf’s present in the program. Given a ptf, we use a bound on EF R, which allows us to leverage Theorem 13
and Corollary 2 to obtain a tighter bound on the rule. Tighter bounds on rules are
useful for two reasons: (1) subsequent applications of the fixpoint operator will in
turn use these new bounds to tighten bounds on ptf’s and (2) they can be used to
identify inconsistent program (as we discuss in Section 3.4.4).

We now define set formula(K) which intuitively means “all time formulas that
appear in K”. These are the formulas upon which Definition 40 will act, and also
through syntactic manipulation, affect other ptf’s in K. As stated earlier, we can
find bounds for any time formula ρ by adding ρ : [0, 1] to the initial APT program.
Definition 42. Given program K consisting of ptf ’s and constrained rules, formula(K)
is the following set:
{
{

φ

| φ : [ℓ, u] ∈ K } ∪
ef r

F : t | (t ∈ [1, tmax ]) ∧ (F ; G : [∆t, ℓ, u] ∈ K) } ∪
ef r

{ G : t | (t ∈ [1, tmax ]) ∧ (F ; G : [∆t, ℓ, u] ∈ K) }

We now have all the pieces we need to define our operator Γ.

123

Definition 43. Given program K, Γ(K) is defined as the following set:
{

ef r

F ; G : [∆t, l bnd(F, G, ∆t, K),
ef r

u bnd(F, G, ∆t, K)]
{

| F ; G : [∆t, ℓ, u] ∈ K } ∪

φ : [l bnd(φ, K), u bnd(φ, K)]∩
[1 − u bnd(¬φ, K), 1 − l bnd(¬φ, K)] | φ ∈ formula(K) } ∪

{

| (BLK(Ai ) :< blki ∈ K) ∧ (φ : [1, 1] ∈ K) ∧

Ai : t : [0, 0]

(φ |= Ai : t − blki + 1 ∧ . . . ∧ Ai : t − 1)} ∪
{

| (OCC(Ai ) : [loi , upi ] ∈ K) ∧ (φ : [1, 1] ∈ K) ∧

Ai : t : [0, 0]

(∃t1 , . . . , tupi ∈ {1, . . . , tmax }) ∧
(φ |= Ai : t1 ∧ . . . ∧ Ai : tupi ) ∧
(t ∈
/ {t1 , . . . , tupi })} ∪
{

BLK(Ai ) :< blki

| BLK(Ai ) :< blki ∈ K} ∪

{

OCC(Ai ) : [loi , upi ]

| OCC(Ai ) : [loi , upi ] ∈ K}

Intuitively, Γ tightens the probability bounds on rules by leveraging probabilistic time formulas using the results we proved in Theorem 13 and Corollary 2. It
tightens the probability bounds on time formulas based other time formulas, rules,
and integrity constraints. This uses the results proved in Lemma 8, Theorem 14
(and/or Corollary 3), and Propositions 15-16 respectively.
Example 3.4.8. Consider the program Kstock from the previous examples. By Definition 42, we know that a ptf time-formula stock decr(10%) : 5 will be included in
Γ(Kstock ). We saw in Example 3.4.7 that l bnd(stock decr(10%) : 5, Kstock ) = 0.0
124

and u bnd(stock decr(10%) : 5, Kstock ) = 0.94. In the same manner, we can compute that l bnd(¬stock decr(10%) : 5, Kstock ) = 0.0 and u bnd(¬stock decr(10%) :
5, Kstock ) = 0.667 (this follows from the fact that EFR(φstock ∧ ¬stock decr(10%) :
5, F1 , G1 , 2) ⊆ [0.5, 0.667]). Hence, we know that the ptf stock decr(10%) : 5 :
[0.333, 0.94] is included in Γ(Kstock ).
Note that Γ returns an APT-program that is satisfied by the exact same set of
interpretations as the original program; this follows directly from the results in the
previous section.
Proposition 17. Suppose I is an interpretation and K is an APT-program. Then:
I |= K iff I |= Γ(K).
We can also make the following statement about the complexity of the operator.
Proposition 18. One iteration of Γ can be performed in time complexity O(|K|2 ·
CHK) where CHK is the bound on the time it takes to check (for arbitrary time
formulas φ, ρ) if φ |= ρ is true.
One source of complexity is comparing ptf’s with other ptf’s. If a ptf is formed
with an elementary time formula, then it only needs to be compared to other ptf’s
that share the same time point – this could reduce complexity. As is usual in logic
programming, Γ can be iteratively applied as follows.
Definition 44. We define multiple applications of Γ as follows.
• Γ(K) ↑ 0 = K
125

• Γ(K) ↑ (i + 1) = Γ(Γ(K) ↑ i)
Now, we will show that Γ has a least fixed point. First, we define a partial
ordering of APT-programs.
Definition 45 (Preorder over APT-Programs). Given K1 , K2 , we say K1 ⊑pre K2 if
and only if:
• ∀φ : [ℓ, u] ∈ K1 , ∃φ : [ℓ′ , u′ ] ∈ K2 s.t. [ℓ′ , u′ ] ⊆ [ℓ, u]
ef r

ef r

• ∀F ; G : [∆t, ℓ, u] ∈ K1 , ∃F ; G : [∆t, ℓ′ , u′ ] ∈ K2 s.t. [ℓ′ , u′ ] ⊆ [ℓ, u]
• If BLK(Ai ) :< blki ∈ K1 , then BLK(Ai ) :< blki ∈ K2
• If OCC(Ai ) : [loi , upi ] ∈ K1 , then OCC(Ai ) : [loi , upi ] ∈ K2
The intuition behind the above definition is that program K1 is below K2 if it
has less rules or ptf’s – or rules/ptf’s with tighter probability bounds. Note that if
K2 is above K1 , then K1 has at least as many satisfying interpretations, and possibly
more, than K2 . Let P ROGBL ,tmax be the set of all APT-programs given Herbrand
base BL and time tmax . It is easy to see that hP ROGBL ,tmax , ⊑pre i is a reflexive and
transitive, and therefore a preorder. In the following, we will say that K1 ∼ K2 ,
read “K1 is equivalent to K2 ” if and only if K1 ⊑pre K2 and K2 ⊑pre K1 . The “∼”
relation is clearly an equivalence relation; we will use [K] to denote the equivalence
class corresponding to K w.r.t. this relation.
Definition 46 (Partial Ordering of APT-Programs). Given two equivalence classes
[K1 ], [K2 ] w.r.t. relation ∼, we say [K1 ] ⊑ [K2 ] if and only if K1 ⊑pre K2 .
126

The “⊑” relation is clearly reflexive, antisymmetric, and transitive, and therefore a partial order over sets of APT-programs. Note that when we use the symbol
⊑, we will often write K1 ⊑ K2 as shorthand for [K1 ] ⊑ [K2 ]. We will also overload
the symbol P ROGBL ,tmax to mean “all equivalence classes of APT-programs” (for
a given tmax and BL ) where appropriate. Therefore, we can now define a complete
lattice, where the top element is a set containing all inconsistent programs, and the
bottom element is set containing the empty program.
Lemma 9. Given ⊥ = {∅} and ⊤ = {K | K is inconsistent}, then the partial order
hP ROGBL ,tmax , ⊑i defines a complete lattice.
What remains to be shown is that Γ is monotonic; if this holds, we can state
it has a least fixed point.
Lemma 10. K ⊑ Γ(K).
Lemma 11. Γ is monotonic.
By the Tarski-Knaster theorem, Γ has a least fixed point.
Theorem 15. Γ has a least fixed point.

3.4.4

Using Γ for Consistency Checking

As noted earlier, the Γ operator can be used to find “loose” entailment bounds
by simply adding an entailment time formula (φ) with probability bounds [0, 1] to
the logic program, and then examining the tightened bounds after one or more
applications of the operator. In this section, we examine how to use Γ for consistency
checking. First, we have a straightforward lemma on consistency.
127

ef r

Lemma 12. Let K be an APT-logic program that entails rule F ; G : [∆t, ℓ, u] or
φ : [ℓ, u] such that one of the following is true:
•ℓ>u
• ℓ < 0 or ℓ > 1
• u < 0 or u > 1.
Under this circumstance, K is inconsistent, i.e., there is no interpretation I such
that I |= K.
The following result follows immediately.
Corollary 4. Let K be an APT-logic program whetre there exists natural number i
ef r

such that Γ(K) ↑ i entails rule F ; G : [∆t, ℓ, u] or φ : [ℓ, u] such that one of the
following is true:
•ℓ>u
• ℓ < 0 or ℓ > 1
• u < 0 or u > 1.
Under this circumstance, K is inconsistent.
We note that the Γ adds time formulas whose probaiblity bounds is determined
by an intersection operation. We observe that an empty intersection of the probability bounds is equivalent to the case where ℓ > u, which allows us to apply the
above corollary to correctly state that the program is not consistent. We illustrate
this in the below example.
128

Example 3.4.9. Consider Kstock from the previous examples. By the definition of Γ,
the ptf stock decr(10%) ∧ cfo resigns : 5 : [0.499, 1] is in Γ(Kstock ). By Example 3.4.6,
we know that cfo resigns : 5 : [0, 0] is also in Γ(Kstock ). However, another application
of Γ entails cfo resigns : 5 : [0.499, 0] (equivalently, cfo resigns : 5 : ∅). As 0.499 > 0,
we know that Kstock is not consistent.
In addition to checking consistency with the Γ operator, we can check for
inconsistencies based on the block and occurence ICs via the following result.
Proposition 19. If there does not exist at least one thread that satisfies all integrity
constraints in an APT-logic program, then that program is inconsistent.
The Thread Existence Problem (ThEX) problem is that of checking existence of a thread that satisfies all block and integrity constraints. Here we show
that ThEX can be solved in constant time – this can allow us to quickly identify
certain inconsistencies in an APT-program. First, we define a partial thread.
Definition 47. A partial thread PTh is a thread such that for all 1 ≤ i ≤ tmax ,
PTh(i) is a singleton set.
For any ground atom Ai with a single associated block-size and occurrence
m
l
max
worlds must satisfy Ai in each partial thread,
constraint5 if more than (blki −1)·t
blki

then all partial threads will have a block of size blki . This allows us to derive the
following results.
5

There is no loss of generality looking at just one block-size IC per ground atom as multiple

such ICs can be coalesced into one by taking the minimum; likewise, there is no loss of generality
in considering just one occurrence per ground atom as they can be merged into one by intersecting
the [lo, up] intervals for that atom.

129

Proposition 20. If loi >

l

(blki −1)·tmax
blki

m

then there does not exist a partial thread for

ground atom Ai such that the single block-size and occurrence IC associated with Ai
hold.
l
m
max
Proposition 21. For ground atom Ai (with associated ICs), if upi > (blki −1)·t
blki
hl
m
i
(blki −1)·tmax
we know that the number of worlds satisfying Ai cannot be in the range
, upi .
blki
The reason for this is simple: it would force the partial thread to have a
sequence of blki consecutive worlds satisfying Ai . We also notice that these checks
can be performed based solely on the values of loi , upi , blki , and tmax . Hence, we
have the following proposition.
Proposition 22. ThEX can be solved in constant time.
In the next section we extend these results for non-ground APT-programs.

3.5

Consistency and Entailment Algorithms for
Non-Ground Programs
The fixpoint procedure described via the Γ operator works in the ground case.

In this section, we study how we may avoid grounding. We start (Section 3.5.1)
with a sampling based approach for consistency checking of non-ground programs.
Section 3.5.2 defines a non-ground fixpoint operator for entailment queries. This
operator avoids grounding the entire program, but guaranteed to provide entailment
bounds for a query that are as tight as our ground operator. We remind the reader

130

that both our consistency-checking algorithm and our fixpoint operator presented
in this section are sound, but not complete.

3.5.1

Consistency Checking for Non-Ground Programs

In this section, we present a sound algorithm for consistency checking of nonground programs. We avoid complete grounding of the rules, while still maintaining
soundness of the algorithm through random sampling of ground instances of rules.
The larger the sample, the more potential inconsistencies can be found.
For a non-ground time formula, φng , we shall use the notation gnd(φng ) to
refer to the ground formula

V

{φ | is a ground instance of φng }. We are now ready

to describe a non-ground analog to the bounds EF R described in the previous
section.
Definition 48. For non-ground formulas Fng , Gng , time ∆t, and non-ground time
formula φng , we define
1.
{EF R(F, G, ∆t, gnd(φng ))|

EF R SET (Fng , Gng , ∆t, φng ) =

F, G are ground instances of Fng , Gng }
2.
EF R IN (Fng , Gng , ∆t, φng ) = (αin , βin )
Where ∃[αin , β ′ ], [α′ , βin ] ∈ EF R SET (Fng , Gng , ∆t, φng ), and 6 ∃[α∗ , β ′′ ], [α′′ , β ∗ ] ∈
EF R SET (Fng , Gng , ∆t, φng ) s.t. α∗ > αin and β ∗ < βin
131

3.
EF R OU T (Fng , Gng , ∆t, φng ) = [αout , βout ]
Where ∃[αout , β ′ ], [α′ , βout ] ∈ EF R SET (Fng , Gng , ∆t, φng ), and 6 ∃[α∗ , β ′′ ], [α′′ , β ∗ ] ∈
EF R SET (Fng , Gng , ∆t, φng ) s.t. [α∗ , β ∗ ] ⊃ [αout , βout ]
The intuition behind Definition 48 is as follows. EF R SET is the set of all
frequency bounds for the different ground instances of Fng , Gng . EF R IN is a pair
consisting of the greatest lower bound of ef r (αin ) and the least upper bound of
ef r (βin ) of all the elements of EF R SET . (αin , βin ) is a tuple, not a bound. It is
possible for αin > βin . EF R OU T represents the tight bound of ef r for any ground
instance of Fng , Gng . We now prove these bounds to be tight.
Lemma 13. Suppose Fng , Gng are non-ground formulas, time ∆t > 0 is an integer,
and φng is a non-ground time formula. Let (αin , βin ) = EF R IN (Fng , Gng , ∆t, φng )
and [αout , βout ] = EF R OU T (Fng , Gng , ∆t, φng ). If Th |= φng , then:
1. for all ground instances F, G of Fng , Gng we have efr(F, G, ∆t, Th) ∈ [αout , βout ]
2. there exist ground instances F, G of Fng , Gng , and we have efr(F, G, ∆t, Th) ≥
αin
3. there exist ground instances F, G of Fng , Gng , and we have efr(F, G, ∆t, Th) ≤
βin
Note that if we were to use the techniques of Section 3.4 for entailment, we
would most likely need to find tight bounds on the elements in the tuple returned by
EF R OU T (Fng , Gng , ∆t, φng ) (specifically a tight lower bound on EF R – as we can
132

be sure that for all ground instances F, G of Fng , Gng that EFR(F, G, ∆t, gnd(φng ))
will fall within these bounds). However, there are a few difficulties with this. First,
we conjecture that to find a good bound on EF R OU T , we would most likely have
to examine all combinations of ground instances of Fng , Gng – which is most likely
equivalent to grounding out the logic program and using Γ. Second, even if we could
efficiently find tight bounds on EF R OU T , they would most likely be trivial - i.e.
[0, 1].
Conversely, consider the tuple (αin , βin ) = EF R IN (Fng , Gng , ∆t, φng ). We
know that for all ground instances F, G of Fng , Gng such that for
[α, β] = EF R(F, G, ∆t, gnd(φng ))
we have αin ≥ α and βin ≤ β ′ . We also know that finding a lower bound on αin and
an upper bound on βin can be done by simply considering any subset of combinations
of ground instances of Fng and Gng .
Example 3.5.1. Consider Ktrain from Figure 2.3 with tmax = 4. Suppose we add
the following ptf (called φ) to the program.
at station(train1, stnA) : 1 ∧ adjEast(stnA, stnB) : 1∧
¬(at station(train1, stnA) : 2) ∧ at station(train1, stnA) : 3 : [1, 1]
Clearly, as
EF R(at station(train1, stnA)∧adjEast(stnA, stnB), at station(train1, stnA), 2, φ) = [1, 1]
we know for
(αin , βin ) = EF R IN (at station(T, S1 ) ∧ adjWest(S1 , S2 ), at station(T, S2 ), 2, φ)
133

that αin = 1 and βin ≤ 1.
Algorithm 9 Finds bounds on EF R IN
FIND-EFR-IN(Fsam , Gsam subsets of ground instances of non-ground
formulas Fng , Gng , ∆t natural number , φng non-ground time formula),
+
−
, βin
returns natural numbers αin

1. Compute gnd(φng )
−
+
2. Set αin
= 0 and βin
=1

3. For each F ∈ Fsam
(a) For each G ∈ Gsam
i. Let (α, β) = EF R(F, G, ∆t, gnd(φng ))
−
−
ii. αin
= max(α, αin
)
+
+
iii. βin
= min(β, βin
)

Algorithm 9 leverages this technique – if φng is already ground, algorithm
FIND-EFR-IN runs in time quadratic in the size of the sample of ground instances of
Fng , Gng . Clearly, this simple algorithm is guaranteed to return a lower bound on
αin and an upper bound on βin .
This information can be leveraged in order to perform consistency checks similar to those described in Section 3.4.4 without resorting to fully grounding out
Fng , Gng and considering all combinations of those ground instances. The intuition
is simple – if there is just one ground instance of a non-ground rule where ℓ > u, then

134

the program is inconsistent. The theorem and corollary below mirror Theorem 13
and Corollary 2 (Page 118) that we described in Section 3.4.2 for the ground case.
Theorem 16. Let K(ng) be a non-ground APT-program that contains the following:
ef r

Non-ground rule: Fng ; Gng : [∆t, ℓ, u]
Non-ground ptf:

φng : [1, 1]

+
−
and (αin , βin ) = EF R IN (Fng , Gng , ∆t, φng ). If we are given αin
≥
≤ αin and βin
−
+
βin , then, K(ng) is not consistent if either αin
> u or βin
< ℓ.

Corollary 5. Let K(ng) be a non-ground APT-program that contains the following:
ef r

Non-ground rule: Fng ; Gng : [∆t, ℓ, u]
φng : [ℓ′ , u′ ]

Non-ground ptf:

−
+
≤ αin and βin
≥
and (αin , βin ) = EF R IN (Fng , Gng , ∆t, φng ). If we are given αin
−
βin , then, K(ng) is not consistent if αin
· ℓ′ > u.

Algorithm 10 is a sound (but not complete) method to quickly check for inconsistency in the non-ground case.
Proposition 23. If the list returned by NG-INCONSIST-CHK contains any elements,
then K(ng) is not consistent.
Note that the algorithm performs only a quadratic number of comparisons.
Proposition 24. NG-INCONSIST-CHK performs O(|K(ng) |2 ) comparisons.6
6

Note: each comparison requires generating samples of ground instances of two formulas in a

rule and running FIND-EFR-IN.

135

Algorithm 10 Checks for inconsistencies in a non-ground program
NG-INCONSIST-CHK(K(ng) non-ground program)
returns list of rules that cause inconsistencies
1. Let L be a list of rules initialized to ∅
2. For each ptf φng : [ℓ′ , u′ ] ∈ K(ng) where u′ = 1, do the following.
ef r

(a) For each rule Fng ; Gng : [∆t, ℓ, u] ∈ K(ng) , do the following.
i. Generate sample sets Fsam , Gsam of ground instances of Fng , Gng .
−
+
ii. Let (αin
, βin
) = FIND-EFR-IN(Fsam , Gsam , ∆t, φng )
ef r

−
iii. If αin
· ℓ′ > u, then add Fng ; Gng : [∆t, ℓ, u] ∈ K(ng) to L
ef r

+
iv. Elseif ℓ′ = 1 and βin
< ℓ, then add Fng ; Gng : [∆t, ℓ, u] ∈ K(ng) to

L
3. Return list L

3.5.2

Entailment for the Non-Ground Case

In this section, we introduce a non-ground operator, ΛK(ng) , that maps ground
programs to ground programs. Using the same lattice of APT-programs we used in
Section 3.4.3, we show that ΛK(ng) also has a least fixed point. Our intuition is as
follows. Suppose we want to find the tightest entailment bounds on some ptf φ; if
we compute lf p(ΛK(ng) (φ : [0, 1])), the result will be an APT-program (let us call
this program Kφ ) s.t. lf p(Γ(Kφ )) will provide the same entailment bounds on φ as
if we had computed the least fixed point of Γ on the grounding of K(ng) . However,

136

in most cases, Kφ will be much smaller than the grounding of K(ng) .
Definition 49. For non-ground program K(ng) and ground program K (note that
f ormula(K) is a set of ground formulas, as defined in Definition 42), ΛK(ng) maps
ground programs to ground programs and is defined as follows. ΛK(ng) (K) =
K
ef r

∪
ef r

{F ; G : [∆t, ℓ, u]| F ; G : [∆t, ℓ, u] is a ground instance of a rule in K(ng) s.t.
∃φ ∈ f ormula(K) where φ is ground and
∃t ∈ [1, tmax ] s.t. φ |= F : t or φ |= G : t
or φ |= ¬F : t or φ |= ¬G : t} ∪
{ρ : [ℓ, u]|

ρ : [ℓ, u] is a ground instance of a ptf in K(ng) s.t.
∃φ ∈ f ormula(K) where φ is ground and φ |= ρ
or φ |= ¬ρ} ∪

{BLK(A) :< blk|

BLK(A) :< blk is a ground instance of a constraint in K(ng) s.t.
∃φ ∈ f ormula(K) where φ is ground and
∃t ∈ [1, tmax ] s.t. φ |= A : t or φ |= ¬A : t} ∪

{OCC(A) : [lo, up]|

OCC(A) : [lo, up] is a ground instance of a constraint in K(ng) s.t.
∃φ ∈ f ormula(K) where φ is ground and }
∃t ∈ [1, tmax ] s.t. φ |= A : t or φ |= ¬A : t}

We will now present an example for this operator.
Example 3.5.2. Recall Ktrain from Figure 2.3 with tmax = 4. The following rules
137

comprise the set ΛKtrain ({at station(train1, stnB) : 4}):
at station(train1, stnB) : 4
efr

at station(train1, stnA) ∧ adjEast(stnA, stnB) ; at station(train1, stnB) : [4, 0.85, 1.0]
efr

at station(train1, stnB) ∧ adjEast(stnB, stnB) ; at station(train1, stnB) : [4, 0.85, 1.0]
efr

at station(train1, stnC) ∧ adjEast(stnC, stnB) ; at station(train1, stnB) : [2, 0.85, 1.0]
efr

at station(train1, stnA) ∧ adjWest(stnA, stnB) ; at station(train1, stnB) : [2, 0.6, 0.7]
efr

at station(train1, stnB) ∧ adjWest(stnB, stnB) ; at station(train1, stnB) : [2, 0.6, 0.7]
efr

at station(train1, stnC) ∧ adjWest(stnC, stnB) ; at station(train1, stnB) : [2, 0.6, 0.7]

We use the same partial ordering and lattice from Section 3.4.3, and show the
monotonicity of ΛK(ng) as follows.
Lemma 14. K ⊑ ΛK(ng) (K) wrt hP ROGBL ,tmax , ⊑i
Lemma 15. ΛK(ng) is monotonic.
Now, we show that ΛK(ng) has a least fixed point.
Definition 50. We define multiple applications of Λ as follows.
• ΛK(ng) (K) ↑ 0 = K
• ΛK(ng) (K) ↑ (i + 1) = ΛK(ng) (ΛK(ng) (K) ↑ i)
Theorem 17. ΛK(ng) has a least fixed point.

138

The next two results demonstrate the soundness of Λ. Given non-ground
program K(ng) , let ground(K(ng) ) be the grounding of this program. The lemma
below follows directly from the definition of the operator. It states that the least
fixed point of the operator is a subset of the grounding of K(ng) .
Lemma 16. Given non-ground program K(ng) , and ground program K, lf p(ΛK(ng) (K)) ⊆
ground(K(ng) ) ∪ K.
Additionally, the following result states that, for a given entailment query, we
obtain the same result whether we use ΛK(ng) or simply ground out K(ng) .
Theorem 18. Given non-ground program K(ng)
φ : [ℓ, u] ∈ lf p(Γ(lf p(ΛK(ng) ({φ : [0, 1]}))))
iff
φ : [ℓ, u] ∈ lf p(Γ(ground(K(ng) ) ∪ {φ : [0, 1]}))

3.6

Experimental Results
This section reports on experiments carried out in the ground case with our

fixpoint algorithm. We demonstrate the Γ operator on 23 different ground APTprograms automatically extracted from two different data sets using a slight improvement of the APT-EXTRACT algorithm from the previous chapter. We were
able to compute fixpoints of APT-programs consisting of over 1,000 ground rules in
about 20 minutes (see the left-hand side of Figure 3.5). Note that this is the time to

139

compute the fixpoint, not to perform a deduction (i.e., via the Λ operator), which
can be done for specific entailment queries, and would be faster.
This section is organized as follows. Section 3.6.1 describes our experimental
setup, data set, and how we extracted rules, integrity constraints, and ptf’s while
Section 3.6.2 examines the runtime of the fixpoint operator.

3.6.1

Experimental Setup

All experiments were run on multiple multi-core Intel Xeon E5345 processors at 2.33GHz, 8GB of memory, running the Scientific Linux distribution of the
GNU/Linux OS, kernel version 2.6.9-55.0.2.ELsmp.7 Our implementation consists
of approximately 4,000 lines of Java code (JDK 1.6.0).
Iraq Special Groups (ISW) This data-set contains daily counterinsurgency events
from Baghdad in 2007-2008. The event data was provided by the Institute for the
Study of War (ISW) and augmented with neighborhood data from the International
Medical Corps. The historical data was represented with 187 ground atoms over
567 days – which is the time granularity we used. Using the APT-Extract algorithm
(presented in the previous chapter), we extracted 3,563 ground rules using the ef r
frequency function.
We considered 13 logic programs from this dataset; each smaller program is a
subset of any of the larger ones, so we have K1 ⊆ K2 ⊆ . . . ⊆ K12 ⊆ K13 . In each
program, we included a prefix consisting of 50 worlds (for more on prefixes, refer to
7

We note that this implementation makes use of only one processor and one core for a single

run, though different runs were distributed across the cluster.

140

Definition 34 on Page 107). The same prefix was used for each ISW program. We set
tmax = 60 for all ISW programs. Additionally, for all ground atoms appearing in a
given program, we added the appropriate block and occurrence integrity constraints.
Later we will present our extraction algorithms for these constraints.
Minorities at Risk Organizational Behavior (MAROB) This data set contains yearly attributes for a variety of political and violent groups over a period of 25
years [181]. Overall, we have extracted over 21.4 million APT-rules from this data
set. These rules were also extracted using APT-EXTRACT with the ef r frequency
function.
We considered 10 APT-logic programs from this dataset, each corresponding
to a different group. As each of these logic programs is associated with actions
for a specific group, all 10 of the MAROB programs are pairwise disjoint. In each
MAROB program, we included a unique prefix of 10 worlds specific to the group
in the program. We set tmax = 13 for each MAROB program. Block-size and
occurrence constraints were also included in each program. Tables 3.1-3.2 provides
some information on these APT-programs.
While integrity constraints (as with rules) could come from an expert, we
decided to extract our ICs from the data. We have included the straightforward
algorithms OC-EXTRACT and BLOCK-EXTRACT to show how we extracted occurrence and block-size IC’s (respectively) for each of the 187 atoms in the data set.
Proposition 25. OC-EXTRACT runs in time O((n − tmax ) · tmax ).
Proposition 26. There are no historical threads such that atom ai is satisfied by
141

Algorithm 11 Extracts occurrence constraints
OC-EXTRACT(ai ground atom , W1 , . . . , Wn historical worlds, tmax maximum time),
returns natural numbers loi , upi
1. Set upi = 0 and loi = tmax
2. For i = 1, i ≤ n − tmax + 1, loop
(a) Set cur = 0
(b) For j = i, j < i + tmax loop
i. If Wj |= ai , then cur = cur + 1
(c) If cur < loi then set loi = cur
(d) If cur > upi then set upi = cur
3. Return loi , upi

less than loi or more than upi worlds when loi , upi are produced by OC-EXTRACT.

Proposition 27. BLOCK-EXTRACT runs in time O(n).
Proposition 28. Given blki as returned by BLOCK-EXTRACT, there is no sequence
of blki or more consecutive historical worlds that satisfy atom ai .

3.6.2

Run Time Evaluation

To evaluate performance, for each logic program, we clocked 10 trials until Γ
reached a fixpoint. In all our trials, a fixpoint was reached after only two or three
applications (see Tables 3.1-3.2). We also note that the experimental relationship
142

MAROB
60

1200

50

1000

Runtime (seconds)

Runtime (seconds)

ISW
1400

800
600
400

200

40
30
20
10

0

0
0

500

1000

0

200

400

600

Number of Ground Rules

Number of Ground Rules

Figure 3.5: Number of ground rules vs. run time (Left: ISW, Right: MAROB). Note
these run-times include the full computation of the fixed point of the Γ operator.
between run time and the number of rules was linear – we conducted a statistical
R2 -test for this and came up with an R2 value of 0.97 for ISW programs and 0.77
for MAROB programs (refer to Figure 3.5). We must point out that the disjoint
relationship among MAROB programs may account for why the run time relationship is not as linear as that for the ISW programs. This graceful degradation in
performance is most likely due to the fact that the number of rules/ptfs that can
tighten the bound of a given rule or ptf is much smaller than the set of entire rules,
which makes the running time of the inner loop very small. Hence, for practical
purposes, the O(|K|2 ) is a loose bound; this worst case is likely to occur only in very
rare circumstances.
We checked entailment by looking at the probability bounds of formulas in
formula(K) (see Definition 42), which is obtained by finding the fixpoint for the
Γ operator on a consistent APT-program. After our initial runs of Γ on the 23
logic programs, we found that 21 of them were inconsistent. As inconsistencies are

143

Program

Gr. Rules

Post. Gr. Atoms

Range of ∆t

tmax

Time Points Γ App.

K1

92

76

[2,10]

60

567

2

K2

102

76

[2,10]

60

567

3

K3

126

76

[2,10]

60

567

3

K4

144

76

[2,10]

60

567

2

K5

169

76

[2,10]

60

567

2

K6

214

76

[2,10]

60

567

3

K7

241

76

[2,10]

60

567

3

K8

278

76

[2,10]

60

567

3

K9

360

79

[2,10]

60

567

3

K10

503

80

[2,10]

60

567

3

K11

644

80

[2,10]

60

567

3

K12

816

80

[2,10]

60

567

3

K13

1081

84

[2,10]

60

567

3

Table 3.1: APT-logic programs used in the run time evaluations. Programs K1 −K13
are based on the ISW data-set.

144

Program

Gr. Rules

Post. Gr. Atoms

Range of ∆t

tmax

Time Points Γ App.

KH

586

189

[2,3]

13

23

3

KJ

679

192

[3,3]

13

25

2

KA

661

162

[2,3]

13

25

2

KB

163

175

[3,3]

13

24

2

KD

539

176

[3,3]

13

25

2

KF T

482

188

[2,3]

13

22

3

KF R

310

177

[3,3]

13

25

2

KHA

458

168

[3,3]

13

13

2

KHI

330

182

[2,3]

13

25

2

KK

94

181

[1,3]

13

25

3

Table 3.2: APT-logic programs used in the run time evaluations. The programs in
this table are based on the MAROB data-set.

145

ISW

MAROB

800

50
Runtime (seconds)

60

Runtime (seconds)

1000

600
400

200

40
30

20
10

0

0
0

200

400

600

0

Number of Ground Rules

200

400

Number of Ground Rules

600

Figure 3.6: Number of ground rules vs. run time for entailment checking (Left: ISW,
Right: MAROB).
found in a constructive way (refer to Section 3.4.4 on Page 127), we could eliminate
rules that caused inconsistencies (we designate the “consistent” subset of a program
with a tick mark, i.e., K2′ is K2 with inconsistency-causing rules removed). Using
these “consistent” APT-programs, we first looked to revalue the performance of
the Γ operator for entailment. Unsurprisingly, as with the run time evaluation we
performed for consistency checking, we found that the run time was related linearly
to the number of ground rules considered. We obtained R2 values of 0.95 for ISW
programs and 0.94 for MAROB programs. See Figure 3.6 for details; run times are
based on the average of 10 trials for each logic program.
As a consequence of Definition 42 (Page 123), the logic program returned by
multiple applications of Γ includes several ptf’s not in the original program. These
ptf’s were either based on formulas seen in the rules, or atoms seen in the rules where
an integrity constraint forces the associated atomic ptf to be assigned probability
0. Many of these ptf’s have probability bounds tighter than [0, 1] – some extremely

146

500
450
400
350
300
Decision ptf's
u-l < 0.1

250
200
150
100
50
0
K1'

K2'

K3'

K4'

K5'

K6'

K7'

K8'

K9' K10' K11' K12' K13'

Figure 3.7: Attributes of ptf’s entailed by the different logic programs (ISW dataset)
tight. We note, as shown in Figure 3.7, that all of our ISW logic program produce
over 300 ptfs where the difference between ℓ and u is less than 0.1 (the number
steadily increases with larger ISW programs8 ). We also looked at “decision ptf’s”;
these are ptf’s where either ℓ ≤ 0.5 or u ≤ 0.5 – the intuition is that the probability
mass is either above or below 0.5, allowing a user to make a decision. The Γ operator
also was successful in producing many ptf’s of this type, producing well over 400 in
over half of the logic programs we considered from the ISW dataset.

8

It is important to point out that all numbers of ptf’s with tight bounds are associated with a

world outside the range of the prefix.

147

Algorithm 12 Extracts block-size constraints
BLOCK-EXTRACT(ai ground atom , W1 , . . . , Wn historical worlds ),
returns natural number blki
1. Set cur = 0
2. Set best = 0
3. For i = 1, i ≤ n, loop
(a) If Wi |= ai
i. cur = cur + 1
(b) Else
i. If cur > best then set best = cur
ii. Set cur = 0
4. If cur > best set best = cur
5. Set blki = best + 1
6. Return blki

148

3.7

Chapter 3 Related Work
In the previous chapter, we showed that APT-Logic distinguishes itself from

other temporal logics in the following ways: (i) It supports reasoning about probability of events over time, (ii) Future worlds can depend on more than just the current
world (i.e., it does not assume the Markov property). (iii) It provides probability
bounds instead of a point probability. (iv) No independence assumptions are made.
[34] was the first effort to provide a declarative semantics for temporal probabilistic LPs. We compared this work with APT-Logic in the previous chapter. No
implementation was proposed and thus no experimental results were studied.
[124] introduce an extension to the Situation Calculus for handling actions
with uncertain effects. The semantics of their logical language is given in terms of
a “Randomly Reactive Automaton”, which allows for probabilistic effects of actions
but has no notion of the current time apart from that implied by the sequence of
actions. They examine next move determination where the results of a move are
dependent on the move chosen as well as on draws from single or from multiple
distributions.
Santos and Young [148] propose the Probabilistic Temporal Network model
(PTNs), which allows to represent temporal (and atemporal) information in combination with probabilistic semantics. PTNs are suitable for representing causality
constrained by time, conditions for the occurrence of events (and at what time they
occur), and periodic and recurrent processes. This model is based on Bayesian
networks (for the probabilistic aspect) and on work by Allen [3] on temporal in-

149

terval algebra for the temporal aspect. Even though this work’s goals overlap to
some extent with those of our own, the fundamental difference lies in the initial
assumptions made. In order to build a PTN, one must have available information
regarding dependencies, prior probabilities for all random variables, temporal causal
relationships between random variables in temporal aggregates, etc. The focus of
our work is to reason about events making no independence assumptions, and only
based on limited information relating small subsets of events. The PTN framework
is, however, very useful for scenarios in which the required information is available, as is the case in probabilistic reasoning with traditional Bayesian Networks.
The key aspect that separates APT-logic from PTN’s, is the fact that APT-logic
makes no assumptions about independence. For example, consider item 1 of
Theorem 8, one of the key building blocks of our fixpoint heuristic. In this case,
if I |= φ : [p, p] and ρ : [p′ , p′ ], then I |= φ ∧ ρ : [max(0, p + p′ − 1), min(p, p′ )]. If
we had assumed independence, then I |= φ ∨ ρ : [p2 , p2 ] – clearly a different answer and not appropriate for domains where we do not wish to make assumptions
about dependence/independence (i.e., the counter-insurgency data that we used for
our experiments). This also is our motivation for the use of probability intervals –
rather than point probabilities.

3.7.1

Work in Verification and PRISM

Logics merging time and probabilities have been studied quite a bit in the area
of verification. [173] was one of the pioneers in this, followed by many including

150

probabilistic CTL [65], and others [25]. Building on this work, Kwiatkowska et. al.
developed a tool known as PRISM [91, 92] to perform this type of model checking.
PRISM has the following characteristics:
1. The user specifies a model - a discrete-time Markov chain (DTMC), continuoustime Markov chain (CTMC) or Markov decision processes (MDP)
2. The user also specifies a property - which is normally a CTL formula
3. PRISM returns a value (normally a probability or expected value) associated
with the property
One can view our implementation in the same light - taking an APT-program
as a model, time formula as a property, and returning entailment bounds as the
value. However, PRISM operates under some very different assumptions than APTlogic which are appropriate for some applications but not for all.
1. The model specified by the user in PRISM is a stochastic process that assumes
the Markov property - that is the probability of being in the next state only
depends on the current state and action. Conversely, an APT-program does
not assume the Markov property. Further, we demonstrated translations
from stochastic processes to APT-programs in Chapter 2. Also, in that chapter,
we showed how it is easy to construct a very simple APT-program where there
is no analogous MDP (using a natural construction).
2. Based on the model specified by the user, PRISM also makes an independence
assumption. Suppose we are in initial state S1 and consider the following
151

a

b

sequence of states, actions, and probabilities in an MDP: S1 →p1 S2 →p2 S3
which states that “state 1 transitions to state 2 on action a with probability p1
and state 2 transitions to state on action b with probability p2 .” PRISM would
calculate the probability of such a sequence - p1 · p2 - hence it has assumed
independence between the two transitions. Likewise, consider the formulas
F (S1 ), F (S2 ), F (S3 ) – formulas satisfied exactly by states S1 , S2 , S3 . Using
the natural translation described in Chapter 2, we can create an analogous
APT-program as follows:
• (F (S1 ) ∧ a ∧ ¬b) : 1 ∧ F (S2 ) : 2 : [p1 , p1 ]
• (F (S2 ) ∧ b ∧ ¬a) : 2 ∧ F (S3 ) : 3 : [p2 , p2 ]
By item 1 of Theorem 8, the following ptf is tightly entailed:
(F (S1 ) ∧ a ∧ ¬b) : 1 ∧ (F (S2 ) ∧ b ∧ ¬a) : 2 ∧ F (S3 ) : 3 : [max(0, p1 + p2 −
1), min(p1 , p2 )]
With APT-logic, we allow for uncertainty - all we can say about the sequence
is it has a probability in [max(0, p1 + p2 − 1), min(p1 , p2 )] – which is clearly
different than p1 · p2 .
3. The property specified by the user in PRISM is based on PCTL [12, 65].
Although there are constructs in PCTL that appear similar to the syntax of
APT-logic, as our semantics differ substantially, the statements have different
meanings. Even if an MDP is encoded in an APT-program, a “leads-to” PCTL
operator (which has a strikingly similar intuition to an APT-rule) has a very

152

different meaning. We explored the specifics of these differences in the previous
chapter.
Basically, PRISM is best suited for situations where the underlying model can
be represented as a stochastic process. Popular applications have included software
verification and certain biology problems that can be easily represented as stochastic
processes. APT-logic is best suited for situations where there are no independence
or Markov assumptions made about the model - which is often the case when we are
working with extracted rules. We have shown APT-logic to be viable for studying the
actions of militia groups in a counter-insurgency environment. Other applications
where APT-logic is well suited include policy analysis and stock price movement.

3.8

Chapter Summary
Logical reasoning with time and probabilities is essential in any application

where the occurrence of certain conditions at time t may cause or imply that other
phenomena may occur δ units in the future. There are numerous such applications
including ones relating to how stock markets will move in the future based on current
or past conditions, medicine where the condition of a patient in the future depends
on various things true now, behavior modeling where the behavior of an individual
or group in the future may depend on his current/past situation. In addition,
most applications where we reason about the future are fraught with uncertainty.
Annotated Probabilistic Temporal Logic (APT-logic for short) was introduced in the
previous chapter as a paradigm for reasoning about sentences of the form “If formula
153

F is true at time t, then formula G will be true at time ∆t with a probability in the
range [L, U ].” More importantly, APT-logic programs were introduced in a manner
that did not require independence or Markovian assumptions, many of which are
inapplicable for several applications.
To date, no implementation of probabilistic temporal logic exists that does
not make use of Markovian or independence assumptions. To our knowledge, this
chapter represnt the first attempt at any implementation of such logics. However,
due to the high complexity of such reasoning (which may also explain why implementations may not exist), practical temporal probabilistic reasoning systems may
not always be complete.
In this chapter, we developed, implemented, and evaluated a fixpoint-based
heuristic for consistency and entailment problems in APT-logic programs. This
chapter makes the following contributions:
1. We show NP-completeness of the APT-logic consistency problem, and coNPcompleteness of the APT-logic entailment problem, extending hardness results
of the previous chapter.
2. We developed a fixpoint based heuristic from the following observations:
• The presence of ptf’s with the probability of 1 in an APT-program allows
us to tightly bound values for frequency functions.
• The bound on frequency functions, in turn, allows us to tighten the bounds
of elements in an APT-program

154

• The above two characteristics can be employed in an operator that maps
APT-programs to APT-programs and has a least fixed point
3. We developed consistency and entailment algorithms for the non-ground case.
4. We implemented our fixpoint heuristic and applied it to 23 real world APTlogic programs derived automatically from two different real world data sets.
This suite of test programs was not written by us. Our experiments show that
our fixpoint based heuristical can calculate fixpoints in time roughly linear
w.r.t. the number of ground rules
5. We also show that using our implementation, we can solve the “tight entailment problem” where the goal is to find the tightest interval [ℓ, u] such that
F : [t, ℓ, u] is entailed by an APT-logic program for a given time t and formula
F.

155

Chapter 4
Geospatial Abduction

In the previous two chapter, we explored temporal aspects of an agent’s behavior with APT logic. The next three chapters deal with spatial aspects of an
agent’s behavior. These chapters are primarily concerned with variants of geospatial abduction problems - inferring unobserved geospatial locations associated with
agent behavior. In this chapter, we formalize the idea of geopspatial abduction and
study some natural problems associated with this framework.1

4.1

Chapter Introduction
There are numerous applications where we wish to draw geospatial inferences

from observations. For example, criminologists [144, 15] have found that there
are spatial relationships between a serial killer’s house (the geospatial inference we
wish to make), and locations where the crimes were committed (the observations).
1

This chapter is based on [157] and [158] which were completed in cooperation with Maria Luisa

Sapino and V.S. Subrahmanian.

156

A marine archaeologist who finds parts of a wrecked ship or its cargo at various
locations (the observations) is interested in determining where the main portion of
the wreck lies (the geospatial inference). Wildlife experts might find droppings of an
endangered species such as the Malayan sun bear (observations) and might want to
determine where the bear’s den is (the geospatial inference to be made). In all these
cases, we are trying to find a single location that best explains the observations (or
the k locations that best explain the observations). There are two common elements
in such applications.
First, there is a set O of observations of the phenomena under study. For
the sake of simplicity, we assume that these observations are points where the phenomenon being studied was known to have been present. Second, there is some
domain knowledge D specifying known relationships between the geospatial location we are trying to find and the observations. For instance, in the serial killer
application, the domain knowledge might tell us that serial killers usually select
locations for their crimes that are at least 1.2 km from their homes and at most
3 km from their homes. In the case of the sun bear, the domain knowledge might
state that the sun bear usually prefers to have a den in a cave, while in the case of
the wreck, it might be usually within a radius of 10 miles of the artifacts that have
been found.
The geospatial abduction problem (GAP for short) is the problem of finding the
most likely set of locations that is compatible with the domain knowledge D and
that best “explains” the observations in O. To see why we look for a set of locations, we note that the serial killer might be using both his home and his office as
157

launching pads for his attacks. In this case, no single location may best account for
the observations. In this chapter, we show that many natural problems associated
with geospatial abduction are NP-Complete, which cause us to resort to approximation techniques. We then show that certain geospatial abduction problems reduce
to several well-studied combinatorial problems that have viable approximation algorithms. We implement some of the more viable approaches with heuristics suitable
for geospatial abduction, and test them on a real-world data-set. The organization
and main contributions of this chapter are as follows.
• Section 4.1.1 formally defines geospatial abduction problems (GAPs for short) and
Section 4.2 analyzes their complexity.
• Section 4.3 develops a “naive” algorithm for a basic geospatial abduction problem
called k-SEP and shows reductions to set-covering, dominating set, and linearinteger programming that allow well-known algorithms for these problems to be
applied to GAPs.
• Section 4.4 describes two greedy algorithms for k-SEP and compares them to a
reduction to the set-covering problem.
• Section 4.5 describes our implementation and shows that our greedy algorithms
outperform the set-covering reduction in a real-world application on identifying
weapons caches associated with Improvised Explosive Device (IED) attacks on
US troops in Iraq. We show that even if we simplify k-SEP to only cases where
k-means classification algorithms work, our algorithms outperform those. We
also note that k-means can only be applied to geospatial abduction in certain,
158

restricted cases as a heuristic with no approximation guarantee. Such cases are
quite limited as the sociol-culutral variables encoded is a feasibility overlay cannot
be incorporated into the input of a k-means algorithm.
• Section 4.6 compares our approach with related work.

4.1.1

Geospatial Abduction Problem (GAP) Definition

Throughout this chapter, we assume the existence of a finite, 2-dimensional
M × N space S 2 for some integers M, N ≥ 1 called the geospatial universe (or
just universe). Each point p ∈ S is of the form (x, y) where x, y are integers and
0 ≤ x ≤ M and 0 ≤ y ≤ N . We assume that all observations we make occur within
space S. We use the space shown in Figure 4.1 throughout this chapter to illustrate
the concepts we introduce. We assume that S has an associated distance function
d which assigns a non-negative distance to any two points and satisfies the usual
distance axioms.3
Definition 51 (observation). An observation O is any finite subset of S.
Consider the geospatial universe shown in Figure 4.1. In the serial killer application, the red dots would indicate the locations of the murders, while in the
ship-wreck example, they would indicate the locations where artifacts were found.
We wish to identify the killer’s location (or the sunken ship or the sun bear’s den).
2

We use integer coordinates as most real world geospatial information systems (GIS) systems

use discrete spatial representations.
3

d(x, x) = 0; d(x, y) = d(y, x); d(x, y) + d(y, z) ≥ d(x, z).

159

12

8

4

0

4

8

12

16

Figure 4.1: A space. Red dots denote observations. Yellow squares denote infeasible
locations. Green stars show one (0,3) explanation, while pink triangles show another
(0,3) explanation.
As mentioned earlier, there are many constraints that govern where such locations might be. For instance, it is unlikely that the sun-bear’s den (or the killer’s
house or office) is in the water, while the sunken ship is unlikely to be on land.
Definition 52 (feasibility predicate). A feasibility predicate feas is a function from
S to {TRUE, FALSE}.
Thus, feas(p) = TRUE means that point p is feasible and must be considered
in the search. Figure 4.1, denotes infeasible places via a yellow square. Throughout
this chapter, we assume that feas is an arbitrary, but fixed predicate.4 Further, as
feas is defined as a function over {TRUE, FALSE}, it can allow for user input based
4

We also assume throughout the chapter that feas is computable in constant time. This is a

realistic assumption, as for most applications, we assume feas to be user-defined. Hence, we can
leverage a data-structure indexed with the coordinates of S to allow for constant-time computation.

160

on analytical processes currently in place. For instance, in the military, analysts
often create “MCOO” overlays where “restricted terrain” is deemed infeasible [170].
We can also easily express feasibility predicates in a Prolog-style language – we
can easily state (in the serial killer example) that point p is considered feasible if
p is within R units of distance from some observation and p is not in the water.
Likewise, in the case of the sun bear example, the same language might state that p
is considered feasible if p is within R1 units of distance from marks on trees, within
R2 units of scat, and if p has some landcover that would allow the bear to hide.
A Prolog-style language that can express such notions of feasibility is the hybrid
knowledge base paradigm [108] in which Prolog style rules can directly invoke a GIS
system.
Definition 53 ((α, β) explanation). Suppose O is a finite set of observations, E is
a finite set of points in S, and α ≥ 0, β > 0 are some real numbers. E is said to be
an (α, β) explanation of O iff:
• p ∈ E implies that feas(p) = TRUE, i.e. all points in E are feasible and
• (∀o ∈ O)(∃p ∈ E) α ≤ d(p, o) ≤ β, i.e. every observation is neither too close nor
too far from some point in E.
Thus, an (α, β) explanation is a set of points (e.g. denoting the possible
locations of the home/office of the serial killer or the possible locations of the bear’s
den). Each point must be feasible and every observation must have an analogous
point in the explanation which is neither too close nor too far.

161

Given an (α, β) explanation E, there may be an observation o ∈ O such that
there are two (or more) points p1 , p2 ∈ E satisfying the conditions of the second
bullet above. If E is an explanation for O, a partnering function ℘E is a function
from O to E such that for all o ∈ O, α ≤ d(℘E (o), o) ≤ β. ℘E (o) is said to be o’s
partner according to the partnering function ℘E . We now present a simple example
of (α, β) explanations.
Example 4.1.1. Consider the observations in Figure 4.1 and suppose α = 0, β = 3.
Then the two green stars denote an (α, β) explanation, i.e. the set {(6, 6), (12, 8)} is
a (0, 3) explanation. So is the set of three pink triangles, i.e. the set {(5, 6), (10, 6),
(13, 9)} is also an (0, 3) explanation.
The basic problem that we wish to solve in this chapter is the following.

The Simple (α, β) Explanation Problem (SEP).
INPUT: Space S, a set O of observations, a feasibility predicate feas, and numbers
α ≥ 0, β > 0.
OUTPUT: “Yes” if there exists an (α, β) explanation for O — “no” otherwise.

A variant of this problem is the k-SEP problem which requires, in addition,
that E contains k elements or less, for k < |O|. Yet another variant of the problem
tries to find an explanation E that is “best” according to some cost function.
Definition 54 (cost function χ). A cost function χ is a mapping from explanations
to non-negative reals.
162

We will assume that cost functions are designed so that the smaller the value
they return, the more desirable an explanation is. Some example cost functions are
given below. The simple one below merely looks at the mean distances between
observations and their partners.
Example 4.1.2 (Mean-distance). Suppose S, O, feas, α, β are all given and suppose
E is an (α, β) explanation for O and ℘E is a partnering function. We could initially
set the cost of an explanation E (with respect to this partnering function) to be:
χ℘E (E) =

Σo∈O d(o, ℘E (o))
.
|O|

Suppose ptn(E) is the set of all partner functions for E in the above setting. Then
we can set the cost of E as:
χmean (E) = inf{χ℘E (E) | ℘E ∈ ptn(E)}.
The above definition removes reliance on a single partnering function as there
may be several partnering functions associated with a single explanation. We illustrate this definition using our sun bear example.
Example 4.1.3. Wildlife experts have found droppings and other evidence of the
Malayan sun bear in a given space, S, depicted in Figure 4.2. Points {o1 , o2 , o3 }
indicate locations of evidence of the Malayan sun bear (we shall refer to these as set
O). Points {p1 , p2 , . . . , p8 } indicate feasible dwellings for the bear. The concentric
rings around each element of O indicate the distance α = 1.7km and β = 3.7km.
The set {p3 , p6 } is a valid (1.7, 3.7) explanation for the set of evidence, O. However,
we note that observation o2 can be partnered with either point. If we are looking to
163

Figure 4.2: Left: Points {o1 , o2 , o3 } indicate locations of evidence of the Malayan
sun bear (we shall refer to these as set O). Points {p1 , p2 , . . . , p8 } indicate feasible
dwellings for the bear. The concentric rings around each element of O indicate the
distance α = 1.7km and β = 3.7km. Right: Points {p1 , p2 , p3 } are feasible for
crime-scenes {o1 , o2 }. {p1 , p2 } are safe-houses within a distance of [1, 2] km. from
crime scene o1 and {p2 , p3 } are safe-houses within a distance of [1, 2] km. from crime
scene o2 .
minimize distance, we notice that d(o2 , p3 ) = 3km and d(o2 , p6 ) = 3.6km, hence p3
is the partner for o2 such that the distance is minimized.
We now define an “optimal” explanation as one that minimizes cost.
Definition 55. Suppose O is a finite set of observations, E is a finite set of points
in S, α ≥ 0, β > 0 are some real numbers, and χ is a cost function. E is said to be
an optimal (α, β) explanation iff E is an (α, β) explanation for O and there is no
other (α, β) explanation E ′ for O such that χ(E ′ ) < χ(E).
164

We present an example of optimal (α, β) explanations below.
Example 4.1.4. Consider the sun bear from Example 4.1.3 whose behavior is depicted in Figure 4.2 (left). While {p3 , p6 } is a valid solution for the k-SEP problem
(k = 2), it does not optimize mean distance. In this case the mean distance would
be 3km. However, the solution {p3 , p7 } provides a mean-distance of 2.8km.

Suppose we are tracking a serial killer who has struck at locations O = {o1 , o2 }.
The points {p1 , p2 , p3 } are feasible locations as safe-houses for the killer (partners).
This is depicted in Figure 4.2 (right). Based on historical data, we know that serial
killers strikes are at least 1km away from a safe-house and at most 2km from the
safe house (α = 1, β = 2). Thus, for k = 2, any valid explanation of size 2 provides
an optimal solution wrt mean-distance as every feasible location for a safe-house is
within 2km of a crime scene.
We are now ready to define the cost-based explanation problem.
The Cost-based (α, β) Explanation Problem.
INPUT: Space S, a set O of observations, a feasibility predicate feas, numbers α ≥ 0,
β > 0, a cost function χ and a real number v > 0.
OUTPUT: “Yes” if there exists an (α, β) explanation E for O such that χ(E) ≤ v
— “no” otherwise.
It is easy to see that standard classification problems like k-means

5

can be

captured within our framework by simply assuming that α = 0, β > max(M, N )2
5

See [4] for a survey on classification work.

165

and that all points are feasible. In contrast, standard classification algorithms cannot
take feasibility into account - and this is essential for the above types of applications.

4.2

Complexity of GAP Problems
SEP can be easily solved in PTIME. Given a set O of observations, for each

o ∈ O, let Po = {p ∈ S | f eas(p) = TRUE ∧ α ≤ d(p, o) ≤ β}. If Po 6= ∅ for each
o, we return “yes”. We call this algorithm STRAIGHTFORWARD-SEP. Another
algorithm would merely find the set F of all feasible points and return “yes” iff for
every observation o, there is at least one point p ∈ F such that α ≤ d(p, o) ≤ β. In
this case, F is the explanation produced - but it is a very poor explanation. In the
serial killer example, F merely tells the police to search all feasible locations without
trying to do anything intelligent. k-SEP allows the user to constrain the size of the
explanation so that “short and sweet” explanations that are truly meaningful are
produced. The following result states that k-SEP is NP-Complete - the proof is a
reduction from Geometric Covering by Discs (GCD) [76].
Theorem 19. k-SEP is NP-Complete.
In the associated optimization problem with k-SEP, we wish to produce an
explanation of minimum cardinality. Note that minimum cardinality is a common
criterion for parsimony in abduction problems [141]. We shall refer to this problem
as MINSEP. This problem is obviously NP-hard by Theorem 19. We can adjust
STRAIGHTFORWARD-SEP to find a solution to MINSEP by finding the minimum
hitting set of the Po ’s.
166

Example 4.2.1. Consider the serial killer scenario in Example 4.1.4 and Figure 4.2
(right). Crime scene (observation) o1 can be partnered with two possible safe-houses
{p1 , p2 } and crime scene o2 can be partnered with {p2 , p3 }. We immediately see that
the potential safe house located at p2 is in both sets. Therefore, p2 is an explanation
for both crime scenes. As this is the only such point, we conclude that {p2 } is the
minimum-sized solution for the SEP problem. However, while it is possible for
STRAIGHTFORWARD-SEP to return this set, there are no assurances it does. As
we saw in Example 4.1.4, E = {p1 , p2 } is a solution to SEP, although a solution
with lower cardinality ({p2 }) exists. This is why we introduce the MINSEP problem.
With the complexity of k-SEP, the following corollary tells us the complexity
class of the Cost-based Explanation problem. We show this reduction by simply
setting the cost function χ(E) = |E|.
Corollary 6. Cost-based Explanation is NP-Complete.
As described earlier, MINSEP has the feel of a set-covering problem. Although
the generalized cost-based explanation cannot be directly viewed with a similar intuition (as the cost maps explanations to reals – not elements of S), there is an
important variant of the Cost-based problem that does. We introduce weighted
SEP, or WT-SEP below.

Weighted Spatial Explanation. (WT-SEP)
INPUT: A space S, a set O of observations, a feasibility predicate feas, numbers
α ≥ 0, β > 0, a weight function c : S → ℜ, and a real number v > 0.
167

OUTPUT: “Yes” if there exists an (α, β) explanation E for O such that
v — “no” otherwise.

P

p∈E

c(p) ≤

In this case, we can easily show NP-Completeness by reduction from k-SEP,
we simply set the weight for each element of S to be one, causing
the cardinality of E.

P

p∈E

c(p) to equal

Corollary 7. WT-SEP is NP-Complete.
Cost-based explanation problems presented in this section are very general.
While the complexity results hold for an arbitrary function in a general case, we
also consider specific functions as well. Below we present the total-distance minimization explanation problem (TD-SEP). This is a problem where we seek to
minimize the sum of distances between observations and their closest partners while
imposing a restriction on cardinality.

Total Distance Minimization Explanation Problem. (TD-SEP)
For space S, let d : S × S → ℜ be the Euclidean distance between two points in S.
INPUT: A space S, a set O of observations, a feasibility predicate feas, numbers
α ≥ 0, β > 0, positive integer k < |O|, and real number v > 0.
OUTPUT: “Yes” if there exists an (α, β) explanation E for O such that |E| = k and
P

oi ∈O

minpj ∈E d(oi , pj ) ≤ v — “no” otherwise.

Theorem 20. TD-SEP is NP-Complete.
The NP-hardness of the TD-SEP is based on a reduction from the k-Median
168

Problem [134]. This particular reduction (details in the appendix) also illustrates
how the k-median problem is a special case of GAPs, but k-median problems cannot
handle arbitrary feasibility predicates of the kind that occur in real-life geospatial
reasoning. The same argument applies to k-means classifiers as well.

4.3

Exact Algorithm for GAP Problems
This section presents four exact approaches to solve k-SEP and WT-SEP.

First, we provide an enumerative approach that exhaustively searches for an explanation. Then, we show that the problem reduces to set-cover, dominating set, and
linear-integer programming. Existing algorithms for these problems can hence be
used directly. Throughout this section, we shall use the symbols ∆ to represent the
bound on the number of partners that can be associated with a single observation
and f to represent the bound on the number of observations supported by a single
partner. Note that both values are bounded by π(β 2 − α2 ), however they can be
much less in practice – specifically f is normally much smaller than ∆.

4.3.1

Naive Exact Algorithm

We now show correctness of NAIVE-KSEP-EXACT. This algorithm provides
an exact solution to k-SEP but takes exponential time (in k). The algorithm first
identifies a set L of all elements of S that could be possible partners for O. Then, it
considers all subsets of L of size less than or equal to k. It does this until it identifies
one such subset as an explanation.
169

Algorithm 13 (NAIVE-KSEP-EXACT)
INPUT: Space S, a set O of observations, a feasibility predicate feas, real numbers α ≥ 0, β > 0, and natural
number k > 0
OUTPUT: Set E ⊆ S of size k (or less) that explains O
1. Let M be a matrix array of pointers to binary string {0, 1}|O| . M is of the same dimensions as S. Each
element in M is initialized to NULL. For a given p ∈ S, M [p] is the place in the array.
2. Let L be a list of pointers to binary strings. L is initialized as null.

3. For each oi ∈ O do the following
(a) Determine all points p ∈ S such that α ≤ d(o, p) ≤ β such that feas(p) = TRUE.
(b) For each of these points, p, if M [p] = NULL then initialize a new array where only bit i is set to 1.
Then add a pointer to M [p] in L.
(c) Otherwise, set bit i of the existing array to 1.

4. For any k elements of L (actually the k elements pointed to by elements of L), we shall designate
ℓ1 , . . . , ℓj , . . . ℓk as the elements. We will refer to the ith bit of element ℓj as ℓj (i).

5. Exhaustively generate all possible combinations of k elements of L until one such combination is found
where ∀i ∈ [1, |O|],

Pk

j=1 (ℓj (i))

>0

6. If no such combination is found, return NO. Otherwise, return the first combination that was found.

170

Proposition 29. If there is a k-sized simple (α, β) explanation for O, then NAIVEKSEP-EXACT returns an explanation. Otherwise, it returns NO.
Finally, we have the complexity of the algorithm.
1
Proposition 30. The complexity of NAIVE-KSEP-EXACT is O( (k−1)!
(π(β 2 −α2 )|O|)(k+1) ).

An exact algorithm for the cost-based explanation problems follows trivially
from the NAIVE-KSEP-EXACT algorithm by adding the step of computing the value
for χ for each combination. Provided this computation takes constant time, this
1
does not affect the O( (k−1)!
(π(β 2 − α2 )|O|)(k+1) ) run time of that algorithm.

4.3.2

An Exact Set-Cover Based Approach

We now show that k-SEP polynomially reduces to an instance of the popular
set-covering problem [80] which allows us to directly apply the well-known greedy
algorithm reviewed in [136]. SET COVER is defined as follows.

The Set-Cover Problem. (SET COVER)
INPUT: Set of elements, E and a family of subsets of E, F ≡ {S1 , . . . , Smax }, and
positive integer k.
OUTPUT: “Yes” if there exists a k-sized subset of F , Fk , such that
Fk } ≡ E.

Sk

i=1 {Si

∈

Through a simple modification of NAIVE-KSEP-EXACT, we can take an instance of k-SEP and produce an instance of SET COVER. We run the first four
171

steps, which only takes O(∆ · |O|) time by the proof of Proposition 30.
Theorem 21. k-SEP polynomially reduces to SET COVER.
Example 4.3.1. Consider the serial killer scenario in Example 4.1.4 and Figure 4.2
(right). Suppose we want to solve this problem as an instance of k-SEP by a reduction to set-cover. We consider the set of crime-scene locations, O ≡ {o1 , o2 } as the
set we wish to cover. We obtain our covers from the first four steps of NAIVE-KSEPEXACT. Let us call the result list L. Hence, we can view the values of the elements
in L as the following sets S1 ≡ {o1 }, S2 ≡ {o1 , o2 }, S3 ≡ {o2 }. These correspond
with points p1 , p2 , p3 respectively. As S2 covers O, p2 is an explanation.
The traditional approach for approximation of set-cover has a time complexity
of O(|E| · |F | · size), where size is the cardinality of the largest set in the family
F (i.e. size = maxi≤|F | |Si |). This approach obtains an approximation ratio of 1 +
ln(size) [136]. As f is the quantity of the largest number of observations supported
by a single partner, the approximation ratio for k-SEP using a greedy-scheme after a
reduction from set-cover is 1+ln(f ). The NAIVE-KSEP-SC algorithm below leverages
the above reduction to solve the k-SEP problem.
Proposition 31. NAIVE-KSEP-SC has a complexity of O(∆ · f · |O|2 ) and an approximation ratio of 1 + ln(f ).
Proposition 32. A solution E to NAIVE-KSEP-SC provides a partner to every observation in O if a partner exists – otherwise, it returns IMPOSSIBLE.
The algorithm NAIVE-KSEP-SC is a naive, straight-forward application of the
O(|E|·|F |·size) greedy approach for set-cover as presented in [136]. We note that it is
172

Algorithm 14 (NAIVE-KSEP-SC)
INPUT: Space S, a set O of observations, a feasibility predicate feas, and real numbers α ≥ 0, β > 0
OUTPUT: Set E ⊆ S that explains O
1. Initialize list E to null. Let M be a matrix array of the same dimensions as S of lists of pointers initialized
to null. For a given p ∈ S, M [p] is the place in the array. Let L be a list of pointers to lists in M , L is
initialized to null.
2. Let O ′ be an array of Booleans of length |O|. ∀i ∈ [1, |O|], initialize O ′ [i] = TRUE. For some element o ∈ O,
O ′ [o] is the corresponding space in the array. Let numObs = |O|
3. For each element o ∈ O, do the following.
(a) Determine all elements p ∈ S such that feas(p) = TRUE and d(o, p) ∈ [α, β]
(b) If there does not exist a p ∈ S meeting the above criteria, then terminate the program and return
IMPOSSIBLE.
(c) If M [p] = null then add a pointer to M [p] to L
(d) Add a pointer to o to the list M [p].

4. While numObs > 0 loop

(a) Initialize pointer cur ptr to null, integer cur size to 0
(b) For each ptr ∈ L, do the following:
i. Initialize integer this size to 0, let M [p] be the element of M pointed to by ptr
ii. For each obs ptr in the list M [p], do the following
A. Let i be the corresponding location in array O ′ to obs ptr
B. If O ′ [i] = TRUE, increment this size by 1
iii. If this size > cur size, set cur size = this size and have cur ptr point to M [p]
(c) Add p to E
(d) For every obs ptr in the list pointed to by cur ptr, do the following:
i. Let i be the corresponding location in array O ′ to obs ptr
ii. If O ′ [i], then set it to FALSE and decrement numObs by 1
(e) Add the location in space S pointed to by cur ptr to E
5. Return E

173

possible to implement a heap to reduce the time-complexity to O(∆·f ·|O|·lg(∆·|O|))
- avoiding the cost of iterating through all possible partners in the inner-loop.
In addition to the straightforward greedy algorithm for set-covering, there
are several other algorithms that provide different time complexity/approximation
ratio combinations. However, with a reduction to the set-covering problem we must
consider the result of [113] which states that set-cover cannot be approximated
within a ratio c · log(n) for any c < 0.25 (where n is the number of subsets in the
family F ) unless N P ⊆ DT IM E[npoly

log n

].

A reduction to set-covering has the advantage of being straightforward. It
also allows us to leverage the wealth of approaches developed for this well-known
problem. In the next section, we show that k-SEP reduces to the dominating set
problem as well. We then explore alternate approximation techniques based on this
reduction.

4.3.3

An Exact Dominating Set Based Approach

We show below that k-SEP also reduces to the well known dominating set
problem (DomSet) [54] allowing us to potentially leverage fast algorithms such as
the randomized-distributed approximation scheme in [75]. DomSet is defined as
follows.

Dominating Set. (DomSet)
INPUT: Graph G = (V, E) and positive integer K ≤ |V |.

174

OUTPUT: “Yes” if there is a subset V ′ ⊂ V such that |V ′ | ≤ K and such that every
vertex v ∈ V − V ′ is joined to at least one member of V ′ by an edge in E.

As the dominating set problem relies on finding a certain set of nodes in a
graph, then, unsurprisingly, our reduction algorithm, Algorithm 15, takes space S,
an observation set O, feasibility predicate feas, and numbers α, β and returns graph
GO based on these arguments.
We now present an example to illustrate the relationship between a dominating
set of size k in GO and a k-sized simple (α, β) explanation for O. The following
example illustrates the relationship between a k-SEP problem and DomSet.
Example 4.3.2. Consider the serial killer scenario in Example 4.1.4, pictured in
Figure 4.2 (right). Suppose we want to solve this problem as an instance of k-SEP
by a reduction to DomSet. We want to find a 1-sized simple (α, β) explanation
(safe-house) for O (the set of crime scenes, {o1 , o2 }). Suppose that after running
an algorithm such as STRAIGHFORWARD-SEP, we find that {p1 , p2 , p3 } are elements
of S that are feasible. {p1 , p2 } are all within a distance of α, β from o1 and {p2 , p3 }
are all within a distance of α, β from o2 . We run KSEP-TO-DOMSET which creates
graph, GO . Refer to Figure 4.3 for the graph. We can see that {p2 } is a 1-sized
dominating sets for GO , hence a 1-sized explanation for O.
We notice that the inner loop of KSEP-TO-DOMSET is bounded by O(∆)
operations and the outer loop will iterate |O| times. Thus, the complexity of KSEPTO-DOMSET is O(∆ · |O|).
175

Figure 4.3: Results of KSEP-TO-DOMSET based on data seen in Figure 4.2 (right).
Note that {p1 , p2 , p′1 , p′2 } form a complete graph and {p2 , p3 , p′′2 , p′3 } also form a complete graph. Note that {p2 } is a dominating set of size 1. Hence, {p2 } is a 1-sized
simple (α, β) explanation for O, as depicted in Figure 4.2 (right).
Proposition 33. The complexity of KSEP-TO-DOMSET is O(∆ · |O|).
Example 4.3.2 should give us some intuition into why the reduction to DomSet works. We provide the formal proof in the Appendix.
Theorem 22. k-SEP is polynomially reducible to DomSet.
The straightforward approximation scheme for DomSet is to view the problem as an instance of SET COVER and apply a greedy algorithm. The reduction
would view the set of vertices in GO as the elements, and the family of sets as each
vertex and its neighbors. This results in both a greater complexity and a worse
approximation ratio when compared with the reduction directly to SET COVER.
Proposition 34. Solving k-SEP by a reduction to DomSet using a straightforward greedy approach has time-complexity O(∆3 · f · |O|2 ) and an approximation
ratio bounded by O(1 + ln(2 · f · ∆)).
There are other algorithms to approximate DomSet [75, 89]. By leveraging
[75], we can obtain an improved complexity while retaining the same approximation
176

ratio as the greedy approach.
Proposition 35. Solving k-SEP by a reduction to DomSet using the distributed,
randomized algorithm presented in [75] has a time complexity O(∆ · |O| + ln(2 · ∆ ·
|O|) · ln(2 · ∆ · f )) with high probability and approximation ratio of O(1 + ln(2 · f · ∆)).
Hence, although a reduction to dominating set generally gives us a worse
approximation guarantee, we can (theoretically) outperform set-cover with the randomized algorithm for dominating set in terms of complexity.

4.3.4

An Exact Integer Linear Programming based Approach

Given an instance of k-SEP, we show how to create a set of integer constraints
that if solved, will yield a solution to the problem.
Definition 56 (OPT-KSEP-IPC). The k-SEP integer programming constraints (OPTKSEP-IPC) require the following information, obtained in O(|O| · π(β 2 − α2 ) time:
• Let L be the set of all possible partners generated in the first four steps of NAIVEKSEP-EXACT.
• For each p ∈ L, let str(p) be the string of |O| bits, where bit str(p)i is 1 if p is
a partner of the ith observation (this is also generated in the first four steps of
NAIVE-KSEP-EXACT).
For each pj ∈ L, let xj ∈ {0, 1}. xj = 1 iff pj is in E.
Then KSEP-IPC consists of the following:
Minimize

P

pj ∈L

xj subject to
177

1. ∀oi ∈ O,

P

pj ∈L

xj · str(pj )i ≥ 1

2. ∀pj ∈ L, xj ∈ {0, 1} (for the relaxed linear program: xj ≤ 1)
Proposition 36. OPT-KSEP-IPC consists of O(|O|π(β 2 −α2 )) variables and O(|O|·
π(β 2 − α2 )) constraints.
Proposition 37. For a given instance of the optimization version k-SEP, if OPTKSEP-IPC is solved, then

S

pj ∈L x =1
j

pj is an optimal solution to k-SEP.

Example 4.3.3. Consider the serial killer scenario in Example 4.1.4, pictured in
Figure 4.2 (right). Suppose we want to solve this problem as an instance of MINSEP.
We would set up the constraints as follows:
Minimize x1 +x2 +x3 subject to 1·x1 +1·x2 +0·x3 ≥ 1 and 0·x1 +1·x2 +1·x3 ≥ 1,
where x1 , x2 , x3 ∈ {0, 1}
Obviously, setting x1 = 0, x2 = 1, x3 = 0 provides an optimal solution. Hence, as x2
is the only non-zero variable, p2 is the explanation for the crime-scenes.
A solution to the constraints OPT-KSEP-IPC can be approximated using the
well-known “rounding” technique [68, 174] that relaxes constraints. We present an
OPT-KSEP-IPC using rounding.
Proposition 38. NAIVE-KSEP-ROUND returns an explanation for O that is within
a factor ∆ from optimal, where ∆ is the maximum number of possible partners
associated with any observation.
There are several things to note about this approach. First, it can be easily
adapted to many of the weighted variants - such as WT-SEP. Second, we note
178

that the rounding algorithm is not a randomized rounding algorithm – which often
produces a solution that satisfies all of the constraints in the linear-integer program.
The above algorithm guarantees that all of the observations will be covered (if an
explanation exists). Finally, this approach allows us to leverage numerous software
packages for solving linear and linear-integer programs.

179

Algorithm 15 (KSEP-TO-DOMSET)
INPUT: Space S, a set O of observations, a feasibility predicate feas, and real
numbers α ≥ 0, β > 0
OUTPUT: Graph GO for use in an instance of a DomSet problem
1. Let GO = (VO , EO ) be a graph. Set VO = S and EO = ∅.
2. Let S be a mapping defined as S : S → VO . In words, S takes elements of the
space and returns nodes from GO as defined in the first step. This mapping does
not change during the course of the algorithm.
3. For each oi ∈ O do the following
(a) Determine all points p ∈ S that are such that α ≤ d(o, p) ≤ β. Call this set Pi
(b) For all p ∈ Pi calculate feas(p). If feas(p) = FALSE, remove p from Pi .
(c) Let Vi = {v ∈ VO |∃p ∈ Pi such that S(p) = v}.
(d) Add |Pi | new nodes to VO . Add these nodes to Vi as well.
(e) For every pair of nodes v1 , v2 ∈ Vi , add edge (v1 , v2 ) to EO .
4. Remove all v ∈ VO where there does not exist an v ′ such that (v, v ′ ) ∈ EO
5. If any Pi ≡ ∅ return IMPOSSIBLE. Otherwise return GO .

180

Algorithm 16 (NAIVE-KSEP-ROUND)
INPUT: Space S, a set O of observations, a feasibility predicate feas, and real
numbers α ≥ 0, β > 0
OUTPUT: Set E ⊆ S that explains O
1. Run the first four steps of NAIVE-KSEP-EXACT
2. Solve the relaxation of OPT-KSEP-IPC
3. For the o ∈ O with the most possible partners, let ∆ be the number of possible
partners associated with o. This can be done in line 1
4. Return all pj ∈ L where xj ≥

1
∆

181

4.4

Greedy Heuristics for GAP Problems

4.4.1

A Linear Time Greedy Approximation Scheme

In this section, we introduce a greedy approximation scheme for the optimization version of k-SEP that has a lower time-complexity than NAIVE-KSEP-SC but
still maintains the same approximation ratio. Our GREEDY-KSEP-OPT1 algorithm
runs in linear time w.r.t. O. The key intuition is that NAIVE-KSEP-SC iterates
through O(∆ · |O|) possible partners in line 4. Our algorithm first randomly picks
an observation and then greedily selects a partner for it. This results in the greedy
step iterating through only O(∆) partners.
Example 4.4.1. Consider the sun bear from Example 4.1.3 and Figure 4.2. After
initializing the necessary data structures in lines 1-3, GREEDY-KSEP-OPT1 iterates
through the observations in O where the associated position in O′ is TRUE. Suppose
the algorithm picks o1 first. It now accesses the list pointed to from OBS[o1 ]. This
gives us a set of pointers to the following elements of S: {p1 , p2 , p3 , p4 }. Following
the greedy selection outlined in line 4 of NAIVE-KSEP-SC, the algorithm iterates
through these points, visiting the list of observations associated with each one in the
matrix array M .
First, the algorithm accesses the list pointed to by M [p1 ]. Figure 4.4 (left)
shows the observations considered when p1 is selected. As there is only one observation in list M [p1 ] whose associated Boolean in O′ is TRUE, the variable cur size is
set to 1 (see line 4(b)iii of NAIVE-KSEP-SC). cur ptr is then set to M [p1 ].

182

Algorithm 17 (GREEDY-KSEP-OPT1)
INPUT: Space S, a set O of observations, a feasibility predicate feas, and real
numbers α ≥ 0, β > 0
OUTPUT: Set E ⊆ S that explains O
1. Run lines 1-2 of NAIVE-KSEP-SC
2. Let OBS be an array, size |O| of lists to pointers in M . For some observation o, let
OBS[o] be the corresponding list in the array.
3. Run the loop in line 3 of NAIVE-KSEP-SC but when partner p of observation o
is considered, add a pointer to M [p] in the list OBS[o]. The list L need not be
maintained.
4. While numObs > 0 loop
(a) Randomly select an element o ∈ O such that O′ [o] = TRUE
(b) Run the greedy-selection loop of line 4 of NAIVE-KSEP-SC, but consider the
list OBS[o] instead of L
5. Return E

183

Figure 4.4: Left: GREEDY-KSEP-OPT1 accesses the list pointed to by M [p1 ] thus
considering all observations available to p1 . Right: GREEDY-KSEP-OPT1 accesses
the list pointed to by M [p2 ] and finds it has more active observations than it found
in the list pointed to by M [p1 ].
Now we consider the next element, p2 . Figure 4.4 (right) shows the list pointed
to by M [p2 ]. As M [p2 ] points to more observations whose associated O′ Boolean is
TRUE, we update cur size to 2 and cur ptr to M [p2 ].
The algorithm then iterates through p3 and p4 , but finds they do not offer more
observations than p2 . Hence, p2 is added to the solution set (E). The algorithm
updates the array of Booleans, O′ and sets O′ [o1 ] and O′ [o2 ] to FALSE (depicted by
X’s over those observations in subsequent figures). numObs is decremented by 2.
Now, we enter the second iteration of line 4. The only element for the algorithm to pick at this point is o3 , as only O′ [o3 ] is TRUE. The list OBS[o3 ] points
to the positions {p6 , p7 , p8 }. In Figure 4.5 we look at what happens as the algorithm considers the p7 . As OBS[o2 ] = FALSE, it only considers o3 when computing
this size.
When the algorithm finishes its consideration of all the elements pointed to
184

Figure 4.5: GREEDY-KSEP-OPT1 considers the observations available to p7 . The
X’s on o1 and o2 signify that OBS[o1 ] and OBS[o2 ] are set to FALSE.
by OBS[o3 ], it will return the first element of that set (p6 ) as neither p7 nor p8
were partners to more available observations than p6 (in our implementation of this
algorithm, we use a coin-flip to break ties among partners with the same number of
observations). GREEDY-KSEP-OPT1 then adds p6 to E and terminates. The final
solution returned, {p2 , p6 }, is a valid (and in this case, optimal) explanation.
Proposition 39 (Complexity of GREEDY-KSEP-OPT1). GREEDY-KSEP-OPT1 has
a complexity of O(∆ · f · |O|) and an approximation ratio of 1 + ln(f ).
Proposition 40. GREEDY-KSEP-OPT1 returns a |E|-sized (α, β) explanation for
O.
GREEDY-KSEP-OPT1 returns IMPOSSIBLE if there is no explanation for O.
We can bound the approximation ratio for GREEDY-KSEP-OPT1 by O(1 +
ln(f )), as it is still essentially a greedy algorithm for a covering problem. The
main difference between GREEDY-KSEP-OPT1 is the way it greedily chooses covers
(partners). This algorithm randomly picks an uncovered observation in each loop
185

and then greedily chooses a cover that covers that observation. Improving the
accuracy of this algorithm (in practice) is tied directly to the selection criteria used
to pick observations, which is random in GREEDY-KSEP-OPT1. In Section 4.4.2
we develop an algorithm that “smartly” picks observations with a dynamic ranking
scheme while maintaining a time complexity lower than the standard set-covering
approach.

4.4.2

Greedy Observation Selection

GREEDY-KSEP-OPT1 randomly selects observations although subsequent partner selection was greedy. It is easy to implement an a-priori ranking of observations
based on something like the maximum number of other observations which share
a partner with it. Such a ranking could be implemented at the start of GREEDYKSEP-OPT1 with no effect on complexity, but the ranking would be static and may
lose its meaning after several iterations of the algorithm. We could also implement
a dynamic ranking. We present a version of GREEDY-KSEP-OPT1 that we call
GREEDY-KSEP-OPT2 that picks the observations based on dynamic ranking, runs
in time O(∆ · f 2 · |O| + |O| · ln(|O|)), and maintains the usual approximation ratio of
1 + ln(f ) for greedy algorithms. Our key intuition was to use a Fibonacci heap [49].
With such a data structure, we can update the rankings of observations at constant
amortized cost per observation being updated. The most expensive operation is to
remove an observation from the heap - which costs an amortized O(ln(|O|)), however
as we can never remove more than |O| items from the heap, this cost is most likely

186

dominated by the cost of the rest of the algorithm, which is more expensive than
GREEDY-KSEP-OPT1 by a factor of f . Recall that f is the bound on the number
of observations supported by a single partner - and is often very small in practice.
In order to leverage the Fibonacci heap, there are some restrictions on how
the ranking can be implemented. First, the heap puts an element with the minimal
key on top, and can only decrease the key of elements - an element in the heap can
never have its key increased. Additionally, there is a need for some auxiliary data
structures as searching for an element in the heap is very expensive. Fortunately,
the k-SEP problem is amenable to these type of data structures.
We based the key (ranking) on a simple heuristic for each observation. The
key for a given observation o is the number of unique observations that share a
partner with o. As we are extracting the minimum-keyed observation, we are taking
the observation that has the “least in common” with the other observations. The
intuition of choosing an observation with “less in common” with other observations
ensures that outliers get covered with larger covers. Meanwhile, elements with a
higher rank in this scheme are covered last, which may lead to a more efficient
cover. In Section 4.5 we show experimentally that this heuristic was viable for the
data-set we considered - providing more accurate results than the reduction from
set-covering.
Example 4.4.2. The basic intuition behind GREEDY-KSEP-OPT2 is similar to
GREEDY-KSEP-OPT1 in that it iterates through the observations and greedily chooses
a partner. The main difference is that it ranks the observations instead of just ran-

187

Algorithm 18 GREEDY-KSEP-OPT2
INPUT: Space S, a set O of observations, a feasibility predicate feas, and real numbers α ≥ 0, β > 0
OUTPUT: Set E ⊆ S that explains O
1. Run lines 1-3 of GREEDY-KSEP-OPT1.

2. Let key1 , . . . key|O| be natural numbers associated with each observation. Initially, they are set to 0. For
some o ∈ O let keyo be the associated number.
3. Let REL OBS be an array of lists of pointers to elements of O. The size of the array is O. For element
o ∈ O, let REL OBS[o] be the corresponding space in the array.
4. For each o ∈ O, do the following:
(a) For each element p ∈ OBS[o], do the following.
i. For each element obs ptr of the list pointed to by M [p], do the following
A. If obs ptr points to an element of O not pointed to in the list REL OBS[o], then add
obs ptr to REL OBS[o] and increment keyo by 1.

5. Let OBS HEAP be a Fibonacci heap. Let QUICK LOOK be an array (size O) of pointers to elements of
the heap. For each o ∈ O, add the tuple ho, keyo i to the heap, along with a pointer to the tuple to
QUICK LOOK[o]. Note we are using keyo as the key for each element in the heap.

6. While OBS HEAP is not empty, loop

(a) Take the minimum element of OBS HEAP, let o be the associated observation with this element.
(b) Greedily select an element of OBS[o] as done in the loop at line 4 of GREEDY-KSEP-OPT1. We shall
call this element p.
(c) For every o′ ∈ O pointed to by a pointer in M [p], such that O ′ [o′ ] = TRUE, do the following.
i. Set O ′ [o′ ] = FALSE
ii. Remove the element pointed to by QUICK LOOK[o′ ] from OBS HEAP
iii. For every element o′′ ∈ O pointed to by an element of REL OBS[o′ ] where O ′ [o′′ ] = TRUE do
the following.
A. Decrease the keyo′′ by 1.
7. Return E

188

Observation

keyi

REL OBS[oi ]

o1

2

{o1 , o2 }

o2

2

{o1 , o2 }

o3

2

{o2 , o3 }

Table 4.1: key values and related observations for observations in the sun bear
scenario introduced in Example 4.1.3.
domly selecting them. Consider the sun bear from Example 4.1.3 whose behavior is
depicted in Figure 4.2. In Example 4.4.1, we used GREEDY-KSEP-OPT1 to solve
the associated k-SEP problem for this situation. We shall discuss how GREEDYKSEP-OPT2 differs.
The first main difference is that the algorithm assigns a rank to each observation oi ,
called keyi , which is also the key used in the Fibonacci heap. This is done in the
loop at line 4. It not only calculates keyi for each observation, but it also records
the elements “related” to it in the array REL OBS. Note that a “related” observation
needs only to share a partner with a given observation. Not all related observations
need to have the same partner. For the sun bear scenario, we show the keys and
related observations in Table 4.1.
As the key values are the same for all elements of O, let’s assume the algorithm
first considers o1 as in Example 4.4.1. As written, we would take the minimum element in the Fibonacci heap (a constant time operation). We would then consider the
partners for o1 which would result in the greedy selection of p2 , (just as in GREEDY189

Figure 4.6: Left: GREEDY-KESP-OPT2 considers all observations that can be partnered with p2 . Notice that in this figure by each observation we show a box that
represents the key of the observation in the Fibonacci heap. Right: GREEDY-KSEPOPT2 removes o1 from the heap, and iterates through the elements in REL OBS[o1 ],
causing it to decrease the key of o2 .
KSEP-OPT1 and NAIVE-KSEP-SC. Also notice we retain the array of Booleans, O′
as well as the array of lists, M to help us with these operations.).
Now the issue arises that we must update the keys for the remaining observations, as well as remove observations covered by p2 . As we maintain REL OBS
and O′ , the procedure quickly iterates through the elements covered by p2 : o1 and o2 .
Figure 4.6 shows the status of the observations at this point.
We remove o1 from the heap, and set O′ [o1 ] to FALSE. This prevents us from
considering it in the future. We now iterate through each o′′ in the list pointed to
by REL OBS[o1 ] where O′ [o′′ ] is TRUE and decrease the key of each by one. As per
table 4.1, REL OBS[o1 ] = {o1 , o2 }. As O′ [o1 ] = FALSE we do nothing. As O′ [o2 ] =
TRUE, we decrease the key of the associated node in the Fibonacci heap. The array
190

QUICK LOOK ensures we can access that element in constant time. Figure 4.6 (left)
graphically depicts this action.
Next, we consider the other element covered by partner p2 : o2 . After removing
this element from the heap and setting O′ [o2 ] to FALSE, we can easily see that there
does not exist any o′′ ∈ REL OBS[o2 ] where O′ [o′′ ] = TRUE. Hence, we can proceed to
pick a new minimum observation from the heap - which is o3 in this case. The greedy
selection proceeds (resulting in the choice of p6 ), followed by the update procedure
(which simply removes the node associated with o3 from the heap and sets O′ [o3 ] =
FALSE). As there are no more elements in the heap, GREEDY-KSEP-OPT2 returns
the solution {p2 , p6 }.
Theorem 23 (Complexity of GREEDY-KSEP-OPT2). GREEDY-KSEP-OPT2 has a
complexity of O(∆ · f 2 · |O| + |O| · ln(|O|)) and an approximation ratio of 1 + ln(f ).
Proposition 41. GREEDY-KSEP-OPT2 returns a |E|-sized (α, β) explanation for
O.
GREEDY-KSEP-OPT2 returns IMPOSSIBLE if there is no explanation for O.

4.5

Implementation and Experiments
In this section, we show that our geospatial abduction framework and algo-

rithms are viable in solving real-world geospatial abduction problems. Using a realworld data set consisting of counter-insurgency information from Iraq, we were able
to accurately locate insurgent weapons cache sites (partners) given previous attacks
(observations) and some additional data (used for feas and α, β). This validates our
191

primary research goal for the experiments - to show that geospatial abduction can
be used to solve problems in the real-world.
We considered the naive set-covering approach along with GREEDY-KSEPOPT1 and GREEDY-KSEP-OPT2, which according to our analytical results, had the
best approximation ratios and time-complexities. We implemented these algorithms
in 4000 lines of Java code, running on a Lenovo T400 ThinkPad laptop running
Vista with an Intel Core 2 Duo T9400 2.53 GHz processor and 4.0 GB of RAM.
Our SCARE (Social-Cultural Abductive Reasoning Engine) system [157] enabled us
to carry out tests on real-world data. This data includes 21 months of Improvised
Explosive Device or IED attacks in Baghdad6 (a 25x27 km region) – these constitute
our observations. It also included information on locations of caches associated with
those attacks discovered by US forces. The locations of the caches constitute the
(α, β) explanation we want to learn. We used data from the International Medical
Corps to define feasibility predicates which took the following factors into account:
(i) the ethnic makeup of neighborhoods in Baghdad - specifically, Sunni locations
were deemed infeasible for cache locations, (ii) the locations of US bases in Baghdad
were also considered infeasible and (iii) bodies of water were also deemed infeasible.
We also separately ran tests on that part of the above data focused on Sadr City
(a 7x7 km district in Baghdad) alone. On both these regions, we overlaid a grid
whose cells were 100m x 100m each — about the size of a standard US city block.
All timings were averaged over 100 runs.
We split the data into 2 parts — the first 7 months of data was used as a
6

Attack and cache location data was provided by the Institute for the Study of War

192

Algorithm 19 (FIND-BOUNDS)
INPUT: Historical, time-stamped observations Oh , historical, time-stamped partners, Eh , real number (distance threshold) βmax
OUTPUT: Real numbers α, β
1. Set α = 0 and β = βmax
2. Set Boolean variable f lag to TRUE
3. For each o ∈ Oh , do the following:
(a) For each p ∈ Eh that occurs after o, do the following.
i. Let d be the Euclidean distance function.
ii. If f lag, and d(o, p) ≤ βmax then set α = d(o, p) and β = d(o, p)
iii. If not f lag, then do the following:
A. If d(o, p) < α then set α = d(o, p)
B. If d(o, p) > β and d(o, p) ≤ βmax then set β = d(o, p)
4. Return reals α, β

“training” set and the next 14 months of data was used for experimental evaluation.
We used the following simple algorithm, FIND-BOUNDS, to determine the α, β values. We set βmax to 2.5 km. We leave more advanced procedures for learning these
parameters to future work. Such parameters could also come from an expert.
Accuracy. Our primary goal in the experiments was to determine if the geospatial
abduction framework and algorithms could provide viable results in a real-world
setting. “Accuracy” in this section refers to two aspects - size of the solution, and

193

Area

Algorithm

Sample Mean

Sample Mean

Solution Size

Number of Partners
≤ 0.5 km
to actual cache

Baghdad

Sadr City

NAIVE-KSEP-SC

14.53

8.13

GREEDY-KSEP-OPT1

15.02

7.89

GREEDY-KSEP-OPT2

14.00

7.49

NAIVE-KSEP-SC

8.00

3.00

GREEDY-KSEP-OPT1

6.61

4.44

GREEDY-KSEP-OPT2

6.00

5.28

Table 4.2: k-SEP Algorithm Results - Solution Size
the distance to the nearest actual cache site. The distance to nearest cache site was
measured by taking the straight-line Euclidean distance to the nearest cache site
that was found after the first attack supported by the projected cache site. We used
the raw coordinate for the actual cache in the data set - not the position closest to
the nearest point in the 100 m resolution grid that we overlaid on the areas. The
accuracy results are summarized in Tables 4.2-4.3.
Overall, GREEDY-KSEP-OPT2 consistently found the smallest solution - of
cardinality 14 for Baghdad and 6 for Sadr City - on all 100 trials. For Baghdad, the
other two algorithms both found a solution of size 14, but both averaged a higher
solution. For Sadr City, GREEDY-KSEP-OPT1 often did find a solution of 6 caches
while NAIVE-KSEP-SC only found solutions of size 8. Additionally, in both tests, the
solution sizes for GREEDY-KSEP-OPT1 varied more than the other two algorithms.
194

Area

Baghdad

Sadr City

Algorithm

Sample Mean

Sample Std Dev

Sample Mean

Avg Dist to

of Avg Dist to

Std Dev of Dist to

actual cache

actual cache

actual cache

NAIVE-KSEP-SC

0.79 km

0.02

0.64

GREEDY-KSEP-OPT1

0.76 km

0.07

0.60

GREEDY-KSEP-OPT2

0.72 km

0.03

0.63

NAIVE-KSEP-SC

0.72 km

0.03

0.46

GREEDY-KSEP-OPT1

0.45 km

0.03

0.46

GREEDY-KSEP-OPT2

0.35 km

0.03

0.47

Table 4.3: k-SEP Algorithm Results - Distances to Actual Cache Sites
Moreover, the HSD for both Baghdad and Sadr City indicated significant difference
between all pairs of algorithms wrt solution size.
Of the partners in a given solution, we also recorded the number of partners less
than 0.5 km away from an actual cache. For Baghdad, NAIVE-KSEP-SC performed
best in this regard - averaging 8.13 partners less than 0.5 km from an actual cache
site. Although this result for Baghdad is significant based on an analysis of variance
(ANOVA) and honest significant differences (HSD) (p-value of 2.3 · 10−9 ), we also
note that the greatest difference among averages was still less than one partner.
This same result for Sadr City, however, tells a different story. For this test, NAIVEKSEP-SC performed poorly with regard to the other two algorithms - only finding
3 partners meeting these criteria for each of the 100 trials. GREEDY-KSEP-OPT2
performed very well in this aspect (for Sadr City). It averaged over 5 partners less

195

than 0.5 km from an actual cache. Further, for Sadr City, all partners found by
GREEDY-KSEP-OPT2 were within 600 m of an actual cache site. The ANOVA (pvalue of 2.2 · 10−16 ) and HSD of partners less than 0.5 km from an actual cache for
the Sadr City trials indicate that these results are significant.
Our primary metric of accuracy was average distance to actual cache. In this
regard, GREEDY-KSEP-OPT2 performed the best. It obtained an average distance
of 0.72 km for Baghdad and 0.35 km for Sadr City. This number was 40 m less for
Baghdad and 100 m less for Sadr City when compared to GREEDY-KSEP-OPT1,
whose average distance varied widely among the trials. With regard to this metric,
NAIVE-KSEP-SC performed the worst - particularly in Sadr City, where it predicted
caches over twice as far from actual caches as GREEDY-KSEP-OPT2 (on average).
For both Baghdad and Sadr City, the simple ANOVA yielded a p-value of 2.2 · 10−16 ,
which suggests with a 99% probability that there is a difference among the algorithms. Also, for both areas, Tukey’s HSD indicates significant difference between
each pair-wise comparison of algorithms.
Algorithm run times. Table 4.4 shows the run-times of our algorithms. In
order to validate the findings suggested by Table 4.4 statistically, we ran analysis of
variance (ANOVA) and Tukey’s Honest Significant Difference test (HSD) for pairwise comparisons [50]. An ANOVA for the Baghdad run-times gave a p-value of
2.2·10−16 , which suggests with well over 99% probability that GREEDY-KSEP-OPT1
is statistically faster than GREEDY-KSEP-OPT2. The HSD for Baghdad indicates
that, with regard to run-times, all pair-wise-comparison of the three algorithms are
significantly different. For Sadr City, the ANOVA gave a p-value of 4.9 · 10−3 , which
196

Area

Algorithm

Sample Mean Run-Time

Sample Run-Time
Standard Deviation

Baghdad

Sadr City

NAIVE-KSEP-SC

354.75 ms

12.86

GREEDY-KSEP-OPT1

162.08 ms

40.83

GREEDY-KSEP-OPT2

201.40 ms

36.44

NAIVE-KSEP-SC

28.85 ms

10.52

GREEDY-KSEP-OPT1

25.44 ms

9.33

GREEDY-KSEP-OPT2

24.64 ms

8.95

Table 4.4: k-SEP Algorithm Performance Results
suggests with a 99% probability that the algorithms differ in run-times. However, the
HSD indicates, with an 82% probability, that there is no difference among GREEDYKSEP-OPT1 and GREEDY-KSEP-OPT2, while both differ significantly from NAIVEKSEP-SC.

4.5.1

A Simple Heuristic to Improve Accuracy

In our implementation of all three algorithms, “ties” in greedy selection of
partners were determined by a “coin toss.” Specifically, we are considering the case
where this size = cur size in line 4(b)iii of NAIVE-KSEP-SC in Section 4.3.2. Let
us re-phrase the situation as follows. Let O be the entire set of observations and
O′ ⊆ O be the set of observations currently not assigned a partner. Let p be the
current partner that best meets the criteria for greedy selection and p′ be the partner
197

we are considering. We define P and P ′ as subsets of O that are the observations
associated with p and p′ respectively. Hence, if |P ′ ∩ O′ | > |P ∩ O′ |, we pick p′ .
As implemented, if |P ′ ∩ O′ | = |P ∩ O′ |, we flip a coin. We add a simple heuristic
that simply states that “partners that cover more observations are preferred.” We
change the criteria as follows:
• If |P ′ ∩ O′ | = |P ∩ O′ |, then do the following:
• If |P ′ | > |P |, pick p′
• If |P | > |P ′ |, pick p
• If |P | = |P ′ |, flip a coin
We shall refer to this as the “tie-breaker” heuristic. The result is that the solution
set of partners covers more observations and hence provides a more “dense” solution.
We added this heuristic to our existing code for all three algorithms and ran
each one 100 times for both the Baghdad and Sadr City areas. Unsurprisingly, as
this is a constant-time operation, run-times were not affected. However, accuracy
improved in all cases. As GREEDY-KSEP-OPT2 still provided the most accurate
results, the following exposition shall focus on how the heuristics affected the solution
size and accuracy for this algorithm.
Because the tie-breaker heuristic only adjusts how two partners are chosen both of which can be paired with the same uncovered observations - the size of the
solution was unaffected in both the Baghdad and Sadr City trials. However, the
number of predicted cache sites less than 500 m from an actual site increased for
both the Baghdad and Sadr City tests. For Baghdad, more trials returned solutions
198

Area

Tie-Breaker

Sample Mean

Sample Mean

Heuristic

Solution Size

Number of Partners
≤ 0.5 km
to actual cache

No

14.00

7.49

Yes

14.00

7.87

No

6.00

5.28

Yes

6.00

6.00

Baghdad

Sadr City

Table 4.5: The Tie-Breaker heuristic on GREEDY-KSEP-OPT2 - Solution Size

Area

Tie-Breaker

Sample Mean

Sample Std Dev

Sample Mean

Heuristic

Avg Dist to

of Avg Dist to

Std Dev of Dist to

actual cache

actual cache

actual cache

No

0.72 km

0.03

0.63

Yes

0.69 km

0.02

0.64

No

0.35 km

0.03

0.47

Yes

0.28 km

0.02

0.11

Baghdad

Sadr City

Table 4.6: The Tie-Breaker heuristic on GREEDY-KSEP-OPT2 - Distances to Actual
Cache Sites

199

with 8 predictions less than 500 m from an actual site than returned 7 - the opposite
being the case without the tie-breaker heuristic. For Sadr City, all elements of every
solution set returned was less than 500 m from an actual cache site. Using the well
known T-Test [50], we showed that these results are statistically significant as this
test returned a p-value of 6.2 · 10−8 for Baghdad and 2.2 · 10−16 for Sadr City.
Summary. The above experiments demonstrate statistically that GREEDY-KSEPOPT2 provides a viable solution - consistently producing the smaller solution sets
which were closer to actual cache sites faster than the basic set-covering approach,
at times approaching the faster, although less-accurate GREEDY-KSEP-OPT1. The
proximity of the elements of the solution set to actual cache sites is encouraging for
real-world use. The results are strong enough that two US Army units used SCARE
to aide in locating IED caches.

4.6

Chapter 4 Related Work
In this section we present related work of three different varieties. We com-

pare GAPs to other forms of abduction, facility location, k-means clustering, and
constrained clustering. As an aside, readers interested in a discussion of the SCARE
software from the perspective of military analysis or social science can refer to [157]
where the software package was introduced. However, that work does not include
any formal technical details on the framework of geospatial abduction, complexity
results, or algorithm analysis.
GAPs and other forms of Abduction. Abduction [137] has been extensively

200

studied in medicine [141, 138], fault diagnosis [26], belief revision [133], database
updates [77, 27] and AI planning [37]. Two major existing theories of abduction
include logic-based abduction [41] and set-covering abduction [19]. Though none
of the above papers deals with spatial inference, [160] presents a logical formalism
dealing with objects’ spatial occupancy, while [149] describe the construction of a
qualitative spatial reasoning system based on sensor data from a mobile robot. In
[149], sensor data are explained by hypothesizing the existence of physical objects
along with the dynamic relationships that hold between them, all with respect to a
(possibly moving) viewpoint. This approach combines both space and time. [90] describes the Spatial Semantic Hierarchy which formalizes, the spatial context in which
a robot moves. In the hierarchy, the topological level defines a map which describes
the environment as a collection of places, paths, and regions, linked by topological relations such as connectivity, order, containment, boundary, and abstraction.
Places (i.e., zero-dimensional points), paths (i.e., one dimensional subspaces, denoting for example a street in a city, possibly represented as an ordering relation on the
places they contain), and boundary regions (i.e., two-dimensional subspaces of the
robot environment) are created from experience represented as a sequence of views
and actions. They are created by abduction, positing the minimal additional set of
places, paths, and regions required to explain the sequence of observed views and
actions.
Set-covering abduction [19] assumes the existence of a function determining
the observable effects of a set of hypotheses, and is based on inverting such function.
Given a set of hypotheses H and a set of observations O, the domain knowledge
201

is represented by a function e that takes as an argument a set of hypotheses and
gives as a result the corresponding set of observations. Thus, for every subset of the
hypotheses H ′ ⊆ H, their effects are known to be e(H ′ ). In this case, abduction
finds a set H ′ ⊆ H such that O ⊆ e(H ′ ), that is, it finds a set of hypotheses H ′
whose effects e(H ′ ) include all observations in O. A common assumption is that the
effects of the hypotheses are independent, that is, for every H ′ ⊆ H, it holds that
e(H ′ ) =

S

h∈H ′

e({h}). If this condition is met, abduction can be seen as a form of

set-covering. No spatial reasoning is done here.

Comparison with facility location. There are several important ways in which
GAPs differ from facility location problems.
• Although it is possible to specify a distance-based cost function, in a GAP problem, the distances between observations and partners are constraints (α and β in
this chapter) whereas facility location problems usually attempt to minimize the
distance between producers and consumers.
• In this chapter, GAP problems have a minimum distance between observations and
partners that must be exceeded. In many respects, this requirement makes GAP
problems more difficult than facility location and other computational geometry
problems as the set of possible partners that cover a given observation is a nonconvex ring. Further, the feasibility function (feas) adds non-uniform holes to
such a ring. [115] addresses the complexity of non-convex covering and highlights
issues with problems such as this.
202

• The feasibility predicate, feas is not part of a facility location problem. This gives
us the ability to restrict certain locations that can be partners.
• In general, the relation between observations and partners can be viewed to be a
set of constraints. In this chapter, we only used α, β,and feas. However, in the
future, we could add additional constraints. Further, as our formalism represents
space as a set of discrete points (also not typically done with facility location),
we can easily specify certain properties of these points to apply such constraints
(such as feas).
Comparsion with k -means clustering. A well-known and studied problem in
clustering location is the k-means problem [116]. This problem can be expressed as
follows:
k-means:
INPUT: Coordinates on a plane C and natural number k
OUTPUT: k disjoint sets of C, C1′ , . . . , Ck′ such that for each Ci , all the mean Euclidean distance among all c ∈ Ci is minimized.

Clustering problems group points into clusters, associating each cluster with a
center. At first glance, one may think that the points are equivalent to observations
and the “centers are equivalent to partners. However, this is not so. Most versions of
the clustering problem seek only to arrange points in groups – with “centers” being
a side-effect of the algorithm. Geospatial abduction problem seeks to find partners
that support observations and places constraints on the location of the partners 203

this is a key difference from “centers” in clustering problems. Clustering algorithms
cannot handle the generality of our feasibility predicate or the (α, β) constraints.
In addition to these obvious differences, we experimentally compared an implementation of k-means with GREEDY-KSEP-OPT2 on the Sadr City data. Even when
we ignore the obvious value of α, β and the feasibility predicate, GREEDY-KSEPOPT2 outperforms the SimpleKMeans solver in WEKA version 3.7.0 [180]. Note
that the exclusion of these parameters makes GREEDY-KSEP-OPT2 perform worse
than it performs with these parameters – yet, it performed better than k-means in
terms of accuracy. Our experiment was set-up as follows:
• We used the same area for the Sadr City tests, as the α value was 0 in these
tests and there were virtually no non-feasible points near the observations. This
allowed us to use WEKA’s k-means implementation “out-of-the-box” as we did
not have to implement any extra infrastructure to deal with feasibility and α = 0.
• We set k = 6, the number of partners consistently found by GREEDY-KSEPOPT2. Normally, we would rather have the algorithm determine this size. Note
that supplying the algorithm with a size already determined by GREEDY-KSEPOPT2 (and, also the smallest size of any explanation for Sadr City we found in
our trials) gives an advantage to k-means. Hence, we did not compare solution
sizes.
• We clustered the observations with k-means and considered the “center” of each
cluster the cache location for the cluster.
• We did not compare timing results, as we ran WEKA in its GUI environment.
204

We ran 500 iterations of the SimpleKMeans and worked with the average centers for the clusters as reported by WEKA. Multiple runs of the 500 iterations
yielded the same centers.

Average Distance Using WEKA, we obtained an average accuracy of 0.38 km, which
is worse than GREEDY-KSEP-OPT2 (average over 100 trials, 0.28 km).

Worst-Case Distance WEKA’s SimpleKMeans returned 2 of the 6 points with a distance of greater than 600 meters from a cache site. Without the “tie-breaking”
heuristic, GREEDY-KSEP-OPT2 never reported a prediction over 600 meters from
a cache site (all reported partners over 100 trials). With the heuristic, GREEDYKSEP-OPT2 never reported a prediction over 500 meters from a cache site.

Best-Case Distance The closest partners ever returned by GREEDY-KSEP-OPT2 (either with our without the heuristic) were 200 m away from an actual cache site (on
average, the closest partner per explanation was 220 m away). WEKA’s SimpleKMeans did return two partners less than 200 m - each only 100 m away from an
actual cache site.

These results suggest that k-means may not be the optimal method for GAP
problems. Further, it does not support feasibility and α. The results do hold some
promise for some variants of cost-based spatial explanation problems that require a
k input from one of our greedy-approaches. However, even in this case, there would
205

be modification required of the k-means algorithm to support feasibility and α.

Comparison with Constrained clustering. Constrained clustering [176] studies clustering where, in addition to the points to be clustered, there are constraints
that either force two points in the same cluster (must-link) or force two points to
be in different clusters (cannot-link). Later work on constrained clustering has focused on distance constraints between elements of C or distance constraints between
clusters [32]. Much of the work in this area is summarized in [14].
At first glance, it may appear that spatial abduction can be expressed as a
cannot-link constrained clustering problem as follows: For each o, o′ ∈ O if 6 ∃p ∈ S
s.t. d(o, p) ∈ [α, β], d(o′ , p) ∈ [α, β], and feas(p), then create a cannot-link constraint
for o, o′ .
However, such a mapping cannot be guaranteed to provide a correct result.
For example, take o1 , o2 , o3 and p12 , p23 , p13 . Suppose o1 and o2 share just partner
p12 , o2 and o3 share just partner p23 and o1 , o3 share just partner p13 . This is entirely
possible given the generality of feas. In such a case, all three observations could be
incorrectly grouped into a single cluster - although it is obvious there is no single
partner that supports all of them. Hence, such a mapping would not be trivial.
Further, most clustering algorithms are not seeking to constructively find centers
that are constrained. We leave the study of constrained clustering to solve GAP
problems (i.e. an adaption of the k-means algorithm) to future work. However,
it is also worth noting that solving constrained clustering problems given cannotlink constraints is NP-complete, so the application of clustering techniques to this
206

problem does not imply a more tractable version of geospatial abduction, but rather
an alternative heuristic.

4.7

Chapter Summary
There are a wide variety of problems where we can make geo-located observa-

tions “on the ground” and where we want to infer a partner location. In this chapter,
we have presented four examples of such problems — one dealing with serial killers,
another dealing with wildlife studies, and a third (perhaps more fun) application
dealing with finding sunken ships. A fourth real world application we have looked
at is that of finding weapons caches associated with Improvised Explosive Device
(IED) attacks in Iraq where we were able to use real world, open source data. It is
clear that many other applications exist as well. For example, a bizarre (but real
world) combination of two of our examples involves frequent attacks by man-eating
leopards on children in certain parts of greater Bombay in India. This situation is
analogous to the serial killer scenario where the leopard is the serial killer. We want
to find the leopard’s favorite “hang outs”, capture it, and solve the problem.
In this chapter, we have made an attempt to formally define a class of geospatial
abduction problems (GAPs for short). We specifically made the following contributions.
• We developed formal mathematical definitions of geospatial abduction problems,
including several variants of the above problems. We conducted a detailed analysis
of the complexity of these problems.
207

• We developed exact algorithms for many of the problems, including a straightforward enumeration approach (NAIVE-KSEP-EXACT), by showing and leveraging
reductions to both the set-covering and dominating set problems, and by articulating these geospatial abduction problems via integer linear programs.
• As the complexity of most of the problems we have studied is NP-hard, we developed two greedy approximation schemes for the k-SEP problem (other than
set-covering) and illustrated a scheme to quickly find a solution using randomized
approaches to the dominating set problem.
• We have implemented these algorithms and conducted experimental comparisons
of the reduction to set-covering and two other greedy approaches - GREEDYKSEP-OPT1 and GREEDY-KSEP-OPT2. Both of these algorithms outperformed
the set-covering reduction in an experiment on the Understanding War Special
Groups data set. We also implemented a “tie-breaker” heuristic that further
improved the accuracy of the algorithms.
• We have also developed approximation schemes using relaxations of the linearinteger program for k-SEP and the cost-based variant WT-SEP.
There are many interesting directions for future work. For example, spatial
abduction in dimensions greater than two might be explored. A probabilistic variant might replace the feasibility predicate with a probability distribution function,
or express the relationship between observations and partners as a PDF based on
distance rather than rely on α, β. Also, the use of randomization in the approxima-

208

tion algorithms may improve results for both the greedy and linear programming
approaches presented in this chapter.
One aspect to explore in future work is the relationship between observations
and partners. k-SEP and its cost based variants only rely on α, β. However, many
applications may have other constraints. Perhaps there is a direction associated with
each observation (as in identifying where an artillery round originated from), which
would limit the locations of the partner. Another possibility is to add geographic
constraints. Perhaps the observation cannot have a partner across a body of water,
or beyond the edge of a cliff.
Another important question is: where do we look for partners if they are
placed they are placed by an adversary? We can think of scenarios, such as in
counterinsurgency, where an enemy obtains a copy of our software and wants to
plan his cache sites in a place where an agent would be unlikely to search for them.
We study this particular problem in Chapter 6. Another natural question is: what
if we want to abduce regions rather than point locations for partners? There are
many real-world applications where a user may wish to find an area to search rather
than a point - in fields varying from paleontology to intelligence. We describe this
extension to the geospatial abduction framework in chapter 5.

209

Chapter 5
Abducing Regions

In the previous chapter, we studied a variety of geospatial problems where
the space is represented as a plane that used discrete integer coordinates. In this
chapter, we modify the framework to use a continuous space instead. Additionally,
rather than abducing points, we assume the space is divided into a set of regions,
and we wish to abduce a set of regions that explains the agent’s behavior.1

5.1

Chapter Introduction
In this chapter, we introduce a variant GAPs called region-based geospatial

abduction problems (RGAPs). In RGAPs, we are given a map, a set O of observations,
and a set of subregions of the map (this could include all subregions of the map in
the worst case or can be defined by some logical condition). We want to find a set
of regions that best “explain” the observations and includes, for each observation,
at least one partner.
1

This chapter is based on [153] which was completed in cooperation with V.S. Subrahmanian.

210

In this chapter, we make several contributions. In Section 5.2 we introduce
multiple possible formal definitions of RGAPs - including cases where the regions are
determined by a given radius from each observation, regions are non-convex, and
when regions are of irregular shape due to terrain restrictions. We then perform
a detailed complexity analysis in Section 5.3, proving that most of these problems
are NP-complete. This leads us to use approximation techniques in Section 5.4.
We also describe some practical implementation issues. Section 5.5 describes our
implementation and includes an experimental evaluation on a real-world data-set
consisting of IED attacks in Baghdad, Iraq and related weapons cache sites. In
our evaluation, regions outputted by the algorithm contained, on average, 1.7 cache
sites, with an average cache density of over 8 caches per square kilometer – significantly higher than the city-wide average of 0.4. Further, the algorithm ran quickly,
performing computation in just over 2 seconds on commodity desktop hardware.
Finally, we survey related work in Section 5.6.

5.2

Technical Preliminaries
To address the problem of region-based geospatial abduction, we introduce a

framework that resembles that of Chapter 4 - but differs in several important aspects.
These include the use of a continuous space and multiple types of explanations. In
Chapter 6, we return to the original framework of Chapter 4.
We assume the existence of a real-valued M × N space S whose elements are
pairs of real numbers from the set [0, M ] × [0, N ]. An observation is any member
211

of S. We use O to denote an arbitrary, but fixed, finite set of observations. We
assume there are real numbers α ≤ β such that for each observation o , there exists
a partner po (to be found) whose distance from o is in the interval [α, β].2 Without
loss of generality, we also assume that all elements of O are over β distance away
from the edge of S. Example 5.2.1 presents a neighborhood as a space and locations
of illegal drug sales as observations.

Example 5.2.1 (Illegal Drug Sales). A criminal gang is selling illegal drugs. Consider the space S depicted in Figure 5.1. Drug dealers were arrested by police at
points O ≡ {o1 , . . . , o13 }. Historical data suggests that safe houses are located within
5km of such transactions (i.e. α = 0 and β = 5km). Note that in Figure 5.1, circles of radius 5km are drawn around the observation points. Police are interested
in locating such safe-houses.
Throughout this chapter, we assume the notion of a distance function d on S
satisfying the usual properties of such distance functions.3 We now define a region
and how they relate to the set of observations. Our intuition is simple - a region
explains an observation if that region contains a partner point for that observation.
Definition 57 (Region / Super-Explanation / Sub-Explanation). A region r is a
subset of S such that for any two points (x, y), (x′ , y ′ ) ∈ r, there is sequence a of
line segments from (x, y) to (x′ , y ′ ) s.t. no line segment lies outside r.
2

Chapter 4 describes methods to learn α, β automatically from historical data.

3

d(x, x) = 0; d(x, y) = d(y, x); d(x, y) + d(y, z) ≥ d(x, z).

212

1. A region r super-explains point o in S iff there exists a point p ∈ r such
that d(o, p) ∈ [α, β].
2. A region r sub-explains some point o in S iff (∀p ∈ r) d(o, p) ∈ [α, β].
First, note that regions can have any shape and may overlap. Throughout this
chapter, we assume that checking if some point o is sub-(super-) explained by region
r can be performed in constant (i.e. O(1)) time. This is a reasonable assumption for
most regular shaped regions like circles, ellipses and polygons. The following result
follows immediately from Definition 57.
Observation 5.2.1. If region r 6= ∅ sub-explains point o, then r super-explains
point o.
We would like to explain observations by finding regions containing a partner.
In some applications, the user may be able to easily search the entire region – hence
a super-explaining region would suffice. In other applications, we may want to be
sure that any point within the region can be a partner as not to waste resources so only a sub-explanation would make sense in such a case. Often, these situations
may depend on the size of the regions. We shall discuss the issue of restricting
region size later in this section. For now, we shall consider regions any shape or
size. Example 5.2.2 shows regions that super- or sub-explain various observations.
Example 5.2.2. Consider the scenario from Example 5.2.1 and the regions
R = {ra , rb , rc , rd , re , rf , rg } shown in Figure 5.1. Suppose these regions correspond
with “support zones” for the drug sales – i.e. places that may contain a safe-house.
213

ra
o1
o3
rb

o2
rc

o4

o9

o13

o6
rd
o7

Figure 5.1:

o5
re

o8 rf

o10
o11

o12
rg

Locations of illegal drug sales and suspected support zones

{ra , rb , rc , rd , re , rf , rg }. The β distance for each observation is shown with a dashed
circle.

214

Consider region ra . As it totally lies within the α, β distance of o1 , it sub- and superexplains this observation. Conversely, region rd super-explains both o6 and o7 but
sub-explains neither.
This chapter studies following decision problems.

Sub-(Super-)Region Explanation Problem (Sub/Sup-REP)
INPUT: Given a space S, distance interval [α, β], set O of observations, set R of
regions, and natural number k ∈ [1, |O|].
OUTPUT: Set R′ ⊆ R, where |R′ | ≤ k and for each o ∈ O, there is an r ∈ R s.t. r
sub-(super-) explains o.

The fact that a set R of regions is part of the input is not an assumption, but
a feature. A user might set R to be all the regions associated with S; alternatively,
he might use a logical condition to define regions, taking into account, the terrain
and/or known aspects of the population living in the area of interest. For instance,
when trying to identify regions containing IED caches in Baghdad used for attacks
by Shi’ite groups, regions were defined to be places that were not predominantly
Sunni and that did not contain US bases or bodies of water. Other kinds of logical
conditions may be used when dealing with burglaries or drug trafficking. Thus, the
set R of regions allows an analyst to specify any knowledge he has, and allows the
system to benefit from that knowledge. If no such knowledge is available, R can be
taken to be the set of all regions associated with S. R can also be used to restrict
215

the size of the region (e.g. only considering regions whose area is less than 5 sq.
km.).
There are two different associated optimization problems associated with both
Sub-REP and Sup-REP. The first deals with finding a subset of regions of minimal
cardinality that explains all observations.

Sub-(Super-)Region Explanation Problem-Minimum Cardinality (Sub/SupREP-MC)
INPUT: Given a space, S, distance interval [α, β], set of observations O, and set of
regions R.
OUTPUT: Set R′ ⊆ R of minimum cardinality, where for each o ∈ O, there is an
r ∈ R s.t. r sub-(super-) explains o.

Our second optimization problem fixes the number of regions returned in the
solution, but maximizes the number of observations that are explained.

Sub-(Super-)Region Explanation Problem-Maximum Explaining (Sub/SupREP-ME)
INPUT: Given a space S, distance interval [α, β], set O of observations, set R of
regions, and natural number k ∈ [1, |O|].
OUTPUT: Set R′ ⊆ R, where |R′ | ≤ k s.t. the number of o ∈ O where there is an
r ∈ R s.t. r sub-(super-) explains o is maximized.

216

Consider the following Example.
Example 5.2.3. Consider the scenario from Example 5.2.2. Consider an instance
of Sup-REP with k = 7. The set {ra , rb , rc , rd , re , rf , rg } is a solution to this problem.
Now consider Sup-REP-MC with k = 6, the set {ra , rc , rd , re , rf , rg } is a solution to
this problem. Finally, consider Sup-REP-ME with k = 2. The set {rc , rd } is a
solution to this problem.
We now consider a special case of these problems that arises when the set R
of regions is created by a partition of the space based on the set of observations (O)
and concentric circles of radii α and β drawn around each o ∈ O. We can associate
regions in such a case with subsets of O. For a given subset O′ , we say that there
is an associated set of induced regions (denoted RO′ ), defined as follows:
RO′ = {{x| ∀o ∈ O′ , d(x, o) ∈ [α, β]∧
∀o′ ∈
/ O′ , d(x, o′ ) ∈
/ [α, β]} }
We note that for a given subset of observations, it is possible to have a set of
induce regions, RO′ that has more than one element. For example, consider set
R∅ = {r1 , r12 } in Figure 5.2. For a given set of observations O, we will use the
notation RO do denote the set of all induce regions. Formally:
RO =

[

O ′ ∈2O

RO ′

RO′ 6≡∅

We illustrate the idea of induce regions in the following example.

217

r1

r2
o1 r
r3 r4 5 r8
o3
r7
r9
r20
r6 o2
r12
r11
r13
o
o5
4
r14
r10
r21
o9
r16
r15
r22 o13
r1
o6
r23 r27
r1
r17
r24 r25r26
o8
r28 o10 r30 o12 r32
o7
r19
r29 o11r
r18
r33 31

Figure 5.2: Space S and the regions in set RO .
Example 5.2.4. In order to identify locations of drug safe-houses, police create 33
induced regions in S by drawing 5km radius circles around all observations (see
Figure 5.2), the set of which is denoted RO = {r1 , . . . , r33 }.
For the special case where RO is the set of regions, we have the following result.
Lemma 17. Suppose O is a set of observation and RO is the induced region. A
region r ∈ RO sub-explains an observation o ∈ O iff it super-explains o.
By this result, for the special case of induced regions, we only need one decision problem.

Induced Region Explanation Problem (I-REP)
INPUT: Given a space, S, distance interval [α, β], set O of observations, and natural
218

number k ∈ [1, |O|].
OUTPUT: Set R′ ⊆ RO , where |R′ | ≤ k and for each o ∈ O, there is an r ∈ R s.t.
r sub-explains o.

As mentioned earlier, the sizes of regions can be regulated by our choice of R.
However, we may also explicitly require that all regions must be less than a certain
area. Consider the following variant of Sup-REP.

Area-Constrained Super-Region Explanation Problem (AC-Sup-REP)
INPUT: Given a space, S, distance interval [α, β], set O of observations, set R of
regions, area A, and natural number k ∈ [1, |O|].
OUTPUT: Set R′ ⊆ R, where |R′ | ≤ k and each r ∈ R′ has an area ≤ A and for
each o ∈ O, there is an r ∈ R s.t. r super-explains o.

The following proposition tells us that AC-Sup-REP is at least as hard as
I-REP, yet no harder than Sup-REP (an analogous result can easily be shown for
an area-constrained version of Sub-REP). We note that essentially, we eliminate the
regions whose area is above area A, which gives us an instance of Sup-REP. To go
the other direction, we directly encode I-REP into an instance of AC-Sup-REP and
have A be larger than the area of any region.
Theorem 24. I-REP is polynomially reducible to AC-Sup-REP.
AC-Sup-REP is polynomially reducible to Sup-REP.

219

In our final observation of this section, we note that the set RO can be used as
a “starting point” in determining regions. For instance, supplemental information
on area that may be restricted from being partnered with an observation may also
be considered and reduce the area of (or eliminate altogether) some regions in the
set. Consider the following example.
Example 5.2.5. Consider the scenario from Example 5.2.4. The police may eliminate a river running through the area and certain other ares from their search.
These “restricted areas” are depicted in Figure 5.3. Note that several regions from
Figure 5.2 are either eliminated or have decreased in size. However, by eliminating
these areas, the police have also pruned some possibilities from their search. For
example, regions r9 , r13 were totally eliminated from consideration.

220

r1

r2
o1 r5
r8
r3 r4 o
r7 3
r9
r6 o2
r20
r12
r13
r
o
o5
11
4
r14
r10
r21
r16
o9
o13
r15
r
22
r
o6
1
r1
r23 r27
r17
r24r25r26
o8
r28 o10 r30 o12 r
o7
32
r19
r29 o11r
r18
r33 31

Figure 5.3: A set of regions in S created based on the distance β = 5km as well as
restricted areas (shown in black).

5.3

Complexity
In this section, we show that Sub-REP, Sup-REP, and I-REP are NP-Complete

and that the associated optimization problems are NP-Hard. We also show that
the optimization problems Sub-REP-MC, Sup-REP-MC, and I-REP-MC cannot be
approximated by a fully polynomial-time approximation scheme (FPTAS) unless
P = N P . We also note that the complexity of the area-constrained versions of
these problems follows directly from the results of this section by the reduction of
Theorem 24 (page 219).
We first prove that I-REP is NP-complete, which then allows us to correctly
identify the complexity classes of the other problems by leveraging Lemma 17. First,

221

we introduce the problem “circle covering” (CC) that was proven to be NP-complete
in [125].

Circle Covering (CC)
INPUT: A space S ′ , set P of points, real number β ′ , natural number k ′ .
OUTPUT: “Yes” if there is a set of points, Q in S ′ such that all points in P are
covered by discs centered on points in Q of radius β ′ where |Q| ≤ k ′ – “no” otherwise.

The theorem below establishes that I-REP is NP-complete.
Theorem 25. I-REP is NP-Complete.
Proof Sketch. Clearly, a solution to I-REP can be verified in PTIME. To show
NP-hardness, we show that CC ≤p I-REP by the following transformation: S = S ′ ,
O = P , β = β ′ , α = 0, and k = k ′ . (⇐) Given a solution to the instance of I-REP,
we can simply pick a point in each returned region, and center a circle on it of radius
β ′ - which will be a solution to CC. Likewise, (⇒) given a solution to CC, we can
be assured that each point in the solution is enclosed by exactly one region from the
set RO , which would ensure a solution to I-REP.



Further, as the optimization version of circle covering is known to have no
FPTAS unless P = N P [70], by the nature of the construction in Theorem 25, we
can be assured of the same result for I-REP-MC.
Corollary 8. I-REP-MC cannot be approximated by a fully polynomial-time ap222

proximation scheme (FPTAS) unless P = N P .
So, from the above Theorem and Corollary and Lemma 17, we get the following
results:
Corollary 9.

1. Sub-REP and Sup-REP are NP-Complete.

2. Sub-REP-MC, Sup-REP-MC, I-REP-MC, Sub-REP-ME, Sup-REP-ME, and
I-REP-ME are NP-Hard.
3. Sub-REP-MC, Sup-REP-MC cannot be approximated by a FPTAS unless P =
NP .

5.4

Algorithms
In this section we devise algorithms to address the optimization problems

associated with Sup-REP, Sub-REP, and I-REP. First, we show that these optimization problems reduce to either instances of set-cover (for Sub/Sup-REP-MC)
or max-k-cover (for Sub/Sup-REP-ME). These problems are well-studied and there
are algorithms that provide exact and approximate solutions. We then provide a
new greedy-algorithm for Sub/Sup-REP-MC that also provides an approximation
guarantee. This is followed by a discussion of approximation for I-REP-ME for the
case where α = 0. Finally, we discuss some practical issues dealing with implementation.

223

5.4.1

Exact and Approximate Solutions by Reduction

In this section we show that the -MC problems can reduce to set-cover and
that the -ME problem can reduce to max-k-cover. First, we introduce the two problems in question. First, we present set-cover [136].

Set-Cover
INPUT: Set of elements S, family of subsets of S, H = H1 , . . . , Hm .
OUTPUT: Subset H′ ⊆ H of minimum cardinality s.t.

S

Hi ∈H′

Hi ⊇ S.

Next, we present max-k-cover [46], which is often regarded as the dual of
set-cover:
Max-k-Cover
INPUT: Set of elements S, family of subsets of S, H = H1 , . . . , Hm , natural number
k ≤ |S|.
OUTPUT: Subset H′ ⊆ H s.t. |H′ | ≤ k where |

S

Hi ∈H′

Hi ∩ S| is maximized.

The key to showing that Sub/Sup-REP optimization problems can reduce to
one of these problems is to determine the family of subsets. We accomplish this as
follows: for each region r ∈ R, we find the subset of O that can be partnered with
r. We shall refer to this set as Or . This gives us the following algorithm for the
optimization problems (we simply omit the k parameter for the -MC problems that
reduce to Set-Cover):

224

REDUCE-TO-COVERING(O set of observations, R set of regions, k natural number)
returns instance of covering problem hS, H, ki
1. For each r ∈ R, find Or (i.e. o is in Or iff r sub/super-explains o)
2. Return hO,

S

r∈R {Or }, ki

Proposition 42. REDUCE-TO-COVERING requires O(|O| · |R|) time.
The following theorem shows that REDUCE-TO-COVERING correctly reduces
a Sub/Sup-REP optimization problem to set-cover or max-k-cover as appropriate.
Theorem 26. Sub/Sup-REP-MC polynomially reduces to Set-Cover and Sub/SupREP-ME polynomially reduces to Max-k-Cover.
This result allows us to leverage any exact approach to the above optimization
problems to obtain a solution to an optimization problem associated with Sub/SupREP. A straightforward algorithm for any of the optimization problems would run
in time exponential in |O| or k and consider every |O| or k sized subset of

S

r∈R {Or }.

Clearly this is not practical for real-world applications. Fortunately, there are several
well-known approximation techniques for both these problems. First, we address the
Sub/Sup-REP-ME problems, which reduce to Max-k-Cover. As the Max-k-Cover
problem reduces to the maximization of a submodular function over a uniform matroid, we can leverage the greedy approximation algorithm of [127] to our problem.
We do so below.
Suppose ‘f ’ denotes the maximum number of observations that can be partnered with a given region.
225

GREEDY-REP-ME(O set of observations, R set of regions, k natural number)
returns R′ ⊆ R
1. Let O =

S

r∈R {Or }

(obtained by REDUCE-TO-COVERING)

2. Let O′ = O, set R′ = ∅
3. While k 6= 0 loop
(a) Let the element Or be the member of O s.t. |Or ∩ O′ | is maximized.
R′ = R′ ∪ r
O′ = O′ − (Or ∩ O′ )
k−−
4. Return R′

Proposition 43. GREEDY-REP-ME runs in O(k·|R|·f ) time and returns a solution
such that the number of observations in O that have a partner region in R′ is within
a factor

e
e−1



of optimal.

Example 5.4.1. Consider Example 5.2.2 (page 213), where the set of regions is
R = {ra , rb , rc , rd , re , rf , rg }. Suppose the police want to run GREEDY-REP-ME to
solve an instance of Sup-REP-ME associated with this situation with k = 3. Initially
set O′ = {o1 , . . . , o13 }. On the first iteration of the outer loop, it identifies set Orc =
{o2 , o3 , o4 , o9 } where the cardinality of Orc ∩ O′ is maximum. Hence, it picks region
rc . The set O′ = {o1 , o5 , . . . , o8 , o10 , . . . o13 }. On the second iteration, it identifies
Ore = {o5 , o13 }, which intersected with O′ provides a maximum cardinality, causing
re to be picked. Set O′ is now {o1 , o6 , . . . , o8 , o10 , . . . , o12 }. On the last iteration,
226

it identifies Org = {o11 , o12 }, again the maximum cardinality when intersected with
O′ . The element is picked and the solution is rc , re , rg , and the observations superexplained are {o2 , o3 , o4 , o5 , o9 , o11 , o12 , o13 }.
Likewise, we can leverage the greedy algorithm for set-cover [136] applied to
Sub/Sup-REP-MC.
GREEDY-REP-MC(O set of observations, R set of regions, ) returns R′ ⊆ R
1. Let O =

S

r∈R {Or }

(obtained by REDUCE-TO-COVERING)

2. Let O′ = O, set R′ = ∅
3. While not O′ ≡ ∅ loop
(a) Let the element Or be the member of O s.t. |Or ∩ O′ | is maximized.
R′ = R′ ∪ r
O′ = O′ − (Or ∩ O′ )
4. Return R′

Proposition 44. GREEDY-REP-MC runs in O(|O| · |R| · f ) time and returns a
solution whose cardinality is within a factor of 1 + ln(f ) of optimal.
Example 5.4.2. Consider the scenario from Example 5.4.1. To explain all points,
the police can create an instance of Sup-REP-MC and use GREEDY-REP-MC. The
algorithm proceeds just as GREEDY-REP-ME in the first three steps (as in Example 5.4.1, but will continue on until all observations are super-explained. So,
GREEDY-REP-MC proceeds for three more iterations, selecting rf (Orf = {o8 , o10 }),
227

rd (Ord = {o6 , o7 }), and finally ra (Ora = {o1 }). The solution returned is:
{rc , re , rg , rf , rd , ra }
We now focus on speeding up the set-cover reduction via the GREEDY-REPMC2 algorithm below.
In the rest of this section, we use ‘∆’ to denote the maximum number of
different regions that can be partnered with a given observation.
Proposition 45. GREEDY-REP-MC2 runs in O(∆ · f 2 · |O| + |O| · ln(|O|) time and
returns a solution whose cardinality is within a factor of 1 + ln(f ) of optimal.
Although GREEDY-REP-MC2 considers regions in a different order than GREEDYREP-MC, it maintains the same approximation ratio. This is because the region (in
set GRPo ) that is partnered with the greatest number of uncovered observations
is selected at each iteration, allowing us to maintain the approximation guarantee.
There are two selections at each step: the selection of the observation (in which
we use a minimal key value based on related observations) and a greedy selection
in the inner loop. Any selection of observations can be used at each step and the
approximation guarantee is still maintained. This allows for a variety of different
heuristics. Further, the use of a data structure such as a Fibonacci Heap allows us
to actually obtain a better time complexity than GREEDY-REP-MC.
Example 5.4.3. Consider the situation in Example 5.2.4 where the police are considering regions RO = {r1 , . . . , r33 } that are induced by the set of observations and
wish to solve I-REP-MC using GREEDY-REP-MC. On the first iteration of the loop
228

GREEDY-REP-MC2(O set of observations, R set of regions, ) returns R′ ⊆ R
1. Let O =

S

r∈R {Or }

(obtained by REDUCE-TO-COVERING)

2. For each observation o ∈ O, let GRPo = {Or ∈ O|o ∈ Or }
3. For each observation o ∈ O, let RELo = {o′ ∈ O|o′ ∈
keyo = |RELo |

S

Or ∈GRPo

Or } and let

4. Let O′ = O, set R′ = ∅
5. While not O′ ≡ ∅ loop
(a) Let o be the element of O where keyo is minimal.
(b) Let the element Or be the member of GRPo s.t. |Or ∩ O′ | is maximized.
(c) If there are more than one set Or that meet the criteria of line 5b, pick the set
w. the greatest cardinality.
(d) R′ = R′ ∪ r
(e) For each o′ ∈ Or ∩ O′ , do the following:
i. O′ = O′ − o′
ii. For each o′′ ∈ O′ ∩ RELo′ , keyo′′ − −
6. Return R′

229

at line 5, the algorithm picks o8 , as keyo8 = 1. The only possible region to pick is
r19 , which can only be partnered with o8 . There are no observations related to o8
other than itself, so it proceeds to the next iteration. It then selects o6 as keyo6 = 2
because RELo6 = {o6 , o7 }. It then greedily picks r17 which sub-explains both o6 , o7 .
As all observations related to o6 are now sub-explained, the algorithm proceeds with
the next iteration. The observation with the lowest key value is o5 as keyo5 = 3 and
RELo5 = {o4 , o5 , o13 }. It then greedily picks region r21 which sub-explains o5 , o13 .
The algorithm then reduces the key value associated with o4 from 4 to 3 and decrements the keys associated with o10 , o11 , o12 (the un-explained observations related to
o13 ) also from 4 to 3. In the next iteration, the algorithm picks o9 as keyo9 = 3.
It greedily picks r12 which sub-explains o9 , o2 . It then decreases keyo4 to 2 and also
decreases the keys associated with o1 and o3 . At the next iteration, it picks o1 as
keyo1 = 2. It greedily selects r4 , which sub-explains o1 , o3 and decreases the keyo4 to
1 which causes o4 to be selected next, followed by a greedy selection of r11 – no keys
are updated at this iteration. In the final iteration, it selects o10 as keyo10 = 3. It
greedily selects r25 , which sub-explains all un-explained observations. The algorithm
terminates and returns {r11 , r12 , r17 , r19 , r21 , r25 }.

5.4.2

Approximation for a Special Case

In Section 5.3, we showed that circle covering is polynomially reducible to IREP-MC. Let us consider a special (but natural) case of I-REP-MC where α = 0, i.e.
there is no minimum distance between an observation and a parter point that caused

230

it. We shall call this special case I-REP-MCZ. There is a great similarity between
this problem and circle-covering. It is trivial to modify our earlier complexity proof
to obtain the following result.
Corollary 10. I-REP-MCZ is polynomially reducible to CC.
Further, we can adopt any algorithm that provides a constructive result for CC
to provide a result for I-REP-MCZ in polynomial time with the following algorithm.
Given some point p, it identifies the set Or associated with the region that encloses
that point.
FIND-REGION(S space, O observation set, β real , p point) returns set Or
1. Set Or = ∅
2. For each o ∈ O, if d(p, o) ≤ β then Or = Or ∪ {o}
3. Return Or .

Proposition 46. The algorithm, FIND-REGION runs O(|O|) time, and region r
(associated with the returned set Or ) contains p.
By pre-processing the regions, we can compute Or a-priori and simply pick a
region r associated with the output for FIND-REGION. While there may be more
than one such region, any one can be selected as, by definition, they would support
the same observations.
Example 5.4.4. Paleontologists working in a 30 × 26km area represented by space
S have located scattered fossils of prehistoric vegetation at O = {o1 , o2 , o3 , o4 }. Pre231

vious experience has led the paleontologists to believe that a fossil site will be within
3km of the scattered fossils. In Figure 5.4, the observations are labeled and circles
with radius of 3 km are drawn (shown with solid lines). Induced regions r1 , . . . , r6 are
also labeled. As the paleontologists have no additional information, and α = 0, they
can model their problem as an instance of I-REP-MCZ with k = 3. They can solve
this problem by reducing it to an instance of circle-covering. The circle-covering algorithm returns three points - p1 , p2 , p3 (marked with an ‘x’ in Figure 5.4). Note that
each point in the solution to circle-covering falls in exactly one region (when using
induced regions). The algorithm FIND-REGION returns the set {o1 , o2 } for point p1 ,
which corresponds with region r2 . It returns set {o3 } for p2 , corresponding with r6
and returns set {o4 } for p3 , corresponding with r5 . Hence, the algorithm returns
regions r2 , r6 , r5 , which explains all observations.
Any algorithm that provides a constructive result for CC can provide a constructive result for I-REP-MCZ. Because of this one-to-one mapping between the
problems, we can also be assured that we maintain an approximation ratio of any
approximation technique.
Corollary 11. An a−approximation algorithm for CC is an a-approximation for IREP-MCZ.
This is useful as we can now use approximation algorithms for CC on I-REPMCZ. Perhaps the most popular approximation algorithms for CC are based on the
“shifting strategy” [70]. To leverage this strategy, we would divide the space, S,
into strips of width 2 · β. The algorithm considers groups of ℓ consecutive strips – ℓ
232

r6
r1

x
o3
o1

r2 x
r5
o2

r3

r4

x

o4

Figure 5.4: Given the instance of I-REP-MCZ for Example 5.4.4 as input for circlecovering, a circle-covering algorithm returns points p1 , p2 , p3 (points are denoted
with an “x”, dashed circles are the area of 3km from the point).
is called the “shifting parameter.” A local algorithm A is applied to each group of
strips. The union of all solutions is a feasible solution to the problem. The algorithm
then shifts all strips by 2 · β and repeats the process, saving the feasible solution.
This can be done a total of ℓ − 1 times, and the algorithm simply picks the feasible
solution with minimal cardinality. In [70], the following lemma is proved (we state
it in terms of I-REP-MCZ – which is done by an application of Corollary 11):
Lemma 18 (Shifting Lemma [70]). Let aS(A) be the approximation factor of the
shifting strategy applied with local algorithm A and aA be the approximation factor
for the local algorithm. Then:
aS(A)



1
= aA · 1 +
ℓ



.

Further, the shifting strategy can actually be applied twice, solving the local
233

algorithm in squares of size 2 · β · ℓ × 2 · β · ℓ. This gives the following result:
a S(S(A))



1
= aA · 1 +
ℓ

2

.

A good survey of results based on the shifting strategy can be found in [48],
which also provides a linear-time algorithm (this result is later generalized by [52]
for multiple dimensions). The following result leverages this for I-REP-MCZ by
Corollary 11 (and is proved in [52]).
Proposition 47. I-REP-MCZ can be solved with an approximation ratio of x ·
1+


1 2
ℓ

in O(Kℓ,ρ · |O|) time. Where p is the maximum number of points in a finite

lattice over a square of side length 2 · β · ℓ s.t. each observation in such a square
lies directly on a point in the lattice and x ∈ {3, 4, 5, 6} (and is determined by β, see
[48] for details) and Kℓ,ρ is defined as follows.
2

Kℓ,ρ = ℓ ·

√
⌈ℓ· 2⌉2 −1 

X
i=1


p
·i
i

An alternative to the shifting strategy leverages techniques used for the related problem of geometric dominating set. In [104], the authors present a 1 + ǫ
1

approximation that runs in O(|O|O( ǫ2 ·lg

5.4.3

2 1
( ǫ ))

) time.

Practical Considerations for Implementation

We now describe some practical implementation issues. Our primary aim is
to find a set of regions that resembles the set of induced regions, RO . There are
several reasons for doing this. One reason is to implement a fast heuristic to deal
with I-REP optimization problems, specifically when α 6= 0. Another, is that such
234

a set of induced regions in the space may be a starting point for creating a set of
regions that may include other data, such as that shown in Example 5.2.5.
As most GIS systems view space as a set of discrete points, we discretized the
space using the REGION-GEN algorithm below. The parameter g is the spacing of
a square grid that overlays the space.
Proposition 48. REGION-GEN has a time complexity Θ(|O| ·

π·β 2
).
g2

Example 5.4.5. Consider the scenario from Example 5.4.4. Suppose the paleontologists now want to generate regions using REGION-GEN instead of using induced
regions. The algorithm REGION-GEN overlays a grid on the space in consideration.
Using an array representing the space, it records the observations that can be explained by each grid point (Figure 5.5, top). As it does this, any grid point that can
explain an observation is stored in list L. The algorithm then iterates through list L,
creating entries in a hash table for each subset of observations, enclosing all points
that explain the same observation with a minimally-enclosing rectangle. Figure 5.5
(bottom) shows the resulting regions r1 , . . . , r6 .
One advantage to using REGION-GEN is that we already have the observations
that a region super-explains stored – simply consider the bit-string used to index the
region in the hash table. Another thing that can be done, for use in an algorithm
such as GREEDY-MC2, where the regions are organized by what observation they
support, can also be easily done during the running of this algorithm at an additional
cost of f (the number of observations that can be partnered with a given region) by updating an auxiliary data structure at line 6a.
235

1

3

1
1

1
1

1
1

1
1

1
1

1
1

1
o
1 11

1

1 12

1

1
1

4

2

12 12 12 24 4 4

4

4

2

4

4

2 2
2 2
2 2

2

3

3

2

2

3

3 3
3 3
o3
3 3 3 3 3
3 3 3 3 3

1 1
1
1

3

3 3
3 3

3
3 3

24 4 4

o22 24 24 o 4 4
2 2 24 4 4 44 4
2 2 24 4 4 4 4
2

4

r6

r1

o3
o1
r2
r4
o2

r5
o4

r3

Figure 5.5: REGION-GEN applied to the paleontology example (Example 5.4.4).
First, it identifies observations associated with grid points (top). It then creates
minimally-enclosing rectangles around points that support the same observations
(bottom).

236

REGION-GEN(S space, O observation set, α, β, g reals returns set R
1. Overlay a grid of spacing g on space S. With each grid point, p, associate set
Op = ∅. This can easily be represented with an array.
2. Initialize list L of pointers to grid-points.
3. For each o ∈ O, identity all grid points within distance [α, β]. For each point
p meeting this criteria, if Op = ∅, add p to L. Also, set Op = Op ∪ {o}
4. For some subset O′ ⊂ O, let str(O′ ) be a bit string of length |O| where every
position corresponding to an element of O′ is 1 and all other positions are 0.
2

⌉ regions indexed by bit-strings of length
5. Let T be a hash table of size ⌈|O|· π·β
g2
|O|
6. For each p ∈ L, do the following:
(a) If T [str(Op )] = null then initialize this entry to be a rectangle that encloses point p.
(b) Else, expand the region at location T [str(Op )] to be the minimumenclosing rectangle that encloses p and region T [str(Op )].
7. Return all entries in T that are not null.

5.5

Experimental Results
We implemented REGION-GEN and GREEDY-MC2 in approximately 3000 lines

of Java code and conducted several experiments on a Windows-based computer with
237

an Intel x86 processor. Our goal was to show that solving the optimization problem
Sup-REP-MC would provide useful results in a real-world scenario. We looked
at counter-insurgency data from [72] that included data on improvised-explosive
device attacks in Baghdad and cache sites where insurgents stored weapons. Under
the assumption that the attacks required support of a cache site a certain distance
away, could we use attack data to locate cache sites using an instance of SupREP-MC solved with GREEDY-MC2 using regions created with REGION-GEN? In
our framework, the observations were attacks associated with a cache (which was
a partner). The goal was to find relatively small regions that contained partners
(caches). We evaluated our approach based on the following criteria:
1. Do the algorithms run in a reasonable amount of time?
2. Does GREEDY-MC2 return regions of a relatively small size?
3. Do the regions returned by GREEDY-MC2 usually contain a partner (cache)?
4. Is the partner (cache) density within regions returned by GREEDY-MC2 significantly greater than the partner density of the space?
5. How does the spacing between grid points affect the runtime and accuracy of
the algorithms?
Overall, the experiments indicate that REGION-GEN and GREEDY-MC2 satisfactorily meet the requirements above. For example, for our trials considering
locating regions with weapons cache sites (partners) in Baghdad given recent IED

238

attacks (observations), with a grid spacing g = 100m, the combined (mean) runtime on a Windows-based laptop was just over 2 seconds. The algorithm produced
(mean) 15.54 regions with an average area of 1.838km2 . Each region, on average,
enclosed 1.739 cache sites. If it did not contain a cache site, it was (on average) 275m
away from one. The density of caches within returned regions was 8.09caches/km2
- significantly higher than the overall density for Baghdad of 0.488caches/km2 .
The rest of this section is organized as follows. Section 5.5.1 describes the
data set we used for our tests and experimental set-up. Issue 1 is addressed in Section 5.5.2. We shall discuss the area (issue 2) of the regions returned in Section 5.5.3
and follow this with a discussion of issue 3 in Section 5.5.4. We shall discuss issue 4
in Section 5.5.5. Throughout all the sections, we shall describe results for a variety
of different grid-spacings, hence addressing issue 5.

5.5.1

Experimental Set-Up

We used the Map of Special Groups Activity in Iraq available from the Institute
for the Study of War [72]. The map plots over 1000 insurgent activities attributed
to what are termed as “Special Groups” - groups with access to certain advanced
weaponry. This data set contains events for 21 months between February 2007 and
November 2008. The activity types include the following categories.
1. Attacks with probable links to Special Groups
2. Discoveries of caches containing weapons associated with Special Groups
3. Detainments of suspected Special Groups criminals
239

4. Precision strikes against Special Groups personnel
We use this data for two geographic areas: the Baghdad urban area and the Sadr
City district. In our experiment, we will view the attacks by the special groups (item
1) as observations and attempt to determine the minimum set of cache sites (item
2), which we shall view as partners. Hence, a region returned by GREEDY-MC2
encloses a partner iff a cache falls within the region.
For distance constraints, we used a simple algorithm to learn the parameter
β (α was set to zero). This was done using the first 7 months of attack data ( 31 of
the available months) and 14 months of cache data. We used the following simple
algorithm, FIND-BETA, to determine these values. Note we set βmax to 2.5 km.
We ran the experiments on a Lenovo T400 ThinkPad laptop with a 2.53 GHz
Intel Core 2 Duo T9400 processor and 4GB of RAM. The computer was running
Windows Vista 64-bit Business edition with Service Pack 1 installed.
As the relationship between attacks and cache sites may differ varied on terrain, we ran tests with two different geographic areas. First, we considered the
entire Baghdad urban area. Then, we considered just the Sadr City district. We
ran FIND-BETA with a βmax of 2.5 km on both areas prior to testing the algorithms.
There were 73 observations (attacks) for Baghdad and 40 for Sadr City. Table 5.1
shows the exact locations and dimensions of the areas considered.
We conducted two types of tests: tests focusing on GREEDY-MC2 and tests
focusing on REGION-GEN.

240

Algorithm 20 Determines β value from historical data
FIND-BETA(Oh historical, time-stamped observations,
Eh historical, time-stamped partners, βmax real)
1. Set β = βmax
2. Set Boolean variable f lag to TRUE
3. For each o ∈ Oh , do the following:
(a) For each p ∈ Eh that occurs after o, do the following.
i. Let d be the Euclidean distance function.
ii. If f lag, and d(o, p) ≤ βmax then set β = d(o, p)
iii. If not f lag, then do the following:
A. If d(o, p) > β and d(o, p) ≤ βmax then set β = d(o, p)
4. Return real β

Area

Lower-Left

Lower-Left

E-W

N-S

Latitude

Longitude

Distance

Distance

Baghdad

33.200◦ N

44.250◦ E

27 km

25 km

Sadr City

33.345◦ N

44.423◦ E

7 km

7 km

Table 5.1: Locations and dimensions of areas considered

241

For the tests of GREEDY-MC2, we used multiple setting for the grid spacing.
We tested grid grid spacings at every 10 meter interval in the range of [70, 1000]
meters - giving a total of 93 different values for g. Due to the fact that REGION-GEN
produces a deterministic result, we ran that algorithm only once per grid setting.
However, we ran 100 trials of GREEDY-MC2 per each parameter g. This was done
for both Baghdad and Sadr City - giving a total of 18, 600 experiments.
To study the effects of grid-spacing on the run-time of REGION-GEN, we also
ran 25 trials for each grid spacing setting for both geographic areas - giving a total of
4, 650 experiments. To compare the algorithms running with different settings for g
in a statistically valid manner, we used ANOVA [50] to determine if the differences
among grid spacings are statistically significant. For some test results, we conducted
linear regression analysis.

5.5.2

Running Time

Overall, the run-times provided by the algorithms were quite reasonable. For
example, for the Baghdad trials, 73 attacks were considered for an area of 675m2 .
With a grid spacing g = 100m, REGION-GEN ran in 2340ms and GREEDY-MC2
took less than 30ms.

For GREEDY-MC2, we found that run-time generally decreased as g increased.
For Baghdad, the average run times ranged over [1.39, 34.47]ms. For Sadr City, these
times ranged over [0.15, 4.97]ms. ANOVAs for both Baghdad and Sadr City run-

242

times gave p-values of 2.2 · 10−16 , which suggests with well over 99% probability that
the algorithm run with different grid settings will result in different run-times. We
also recorded the number of regions considered in each experiment (resulting from
the output of REGION-GEN). Like run-times, we found that the number of regions
considered also decreased as the grid spacing increased. For Baghdad, the number
of considered regions ranged over [88, 1011]. For Sadr City, this number ranged over
[25, 356]. ANOVAs for both Baghdad and Sadr City number of considered regions
gave p-values of 2.2 · 10−16 , which suggests with well over 99% probability that the
algorithm run with different grid settings will result in different numbers of considered regions. Note that this is unsurprising as REGION-GEN run deterministically.
We noticed that, generally, only grid spacings that were near the same value would
lead to the same number of considered regions.

The most striking aspect of the run-time/number of regions considered results
for GREEDY-MC2 is that these two quantities seem closely related (see Figure 5.6).
This most likely results from the fact that the number of regions that can be associated with a given observation (∆) increases as the number of regions increases.
This coincides with our analysis of GREEDY-MC2 (see Proposition 45).
We also studied the average run-times for REGION-GEN for the various different settings for g. For Baghdad, the average run times ranged over [16.84, 9184.72]ms.
For Sadr City, these times ranged over [0.64, 308.92]ms. ANOVAs for both Baghdad
and Sadr City run-times gave p-values of 2.2 · 10−16 , which suggests with well over
99% probability that the algorithm run with different grid settings will result in
243

SADR CITY

35

5

30
4

25
20

3

15

2

10
1

5
70
140
210
280
350
420
490
560
630
700
770
840
910
980

0

0
70
140
210
280
350
420
490
560
630
700
770
840
910
980

Time in ms / 100s of Regions

BAGHDAD

40

6

Grid Spacing (m)
Solid Line = Runtime
Dotted Line = Number of Regions

Figure 5.6: The run-time of GREEDY-MC2 in ms compared with the number of
regions considered.
different run-times. Our analysis of REGION-GEN (See Proposition 48) states that
the algorithm runs in time O( g12 ). We found striking similarities with this analysis
and the experimental results (see Figure 5.7).

5.5.3

Area of Returned Regions

In this section, we examine how well the REGION-GEN/GREEDY-MC2 suite of
algorithms address the issue of returning regions that are generally small. Although
not inherently part of the algorithm, our intuition is that the Sup-REP-MC optimization problem will generally return small regions based on the set R produced
by REGION-GEN. The reason for this is that we would expect that smaller regions
generally support more observations (note that this is not always true, even for induced regions, but our conjecture is that it is often the case for induced regions or
the output of REGION-GEN).

244

SADR CITY

BAGHDAD

350
300

Time in ms

250
200
150
100
50
70
150
230
310
390
470
550
630
710
790
870
950

0

70
150
230
310
390
470
550
630
710
790
870
950

10000
9000
8000
7000
6000
5000
4000
3000
2000
1000
0

Grid Spacing (m)
Solid Line = Runtime
Dotted Line = Analytical Results

Figure 5.7: A comparison between analytical (O( g12 )) and experimental results for
the run-time of REGION-GEN compared with grid spacing (g).
To define “small” we look at the area of a circle of radius β as a basis for
comparison. As different grid settings led to different values for β, we looked at
the smallest areas. For a given trial, we looked at the average area of the returned
regions.

For Baghdad, the average areas ranged over [0.611, 2.985]km2 . For Sadr City,
these times ranged over (0.01, 0.576]km2 . ANOVAs for both Baghdad and Sadr City
run-times gave p-values of 2.2 · 10−16 , which suggests with a 99% probability that
the algorithm run with different grid settings will result in different average areas.
Plotting the areas compared with the established “minimum area” described earlier
in this section clearly shows that REGION-GEN/GREEDY-MC2 produce solutions
with an average area that is about half of this value - refer to Figure 5.8.
Overall, there seemed to be little relation between grid spacing and average
area of the returned set of regions - based on grid spacings in [70, 1000]m. As
245

BAGHDAD
6

1.4

maximum 5

maximum

1.2

4

1
0.8

3

0.6

2

0.4
1

0.2

70
140
210
280
350
420
490
560
630
700
770
840
910
980

0

0
70
150
230
310
390
470
550
630
710
790
870
950

Avg Area per Region (km2)

SADR CITY
1.6

Grid Spacing (m)

Figure 5.8: Average areas for solutions provided by REGION-GEN/GREEDY-MC2
for Baghdad and Sadr City.
an example, we provided screen-shots of GREEDY-MC2 for g = 100 and g = 1000
(Figure 5.9). Anecdotally, we noticed that larger grid spacing led to more “pinpoint”
regions - regions encompassing only one point in the grid (and viewed as having an
area of 0). This is most likely due to the fact that overlaps in the circles around
observations points would overlap on fewer grid points for larger values of g. Another
factor is that different settings for g led to some variation of the value β - which
also affects accuracy (note for our analysis we considered only the smallest values
of β as an upper bound for the area - see Figure 5.8.

5.5.4

Regions that Contain Caches

In this section we discuss the issue of ensuring that most of the returned regions
enclose at least one partner (cache in the case of our experiments). One measure
of this aspect is to look at the average number of caches enclosed per region in a
given result. We found, that for Baghdad, we generally enclosed more than 1 cache
246

g= 100 m
+
+
+

g= 1000 m
+

+
+
+
+
+

+

Figure 5.9: Results from two runs of GREEDY-MC2 - g = 100m (top), g = 1000m
(bottom). Pinpoint-regions are denoted with plus-signs. Notice that the average
areas of the results are comparable.

247

BAGHDAD

0.3

3

0.25

2.5

0.2

2

0.15

1.5

0.1

1

0.05

0.5

0

0
70
150
230
310
390
470
550
630
710
790
870
950

3.5

70
150
230
310
390
470
550
630
710
790
870
950

Avg Caches Enclosed Per Region

SADR CITY
0.35

Grid Spacing (m)

Figure 5.10: Average caches enclosed per region for Baghdad and Sadr City for
various grid-spacing settings.
per region in a given result - this number was in the range [0.764, 3.25]. The results
for Sadr City were considerably lower - in the range [0, 0.322]. ANOVAs for both
Baghdad and Sadr City gave p-values of 2.2 · 10−16 , which suggests with a 99%
probability that the algorithm run with different grid settings will result in different
average number of enclosed caches. However, we did not observe an obvious trend
in the data (see Figure 5.10).

As an alternative metric - we look at the number of regions in provided by
GREEDY-MC2 that contain at least one region. Figure 5.12 shows the number of
regions returned in the output. For Baghdad, generally less than half the regions
in the output will enclose a cache - the number of enclosing regions was in [1, 8],
while the total number of regions was in [10.49, 22]. This result, along with the
average number of caches enclosed by a region - may indicate that while sometimes
GREEDY-MC2 may find regions that enclose many caches, there are often regions
248

C C
C

C
CC
CCC CC
C
C A

C

CC
C C
C

C C
C
C C CC CC
CC CC C
+
C C+CC CC D
C CC+CCC
C
CCCC C
C
C
C
CC
CC
C
CCC I
C C C
CCCC
C
C C
C
CC
E
C
C
CCC
CCC
CC
C
CC
C

C C

C

C
C
C CC
CC C C
C

C
C

C

B

C
F CC C C
CC
C CCC
CC C CCG
C
C C CC C
C
C
C CC C C C C
C CC
CC
C
C
C CC CCC
C C
CC C C
C H CCC
C
C
CC
C C
C
C
CC

J

C
CC
C

C CC

C
CC
C

Figure 5.11: The output of GREEDY-MC2 for Baghdad with g = 100m compared
with the locations of actual cache sites (denoted with a “C”). Notice that regions
A-E do not contain any cache sites while regions G-I all contain numerous cache
sites.
that enclose no caches as well. This may indicate that for Baghdad, some attackscache relationships conform to our model and others do not - perhaps there is another
discriminating attribute about the attacks not present in the data that may account
for this phenomenon. For example, perhaps some attacks were preformed by some
group that had a capability to store weapons in a cache located further outside the
city, or perhaps some groups had the capability to conduct attacks using cache sites
that were never found. We illustrate this phenomenon with an example output in
Figure 5.11. Note that in the figure, regions A-E do not contain any cache sites
while regions G-I all contain numerous cache sites.

For Sadr City, the number of caches that contain one region was significantly

249

12

SADR CITY

10

20

8
15
6
10
4
5

2

0
70
150
230
310
390
470
550
630
710
790
870
950

0

70
140
210
280
350
420
490
560
630
700
770
840
910
980

Number of Regions

BAGHDAD

25

Grid Spacing (m)
Solid Line = Avg. number of regions enclosing at least one cache
Dotted Line = Average total regions

Figure 5.12: Regions in the output that enclose at least one partner (cache) and
total number of regions returned for Baghdad and Sadr City.
lower - in the range [0, 2], while the total number of returned regions was in [3, 9.8].
ANOVAs for both Baghdad and Sadr City gave p-values of 2.2·10−16 , which suggests
with well over 99% probability that the algorithm run with different grid settings
will result in different number of caches that enclose a region.
We believe that the low numbers for caches enclosed by regions for Sadr City
were directly related to the smaller areas of regions. However, the mean of the average area of a returned set of regions was 0 for 49 of the 94 different grid settings (for
Sadr City). This means that for the majority of grid settings, the solution consisted
only of “pinpoint” regions (see Section 5.5.3 for a description of “pinpoint” regions).

Obviously, it is unlikely for a pinpoint region to contain a cache site merely due
to its infinitesimally small area. To better account for this issue - we develop another
metric - distance to nearest cache. If a region contains a cache, the value for this metric is 0. Otherwise, it is the distance to the closest cache outside of the region. For
250

BAGHDAD
0.8

0.4

0.7

0.35

0.6

0.3

0.5

0.25

0.4

0.2
0.1

0.2

0.05

0.1

0

0
70
140
210
280
350
420
490
560
630
700
770
840
910
980

0.3

0.15

70
150
230
310
390
470
550
630
710
790
870
950

Distance to Nearest Cache Outside Region

SADR CITY
0.45

Grid Spacing (m)
Solid Line = Avg. Distance
Dotted Line = Linear Regression

Figure 5.13: Distance to nearest cache vs. grid spacing.
Baghdad, we obtained distances in [0.246, 0.712]km, for Sadr City, [0.080, 0.712]km.
ANOVAs for both Baghdad and Sadr City gave p-values of 2.2·10−16 , which suggests
with well over 99% probability that the algorithm run with different grid settings
will result in different distances to the nearest cache. Using linear regression, we
observed that this distance increases as grid spacing increases. For Baghdad, we obtained R2 = 0.2396 and R2 = 0.2688 for Sadr City. See Figure 5.13 for experimental
results and the results of the liner regression analysis.

5.5.5

Partner Density

T consider the density of partners in the regions, we compare the number of enclosed partners to the overall partner density of the area in question. For Baghdad,
there were 303 caches in an area 27 × 24km - giving a density of 0.488caches/km2 .
For Sadr City, there were 64 caches in an area 7 × 7km - giving a density of
1.306caches/km2 . In our experiments, we looked at the cache density for each output. For Baghdad, the density was significantly higher - in [0.831, 34.9]cache/km2 .
251

35

SADR CITY

BAGHDAD

40
35

25

30

Caches per km2

30

25

20

20

15
15

10

0
70
150
230
310
390
470
550
630
710
790
870
950

5

0

70
140
210
280
350
420
490
560
630
700
770
840
910
980

10

5

Grid Spacing (m)

Dotted line = Linear regression
Dashed Line = Overall cache density
Solid Line = Cache density in returned regions

Figure 5.14: Cache density of outputs produced by GREEDY-MC2 for Baghdad and
Sadr City compared with overall cache density and linear-regression analysis.
If we consider g ∈ [70, 200], the density is in [7.19, 32.9]cache/km2 . For g = 100,
the density was 8.09caches/km2 . Most likely due to the issue of “pinpoint” regions
described in Section 5.5.3, the results for Sadr City, were often lower than the overall
density (in [0, 31.3]cache/km2 ). For g = 100, the density was 2.08caches/km2 . We
illustrate these results compared with overall cache density in Figure 5.14.
ANOVAs for both Baghdad and Sadr City gave p-values of 2.2 · 10−16 , which
suggests with well over 99% probability that the algorithm run with different grid
settings will result in different cache densities. Using linear regression, we observed
that this cache density decreases as grid spacing increases. For Baghdad, we obtained R2 = 0.1614 and R2 = 0.1395 for Sadr City. See Figure 5.14 for experimental
results and the results of the liner regression analysis.
Although partner density is a useful metric, it does not tell us anything about
partners that lie close to a region - although still outside. For example, consider
Figure 5.11. Although region A does not enclose any caches, there is a cache just
252

C

F C
C
C
C

C
C
C
C

C
C

Figure 5.15: Close-up of region F from Figure 5.11. While region F contains 1
cache, there are 4 other caches < 250m from the boundary of that region. The
area-quadrupling metric helps us account for such scenarios.
outside - region B is similar. Also consider the cluster of caches south of region E
and north of region J - in this situation it appears as though GREEDY-MC2 mispositioned a region. We include a close-up of region F in Figure 5.15, which encloses
a cache, but there are also 4 other caches at a distance of 250m or less.
In order to account for such phenomena, we created an area-quadrupling metric
- that is we uniformly double the sides of each region in the output. Then, we
calculated the density of the output with area-quadrupled regions. For Baghdad,
this density was in [0.842, 30.3]caches/km2 . For Sadr City, this density was in
[0, 12.3]caches/km2 . These results are depicted in Figure 5.16.
As the regions for Sadr City were often smaller than those in Baghdad, we
found that the cache density for area-quadrupled regions was often higher for Sadr
City (i.e. a region in Sadr City would have nearby cache sites). An example is

253

SADR CITY

BAGHDAD
35

10

30

Caches per km2

8

25
20

6

15

4

10

2

5
0
70
140
210
280
350
420
490
560
630
700
770
840
910
980

70
140
210
280
350
420
490
560
630
700
770
840
910
980

0

Grid Spacing (m)
Solid Line = Cache density in quadruple-size regions
Dotted Line = Linear regression

Figure 5.16: Area quadrupled cache density of output produced by GREEDY-MC2
with linear-regression analysis.
shown in Figure 5.15.
ANOVAs for both Baghdad and Sadr City gave p-values of 2.2 · 10−16 , which
suggests with well over 99% probability that the algorithm run with different grid
settings will result in different cache densities for area-quadrupled regions. We also
conducted linear regression analysis, and like the normal partner density, we found
that cache density decreases as grid spacing increases. However, this liner analysis
was more closely correlated with the data than the analysis for non-area quadrupled
density. For Baghdad, we obtained R2 = 0.3171 (for non-area quadrupled, we
obtained R2 = 0.1614) and R2 = 0.3983 (for non-area quadrupled, we obtained
R2 = 0.1395) for Sadr City. See Figure 5.16 for experimental results and the results
of the liner regression analysis.

254

5.6

Chapter 5 Related Work
Facility location [164] may also appear similar to this work. However, facility

location problems normally seek to locate a facility at an infinitesimal point with
respect to some minimality criteria - not identify a region. Further, in a facility location problem, distance is often sought to be minimized - so a “closer” facility may
be more optimal. In our formulation, we restrict distance with α, β, but a more optimal region is not necessarily closer to its associated observation. Rather, a region
is often more optimal provided if it supports multiple partners. This may, in fact,
make regions further from their observations. Another problem, which influences
some facility location work, is the k-means problem [116]. This type of “clustering” technique looks to group points together and possibly locate a “center.” While
there is an implicit grouping of observations by the algorithms of this paper, we
are attempting to find regions that explain them rather than simply group them.
Moreover, Chapter 4 shows experimentally that the methods for solving GAPs significantly outperform simply applying k-means algorithms. This fact illustrates that
the problem of this paper (and other work in geospatial abduction) is fundamentally
different from work in clustering. Perhaps some of the closest work to our problem
is in the study of the circle-covering problem [125, 70, 58, 16]. The problem of
this paper is more general than circle-covering although special case of the regionexplanation problem does reduce to circle-covering, as described in Section 5.4.2
(page 230).

255

5.7

Chapter Summary
In this chapter we explored a variant of “geospatial abduction” (which was in-

troduced in chapter 4) called region-based geospatial abduction problems where the
user wishes to identify a set of regions that best explain a given set of observations.
This has several important applications including criminology [144], marketing [55],
natural science [143], and the military [170]. We explored properties and the complexity of several variants of this problem, including variants where the space is
induced by a distance from the observations, as well as when the regions are irregular shapes (including non-convex). As most of the problems were NP-hard, we
illustrated a variety of approximation techniques, often with guarantees, to address
these problems. We also implemented some of our algorithms and evaluated with
a real-world counterinsurgency [72] data-set to find weapons cache sites based on
attack data in Baghdad, Iraq and produced regions that had an average density of
over 8 caches per square kilometer, significantly higher than the city wide density
of 0.4.
There are many interesting open questions relating to this type of abduction
problem. Future work may include studies of the counting version of the problem,
where we may consider all possible solutions to a given region explanation problem
according to a probability distribution and determine the “most probable” regions.
Another aspect to consider would be time – perhaps in some applications the locations of the partners are in a certain region only at a certain time.

256

Chapter 6
Adversarial Geospatial Abduction

Given an instance of a geospatial abduction problem from Chapter 4, where
do we look for partners if an adversary is aware of the algorithms we are using? We
study this situation, along with a complementary problem in this chapter.1

6.1

Chapter Introduction
Geospatial abduction problems (GAPs) were introduced in Chapter 4 to find

a set of locations that “best explain” a given set of locations of observations. We
call these inferred sets of locations “explanations”. There we described many such
applications of GAPs.
Chapter 4 defined geospatial abduction problems (GAPs) and studied a version of the problem where the adversary (the “bad guy” or the entity that wishes
to evade detection) does not reason about the agent (the “good guy” or the entity
1

This chapter is based on [154] completed in cooperation with John Dickerson and V.S. Sub-

rahmanian.

257

that wants to detect the adversary). Despite this significant omission, they were
able to accurately predict the locations of weapons caches in real-world data about
IED attacks in Baghdad. In this chapter, we introduce adversarial geospatial abduction problems where both the agent and the adversary reason about each other.
Specifically, we:
1. Axiomatically define reward functions to be any functions that satisfy certain
basic axioms about the similarity between an explanation chosen by the adversary (e.g. where the serial killer lives and works or where the insurgents put
their IED caches) and define notions of expected detriment (to the adversary)
and expected benefit (to the agent).
2. Formally define the optimal adversary strategy (OAS) that minimizes chances
of detection of the adversary’s chosen explanation and the maximal counteradversary strategy (MCA) that maximizes the probability that the agent will
detect the adversary’s chosen explanation.
3. Provide a detailed set of results on the computational complexity of these
problems, the counting complexity of these problems, and the possibility of
approximation algorithms with approximation guarantees for both OAS and
MCA.
4. Develop mixed integer linear programming algorithms (MILPs) for OAS and
two algorithms, MCA-LS and MCA-GREEDY-MONO, to solve MCA with certain approximation guarantees. MCA-LS has no assumptions, while MCAGREEDY-MONO assumes monotonicity.
258

5. Develop a prototype of our MILP algorithms to solve the OAS problem, using
our techniques for variable reduction on top of a integer linear program solver.
We demonstrate the ability to achieve near-optimal solutions as well as a
correct reduction of variables by 99.6% using a real-world data set.
6. Develop a prototype implementation that shows that both MCA-LS and MCAGREEDY-MONO are highly accurate and have very reasonable time frames.
Though MCA-GREEDY-MONO is slightly faster than MCA-LS, we found that
on every single run, MCA-LS found the exact optimal benefit even though its
theoretical lower bound approximation ratio is only 1/3. As MCA-LS does not
require any additional assumptions and as its running time is only slightly
slower than that of MCA-GREEDY-MONO, we believe this algorithms has a
slight advantage.
The main contributions of the chapter are as follows. Section 6.2 first reviews
the GAP framework of Chapter 4. Section 6.3 extends GAPs to the adversarial case
using axiomatically defined reward function (Section 6.2). Section 6.4 complexity
results and several exact algorithms using MILPs for the OAS problem. Section 6.5
provides complexity results and develops exact and approximate methods MCA
—including an approximation technique that provides the best possible guarantee
unless P=NP. We then briefly describe our prototype implementation and describe
a detailed experimental analysis of our algorithms. Finally, related work is then
described in Section 6.7.

259

6.2

Overview of GAPs
We utilize the same definitions of a space, observations, feasibility, partners,

and explanations as we did in Chapter 4. We note in that chapter we often sought
to find an explanation of minimal cardinality, a common parsimony requirement.
Alternatively, another requirement that can be imposed on an explanation is irredundancy.
Definition 58. An explanation E is irredundant iff no strict subset of E is an
explanation.
Intuitively, if we can remove any element from an explanation – and this action
causes it to cease to be a valid explanation – we say the explanation is irredundant.
Example 6.2.1. Figure 6.1 shows a map of a drug plantation depicted in a 18 ×
14 grid. The distance between grid squares is 100 meters. Observation set O =
{o1 , o2 , o3 , o4 , o5 } represents the center of mass of the poppy fields. Based on an
informant or from historical data, drug enforcement officials know that there is a
drug laboratory located 150 − 320 meters from the center mass of each field (i.e. in a
geospatial abduction problem, we can set [α, β] = [150, 320]). Further, based on the
terrain, the drug enforcement officials are able to discount certain areas (shown in
black on Figure 6.1, a feasibility predicate can easily be set up accordingly). Based on
Figure 6.1, the set {p40 , p46 } is an irredundant explanation. The sets {p42 , p45 , p48 }
and {p40 , p45 } are also irredundant explanations.
In Chapter 4, we showed the problem of finding an explanation of size k
to be NP-Complete based on a reduction from the known NP-Complete problem
260

o4
33 34 35

o1
37 38
44 45 46 47

o3

52

40 41 42 43
48 49 50
56

o2

o5

57

Figure 6.1: Map of poppy fields for Example 6.2.1. For each labeled point pi , the
“p” is omitted for readibility.
Geometric Covering by Discs (GCD) seen in [76]. As with most decision problems,
we define the associated counting problem, #GCD, as the number of “yes” answers to
the GCD decision problem. The result below, which is new, shows that #GCD is #Pcomplete and, moreover, that there is no fully-polynomial random approximation
scheme for #GCD unless N P equals the complexity class RP .2
Lemma 19. #GCD is #P-complete and has no FPRAS unless NP=RP.
We can leverage the above result to derive a complexity result for the counting
version of k-SEP.
2

RP is the class of decision problems for which there is a randomized polynomial algorithm

that, for any instance of the problem, returns “false” with probability 1 when the correct answer
to the problem instance is false, and returns “true” with probability (1 − ǫ) for a small ǫ > 0 when
the correct answer to the problem instance is “true.”

261

Theorem 27. The counting version of k-SEP is #P-Complete and has no FPRAS
unless NP=RP.

6.3

Geospatial Abduction as a Two-Player Game
Throughout this chapter, we view geospatial abduction as a two-player game

where an agent attempts to find an “explanation” for a set of observations caused
by the adversary who wants to hide the explanation from the agent.
Each agent chooses a strategy which is merely a subset of S. Though “strategy”
and “observation” are defined identically, we use separate terms to indicate our
intended use. In the IED example, the adversary’s strategy is a set of points where
to place his cache, while the agent’s strategy is a set of points that he thinks hold
the weapons caches. Throughout this chapter, we use Egt (resp. C) to denote the
strategy of the adversary (resp. agent).
Given a pair (Egt , C) of adversary-agent strategies, a reward function measures
how similar the two sets are. The more similar, the better it is for the agent. As
reward functions can be defined in many ways, we choose an axiomatic approach so
that our framework applies to many different reward functions including ones that
people may invent in the future.
Definition 59 (Reward Function). A reward function is any function rf : 2S ×2S →
[0, 1] that for any k-explanation Egt 6≡ ∅ and set C ⊆ S, the function satisfies:
1. If C = Egt , then rf(Egt , C) = 1

262

2. For C, C ′ then
rf(Egt , C ∪ C ′ ) ≤ rf(Egt , C) + rf(Egt , C ′ ) − rf(Egt , C ∩ C ′ ).
We now define the payoffs for the agent and adversary.
Observation 6.3.1. Given adversary strategy Egt , agent strategy C, and reward
function rf, the payoff for the agent is rf(Egt , C) and the payoff for the adversary is
−rf(Egt , C).
It is easy to see that for any reward function and pair (Egt , C), the corresponding game is a zero-sum game [102]. Our complexity analysis assumes all reward
functions are polynomially computable. All the specific reward functions we propose in this chapter satisfy this condition.
The basic intuition behind the reward function is that the more the strategy
of the agent resembles that of the adversary, the closer the reward is to 1. Axiom 1
says that if the agent’s strategy is the same set as adversary’s, then the reward is
1. Axiom 2 says that adding a point to C cannot increase the reward to the agent
if that point is already in C, i.e. double-counting of rewards is forbidden.
The following theorem tells us that every reward function is submodular, i.e.
the marginal benefit of adding additional points to the agent’s strategy decreases as
the cardinality of the strategy increases.
Proposition 49 (Submodularity of Reward Functions). Every reward function is
submodular, i.e. If C ⊆ C ′ , and point p ∈ S s.t. p ∈
/ C and p ∈
/ C ′ , then rf(Egt , C ∪
{p}) − rf(Egt , C) ≥ rf(Egt , C ′ ∪ {p}) − rf(Egt , C ′ ).
263

Some readers may wonder why rf(Egt , ∅) = 0 is not an axiom. While this is
true of many reward functions, there are reward functions where we may wish to
penalize the agent for “bad” predictions. Consider the following reward function.
Definition 60 (Penalizing Reward Function). Given a distance dist, we define the
penalizing reward function, prf(dist) (Egt , C), as follows:
1 |{p ∈ Egt |∃p′ ∈ C s.t. d(p, p′ ) ≤ dist}| |{p ∈ C| 6 ∃p′ ∈ Egt s.t. d(p, p′ ) ≤ dist}|
+
−
2
2 · |Egt |
2 · |S|
Proposition 50. prf is a valid reward function.
Example 6.3.1. Consider Example 6.2.1 and the explanation Egt ≡ {p40 , p46 } (resembling actual locations of the drug labs), the set C ≡ {p38 , p41 , p44 , p56 } (representing areas that the drug enforcement officials wish to search), distance dist =
100 meters.There is only one point in Egt that is within 100 meters of a point
in C (point p40 ) and 3 points in C more than 100 meters from any point in Egt
(points p38 , p44 , p56 ). These relationships are shown visually in Figure 6.2. Hence,
prf(dist) (Egt , C) = 0.5 + 0.25 − 0.011 = 0.739.
prf penalizes the agent if he poorly selects points in S. The agent starts with
a reward of 0.5. The reward increases if he finds points close to elements of Egt —
otherwise it decreases.
A reward function is zero-starting if rf(Egt , ∅) = 0, i.e. the agent gets no
reward if he infers nothing.
Definition 61. A reward function, rf, is monotonic if (i) it is zero-starting and
(ii) if C ⊆ C ′ then rf(Egt , C) ≤ rf(Egt , C ′ ).
264

o4
33 34 35

o1
37 38
44 45 46 47

o3

52

40 41 42 43
48 49 50
56

o2

o5

57

Figure 6.2: Dashed circles encompass all feasible points within 100 meters from
explanation {p40 , p45 }.
We now define several example monotonic reward functions.
The intuition behind the cutoff reward function crf is simple: for a given
distance dist (the “cut-off” distance), if for every p ∈ Egt , there exists p′ ∈ C such
that d(p, p′ ) ≤ dist, then p′ is considered “close to” p.
Definition 62 (Cutoff Reward Function). Reward function based on a cut-off distance, dist.
crf(dist) (Egt , C) :=

card({p ∈ Egt |∃p′ ∈ C s.t. d(p, p′ ) ≤ dist})
card(Egt )

The following proposition shows that the cutoff reward function is a valid,
monotonic reward function.
Proposition 51. crf is a valid, monotonic reward function.

265

Example 6.3.2. Consider Example 6.3.1. Here, crf(dist) (Egt , C) returns 0.5 as one
element of Egt is within 100 meters of an element in C.
By allowing a more general notion of “closeness” between points p ∈ Egt and
p′ ∈ E, we are able to define another reward function, the falloff reward function,
frf. This function provides the most reward if p = p′ but, unlike the somewhat
binary crf, gently lowers this reward to a minimal zero as distances d(p, p′ ) grow.
Definition 63 (Falloff Reward Function). Reward function with value based on
minimal distances between points.




frf(Egt , C) :=

P

 p∈E
with d(p, p′ ) :=

0
gt

1
|Egt |+minp′ ∈C (d(p,p′ )2 )

if C = ∅
otherwise

q
(px − p′x )2 + (py − p′y )2 . In this case, the agent’s reward is in-

versely proportional to the square of the distance between points, as the search area
required grows proportionally to the square of this distance.
Proposition 52. frf is a valid, monotonic reward function.
In practice, an agent may assign different weights to points in S based on
the perceived importance of their partner observations in O. The “weighted reward
function” wrf gives greater reward for being “closer” to points in Egt that have high
weight than those with lower weights.
Definition 64 (Weighted Reward Function). Given weight function W : S → R+ ,
and a cut-off distance dist we define the weighted reward function to be:
P
{p∈Egt |∃p′ ∈C s.t. d(p,p′ )≤dist} W (p)
P
wrf(W,dist) (Egt , C) :=
′
p′ ∈Egt W (p )
266

Proposition 53. wrf is a valid, monotonic reward function.
It is easy to see that the weighted reward function is a generalization of the
cutoff reward function where all weights are 1.

6.3.1

Incorporating Mixed Strategies

In this section, we introduce pdfs over strategies (or “mixed strategies” [102])
and introduce the notion of “expected reward.” We first present explanation/strategy
functions which return an explanation (resp. strategy) of a certain size for a given
set of observations.
Definition 65 (Explanation/Strategy Function). An explanation (resp. strategy)
function is any function ex fcn : 2S × N → 2S (resp. sf : 2S × N → 2S ) that, given
a set O ⊆ S and k ∈ N, returns a set E ⊆ S such that E is a k-sized explanation of
O (resp. E is a k-sized subset of S). Let EF be the set of all explanation functions.
Example 6.3.3. Following from Example 6.2.1, we shall define two functions ex fcn1 , ex fcn2 ,
which for set O (defined in Example 6.2.1 and k ≤ 3, give the following sets:
ex fcn1 (O, 3) = {p42 , p45 , p48 }
ex fcn2 (O, 3) = {p40 , p46 }
These sets may correspond to explanations from various sources. Perhaps they correspond to the answer of an algorithm that drug-enforcement officials use to solve
GAPs. Conversely, they could also be the result of a planning session by the drug
cartel to determine optimal locations for the drug labs.
267

In theory, the set of all explanation functions can be infinitely large; however,
it makes no sense to look for explanations containing more points than S — so we
assume explanation functions are only invoked with k ≤ (M + 1) × (N + 1).
A strategy function is appropriate for an agent who wants to select points resembling what the adversary selected, but is not required to produce an explanation.
Our results typically do not depend on whether an explanation or strategy function
is used (when they do, we point it out). Therefore, for simplicity, we use “explanation function” throughout the chapter. In our complexity results, we assume that
explanation/strategy functions are computable in constant time.
Both the agent and the adversary do not know the explanation function (where
is the adversary going to put his weapons caches? where will US forces search for
them?) in advance. Thus, they use a pdf over explanation functions to estimate
their opponent’s behavior, yielding a “mixed” strategy.
Definition 66 (Explanation Function Distribution). Given a space S, real numbers
α, β, feasibility predicate feas, and an associated set of explanation functions EF, an
explanation function distribution is a finitary3 probability distribution exfd : EF →
[0, 1] with

P

ex fcn∈EF

exfd(ex fcn) = 1. Let EFD be a set of explanation function

distributions.

We use |exfd| to denote the cardinality of the set EF associated with exfd.
Example 6.3.4. Following from Example 6.3.3, we shall define the explanation
function distribution exfddrug that assigns a uniform probability to explanation func3

That is, exfd assigns non-zero probabilities to only finitely many explanation functions.

268

tions in the set ex fcn1 , ex fcn2 (i.e. exfddrug (ex fcn1 ) = 0.5).
We now define an “expected reward” that takes into account these mixed
strategies specified by explanation function distributions.
Definition 67 (Expected Reward). Given a reward function rf, and explanation
function distributions exfdadv , exfdag , the expected reward is the function EXR(rf) :
EFD × EFD → [0, 1]. For some explanations function distributions exfdadv , exfdag ,
we define EXR(rf) (exfdadv , exfdag ) as follows:
X

ex fcnadv ∈EFadv



exfdadv (ex fcnadv ) ·

X

ex fcnag ∈EFag



exfdag (ex fcnag ) · rf(ex fcnadv , ex fcnag )

However, in this chapter, we will generally not deal with expected reward
directly, but two special cases - expected adversarial detriment and expected agent
benefit - in which the adversary’s and agent’s strategies are not mixed respectively.
We explore these two special cases in the next two sections.

6.4

Selecting a Strategy for the Adversary
In this section, we look at how an adversary would select points (set Egt ) in the

space he would use to cause observations O. For instance, in the IED example, the
adversary needs to select Egt and O so that Egt is an explanation for O. We assume
the adversary has a probabilistic model of the agent’s behavior (an explanation
function distribution) and that he wants to eventually find an explanation (e.g. to
put his weapons caches at). Hence, though he can use expected reward to measure
how close the agent will be to his explanation, only the agent’s strategy is mixed.
269

His actions are concrete. Hence, we introduce a special case of expected reward –
expected adversarial detriment.
Definition 68 (Expected Adversarial Detriment). Given any reward function rf,
and explanation function distribution exfd, the expected adversarial detriment is the
function EXR(rf) : EFD × 2S → [0, 1] defined as follows:
EXR(rf) (exfd, Egt ) =

X

ex fcn∈EF

rf(Egt , ex fcn(O, k)) · exfd(ex fcn)

Intuitively, the expected adversarial detriment is the fraction of partner locations the agent may uncover. Consider the following example.
Example 6.4.1. Following from the previous examples, suppose the drug cartel
is planning three drug labs. Suppose they have information that drug-enforcement
agents will look for drug labs using exfddrug (Example 6.3.4). One suggestion the
adversary may consider is to put the labs at locations p41 , p52 (see Figure 6.1). Note
that this explanation is optimal wrt cardinality. With dist = 100 meters, they wish
to compute EXR(crf) (exfddrug , {p41 , p52 }). We first need to find the reward associated
with each explanation function (see Example 6.3.3):
crf(dist) ({p41 , p52 }, ex fcn1 (O, 3)) = 1
crf(dist) ({p41 , p52 }, ex fcn2 (O, 3)) = 0.5
Thus, EXR(crf) (exfddrug , {p41 , p52 }) = 0.5 · 1 + 0.5 · 0.5 = 0.75. Hence, this is probably
not the best location for the cartel to position the labs wrt crf and exfd – the expected
adversarial detriment of the drug-enforcement agents is large.

270

The expected adversarial detriment is a quantity that the adversary would
seek to minimize — this now defined as an optimal adversarial strategy below.
Definition 69 (Optimal Adversarial Strategy). Given a set of observations O,
natural number k, reward function rf, and explanation function distribution exfd,
an optimal adversarial strategy is a k-sized explanation Egt for O such that
EXR(rf) (exfd, Egt ) is minimized.

6.4.1

The Complexity of Finding an Optimal Adversarial
Strategy

In this section, we formally define the optimal adversary strategy (OAS) problem and study its complexity.

OAS Problem
INPUT: Space S, feasibility predicate, feas, real numbers α, β, set of observations,
O, natural number k, reward function rf, and explanation function distribution
exfd.
OUTPUT: The optimal adversarial strategy, Egt .

We show that the known NP-hard problem Geometric Covering by Discs (see
Section 6.2) is polynomially reducible to OAS - this establishes NP-hardness.
Theorem 28. OAS is NP-hard.
The proof of the above theorem yields two insights. First, OAS is NP-hard
271

even if the reward function is monotonic (or anti-monotonic). Second, OAS remains
NP-hard even if the cardinality of EF is small - in the construction we only have one
explanation function. Thus, we cannot simply pick an “optimal” function from EF.
To show an upper bound, we define OAS-DEC to be the decision problem associated
with OAS. If the reward function is computable in polynomial time, OAS-DEC is
in NP.

OAS-DEC
INPUT: Space S, feasibility predicate, feas, real numbers α, β, set of observations,
O, natural number k, reward function rf, explanation function distribution exfd,
and number R ∈ [0, 1].
OUTPUT: “Yes” if there exists an adversarial strategy, Egt such that EXR(rf) (exfd, Egt ) ≤
R – “no” otherwise.
Theorem 29. If the reward function is computable in PTIME, then OAS-DEC is
NP-complete.
Suppose we have an NP oracle that can return an optimal adversarial strategy
- lets call it Egt . Quite obviously, this is the best response of the adversary to the
mixed strategy of the agent. Now, how does the agent respond to such a strategy?
If we were to assume that such a solution were unique, then the agent would simply
have to find an strategy C such that rf(Egt , C) is maximized. This would be a special
case of the problem we discuss in Section 6.5. However, this is not necessarily the
case. A natural way to address this problem is to create a uniform probability
272

distribution over all optimal adversarial strategies and optimize the expected reward
– again a special case of what is to be discussed in Section 6.5. However, obtaining
the set of explanations is not an easy task. Even if we had an easy way to exactly
compute an optimal adversarial strategy, finding all such strategies is an even more
challenging problem. In fact, it is at least as hard as the counting version of GCD
– which we already have shown to be #P-hard and difficult to approximate. Let us
consider the following theorem.
Theorem 30. Finding the set of all adversarial optimal strategies that provide a
“yes” answer to OAS-DEC is #P-hard.

6.4.2

Pre-Processing and Naive Approach

In this section, we present several algorithms to solve OAS. We first present a
simple routine for pre-processing followed by a naive enumeration-based algorithm.
We use ∆ to denote the maximum number of partners per observation and f
to denote the maximum number of observations supported by a single partner. In
general, ∆ is bounded by π(β 2 − α2 ), but may be lower depending on the feasible
points in S. Likewise, f is bounded by min(|O|, ∆) but may be much smaller depending on the sparseness of the observations.

Pre-Processing Procedure. Given a space S, a feasibility predicate feas, real
numbers α, β ∈ [0, 1], and a set O of observations, we create two lists (similar to a
standard invertex index) as follows.

273

4

5

6

7

12 13 14 15 16
22
23
30
31
o1
37 38
44 45 46 47

1 2 3
8 9 10 11

17 18 19 20
21
24 25 26 27 28
29
o4
32
33 34 35 36
39

52

o3

40 41 42 43
48 49 50 51

53 54 55 56

o5

57 58 59 60

o2

61 62 63
65 66

64
67

Figure 6.3: Set L of all possible partners for our drug laboratory location example.
• Matrix M . M is an array of size S. For each point p ∈ S, M [p] is a list of
pointers to observations. M [p] contains pointers to each observation o such that
feas(p) is true and such that d(o, p) ∈ [α, β].
• List L. List L contains a pointer to position M [p] in the array M iff there exists
an observation o ∈ O such that feas(p) is true and such that d(o, p) ∈ [α, β]..
It is easy to see that we can compute M and L in O(|O| · ∆) time. The example
below shows how M, L apply to our running drug example.
Example 6.4.2. Consider our running example concerning the location of drug
laboratories that started with Example 6.2.1. The set L consists of {p1 , . . . , p67 }.
The matrix M returns lists of observations that can be associated with each point.
For example, M (p40 ) = {o3 , o4 , o5 } and M (p46 ) = {o1 , o2 }.
Naive Approach. After pre-processing, a straight-forward exact solution to OAS
274

would be to enumerate all subsets of L that have a cardinality less than or equal to
k. Let us call this set L∗ . Next, we eliminate all elements of L∗ . that are not valid
explanations. Finally, for each element of L∗ , we compute the expected adversarial
detriment - and return the element of L∗ for which this value is the least. Clearly,
this approach is impractical as the cardinality of L∗ can be very large. Further, this
approach does not take advantage of the specific reward functions. We now present
mixed integer linear programs (MILPs) for wrf and frf and later look at ways to
reduce the complexity of solving these MILPs.

6.4.3

Mixed Integer Linear Programs for OAS under wrf, crf, frf

We present mixed integer linear programs (MILPs) to solve OAS exactly for
some specific reward functions. First, we consider the reward function wrf. Later,
in Section 6.4.4, we show how to improve efficiency by correctly reducing the number
of variables in such MILPs. Note that these constraints can also be used for crf as
wrf generalizes crf.
Definition 70 (wrf MILP). We associate an integer-valued variable Xi with each
pi ∈ L.
Minimize:
X

ex fcnj ∈EF

!

exfd(ex fcnj ) ·

X

pi ∈L

!

subject to:
1. Xi ∈ {0, 1}
2. Constraint

P

pi ∈L

Xi ≤ k
275

wi · ci,j
Xi · ( P
)
pi ∈L wi · Xi

##

3. For each oj ∈ O, add constraint
P

pi ∈L d(oj ,pi )∈[α,β]

Xi ≥ 1

4. For each pi ∈ L and ex fcnj ∈ EF, let constant ci,j = 1 iff ∃p′ ∈ ex fcn(O, k)
s.t. d(p′ , pi ) ≤ dist and 0 otherwise.
Example 6.4.3. Continuing from Examples 6.4.1 (page 270) and 6.4.2, suppose
the drug cartel wishes to produce an adversarial strategy Egt using wrf. Consider
the case where we use crf, k ≤ 3, and dist = 100 meters as before (see Example 6.4.1). Clearly, there are 67 variables in these constraints, as this is the cardinality of set L (as per Example 6.4.2). The constants ci,1 are 1 for elements in the
set {p35 , p40 , p41 , p42 , p43 , p44 , p45 , p46 , p49 , p49 , p50 , p52 , p56 } (and 0 for all others). The
constants ci,2 are 1 for elements in the set {p33 , p37 , p40 , p41 , p45 , p46 , p47 , p48 } (and 0
for all others).
We can create a MILP for frf as follows.
Definition 71 (frf MILP). Minimize:
X

ex fcnj ∈EF

!

exfd(ex fcnj ) ·

X

pi ∈L

!

subject to:
1. Xi ∈ {0, 1}
2. Constraint

P

pi ∈L

Xi ≤ k

3. For each oj ∈ O, add constraint
P

pi ∈L d(oj ,pi )∈[α,β]

Xi ≥ 1
276

Xi · (

ci,j +

1
P

pi ∈L

Xi

)

##

4. For each pi ∈ L and ex fcnj ∈ EF, let constant ci,j = minp′ ∈ex fcn(O,k) (d(pi , p′ )2 ).
The following theorem tells us that solving the above MILPs correctly yields
a solution for the OAS problem under both wrf or frf.
Proposition 54. Suppose S is a space, O is an observation set, [α, β] ⊆ [0, 1] and
suppose the wrf and frf MILPs are defined as above.
1. Suppose Egt ≡ {p1 , . . . , pn } is a solution to OAS with wrf(resp. frf). Consider
the assignment that assigns 1 to each X1 , . . . , Xn corresponding to the pi ’s and
0 otherwise. This assignment is an optimal solution to the MILP.
2. Given the solution to the constraints, if for every Xi = 1, we add point pi to
set Egt , then Egt is a solution to OAS with wrf(resp. frf).
Setting up either set of constraints can be performed in polynomial time –
where computing the ci,j constants is the dominant operation.
Proposition 55. Setting up the wrf/frf Constraints can be accomplished in O(|EF|·
k · |O| · ∆) time (provided the weight function W can be computed in constant time).
The number of variables for either set of constraints is related to the size of L
- which depends on the number of observations, spacing of S, and α, β.
Proposition 56. The wrf/frf Constraints have O(|O| · ∆) variables and 1 + |O|
constraints.
The MILPs for wrf and frf appear non-linear as the objective function is fractional. However, as the denominator is non-zero and strictly positive, the Charnes277

Cooper transformation [22] allows us to quickly (in the order of number of constraints multiplied by the number of variables) transform the constraints into a
purely integer-linear form. Many linear and integer-linear program solvers include
this transformation in their implementation.
Proposition 57. The wrf/frf constraints can be transformed into a purely linearinteger form in O(|O|2 · ∆) time.
We note that a linear relaxation of any of the above three constraints can yield
a lower bound on the objective function in O(|L|3.5 ) time.
Proposition 58. Given the constraints of Definition 70 or Definition 71, if we
consider the linear program formed by setting all Xi variables to be in [0, 1], then the
value returned by the objective function will be a lower bound on the value returned
by the objective function for the mixed integer-linear constraints, and this value can
be obtained in O(|O|3.5 · ∆3.5 ) time.
Likewise, if we solve the mixed integer linear program with a reduced number
of variables, we are guaranteed that the solution will cause the objective function
to be an upper bound for the original set of constraints.
Proposition 59. Consider the MILPs in Definition 70 and Definition 71. Suppose
L′ ⊂ L and every variable Xi associated with some pi ∈ L′ is set to 0. The resulting
solution is an upper bound on the objective function for the constraints solved on the
full set of variables.

278

6.4.4

Correctly Reducing the Number of Variables for crf

As the complexity of solving MILPs is closely related to the number of variables
in the MILP, the goal of this section is to reduce the number of variables in the MILP
associated above with the crf reward function. In this section, we show that if we
can find a certain type of explanation called a δ-core optimal explanation, then we
can “build-up” an optimal adversarial strategy in polynomial time. It also turns out
that finding these special explanations can be accomplished using a MILP which
will often have significantly less variables than the MILP’s of the last section. First,
we consider the wrf constraints applied to crf which is a special case of wrf. The
objective function for this caseis:
X

ex fcnj ∈EF

!

exfd(ex fcnj ) ·

X

pi ∈L

!

Xi · ( P

ci,j
pi ∈L

Xi

)

##

where for each pi ∈ L and ex fcnj ∈ EF, ci,j = 1 iff ∃p′ ∈ ex fcn(O, k) s.t. d(p′ , pi ) ≤
dist and 0 otherwise. If we re-arrange the objective function, we see that with each
Xi - variable associated with point pi ∈ L, there is an associated constant - consti :
X

consti =

ex fcnj ∈EF

exfd(ex fcnj ) · ci,j .

This lets us re-write the objective function as:
P

pi ∈L

P

Xi · consti
.
pi ∈L Xi

Example 6.4.4. Continuing from Example 6.4.3, consti = 0.5 for the following elements: {p33 , p35 , p37 , p42 , p43 , p44 , p47 , p49 , p50 , p52 , p56 }; consti = 1 for these elements:
{p40 , p41 , p45 , p46 , p48 }, and 0 for all others.
279

In many covering problem where we wish to find a cover of minimal cardinality,
we could reduce the number of variables in the integer program by considering
equivalent covers as duplicate variables. However, for OAS, this technique can not
be easily applied. The reason for this is because an optimal adversarial explanation
is not necessarily irredundant (see Definition 58, page 260). Consider the following.
Suppose, we wish to find an optimal adversarial strategy of size k. Let P be a
irredundant cover of size k − 1. Suppose there is some element p′ ∈ P that covers
only one observation - o′ . Hence, there is no p ∈ P − {p′ } that covers o′ by the
definition of an irredundant cover. Suppose there is also some p′′ ∈
/ P that also
covers o′ . Now, let m =

P

pi ∈P −p′

consti . Let the const′ be the value associated

with both p′ and p′′ . Consider the scenario where const′ <

m
.
k−2

Suppose by way

of contradiction, that the optimal irredundant cover is also the optimal adversarial
strategy. Then, by the definition of an optimal adversarial strategy we know that
the set P is more optimal than P ∪{p′′ }. This would mean that

m+const′
k−1

<

m+2·const′
.
k

This leads us to infer that m < const′ ·(k−2), which clearly contradicts const′ <

m
.
k−2

It is clear that a solution to OAS need not be irredundant.
However, we do leverage the idea of an irredundant cover in a different exact
approach in this section which may provide a speedup over the exact algorithms
of the previous section. The main intuition is that each OAS solution contains an
irredundant cover, and if we find such a cover, we can build an optimal adversarial
strategy in polynomial time. First, we define a core explanation.
Definition 72 (Core Explanation). Given an observation set O and set L of possible
280

partners, an explanation Ecore is a core explanation iff:
1. There are no two elements p, p′ ∈ Ecore such that ∀o ∈ O s.t. o, p are partners,
then o, p′ are also partners.
2. For any pi ∈ Ecore , there does not exist pj ∈ L such that:
• ∀o ∈ O s.t. o, pi are partners, then o, pj are also partners.
• constj < consti
We now show that any optimal adversarial strategy contains a subset that is
a core explanation.
Theorem 31. If Egt is an optimal adversarial strategy, there exists a core explanation Ecore ⊆ Egt .
Example 6.4.5. Continuing from Example 6.4.4, consider the set Egt ≡ {p34 , p38 , p57 }
(which would correspond to drug lab locations as planned by the cartel). Later, we
show that this is an optimal adversarial strategy (the expected adversarial detriment
associated with Egt is 0). Consider the subset p34 , p38 . As p34 explains observations
o3 , o4 , o5 and p38 explains observations o1 , o2 , this set is also an explanation. Obviously, it is of minimal cardinality. Hence, the set {p34 , p38 } is a core explanation
of Egt .
Suppose we have an oracle that, for a given k, O, and exfd returns a core
explanation Ecore that is guaranteed to be a subset of the optimal adversarial strategy
associated with k, O, and exfd. The following theorem says we can find the optimal
281

Algorithm 21 BUILD-STRAT
INPUT: Partner list L, core explanation Ecore , natural number k
OUTPUT: Optimal adversarial strategy Egt
1. If |Ecore | = k, return Ecore
2. Set Egt = Ecore . Let k ′ = |Ecore |
3. Sort the set L − Ecore by consti . Let L′ = {p1 , . . . , pk−k′ } be the k − k ′ elements
of this set with the lowest values for cosnti
4. For each pi ∈ L′ let Pi be the set {p1 , . . . , pi }
5. For each Pi let Si =

P
′

j≤i

constj

6. Let ans = minpi ∈L′ ({ k ·EXR

(rf)

(exfd,Ecore )+Si
})
k′ +i

7. Let Pans be the Pi associated with ans
8. If const1 ≥ EXR(rf) (exfd, Ecore ), return Ecore , else return Ecore ∪ Pans
adversarial strategy in polynomial time. The key intuition is that we need not
concern ourselves with covering the observations as Ecore is an explanation. The
algorithm BUILD-STRAT follows from this theorem.
Theorem 32. If there is an oracle that for any given k, O, and exfd returns a core
explanation Ecore that is guaranteed to be a subset of the optimal adversarial strategy
associated with k, O, and exfd, then we can find an optimal adversarial strategy in
O(∆ · |O| · log(∆ · |O|) + (k − |Ecore |)2 ) time.

282

We now introduce the notion of δ-core optimal. Intuitively, this is a core explanation of cardinality exactly δ that is optimal wrt expected adversarial detriment
compared to all other core explanations of that cardinality.
Definition 73. Given exfd, a core explanation, Ecore , is δ-core optimal iff:
• |Ecore | = δ
′
• There does not exist another core explanation, Ecore
of cardinality exactly δ, such
′
that EXR(rew(O,δ) ) (exfd, Ecore
) < EXR(rew(O,δ) ) (exfd, Ecore )

From this, we obtain the following lemma that tells us that an OAS must
contain a core explanation that is δ-core optimal.
Lemma 20. Given an optimal adversarial strategy, Egt , if core explanation Ecore , of
size δ, is a subset of Egt , then Ecore is δ-core optimal.
We now present a set of linear constraints to find a δ-core optimal explanation. Of course we can easily adopt the constraints of the previous section, but this
would offer us no improvement in performance. We therefore create an MILP that
should have a significantly smaller number of variables in most cases. First, given a
set of possible partners L, we define set L∗ - the reduced partner set - which often
will have a cardinality much smaller than L. Later, we use this set in a new set of
constraints to find a δ-core optimal explanation. We define L∗ below.
Definition 74 (Reduced Partner Set). Given observations O, and set of possible

283

partners L, we define reduced partner set L∗∗ as follows:
L∗∗ ≡ {pi ∈ L| 6 ∃pj ∈ L s.t. (constj < consti ) ∧ (∀o ∈ O s.t. o, pi are partners,
o, pj are also partners)}
We define L∗ as follows:
L∗ ≡ {pi ∈ L∗∗ | 6 ∃pj ∈ L∗∗ s.t. (constj = consti ) ∧ (∀o ∈ O s.t. o, pi are partners,
o, pj are also partners)}
Lemma 21.

1. If explanation E is δ-core optimal, then E ⊆ L∗∗ .

2. If for some natural number δ, there exists an explation of size δ, then there
exists a δ-core optimal explanation E s.t. E ⊆ L∗ .
Example 6.4.6. Let us continue from Example 6.4.5. Based on pre-processing and
the computation of consti , we can easily produce the data of Table 6.1 in polynomial
time. Based on this, we obtain a reduced partner set L∗ ≡ {p34 , p38 , p57 }.
We now present the δ-core constraints. Notice that the cardinality requirement
in these constraints is “=” and not “≤”. This is because Lemma 20 ensures us
of a core-explanation that is δ-core optimal, meaning that the core explanation
must have cardinality exactly δ. This also allows us to eliminate variables from the
denominator of the objective function, as the denominator must equal δ as well.
Definition 75 (δ-core MILP). Given parameter δ, and reduced partner set L∗ , we
define the δ-core constraints by first associating a variable Xi with each pi ∈ L∗ .
Then: Minimize:
1 X
Xi · consti
δ p ∈L∗
i

284

Supported Observations

consti = 0

consti = 0.5

o1

p4 − p6 , p12 − p16 , p22 − p23 , p30 − p31

p44

o 1 , o2

p38

p37 , p52

o2

p64 , p67

p47

o 2 , o3

p57

o3

p17 − p19 , p24 − p26 , p32 , p39 , p58 − p59

o 3 , o4

p27 − p28

p33

o4

p1 − p3 , p7 − p11 , p20 − p21 , p29 , p51

p50

o 3 , o4 , o5

p34 , p53 − p54

p49

o5

p36 , p60 − p66

p35

p45 , p46

p40 − p41

p42 − p43

o 4 , o5
o 3 , o5

consti = 1

p55

p56

p48

Table 6.1: The set L partitioned by consti and supported observations.

285

subject to:
1. Xi ∈ {0, 1}
2. Constraint

P

pi ∈L

Xi = δ

3. For each oj ∈ O, add constraint
P

pi ∈L∗ d(oj ,pi )∈[α,β]

Xi ≥ 1

Example 6.4.7. Using set L∗ from Example 6.4.6, we can create δ-core constraints
as follows:
Minimize
1
(X34 · const34 + X38 · const38 + X57 · const57 )
δ
subject to:
1. X34 , X38 , X57 ∈ {0, 1}
2. X34 + X38 + X57 = δ
3. X38 ≥ 1 (for observation o1 )
4. X38 + X57 ≥ 1 (for observation o2 )
5. X34 + X57 ≥ 1 (for observation o3 )
6. X34 ≥ 1 (for observations o4 , o5 )
In the worst case, the set L∗ ≡ L. Hence, we can assert that:
Proposition 60. The δ-core constraints require O(∆ · |O|) variables and 1 + |O|
constraints.
286

Proposition 61. Given δ-core constraints:
1. Given set δ-core optimal explanation Ecore ≡ {p1 , . . . , pn }, if variables
X1 , . . . , Xn - corresponding with elements in Egt are set to 1 - and the rest
of the variables are set to 0, the objective function of the constraints will be
minimized.
2. Given the solution to the constraints, if for every Xi = 1, we add point pi to
set Ecore , then Ecore is a δ-core optimal solution.
We now have all the pieces required to leverage core-explanation and reduced
partner sets to find an optimal adversarial strategy. By Theorem 6.4.5, we know
that any optimal adversarial strategy must have a core explanation. Further, by
Lemma 20, such a core explanation is δ-core optimal. Using a (usually) much
smaller mixed-integer-linear program, we can find such an explanation. We can
then find the optimal adversarial strategy in polynomial time using BUILD STRAT.
Though we do not know what δ is, we know it must be in the range [1, k]. Further,
using a relaxation of the OPT-KSEP-IPC constraints for solving geospatial abduction
problems (as presented in [158], we can easily obtain a lower bound tighter than 1 on
δ. Hence, if we solve k such (most likely, small) mixed-integer-linear programs, we
are guaranteed that at least one of them must be a core explanation for an optimal
adversarial strategy. We note that these k MILP’s can be solved in parallel (and the
following k instances of BUILD-STRAT can also be run in parallel as well). An easy
comparison of the results of the parallel processes would be accomplished at the
end. As L∗ is likely to be significantly smaller than L, this could yield a significant
287

reduction in complexity. Further, various relaxations of this technique can be used
- i.e. only using one value of δ.
Example 6.4.8. Continuing from Example 6.4.7 where the cartel members are attempting to find an OAS to best position drug laboratories, suppose they used the
relaxation of OPT-KSEP-IPC (from [158]) to obtain a lower bound on the cardinality
of an explanation and found it to be 2. With k = 3, they would solve two MILP’s
of the form of Example 6.4.7 - one with δ = 2 and one with δ = 3. The solution to
the first MILP would set X34 and X38 both to 1 while the second MILP would set
X34 , X38 , and X57 all to 1. As the expected adversarial detriment for both solutions
is 0, they are both optimal and running BUILD-STRAT is not necessary. Either
{p34 , p38 } or {p34 , p38 , p57 } can be returned as an OAS.

6.5

Finding a Counter-Adversary Strategy
Now that we have examined ways in which the adversary can create a strategy

based on probabilistic knowledge of the agent, we consider how the agent can devise
an “optimal” strategy to counter the adversary. As before, we use a special case of
expected reward (Definition 6.3.1 from Section 67.
Definition 76 (Expected Agent Benefit). Given a reward function rf, and explanation function distribution exfd, the expected agent benefit is the function
EXB(rf) : 2S × EFD → [0, 1] defined as follows:
EXB(rf) (C, exfd) =

X

ex fcn∈EF

rf(ex fcn(O, k), C) · exfd(ex fcn)
288

Example 6.5.1. Following from Examples 6.2.1 and 6.3.4, suppose drug-enforcement
agents have information that the cartel is placing drug labs according to exfddrug .
(such information could come from multiple runs of the GREEDY-KSEP-OPT2 algorithm of [158]). The drug-enforcement agents wish to consider the set C ≡ {p41 , p52 }.
First, they must calculate the reward associated with each explanation function (note
that k = 3, dist = 100 and rf = crf).
crf(dist) (ex fcn1 (O, 3), {p41 , p52 }) = 0.67
crf(dist) (ex fcn2 (O, 3), {p41 , p52 }) = 0.5
(as an aside, we would like to point out the asymmetry in crf - compare these computations with the results of Example 6.4.1). Hence, EXB(crf) ({p41 , p52 }, exfddrug ) =
0.634.
We now define a maximal counter-adversary strategy. This is the agent’s best
response to the mixed strategy of an adversary.
Definition 77 (Maximal Counter-Adversary Strategy (MCA)). Given a reward
function rf and explanation function distribution exfd, a maximal counter-adversary
strategy, C, is a subset of S such that EXB(rf) (C, exfd) is maximized.
Note that MCA does not include a cardinality constraint. This is because we
do not require reward functions to be monotonic. In the monotonic case, we can
trivially return all feasible points in S and be assured of a solution that maximizes
the expected agent benefit. Therefore, for the monotonic case, we include an extra
parameter B ∈ {1, . . . , |S|} (for “budget”) which will serve as a cardinality requirement for C. This cardinality requirement for C is necessarily the same as for Egt
289

as the agent and adversary may have different sets of resources. Also, we do not
require that C be an explanation. We discuss the special case where the solution to
the MCA problem is required to be an explanation in the appendix.

6.5.1

The Complexity of Finding a Maximal Counter-Adversary
Strategy

We now formally define the problem of finding a maximal counter-adversary
strategy.

MCA Problem
INPUT: Space S, feasibility predicate, feas, real numbers α, β, set of observations,
O, natural numbers k, B, reward function rf, and explanation function distribution
exfd.
OUTPUT: The maximal counter-adversary strategy, C.

MCA is NP-hard via a reduction of the GCD problem.
Theorem 33. MCA is NP-hard.
The proof of the above result shows that MCA is NP-hard even if the reward
function is monotonic. Later, in Section 6.5.3, we also show that MCA can encode
the NP-hard MAX-K-COVER problem [46] as well (which provides an alternate
proof for NP-hardness of MCA). We now present the decision problem associated
with MCA and show that it is NP-complete under reasonable conditions.
290

MCA-DEC
INPUT: Space S, feasibility predicate, feas, real numbers α, β, set of observations,
O, natural numbers k, B, reward function rf, explanation function distribution exfd,
and number R ∈ [0, 1].
OUTPUT: The counter-adversary strategy, C such that EXB(rf) (C, exfd) ≥ R.

Theorem 34. MCA-DEC is NP-complete, provided the reward function can be
evaluated in PTIME.
Not only is MCA-DEC NP-hard, under the same assumptions as above,
the counting version of the problem is #P-complete and moreover, it has no fully
polynomial random approximation scheme.
Theorem 35. Counting the number of strategies that provide a “yes” answer to
MCA-DEC is #P-complete and has no FPRAS unless NP==RP.
Theorem 35 tells us that MCA may not have a unique solution. Therefore,
setting up a mixed-strategy of all MCA’s to determine the “best response” to the
MCA of an agent by an adversary would be an intractable problem. This mirrors
our result of the previous section (Theorem 30, page 273).

291

6.5.2

MCA in the General Case: Exact and Approximate
Algorithms

We now describe exact and approximate algorithms for finding a maximal
counter-adversary strategy in the general case. Note that throughout this section
(as well as in Section 6.5.3), we assume that the same pre-processing for OAS is
used (cf. Section 6.4.2). We will use the symbol L to refer to the set of all possible
partners.

An Exact Algorithm For MCA. A naive, exact, and straightforward approach
to the MCA problem would simply consider all subsets of L and pick the one which
maximizes the expected agent benefit. Obviously, this approach has a complexity
O(

P|S|

i=0

|L|
i



) and is not practical. This is unsurprising as we showed this to be an

NP-complete problem.
Approximation in the General Case. Despite the impractical time complexity
associated with an exact approach, it is possible to approximate MCA with guarantees – even in the general case. This is due to the fact that when exfd is fixed, the
expected agent benefit is submodular.
Theorem 36. For a fixed O, kexfd, the expected agent benefit, EXB(rf) (C, exfd) has
the following properties:
1. EXB(rf) (C, exfd) ∈ [0, 1]

292

2. For C ⊆ C ′ and some point p ∈ S where p ∈
/ C ′ , the following is true:
EXB(rf) (C∪{p}, exfd)−EXB(rf) (C, exfd) ≥ EXB(rf) (C ′ ∪{p}, exfd)−EXB(rf) (C ′ , exfd)
(i.e. expected agent benefit is sub-modular for MCA)
It follows immediately that MCA reduces to the maximization of a submodular
function. We now present the MCA-LS algorithm that leverages this submodularity.
The following two propositions leverage Theorem 36 and Theorem 3.4 of [47].
Proposition 62. MCA-LS has time complexity of O( 1ǫ · |L|3 · F (exfd) · lg(|L|) where
F (exfd) is the time complexity to compute EXB(rf) (C, exfd) for some set C ⊆ L.
Proposition 63. MCA-LS is an ( 13 −

ǫ
)-approximation
|L|

algorithm for MCA.

Example 6.5.2. Let us consider our running example where drug-enforcement
agents are attempting to locate illegal drug laboratories in the area depicted in Figure 6.1. The agents have information that there are k or less drug laboratories that
support the poppy fields (set of observations O) and that they are positioned according to exfddrug (see Example 6.3.4, page 268). The agents wish to find a maximal
counter-adversarial strategy using the prf reward function (see page 60). They decide to use MCA-LS to find such a strategy with ǫ = 0.1. Initially (at line 3), the
algorithm selects point p48 (renumbering as p1 , note that in this example we shall use
pi and inci numbering based on Example 6.2.1 rather than what the algorithm uses).
Hence, inc40 = 0.208 and cur val = 0.708. As the elements are sorted, the next point
to be considered in the loop at line 4 is p40 which has an incremental increase of 0, so
it is not picked. It then proceeds to point p41 - which gives an incremental increase
293

Algorithm 22 (MCA-LS)
INPUT: Reward function rf, set O of observations, explanation function distribution exfd, possible partner set L,
real number ǫ > 0
OUTPUT: Set C ⊂ S
1. Set C ∗ = L, for each pi ∈ C ∗ let inci = EXB(rf) ({p}, exfd) − EXB(rf) (∅, exfd).
2. Sort the pi ’s in C ∗ from greatest to least by inci (i.e. p1 is the element with the greatest inci ).
3. C = {p1 }, C ∗ = C ∗ − {p1 }, cur val = inc1 + EXB(rf) (∅, exfd), f lag1 = true, i = 2
4. While f lag1

(a) new val = cur val + inci
(b) If new val > (1 +

ǫ
)
|L|2

· cur val then

i. If EXB(rf) (C ∪ {pi }, exfd) > (1 +

ǫ
)
|L|2

· EXB(rf) (C, exfd) then:

C = C ∪ {pi }, C ∗ = C ∗ − {pi }, cur val = EXB(rf) (C ∪ {pi }, exfd)
(c) If new val ≤ (1 +

ǫ
)
|L|2

· cur val or if pi is the last element then

i. j = 1, f lag2 = true, number each pj ∈ C
ii. While f lag2
A. If EXB(rf) (C − {pj }, exfd) > (1 +

ǫ
)
|L|2

· EXB(rf) (C, exfd) then:

C = C − {pj }, cur val = EXB(rf) (C − {pj }, exfd)
For each pi ∈ C ∗ let inci = EXB(rf) (C ∪ {pi }, exfd) − EXB(rf) (C, exfd).
Sort the pi ’s in C ∗ from greatest to least by inci
i = 0, f lag2 = false
B. Else,
If pj was the last element of C then set f lag1, f lag2 = false
Otherwise, j + +
(d) i + +
5. If EXB(rf) (L − C, exfd) > EXB(rf) (C, exfd) then set C = L − C
6. Return C

294

of 0.084 and is added to C so cur val = 0.792. Point p45 is considered next, which
gives an incremental increase of 0.208 and is picked, so now cur val = 1.0. The
algorithm then considers point p46 , which does not afford any incremental increase.
After considering points p33 , p35 , p37 , p42 , p43 , p44 , p47 , p49 , p50 , p52 , p56 - and finds the
all give a negative incremental increase (and thus, are not picked), the algorithm
finds that the old incremental increase of the next element, p1 , would cause the “if ”
statement at line 4c to be true, thus proceeding to the inner loop inside that “if ”
statement (line 4(c)iiA). This loop considers if the removal of any picked elements
- p48 , p41 , p45 causes the expected agent benefit to increase. However, in this example,
if any of the elements are removed, the expected agent benefit decreases. Hence, the
boolean f lag1 is set to false and the algorithm exits the outer loop. The algorithm
then returns the set C ≡ {p48 , p41 , p45 } which is optimal.

6.5.3

Finding a Maximal Counter-Adversary Strategy, the
Monotonic Case

In the previous section we showed that a

1
3

approximate solution to MCA

can be found in polynomial time even without any monotonicity restriction. In this
section, we show that under the additional assumptions of monotonicity of reward
functions, we can obtain a better 63% approximation ratio with a faster algorithm.
Here, we also have the additional cardinality requirement of B for the set C (as
described in Section 6.5). We first show that expected agent benefit is monotonic
when the reward function is.

295

Corollary 12. For a fixed O, kexfd, if the reward function is monotonic, then the
expected agent benefit, EXB(rf) (C, exfd) is also monotonic.
Thus, when we have a monotonic reward function, the MCA problem reduces
to the maximization of a monotonic, normalized4 submodular function w.r.t. a
uniform matroid5 – this is a direct consequence of Theorem 36 and Corollary 12.
Therefore, we can leverage the result of [127], to develop the MCA-GREEDY-MONO
algorithm below. We improve performance by including “lazy evaluation” using the
intuition is that the incremental increase caused by some point p at iteration i of
the algorithm is greater than or equal to the increase caused by that point at a
later iteration. As with MCA-LS, we also sort elements by the incremental increase,
which may allow the algorithm to exit the inner-loop earlier. In most non-trivial
instances of MCA, this additional sorting operation will not affect the complexity
of the algorithm (i.e. under the assumption that the time to compute EXB(rf) is
greater than lg(|L|), we make this same assumption in MCA-LS as well).
Proposition 64. The complexity of MCA-GREEDY-MONO is O(B · |L| · F (exfd))
where F (exfd) is the time complexity to compute EXB(rf) (C, exfd) for some set C ⊆ L
of size B. In the first iteration of the algorithm,
e
Corollary 13. MCA-GREEDY-MONO is an ( e−1
)-approximation algorithm for MCA

(when the reward function is monotonic).
e
In addition to the fact that MCA-GREEDY-MONO is an ( e−1
)-approximation
4

As we include zero-starting in our definition of monotonic.

5

In our case, the uniform matroid consists of all subsets of L of size B or less.

296

Algorithm 23 (MCA-GREEDY-MONO)
INPUT: Monotonic reward function rf, set O of observations, real number B > 0,
explanation function distribution exfd, possible partner set L, real number ǫ > 0
OUTPUT: Set C ⊂ S
1. Initialize C = ∅ and C ∗ = L
2. For each pi ∈ C ∗ , set inci = 0
3. Set last val = EXB(rf) (C, exfd)
4. While |C| ≤ B
(a) pbest = null, cur inc = 0
(b) For each pi ∈ C ∗ , do the following
i. If inci < cur inc, break loop and goto line 4c.
ii. Let inci = EXB(rf) (C ∪ {p}, exfd) − last val
iii. If inci ≥ cur inc then cur inc = inci and pbest = p
(c) C = C ∪ {pbest }, C ∗ = C ∗ − {pbest }
(d) Sort C ∗ in descending order by inci .
(e) Set last val = EXB(rf) (C, exfd)
5. Return C

297

algorithm for MCA, it also provides the best possible approximation ratio unless
P = N P . This is done by a reduction of MAX-K-COVER [46].
Theorem 37. MCA-GREEDY-MONO provides the best approximation ratio for MCA
(when the reward function is monotonic) unless P = N P .
The following example illustrates how MCA-GREEDY-MONO works.
Example 6.5.3. Consider the situation from Example 6.5.2, where the drug-enforcement
agents are attempting to locate illegal drug labs. Suppose they want to locate the labs,
but use the crf reward function, which is monotonic and zero-starting. They use
the cardinality requirement B = 3 in MCA-GREEDY-MONO. After the first iteration
of the loop at line 4, the algorithm selects point p48 as it affords an incremental
increase of 0.417. On the second iteration, it selects point p46 , as it also affords
an incremental increase of 0.417, so last val = 0.834. Once p46 is considered, the
next point considered is p33 , which had a previous incremental increase (calculated
in the first iteration) of 0.25, so the algorithm can correctly exit the loop to select
the final element. On the last iteration of the outer loop, the algorithm selects point
p35 , which gives an incremental increase of 0.166. Now the algorithm has a set of
cardinality 3, so it exits the outer loop and returns the set C = {p48 , p46 , p35 }, which
provides an expected agent benefit of 1, which is optimal. Note that this would not be
an optimal solution for the scenario in Example 6.5.2 which uses prf as p35 would
incur a penalty (which it does not when using crf as in this example).

298

6.6

Implementation and Experiments
In this section, we describe prototype implementations and experiments for

solving the OAS and MCA problems. For OAS, we create a MILP for the crf case
and reduce the number of variables with the techniques we presented in Section 6.4.
For MCA, we implement both the MCA-LS and MCA-GREEDY-MONO.
We carried out all experiments for MCA on an Intel Core2 Q6600 processor
running at 2.4GHz with 8GB of memory available, using code written in Java 1.6; all
runs were performed in Windows 7 Ultimate 64-bit using a 64-bit JVM, and made
use of a single core. We also used functionality from the previously-implemented
SCARE software from Chapter 4 to calculate, for example, the set of all possible
partners L.
Our experiments are based on 21 months of real-world Improvised Explosive
Device (IED) attacks in Baghdad6 , see Chapter 4. The IED attacks in this 25 × 27
km region constitute our observations. The data also includes locations of caches
associated with those attacks discovered by US forces. These constitute partner
locations. We used data from the International Medical Corps to define feasibility
predicates based on ethnic makeup, location of US bases, and geographic features.
We overlaid a grid of 100m × 100m cells—about the size of a standard US city
block. We split the data into two parts; the first 7 months of data were used as a
“training” set to learn the [α, β] parameters and the next 14 months of data were
used for the observations. We created an explanation function distribution based
6

Attack and cache location data provided by the Institute for the Study of War.

299

on multiple runs of GREEDY-KSEP-OPT2 algorithm described in Chapter 4.
We also made use of classes and methods from our previously-implemented
SCARE software from Chapter 4 to provide features such as pre-processing (see the
discussion in Section 6.4.2, page 273). We carried out all experiments for OAS on
an Intel Core2 Q6600 processor running at 2.4GHz with 8GB of memory available,
using Java 1.6; all runs were performed in Windows 7 Ultimate 64-bit using a 64-bit
JVM, and made use of a single core.

6.6.1

OAS Implementation

We now present experimental results for the version of OAS, with the crf
reward function, based on the constraints in Definition 70 and variable-reduction
techniques of Section 6.4.4. First, we discuss promising real-world results for the
calculation of the reduced partner set L∗ , described in Definition 72. Then, we
show that an optimal adversarial strategy can be computed quite tractably using
the methods discussed in Section 6.4.4. Our implementation was written on top of
the QSopt7 MILP solver and used 900 lines of Java code.
Reduced Partner Set. As discussed in Section 6.4.2, producing an optimal adversarial strategy for any reward function relies heavily on efficiently solving a (provably
worst-case intractable) integer linear program. The number of integer variables in
these programs is based solely on the size of the partner set L; as such, the ability
to experimentally solve OAS relies heavily on the size of this set.
7

http://www2.isye.gatech.edu/ wcook/qsopt/index.html

300

Our real-world data created a partner set L with cardinality 22,692. We then
applied the method from Definition 72 to reduce this original set L to a smaller
subset of possible partners L∗ , while retaining the optimality of the final solution.
This simple procedure, while dependent on the explanation function distribution
exfd as well as the cutoff distance for crf, always returned a reduced partner set L∗
with cardinality between 64 and 81. This represents around a 99.6% decrease in the
number of variables required in the subsequent integer linear programs!
Figure 6.4 provides more detailed accuracy and timing results for this reduction. Most importantly, regardless of parameters chosen, our real-world data is
reduced by orders of magnitude across the board. We see a slight increase in the
size of the reduced set L∗ as the size of the explanation function distribution exfd
increases. This can be traced back to the strict inequality in Definition 74. As
we increase the number of nontrivial explanation functions in exfd, the number of
nonzero constants consti increases. This results in a higher number of candidates
for the intermediary set L∗∗ . We see a similar result as we increase the penalizing
cutoff distance. Again, this is a factor of the strict inequality in Definition 74 in
conjunction with a higher fraction of nonzero consti constants.
Interestingly, Figure 6.4 shows a slight decrease in the runtime of the reduction
as we increase the penalizing cutoff distance. Initially, this seems counterintuitive;
with more nontrivial constants consti , the construction of the intermediary set L∗∗
requires more work. However, this extra work pays off during the computation of
the final reduced set L∗ . In our experiments, the reduction from L to L∗∗ took less
time than the final reduction from L∗∗ to L∗ . This is due to frequent short circuiting
301

OAS Partner Set Reduction: Size vs. Distance
|efd| = {10,15,20,...,200}
90
80
70
10

60
|L*|

15
50
20
40
25

30

50

20

100

10

200

0
100

200

300

400

500

Cutoff Distance

OAS Partner Set Reduction: Time vs. Distance
|efd| = {10,15,20,...,200}
180
160
Computation Time (s)

140
10

120

15
100
20
80

25
60

50

40

100

20

200

0
100

200

300

400

500

Cutoff Distance

Figure 6.4: The size of the reduced partner set L∗ (left) and the time required to
compute this reduction (right). Regardless of parameters chosen, we see a 99.6%
decrease in possible partners—as well as integer variables in our linear program—in
under 3 minutes.
in the computation of the right-hand side of the conjunction during L∗∗ creation. As
we increase the penalizing cutoff distance, the size of L∗∗ actually decreases, resulted
in a decrease in the longer computation of L∗ . As seen above, this decrease in L∗∗
did not correspond to a decrease in the size of L∗ .

302

Optimal Adversarial Strategy. Using the set L∗ , we now present results to find
an optimal adversarial strategy using δ-core optimal explanations. This is done
by minimizing the MILP of Section 6.4.4, then feeding this solution into BUILDSTRAT. Since we do not know the value of δ in advance, we must perform this
combined operation multiple times, choosing the best—lowest expected detriment—
adversarial strategy as optimal.
A note on the lower bound for δ: as shown by Chapter 4, finding a minimumcardinality explanation is NP-hard. Because of this, it is computationally difficult to
find a tight lower bound for δ. However, this lower bound can be estimated empirically. For instance, for our set of real-world data from Baghdad, an explanation of
cardinality below 14 has never been returned—even across tens of thousands of runs
of GREEDY-KSEP-OPT2. Building on this strong empirical evidence, the minimum
δ used in our experiments is 14.
Figure 6.5 shows both timing and expected detriment results as the size of the
explanation function |exfd| and maximum strategy cardinality k are varied. Note
that a lower expected detriment is better for the adversary, with zero representing no
probability of partner discovery by the reasoning agent. As the adversary is allowed
larger and larger strategies, its expected detriment smoothly decreases toward zero.
Intuitively, as the number of nontrivially-weighted explanation functions in exfd
increases, the expected detriment increases as well. This is a side effect of a larger
|exfd| allowing the reasoning agent to cover a larger swath of partner locations.
Recall that, as the maximum k increases, we must solve linear programs for
303

OAS: Expected Detriment vs. Size k
|efd| = {10,20,50,100,200}
0.025

Expected Detriment

0.02

10

0.015

20
50

0.01

100
200

0.005

0
14

20

26

32

38

44

50

Maximum Size k

OAS: Time vs. Size k
|efd| = {10,20,50,100,200}
700

Computation Time (ms)

600
500
10

400

20
300

50

200

100
200

100
0
14

20

26

32

38

44

50

Maximum Size k

Figure 6.5: Expected detriment of the optimal adversarial strategy (left, lower is
better) and the runtime of the integer linear program required to produce this
strategy in milliseconds (right). Note the smooth decrease toward zero detriment as
k increases, corresponding with a near-linear increase in total runtime.
each δ ∈ {klow , k}. This is mirrored in the timing results in Figure 6.5, which assumes
klow = 14. As k increases, we see a near linear increase in the total runtime of the set
of integer programs. Due to the reduced set L∗ , we are able to solve dozens of integer
programs in less than 800ms; were we to use the unreduced partner set L, this would

304

be intractable. Note that the runtime graph includes that of BUILD-STRAT which
always ran in under sixteen milliseconds.

6.6.2

MCA Implementation

First, we briefly discuss an implementation of the naive MCA algorithm discussed in section 6.5.2. Next, we provide promising results for the MCA-LS algorithm
using the prf reward function. Finally, we give results for the MCA-GREEDY-MONO
using the monotonic crf reward function, and qualitatively compare and constrast
the results from both algorithms.
MCA-Naive. The naive, exact solution to MCA—considering all subsets of L
with cardinality kC or more and picking the one which maximizes the expected
agent benefit—is inherently intractable. This approach has a complexity O(

|L|
kC



),

and is made worse by the large magnitude of the set L. In our experimental setup,
we typically saw |L| > 20, 000; as such, for even the trivially small kC = 3, we
must enumerate and rank over a trillion subsets. For any realistic value of kC , this
approach is simply unusable. Luckily, we will see that both MCA-LS and MCAGREEDY-MONO provide highly tractable and accurate alternatives.

MCA-LS. In sharp contrast to the naive algorithm described above, the MCA-LS
algorithm provides (lower-)bounded approximate results in a tractable manner. Interestingly, even though MCA-LS is an approximation algorithm, in our experiments
on real-world data from Baghdad using the prf reward function, the algorithm re-

305

turned strategies with an expected benefit of 1.0 on every run. Put simply, on
our practical test data, MCA-LS always completely maximized the expected benefit. This significantly outperforms the lower-bound approximation ratio of 1/3.
We would also like to point out that this is the first implementation (to the best
of our knowledge) of the non-monotonic submodular maximization approximation
algorithm of [47].
Since the expected benefit was maximal for every strategy C returned, we
move to analyzing the particular structure of these strategies. Figure 6.6 shows a
relationship between the size |C|, the cutoff distance dist, and the cardinality of the
expectation function distribution |exfd|. Recall that prf penalizes any strategy that
does not completely cover its input set of observations; as such, intuitively, we see
that MCA-LS returns larger strategies as the penalizing cutoff distance decreases. If
the algorithm can cover all possible partners across all expectation functions, it will
not receive any penalty. Still, even when dist is 100m, the algorithm returns C only
roughly twice the size as minimum-sized explanation found by GREEDY-KSEP-OPT2
(which, based on the analysis of Chapter 4, is very close to the minimum possible
explanation). As the cutoff dist increases, the algorithm returns strategies with
sizes converging, generally, to a baseline—the smallest-sized explanation found by
the algorithm of Chapter 4, |E|. This is an intuitive soft lower bound; given enough
leeway from a large distance dist, a single point will cover all expected partners.
This is not a strict lower bound in that, given two extremely close observations with
similar expected partners, a single point may sufficiently cover both.
In Figure 6.7, we see results comparing overall computation time to both the
306

MCA-LS: Strategy Size vs. Distance
min|e| = 14, |efd| = {5,10,...,40}
35
30

Strategy Size

5

25

10

20

15

20
15
25

10

30
35

5

40
0

|e|
100

150

200

250

300

350

400

450

500

Distance (Penalty Cutoff)

MCA-LS: Average Strategy Size vs. Distance
min|e| = 14, |efd| averaged across {5,10,...,40}
30
25

Strategy Size

20
15
10
5
0
100

150

200

250

300

350

400

450

500

Distance (Penalty Cutoff)

Figure 6.6: The average size of the strategy recommended by MCA-LS decreases as
the distance cutoff increases. For these experiments, the minimum cardinality for a
given explanation E considered is exfd was 14, which gives us a natural lower bound
on the expected size of a strategy. Note the convergence to this bound at cutoff
distances at and above 300 meters.
distance dist and the cardinality of exfd. For more strict (i.e., smaller) values of
dist, the algorithm—which, under prf, is penalized for all uncovered observations
across exfd—must spend more time forming a strategy C that minimizes penaliza307

MCA-LS: Time vs. Distance
min|e| = 14, |efd| = {5,10,...,40}
140000
120000
5

100000
Time (ms)

10
80000
15
20

60000

25
40000
30
20000

35
40

0
100

150

200

250

300

350

400

450

500

Distance (Penalty Cutoff)

MCA-LS: Average Time vs. Distance
min|e|= 14, |efd| averaged across {5,10,...,40}
45000
40000

Average Time (ms)

35000
30000
25000
20000
15000
10000
5000
0
100

150

200

250

300

350

400

450

500

Distance (Penalty Cutoff)

Figure 6.7: The runtime of MCA-LS decreases as the penalizing cutoff distance is
relaxed. Note the relation to Figure 6.6; intuitively, larger recommended strategies
tend to take longer to compute.
tion. Similarly, as the distance constraint is loosened, the algorithm completes more
quickly. Finally, an increase in |exfd| results in higher computational cost; as explained in Proposition 62, this is due to an increase in F (exfd), the time complexity
of computing EXB(rf) (C, exfd). Comparing these results to Figure 6.6, we see that
the runtime of MCA-LS is correlated to the size of the returned strategy C.
308

MCA-Greedy-Mono: EXB vs. Budget
|efd| = 10, Distances = {50, 100, ..., 500}
0.8
0.7

Expected Benefit

50
0.6

100

0.5

150
200

0.4

250
0.3
300
0.2

350

0.1

400
450

0
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28

500

Budget

MCA-Greedy-Mono: EXB vs. Budget
|efd| = 100, Distances = {50, 100, ..., 500}
0.6
50

0.5
Expected Benefit

100
0.4

150
200

0.3

250
0.2

300
350

0.1
400
450

0
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28

500

Budget

Figure 6.8: Expected benefit of the strategy returned by MCA-GREEDY-MONO
as the budget increases, with |exfd| = 10 (left) and |exfd| = 100 (right). Note the
decrease in expected benefit due to the increase in |exfd|. Similarly, note the increase
in expected benefit given a larger cutoff distance.

MCA-GREEDY-MONO. As discussed in Section 6.5.3, MCA-GREEDY-MONO
provides tighter approximation bounds than MCA-LS at the cost of a more restrictive
(monotonic) reward function. For these experiments, we used the monotonic rf =
309

crf. Recall that a trivial solution to MCA given a monotonic reward function is
C = L; as such, MCA-GREEDY-MONO uses a budget B to limit the maximum size
|C| ≪ |L|. We varied this parameter B ∈ {1, . . . , 28}.
Figure 6.8 shows the expected benefit EXB(rf) (C, exfd) increase as the maximum
allowed |C| increases. In general, the expected benefit of C increases as the distance
constraint dist is relaxed. However, note the points with B ∈ {3, . . . , 9}; we see
that dist ≤ 100 performs better than dist > 100. We believe this is an artifact of
our real-world data. Finally, as |exfd| increases, the expected benefit of C converges
more slowly to 1.0. This is intuitive, as a wider spread of possible partner positions
will, in general, require a larger |C| to provide coverage.
Figure 6.9 shows that the runtime of MCA-GREEDY-MONO increases as predicted by Proposition 62. In detail, as we linearly increase budget B, we also linearly
increase the runtime of our F (exfd) = EXB(rf) (C, exfd). In turn, the overall runtime
O(B · |L| · F (exfd)) increases quadratically in B, for our specific reward function.
Finally, note the increase in runtime as we increase |exfd| = 10 to |exfd| = 100. Theoretically, this increases F (exfd) linearly; in fact, we see almost exactly a ten-fold
increase in runtime given a ten-fold increase in |exfd|.

310

MCA-Greedy-Mono: Time vs. Budget
|efd| = 10, Distances = {50, 100, ..., 500}
10000
9000
50
8000
100

Time (ms)

7000

150

6000

200

5000

250

4000

300

3000

350

2000

400

1000

450

0
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28

500

Budget

MCA-Greedy-Mono: Time vs. Budget
|efd| = 100, Distances = {50, 100, ..., 500}
80000
70000

Time (ms)

50
60000

100

50000

150

200

40000

250
30000
300
20000

350

10000

400
450

0

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28

500

Budget

Figure 6.9: Runtime of MCA-GREEDY-MONO as the budget increases, with |exfd| =
10 (left) and |exfd| = 100 (right). Note the increase in runtime due to the extra
determinism of a larger exfd.

6.7

Chapter 6 Related Work
A similar motivation to this chapter exists in the field of (multi-)agent security,

where the central idea is to protect a set of targets from adversaries. These games
are typically modeled on top of graphs, with agents and adversaries competing
to protect or penetrate a set of targets. [135] represents the adversary’s behavior
311

through a probability distribution over states, indicating the probability of that
state being targeted; no real graph structure is considered, much less a geospatial
model. [1] and [2] consider an environment with more hidden information, and
attempt to detect adversarial penetrations across the routes (represented as paths
on a graph) of patrolling agents. [139] solves Stackelberg (leader-follower) games
under the assumption of bounded reasoning rationality, again on a graph network.
[35] explores protecting dynamic targets from rational adversaries on real-world road
networks.

6.8

Chapter Summary
Geospatial abduction was introduced in Chapter 4 and used to infer a set of

partner locations from a set of observations, given a feasibility predicate and an
interval [α, β] ⊆ [0, 1]. Chapter 4 developed exact and approximate algorithms for
GAPs. In particular, no adversary was assumed to exist there. In this chapter, we
study the case of geospatial abduction where there is an explicit adversary who is
interested in ensuring that the agent does not detect the partner locations. This
is the case with real world serial killers and insurgents who launch IED attacks.We
develop a game-theoretic framework for reasoning about the best strategy that an
adversary might adopt (based on the minimizing the adversary’s detriment) and the
best strategy that the agent could adopt to counter the adversary’s strategy.
We consider the adversarial geospatial abduction problem to be a two player
game—an agent (“good” guy) and an adversary (“bad” guy). The adversary is

312

attempting to cause certain observable events to occur (e.g. murders or IED attacks)
but make it hard to detect the associated set of partner locations (e.g. location of
the serial killers home/office, or the locations of weapons caches supporting the
IED attacks). We use an axiomatically-defined “reward function” to determine how
similar two explanations are to each other. We study the problems of finding the
best response for an agent and adversary to a mixed strategy (based on a probability
distribution over explanations) of the opponent. We formalize these problems as
the “optimal adversarial strategy” (OAS) and maximal counter-adversary strategy
(MCA) problem. We show both OAS and MCA to be NP-hard and provide exact
and approximate methods for solving them. When reasoning about the best possible
strategy for the adversary, we present a mixed integer programming based algorithm
and show that the MILP in question can be greatly reduced through the elimination
of many variables using the concept of a δ-core explanation. Our experiments are
carried out on real world data about IED attacks over a period of 21 months in
Baghdad.
When reasoning about the best possible strategy for the adversary, we present
two algorithms. The MCA-LS algorithm is very general and leverages submodularity of reward functions. The MCA-GREEDY-MONO algorithm assumes the reward function is monotonic. Both MCA-LS and MCA-GREEDY-MONO are highly
accurate and have very reasonable time frames. Though MCA-GREEDY-MONO is
slightly faster than MCA-LS, we found that on every single run, MCA-LS found the
exact optimal benefit even though its theoretical lower bound approximation ratio
is only 1/3—a truly remarkable performance. As MCA-LS does not require any
313

additional assumptions and as its running time is only slightly slower than that of
MCA-GREEDY-MONO, we believe this algorithms has a slight advantage.

314

Chapter 7
Geospatial Optimization

The next two chapters deal with optimal selection of agent actions. Here the
agent has the as set of actions that modify attributes of a geospatial region and
he wishes to select a limited number of such actions (with respect to some budget)
in a manner that either achieves some goal (goal-based geospatial optimization)
and/or maximizes a benefit function (benefit-maximizing geospatial optimization).
Additionally, there are certain combinations of actions that cannot be performed
together. In this chapter, we study the complexity of geospatial optimization problems and present algorithm for solving such problems - either exactly or within a
certain factor of optimal.1

7.1

Chapter Introduction
There are numerous applications which require the ability to take certain ac-

tions (e.g. distribute money, medicines, people etc.) over a geographic region. For
1

This chapter is based research that was completed in cooperation with V.S. Subrahmanian.

315

14
12

Group 1 (grp1)
Group 2 (grp2)

1 Influential center for group 1 (hq1)
2 Influential center for group 2 (hq2)

8

10

High-cost area (hi_cost)
Non-populated area (non_pop)

4

6

2

0

2

1

0

2

4

6

8

10

12

14

16

Figure 7.1: Locations in a district - contingency groups and unpopulated areas.
instance, a disaster relief organization must allocate people and supplies in a region
after a disaster. A public health organization needs to allocate limited vaccine stocks
to people across the region. A government needs to allocate funds for education or
unemployment training across a region.
Figure 7.1 shows a 2-dimensional map of a region. A political candidate can
only make so many campaign stops and public appeals. We assume that a map M
is discrete (this is a common assumption in most GIS systems) and has coordinates
drawn from [0, . . . , M ] × [0, . . . N ] where the bottom left corner of the map is the
point (0, 0). The candidate wants to identify the best places to campaign or make
public appeals to maximize his exposure. Additionally, the map shows un-populated
areas, areas where campaigning costs are high, and areas dominated by one of two

316

constituent groups. All of these factors may affect the set of locations the candidate
selects to optimize his exposure.
In this chapter, we introduce geographic optimization problems or GOPs that
capture and solve problems such as those mentioned above. The organization and
contribution of the chapter is as follows. Section 7.2 formally defines GOPs - specifically we introduce goal-based and benefit-maximizing GOPs (GBGOP and BMGOP
respectively). Section 7.3 shows that both GBGOP and BMGOP are NP-hard (with
the associated decision problems in the complexity class NP). Additionally, we prove
non-trivial theoretical limits on approximation: if GBGOP were to be approximated
within the logarithm of the input then NP would have a slightly super-polynomial
oracle. BMGOP cannot be approximated within a guaranteed factor greater than
0.63 unless P=NP. Section 7.4 presents integer programs to solve both GBGOP and
BMGOP using an IP solver like CPLEX. In Section 7.5, we show how to correctly
reduce the number of variables in the integer constraints for GBGOP. We then develop the BMGOP-Compute algorithm in Section 7.6 that can quickly approximate
a BMGOP in polynomial time and provides an approximation guarantee.

7.2

GOPs Formalized
Throughout this chapter, we assume that M = [0, . . . , M ] × [0, . . . , N ] is an

arbitrary, but fixed “map”. We define a logical language L whose constant symbols
are members of M and that has an infinite set Lvar of variable symbols disjoint from
M. L has a set G = {g1 , . . . , gn } of unary predicate symbols. As usual, a term is
317

either a constant symbol or variable symbol. If t is a term, then gi (t) is an atom. If
t is a constant, then gi (t) is ground. Intuitively, if p ∈ M, then gi (p) says that point
p has property gi . We use BL to denote the set of all ground atoms. Well-formed
formulas (wffs) are defined in the usual way. (i) Every atom is a wff. (ii) If F, G are
wffs, then so are F ∧ G, F ∨ G, ¬F are all wffs.
Example 7.2.1. Consider the map Mcpgn in Figure 7.1 with the predicates of G
including the following:
{hi cost, non pop, grp1 , grp2 , hq1 , hq2 }
The predicate exposure not depicted in the figure corresponds to a candidate receiving exposure in a certain area. hi cost((1, 9)), hq1 ((4, 3)), non pop((8, 1)), and
grp2 ((5, 8)) are all examples of ground atoms.
A state is any subset of BL . We use S to denote the set of all states. Satisfaction of formulas is defined in the obvious way. State s satisfies a ground atom A,
denoted s |= A, iff A ∈ s. s |= F ∨ G iff s |= F or s |= G. s |= F ∧ G iff s |= F
and s |= G. s |= ¬F iff s does not satisfy F .
Example 7.2.2. The shading shown in Figure 7.1 defines a state. For example,
hi cost((1, 9)) ∈ scpgn while exposure((1, 9)) ∈
/ scpgn .
An action maps points to sets of ground atoms.
Definition 78 (Action). An action is a mapping a : M → 2BL . We use A to
denote the set of actions. An action-point pair is any member of A × M.
318

An action-point pair (a, p) is executed if action a takes place at point p. Thus,
one can think of (a, p) as saying that action a occurs at point p. The result of
executing a set SOL of action-point pairs in state s0 is denoted appl(SOL, s0 ) and
is the set (s0 ∪ {a(p) | (a, p) ∈ SOL}).
Example 7.2.3. Continuing with example 7.2.2, our candidate has actions Acpgn =
{nor, appeal1 , appeal2 } where nor refers to a normal campaign stop and appeal1 , appeal2
refer to public appeals to constituent groups 1 and 2 respectively. The actions map
to ground atoms as follows.
nor(p) = {exposure(p′ )| ¬non pop(p′ ) ∧ d(p, p′ ) ≤ 1}
appeali (p) = {exposure(p′ )| hqi (p) ∧ grpi (p′ )}

The first action says that when a normal campign stop is made at point p and
p′ is a populated place one distance unit or less from p, then the candidate has
exposure at place p′ as well. The second action says that if the candidate makes an
appeal (action) at point p and p is the headquarters of interest group grpi , then the
candidate has obtained exposure in all places associated with interest group grpi .
Definition 79 (Cost Function). A cost function, C : A × M → [0, 1].
Throughout this chapter, we assume the cost function is arbitrary but fixed and
can be computed in constant time. We also assume that if A×M = {(a1 , p1 ), . . . , (am , pm )},
then ci is used to denote C(ai , pi ).
(s)
and is defined (based
Example 7.2.4. The cost function for our example is Ccpgn

on some state s) as follows: C(s)
cpgn (a, p) = 1 if hi cost(p) ∈ s and 0.5 otherwise.
319

We also assume the existence of a set of integrity constraints IC that specify
that certain actions cannot be jointly taken if some conditions hold w.r.t. the state
— such constraints were defined before by [40].
Definition 80 (Integrity Constraint). If Φ is a set of action-point pairs and χ is a
wff, then Φ ←֓ χ is an integrity constraint.
When Φ ←֓ χ is ground (this is where χ is ground), this says that if χ is true,
then only one action-point pair in Φ may be executed. Formally, suppose s is a
state and Φ′ is a set of action-point pairs and Φ ←֓ χ is ground. (s, Φ′ ) |= Φ ←֓ χ
iff either s 6|= χ or s |= χ and |Φ ∩ Φ′ | ≤ 1. (s, Φ′ ) satisfies an integrity constraint
iff it satisfies all ground instances of it. (s, Φ′ ) |= IC where IC is a set of integrity
constraints iff (s, Φ′ ) satisfies every constraint in that set. Given a state s and set
IC of integrity constraints, we use ICs to denote the set of all ground instances of
integrity constraints in IC where the associated wff χ is satisfied by s2 .
Example 7.2.5. Continuing Example 7.2.4, let ICcpgn be:
{{appeal1 ((4, 3)), appeal2 ((10, 7))} ←֓ TRUE}
This constraint says that an appeal can be made to either group 1 or group 2 at
their center of influence, but not both — for instance, these two groups may have
opposing views.
We now introduce the goal-based geospatial optimization problem (GBGOP).
This problem takes as input a map M, initial state s0 , set of actions A, cost function
2

Formally, ICs = {(Φ ←֓ χ) ∈ IC|s |= χ}

320

C, integrity constraints IC, positive real number c, and disjoint sets Θin , Θout ⊆ BL .
Intuitively, c restricts the total cost and Θin (resp. Θout ) is a set of atoms that must
be true (resp. false) after the actions are applied. Our optimality criteria for a
GBGOP is to minimize the cardinality of the action-point pairs. A GBGOP can be
viewed as an abductive inference problem (i.e. find a set of actions that lead to the
current state) - where minimal cardinality is a common parsimony requirement.
Definition 81 (GBGOP Solution, Optimal Solution). A solution to a GBGOP
(M, s0 , A, C, IC, c, Θin , Θout ) is a set SOL ⊆ A×M such that: (i) Σ(ai ,pi )∈SOL ci ≤ c,
(ii) (s0 , SOL) |= IC, and (iii) appl(s0 , SOL) |=

V

Ai ∈Θin

Ai ∧

V

Aj ∈Θout

¬Aj .

A solution SOL is optimal iff there is no other solution SOL′ such that
|SOL′ | ≤ |SOL|.
Our next type of problem is a benefit-maximizing geospatial optimization problem (BMGOP) that also considers a benefit function, defined as follows.
Definition 82 (Benefit Function). The benefit function, B : BL → ℜ+ maps
atoms to positive real numbers.
Example 7.2.6. In our running example, we use the benefit function Bcpgn where
Bcpgn (A) = 1 if A has the form exposure() and 0 otherwise.
As with cost, we assume the benefit function to be arbitrary but fixed and
computable in constant time. We also assume that if BL = {A1 , . . . , An }, then
B(Ai ) is denoted bi . A BMGOP takes as input, M, s0 , A, C, IC, and c - all defined
the same as for a GBGOP. Additionally it takes benefit function B and natural
321

number k. Here k is a bound on the number of actions the agent can take as we
attempt to maximize benefit as an optimality criteria.
Definition 83 (BMGOP Solution, Optimal Solution). A solution to a BMGOP
(M, s0 , B, A, C, IC, k, c) is a set SOL ⊆ A × M such that: (i) |SOL| ≤ k and (ii)
Σ(ai ,pi )∈SOL ci ≤ c, and (iii) (s0 , SOL) |= IC.
A solution SOL is optimal iff there is no other solution SOL′ such that:
X

bi <

bi

Ai ∈appl(SOL′ ,s0 )

Ai ∈appl(SOL,s0 )

7.3

X

Complexity Results
Here, we provide complexity results for GBGOPs and BMGOPs. First, we

establish both as being at least NP-hard.
Theorem 38. Given GBGOP (M, s0 , A, C, IC, c, Θin ,
Θout ), finding an optimal solution SOL ⊆ A × M is NP-hard. This result holds
even if for each a ∈ A, p ∈ M, it is the case that ∀g ′ (p′ ) ∈ a(p), p′ = p - i.e. each
action only affects the point is is applied to.
Proof Sketch. We embed the known NP-hard problem of SET-COVER [46] which
takes as input a set of n elements, S and a family of m subsets of S, H ≡
{H1 , . . . , Hm }, and outputs H′ ⊆ H s.t. the union of the subsets covers all elements
in S and H′ is of minimal cardinality. We encode this problem into a GBGOP as
follows: we set G = {g1 , . . . , gn } - each predicate in G corresponds to an element
in S, the map, M consists of a single point, p, the actions A = {a1 , . . . , am } s..t
322

each action ai A corresponds to an element in H and each is defined as follows:
ai (p) =
Θin =

S

S

xj ∈Hi {gj (p)}.

gi ∈G {gi (p)},

The cost function C returns 1 for each action-point pair,

Θout = ∅, and finally, we set s0 = ∅, IC = ∅, c = n.

2

Theorem 39. Given BMGOP (M, s0 , B, A, C, IC, k, c), finding an optimal solution
SOL ⊆ A is NP-hard. This result holds even if for each a ∈ A, p ∈ M, it is the
case that ∀g ′ (p′ ) ∈ a(p), p′ = p - i.e. each action only affects the point is is applied
to).
Proof Sketch. The problem MAX-K-COVER [46] is considered the dual of SETCOVER and accepts the same input as that problem, with an additional natural K.
It outputs K subsets that covers a maximal amount of elements in S. The encoding
reflects that of Theorem 38 except now we assign a benefit of 1 for each ground
atom and set k = K.

2

One may think that one can solve GOPs efficiently in practice by using fully
polynomial time approximation schemes (FPTAS). However, by the nature of our
constructions used in the NP-hardness results, this is not possible for either type of
GOP under accepted theoretical assumptions.
Theorem 40. If for some ǫ > 0, there is a PTIME algorithm to approximate
GBGOP within (1 − ǫ) · ln(|A × M|), then N P ⊂ T IM E(|A × M|O(lg lg |A×M|) ) (NP
has a slightly super-polynomial algorithm).
Proof Sketch. Follows from Theorem 38 and [46, Theorem 4.4].

2

Theorem 41. Finding an optimal solution to BMGOP cannot be approximated in
323

PTIME within a ratio of

e−1
e

+ ǫ (approx. 0.63) for some ǫ > 0 (where e is the

inverse of the natural log) unless P=NP, even when IC = ∅.
Proof Sketch. Follows from Theorem 39 and [46, Theorem 5.3].

2

Next, under some reasonable assumptions, the decision problems for GBGOP/BMGOP are in-NP.
Theorem 42. Given GBGOP (M, s0 , A, C, IC, c, Θin ,
Θout ), if the cost function and all actions a ∈ A can be polynomially computed, then
determining if there is a solution SOL for the instance of the GBGOP s.t. for some
real number k, |SOL| ≤ k is in-NP.
Theorem 43. Given BMGOP (M, s0 , B, A, C, IC, k, c), if the cost function, benefit
function, and all actions a ∈ A can be polynomially computed, then determining if
there is a solution SOL for the instance of the BMGOP s.t. for some real number
val,

P

Ai ∈appl(SOL,s0 ) bi

≥ val is in-NP.

As stated earlier, a GBGOP may also be viewed as an abductive inference

problem. Even though finding a solution (not necessarily optimal) to a GBGOP
can trivially be conducted in PTIME3 , counting the number of solutions is #Pcomplete. This counting problem is difficult to approximate.
Theorem 44. Counting the number of solutions to a GBGOP (under the assumptions of Theorem 42) is #P-complete.
Proof Sketch. The MONSAT problem takes a set C of n clauses of K disjuncted
literals (no negation) over set L of atoms (size m) and outputs “yes” iff there is a
3

Return the set {(ai , pi ) ∈ A × M|ai (pi ) ∩ Θout = ∅}

324

subset of L that satisfies all clauses in C. This problem has an obvious resemblance
to SET-COVER (with no cardinality criteria) and we embed it into a GBGOP
in a way similar to the construction of Theorem 38. The key here is to have the
predicates correspond to clauses and actions correspond to lierals - each ai is defined
as follows: ai (p) = {gj (p)|{ℓi } |= φj }, where ℓi is the corresponding literal and gj is
the predicate that corresponds to clause φj . The reduction is parsimonious, and as
#MONSAT is #P-hard, the hardness result follows. The membership in #P follows
from Theorem 42.

2

Theorem 45. For ǫ > 0, approximating the number of solutions to a GBGOP
within a factor of 2|A×M|

1−e

is NP-hard.

Proof Sketch. Follows from Theorem 44 and Theorem 3.2 of [145].

7.4

2

Integer Programs for Solving GOPs
In this section, we present an integer programming (IP) algorithms for both

GBGOP and BMGOP which provide exact solutions. Given a GBGOP, the IP
associates an integer-valued variable Xi with each action-point pair (ai , pi ) ∈ A×M
where ai (pi ) ∩ Θout = ∅. Intuitively, Xi = 1 denotes that action ai is performed at
point pi .
Definition 84 (GBGOP-IP). Let set R = {(ai , pi ) ∈ A × M|ai (pi ) ∩ Θout = ∅}.

325

For each action-point pair (ai , pi ) ∈ R, create variable Xi ∈ {0, 1}.
|R|
X

min

Xi

(7.1)

i=1

X

s.t.

aj (pj )|Ai ∈aj (pj )

X

(ai ,pi )∈R

Xj ≥ 1

∀Ai ∈ Θin − s0

c i · Xi ≤ c

X

(ai ,pi )∈Φ

(7.2)
(7.3)

Xi ≤ 1 ∀(Φ ←֓ χ) ∈ ICs0

(7.4)

The objective function minimizes the total number of action-point pairs. Constraint (7.2) ensures that every ground atom in Θin (that does not appear in the
initial state) is caused by at least one of the selected action-point pairs. Constraint (7.3) enforces the constraint on cost. Constraint (7.4) ensures that the
integrity constraints are satisfied. Next we present our integer constraints for a
BMGOP where the IP associates an integer-valued variable Xi with each actionpoint pair (ai , pi ) ∈ A × M, and an integer-valued variable Yj with each ground
atom Aj ∈ BL − s0 . The intuition for the Xi variables is the same as in GBGOP-IP.
Definition 85 (BMGOP-IP). For each action-point pair (ai , pi ) ∈ A × M, create
variable Xi ∈ {0, 1}. For each Ai ∈ BL − s0 create variable Yi ∈ {0, 1}.
max

X

bi +

Ai ∈s0

s.t.

|BL |−|s0 |

X
i=1

X

aj (pj )|Ai ∈aj (pj )

Xj ≥ Yi

X

(ai ,pi )∈A×M

(7.5)
∀Ai ∈ BL − s0

(7.6)

Xi ≤ k

(7.7)

c i · Xi ≤ c

(7.8)

(ai ,pi )∈A×M

X

bi · Y i

X

(ai ,pi )∈Φ

Xi ≤ 1 ∀(Φ ←֓ χ) ∈ ICso

326

(7.9)

In the above IP, the objective function looks at each ground atom and sums
the associated benefit if the associated Yi variable is 1 - meaning that atom Ai is
true after the actions are applied. Constraint (7.6) effectively sets a Yi variable
to 1 if an action that causes Ai to be true occurs. Constraint (7.7) enforces the
cardinality requirement. Constraints 7.8-7.9 mirror constraints 7.3-7.4 of GBGOPIP. The result below shows that a solution σ to the above IPs4 , when restricted to
the Xi variables, provides an immediate solution to the GOP.
Proposition 65. Suppose Γ is a GBGOP (resp. BMGOP) and IP (Γ) is its corresponding integer program (GBGOP-IP, resp. BMGOP-IP). Then:
1. If SOL is a solution to Γ, then there is a solution σ of IP (Γ) such that
σ ⊇ {Xi = 1 | (ai , pi ) ∈ SOL}.
2. If σ is a solution to IP (Γ), then there is a solution SOL to Γ such that
{Xi = 1 | (ai , pi ) ∈ SOL} ⊆ σ.
We note that for GBGOP-IP, the number of variables is fairly large – O(|{(ai , pi ) ∈
A × M|ai (pi ) ∩ Θout = ∅}|) variables and O(|Θin − s0 | + |ICs0 | + 1) constraints.
BMGOP-IP has even more variables - (though not exponential) - O(|M|·(|A|+|G|))
variables and O(|M| · |G| + |ICs0 | + 2) constraints.
4

A solution to GBGOP-IP or BMGOP-IP is an assignment of values to variables that optimizes

the objective function. Thus, a solution can be described as a set of equations assigning values to
the variables Xi , Yj .

327

7.5

Correct Variable Reduction for GBGOP-IP
The set of integer constraints for GBGOP has O(|R|) variables where R ⊆

A × M. We show how to correctly reduce the number of variables by considering
only a subset of R - thereby providing a smaller integer program. Our intuition
is that an optimal solution SOL is an irredundant cover of Θin meaning there is
no subset SOL′ ⊂ SOL that is also a solution. Hence, we can discard certain
elements of R that cannot possibly be in an optimal solution. First, for a given
GBGOP Γ = (M, s0 , A, C, IC, c, Θin , Θout ), we introduce QΓ(a,p) = {Φ|(Φ ←֓ χ) ∈
ICs0 ∧(a, p) ∈ Φ} and the set of ground atoms each action-point pair affects AffΓ(a,p) =
ai (pi ) ∩ (Θin − (Θin ∩ s0 )). We can now define a reduced action-point set.
Definition 86 (Reduced Action-Point Set). Given GBGOP
Γ = (M, s0 , A, C, IC, c, Θin , Θout )
and set R = {(ai , pi ) ∈ A × M|ai (pi ) ∩ Θout = ∅}, we define reduced action-point
set R∗ = {(ai , pi ) ∈ R| 6 ∃(aj , pj ) ∈ R s.t.
(cj ≤ ci ) ∧ (QΓ(aj ,pj ) ⊆ QΓ(ai ,pi ) ) ∧ (AffΓ(ai ,pi ) ⊆ AffΓ(aj ,pj ) )}
Example 7.5.1. Consider the campaign scenario last discussed in Example 7.2.5.
Suppose the candidate wants to optimize the following GBGOP:
cpgn
cpgn )
Γ = (Mcpgn , scpgn , Acpgn , C(s
cpgn , ICcpgn , 4, Θin , ∅)

where each A ∈ Θcpgn
has the form exposure(p) where p is a point in one of the
in
two dashed rectangles in Figure 7.1. Note that as map Mcpgn contains 187 points,
328

|A| = 3, and Θout = ∅, the cardinality of R is 561. By contrast, the set R∗ consists
of only 7 elements, 1.2% of the size of R. Here we have
R∗ = {(nor, (5, 4)), (nor, (5, 3)), (nor, (5, 2)), (nor, (10, 8)),
(nor, (10, 7)), (nor, (10.6)), (appeal1 , (4, 3))}
Intuitively, all elements in R∗ are preferable for membership in an optimal
solution over R − R∗ as they cost less, result in the same changes to the state, and
occur in the same or fewer integrity constraints. Set R∗ can be found in quadratic
time with a naive algorithm - an operation that is likely dominated by solving or
approximating GBGOP-IP. The next lemma says that R∗ must contain an optimal
solution.any optimal solution to a GBGOP. This can then be used to correctly
reduce the number of variables in GBGOP-IP.
Lemma 22. Given GBGOP Γ = (M, s0 , A, C, IC, c, Θin , Θout ), for any optimal
solution SOL ⊆ R, there is an optimal solution SOL′ ⊆ R∗ .
Proof Sketch. We show this by proving that for any set W = SOL ∩ (R − R∗ ), there
is some set W ′ ⊆ R∗ − (R∗ ∩ SOL) s.t. (SOL − W ) ∪ W ′ is also a solution.
Proposition 66. Suppose Γ is a GBGOP and IP (Γ) is its corresponding integer
program. We can create such a program with a variable for every element of R∗
(instead of R) and Proposition 65 still holds true.

329

7.6

The BMGOP-Compute Algorithm
While BMGOP-IP can solve a BMGOP exactly, doing so is computationally

intractable. We now present an approximation algorithm that runs in PTIME but
provides a lower approximation ratio than proved in Theorem 41. First, we show
that a BMGOP reduces to an instance of submodular maximization problem5 with
respect to packing constraints. We then leverage some known methods [11] to solve
such problems and develop a fast, deterministic algorithm to approximate BMGOP
with an approximation bounds. Given BMGOP Γ = (M, s0 , B, A, C, IC, k, c), consider the objective function in BMGOP-IP. We can write that function as a mapping
from action-point pairs to reals. We denote this function (specific for BMGOP Γ)
as fΓ : 2A×M → ℜ+ , where fΓ (S) =

P

Ai ∈appl(S,s0 ) bi ,

which has certain properties.

Proposition 67. For BMGOP Γ, function fΓ is: (i) submodular, (ii) monotonic,
i.e. Z1 ⊆ Z2 → fΓ (Z1 ) ≤ fΓ (Z2 ) and (iii) under the condition ∀Ai ∈ BL , bi = 0, we
have fΓ (∅) = 0.6
Proof Sketch. Consider S ⊆ S ′ ⊆ A × M and (a, p) ∈
/ S ′ . We must show fΓ (S ∪
{(a, p)}) − fΓ (S) ≥ fΓ (S ′ ∪ {(a, p)}) − fΓ (S ′ ). Suppose, BWOC fΓ (S ∪ {(a, p)}) −
fΓ (S) < fΓ (S ′ ∪ {(a, p)}) − fΓ (S ′ ). Then we have
P

Ai ∈appl(S ′ ∪{(a,p)},s0 )−appl(S ′ ,s0 ) bi .
5

P

Ai ∈appl(S∪{(a,p)},s0 )−appl(S,s0 ) bi

<

However, by the definition of appl, we have appl(S∪

Suppose Z is a set. A function f : 2Z → R is said to be submodular iff for all Z1 , Z2 such that

Z1 ⊆ Z2 and all z ∈
/ Z2 , it is the case that f (Z1 ∪ {z}) − f (Z1 ) ≥ f (Z2 ∪ {z}) − f (Z2 ), i.e. the
incremental value of adding z to the smaller set Z1 exceeds the incremental value of adding it to
the larger set Z2 . Here, R denotes the reals.
6

Henceforth, we will assume this condition to be true.

330

{(a, p)}, s0 )−appl(S, s0 ) ⊇ appl(S ′ ∪{(a, p)}, s0 )−appl(S ′ , s0 ), which is a contradiction.2

As our objective function is submodular, and constraints 7.7-7.9 are linear
packing constraints, any instance of a BMGOP can be viewed as maximization of
a submodular function wrt linear packing constraints and hence, methods to solve
such problems can be used here. The BMGOP-Compute algorithm leverages this
idea and illustrated in Example 7.6.1.
Example 7.6.1. Following Example 7.2.5. Suppose the candidate wants to optimize
cpgn )
BMGOP: (Mcpgn , scpgn , Bcpgn , Acpgn , C(s
cpgn , ICcpgn , 3, 2). In this case, we will set

δ = 0.001. He wishes to find a set of 3 action-point pairs to optimize his exposure.
BMGOP-Compute sets λ = 22.14, w′ = 0.33, w′′ = 0.50, and w1 = 0.50 in lines 1
and 2. In the first iteration of the loop at line 3, it finds the action-point pair that
minimizes the quantity at line 3 is (appeal1 , (4, 3)) - which has the associated value
0.073. Note, other action-point pairs with low values are (appeal2 , (10, 7)) with 0.083
and (nor, (15, 6)) also with 0.083. It then adds (appeal1 , (4, 3)) to SOL and updates
w′ = 0.93, w′′ = 1.09, and w1 = 2.35. On the next iteration, the BMGOP-Compute
picks (nor, (15, 6)), which now has a value of 0.164. During this iteration, the value
of (appeal2 , (10, 7)) has increased substantially - to 0.294, so it is not selected. At
the end of the iteration, w′ is updated to 2.611 and w′′ is updated to 2.364. As
(nor, (15, 6)) does not impact the lone integrity constraint, the value w1 remains
at 2.354. In the third iteration, BMGOP-Compute selects (nor, (15, 9)) which has a
value of 0.421. Again, the value of (appeal2 , (10, 7)) has increased - but this time only

331

BMGOP-Compute
INPUT: BMGOP (M, s0 , B, A, C, IC, k, c)
OUTPUT: SOL ⊆ A × M
1. Set SOL = ∅, δ to be an infinitesimal,
and set λ = e2−δ · (2 + |ICs0 |).
2. Set w′ = 1/k and w′′ = 1/c. For each (Φi ←֓ χi ) ∈ ICs0 , set wi = 1/(2 − δ).
3. While k · w′ + c · w′′ + (2 − δ) ·

P

i wi

≤ λ and SOL 6= A × M

(a) Let (aj , pj ) ∈ A × M − SOL have minimal
(

P

w′ +w′′ ·cj +

P

Ai ∈appl(SOL∪{(aj ,pj )},s0

i|(aj ,pj )∈Φi
) bi )−(

P

wi

Ai ∈appl(SOL,s0 ) bi )

(b) SOL = SOL ∪ {(aj , pj )}
(c) Set w′ = w′ · λ1/k , w′′ = w′′ · λcj /c and for each integrity constraint i s.t.
(aj , pj ) ∈ Φi , set
wi = wi · λ1/(2−δ)
4. If SOL is not a valid solution then
(a) If

P

P

Ai ∈appl(SOL−{(aj ,pj )},s0 ) bi

≥

Ai ∈appl({(aj ,pj )},s0 ) bi ,

then SOL = SOL − {(aj , pj )}
(b) Else SOL = {(aj , pj )}
5. Return SOL

332

to 0.472. BMGOP-Compute re-calculates w′ = 7.331, w′′ = 5.128 and w1 remains at
2.354. On the last iteration, BMGOP-Compute picks (appeal2 , (10, 7)) as it has the
lowest value – 0.942. After this fourth iteration, it updates w′ = 20.589, w′′ = 11.124,
and w1 = 11.0861 - which now total to 42.799 – exceeding λ (22.14) – causing
BMGOP-Compute to exit the outer loop. Now SOL has 4 elements, exceeding the
cardinality constraint (as well as the integrity constraint). The checks done in line 4
remove (appeal2 , (10, 7)) from SOL - making the result feasible. BMGOP-Compute
returns {(appeal1 , (4, 3)), (nor, (15, 6), (nor, (15, 9))} which causes the benefit to be
45.
Proposition 68. Suppose Γ is a BMGOP and SOL is the set returned by BMGOPCompute. Then SOL is a solution to Γ.7
Proposition 69. BMGOP-Compute runs in O(k · |M| · |A| · |ICs0 |) time. Proof
Sketch. Clearly, the outer loop can iterate no more than k times. The inner loop
iterates for each element of A × M - hence requiring time O(|M| · |A|). The calculation at line 3a requires O(|ICs0 |) time.

2

The following important theorem states that BMGOP-Compute provides an
approximation guarantee. Because of Theorem 41 and as BMGOP-Compute is polynomial, we know that this approximation guarantee cannot be as good as

e−1
e

+ ǫ.

The result leverages Theorem 1.1 of [11] together with the above theorems. By
this result, the approximation factor of BMGOP-Compute depends on |ICs0 |. We
7

Here, SOL is not necessarily an optimal solution.

333

Approximation Factor

0.75
Best unless P=NP

0.55

0.35
BMGOP-Compute

0.15
1

4
7
10
13
16
Number of Integrity Constraints

19

Figure 7.2: |ICs0 | vs. approximation ratio.
illustrate this relationship, in Figure 7.2. For our target applications, we envision
|ICs0 | ≤ 20.
Theorem 46. Under the assumption that k, c ≥ 2 − δ, BMGOP-Compute provides
a solution within a factor of

1
(2+|ICs0 |)1/(2−δ)

(where δ is an infinitesimal) of optimal.

Proof Sketch. BMGOP-Compute follows from Algorithm 1 of [11] which optimizes a
submodular function subject to m packing constraints within

1
m1/W

where W is the

minimum width of the packing constraints - defined as the minimum of the size of
the constraint divided by the cost of an element. For constraint 7.7, the W = k. For
constraint 7.8, the W ≥ c. We can replace constraint 7.9 with:

P

(ai ,pi )∈Φj

Xi ≤ 2−δ

∀(Φj ←֓ χj ) ∈ ICso which maintains correctness as two variables to set to 1 and
exceeds 2 − δ. The new constraint has width 2 − δ, which, is the minimum. We then
apply Theorem 1.1 of [11].

2

334

7.7

Chapter 7 Related Work
Though spatial reasoning has been studied extensively in AI [7, 142, 103],

many of the paradigms that have emerged for such reasoning are qualitative in
nature. Such qualitative spatial reasoning efforts include the influential region connection calculus for qualitative reasoning about space. There has also been work
on quantitative methods for reasoning about space [74] which contains articles on
spatial reasoning in the presence of uncertainty using both logical and fuzzy methods. Spatial reasoning with quantitative information has been studied extensively
in image processing [179, 163].
However, unlike this vast body of work, this chapter focuses on a different
problem. Suppose we are dealing with a map M, a cost function C, a set A of
possible actions, a bound on the cost c, and a bound on the number of actions
we can take, what set of actions should be taken so as to optimize a given objective function. Two versions of this problem are studied in this chapter - GBGOP
and BMGOP which differ in what they optimize. Both problems are proved to
be NP-hard (NP-complete under realistic assumptions) and we further prove that
the number of solutions to GBGOP is #P-complete. We also find limits on approximating an optimal solution to BMGOP and GBGOP (in PTIME) under accepted theoretical assumptions. We develop integer programming formulations of
both problems and then present a way of simplifying the IP for GBGOP. We further
present the BMGOP-Compute algorithm for BMGOP and show that it is polynomial
and has a guaranteed approximation ratio (though not high enough to contract the

335

NP-hardness result).

7.8

Chapter Summary
In this chapter, we introduced “geospatial optimization problems” or GOPs

that aide the user in taking certain actions over a geographic region. We showed
these problems to be NP-hard and provided integer constraints. For the goal-based
variant, we correctly reduce the number of variables. For the benefit-maximizing
variant, we provide an approximation algorithm. In future work, we look to implement this framework and explore methods to achieve further scalability. In many
applications, there also exists an underlying diffusion process (i.e. epidemiology).
This is not accounted for with geospatial optimization. In the next chapter, we look
at optimal selection of actions with respect to a diffusion process.

336

Chapter 8
Social Network Optimization Problems

While we look to optimize certain geospatial properties in the previous chapter, we note that for some real-world applications, such as many epidemiological
situations, there is an underlying diffusion process that also affect geospatial proprieties. Given such a diffusion process and a network, we seek to find vertices of that
network that optimize an aggregate and satisfy certain logical conditions. Here, we
formalize the study of this type of agent behavior with the study of social network
optimization problems (SNOPs).1 Note that in this chapter, the acronym “GAPs”
does not refer to the geospatial abduction problems of the past three chapters but
rather the generalized annotated programs of [86].
1

This chapter is based on [159] and [152], completed in cooperation with Maria Luisa Sapino,

Matthias Broecheler and V.S. Subrahmanian.

337

8.1

Chapter Introduction
There is a rapid proliferation of different types of graph data in the world to-

day. These include social network data (FaceBook, Flickr, YouTube, etc.), cell phone
network data [126] collected by virtually all cell phone vendors, email network data
(such as those derived from the Enron corpus2 ), as well as information on disease
networks [45, 5]. There has been years of work on analyzing how various properties of nodes in such networks “diffuse” through the network - different techniques
have been invented in different academic disciplines including economics [73, 150],
infectious diseases [45], sociology [61] and computer science [81].
Past work on diffusion has several limitations. First, they largely assume that
a social network is nothing but a set of vertices and edges [178, 29, 147]. In contrast,
our notion of SNOPs allows a richer model where edges and vertices can both be
labeled with properties. For instance, a political campaigner hoping to spread a
positive message about a campaign needs to use demographics (e.g. sex, age group,
educational level, group affiliations, etc.) for targeting a political message — a “one
size fits all” message will not work. Second, past work on diffusion has no notion
of “strength” associated with edges. It may well be the case, in many applications,
that the degree of contact between two vertices (e.g. number of minutes person A
spends on the cell phone with person B) is a proxy for the strength of the relationship
between A and B, which in turn may have an impact of whether A can influence B
or not. Third, these past frameworks [73, 150, 45, 61] usually reason about a single
2

http://www.cs.cmu.edu/eenron/

338

diffusion model, rather than develop a framework for reasoning about a whole class
of diffusion models.
In this chapter, we first argue that a class of the well-known Generalized Annotated Program (GAP) paradigm [86, 85, 168] and their variants [175, 88, 107, 109,
31] including Linear GAPs (introduced here) form a convenient method to express
many diffusion models. Next, unlike most existing work in social networks which
focus on learning diffusion models, we focus on reasoning with previously learned
diffusion models (expressed via GAPs). In particular, we consider the problem of
optimal decision making in social networks which have associated diffusion models
expressible as Linear GAPs, though many of the results in the chapter apply to
arbitrary GAPs as well. Here are two examples.
• (Q1) Cell phone plans. A cell phone company is promoting a new cell phone
plan - as a promotion, it is giving away k free plans to existing customers.3 Which
set of k people should they pick so as to maximize the expected number of plan
adoptees predicted by a cell phone plan adoption diffusion model they have learned
from their past promotions?
• (Q2) Medication distribution plan.

A government combating a disease

spread by physical contact has limited stocks of free medication to give away.
Based on a diffusion model of how the disease spreads (e.g. kids might be more
susceptible than adults, those previously inoculated against the disease are safe,
3

Our SNOP framework allows us to add additional constraints — for instance, that plans can

only be given to customers satisfying certain conditions, e.g. not be employees of the cell phone
company.

339

etc.), they want to find a set of k people who (jointly) maximally spread the
disease (so that they can provide immediate treatment to these k people in an
attempt to halt the disease’s spread).4
Both the above problems are instances of a class of queries that we call SNOP
queries. They differ from queries studied in the past in quantitative (both probabilistic and annotated) logic programming in two fundamental ways: (i) They are
specialized to operate on graph data where the graph’s vertices and edges are labeled with properties and where the edges can have associated weights, (ii) They
optimize complex objective functions that can be specified by the user. Neither of
these has been studied before by any kind of quantitative logic programming framework, though work on optimizing objective functions in the context of different
types of semantics (minimal model and stable model semantics) has been studied
before [99]. And of course, constraint logic programming [8] has also extensively
studied optimization issues as well in logic programming - however, here, optimization and constraint solving is embedded in the constraint logic program, whereas in
our case, they are part of the query over an annotated logic program.
This chapter is organized as follows. In Section 8.2, we provide an overview
of GAPs (past work), define a social network, and explain how GAPs can represent some types of diffusion in SNs. Section 8.3 formally defines different types of
4

Again, our SNOP framework allows us to add additional constraints — for instance, that

medication can only be given to people satisfying certain conditions, e.g. be over a certain age,
or be within a certain age range and not have any conditions that are contra-indicators for the
medication in question.

340

social network optimization problems and provides results on their computational
complexity and other properties. Section 8.4 shows how our framework can represent several existing diffusion models for social networks including economics and
epidemiology. In Section 8.5 we present the exact SNOP-Mon algorithm to answer
SNOP queries under certain assumptions of monotonicity. We then develop a greedy
algorithm GREEDY-SNOP and show that under certain conditions, it is guaranteed
e
to be an ( e−1
) approximation algorithm for SNOP queries — this is the best possible

approximation guarantee. Last, but not least, we describe our prototype implementation and experiments in Section 8.7. Specifically, we tested our GREEDY-SNOP
algorithm on a real-world social network data set consisting of over 7000 nodes and
over 103,000 edges from Wikipedia logs. We show that we solve social network optimization problems over real data sets in acceptable times. We emphasize that much
additional work is required on further enhancing scalability and that research on
social network optimization problems is at its very infancy. Finally, in Section 8.8,
we review related work.

8.2

Technical Preliminaries
In this section, we first formalize social networks, then briefly review gener-

alized annotated logic programs (GAPs) [86] and then describe how GAPs can be
used to represent concepts related to diffusion in SNs.

341

8.2.1

Social Networks Formalized

Throughout this chapter, we assume the existence of two arbitrary but fixed
disjoint sets VP, EP of vertex and edge predicate symbols respectively. Each vertex
predicate symbol has arity 1 and each edge predicate symbol has arity 2.
Definition 87. A social network (S) is a 5-tuple (V, E, ℓvert , ℓedge , w) where:
1. V is a set whose elements are called vertices.
2. E ⊆ V × V is a multi-set whose elements are called edges.
3. ℓvert : V → 2VP is a function, called vertex labeling function.
4. ℓedge : E → EP is a function, called edge labeling function.

5

5. w : E × EP → [0, 1] is a function, called weight function.
We now present a brief example of an SN that will be used throughout this
chapter.
Example 8.2.1. Let us return to the cell phone example (query (Q1)). Figure 8.1 shows a toy SN the cell phone company might use. Here, we might have
VP = {male, f emale, adopters, temp adopter, non adptr} denoting the sex and past
adoption behavior of each vertex; EP might be the set {phone, email, IM } denoting
the types of interactions between vertices. w(v1 , v2 , ep) denotes the percentage of
communications of type ep ∈ EP initiated by v1 that were with v2 (measured either
5

Each edge e ∈ E is labeled by exactly one predicate symbol from EP. However, there can be

multiple edges between two vertices labeled with different predicate symbols.

342

Figure 8.1: Example cellular network.
w.r.t. time or bytes). The function ℓvert is shown in figure 8.1 by the shape (denoting
past adoption status) and shading (male/female). The type of edges (bold for phone,
dashed for email, dotted for IM) is used to depict ℓedge .
It is important to note that our definition of social networks is much broader
than that used by several researchers [5, 45, 73, 81] who often do not consider either
ℓedge or ℓvert or edge weights through the function w — it is well-known in marketing
that intrinsic properties of vertices (customers, patients) and the nature and strength
of the relationships (edges) is critical for decision making in those fields.
Note. We assume that SNs satisfy various integrity constraints. In Example 8.2.1,
it is clear that ℓvert (V ) should include at most one of male, f emale and at most one
of adopters, temp adopter,non adptr. We assume the existence of some integrity
constraints to ensure this kind of semantic integrity – they can be written in any
343

reasonable syntax to express ICs – in the rest of this chapter, we assume that social
networks have associated ICs and that they satisfy them. In our example, we will
assume ICs ensuring that a vertex can be marked with at most one of male/f emale
and at most one of adopters, temp adopter, non adptr.

8.2.2

Generalized Annotated Programs: A Recap

We now recapitulate the definition of generalized annotated logic programs
from [86]. We assume the existence of a set AVar of variable symbols ranging over
the unit real interval [0, 1] and a set F of function symbols each of which has an
associated arity. We start by defining annotations.
Definition 88 (annotation term). (i) Any member of [0, 1] ∪ AVar is an annotation.
(ii) If f is an n-ary function symbol over [0, 1] and t1 , . . . , tn are annotations, then
f (t1 , . . . , tn ) is an annotation.
For instance, 0.5, 1, 3 and X are all annotation terms. If +, ∗, / are all binary
function symbols, then

(X+1)∗0.5
3

is an annotation term.

We define a separate logical language whose constants are members of V and
whose predicate symbols consist of VP ∪ EP. We also assume the existence of
a set V of variable symbols ranging over the constants (vertices). No function
symbols are present. Terms and atoms are defined in the usual way (cf. [106]). If
A = p(t1 , . . . , tn ) is an atom and p ∈ VP (resp. p ∈ EP), then A is called a vertex
(resp. edge) atom. We will use AV and AE to denote the sets of all ground vertex
and edge atoms, respectively and A = AV ∪ AE . We note that |AV | = |VP| · |V| and
344

|AE | = |EP| · |E|.
Definition 89 (annotated atom/GAP-rule/GAP). If A is an atom and µ is an
annotation, then A : µ is an annotated atom. If A0 : µ0 , A1 : µ1 , . . . , An : µn are
annotated atoms, then
A0 : µ0 ← A1 : µ1 ∧ . . . ∧ An : µn
is called a GAP rule. When n = 0, the above GAP-rule is called a fact. A GAP-rule
is ground iff there are no occurrences of variables from either AVar or V in it. A
generalized annotated program Π is a finite set of GAP rules.
Every social network SN = (V, E, ℓvert , ℓedge , w) can be represented by the
GAP ΠSN = {q(v) : 1 ← | v ∈ V ∧ q ∈ ℓvert (v)} ∪ {ep(V1 , V2 ) : w(V1 , V2 , ep) ←
| (V1 , V2 ) ∈ E ∧ ℓedge (V1 , V2 ) = ep}.
Definition 90 (embedded social network). A social network SN is said to be embedded in a GAP Π iff ΠSN ⊆ Π.
It is clear that all social networks can be represented as GAPs. When we
augment ΠSN with other rules — such as rules describing how certain properties
diffuse through the social network, we get a GAP Π ⊇ ΠSN that captures both the
structure of the SN and the diffusion principles. Here is a small example of such a
GAP.
Example 8.2.2. The GAP Πcell might consist of ΠSN using the social network of
Figure 8.1 plus the GAP-rules:

345

1. will adopt(V ) : 0.8 × X + 0.2 ← adopter(V ) : 1 ∧ male(V ) : 1 ∧
IM (V, V ′ ) : 0.3 ∧ f emale(V ′ ) : 1 ∧ will adopt(V ′ ) : X.
2. will adopt(V ) : 0.9 × X + 0.1 ← adopter(V ) : 1 ∧ male(V ) : 1 ∧
IM (V, V ′ ) : 0.3 ∧ male(V ′ ) : 1 ∧ will adopt(V ′ ) : X.
3. will adopt(V ) : 1 ← temp adopter(V ) : 1 ∧ male(V ) : 1 ∧ email(V ′ , V ) : 1 ∧
f emale(V ′ ) : 1 ∧ will adopt(V ′ ) : 1.

Rule ( 1) says that if V is a male adopter and V ′ is female and the weight of
V ’s instant messages to V ′ is 0.3 or more, and we previously thought that V would
be an adopter with confidence X, then we can infer that V will adopt the new plan
with confidence 0.8 × X + 0.2. The other rules may be similarly read.
Suppose S is a social network and Π ⊇ ΠS is a GAP. In this case, we call the
rules in Π − ΠS diffusion rules. We use Ad−hd to refer to the set of ground atoms in
the heads of all diffusion rules of some fixed Π. Note that for the models presented
in this chapter, Ad−hd ⊆ AV , meaning edge weights do not change as a result of the
diffusion process. However, for the general case, it is possible for edge weights to
change as a result of the diffusion process.
GAPs have a formal semantics that can be immediately used. An interpretation I is any mapping from the set of all grounds atoms to [0, 1]. The set I of all
interpretations can be partially ordered via the ordering: I1  I2 iff for all ground
atoms A, I1 (A) ≤ I2 (A). I forms a complete lattice under the  ordering.
Definition 91 (satisfaction/entailment). An interpretation I satisfies a ground annotated atom A : µ, denoted I |= A : µ, iff I(A) ≥ µ. I satisfies the ground
346

GAP-rule AA0 ← AA1 ∧ . . . ∧ AAn (denoted I |= AA0 ← AA1 ∧ . . . ∧ AAn ) iff
either (i) I satisfies AA0 or (ii) there exists an 1 ≤ i ≤ n such that I does not
satisfy AAi . I satisfies a non-ground atom (rule) iff I satisfies all ground instances
of it. GAP Π entails AA, denoted Π |= AA, iff every interpretation I that satisfies
all rules in Π also satisfies AA.
As shown by [86], we can associate a fixpoint operator with any GAP Π that
maps interpretations to interpretations.
Definition 92. Suppose Π is any GAP and I an interpretation. The mapping TΠ
that maps interpretations to interpretations is defined as TΠ (I)(A) = sup{µ | A :
µ ← AA1 ∧ . . . ∧ AAn is a ground instance of a rule in Π and for all 1 ≤ i ≤ n,
I |= AAi }.
[86] show that TΠ is monotonic and has a least fixpoint lf p(TΠ ). Moreover,
they show that Π entails A : µ iff µ ≤ lf p(TΠ )(A) and hence lf p(TΠ ) precisely
captures the ground atomic logical consequences of Π. They also define the iteration
of TΠ as follows TΠ ↑ 0 is the interpretation that assigns 0 to all ground atoms.
TΠ ↑ (i + 1) = TΠ (TΠ ↑ i). This can be extended in the obvious way to limit
ordinals.
Thus, we see that any social network S can be represented as a GAP ΠS .
We will show (in Section 8.4) that many existing diffusion models for a variety
of phenomena can be expressed as a GAP Π ⊇ ΠS by adding some GAP-rules
describing the diffusion process to ΠS .

347

8.3

Social Network Optimization (SNOP) Queries

8.3.1

Basic SNOP Queries

In this section, we develop a formal syntax and semantics for optimization in
social networks, taking advantage of the above embedding of SNs into GAPs. In
particular, we formally define SNOP-queries, examples of which have been informally introduced earlier as (Q1) and (Q2). We see from queries (Q1),(Q2) that a
SNOP-query looks for a set V′ of vertices and has the following components: (i) an
objective function expressed via an aggregate operator, (ii) an integer k ≥ 0, (iii)
a set of conditions that each vertex in V′ must satisfy, and (iv) a goal atom g(V )
where g is a vertex predicate and V is a variable.
Aggregates. It is clear that in order to express queries like (Q1),(Q2), we need
aggregate operators which are mappings agg : FM([0, 1]) → R+ (R+ is the set of
non-negative reals) where FM(X) denotes the set of all finite multisets that are
subsets of X. Relational DB aggregates like SUM,COUNT,AVG,MIN,MAX are all
aggregate operators which can take a finite multiset of reals as input and return a
single positive real.
Vertex condition. A vertex condition V C is a conjunction of annotated vertex
atoms containing exactly one variable.
Thus, in our example, male(V ) : 1 ∧ adopter(V ) : 1 is a conjunctive vertex
condition, but male(V ) : 1 ∧ email(V, V ′ ) : 1 is not. We are now ready to define a
SNOP-query.

348

Definition 93 (SNOP-query). A SNOP-query is a 4-tuple (agg, V C, k, g(V )) where
agg is an aggregate, V C is a vertex condition, k ≥ 0 is an integer, and g(V ) is a
goal atom.
If we return to our cell phone example, we can set agg = SUM, k = 3 (for
example), V C = true and the goal to be adopter(V ). Here, the goal is to find
a set AN S of vertices v such that AN S’s cardinality is 3 or less and such that
SUM{lf p(TΠ )(adopter(v)) | v ∈ AN S} is maximized. Here, the SUM is applied to
a multiset rather than a set. Note that the diffusion model’s impact is captured in
this example via the lf p(TΠ )(adopter(v)) expression which, intuitively, tells us the
confidence (according to the diffusion model) that vertex v will be an adopter. If we
return to an extended version of our cell phone example and we want to ensure that
the vertices in AN S are not employees of the company (let’s call this company C),
then we merely can set V C = not employee(V ) : 1.6 This query now asks us to find
a set AN S of three or less vertices — none of which is an employee of the company
C — such that the sum Σv∈AN S {lf p(TΠ )(adopter(v)) | v ∈ AN S} is maximized.
Our framework also allows the vertex condition V C to have annotations other
than 1. So in our cell phone example, the company could explicitly exclude anyone
whose “opinion” toward the company is negative. If opinion is quantified on a continuous [0, 1] scale (such automated systems do exist [166]), then the vertex condition
6

In this chapter, we do not consider non-monotonic negation and choose merely to represent

not employee as a predicate symbol. The extension of GAPs to non-monotonic negation has been
studied [31] — future work can extend non-monotonic negation to the case of the type of social
network optimization problems studied in this chapter.

349

might be restated as V C = not employee(V ) : 1 ∧ negative opinion(V ) C : 0.7
which says that the company wants to exclude anyone whose negativity about the
company exceeds 0.7 according to an opinion scoring engine such as [166].
Definition 94 (pre-answer/value). Suppose an SN S = (V, E, ℓvert , ℓedge , w) is embedded in a GAP Π. A pre-answer to the SNOP query Q = (agg, V C, k, g(V ))
w.r.t. Π is any set V′ ⊆ V such that: (i) |V′ | ≤ k, (ii) for all vertices v ′ ∈ V′ ,
lf p(T{Π ∪ {g(v′ ):1← | v′ ∈V′ } ) |= V C[V /v ′ ]. We use pre ans(Q) to denote the set of all
pre-answers to query Q.
The value, value(V′ ), of a pre-answer V′ is agg({lf p(TΠ ∪ {g(v′ ):1← | v′ ∈V′ } )(g(V ))|V ∈
V}) — here, the aggregate is applied to a multi-set rather than a set. We also note
that we can define value as a mapping from interpretations to reals based on a SNOP
query. We say value(I) = agg({I(g(v)) | v ∈ V}).
If we return to our cell phone example, V′ is the set of vertices to which the
company is considering giving free plans. (value(V′ )) is computed as follows.
1. Find the least fixpoint of TΠ′cell where Π′cell is Πcell expanded with annotated
atoms of the form adopter(V ′ ) : 1 for each vertex V ′ ∈ V′ .
2. For each vertex V ∈ V (the entire set of vertices, not just V′ now), we now
find the confidence assigned by the least fixpoint.
3. Summing up these confidences gives us a measure of the expected number of
plan adoptees.
Definition 95 (answer). Suppose an SN S = (V, E, ℓvert , ℓedge , w) is embedded in
350

a GAP Π and Q = (agg, V C, k, g(V )) is a SNOP-query. A pre-answer V′ is an
answer to the SNOP-query Q iff the SNOP-query has no other pre-answer V′′ such
that value(V′′ ) > value(V′ ).7
The answer set, ans(Q), to the SNOP-query Q = (agg, V C, k, g(V )) w.r.t. Π
is the set of all answers to Q.
Example 8.3.1. Consider the GAP Πcell with the social network from Figure 8.1
embedded and the SNOP-query Qcell = (SU M, true, 3, will adopt). The sets V′1 =
{v15 , v19 , v6 } and V′2 = {v15 , v18 , v6 } are both pre-answers. In the case of V′1 , two
applications of the TΠ operator yields a fixpoint where the vertex atoms formed
with will adopt in set {v15 , v19 , v6 , v12 , v18 , v7 , v10 } are annotated with 1. For V2 ,
only one application of TΠ is required to reach a fixpoint, and the corresponding set of vertices (where the vertex atom formed with will adopt is annotated
with 1) is {v15 , v6 , v12 , v18 , v7 , v10 }. As these are the only vertex atoms formed with
will adopt that have a non-zero annotation after reaching the fixed point, we know
that value(V′1 ) = 7 and value(V′2 ) = 6. As value(V′1 ) > value(V′2 ), V′1 is an answer
to this SNOP-query.

8.3.2

Special Cases of SNOP Queries

In this section, we examine several special cases of SNOP queries that still
allow us to represent a wide variety of diffusion models. Table 8.1 illustrates the
special cases discussed in this section while Table 8.2 illustrates the various proper7

Throughout this chapter, we only treat maximization problems - there is no loss of generality

in this because minimizing an objective function f is the same as maximizing −f .

351

Type

Special Case

Reference

Special cases of Π

Linear GAP

Definition 96

Monotonicity

Definition 97

Positive linear

Definition 98

Zero-starting

Definition 100

A-priori V C

Definition 101

Special cases of agg

Special cases of value

Table 8.1: Special cases of SNOP queries
ties.

Special Cases of the GAP. First, we present a class of GAPs called linear GAPs.
Intuitively, a linear GAP is a GAP where the annotations in the rule head are linear
functions and the annotations in the body are variables is the atom is a vertex atom
and constant otherwise. It is important to note that a wide variety of diffusion
models can be represented with GAPs that meet the requirements of this special
case. We define it formally below.
Definition 96 (Linear GAP). A GAP-rule r of the form
H0 : µ0 ← A1 : µ1 ∧ . . . ∧ An : µn
is said to be linear iff there exist constants c0 , . . . , ci , . . . , cn where ∀i, ci ∈ [0, 1] and
each ground instance rθ of r has the form
H0 : c0 + c1 · X1 θ + ... + cn · Xn θ ← A1 : X1 θ ∧ . . . ∧ An : Xn θ
352

and Σni=1 ci ∈ [0, 1].
A GAP is linear iff each rule in it is linear.
Note that the linear GAP allows for a wide variety of models to be expressed.
For example, suppose we have a diffusion model in which the edge atoms do not
appear in any rule head (except the facts that embed the SN). In this case, edge
weights can be treated as constants. Hence, we can allow rules where the annotation
of a vertex atom is multiplied or divided by an edge weight (as they behave as
constants) - provided the sum of all constants is in the interval [0, 1]. Section 8.4
will show that several well-known network diffusion models can be embedded into
our framework. Diffusion Models 8.4.2 and 8.4.4 are linear GAPs while Diffusion
Models 8.4.1 and 8.4.3 are not.
Special Aggregates. We define two types of aggregates — monotonic aggregates
and positive linear aggregates.
To define monotonicity, we first define a partial ordering ⊑ on multi-sets of
numbers as follows. X1 ⊑ X2 iff there exists an injective mapping β : X1 → X2
such that (∀x1 ∈ X1 )x1 ≤ β(x1 ).
Definition 97 (Monotonic Aggregate). The aggregate agg is monotonic (resp.
anti-monotonic) iff whenever X1 ⊑ X2 , it is the case that agg(X1 ) ≤ agg(X2 )
(resp. agg(X2 ) ≤ agg(X1 )).
Definition 98 (Positive-Linear Aggregate). The aggregate agg, applied to the finite multiset FM(X) is positive linear iff it is of the form agg(FM(X)) = c0 +
Σxi ∈FM(X) ci xi where (for n = |FM(X)|) c1 , . . . , cn ≥ 0. Note that c0 can be positive,
353

negative, or 0.
Proposition 70. If agg is positive-linear, then it is monotonic.
It is important to note that in our definition of positive-linear, we only require
that the coefficients associated with the elements of the multi-set be positive - we allow for an additive constant to be negative. One obvious example of a positive-linear
aggregate is SUM. Any positive, weighted sum will also meet these requirements –
an example is the fixed-subset average function given below.
Definition 99 (Fixed-Subset Average). For set X of reals, given a fixed subset
Xsubset ⊆ X, the fixed-subset average is the quantity:
average(Xsubset ) =

X
1
(x)
card(Xsubset ) x∈X
subset

Special cases of the query. We now describe two special cases of the query. In one
case, we consider zero-starting value functions, while in a second case, we consider
a-priori vertex conditions V C. Intuitively, zero-starting means that value(∅) = 0.
However, there are several ways in which this criteria may be met - for example, we
can simply adjust the aggregate by subtracting a constant (which, for positive-linear
aggregates, would still allow an aggregate to meet our definition of positive-linear).
An a-priori V C is one where lf p(TΠ ) satisfies V C iff V C was satisfied already by
TΠ ↑ 1. Intuitively, an a-prior V C is like a “fact” in classical logic programming
and where the application of the fixpoint operator makes no change to what was
true originally. We present formal definitions below.
Definition 100 (Zero-starting). A SNOP-query is zero-starting (w.r.t. a given
social network S and a GAP Π ⊇ ΠS ) iff value(∅) = 0.
354

Note that the function value() is uniquely defined by a social network, a SNOPquery, and a diffusion model Π and hence the above definition is well defined. The
result below states that as long as we consider positive linear aggregates, we can
always modify a non zero-starting aggregate to one that is.
Proposition 71. If a SNOP-query is not zero-starting w.r.t. a social network S
and a GAP Π ⊇ ΠS , and the aggregate is positive-linear, it can be expressed as
a zero-starting SNOP-query in linear time while still maintaining a positive-linear
aggregate.
Definition 101 (A-Priori V C). In an a-priori V C SNOP-query, for set V′ ⊆ V,
we modify the definition of value(V′ ) (Definition 94, part ii) as follows:
For all vertices v ′ ∈ V′ , g(v ′ ) : 1 ∧

V

pred∈ℓvert (v ′ )

pred(v ′ ) : 1 |= V C[V /v ′ ].

Note that both examples (Q1),(Q2) we gave in the Introduction have a-priori
VCs. If, in the cell phone example, we require that the free cell phones are given
to non-employees, then this is an a-priori V C because being an employee is not
determined by the diffusion process, but by whether a vertex in the social network
had the associated non-employee property. Likewise, in the case of an a-priori V C in
the medical example saying that an individual below 5 should not get the medicine,
this boils down to a static labeling of each node’s age (below 5 or not) which is not
affected by the diffusion process.
Example 8.3.2. Consider a painting company attempting to conduct a viral marketing strategy. Consider the simple social network depicted in Figure 8.2. White
vertices represent individuals with whom the paint company has had prior business.
355

7

1

6
8
3
10

2

9
4

5

18

17
16

15

12

11

13
19

20

14

Figure 8.2: Social Network for the painting company.
Suppose the represent this with a predicate prior and vertex atoms formed with some
white vertex v and prior are annotated with 1 (i.e. prior(v) : 1) while the rest are
annotated with 0. Based on local telemarketing legislation, the paint company can
only contact individuals with which it had a prior business relationship. As the paint
company intends to market to a set of high-payoff vertices in a short period of time,
it is unreasonable to expect the number vertices where where a prior vertex atom is
annotated with 1 to increase. Hence, they create a logic program such that the vertex
condition V C(V ) = prior(V ) : 1 is a-priori.

8.3.3

Properties of SNOPs

In this section, we will prove several usful properties of SNOP queries that use
various combinations of the assumptions presented in the previous section. Later,

356

Propoerty

Assumptions

Monotonicity of value (Lemma 23)

Monotonicity

Multiset {V′ ⊆ V|V′ is a pre-answer} is a uniform matroid

A-priori V C

(Lemma 24)
Linear GAP
Positive linear agg
Submodularity (Theorem 47)
A-priori V C

Table 8.2: Properties that can be proven given certain assumptions
we will leverage some of these properties in our algorithms. Table 8.2 summarizes
the different properties that we prove in this section (as well as what assumptions we
make to prove these properties). Table 8.3 shows how these properties are leveraged
in the algorithms that we will present later in the chapter.
The first property we show is that the value function is monotonic. This follows
directly from the monotonicity of the aggregate - hence we present the following easy

Algorithm

Property

Exact algorithm with pruning (Section 8.5.2)

Monotonicity of value
Submodularity

Approx. Ratio on Greedy Algorithm (Section 8.5.3)
Zero-starting

Table 8.3: How the various properties are leveraged in the Algorithms

357

lemma.
Lemma 23. Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP
Π ⊇ ΠS ), if agg is monotonic (Definition 97), then value (defined as per Q and Π)
is monotonic.
Next, we show that the multiset of pre-answers is a uniform matroid in the
special case of an a-priori V C.
Lemma 24. Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP
Π ⊇ ΠS ), if V C is applied a-priori (as per Definition 101), the set of pre-answers
(to query Q) is a uniform matroid.
An important property in social networks is submodularity. Intuitively,if X is
a set, then a function f : 2X → R is submodular iff whenever X1 ⊆ X2 and x ∈
/ X2 ,
f (X1 ∪ {x}) − f (X1 ) ≥ f (X2 ∪ {x}) − f (X2 ). The following result states that the
value() function associated with a linear GAP with an a-priori vertex condition V C
and a positive linear aggregate function is guaranteed to be submodular.
Theorem 47. Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP
Π ⊇ ΠS ) if the following criteria are met:
• Π is a linear GAP
• V C is applied a-priori
• agg is positive linear,
then value (defined as per Q and Π) is sub-modular.
In other words, for Vcond ≡ {v ′ |v ′ ∈ V and (g(v ′ ) : 1 ∧
358

V

pred∈ℓvert (v ′ )

pred(v ′ ) : 1 |=

V C[V /v ′ ])} and sets V1 ⊆ V2 ⊆ Vcond and v ∈ Vcond , v ∈
/ V1 ∪ V2 , the following
holds:
value(V1 ∪ {v}) − value(V1 ) ≥ value(V2 ∪ {v}) − value(V2 )
Proof Sketch: Consider a linear polynomial with a variable for each vertex in the
set of vertices that meet the a-priori V C, where setting the variable to 1 corresponds
to the vertex being picked and setting it to 0 indicates otherwise. For any subset of
vertices meeting the a-priori V C, there is an associated polynomial of this form such
that when the variables corresponding to the vertices are set to 1 (and the rest set to
0), the answer is equal to the corresponding value for that set. For a sets V1 , V2 and
vertex v (as per the statement), we show that submodualirty holds by manipulating
such polynomials.
Example 8.3.3. We now show an example of a SNOP-query that is not submodular when a non-linear GAP is considered. Figure 8.3 shows a social network.
This social network has one edge predicate, e, and all edges are weighted with 1.
Nodes in the network are either susceptible to the disease (circles) or carriers (diamonds) - the associated predicates are suc and car respectively. Additionally, we
have the predicates inf, exp denoting vertices that have been infected by or exposed
to the disease.
Let Πdisease be the embedding of this network plus the following diffusion rules.
exp(V ) : 1 ← inf(V ) : 1
exp(V ) : 1 ← e(V ′ , V ) : 1 ∧ inf(V ′ ) : 1 ∧ suc(V ) : 1
359

v1

v4

v2

v3

v6

v7

v5

Figure 8.3: Social network corresponding with Example 8.5.1 concerning disease
spread.
P
Ii
inf(V ) : ⌊ P i ⌋ ← exp(V ) : 1 ∧
i Ei

^

Vi |(Vi ,V )∈E

(edge(Vi , V ) : Ei ∧ inf (Vi ) : Ii )

Intuitively, the second rule says that a vertex becomes exposed if that vertex

is susceptible and it has at least one incoming neighbor that is infected. The third
rule states that a vertex becomes infected if it is exposed and all its neighbors are
infected. Suppose, for illustrative purposes, that inf(v5 ), inf(v7 ) are annotated with
1.
Consider the function value based on the SNOP query (Πdisease , SU M, true, 2, inf(V )).
Obviously, as the GAP is not linear, it does not meet the requirements of Theorem 47 to prove submodularity. We can actually show through counterexample, that
this SNOP query is not submodular. Consider the following:
value({v1 , v5 }) − value({v1 }) = 1
and
value({v1 , v7 , v5 }) − value({v1 , v7 }) = 5
This shows a clear violation of submodularity.

360

8.3.4

The Complexity of SNOP Queries

We now study the complexity of answering a SNOP query. First, we show
that SNOP-query answering is NP-hard by a reduction from max k-cover [46]. We
show that the problem is NP-hard even when many of the special cases hold.
Theorem 48. Finding an answer to SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN
S and GAP Π ⊇ ΠS ) is NP-hard (even if Π is a linear GAP, V C = ∅, agg = SU M
and value is zero-starting).
Proof Sketch: The known NP-hard problem of MAX-K-COVER [46] is defined as
follows.
INPUT: Set of elements, S and a family of subsets of S, H ≡ {H1 , . . . , Hmax }, and
positive integer K.
OUTPUT: Less than or equal to K subsets from H such that the union of the subsets
covers a maximal number of elements in S.
We show that MAX-K-COVER can be embedded into a social network and that the
corresponding SNOP-query gives an optimal answer to MAX-K-COVER. The embedding is done by creating a social network resembling a bipartite graph, where vertices represent either the elements or the subsets from the input of MAX-K-COVER.
For every vertex pair representing a set and an element of that set, there is an edge
from the set vertex to the element vertex. A single vertex and edge predicate are
used - vertex and edge. A single non-ground diffusion rule is added to the GAP:
vertex(V ) : X ← vertex(V ′ ) : X ∧ edge(V ′ , V ) : 1. The aggregate is simply the
sum of the annotations associated with the vertex atoms. We show that the picked
361

vertices that maximize the aggregate correspond with picked subsets that maximize
output of the problem. Also, as we do not use V C, the GAP is linear, and the
aggregate is positive-linear, we know that the value function is submodular.

Under some reasonable conditions, the problem of answering SNOP-queries is
also in NP.
Theorem 49. Finding an answer to a decision problem associated with SNOP query
Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP Π ⊇ ΠS ) where agg and the functions
in F are polynomially computable is in-NP.
Most common aggregate functions like SUM, AVERAGE, Weighted average,
MIN, MAX, COUNT are all polynomially computable. Moreover, the assumption
that the functions in F are polynomially computable is also reasonable.
Later in this chapter, we shall address the problem of answering a SNOP-query
using an approximation algorithm. We re-state the definition of approximation
below (see [54]).
Definition 102 (Approximation). For a given instance I of a maximization problem
with optimal solution OP T (I), an α-approximation algorithm A is an algorithm such
that for any instance I
OP T (I) ≤ α · A(I)
Based on the above definition, we shall say that V′ is an α1 -approximation to a
SNOP query if value(V′opt ) ≤ α · value(V′ ) (where Vopt is the answer to the SNOP
query). Likewise, the algorithm that produces V′ in this case is an α-approximation
362

algorithm. We note that due to the nature of the reduction from MAX-K-COVER
that we used to prove NP-hardness, we can now show that unless P = NP, there is
no PTIME-approximation of the SNOP-query answering problem that can guarantee
that the approximate answer is better than 0.63 of the optimal value. This gives us
an idea of the limits of approximation possible for a SNOP-query with a polynomialtime algorithm. Later, we will develop a greedy algorithm that precisely matches
this approximation ratio.
Theorem 50. Answering a SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and
GAP Π ⊇ ΠS ), cannot be approximated in PTIME within a ratio of

e−1
e

+ ǫ for some

ǫ > 0 (where e is the inverse of the natural log) unless P = NP – even if Π is a
linear GAP, V C = ∅, agg = SU M and value is zero-starting.
(That is, there is no polynomial-time algorithm that can approximate value
within a factor of about 0.63 under standard assumptions.)

8.3.5

Counting Complexity of SNOP-Queries

In this section, we ask the question: how many answers are there to a SNOPquery (agg, V C, k, g(V ))? In the case of the cell phone example, this corresponds
to asking “How many sets AN S of people are there in the the network such that
AN S has k or fewer people and AN S optimizes the aggregate, subject to the vertex
condition V C?” If there are m such sets AN S1 , . . . , AN Sm , this means the cell
phone company can give the free cell phone plan to eithe all members of AN S1
or to all members of AN S2 , and so forth. The “counting complexity” problem of

363

determining m is is #P -complete.
Theorem 51. Counting the number of answers to SNOP query Q = (agg, V C, k, g(V ))
(w.r.t. SN S and GAP Π ⊇ ΠS ) is #P-complete.

8.3.6

The SNOP-ALL Problem

Though the cell phone company may not want to give free calling plans to
all possible members of AN S1 , . . . , AN Sm , in the case of the epidemiology example
where a government wants to check the spread of a disease, the government may
reason as follows. It has only k units of medicine to hand out now, and hence it
needs to choose to give those medicines to all members of exactly one of the AN Si ’s.
However, the government wants to know how many people are in all of the AN Si ’s
so as to determine how to plan for the future (e.g. placing future orders).
Although the counting version of the query is #P -hard, finding the union
of all answers to a SNOP query is no harder than a SNOP query (w.r.t. PTIME
reductions). We shall refer to this problem as SNOP-ALL - and it reduces both to
and from a regular SNOP query in PTIME.
We first prove NP-hardness, showing by showing we can answer a SNOP query
in PTIME with an oracle to SNOP-ALL.
Theorem 52. Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP
Π ⊇ ΠS ), finding

S

′ ∈ans(Q)
Vans

′
is NP-hard.
Vans

Proof Sketch: We show NP-hardness by the embedding of a SNOP-query in a
SNOP-ALL query via the following informal algorithm (FIND-SET) that takes an
364

instance of SNOP-ALL (Q) and some vertex set V ∗ , |V ∗ | ≤ k.
1. If |V ∗ | = k, return V ∗
2. Else, solve SNOP-ALL(V ∗ ), returning set V ′′ .
(a) If V ′′ − V ∗ ≡ ∅, return V ∗
(b) Else, pick v ∈ V ′′ − V ∗ and return FIND-SET(Q, V ∗ ∪ v)
The theorem below shows that SNOP-ALL can be answered in PTIME with
an oracle to a SNOP-query.
Theorem 53. Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP
Π ⊇ ΠS ), finding

S

′ ∈ans(Q)
Vans

′
Vans
reduces to |V | + 1 SNOP-queries.

Proof Sketch: Using an oracle that correctly answers SNOP-queries, we can answer a SNOP-ALL query by setting up |V | SNOP-queries as follows:
• Let kall be the k value for the SNOP-ALL query and for each SNOP-query i, let
ki be the k for that query. For each query i, set ki = kall − 1.
• Number each element of vi ∈ V such that g(vi ) and V C(vi ) are true. For the ith
SNOP-query, let vi be the corresponding element of V
• Let Πi refer to the GAP associated with the ith SNOP-query and Πall be the
program for SNOP-ALL. For each program Πi , add fact g(vi ) : 1
• For each SNOP-query i, the remainder of the input is the same as for SNOP-ALL.
After the construction, do the following:
365

1. We shall refer to a SNOP-query that has the same input as SNOP-ALL as the
′ (pri)
′ (pri)
“primary query.” Let Vans
be an answer to this query and value(Vans
)

be the associated value.
′ (i)
′ (i)
2. For each SNOP-query i, let Vans
be an answer and value(Vans
) be the

associated value.
3. Let V ′′ , the solution to SNOP-ALL be initialized as ∅.
′ (i)
′ (pri)
4. For each SNOP-query i, if value(Vans
) = value(Vans
), then add vertex vi

to V ′′ .

8.4

Applying SNOPs to Real Diffusion Problems
In this section, we show how SNOPs can be applied to real-word diffusion

problems. We look at three categories of diffusion models – tipping models (Section 8.4.1), where a given vertex adopts a behavior based on the ratio of how many
of its neighbors previously adopted the behavior, cascading models (Section 8.4.2),
where a property passes from vertex to vertex solely based on the strength of the
relationship between the vertices, and homophilic models (Section 8.4.3), where
vertices with similar properties tend to adopt the same behavior – irrespective (or
in addition to) of network relationships. None of these approaches solves SNOPqueries — they merely specify diffusion models rather than performing the kinds of
optimizations that we perform in SNOP-queries.

366

8.4.1

Tipping Diffusion Models

Tipping models [150, 61] have been studied extensively in economics and sociology to understand diffusion phenomena. In tipping models, a vertex changes a
property based on the cumulative effect of its neighbors. In this section, we present
the tipping model of Jackon-Yariv [73], which generalizes many existing tipping
models.

The Jackson-Yariv Diffusion Model [73]. In this framework, the social network
is just a directed graph G′ = (V′ , E′ ) consisting of a set of agents (e.g. people). Each
agent has a default behavior (A) and a new behavior (B). Suppose di denotes the
degree of a vertex vi . [73] use a function γ : {0, . . . , |V| − 1} → [0, 1] to describe
how the number of neighbors of v affects the benefits to v for adopting behavior
B. For instance, γ(3) specifies the benefits (in adopting behavior B) that accrue to
an arbitrary vertex v ∈ V′ that has three neighbors. Let πi denote the fraction of
neighbors of vi that have adopted behavior B. Let constants bi and ρi be the benefit
and cost respectively for vertex vi to adopt behavior B, respectively. [73] state that
node vi switches to behavior B iff

bi
ρi

· γ(di ) · πi ≥ 1.

Returning to our cell-phone example, one could potentially use this model to
describe the spread of the new plan. In this case, behavior A would be adherence to
the current plan the user subscribes to, while B would be the use of the new plan.
The associated SNOP-query would find a set of nodes which, if given a free plan,
would jointly maximize the expected number of adoptees of the plan. Cost and

367

benefit could be computed from factors such as income, time invested in switching
plans, etc. Below is a straight-forward embedding of this model into our framework.
Diffusion Model 8.4.1 (Jackson-Yariv model). Given a Jackson-Yariv model consisting of G′ = (V′ , E′ ) and g, we can set up an SN (V′ , E′′ , ℓvert , ℓedge , w) as follows.
We define E′′ = {(x, y), (y, x) | (x, y) ∈ E′ }. We have a single edge predicate symbol
edge and ℓedge assigns 1 to all edges in E′′ . Our associated GAP ΠJY now consists
of ΠSN plus the single rule:
P
X
bi
j Xj
B(Vi ) : ⌊ · γ(
Ej ) · P
⌋←
ρi
j Ej
j

^

Vj |(Vj ,Vi )∈E′′

(edge(Vj , Vi ) : Ej ∧ B(Vj ) : Xj )

It is easy to see that this rule (when applied in conjunction with ΠSN for

a social network SN ) precisely encodes the Jackson-Yariv semantics. Note that
Πdisease from Example 8.3.3 on page 359 is a special case of this model.
We notice right away that the above GAP is not linear. However, the good
news is the non-linearity is only due to the floor function. If we eliminate the
floor-function, we can represent a variant of this model where the annotation would
represent an “expected likelihood” that an agent adopts behavior B. This new embedding of the Jackson-Yariv models is a linear GAP under the following conditions
(forall Vi ).
|{Vj |(Vj , Vi ) ∈ E′′ }| ·

bi
· γ(
ρi

bi
· γ(
ρi

X

Vq |(Vq ,Vi )∈E′′

X

Vq |(Vq ,Vi )∈E′′

w(Vq , Vi , edge)) · P

w(Vq , Vi , edge)) · P

Vq |(Vq ,Vi )∈E

′′

1
≤1
w(Vq , Vi , edge)

1
∈ [0, 1]
Vq |(Vq ,Vi )∈E′′ w(Vq , Vi , edge)

As the Jackson-Yariv model does not cause edge weights to change, they can be
treated as constants upon grounding (hence, annotations of edge atoms can be
368

multiplied or divided by the annotations of vertex atoms in the heads of the diffusion
rules). This allows us to easily create a linear version of the Jackson-Yariv model
below.
Diffusion Model 8.4.2 (Linear Jackson-Yariv model).
P
X
^
bi
j Xj
B(Vi ) : · γ(
Ej ) · P
←
(edge(Vj , Vi ) : Ej ∧ B(Vj ) : Xj )
ρi
E
j
j
′′
j
Vj |(Vj ,Vi )∈E

If we consider the above model in terms of Definition 96 (Linear GAPs), for

each ground diffusion rule, the annotated atom in the head, formed with B(Vi ) is
annotated with a linear expression of the form
c0 + c1 · X1 + . . . + c|{Vj |(Vj ,Vi )∈E′′ }| · X|{Vj |(Vj ,Vi )∈E′′ }|
Here, c0 = 0, and for all j > 0,
cj =

bi
· γ(
ρi

X

Vq |(Vq ,Vi )∈E′′

w(Vq , Vi , edge)) · P

1
Vq |(Vq ,Vi )∈E′′ w(Vq , Vi , edge)

where each j is an index of an incoming vertex to Vi . Note that we can directly
use edge weights from the original social network (as expressed by the function w)
because the Ej annotations are for edge atoms and do not change in the diffusion
process (as edge weights do not appear in the heads of any diffusion rules in the
model). Clearly, under our stated assumption, linearity holds.
Example 8.4.1. Figure 8.4 illustrates a social network of individuals who share
photographs. Edges are directional formed with a predicate share and weighted 1.
Vertex predicates include {buys camera, pro}. If the vertex is shaded, the vertex
atom formed with pro is annotated with 1. All other vertex atoms are annotated
with zero.
369

v1

v9
v5

v10

v7

v4

v8

v6

v2

v3

Figure 8.4: Social network of individuals sharing photographs. Shaded vertices are
professional photographers. All edges are directional share edges.
A vendor wishes to sell a camera and wants to see how the popularity of the
camera will spread in the network. He wants to use a Jackson-Yariv style diffusion
model. Consider the social network embedded into a logic program, Π along with
following Jackon-Yariv style tipping diffusion rule:
P
j Xj · E j
⌋←
buys camera(V ) : ⌊ P
j Ej

^

Vj |(Vj ,V )∈E

(shares(Vj , V ) : Ej ∧buys camera(Vj ) : Xj )

We will call the logic program with the above diffusion rule Πsf wf d . Alternatively,
we could have a linear version of it as follows (again, linearity follows by the fact
that we can treat the edge weights as constants upon grounding):
P
j Xj · Ej
←
buys camera(V ) : P
j Ej

^

Vj |(Vj ,V )∈E

(shares(Vj , V ) : Ej ∧buys camera(Vj ) : Xj )

We will call the logic program formed with that diffusion rule (no floor function)
Πlin . In this case, the grounded diffusion rules have a head formed with the atom
370

buys camera(V ) annotated with the linear expression
co + c1 · X1 + . . . + c|{Vj |(Vj ,V )∈E′′ }| · X|{Vj |(Vj ,V )∈E}|
Here, c0 = 0 and for all j > 0 we have,
cj = P

w(Vj , V, shares)
Vq |(Vq ,V )∈E w(Vq , V, edge)

where each j is an index of an incoming vertex to V . Clearly, each cj ∈ [0, 1]
and the sum of all these constants is 1, which gives us linearity in accordance with
Definition 96. Table 8.4 shows the least fixed point for the two different GAPs
(original JY model and the linear version) that arise when we assign vertex atom
buys camera(v2 ) an annotation of 1 — it also shows as well as the sum of the
annotations.

8.4.2

Cascading Diffusion Models

In a cascading model, a vertex obtains a property from one of its neighbors,
typically based on the strength of its relationship with the neighbor. These models were introduced in the epidemiology literature in the early 20th century, but
gained increased notice with the seminal work of [5]. Recently, cascading diffusion
models have been applied to other domains as well. For example, [20] (diffusion
of photos in Flickr) and [167] (diffusion of bookmarks in FaceBook) both look at
diffusion process in social networks as “social cascades” of this type. In this section,
we present an encoding of the popular SIR model of disease spread in our framework.

371

Vertex Atom

Annotation Assigned by

Annotation Assigned by

lf p(TΠsf wd ∪{buys camera(v2 ):1←} )

lf p(TΠlin ∪{buys camera(v2 ):1←} )

buys camera(v1 )

0.0

0.5

buys camera(v2 )

1.0

1.0

buys camera(v3 )

1.0

1.0

buys camera(v4 )

0.0

0.0

buys camera(v5 )

0.0

0.0

buys camera(v6 )

0.0

0.0

buys camera(v7 )

0.0

0.25

buys camera(v8 )

0.0

0.5

buys camera(v9 )

0.0

0.5

buys camera(v10 )

0.0

0.5

SUM

2

4.25

Table 8.4: Comparison between straightforward and linear Jackson-Yariv Models

372

The SIR Model of Disease Spread. The SIR (susceptible, infectious, removed )
model of disease spread [5] is a classic disease model which labels each vertex in a
graph G = (V, E) (of humans) with susceptible if it has not had the disease but can
receive it from one of its neighbors, infectious if it has caught the disease and trec
units of time have not expired, and removed where the vertex can no longer catch
or transmit the disease. The SIR model assumes that a vertex v that is infected can
transmit the disease to any of its neighbors v ′ with a probability pv,v′ for trec units
of time. We would like to “find a set of k vertices that would maximize the expected
number of vertices that become infected”. These are obviously good candidates to
treat with appropriate medications.
Diffusion Model 8.4.3 (SIR model). Let S = (V, E, ℓvert , ℓedge , w) be an SN where
each edge is labeled with the predicate symbol e and w(v, v ′ , e) = pv,v′ . We use
the predicate inf to designate the initially infected vertices. In order to create a
GAP ΠSIR capturing the SIR model of disease spread, we first define trec predicate
symbols rec1 , . . . , rectrec where reci (v) intuitively means that node v was infected i
days ago. Hence, rectrec (v) means that v is “removed.” We embed S into GAP
ΠSIR by adding the following diffusion rules. If trec > 1, we add a non-ground rule
for each i = {2, . . . , trec } - starting with trec :
reci (V ) : R ← reci−1 (V ) : R
rec1 (V ) : R ← inf(V ) : R
inf(V ) : (1 − R) · PV ′ ,V · (PV ′ − R′ ) ← rectrec (V ) : R ∧ e(V ′ , V ) : PV ′ ,V ∧
inf(V ′ ) : PV ′ ∧ rectrec (V ′ ) : R′ .
373

The first rule says that if a vertex is in its (i − 1)’th day of recovery with
certainty R in the j’th iteration of the TΠSIR operator, then the vertex is i days into
recovery (with the same certainty) in the j +1’th iteration of the operator. Likewise,
the second rule intuitively encodes the fact that if a vertex became infected with
certainty R in the j’th iteration of the TΠSIR operator, then the vertex is one day
into recovery in the j + 1’th iteration of the operator with the same certainty. The
last rule says that if a vertex V ′ was infected with probability PV ′ and there is an
edge from V ′ to V in the social network (weighted with probability PV ′ ,V ), and the
vertex V ′ has recovered with certainty R′ , given the probability 1 − R that V is not
already recovered, (and hence, cannot be re-infected), then the certainty that the
vertex V gets infected is (1 − R) · PV ′ ,V · (PV ′ − R′ ). Here, PV ′ − R′ is one way of
measuring the certainty that V ′ has recovered (difference of the probability that it
was infected and the probability it has recovered) and PV ′ ,V is the probability of
infecting the neighbor.
To see how this GAP works, we execute a few iterations of the TΠSIR operator
and show the fixpoint that it reaches on the small graph shown in Figure 8.5. In
this graph, the initial infected vertices are those shown as a shaded circle. The
transmission probabilities weight the edges in the graph.
The SNOP-query (SU M, true, k, inf ) can be used to compute the expected
number of infected vertices in the least fixpoint of TΠ . This query says “find the k
vertices in the social network which, if infected, would cause the maximal number
of vertices to become infected in the future.” However, the above set of rules can
be easily used to express other things. For instance, an epidemiologist may not be
374

c

0.1

i
0.2

a

0.2

0.3

b

d

0.4

f
0.1

g

0.3

h
0.05

Shaded vertices are infected.
Edges are bi-directional,
trec =2

1 inf(a):1, inf(c):1, inf(d):1
2 rec1(a):1, rec1(c):1, rec1(d):1, inf(b):0.2, inf(d):0.3,
inf(f):0.3, inf(g):0.05, inf(i):0.1
3 rec2(a):1, rec2(c):1, rec2(d):1, rec1(b):0.2,
rec1(d):0.3, rec1(f):0.3, rec1(g):0.05, rec1(i):0.1
inf(g):0.08
4 rec2(b):0.2, rec2(d):0.3, rec2(f):0.3, rec2(g):0.05,
rec2(i):0.1, rec1(g):0.08
5 rec2(g):0.08

Figure 8.5: Left: Sample network for disease spread. Right: annotated atoms
entailed after each application of TΠSIR (maximum, non-zero annotations only).
satisfied with only one set of k vertices that can cause the disease to spread to the
maximum extent - as there may be another, disjoint set of k vertices that could
cause the same effect. The epidemiologist may want to find all members of the population, that if in a group of size k could spread the disease to a maximum extent.
This can be answered using a SNOP-ALL query, described in Section 8.3.

The SIS Model of Disease Spread. The SIS (Susceptible-Infectious-Susceptible)
model [67] is a variant of the SIR model. In SIS, an an individual becomes susceptible to disease after recovering (as opposed to SIR, where an individual acquires
permanent immunity). SIS can be easily represented by a modification to the construction given above.
Diffusion Model 8.4.4 (SIS model). Take Diffusion Model 8.4.3 and change the
third rule to
inf(V ) : PV ′ ,V · (PV ′ − R′ ) ← e(V ′ , V ) : PV ′ ,V ∧ inf(V ′ ) : PV ′ ∧ rectrec (V ′ ) : R′ .
375

Here, we do not consider the probability that vertex V is immune – hence this
probability of recovery does not change the probability of becoming infected.

Diffusion in the Flickr Photo Sharing Network. The Flickr social network is
designed for sharing of digital photographs. Users create a list of “favorite” photos
that can be viewed by other users on the network. In [20], the authors studied how
photographs spread to the favorite lists of different users using a variant of the SIS
model. The key difference is that they do not consider a node “recovered” – i.e. once
a photo was placed on a favorite list, it was relatively permanent (the study was
conducted over about 100 days). They also found that photos lower on a favorite
list (as the result of a user marking a large number of photos as “favorite”) for a
given user could still spread through the network. Hence, we present a GAP that
captures the intuition of how Flickr photos spread according to [20].
Diffusion Model 8.4.5 (Flickr Photo Diffusion).
photoi (V ) : consti · Xi ← connected to(V ′ , V ) : 1 ∧ photoi (V ′ ) : Xi
In Diffusion Model 8.4.5, the annotation of the vertex atom photoi (V ) is the
likelihood that vertex V has marked photo i as one of its favorites. The predicate
connected to is the sole edge label representing that there is a connection from vertex
V ′ to V (users select other users on this network). Additionally, the value consti is
a number in [0, 1] that determines the likelihood that a given photo spreads in the
network. As the edge weights do not change in this model, upon grounding, we can
eliminate the annotated atom connected to(V ′ , V ) : 1 from the body (as for each
376

vertex V , we would only need to ground out a diffusion rule for each incoming edge
to V ). Therefore, as consti ∈ [0, 1], linearity follows. We note that for all of these
models, the annotation functions reflect one interpretation of the likelihood that a
vertex is infected or recovered – others are possible in our framework.

8.4.3

Homophilic Diffusion Models

Recently, [9] studied the spread of mobile application use on a global instantmessaging network of over 27 million vertices. They found that network-based
diffusion could overestimate the spread of a mobile application and, for this scenario,
over 50% of the adopted use of the applications was due to homophily - vertices
with similar properties adopting similar applications.
This result should not be surprising – the basic idea behind web-search advertising is that two users with a similar property (search term) will be interested
in the same advertised item. In fact, [20] explicitly pre-processed their Flickr data
set with a heuristic to eliminate properties attained to vertices that could not be
accounted for with a diffusion process. We can easily represent homophilic diffusion
in a GAP with the following type of diffusion rule:
Diffusion Model 8.4.6 (Homophilic Diffusion of a Product).
buys product(V ) : 0.5 × X ← property(V ) : 1 ∧ exposed to product(V ) : X
In Diffusion Model 8.4.6, if a vertex is exposed to product (i.e. through mass
advertising) and has a certain property, then the person associated with the vertex
purchases the product with a likelihood of 0.5. For this rule, there are no network
377

effects. Note that if the predicate property does not appear in any other rule heads,
then the GAP is linear.
[177], the authors propose a “big seed” marketing approach that combines
both homophilic and network effects. They outline a strategy of advertising to a
large group of individuals who are likely to spread the advertisement further through
network effects. We now describe a GAP that captures the ideas underlying big seed
marketing. Suppose we have a set of attribute labels AL ⊆ VP. These attributes
may be certain demographic characteristics - anything from education level to race
to level of physical fitness. Suppose we want to advertise to k groups with one
of these attributes to maximize an aggregate with respect to a goal predicate g.
Consider the following construction.
Diffusion Model 8.4.7 (Big Seed Marketing). The GAP includes an embedding of
the social network, as well as the network diffusion model of the user’s choice, and
the following additions.
1. Add vertex label attrib to VP.
2. For each attribute label lbl ∈ AL, add vertex vlbl to V. Set ℓvert (vlbl ) = {attrib}.
3. For each attribute label lbl ∈ AL, let eff lbl be a constant in [0, 1]. This corresponds to the confidence that, if advertised to, a vertex v with label lbl obtains
an annotation of 1 on g(v).
4. This construction uses an a-priori V C = attrib(V ) : 1.
5. Subtract k from the aggregate – this discounts the vertices created in part 2.
378

6. For each lbl ∈ AL, add the following non-ground rule:
g(V ) : eff lbl × X ← lbl (V ) : 1 ∧ g(vlbl ) : X
Note that in the above diffusion model, the vlbl vertices correspond to advertisements directed toward different vertex properties. The V C condition forces the
query to only return vlbl vertices. The diffusion rule, added per label, ensures that
the mass advertisement is received and that the vertex acts accordingly (hence the
ef flbl constants). Also, it is important to note that this construction is linear if no
vertex atom formed with a predicate in AL appears in the head of a diffusion rule.
We close this section with a note that while all diffusion models mentioned here
have been developed by others and have been shown above to be representable via
GAPs, none of these papers has developed algorithms to solve SNOP-queries. We
emphasize that not only do we give algorithms to answer SNOP-queries in the next
section, our algorithms take any arbitrary diffusion model that can be expressed
as a GAP, and an objective function as input. In addition, our notion of a social
network is much more general than that of many of these extant approaches.

8.5

Algorithms
In this section we study how to solve SNOP problems algorithmically.

379

8.5.1

Naive Algorithm

The naive algorithm for solving the SNOPS query (agg, V C, k, g(V )) is to first
find all pre-answers to the query. Then compute the value for each pre-answer and
find the best. This is obviously an extremely expensive algorithm that is unlikely
to terminate in a reasonable amount of time.
An execution strategy that first finds all vertices in a social network S that
satisfy the vertex condition and then somehow restricts interest to those vertices in
the above computation (where S is embedded in a GAP Π) would not be correct for
two reasons. First, lf p(TΠ ) assigns a truth value to each ground vertex atom A that
might be different from what is initially assigned within the social network. Second,
when we add a new ground vertex atom A to Π (e.g. in our cell phone example,
when we consider the possibility of assigning a free calling plan to a vertex v), it
might be the case that vertices that previously did not satisfy the vertex condition
V C do so after the addition of A to Π.

8.5.2

A Non-Ground Algorithm in the Monotonic Case

There are three major problems with the Naive algorithm. The first problem
is that the aggregate function is very general and has no properties that we can
take advantage of. Hence, we can show that the entire search space might need
to be explored if an arbitrary aggregate function is used. The second problem is
that it works on the “ground” instantiation of Π. The third problem is that the
TΠ operator maps all ground atoms to the [0, 1] interval and there can be a very

380

large number of ground atoms to consider. For instance, if we have a very small
social network with just 1000 vertices and a rule with 3 variables in it, that rule has
109 possible ground instances - an enormous number. Likewise, if there is a ternary
predicate symbol in the language of Π, then there are 109 ground atoms to consider.
All these problems are further aggravated by the fact that fixpoints might have to be
computed several times.
In this section, we provide an algorithm to compute answers to a SNOPquery under the assumption that our aggregate function is monotonic and under
the assumption8 that all rules in a GAP have the form A : f (X1 , . . . , Xn ) ← B1 :
X 1 , ∧ · · · , Bn : X n .
In this case, we define a non-ground interpretation and a non-ground fixpoint
operator SΠ . This leverages existing work on non-ground logic programming initially
pioneered by [114] and later adapted to different logic programming extensions by
[59, 39, 165]. We start by defining a non-ground interpretation.
Definition 103. A non-ground interpretation is a partial mapping N G : A → [0, 1].
Every non-ground interpretation N G represents an interpretation grd(N G) defined
as follows: grd(N G)(A) = max{N G(A′ ) | A is a ground instance of A′ }. When there
is no atom A′ which has A as a ground instance and for which N G(A′ ) is defined,
8

This latter assumption does not cause any loss of generality for all practical purposes if we also

make the reasonable assumption that any constant annotations in a rule body can be translated into
constraints. So if Bi : 0.5 occurs in the body of a rule, it can be replaced by Bi : Vi ∧ Vi ≥ 0.5. [86]
show that allowing such constraints involving annotated constraints can be easily accommodated
by a simple extension to the semantics of GAPs.

381

then we set grd(N G)(A) = 0.
Thus, in a language with just three constants a, b, c and one predicate symbol
p, the non-ground interpretation that maps p(X, a) to 0.5 and everything else to 0
corresponds to the interpretation that assigns 0.5 to p(a, a), p(b, a) and p(c, a) and 0
to every other ground atom. Non-ground interpretations are succinct representations
of ordinary interpretations - they only keep track of assignments to non-ground
atoms (not necessarily all ground atoms) and they do not need to worry about
atoms assigned 0. In the worst case, the number of non-ground atoms that N G
keeps track of is no worse than a ground interpretation. We now define a fixpoint
operator that maps non-ground interpretations to non-ground interpretations.
Definition 104 (operator SΠ ). The operator SΠ associated with a GAP Π maps
a non-ground interpretation N G to the non-ground interpretation SΠ (N G) where
SΠ (N G)(A) = max{f (X1 , . . . , Xn ) | A : f (µ1 , . . . , µn ) ← B1 : µ1 ∧ . . . ∧ Bn : µn
is a rule in Π such that for all 1 ≤ i ≤ n, there exists an atom Bi′ such that
(B1 , . . . , Bn ) and (B1′ , . . . , Bn′ ) are simultaneously unifiable via a most general unifier
θ and (i) if µi is a constant, then N G(Bi θ) ≥ µi , and (ii) if µi is a variable,
then N G(Bi θ) = Xi }. (In this definition, without loss of generality, we assume
the variables occurring in rules in Π are mutually standardized apart and are also
different from those in N G).
The fixpoint operator SΠ delays grounding to the maximal extent possible by
(i) only looking at the rules in Π directly rather than ground instances of rules in Π
(which is what TΠ does), and (ii) by trying to assign values to non-ground atoms
382

rather than ground instances - unless there is no other way around it. The following
example shows how SΠ works.
Example 8.5.1. Some specific diffusion models focus on certain features in a graph
that encourage the diffusion process. For example, [105] describes a diffusion process that is augmented by the presence of “funnels” in the graph. In this example,
concerning disease spread, we take advantage of such features computationally by
leveraging the operator SΠ .
Consider Example 8.3.3 from page 359 where we present a social network and
some diffusion rules for disease spread embedded in program Πdisease .
Let us apply SΠdisease till we reach a fixed point. With the first application,
we entail annotated atoms {exp(v4 ) : 1, exp(v5 ) : 1, exp(v6 ) : 1, exp(v7 ) : 1, }. With
the next application, {inf(v4 ) : 1, inf(v6 ) : 1} are entailed. Then, with the next
application, the non-ground annotated atom exp(V ) : 1 is entailed. With the final
application of the operator, the non-ground annotated atom inf(V ) : 1 is entailed.
Consider the ordering  defined as follows on non-ground interpretations:
N G1  N G2 iff grd(N G1 ) ≤ grd(N G2 ). In this case, it it easy to see that:
Proposition 72. Suppose Π is any GAP. Then:
1. SΠ is monotonic.
2. SΠ has a least fixpoint lf p(SΠ ) and lf p(TΠ ) = grd(lf p(SΠ )). That is, lf p(SΠ )
is a non-ground representation of the (ground) least fixpoint operator TΠ .
In short, SΠ is a version of TΠ that tries to work in a non-ground manner as
much as possible. We now present the SNOP-Mon algorithm to compute answers to a
383

Figure 8.6: Search tree for Example 8.5.2.
SNOP-query (agg, V C, k, g(V )) when agg is monotonic. The SNOP-Mon algorithm
uses the following notation: value(N G) is the same as value(grd(N G)) and N G
satisfies a formula iff grd(N G) satisfies it.
The following example shows how the SNOP-Mon algorithm works.
Example 8.5.2. Consider the program Πdisease from Example 8.5.1. Suppose, we
want to answer a SNOP query (Πdisease , SU M, true, 2, inf(V )). The search-tree in
Figure 8.6 illustrates how SNOP-Mon searches for an optimal solution to the query.
In the figure, we labeled each node with the set of vertices and a real number. The vertices correspond to the vertex atoms (annotated with 1) formed with inf added to GAP
in step 4(c)i. The real number corresponds to the value resulting from this addition.
Underlined nodes in the search tree represent potential solutions where bestV al and
bestSOL are updated. Notice, that, for example, the set {v4 , v1 } is never considered.
This is because inf(v1 ) is entailed anytime a candidate solution includes v4 . The optimal solution is found to be {v7 , v5 }. In this example, the algorithm considers solutions in the following order: {}, {v4 }, {v4 , v7 }, {v4 , v5 }, {v4 , v6 }, {v7 }, {v7 , v5 }, {v7 , v1 },
{v7 , v2 }, {v7 , v3 }, {v5 }, {v5 , v6 }, {v5 , v1 }, {v5 , v2 }, {v5 , v3 }, {v6 }, {v6 , v1 }, {v6 , v2 },
384

SNOP-Mon(Π, agg, V C, k, g(V ))
1. The variable Curr is a tuple consisting of a GAP and natural number. We initialize
Curr.P rog = Π; Curr.Count = 0.
2. T odo is a set of tuples described in step 1. We initialize T odo ≡ {Curr}
3. Initialize the real number bestV al = 0 and GAP bestSOL = N IL
4. while T odo 6≡ ∅ do
(a) Cand = first member of T odo; T odo = T odo − {Cand}
(b) if value(lf p(SCand.P rog )) ≥ bestV al ∧ lf p(SCand.P rog ) |= V C then
i. bestV al = value(lf p(SCand.P rog ); bestSOL = Cand
(c) if Cand.Count < k then
i. For each ground atom g(V )θ, s.t. 6 ∃OtherCand ∈ T odo where
OtherCand.P rog ⊇ Cand.P rog,
|OtherCand.P rog| ≤ |Cand.P rog| + 1,
and lf p(SOtherCand.P rog ) |= g(V )θ : 1, do the following:
A. Create new tuple N ewCand.
Set N ewCand.P rog = Cand.P rog ∪ {g(V )θ : 1 ←}.
Set N ew.Count = Cand.Count + 1)
B. Insert N ewCand into T odo
ii. Sort

the

elements

of

Element

∈

T odo

in

descending

value(Element.P rog), where the first element, T op
greatest such value (i.e.

∈

order

of

T odo, has the

there does not exist another element T op′ s.t.

value(T op′ .P rog) > value(T op.P rog))
5. if bestSOL 6= N IL then return (bestSOL.P rog − Π) else return NIL.

385

{v6 , v3 }, {v1 }, {v2 }, {v3 }.
The following result states that the SNOP-Mon algorithm is correct.
Theorem 54. Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP
Π ⊇ ΠS ), if agg is monotonic then:
• There is an answer to the SNOP-query Q w.r.t. the GAP Π iff SNOPMon(Π, agg, V C, k, g(V )) does not return NIL.
• If SNOP-Mon(Π, agg, V C, k, g(V )) returns any result other than NIL, then
that result is an answer to the SNOP-query Q w.r.t. the GAP Π.

8.5.3

Approximation Algorithms: GREEDY-SNOP

Even though SNOP-Mon offers advantages such as pruning of the search tree
and leverages non-ground operations to increase efficiency over the naive algorithm,
it is still intractable in the worst case. Regretfully, Theorem 48 precludes an exact
solution in PTIME and Theorem 50 precludes a PTIME α-approximation algorithm
where α <

e
.
e−1

Both of these results hold for the restricted case of linear-GAPs

and positive linear aggregate functions.
The good news is that we were able to show that (i) for linear-GAPs and
positive-linear aggregates, the value function is submodular (Theorem 47). (ii) Under these conditions, we can reduce the problem to the maximization of a submodular function over a uniform matroid (the uniformity of the matroid is proved in
Lemma 24 when V C is applied a-priori). (iii) We can leverage the work of [127] that
admits a greedy

e
e−1

approximation algorithm. In this section, we develop a greedy
386

algorithm for SNOP-queries that leverages the above three results.
The GREEDY-SNOP algorithm shown below assumes a linear GAP, a positivelinear aggregate, and a zero-starting value function. The algorithm provides

e
e−1

approximation to the SNOP-query problem. As this matches the upper bound of
Theorem 50, we cannot do better in terms of an approximation guarantee.
GREEDY-SNOP(Π, agg, V C, k, g(V )) returns SOL ⊆ V


V
1. Initialize SOL = ∅ and REM = {v ∈ V| g(v) : 1 ∧ pred∈ℓvert (v) pred(v) : 1 |=
V C[V /v]}

2. While |SOL| < k and REM 6= ∅
(a) vbest = null, val = value(SOL), inc(alg) = 0
(b) For each v ∈ REM, do the following
(alg)

i. Let incnew = value(SOL ∪ {v}) − val
(alg)

(alg)

ii. If incnew ≥ inc(alg) then inc(alg) = incnew and vbest = v
(c) SOL = SOL ∪ {vbest }, REM = REM − {vbest }
3. Return SOL

We now analyze the time complexity of GREEDY-SNOP.
Proposition 73. Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and
GAP Π ⊇ ΠS ), the complexity of GREEDY-SNOP is O(k · |V| · F (|V|)) where F (|V|)
is the time complexity to compute value(V ′ ) for some set V ′ ⊆ V of size k.
We note that most likely, the most expensive operation is the computation of
387

value at line 2(b)i. One obvious way to address this issue is by using a non-ground
version of the fixed-point. We address this issue later.
Theorem 55. If SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP
Π ⊇ ΠS ) meets the following criteria:
• Π is a linear GAP
• V C is applied a-priori
• agg is positive linear
• value is zero-starting.
e
Then GREEDY-SNOP is an ( e−1
)-approximation algorithm for the query.

Example 8.5.3. Consider Example 8.4.1 and program Πlin from page 369. Consider the SNOP-query where agg = SUM, V C(V ) = pro(V ), k = 2, and g(V ) =
buys camera(V ). On the first iteration of GREEDY-SNOP, the algorithm computes
the value for all vertices in the set REM AIN IN G which are v1 , v2 , v3 , v5 , v7 , v9 , v10 .
The resulting annotations of the fixed points and aggregates are shown in Table 8.5.
As value(∅) = 0, the incremental increase afforded by v2 is 4.25 – and clearly
the greatest of all the vertices considered. GREEDY-SNOP adds v2 to SOL, removes
it from REM and proceeds to the next iteration. Table 8.6 shows the incremental
increases for the second iteration. As v5 provides the greatest increase, it is picked,
and the resulting solution is {v2 , v5 }.

388

Vertex Atom

v1

v2

v3

v5

v7

v9

v10

buys camera(v1 )

1.0

0.5

0.0

0.5

0.0

0.0

0.0

buys camera(v2 )

0.0

1.0

0.0

0.0

0.0

0.0

0.0

buys camera(v3 )

0.0

1.0

1.0

0.0

0.0

0.0

0.0

buys camera(v4 )

0.0

0.0

0.0

0.0

0.0

0.0

0.0

buys camera(v5 )

0.0

0.0

0.0

1.0

0.0

0.0

0.0

buys camera(v6 )

0.0

0.0

0.0

0.0

0.0

0.0

0.0

buys camera(v7 )

0.0

0.25

0.25

0.0

1.0

0.0

0.0

buys camera(v8 )

0.0

0.5

0.5

0.0

0.0

0.0

0.0

buys camera(v9 )

0.33

0.5

0.33

0.17

0.0

1.0

0.33

buys camera(v10 )

0.0

0.5

0.5

0.0

0.0

0.0

1.0

SUM

1.33

4.25

2.58

1.67

1.0

1.0

1.33

Table 8.5: First iteration of the greedy algorithm.

389

Vertex

Incremental Increase

Incremental Increase

on First Iteration

on Second Iteration

v1

1.33

0.67

v2

4.25

NA

v3

2.58

0.0

v5

1.67

1.67

v7

1.0

0.75

v9

1.0

0.5

v10

1.33

0.67

Table 8.6: Incremental Increases for Both Iterations of GREEDY-SNOP.

390

8.6

Scaling GREEDY-SNOP
This section is dedicated to providing improvements to GREEDY-SNOP in

order to increase speed and/or enhance scalability. In this section, we will present
an approach that does not necessarily select the same vertices as GREEDY-SNOP
called GREEDY-SNOP2. We shall use the term “the greedy algorithm” to describe
one of the two algorithms - noting when it makes a difference.
Most of the notation in this section will specify an iteration of the greedy
algorithm (i.e. for GREEDY-SNOP, this would refer to an iterations of the outer
loop at line 2). Our first piece of notation will be SOLi which specifies the solution
after i iterations of the greedy algorithm. So, for GREEDY-SNOP, SOL0 ≡ ∅ and
SOLi refers to SOL after i executions of line 2c. Likewise, we shall define REMi as
the set of vertices (satisfying some a-priori V C) not picked at the end of iteration i.
The next piece of notation is for the GAP itself, Π. We define Πi as Π ∪
S

v∈SOLi {g(v)

(alg)

: 1 ←}. This allows us to define Ii

= lf p(SΠi ) which is an in-

terpretation that corresponds to the fixed point at each iteration.9 We will also

specify Ii (v) = lf p(SΠi−1 ∪{g(v):1←} ) which is an interpretation at each iteration if
the greedy algorithm picks some vertex v written. We define Ii (v) only for i > 0.
We will also define a special mapping that tells us the increase in annotation if
vertex v is selected by the greedy algorithm at iteration i. We will often treat
this mapping as an interpretation and define it for each ground atom A. Formally,
9

We can substitute the S operator for the T operator if we wished to, but throughout this

section, we shall assume the use of the S operator as it would most likely yield an improvement in
performance.

391

(alg)

INCi (v)(A) = Ii (v)(A) − Ii−1 (A). Unless specified otherwise, we will only be concerned about ground atoms formed with the goal predicate (g(V )). Hence, we can
most likely reduce storage requirements for Ii (v) and INCi (v) in practice. For linear
GAPs, we have the following proposition concerning the increase in annotation.
Proposition 74. For all ground atoms A and vertices v, INCi−1 (v)(A) ≥ INCi (v)(A).
Now we will show that by saving Ii (v) at each iteration, we can potentially
increase the speed at which subsequent fixed points are calculated. First, we consider
the GAP formed from some GAP Π at its least fixed point.
Definition 105. PROG(Π) = Π∪{A : µ|A : µ is a non-ground annotated atom in lf p(SΠ )}
From this, we have the following two lemmas.
Lemma 25. For all programs Π and any atom A, lf p(SPROG(Π) )(A) = lf p(SΠ )(A)
Lemma 26. If Π3 ≡ Π1 ∪ Π2 , then for any atom A,
lf p(SΠ3 )(A) = lf p(SPROG(Π1 )∪PROG(Π2 ) )(A)
This leads us to the following proposition.
Proposition 75. If Π3 ≡ Π1 ∪ Π2 , then for any atom A,
lf p(SΠ3 )(A) = lf p(SPROG(PROG(Π1 )∪PROG(Π2 )) )(A)
So, suppose GREEDY-SNOP is on iteration i − 1 and considers some vertex v
which it does not select. As it calculated the fixed-point, we can save Ii−1 (v) and
easily create PROG(Πi−2 ∪ {g(v) : 1 ←}) using this information. At the end of
392

iteration i − 1 we can also have PROG(Πi−1 ) easily stored as well. Now suppose
vertex v is being considered again on iteration i. Rather than computing the fixed
point of SΠi−1 ∪{g(v):1←} in the straight-forward manner, we can use Proposition 75
and compute the least fixed point of SPROG(Πi−1 )∪PROG(Πi−2 ∪{g(v):1←}) , which will
likely converge faster. We will use the notation PROGi (v) to refer to the program
PROG(Πi−1 ∪ {g(v) : 1 ←}).
Example 8.6.1. Consider Example 8.5.3. Consider what happens when GREEDYSNOP computes value when considering vertex v3 on the second iteration. A quick
look at Table 8.5 reveals that, as vertex atom buys camera(v3 ) is annotated with 1
after the first iteration when v2 was considered. This means that the annotations
assigned when v3 is added after v2 will remain the same (hence, there was no incremental increase when v2 was added in the second iteration). By calculating the
fixed point using SPROG(Π1 )∪PROG(Π0 ∪{g(v3 ):1←}) will cause S to converge after a single
iteration in this case – as the maximum annotations are already assigned by rules
in program PROG(Π1 ).
(alg)

With the Ii

defined, we can specify value at each iteration:
(alg)

vali = agg({Ii

(g(V ))|V ∈ V})

Next, we specify a notation to refer to how much the value has increased after i
(alg)

iterations of the greedy algorithm – the incremental increase – or inci
(alg)

i > 0). Formally, inci

(defined for

= vali − vali−1 . Note that we use the superscript (alg) to

signify that this corresponds with the incremental increase based on the vertex (or
vertices) selected by the greedy algorithm at iteration i. The optimal incremental
393

(opt)

increase – inci

– refers to the incremental increase if the greedy algorithm selects

a single vertex that causes the greatest possible incremental increase to value. Note
(alg)

that GREEDY-SNOP always picks a vertex at each iteration such that inci
(opt)

inci

=

. Consider the following proposition.
(opt)

Proposition 76. inci

(opt)

≤ inci−1 .

We will now define the incremental increase if the algorithm selects a specific
vertex v at iteration i - written inci (v). So, if the greedy algorithm selects vertex v,
(alg)

then inci

= inci (v). Formally, inci (v) = value(SOLi−1 ∪ {v}) − vali−1 . As with

Ii (v), inci (v) is only defined for i > 0. Also based on the definition of submodularity,
we have the following corollary to Proposition 76.
Corollary 14. inci (v) ≤ inci−1 (v).
Corollary 14 allows for a possible speed-up. For example, consider GREEDYSNOP on some iteration i.
(opt)

inci

Suppose, while considering vertex v1 , it computes

(v1 ). Now, it proceeds to the next vertex, v2 . If, on some previous itera(opt)

tion j ≤ i, we saved incj

(opt)

(v2 ) and this value is less than or equal to inci

(v1 ),

then we need not consider v2 as the incremental increase it can provide cannot possibly be greater than v1 . Such a technique is also leveraged in [101] on a different
problem that reduces to the maximization of a submodular function over a uniform
matroid. In that work, this type of improvement led to an increase in speed by a
factor of 700.
However, the storage of the last incremental increase for a given vertex may
still need to be re-calculated after several iterations. One way to avoid this is to
394

obtain an upper bound on inci (v). We can do this with the special interpretation
INCi (v) that we already defined. Consider the following observation for positivelinear aggregates.
Fact 1. inci (v) = agg({INCi (v)(g(v ′ ))|v ′ ∈ V})
Based on Observation 1 and Proposition 74, we can use the following result to
obtain an upper bound for inci (v).
Proposition 77. For j ≤ i, we have:




′

inci (v) ≤ agg {min 1, INCj (v)(g(v )) +

(alg)
Ii−1 (g(v ′ ))



−

(alg)
Ii−1 ((g(v ′ )))|v ′


∈ V}

We shall refer to the quantity




(alg)
(alg)
agg {min 1, INCj (v)(g(v ′ )) + Ii−1 (g(v ′ )) − Ii−1 ((g(v ′ )))|v ′ ∈ V}
(up)

where the j is the annotation increase for vertex v was stored, as inci

(v). Consider

the following example.
Example 8.6.2. Consider Example 8.5.3. Suppose, at the start of the second it(up)

eration, the algorithm computes an inc2 (v) for all v ∈ REM1 . It would simply
use the fixed point computations of the first iteration to create INC1 (v) for each (see
(alg)

Table 8.5). In Table 8.7, we show values assigned by I1

(interpretation after the

first iteration) and INC1 (v5 ) (incremental increase for each vertex atom from v5 ).
(up)

Using the information in Table 8.7, we can easily compute inc2 (v5 ) to be
1.67. In this case, this is a very tight upper bound, matching the actual incremental
increase as depicted in Table 8.6.
395

(alg)

Vertex Atom

I1

INC1 (v5 )

buys camera(v1 )

0.5

0.5

buys camera(v2 )

1.0

0.0

buys camera(v3 )

1.0

0.0

buys camera(v4 )

0.0

0.0

buys camera(v5 )

0.0

1.0

buys camera(v6 )

0.0

0.0

buys camera(v7 )

0.25

0.0

buys camera(v8 )

0.5

0.0

buys camera(v9 )

0.5

0.17

buys camera(v10 )

0.5

0.0

(up)

Table 8.7: Calculating inc2 (v5 ).

396

0.7

0.6

Overall Approximation

0.5

0.4

0.3

0.2

0.1

0

Approximation of Increment

Figure 8.7: Effect on overall approximation given an incremental approximation
factor.
(opt)

We can also use upper bounds on inci (v) to obtain an upper bound on inci
for a given iteration. We present the following observation.
Fact 2.

(opt)
inci

≤ min



(opt)
(up)
inci−1 , maxv∈REMi−1 (inci (v))





(opt)
(up)
We shall refer to the quantity min inci−1 , maxv∈REMi−1 (inci (v)) as inc(opt,up) .

We can use this information to select vertices that cause an incremental increase
within ǫ of optimal. Consider the following result of [60] (Theorem 1).

Theorem 56. Consider the greedy algorithm of [127]. If at each step of the greedy
algorithm, the incremental improvement is approximated within a factor of ǫ, then
the greedy algorithm is an
within

eǫ −1
eǫ

eǫ
eǫ −1

approximation algorithm (i.e. obtains a solution

of optimal).

We plot the relationship between the approximation of the incremental improvement vs. overall approximation in Figure 8.7.

397

So, suppose the user specifies an additional parameter ǫ in the input of the
greedy algorithm that corresponds to the ǫ in Theorem 56. One way to leverage this
approximation is to compute the aggregate after each application of the S operator
and halt computation once the aggregate is within ǫ · inc(opt,up) . We introduce
new notation for each vertex v that takes this partial fixed point computation into
(ǫ)

(ǫ)

(ǫ)

account – PROGi (v), inci (v), and INCi (v), which correspond with the previously
described PROGi (v), inci (v), and INCi (v) respectively. The algorithm APPROXVALUE computes these items for the current iteration.
Theorem 56 can be leveraged in another way that allows for the selection of
multiple vertices in a single iteration of the greedy algorithm. First, we define the
notion of vertex spread which intuitively refers to all other vertices that increase
their annotation when vertex v is added at iteration i. For vertex v at iteration i,
(ǫ)

(ǫ)

with parameter ǫ, we define spreadi (v) = {v ′ ∈ V|INCi (v)(g(v ′ )) > 0}. Using this
information, for a set of vertices, V′ , we can now specify a spread-graph.
Definition 106 (Spread Graph). For a given iteration, i, set of vertices V′ , and
(ǫ)

parameter ǫ, we define the spread-graph GSi (V′ ) = (Vspread , Espread ) as a graph
where:
1. For each vp ∈ V′ , there is a corresponding node vp′ ∈ Vspread and no other nodes
in Vspread .
2. There is an undirected edge (vp′ , vq′ ) ∈ Espread iff for corresponding vertices
(ǫ)

(ǫ)

vp , vq ∈ V′ , spreadi (vp ) ∩ spreadi (vq ) 6≡ ∅
(ǫ)

Returning to the notion of selecting vertices that where inci (v) or inci (v)
398

(alg)

(ǫ)

APPROX-VALUE(v, PROGj (v), PROG(Πi−1 ), agg, inc(opt,up) , vali−1 , Ii−1 , ǫ) (j < i)
(ǫ)

(ǫ)

(ǫ)

returns real number inci (v), function INCi (v), program PROGi (v), and Boolean
f lag.
(ǫ)

(ǫ)

(ǫ)

1. inci (v) = 0, INCi (v) and Itemp assign all atoms 0, Πtemp = PROGj (v) ∪ Πi−1 ,
f lag = false.
(ǫ)

2. While inci (v) < ǫ · inc(opt,up) and ¬f lag
(a) Iprev = Itemp
(b) Let Itemp be SΠtemp applied to Itemp .
(c) f lag = (Iprev == Itemp )
(ǫ)

(d) inci (v) = agg({Itemp (g(V ))|V ∈ V}) − vali−1
(alg)

(ǫ)

3. For all A ∈ A, set INCi (v)(A) = max(0, Itemp (A) − Ii−1 (A))
(ǫ)

4. Set PROGi (v) = PROG(Πi−1 ) ∪ {A : Itemp (A) ← |A ∈ A}
(ǫ)

(ǫ)

(ǫ)

5. Return inci (v), INCi (v), PROGi (v), f lag.

399

are greater than or equal to ǫ · inc(opt,up) , let us define a set cand(ǫ) i = {v ∈
′

(ǫ)

REMi−1 |inci (v) ≥ ǫ · inc(opt,up) }. Let cand(ǫ) i be a subset of cand(ǫ) i . We have
the following theorem.
(ǫ)

Theorem 57. If the nodes in GSi (cand(ǫ) i ) corresponding with elements of cand(ǫ) i

′

(ǫ)

are an independent set of GSi (cand(ǫ) i ), then the greedy algorithm can select all
′

vertices in cand(ǫ) i and still obtain a solution within

eǫ −1
eǫ

of optimal.

So, Theorem 57 allows the greedy algorithm to select more than one vertex
during a given iteration. Further, as the value of ǫ increases, the cardinality of an
(ǫ)

independent set of GSi (cand(ǫ) i ) should also increase, meaning that the user can
use ǫ as a way to trade accuracy for performance.
Although the problem of finding a maximal independent set is NP-hard, several
polynomial approximation algorithms have been studied [69]. Where n is the number
of vertices, a simple greedy approach illustrated in [69] runs in O(n2 ) time and
ensures finding an independent set of at least

n
δ+1

where δ is the average degree of the

graph. Note that for our application n = |cand(ǫ) i |, and we expect |cand(ǫ) i | << |V|.
We present this algorithm, GREEDY-INDEP-SET, below.
There are several modifications that can be made to GREEDY-INDEP-SET. For
example, we can leverage the Fibonacci heap of [49] to obtain a O(n lg n) run time.
Another easy modification to GREEDY-INDEP-SET that may provide better approximations in practice would be to select vertices that not only have a low degree, but
also where the incremental increase is greater. In Example 8.6.3, we describe such
a heuristic. Additionally, in [69], the authors also present a more advanced approx400

GREEDY-INDEP-SET(G = (V, E)) returns V ′ ⊂ V
1. V ′ = ∅
2. While V 6≡ ∅ do the following.
(a) Let v be the vertex in V with the smallest degree. Add v to set V ′ . Remove
v and all its neighbors (and adjacent edges) from G
3. Return V ′

imation algorithm that provides an indecent set within

2
δ+1

of optimal. However,

it is important to note that we need not solve this problem exactly, and we do not
want this to become a dominating operation in the overall algorithm.
So far, we have illustrated a variety of ways to scale GREEDY-SNOP and still
provide an approximation guarantee. We combine the techniques we have described
thus far in GREEDY-SNOP2, illustrated in the following example.
Example 8.6.3. Consider Example 8.4.1 and program Πlin from page 369. Consider the SNOP-query where agg = SUM, V C(V ) = pro(V ), k = 3, and g(V ) =
buys camera(V ) along with the parameter ǫ = 0.4. On the first iteration of GREEDYSNOP2, the algorithm computes the value for all vertices in the set REM AIN IN G
which are v1 , v2 , v3 , v5 , v7 , v9 , v10 . Note that due to step 3 of GREEDY-SNOP2, the
algorithm computes the complete fixed point, just as it did in Example 8.5.3 when we
used GREEDY-SNOP. Refer to Table 8.5 on page 389 for the resulting interpretations.
As inc(opt,up) is 4.25 for the first iteration, the set cand(ǫ) for this iteration includes
all vertices where the incremental increase is greater than or equal to 0.4·4.25 = 1.7.
401

GREEDY-SNOP2(Π, agg, V C, k, g(V ), ǫ) returns SOL ⊂ V
1. Initialize SOL = ∅ and REM = {v ∈ V|g(v) : 1 ∧
(alg)

2. Compute PROG(ǫ) (Π0 ) and I0

V

pred∈ℓvert (v)

pred(v) : 1 |= V C[V /v]}

.
(ǫ)

3. For each v ∈ REM, compute PROG0 (v), and INC1 (v).
4. While |SOL| ≤ k and REM 6= ∅
(a) Set vbest = null, cand(ǫ) = ∅, inc(alg) = 0, val = value(SOL)
(b) For each v ∈ REM, calculate inc(up) (v) as per Proposition 77 using the last saved
INCj (v) that was calculated
(c) Calculate inc(opt,up) as per Observation 2.
(d) Sort the elements of REM from greatest to least by inc(up) (v)
(alg)

(e) For each v ∈ REM where inc(up) (v) > min(incbest , ǫ · inc(opt,up) ), do the following
i. hinc(ǫ) (v), INC(ǫ) (v), PROG(ǫ) (v), f lagi =
APPROX-VALUE(v, PROG(ǫ) (v), PROG(Π), agg, inc(opt,up) , val, I (alg) , ǫ)
ii. If inc(ǫ) (v) ≥ inc(alg) then inc(alg) = inc(ǫ) (v) and vbest = v
iii. If ¬f lag then add v to cand(ǫ)
iv. If f lag then set INC(v) = INC(ǫ) (v)
(f) If cand(ǫ) ≡ ∅ then SOL = SOL ∪ {vbest }, REM = REM − {vbest }
(g) Else do the following:
i. Create GS(ǫ) (cand(ǫ) )
′

ii. Let cand(ǫ) be the subset of REM corresponding with the nodes of an independent set in GS(ǫ) (cand(ǫ) )
′

iii. SOL = SOL ∪ cand(ǫ) , REM = REM − cand(ǫ)
5. Return SOL

402

′

ITERATION 1

ITERATION 2

v2
v3

v1

v10

v5

v7

Figure 8.8: Left: spread graph after iteration 1. Right: spread graph after iteration
2.
Hence, cand(ǫ) = {v2 , v3 }. In Figure 8.8, we show the spread graph created with this
set. As the singletons v2 , v3 are both independent sets, the algorithm can pick either.
Although we do not specify a “tie-breaker” in GREEDY-SNOP2, a reasonable heuristic would be to select the vertex with the greatest incremental increase, which would
be v2 , so we add v2 to SOL.
In the second iteration, we calculate the upper bound using the special interpretation INCi (v) for each vertex v. In Example 8.6.2 on page 395, we show how
to do this for vertex v5 and this is found to be 1.67. This also happens to be the
greatest upper bound for any vertex in REM. Therefore, after computing the fixed
points, we select all vertices whose incremental increase is greater than or equal to
0.4 · 1.67 = 0.67. So, for this iteration cand(ǫ) = {v1 , v5 , v7 , v10 }. The spread graph is
also shown in Figure 8.8. Using the heuristic we described for the first iteration, the
algorithm would select {v5 , v7 } and add them to SOL. Hence the algorithm returns
{v2 , v5 , v7 }. Note that the algorithm was able to totally avoid a third iteration, even
though it was required to (and does) return a set of three vertices.
Proposition 78. The complexity of GREEDY-SNOP2 is O(k · |V| · F (|V|)) where
403

F (|V|) is the time complexity to compute value(V ′ ) for some set V ′ ⊆ V of size k.
Proposition 79. Given a SNOP-query meeting the following criteria:
• Π is a linear GAP
• V C is applied a-priori
• agg is positive linear
• value is zero-starting
Then GREEDY-SNOP2 is an

eǫ
-approximation
eǫ −1

algorithm for the query.

Now we will show a way to possibly further improve scalability while preserving
the approximation guarantee of Proposition 79. Our intuition is to use a spreadgraph on all vertices in REM0 to partition the problem, and then run the greedy
algorithm on each sub-problem. Consider the following definition:
Definition 107 (Disjoint Node Set). Given an un-directed, un-weighted graph G =
(V, E), we say sets V1 , V2 ⊆ V are disjoint node sets iff
1. There is no edge from any node in V1 to a node in V2
2. (or equivalently) Any set of two nodes where one is picked from V1 and one is
picked from V2 is an independent set of G
We provide a simple algorithm for finding disjoint node sets in Appendix G.2.15
(page 609). Now we present GREEDY-SNOP-DIV that uses disjoint node set to partition the problem and still maintain the approximation guarantee of Proposition 79.
404

GREEDY-SNOP-DIV(Π, agg, V C, k, g(V ), ǫ) returns SOL ⊂ V
1. Initialize SOL = ∅ and REM0 = {v ∈ V|g(v) : 1 ∧
V C[V /v]}

V

pred∈ℓvert (v) pred(v)

: 1 |=

(ǫ)

2. For each v ∈ REM0 , calculate set spread1 (v)
(ǫ)

3. Create graph GS1 (REM0 ) = (Vspread , Espread ).
4. Let DN S1 , . . . , DN Sn be the disjoint node sets of Vspread
5. Create predicates set1 , . . . , setn . For all v ∈ V set the weight seti (v) to 1 iff the
corresponding node in Vspread is in DN Si and 0 otherwise.
6. Create n new SNOP queries where for query i, the input is Π, agg, V C(V ) ∧
seti (V ), min(k, |DN Si |), g(V ), ǫ.
7. Let SOL(1) , . . . , SOL(n) be the solutions to each SNOP query as returned by
GREEDY-SNOP or GREEDY-SNOP2. Let SOLall be the union of all these sets.
With each vertex v ∈ SOLall , let inc(v) be the incremental increase caused by that
vertex in its SNOP-query.
8. Sort SOLall by inc(v) from greatest to least
9. Return the top k elements of SOLall .

405

(ǫ)

In the below example, we use the disjoint node sets of GS0 (REM0 ) to partition
the problem.
Example 8.6.4. Consider Example 8.3.2 on page 355. Recall, that in this problem,
20 vertices, v1 , . . . , v20 meet an a-priori V C and thus comprise the set REM0 (see
(ǫ)

Figure 8.2). Suppose, for each vi ∈ REM0 , we find the set spread1 (vi ) and the
results are shown by the shaded ovals in Figure 8.6.4.
Using Figure 8.9(top), we can easily see the intersection of two sets of vertices corresponding with vertex spreads. For example, there are 4 vertices in the set
(ǫ)

(ǫ)

(ǫ)

(ǫ)

spread1 (v18 )∩spread1 (v20 ), while there are 8 vertices in spread1 (v1 )∩spread1 (v2 ).
(ǫ)

Based on these intersections, we can obtain the spread graph GS1 (REM0 ) – shown
in Figure 8.9(bottom).
Based on the spread graph of Figure 8.9(bottom), there are 5 disjoint node sets
- this is how GREEDY-SNOP-DIV will partition the problem:
DN S1 = {

v1 , v2 , v3 , v4 , v5

}

DN S2 = {

v6 , v7 , v8 , v9 , v10

}

DN S3 = { v11 , v12 , v13 , v14 , v15 }
DN S4 = {

v16 , v17

}

DN S5 = {

v18 , v19 , v20

}

So, GREEDY-SNOP-DIV would then create predicates set1 , set2 , set3 , set4 , set5
for each of the disjoint node sets above. The vertex atoms formed with these predicates are assigned 1 iff the vertex is in the corresponding disjoint node set. For

406

7

1

6

8

3
10

2

9
4

5

18

17
16
15

12

13

11

20

19

14

7

6

1

8
3

10
9

2
4

17

16

5

15

12

18
13

11

19

20

14

Figure 8.9: Top: Social Network for the painting company with vertex spread shown
(ǫ)

as shaded ovals. Bottom: Spread graph GS1 (REM0 ) for the painting company
example.

407

example, set1 (v1 ) and set4 (v16 ) are annotated with 1 while set4 (v1 ) and set1 (v16 ) are
annotated with 0.
Recall that the original V C was prior(V ) (see Example 8.3.2). We now create
5 new SNOP queries with the following a-priori vertex conditions (i.e. V Ci is the
vertex condition for query i).

Query 1: V C1 = prior(V ) : 1 ∧ set1 (V ) : 1
Query 2: V C2 = prior(V ) : 1 ∧ set2 (V ) : 1
Query 3: V C3 = prior(V ) : 1 ∧ set3 (V ) : 1
Query 4: V C4 = prior(V ) : 1 ∧ set4 (V ) : 1
Query 5: V C5 = prior(V ) : 1 ∧ set5 (V ) : 1
The algorithm would then take the results of the 5 queries obtained from runs
of GREEDY-SNOP2 and order the union of all solutions by the incremental increase.
GREEDY-SNOP-DIV would then return the top k vertices.
Proposition 80. Given a SNOP-query meeting the following criteria:
• Π is a linear GAP
• V C is applied a-priori
• agg is positive linear
• value is zero-starting
Then GREEDY-SNOP-DIV is an

eǫ
-approximation
eǫ −1

408

algorithm for the query.

We notice that GREEDY-SNOP-DIV allows us to partiiton the problem in way
where for each of the n disjoint node sets can be handled by an instance of GREEDYSNOP2 on a different machine. Further, we can maintain a “master process” where
each of the n instances of GREEDY-SNOP2 can report their latest vertices added
to the solution and the corresponding incremental increase. This can allow the
master process to terminate the instances of GREEDY-SNOP2 early (i.e. once the
incremental increase of a vertex picked by an instance of GREEDY-SNOP2 is to low
to be added to the final solution).

8.7

Implementation and Experiments
We have implemented the GREEDY-SNOP algorithm in 660 lines of Java code

by re-using and extending the diffusion modeling Java library of [17] (approx 35K
lines of code). Our implementation uses multiple threads in the inner loop of the
GREEDY-SNOP algorithm to increase efficiency. All experiments were executed
on the same machine with a dedicated 4-core 2.4GHz processor and 22GB of main
memory. Times were measured to millisecond precision and are reported in seconds.

8.7.1

Experimental Setting

Data set. In order to evaluate GREEDY-SNOP, we used a real world dataset based
on a social network of Wikipedia administrators and authors. Wikipedia is an online
encyclopedia collaboratively edited by many contributors from all over the world.
Selected contributors are given privileged administrative access rights to help main409

tain and control the collection of articles with additional technical features. A vote
by existing administrators and ordinary authors determines whether an individual is
granted administrative privileges. These votes are publicly recorded. [100] crawled
2794 elections from the inception of Wikipedia until January 2008. The votes casted
in these elections give rise to a social network among Wikipedia administrators and
authors by representing a vote of user i for user j as a directed edge from node i to
j. In total, the dataset contains 103, 663 votes (edges) connecting more than 7000
Wikipedia users (vertices). Hence, the network is large and densely connected.

SNOP-Query. In our experiments, we consider the hypothetical problem of finding
the most influential administrators in the Wikipedia social network described above.
We treat votes as a proxy for the inverse of influence. In other words, if user i
voted for user j, we assume user j (intentionally through lobbying or unintentionally
through the force of his contributions to Wikipedia) influenced user i to vote for
him. All edges are assigned a weight of 1. Our SNOP-queries are designed as per
the following definition.
Definition 108 (Wikipedia SNOP-Query). Given some natural number k > 1, a
Wikipedia SNOP query, W Q(k) is specified as follows:
• agg = SUM – the intuition is that the aggregate provides us an expected number
of vertices that are influenced.
• V C = true – we do not use a vertex condition in our experiments
• k as specified by the input
410

• goal(V ) = inf luenced(V )
Diffusion Models Used. We represented the diffusion process with two different
models: one tipping and one cascading.
• Cascading diffusion model. We used the Flickr Diffusion Model ( Diffusion
Model 8.4.5 on page 376) described in Section 8.4.2. In this model, a constant
parameter α represents the “strength” or “likelihood” of influence. The larger the
parameter α the higher the influence of a user on those who voted for her.

• Tipping diffusion model. [21] shows that there is a relationship between the
likelihood of a vertex marking a photo as a favorite and the percentage of their
neighbors that also marked that photo as a favorite. This implies a tippingmodel (as in Section 8.4.1). We apply the Jackson-Yariv mode (i.e. Diffusion
Model 8.4.2) with B equated to inf luence. The predicate e corresponds to vote.
b

For each vertex Vj ∈ V, we set the benefit to cost ratio ( cjj ) to 1. Finally, the
function γ defined in the Jackson Yariv model is the constant-valued function (for
all values of x):
γ(x) = α.
This says that irrespective of the number of neighbors that a vertex has, the
benefit to adopting strategy B (i.e. inf luence) is α. Therefore, the resulting
diffusion rule for the linear Jackson-Yariv model is:
P
j Xj
inf luence(V ) : α · P
←
j Ej

^

Vj |(Vj ,V )∈E

(vote(Vj , V ) : Ej ∧ inf luence(Vj ) : Xj )

411

.-&/#$'%012%3"4$2$&5%)%*+,-$'%
&!!!!"
)*+,*-./0"1.23+.4/"
5.66./0"1.23+.4/"

!"#$%"&%'$(%

%#!!!"
%!!!!"
$#!!!"
$!!!!"
#!!!"
!"

!'!#"

!'$"

!'$#"

!'%"

!'%#" !'&"
)%*+,-$%

!'&#"

!'("

!'(#"

!'#"

Figure 8.10: Runtimes of GREEDY-SNOP for different values of α and k = 5 in both
diffusion models
For both models, we derive a unique logic program for each setting of the
parameter α. The parameter α depends on the application and can be learned from
ground truth data. In our experiments, we varied α to avoid introducing bias.

8.7.2

Experimental Results

Run-time of GREEDY-SNOP with varying α and different diffusion models. Figure 8.10 shows the total runtime of GREEDY-SNOP in seconds to find the
set of k = 5 most influential users in the Wikipedia voting network for different
values of the strength of influence parameter α. We varied α from 0.05 (very low
level of influence) to 0.5 (very high level of influence) for both the cascading and
tipping diffusion model. We observe that higher values of α lead to higher runtimes
as expected since the scope of influence of any individual in the network is larger.
Furthermore, we observe that the runtimes for the tipping diffusion model increase
412

!"#$%0-%5&1%6&1"2"1*34'%
)!!!!"
!"#$%"&%'$(%

(!!!!"
'!!!!"

*+,-+./01"2/34,/50"
6/77/01"2/34,/50"

&!!!!"
%!!!!"
$!!!!"
#!!!!"
!"
'"

#!"
#'"
$!"
)*#+$,%-.%(-#/*0$1%"&1"2"1*34'%

$'"

Figure 8.11: Runtimes of GREEDY-SNOP for different values of k and α = 0.2 in
both diffusion models

!"#$%2$3%)&*"."*/01%
&#!!"
!"#$%"&%'$(%

&!!!"
%#!!"
%!!!"
$#!!"
$!!!"
,-./-0123"4156.172"
8199123"4156.172"

#!!"
!"

$" %" &" '" #" (" )" *" +" $!"$$"$%"$&"$'"$#"$("$)"$*"$+"%!"%$"%%"%&"%'"%#"
)&*$+%,-%)&*"."*/01%

Figure 8.12: Time per iteration of GREEDY-SNOP for α = 0.2 in both diffusion
models

413

more slowly with α compared to the cascading model.

Run-time of GREEDY-SNOP with varying k. For the next set of experiments,
we keep the strength of influence fixed to α = 0.2 and varied k which governs the
size of the set of influencers. Figure 8.11 reports the runtime of GREEDY-SNOP for
the query W Q(k) with k = 5, 10, 15, 20, 25. For the cascading model, the runtime
is approximately linear in k a curve-fitting analysis using Excel showed a slight superlinear trend (even though the figure itself looks linear at first sight). Figure 8.12
shows the time taken to execute each of the 25 iterations of the outer loop for the
query W Q(25) with α = 0.2. Note that each subsequent iteration is more expensive
than the previous one since the size of the logic programs to consider increases with
the addition of each ground atom inf luence(Vi ). However, we also implemented the
practical improvement of “lazy evaluation” of the submodular function as described
in [101]. This improvement, which maintains correctness of the algorithms, stores
previous improvements in total score and prunes the greedy search for the highest
scoring vertex as discussed. We found that this technique also reduced the runtime
of subsequent iterations.

Our experimental results show that we can answer SNOP queries on large
social networks. For example, computing the set of five most influential Wikipedia
users in the voting network required approximately 2 hours averaged over the different values of α in the tipping diffusion model.

414

8.8

Chapter 8 Related Work
There has been extensive work in reasoning about diffusion in social networks.

However, to our knowledge, there is no work on the relationship between logic
programming and social networks. Moreover, there is no general framework to
solve social network optimization problems that can take a broad class of diffusion
models as input. We believe this work represents the first deterministic framework
for representing generalized diffusion models that allows for different properties and
weights on vertices and edges. Previously, the authors presented the framework of
SNOPs in [159]. However, this brief technical communication did not include either
our exact or approximate algorithms, an implementation, experiments, the SNOPALL problem, many of the complexity results, or many of the constructions seen in
this chapter (such as the homophilic diffusion models and big-seed marketing).

8.8.1

Related Work in Logic Programming

We first compare our work with annotated logic programming [86, 85, 168]
and its many extensions and variants [175, 88, 107, 109, 31, 82, 110]. There has
been much work on annotated logic programming and we have built on the syntax
and semantics of annotated LP. However, we are not aware of any work on solving
optimization queries (queries that seek to optimize an aggregate function) w.r.t.
annotated logic programming.
There are a few papers on solving optimization problems in logic programming. The best of these is constraint logic programming [172] which can embed

415

numerical computations within a logic program. However, CLP does not try to find
solutions to optimization problems involving semantics structures of the program
itself. Important examples of constraint logic programming include [51, 117] where
annotated LP is used for temporal reasoning, [99] assumes the existence of a cost
function on models. They present an analysis of the complexity and algorithms to
compute an optimal (w.r.t. the cost function) model of a disjunctive logic program
in 3 cases: when all models of the disjunctive logic program are considered, when
only minimal models of the disjunctive logic program is considered, and when stable
models of the disjunctive logic program are considered. In contrast, in this chapter, there are two differences. First, we are considering GAPs. Second, we are not
looking for models of a GAP that optimize an objective function - rather, we are
trying to find models of a GAP together with some additional information (namely
some vertices in the social network for which a goal atom g(v) : 1 is added to the
GAP) which is constrained (at most k additional atoms) so that the resulting least
fixpoint has an optimal value w.r.t. an arbitrary value function. In this regard, it
has some connections with abduction in logic programs[41], but there is no work on
abduction in annotated logic programs that we are aware of or work that optimizes
an arbitrary objective function.
Our chapter builds on many techniques in logic programming. It builds upon
non-ground fixpoint computation algorithms proposed by [114] and later extended
for stable models semantics [59, 39], and extends these non-ground fixpoint algorithms to GAPs and hen applies the result to define the SNOP-Mon algorithm to
find answers to SNOP-queries which, to the best of our knowledge, have not been
416

considered before.

8.8.2

Work in Social Networks

[81] is one of the classic works in this area where a generalized diffusion framework for social networks is proposed. This work presents two basic diffusion models
– the linear threshold and independent cascade models. Both models utilize random
variables to specify how the diffusion propagates. These models roughly resemble
non-deterministic versions of the tipping and cascading models presented in Section 8.4 of this chapter. Neither model allows for a straightforward representation
of multiple vertex or edge labels as this work does. Additionally, unlike this chapter,
where we use a fixed-point operator to calculate how the diffusion process unfolds,
the diffusion models of [81] utilize random variables to define the diffusion process
and compute the expected number of vertices that have a given property. The authors of [81] only approximate this expected value and leave the exact computation
of it as an open question. Further, they provide no evidence that their approximation has theoretical guarantees.
The more recent work of [23] showed this computation to be #P-hard by a
reduction from S-T connectivity, which has no known approximation algorithm.
This suggests that a reasonable approximation of the diffusion process of [81] may
not be possible. This contrasts sharply with the fixed-point operator of [86], which
can be solved in PTIME under reasonable assumptions (which are present in this
chapter). [81] focus on the problem of finding the “most influential nodes” in the

417

graph – which is similar in intuition to a SNOP query. However, this problem only
looks to maximize the the expected number of vertices with a given property, not
a complex aggregate as a SNOP query does. Further, the approximation guarantee
presented for the “most influential node” problem is contingent on an approximation
of the expected number of vertices with a certain property, which is not shown (and,
as stated earlier, was shown by [23] to be a #P-hard problem).
In short, the frameworks of [23] and [81] cannot handle arbitrary aggregates
nor vertex conditions nor edge and vertex predicates nor edge weights as we do.
Nor can they define an objective function using a mix of the aggregate and the g(−)
predicate specified in the definition of a SNOP-query.

8.9

Chapter Summary
Social networks are proliferating rapidly and have led to a wave of research on

diffusion of phenomena in social networks. In this chapter, we introduce the class
of Social Network Optimization Problems (SNOPs for short) which try to find a set
of vertices (where each vertex specifies some user specified vertex condition) that
have cardinality k or less (for a user-specified k > 0) and that optimize an objective
function specified by the user in accordance with a diffusion model represented
via the well-known Generalized Annotated Program (GAP) framework. We have
used specific examples of SNOP-queries drawn from product adoption (cell phone
example) and epidemiology.
The major contributions of this chapter include the following:

418

• We showed that the complexity of answering SNOP-queries as NP-Complete and
identified the complexity classes associated with related problems (under various
restrictions). We showed that the complexity of counting the number of solutions
to SNOP-queries is #P-complete.
• We proved important results showing that there is no polynomial-time algorithm
that computes an α-approximation to a SNOP-query when α ≥

e
.
e−1

• We described how various well-known classes of diffusion models (cascading, tipping, homophilic) from economics, product adoption and marketing, and epidemiology can be embedded into GAPs.
• We presented an exact-algorithm for solving SNOP-queries under the assumption
of a monotonic aggregate function.
• We proved that SNOP-queries are guaranteed to be submodular when the GAP
representing the diffusion model is linear and the aggregate is positive-linear. We
were able to leverage this result to develop the GREEDY-SNOP algorithm that
runs in polynomial-time and that achieves the best possible approximation ratio
of

e
e−1

for solving SNOPs.

• We develop the first implementation for solving SNOP-queries and showed it
could scale to a social network with over 7000 vertices and over 103,000 edges.
Our experiments also show that SNOP-queries over tipping models can generally
be solved more quickly than SNOP-queries over cascading models.
Much work remains to be done and this chapter merely represents a first step
419

towards the solution of SNOP-queries. Clearly, we would like to scale SNOP-queries
further for social networks consisting of millions of vertices and billions of edges.
This will require some major advances and represents a big challenge.

420

Chapter 9
Future Work

There are many interesting questions that remain to be studied regarding
spatio-temporal aspects of an agent’s behavior. In this section, we briefly outline
some important open questions relating to the work presented in this dissertation.
First, let us discuss extensions to reasoning about time using APT logic. Based
on the framework presented in Chapter 2, we devised a fixpoint operator in Chapter 3 that provides sound, but incomplete solutions to consistency and entailment
problems. Given a propositional formula F at time t (together forming a time formula F : t) and an APT program K, our operator was able to produce a probability
bound [ℓ, u] such that K entails F : t : [ℓ, u]. As our operator is only sound, we
do not guarantee that the bounds [ℓ, u] are the tightest possible. Further, even if
we could obtain the tightest probability bounds possible, there is no guarantee on
how close ℓ is to u. Hence, if we obtain the probability bounds [0.4, 0.7], what can
we say about the likelihood of F occurring at time t? The work of [18] considers a
novel approach for dealing with the problem of the action-probabilistic programs of

421

[83]1 . Using random walks over the space of solutions to the query, they were able
to produce a histogram of the the semantic structures for the query formula. As it
is easy to compute the probability associated with each semantic structure, the authors of that paper were able to create a histogram of number of semantic structures
with a given probability. Therefore, if a query returned a bounds of [0.4, 0.7], they
may also know that 80% of the semantic structures had a probability in the range
[0.67, 0.7], for example. A key issue encountered in [18] was the dimensionality of
the space, which was exponenetial in the number of ground atoms. With APT logic,
the problem is greatly increased, as the number of dimensions would be exponential
in the product of number of ground atoms and time points. Most likely, heuristic
methods for dimensionality reduction (perhaps by leveraging the FELC or WELC
constraints of Chapter 2) would have to be employed in such work.
As far as the geospatial abduction problems of Chapters 4-6, an important
direction would be to consider the case where the observations were caused by
more than one agent. For example, in our experiments described in Chapter 45, we considered attacks and caches from Iranian-sponsored militants in Iraq. We
implicitly assumed that these groups conducting attacks would operate in a similar
manner and would share areas used for caches. As the results of our experiments
were generally encouraging, this was most likely a valid assumption. However,
suppose we have a set of attacks that could come from a variety of groups, which
may not all operate in a similar manner and may not cooperate with each other.
In such a case, it may not be appropriate to apply the algorithms of those chapters
1

Time is not considered in [83] or [18].

422

as-is. There are two approaches to this variant: (1) cluster the attacks beforehand
and solve an GAP for each cluster or (2) extend GAPs to a probabilistic and/or
multi-agent case. Both raise interesting technical and practical issues.
Our work on optimally selecting agent actions in Chapters 7-8 looked at picking
a set of agenst action with respect to some structure that maximizes an aggregate
function. For the geospatial optimization problems of Chapter 7, although we were
able to devise a polynomial-time approximation algorithm, it still has a runtime
linearly proportional to the size of the map. For a large map, or a map of fine
granularity, this may not be practical. Therefore, an obvious direction in future
work is to devise a method to scale algorithms for answering geospatial optimization
queries. For queries where we considered a diffusion process (the SNOP queries of
Chapter 8), we did provide some methods to increase scalability. However, there
is another issue with SNOPs. Although we could show embeddings for a wide
variety of diffusion processes, these diffusion processes were monotonic in nature.
For example, the confidence that vertex v has some property increases with each
application of the fixpoint operator. This monotonic nature is what allowed us to
leverage the generalized annotated programs of [86]. However, there are diffusion
process such as voter models in physics [162] and evolutionary graph theory in
biology [105] that are not monotonic in nature - hence the confidence vertex v has
some property may increase or decrease at each time step. Computing the outcome
of such process is difficult - in [105], the authors show evolutionary graph problems
to be NP-hard. Currently, most work in this area relies on simulation. Hence,
the first challenge with non-monotonic diffusion is to develop an efficient algorithm
423

to determine the outcome of the diffusion process. One way to do this would be
to introduce negation into the logic program. However, in this case we will most
likely lose some computational properties that allow us to approximate SNOPs.
Another is to adopt the “competitive” diffusion framework of [17]. However, it is
unclear if voter model and/or evolutionary graph problems can be embedded into
this framework. The second challenge is to answer a SNOP-query with respect
to these problems. This most likely will add an additional layer of complexity.
There are other aspects of SNOPs that can be explored as well. We note that our
framework can be used to solve problems where “homophilic” [9] or non-network
effects – even at the same time as network diffusion. Although the algorithms of
this dissertation can be applied to these problems in a straight-forward manner, it
remains an open question to create a tailored, efficient approach to these type of
problems. Such an approach would aide greatly in “big-seed” marketing [177] that
combines both viral-marketing along with mass-marketing.
Hence, although this paper explored many aspects of spatio-temporal reasoning about agent behavior, there are still some interesting open questions that should
be explored.

424

Chapter 10
Conclusion

In this dissertation, we examined several aspects of reasoning regarding spatiotemporal agent behavior. These included determining the probability that an agent
takes a given action at a certain time, abducing geospatial phenomenon, and optimizing the selection of an agents actions.
To determine the probability of an agent taking a given action at a given time,
we have introduced a new framework for temporal-probabilistic reasoning called
Annotated Probabilistic Temporal (APT) Logic. This logic-programming based approach allows one to create and/or automatically learn models of agent behavior
based on past actions and determine the probability of some action at a certain time
by performing an entailment query. Notably, unlike other formalisms for reasoning
about time and probability together, APT-logic does not make Markov or independence assumptions. Despite not making these assumptions, we have designed and
implemented an approximation technique based on a sound, but incomplete fixpoint
operator (we resort to approximation techniques as we show answering such a query

425

is NP-complete). Although incomplete, in our experiments, the implementation of
this operator was shown to find tight bounds on entailment formualae. The calculation runs in approximately linear time in the size of the model, which is a significant
improvement over exact methods for solving these queries which require solving a
linear program with an exponential number of variables.
To reason about the spatial aspects of an agent’s behavior, we looked at observed manifestations of the behavior (called “observations”) that must have been
caused by some other, unobserved, geospatial phenomenon (called “partners”).
Finding a set of partners corresponding to the observations is an instance of a
problem known as “geospatial abduction.” In this dissertation, we have created a
framework for this scenario and explored the problem of finding a set of partners
given a set of observations and constraints on the relationship between the two. Unfortunately, as we show many such problems to be NP-complete, we again resorted
to approximation techniques. In addition to showing reductions from well-known
problems, we created a novel greedy algorithm, that while maintaining an approximation guarantee, allows for the use of additional heuristics. We implemented this
algorithm in a software package called “SCARE” and showed that it significantly
out-performed naive techniques for locating weapons caches associated with attack
sites using a counter-insurgency data-set. We then explored a variant of a geospatial
abduction problem that requires the solution to return regions rather than pin-point
locations. Again, as this problem was NP-complete, we had to resort to approximation techniques. We note that a special case of this problem actually reduces to
circle-covering, for which there are known approximation techniques. We also in426

troduced an approximation technique for a more general case, implemented it, and
showed it to provide viable results on real-world data.
As a geospatial abduction problem, like many other abduction problems, can
have multiple solutions, a natural question is “how does one solve such problems
when the adversary has knowledge of your algorithm?” We explore this situation
where the adversary has a probability distribution of the solutions to a geospatial
abduction problem and can position his partners ahead of time in a manner to avoid
discovery by the agent. This problem, again, is NP-complete. However, we show it
can reduce to a mixed linear-integer program that can be made more tractable by
significantly reducing the number of variables and using parallelization. We show
the viability of this approach by implementing this algorithm using a linear-integer
program solver. A natural complement to this problem that we explored is how an
agent should select partners given a probability distribution of how the adversary
selected locations. We show that this problem reduces to the maximization of a
submodular function over a uniform matroid and can be solved using several wellknown approximation techniques. We also presented an implementation.
We then studied optimal selection of agent actions. The first problem of this
type was a “geospatial optimization” problem. Here the agent has a set of actions
that modify attributes of a geospatial region and he wishes to select a limited number of such actions (with respect to some budget) in a manner that either satisfies
some goal (goal-based geospatial optimization) and/or maximizes a benefit function
(benefit-maximizing geospatial optimization). Additionally, there are certain combinations of actions that cannot be performed together. We proved that both goal427

based and benefit-maximizing geospatial optimization problems are NP-complete
under reasonable assumptions and proved theoretical limits on their approximation.
We then develop algorithms for solving such problems - either exactly or within a
certain factor of optimal.
We also look at optimally selecting agent actions in the presence of a diffusion
process under the structure of a social network. To address this topic, we presented
an annotated-program based framework for studying social network optimization
problems - that is given a social network (a weighted, directed graph with vertex
and edge labels), and a diffusion process, can we identify the vertices of the network
that cause a given phenomenon to spread to the maximum extent possible. This
generalized framework allows great flexibility is expressing several well-known diffusion models in the areas of marketing, information spread, and disease. We show
queries relating to this problem to be strongly NP-complete as it can encode the
max-k-cover problem. However, we also show that if the annotated program representing the diffusion process is “linear” then the value oracle associated with this
query is submodular - which allows us to leverage a greedy approach that provides
the best approximation guarantee for such a query unless P=NP. Using a variety
of techniques, we show that this algorithm can be scaled to large networks and we
provide an implementation as well.

428

Appendix A
Appendix for Chapter 2

A.1
A.1.1

Additional Results
Frequency Equivalence under the PCD Restriction

While obtaining a noticeable speedup for constrained programs using FELC, we
were still required to conduct an operation exponential in the product of atoms and
time points. In this subsubsection we leverage the PCD restrictions from Definition
3.5 to ensure that there are no empty frequency-equivalence classes. First, we present
some notation to describe sets of threads associated with each rule. Then, we
show how the PCD restrictions allow us to leverage FELC without preprocessing.
Finally, as the PCD requirements do not permit annotated formulas, we present
some methods to allow for annotated formulas as well.
Our key intuition is noticing that the result of Lemma 3.6 uses the axioms to
ensure that we can create threads where the frequency function for each rule equals
0 or 1. Then, we use the one-tailed restriction that PCD’s provide us in order to
429

ensure that β = 1 (it is not hard to prove a similar theorem where α is set to 0).
With this one-tailed restriction, threads with a frequency function of 0 are outside
of [α, β] and threads with a frequency of 1 will be inside this range.
To help us in our discussion of how FELC can leverage PCD programs, we
present some notation used in describing classes of frequency equivalent threads;
associated thread subsets allow us to formalize the notion of a frequency-equivalent
class of threads. We provide the definition below.
Definition 109 (Associated Thread Subsets (ATS)). For a given constrained rule,
fr

ri = F ֒→ G : [∆t, ℓ, u, α, β], the Associated Thread Subsets (ATS) are the subsets
of the set of threads considered in the satisfaction of ri :
• ATSi is the set of threads {Th ∈ T | α ≤ fr(Th, F, G, ∆t) ≤ β}.
• ATSi is the set of threads {Th ∈ T | Th ∈
/ ATSi }.
Intuitively, a thread is in a rule’s associated thread subset (ATS) if its frequency
function with respect to that particular rule falls within that rule’s [α, β] frequency
function bounds. Threads not meeting this criteria are said to be in the complement
associated thread subset (ATS) for that rule.
Normally, in this subsubsection, we refer to a given frequency equivalence class
as cls where s ∈ [0, 1]m - where m is the number of rules in the APT-program. With
this notation, the ATS of every rule (ri ) where si = 1 is intersected with the ATS of
every rule where si = 0. Formally,
cls =

(

\

si =1

ATSi

)

430

∩

(

\

si =0

ATSi

)

One can easily see that a frequency equivalence class is empty if the intersubsubsection of any two subsets described above are empty. Consider the following
example.
Example A.1.1. Consider the discussion on the two rules from Kstock in Example
3.11.
pfr

Let r2 = sec rumor ∧ earn incr(10%) ֒→ stock decr(10%) : [2, 0.65, 0.97, 0.7, 1.0] and
pfr

r3 = sec rumor∧earn incr(10%) ֒→ stock decr(10%)∧cfo resigns : [2, 0.68, 0.95, 0.7, 0.8].
Recall that in Example 3.11 we determined that for any given thread, it was not possible for the pf r associated with r3 to exceed the pf r associated with r2 . Therefore,
as β2 = 1, we can conclude that ATS2 ∩ ATS3 ≡ ∅.
We can now examine how to utilize the PCD restriction to ensure that all
frequency equivalence classes are non-empty. First, using the one-tailed restriction
fri

described earlier, consider rule ri = Fi ֒→ Gi : [∆ti , ℓi , ui , αi , 1] (where αi > 0).
For thread Th, if fri (Th, Fi , Gi , ∆ti ) = 1 then Th ∈ ATS. If fri (Th, Fi , Gi , ∆ti ) = 0
then Th ∈ ATS. However, we then must add most of the other PCD restrictions to
ensure that the thread construction of the 0 and 1 threads can occur for each rule.
In fact, the only PCD restriction not needed is the sixth restriction that sets u = 1
for all rules.
Two of the PCD restrictions are particularly limiting. One requires that for
each rule pre-condition there exists a unique world that only satisfies that precondition. The second is similar: there exists a unique world that does not satisfy
any rule’s pre or post-conditions. It may, however, be possible to specify such
431

restrictions as part of a procedure to obtain such rules. Regardless, once one has
an APT-logic program satisfying the PCD restrictions, one can be guaranteed the
below property, which we will shortly see to be useful.
Theorem 58. Suppose APT-Logic program, K =

Sm

i=1

fri

{ri } where ri = Fi ֒→ Gi :

[∆ti , ℓi , ui , αi , βi ] meets PCD restrictions 1-6 of Definition 3.5. Then, for all binary
numbers s ∈ [0, 1]m , frequency equivalence classes cls = {
contains at least one thread.

T

si =1

ATSi }∩{

T

si =0

ATSi }

Before investigating the utility of the above theorem, we notice that restriction 4 creates an issue if we decide to include annotated formulas. Recall that, by
Theorem 2.20, to create a constrained rule that is equivalent to an annotated formula, we must set the pre-condition to TRUE. Additionally, PCD programs do not
allow qf r. Clearly, this causes the above Theorem to be not applicable under that
circumstance. However, we can provide a similar set of restrictions that will allow
annotated formulas. The intuition for the proof is simple, we simply extend tmax to
be as long as the maximum t value in any of the annotated formulas in question,
and add some restrictions about the existence of satisfying worlds which resemble
those of the last theorem extended to annotated formulas.
Corollary 15. For a constrained APT-Logic program, K =
fri

Sm

i=1

{ri } where ri =

Fi ֒→ Gi : [∆ti , ℓi , ui , αi , βi ] and set of annotated formulas, F ACT S =
where afj = Qj : [t′j , ℓ′j , u′j ] with the following restrictions,
1. K meets PCD restrictions 1-4 of Definition 3.5
2. tmax ≥ maxj (t′j ) + |K| · maxi (∆ti )
432

Sk

j=1

afj

3. ∃ world w∅ such that ∀i ∈ [0, m] w∅ 6|= Fi , w∅ 6|= Gi , and ∀j ∈ [0, k] w∅ 6|= Qj
4. ∀j ∈ [0, k], there exists world qwj such that qwj |= Qj and ∀i ∈ [0, m] qwj 6|=
Fi .
5. No two annotated formulas in F ACT S are at the same timepoint.
Then for all s ∈ [0, 1]m+k , frequency equivalence classes cls =
T

si =0

	
ATSi contains at least one thread.

T

si =1

	
ATSi ∩

Again, we have a potentially problematic restriction in that we do not allow
multiple annotated formulas in the same time point (restriction 5). We can relax this
restriction with the following corollary to determine if a given frequency equivalence
class exists or not. Essentially, the non-emptiness of a frequency equivalence class
that contains intersubsubsections of ATS or ATS sets for annotated formulas is
determined by the existence of worlds satisfied by the non-annotated portion of the
annotated formulas that share the same time point.
Corollary 16. Assume we have the following:
• Constrained APT-Logic program, K =

Sm

i=1

• Set of annotated formulas, F ACT S =
(q)

• ∀j ∈ [1, k], we define ATSj

Sk

fri

{ri } where ri = Fi ֒→ Gi : [∆ti , ℓi , ui , αi , βi ]

j=1

(q)

and ATSj

qfr

afj where afj = Qj : [tj , ℓj , uj ]

to be the ATS and ATS for rule r =

TRUE ֒→ Qj : [t, ℓj , uj , 1, 1] created from annotated formula afj ∈ F ACT S using
qf r
• Restrictions 1-5 from Corollary 15
433

Then, for all subsets of SAM ET IM E ⊆ F ACT S, where for all af1 , af2 ∈ SAM ET IM E,
t1 = t2 ; for all strings s2 ∈ [0, 1]|SAM ET IM E| all frequency equivalence classes, cl that
intersect {

T

(q)

s2i =1

ATSi } ∩ {

T

(q)

s2i =0

ATSi } are non-empty iff:

∃ world wp such that for all afi ∈ SAM ET IM E where s2i = 1, wp |= Qi and for
all afj ∈ SAM ET IM E where s2j = 0, wp 6|= Qj .
Theorem 58, and Corollaries 15 and 16 provide restrictions that force all
frequency-equivalence classes to be non-empty. This allows us to leverage FELC
without any type of pre-processing algorithm, which we have shown to be expensive. As stated earlier, PCD restrictions could be specified by a tool used to learn
the rules from a given data-set.

A.1.2

The ALC-ENT Algorithm for Entailment

We present an algorithm for alternate linear constraints, ALC-ENT, that computes entailment using linear constraints other than SLC.
Proposition 81. If K entails r, then ALC-ENT returns ENTAILS. If K does not
entail r, then ALC-ENT returns NOT ENTAILS.
In the worst case, to solve ALC-ENT requires constructing the linear constraints
once and solving the linear program twice.
Example A.1.2. Recall that in Example A.1.1 we presented rules
pfr

r2 = sec rumor ∧ earn incr(10%) ֒→ stock decr(10%) : [2, 0.65, 0.97, 0.7, 1.0] and
pfr

r3 = sec rumor∧earn incr(10%) ֒→ stock decr(10%)∧cfo resigns : [2, 0.68, 0.95, 0.7, 0.8].

434

Algorithm 24 Alt. Linear Constraints for Entailment of Rule r by Program K
ALC-ENT(APT-Program K)
1. Create the set of alternate linear constraints for WELC(K ∪ r) or FELC(K ∪ r).
fr

fr

2. If r is unconstrained, (r = F ; G : [∆t, ℓ, u]), create rule r′ = F ; G :
[∆t, ℓ′ , u′ ] where ℓ′ , u′ are variables. Note that unconstrained entailment can
only be checked if the constraints used are WELC in this algorithm.
fr

fr

3. If r is constrained, (r = F ֒→ G : [∆t, ℓ, u, α, β]) create rule r′ = F ֒→ G :
[∆t, ℓ′ , u′ , α, β] where ℓ′ , u′ are variables.
4. Create set of linear constraints WELC(K ∪ {r′ }) or FELC(K ∪ {r′ }).
5. Let ℓ̄′ be the minimization of ℓ′ subject to the linear constraints.
6. Let ū′ be the maximization of u′ subject to the linear constraints.
7. If [ℓ̄′ , ū′ ] ⊆ [ℓ, u] return ENTAILS otherwise return NOT ENTAILS.
Let Kent-ex = {r2 }. Suppose we want to determine if Kent-ex entails r3 using ALCpfr

ENT, employing the FELC constraints. We create rule r3′ = sec rumor∧earn incr(10%) ֒→
stock decr(10%) ∧ cfo resigns : [2, ℓ′ , u′ , 0.7, 0.8]. Based on Example A.1.1, we know
there are 3 frequency equivalence classes for Kent-ex ∪{r3′ } as ATS2 ∩ATS3 ≡ ∅. Hence,
we have 3 variables, v̄00 , v̄01 , v̄11 . Therefore, we set up the following constraints:
• For rule r2 : 0.65 ≤ v̄01 + v̄11 ≤ 0.97
• For rule r3′ : ℓ′ ≤ v̄11 ≤ u′

435

• v̄00 + v̄01 + v̄11 = 1
As it turns out, the minimization of ℓ′ is 0 and the maximization of u′ is 0.97. Since
[0, 0.97] 6⊂ [0.68, 0.95], we can say that Kent-ex does not entail r3 .

A.1.3

An Example Comparing PCTL to APT-rules

In this appendix, we provide a small example of a Markov Process which for
some tmax can be expressed as an APT-program. We then show that there is a “leadto” PCTL formula that is satisfied by the Markov Process and also show an APT-rule
that is similar, though not entailed by K, to the corresponding APT-program.
Given ground atoms BL , consider a Markov Process, M defined as follows:
• Set of states S = {S1 , S2 , S3 }, where each si has a unique label based on ground
atoms in BL
• Transition probability P defined as follows:
P (S1 , S2 ) = 0.3,
P (S1 , S3 ) = 0.7,
P (S2 , S1 ) = 0.2,
P (S2 , S3 ) = 0.8,
P (S3 , S1 ) = 0.1,
P (S3 , S2 ) = 0.9,
and 0 for all other transitions.
• Initial state S3
436

We will define formulas F (S1 ), F (S2 ), F (S3 ) to be propositional formulas
satisfied by exactly S1 , S2 , S3 respectively. For tmax = 5, let APT program K be the
APT-program corresponding to M constructed using MAKE-APT (Algorithm 7).
Let us consider the following PCTL formula:
max
F (S1 )y≤2
G≤t
≥1
≥0.75 F (S1 )

This formula intuitively says: “for all sequences starting at time 1 and ending at
time tmax (i.e., the first tmax states), the probability that formula F (S1 ) is followed
by itself in less than 2 time units is greater than 0.75.”
So, let us consider all sequences of states that start in S1 and end in S1 of
length 3 or less (obviously, S1 |= F (S1 )).
• hS1 , S2 , S1 i
• hS1 , S3 , S1 i
By the multiplication of transition probabilities, the first sequence has a probability of 0.06 and the second has a probability of 0.07 – hence, as they sum to 0.13,
we see that the PCTL formula is not satisfied by M .
max
M 6|= G≤t
F (S1 )y≤2
≥1
≥0.75 F (S1 )

So, now let us consider an “analogous” APT-rule:
efr

F (S1 ) ; F (S1 ) : [2, 0.75, 1]
By the results of Section 6.1, we know there must be exactly one satisfying interpretation for K – as there is exactly one interpretation associated with M ; lets call this
437

interpretation I. Consider the following list of sequences of states, which correspond
to threads assigned a non-zero probability by I. Below we list the sequences, the
probability, and the frequency – that is for the associated thread, Th, the value
efr (F (S1 ), F (S1 ), 2, Th).

438

Sequence Probability Frequency
S3 , S1 , S2 , S1 , S2

0.0018

1

S3 , S1 , S2 , S1 , S3

0.0042

1

S3 , S1 , S2 , S3 , S1

0.0024

0

S3 , S1 , S2 , S3 , S2

0.0216

0

S3 , S1 , S3 , S1 , S2

0.0021

1

S3 , S1 , S3 , S1 , S3

0.0049

1

S3 , S1 , S3 , S2 , S1

0.0126

0

S3 , S1 , S3 , S2 , S3

0.0504

0

S3 , S2 , S1 , S2 , S1

0.0108

1

S3 , S2 , S1 , S2 , S3

0.0432

0

S3 , S2 , S1 , S3 , S1

0.0126

1

S3 , S2 , S1 , S3 , S2

0.1134

0

S3 , S2 , S3 , S1 , S2

0.0216

1

S3 , S2 , S3 , S1 , S3

0.0504

1

S3 , S2 , S3 , S2 , S1

0.1296

1

S3 , S2 , S3 , S2 , S3

0.5184

1

We note that the probability mass associated with the APT-rule sums to
0.7564; hence, the APT-rule is entailed by the program and satisfied by I, while
the PCTL formula is not.
439

It is also important to notice other differences. As we can create APT-programs
that do not have corresponding MDP’s, there is a corresponding expressiveness in
the APT-rules that cannot be replicated with PCTL. Conversely, APT-logic does not
handle infinite temporal sequences; problems with this requirement may be better
suited for PCTL.

A.2
A.2.1

Proofs
Proof of Lemmas 2.12 and 2.14

pfr satisfies Axioms FF1-FF4 (2.12).
efr satisfies Axioms FF1-FF4 (2.14).
Proof. .
Axioms FF1,FF2,FF3 follow directly from the definitions of pfr and efr .
Axiom FF4: We construct Th 0 such that pfr (Th 0 , F, G, ∆t) = 0 as follows (one
can verify that the same Th 0 causes efr (Th 0 , F, G, ∆t) = 0). Either F ∧ ¬G has
a solution or it does not. Proceeding by cases. When F ∧ ¬G has a solution, let
Th 0 (i) |= F ∧ ¬G for all i. Notice that in this case, pfr (Th 0 , F, G, ∆t) = 0. When
F ∧ ¬G has no solution, then let w0 |= F (possible since F is not a contradiction)
and w1 |= ¬G (possible since G is not a tautology), and set Th 0 (0) = w0 , Th 0 (i >
0) = w1 . Note that w1 does not satisfy F (otherwise F ∧ ¬G would have a solution),
and that therefore pfr (Th 0 , F, G, ∆t) = 0. In all cases pfr (Th 0 , F, G, ∆t) = 0.
We now construct Th 1 such that pfr (Th 1 , F, G, ∆t) = 1 as follows (one can

440

again verify that the same Th 1 causes efr (Th 1 , F, G, ∆t) = 1). When F is not a
tautology, there is a world w that does not satisfy F . Assign Th 1 (i) = w for all i.
Note that pfr (Th 1 , F, G, ∆t) = 1. When F is a tautology then we know G is not a
contradiction. Thus there is w that satisfies G. Assign Th 1 (i) = w, and note that
pfr (Th 1 , F, G, ∆t) = 1.

A.2.2

Proof of pfr Property 5

Below we prove pfr property 5.
Proof. CASE 1: a + b ≤ 1
As pfr (Th, F1 , F2 ∧ F3 , ∆t) ≥ 0 by the definition of pfr , this is trivial.
CASE 2: a + b > 1
Let W1 , W2 , W3 , W2,3 be sets of worlds that satisfy F1 , F2 , F3 , F2 ∧ F3 respectively.
As a + b > 1, then we know that W2 ∩ W3 6= ∅. Let W ∗ be this set.
As all w∗ ∈ W ∗ satisfy F2 and F3 , then W ∗ ⊆ W2,3 .
Let F ∗ be a formula that ∀w∗ ∈ W ∗ , w∗ |= F ∗ .
Hence, pfr (Th, F1 , F ∗ , ∆t) ≥ a + b − 1.
As W ∗ ⊆ W2,3 , the statement follows.

A.2.3

Proof of Proposition 2.15

Part (1): Let Th be a thread, F and G be formulas, and ∆t1 and ∆t2 be two temporal intervals. If ∆t1 ≤ ∆t2 , we have that pfr (T h, F, G, ∆t1 ) ≤ efr (T h, F, G, ∆t2 ).
Proof. CLAIM 1: pfr (T h, F, G, ∆t1 ) ≤ efr (T h, F, G, ∆t2 ) for ef n(Th, F, G, ∆t2 , tmax −
441

∆t2 , tmax ) = 0.
(1) By the definition of ef n, we have: |{t : Th(t) |= F ∧ Th(t + ∆t1 ) |= G}| ≤ |{t :
Th(t) |= F ∧ ∃t′ ∈ [t, t + ∆t2 ] s.t. Th(t′ ) |= G}|
(2) Hence, |{t : Th(t) |= F ∧ Th(t + ∆t1 ) |= G}| ≤ ef n(Th, F, G, ∆t2 , 0, tmax ). The
claim follows.

CLAIM 2: pfr (T h, F, G, ∆t1 ) ≤ efr (T h, F, G, ∆t2 )
(1) Let x = ef n(Th, F, G, ∆t2 , tmax − ∆t2 , tmax ) > 0
(2) Let

a
b

= pfr (T h, F, G, ∆t1 )

(3) Let

c
d

= efr (T h, F, G, ∆t2 )

(4) By claim 1, we have

a
b

≤

c−x
.
d−x

(5) By the definition of pfr and efr , we know that d − x = b, therefore ab ≤ bc − bx.
(6) By the definition of pfr , we know that a ≤ b, therefore a(b + x) ≤ bc which
is equivalent to ad ≤ bc. (7) Hence, ad ≤ bc which gives us pfr (T h, F, G, ∆t1 ) ≤
efr (T h, F, G, ∆t2 ).
Part 2: Let Th be a thread, F and G be formulas, and ∆t be a temporal interval.
The following inequality always holds:
efr (T h, F, G, ∆t) ≤

∆t
X

pfr (T h, F, G, i)

i=1

CLAIM 1: If efr (T h, F, G, ∆t) − efr (T h, F, G, ∆t − 1) = efr (T h, F, G, ∆t) then
ef n(Th, F, G, ∆t, tmax − ∆t, tmax ) = 0

(Claim 1). Suppose, ∃ef n(Th, F, G, ∆t, tmax − ∆t, tmax ) 6= 0 then, as there can be
442

no two worlds in Th that satisfy F and G with exactly ∆t time periods between,
efr (T h, F, G, ∆t − 1) 6= 0 as the two such worlds would satisfy F and G within
≤ ∆t − 1 time intervals.
Therefore, we have a contradiction as efr (T h, F, G, ∆t) − efr (T h, F, G, ∆t − 1) =
efr (T h, F, G, ∆t) forces efr (T h, F, G, ∆t − 1) = 0.

CLAIM 2: efr (T h, F, G, ∆t) ≤ efr (T h, F, G, ∆t − 1) + pfr (T h, F, G, ∆t)
Intuition: If we consider an efr with ∆t and subtract the same efr with ∆t − 1,
we are essentially only considering G at exactly ∆t, hence the pfr for ∆t. Claim 1
allows us to ignore the effect of ef n in for the worlds between tmax − ∆t, tmax .

(Claim 2). By the definition of efr , we know efr (T h, F, G, ∆t) ≥ efr (T h, F, G, ∆t −
1).
Therefore, 0 ≤ efr (T h, F, G, ∆t) − efr (T h, F, G, ∆t − 1) ≤ efr (T h, F, G, ∆t).
By claim 1, if efr (T h, F, G, ∆t) − efr (T h, F, G, ∆t − 1) is maximized (hence
efr (T h, F, G, ∆t)−efr (T h, F, G, ∆t−1) = efr (T h, F, G, ∆t)) then ef n(Th, F, G, ∆t, tmax −
∆t, tmax ) = 0. Therefore, by the definitions of pfr and efr we have efr (T h, F, G, ∆t)−
efr (T h, F, G, ∆t − 1) ≤ pfr (T h, F, G, ∆t). Therefore, we know if efr (T h, F, G, ∆t) −
efr (T h, F, G, ∆t − 1) ≤ pfr (T h, F, G, ∆t). The claim follows.

(Proposition 2). By induction on ∆t.

443

BASE CASE: By the definition of pfr and efr we have efr (T h, F, G, 1) = pfr (T h, F, G, 1).
INDUCTIVE HYPOTHESIS: Assume efr (T h, F, G, ∆t−1) ≤
is true.

P∆t−1
i=1

pfr (T h, F, G, i)

INDUCTIVE STEP: By the inductive hypothesis. efr (T h, F, G, ∆t−1) ≤

P∆t−1
i=1

pfr (T h, F, G, i).

We add pfr (T h, F, G, ∆t) to both sides. efr (T h, F, G, ∆t − 1) + pfr (T h, F, G, ∆t) ≤
P∆t

i=1

pfr (T h, F, G, i). By claim 2, we have efr (T h, F, G, ∆t) ≤

We can now apply the inductive hypothesis and are finished.

A.2.4

P∆t

i=1

pfr (T h, F, G, i).

Proof of Proposition 2.17

Part (1): Let I be a temporal interpretation, F and G be formulas, and ∆t
be a temporal interval. If I |=
[∆t, max(ℓi ), min(

P∆t

i=1

ui , 1)]

S∆t

i=1 {F

pfr

efr

; G : [i, ℓi , ui ]} then I |= F ; G :

Proof. By Proposition 2.15, we have the following: max(
P

Th∈T

P

Th∈T

I(Th)·pfr (Th, F, G, i)) ≤

I(Th)·efr (Th, F, G, ∆t). By Proposition 2, we have the following:

efr (Th, F, G, ∆t) ≤

P

Th∈T

I(Th) · min(

The statement immediately follows.

P∆t

i=1

pfr (Th, F, G, i))

P

Th∈T

I(Th)·

fr

Part (2): If I |= F ֒→ G : [∆t, ℓp , up , a, b] then ∀aℓ , bℓ , au , bu such that aℓ ≤ a ≤ au
fr

fr

and bℓ ≤ b ≤ bu we have I |= F ֒→ G : [∆t, ℓp , 1, aℓ , bu ] and I |= F ֒→ G :
[∆t, 0, up , au , bℓ ].

fr

fr

Proof. PART 1: I |= F ֒→ G : [∆t, ℓ, u, a, b] then I |= F ֒→ G : [∆t, ℓ, 1, aℓ , bu ]
We know that {Th : a ≤ fr(Th, F, G, ∆t) ≤ b} ⊆ {Th : aℓ ≤ fr(Th, F, G, ∆t) ≤ bu }
444

Hence, if ℓ1 ≤

P

Th∈T , aℓ ≤fr(Th,F,G,∆t)≤bu

I(Th) ≤ u1 then ℓ ≤ ℓ1 and u1 ≤ 1. The

statement follows.

fr

fr

PART 2: I |= F ֒→ G : [∆t, ℓ, u, a, b] then I |= F ֒→ G : [∆t, 0, u, au , bℓ ]
We know that {Th : au ≤ fr(Th, F, G, ∆t) ≤ bℓ } ⊆ {Th : a ≤ fr(Th, F, G, ∆t) ≤ b}
Hence, if ℓ2 ≤

P

Th∈T , au ≤fr(Th,F,G,∆t)≤bℓ

I(Th) ≤ u2 then 0 ≤ ℓ2 and u2 ≤ u. The

statement follows.

A.2.5

Proof of Lemma 2.19

The qfr satisfies Axioms FF1-FF4.
Proof. qfr satisfies axioms FF1-FF3 by definition. Axiom FF4 is satisfied with
the following thread constructions: Create thread, Th 1 such that Th 1 (1) |= F
and Th 1 (∆t) |= G.

By the definition of qfr , qfr (Th 1 , F, G, ∆t) = 1.

Create

thread, Th 0 such that Th 0 (1) 6|= F and Th 0 (∆t) 6|= G. By the definition of qfr ,
qfr (Th 0 , F, G, ∆t) = 0.

A.2.6

Proof of Theorem 2.20
qfr

Part (1): Let q = Q : [t, ℓ, u] be an annotated formula, r = TRUE ֒→ Q : [t, ℓ, u, 1, 1]
be a constrained rule, and I be a tp-interpretation. Then, I |= q iff I |= r.
Proof. By the definition of qfr , ∀Th i such that qfr (Th i , TRUE, Q, t) = 1, Th i (t) |=
445

Q. Hence, the set of threads where ℓ ≤ qfr (Th i , TRUE, Q, t) ≤ u equivalent to the
set of threads where Th i (t) |= Q. By the definitions of satisfaction for annotated
formulae and constrained rules, the statement follows.
qfr

Part (2): Let q = Q : [t, ℓ, u] be an annotated formula, r = TRUE ; Q : [t, ℓ, u] be
a unconstrained rule, and I be a tp-interpretation. Then, I |= q iff I |= r.
Proof. By the definition of qfr , qfr (Th, TRUE, Q, t) = 0 iff Th(t) 6|= Q
and qfr (Th, TRUE, Q, t) = 1 iff Th(t) |= Q.
Hence, for all interpretations,

P

Th∈T ,Th(t)|=Q

I(Th) =

P

Th∈T

I(Th)qfr (Th, TRUE, Q, t).

By the definitions of satisfaction for annotated formulae and constrained rules, the
statement follows.

A.2.7

Proof of Lemma 3.1
fr

Consider the APT-Program consisting of {r} where r = F ; G : [∆t, ℓ, u].
1. If G is a tautology, then {r} is consistent iff u = 1.
2. If F is a tautology and G is a contradiction, then {r} is consistent iff ℓ = 0.
3. If F is a contradiction, then {r} is consistent iff u = 1.
4. If F is not a contradiction, G is not a tautology, and either F is not a tautology
or G is not a contradiction then {r} is consistent.
Proof. The items follow directly from Axioms FF1-FF4 respectively.

446

1. Suppose G is a tautology.
By FF1, fr(Th, F, G, ∆t) is 1 for all Th, ∆t and F . Thus
P

Th∈T

P

Th∈T

I(Th)fr(Th, F, G, ∆t) =

I(Th) = 1. Therefore {r} is consistent iff u = 1.

2. Suppose F is a tautology and G is a contradiction.
By FF2, fr(Th, F, G, ∆t) is 0 for all Th, and ∆t. Thus
0. Therefore r is consistent iff ℓ = 0.

P

Th∈T

I(Th)fr(Th, F, G, ∆t) =

3. Suppose F is a contradiction.
By FF3, fr(Th, F, G, ∆t) is 1 for all Th, ∆t and G. Thus
P

Th∈T

P

Th∈T

I(Th)fr(Th, F, G, ∆t) =

I(Th) = 1. Therefore {r} is consistent iff u = 1.

4. Suppose F is not a contradiction, G is not a tautology, and either F is not a
tautology or G is not a contradiction
By FF4, we have Th 0 and Th 1 such that fr(Th 0 , F, G, ∆t) = 0 and fr(Th 1 , F, G, ∆t) =
1. Let I be the interpretation assigning probability ℓ to Th 1 and probability
1 − ℓ to interpretation Th 0 . I fr-satisfies r, thus {r} is consistent.

A.2.8

Proof of Theorem 3.2

Deciding the consistency of an APT-logic program containing a single unconstrained APT-rule is NP-Complete.
Proof. In NP: Lemma 3.1 covers all possible cases where a single unconstrained
fr

rule r = F ; G : [∆t, ℓ, u] may be consistent. In each case, there is a different
447

witness:
1. If ℓ = 0 and u = 1 then no witness is needed (such rules are always consistent).
2. If ℓ = 0 and u < 1 then we need two worlds w0 and w1 as a witness. w0 does
not satisfy G and proves G is not a tautology (keeping part one of Lemma 3.1
from applying). w1 satisfies F and proves F is not a contradiction. (keeping
part three of Lemma 3.1 from applying). Note that either part two or part
four of the lemma apply (depending on if F is a contradiction and G is a
tautology or not), and in either case {r} is consistent.
3. If ℓ > 0 and u = 1 we need a world, w, which does not satisfy F or does
satisfy G (keeping part two of Lemma 3.1 from applying). Note that with
these assumptions, exactly one of the other parts of the lemma applies and in
all cases {r} is consistent.
4. In all other cases we have that ℓ > 0 and u < 1. Here we need three worlds as
the witness, w0 which does not satisfy G, w1 which satisfies F , and w3 which
either does not satisfy F or satisfies G. When such worlds do not exist, one
of the other cases applies and enforces that {r} is not consistent – thus such
worlds always exist when {r} is consistent. The worlds allow the application
of part four of Lemma 3.1 to prove consistency.
NP-hard: By reduction from SAT. Take SAT formula F , and create annotated
fr

rule r = F ; FALSE : [1, 0, 0]. c is consistent iff F has a satisfying assignment.
(⇒) Suppose {r} is consistent and F has no satisfying assignment. Thus F is a
448

contradiction and by part three of lemma 3.1, u must be 1 in order for {r} to be
consistent. But u is not 1 (it is 0), so there is a contradiction and F has a satisfying
assignment.
(⇐) Suppose F has a satisfying assignment. Then either F is a tautology, which
gives that {r} is consistent by part two of lemma 3.1; or not, in which case part
three of lemma 3.1 implies {r} is consistent.

A.2.9

Proof of Lemma 3.3
fr

Let K = {r = F ֒→ G : [∆t, ℓ, u, α, β]} be a constrained APT-Program consisting of a single rule. K is consistent iff at least one of the following conditions
hold.
• u = 1 and there exists Th in such that α ≤ fr(Th in , F, G, ∆t) ≤ β.
• ℓ = 0 and there exists Th out such that α > fr(Th out , F, G, ∆t) or β < fr(Th out , F, G, ∆t).
• There exists both Th in and Th out as described above.
Proof. (1) Let Th in be a thread such that α ≤ fr(Th in , F, G, ∆t)β. Let Th out be a
thread such that α > fr(Th out , F, G, ∆t) or β < fr(Th out , F, G, ∆t).
(2) By the axioms FF1-FF4 and the pigeon-hole principle, there must exist at least
one of thin , Th out .
We have three cases: CASE 1: thin , Th out both exist.
Consider interpretation I such that I(Th in ) = 1. By the definition of satisfaction,
I |= r. Therefore {r} is consistent.
449

CASE 2: Only thin exists.
Then, for all threads, Th, α ≤ fr(Th, F, G, ∆t) ≤ β. So, for any satisfying interpretation, the sum of all threads Th where α ≤ fr(Th, F, G, ∆t) ≤ β is 1. Hence, u
must equal 1, or I is not a satisfying interpretation.
CASE 3: Only thout exists.
Then, for all threads, Th, α > fr(Th, F, G, ∆t) or β < fr(Th, F, G, ∆t). So, for any
satisfying interpretation, the sum of all threads Th where α ≤ fr(Th, F, G, ∆t) ≤ β
is 0. Hence, ℓ must equal 0, or I is not a satisfying interpretation.

The statement follows directly from the above cases.

A.2.10

Proof of Theorem 3.4

Deciding the consistency of an APT-logic program containing a single constrained APT-rule is NP-Complete.
fr

Proof. In NP: Lemma 3.3 covers all cases where a single constrained rule r = F ֒→
G : [∆t, ℓ, u, α, β] may be consistent. In each case, there is a different witness:
• There exists Th in such that α ≤ fr(Th in , F, G, ∆t)β and u = 1. Here Th in is the
witness.
• There exists Th out such that α > fr(Th out , F, G, ∆t) or β < fr(Th out , F, G, ∆t)
and ℓ = 1. Here Th out is the witness.
• There exists both Th in and Th out as described above. Here, the witnesses are
Th in and Th out .
450

NP-hard: By reduction from SAT. Take SAT formula F , and create annofr

tated rule r = F ֒→ FALSE : [1, 1, 1, 0, 0]. r is consistent iff F has a satisfying
assignment.
(⇒) Suppose {r} is consistent and F has no satisfying assignment. Thus F is a
contradiction. Thus, by FF3, for all Th, fr(Th, F, FALSE, ∆t) = 1. This is outside
of the range [α, β] for the rule. Hence, Th in , as described in Lemma 3.3 cannot
possibly exist. Although Th out does exist, as ℓ 6= 0, {r} is not consistent by Lemma
3.3. Therefore, we have a contradiction and F must have a satisfying assignment.
(⇐) Suppose F has a satisfying assignment. If F is not a tautology, then we can
apply FF4 and create Th 0 such that fr(Th 0 , F, FALSE, 1) = 0. If F is a tautology,
then all threads are Th 0 as described earlier. As 0 ∈ [α, β] and u = 1, then by
Lemma 3.3, we know that {r} is consistent.

A.2.11

Proof of Lemma 3.6

If an APT-Program, K = {r1 , . . . , ri , . . . , rn }, is PCD, then for any disjoint
partition of rules, K1 , K2 , there exists a thread Th such that for all rules r1 ∈ K1 ,
fr1 (Th, F1 , G1 , ∆t1 ) = 1 and for all rules r2 ∈ K2 , fr2 (Th, F2 , G2 , ∆t2 ) = 0.
Proof. We will use the worlds wi and w∅ specified in the definition of PCD. Let
max(∆t) be the maximum ∆t of any rule in K. For each rule ri in K2 , we set world
Th(max(∆ti ) · (i − 1)) = wi . Set all other worlds in Th to w∅ . Note that by the
axioms, for all rules r1 ∈ K1 , fr1 (Th, F1 , G1 , ∆t1 ) = 1 and for all rules r2 ∈ K2 ,
fr2 (Th, F2 , G2 , ∆t2 ) = 0.

451

A.2.12

Proof of Theorem 3.7

For a mixed PCD APT-Program K = {r1 , . . . , ri , . . . , rn }, if for all ri , ℓi ≤
|K| − 1
then K is consistent.
|K|
Proof. (1) For every rule ri ∈ K, let thread Th i such fri (Th i , Fi , Gi , ∆ti ) = 0 and
∀j 6= i, frj (Th , Fj , Gj , ∆tj ) = 1. These threads exists by Lemma 3.6.
(2) Let thread Th ∅ is a thread where every world is w∅ . This thread exists by Lemma
3.6.
(3) Let max(ℓi ) be the maximum lower probability bound of all rules in K.
(4) We create interpretation I as follows: ∀Th i , I(thi ) =
I(Th ∅ ) = 1 −

CLAIM 1:

P

P|K|

i=1

Th∈T

1
· max(ℓi ) and
|K| − 1

I(thi ). For any other thread, Th, I(Th) = 0.

=1

(5) By (4), the only threads that must have a non-zero probability by I are
Th 1 , . . . Th i , . . . , Th |K| .
(6) By (4),

P|K|

i=1

I(Th) = |K| ·

1
· max(ℓi ).
|K| − 1

(7) Then, by the requirement on ℓi in the theorem statement,
|K| − 1
1
·
.
|K| − 1
|K|
P
(8) Hence, |K|
i=1 I(Th) ≤ 1.

P|K|

i=1

I(Th) ≤ |K| ·

(9) By (8) and (4), the claim follows.

CLAIM 2: Interpretation I satisfies all unconstrained rules in K
(10) We will consider ri ∈ K.

As ui = 1, we have to show only that ℓi ≤
452

P

Th∈T

I(Th)fri (Th, F (i) , G(i) , ∆t(i) ).

(11) Based on (1-2),

P|K|

j=1

I(thj ) − I(thi ) ≤

P

Th∈T

I(Th)fri (Th, F (i) , G(i) , ∆t(i) ).

P
1
·max(ℓi )) ≤ Th∈T I(Th)fri (Th, F (i) , G(i) , ∆t(i) ).
|K| − 1
P
(13) By (3), for all rules, ri ∈ K, ℓi ≤ Th∈T I(Th)fri (Th, F (i) , G(i) , ∆t(i) )
(12) Hence, by (4), (|K|−1)·(

(14) Therefore, by (13) and the definition of satisfaction, all unconstrained rules in
K are satisfied by I.

CLAIM 3: Interpretation I satisfies all unconstrained rules in K
We have two cases:
CASE 1: α = 0
Then,
rule r

P

Th∈T 0≤fr(Th,F,G,∆t)≤1

I(Th) = 1 and as u = 1, I satisfies constrained

CASE 2: α 6= 0
Notice that for all threads, Th that I assigns a non-zero probability to, that
fr(Th, F, G, ∆t) is either zero or one. Hence, for all rules,
P

Th∈T α≤fr(Th,F,G,∆t)≤1

ℓi ≤

P

Th∈T

P

Th∈T

I(Th)fr(Th, F, G, ∆t) =

I(Th) = 1. By the first claim, we know that for all rules

I(Th)fr(Th, F, G, ∆t), therefore, by the definition of satisfaction, and

that fact that βi = 1 for all constrained rules, we know that I satisfies all constrained
rules.

453

A.2.13

Proof of Proposition 3.9

For mixed APT-Logic Program K, K is consistent iff SLC(K) has a solution.
Proof. (⇒): Let I be an interpretation satisfying K. For each thread, Th j , set
variable vj = I(Th j ).

Based on the definitions of interpretation and satisfac-

tion, we know that for the first m lines of the linear program provide a valid solution (i.e. substituting I(Th j ) for vj for a given unconstrained rule gives ℓi ≤
Pn

j=1

fr(Th j , Fi , Gi , ∆ti ) · I(Th j ) ≤ ui which is the definition of satisfaction, substi-

tuting I(Th j ) for vj for a given constrained rule gives

ℓi ≤

P

Th j ∈T α≤fr(Th ,F ,G ,∆t )≤β
j i
i
i

I(Th j ) ≤ ui which is also definition of satisfaction).

Based on the definition of an interpretation, we know that
is equivalent to the last line of the linear program.

Pn

j=1

I(Th j ) = 1, which

(⇐): Let v1 , . . . , vn be a solution to the linear program. Let I be an interpretation
where I(Th j ) = vj . Based on the definitions of satisfaction, interpretation, and the
lines of the linear program, I is a valid interpretation for K.

A.2.14

Proof of Lemma 3.13

For APT-logic program K, and ≡K -partitioning P1 , · · · , Pm of T , for all threads
Th, Th ′ ∈ Pi , all F, G ∈ f ormula(K), and all ∆t
• qfr (Th, F, G, ∆t) = qfr (Th ′ , F, G, ∆t)
• efr (Th, F, G, ∆t) = efr (Th ′ , F, G, ∆t)
• qfr (Th, F, G, ∆t) = qfr (Th ′ , F, G, ∆t)
454

Proof. In both pfr and efr, the numerator and denominator depend only on the
worlds in the threads satisfied by F and G. Since F and G are in f ormula(K), we
know that at all time points Th and Th ′ either both satisfy F or both do not satisfy
F (and likewise for G). Therefore exactly the same time points will be counted in
the numerator and denominator of pfr and efr for both Th and Th ′ , so the values
qfr (Th, F, G, ∆t) and qfr (Th ′ , F, G, ∆t) will be equivalent (and likewise for efr).

For qfr , we notice that other than circumstances where the value of qfr reflects
the axioms, this frequency function returns 1 if F is satisfied at Th(1) and G is
satisfied at Th(∆t). As F and G are also in f ormula(K), we know that worlds
Th(1) and Th(∆t) either satisfy or do not satisfy F and G respectively. Therefore,
qfr (Th, F, G, ∆t) = qfr (Th ′ , F, G, ∆t).

A.2.15

Proof of Proposition 3.15

For any APT-program K, WELC(K) is solvable iff K is consistent.
Proof. ⇒ Suppose WELC(K) is solvable to show that K is consistent. Define interpretation I as follows: For each partition Pi , pick one Th ∈ Pi and set
I(Th) = v̂label(Pi ) . For all other Th, set I(Th) = 0. Because of conditions 4
and 5,

P

Th

I(Th) = 1. Because of the first constraints for constrained rules,

unconstrained rules, and annotated formula, I satisfies K.
⇐ Suppose K is consistent. Let I be a satisfying interpretation. Assign a solution to WELC(K) as follows: For each Pi and lbl where lbl = label(Pi ), v̂lbl =
455

P

Th∈Pi

I(Th), and for any lbl where there is no Pi s.t. label(Pi ) = lbl, v̂lbl = 0.

Since I is consistent, this variable assignment will satisfy conditions relating to

constrained rules, unconstrained rules, and annotated formula. The other constraints are clearly met.

A.2.16

Proof of Theorem 3.17

For APT-Logic Program, K, determining the existence of an equivalence class
is NP-Complete.
Proof. NP-Hard: Let F be a sat formula. Create program K consisting of annotated formula F : [1, 1, 1] and let tmax = 1. There is equivalence class Pi such
that label(Pi ) = 1 iff there is a satisfying assignment for F . ⇒: Suppose there is
an equivalence class Pi , then for Th ∈ Pi , Th(1) |= F and Th(1) is a satisfying
assignment for F . ⇐: Suppose there is a satisfying assignment w for F , then the
thread Th where Th(1) has label 1.
In NP: The existence of equivalence class Pi such that label(Pi ) = lbl can be
guaranteed by a thread Th such that label(Th) = lbl. This thread is the witness.

A.2.17

Proof of Proposition 3.19

For any constrained APT-logic program K, ∼K is reflexive, symmetric, and
transitive.
Proof. Straightforward.
456

A.2.18

Proof of Theorem 3.21

For constrained APT-Logic Program K, K is consistent iff there is a solution
to FELC(K).
Proof. (⇒): Let I be an interpretation satisfying K. Create an assignment θ where
for each E ∈ T [∼K fr], assign v̄str(E) θ =

P

satisfies constraint 1 follows from the fact that
1=

X

X

I(Th) =

Th∈T

E∈T

[∼K fr]

X

Th∈E

P

I(Th). That this assignment θ
I(Th) = 1 by simple algebra:

Th∈T

I(Th) =

Th∈E

X

E∈T

v̄str(E)

[∼K fr]

That this assignment θ satisfies constraint 2 follows directly form the definition
of θ (v̄str(E) θ is zero when E is empty).
That this assignment θ satisfies constraint 3 follows from the fact that for all
i,
ℓi ≤

X

Th∈T ,αi ≤fr(Th,Fi ,Gi ,∆ti )≤βi

I(Th) ≤ ui

. Consider that due to the definition of str(E):
X

Th∈T ,αi ≤fr(Th,Fi ,Gi ,∆ti )≤βi

I(Th) =
E∈T

X

[∼K fr],str(E)

X

i =1 Th∈E

I(Th) =
E∈T

X

[∼K fr],str(E)

v̄str(E) θ.
i =1

By direct substitution, we now have that θ satisfies the last, and final, constraint.
(⇐): Let θ be a solution to FELC(K). Construct an interpretation I where for
each E ∈ T [∼K fr], we pick one Th ∈ E and assign I(Th) = v̄str(E) and all other
I(Th) are set to 0 (due to constraint 2, this construction is well-defined). That
P

Th∈T

I(Th) = 1 follows from constraint 1. That I |= K follows from constraint 3

algebraically similar to the above.
457

A.2.19

Proof of Proposition 3.23

If a given equivalence class is empty, BFECA returns EMPTY. If there is a
thread in a given equivalence class, BFECA returns OK.
Proof. CLAIM 1: If a given equivalence class is empty, BFECA returns EMPTY.
Suppose by way of contradiction, that for a class, cls reported EMPTY by BFECA
actually contains thread Th. The class cls is defined as follows:
cls =

(

\

ATSi

si =1

)

∩

(

\

ATSi

si =0

)

Then, for all ATSi such that si = 1, Th ∈ ATSi and all ATSi such that si = 0,
Th ∈ ATSi . If such a thread existed, it would have been found in steps 1-3 of
BFECA, hence a contradiction.

CLAIM 2: If there is a thread in a given equivalence class, BFECA returns
OK.
Suppose by way of contradiction, that for a class, cls reported OK by BFECA actually
does not contain a thread. The class cls is defined as follows:
cls =

(

\

si =1

ATSi

)

∩

(

\

ATSi

si =0

)

Hence, there does not exist a thread, Th such that for all ATSi such that si = 1,
Th ∈ ATSi and all ATSi such that si = 0, Th ∈ ATSi . However, by steps 1-3 of of
BFECA, at least one such thread was identified. Hence a contradiction.

The statement follows directly from claims 1-2.
458

A.2.20

Proof of Theorem 58

Suppose APT-Logic program, K =

fri

Sm

i=1

{ri } where ri = Fi ֒→ Gi : [∆ti , ℓi , ui , αi , βi ]

meets PCD restrictions 1-6 of Definition 3.5. Then, for all binary numbers s ∈
[0, 1]m , frequency equivalence classes cls = {
least one thread.

T

si =1

T
ATSi } ∩ { si =0 ATSi } contains at

Proof. CLAIM: There exists at least one thread in any cls
Follows directly from lemma 3.6. Note that PCD restriction 7 is not used in this
lemma. By the definition of the associated thread subsets, class cls contains at least
one thread.

The statement of the theorem follows from the above claim.

A.2.21

Proof of Corollary 15

For a constrained APT-Logic program, K =

Sm

i=1

[∆ti , ℓi , ui , αi , βi ] and set of annotated formulas, F ACT S =
Qj : [tj , ℓj , uj ] with the following restrictions,

fri

{ri } where ri = Fi ֒→ Gi :
Sk

j=1

afj where afj =

1. K meets PCD restrictions 1-4 of Definition 3.5
2. tmax ≥ max(t) + |K| · max(∆ti )
3. ∃ world w∅ such that ∀i ∈ [0, m] and ∀j ∈ [0, k] w∅ 6|= Fi , w∅ 6|= Gi , and
w∅ 6|= Qj

459

4. ∀j ∈ [0, k], there exists world qwj such that qwj |= Qj and ∀i ∈ [0, m] qwj 6|=
Fi .
5. No two annotated formulas in F ACT S are at the same timepoint.
Then for all s ∈ [0, 1]m+k , frequency equivalence classes cls = {
{

T

si =0

ATSi } contains at least one thread.
(q)

Proof. ∀j ∈ [1, k], we define ATSj

(q)

and ATSj

T

si =1

ATSi } ∩

to be the ATS and ATS for rule

qfr

r = TRUE ֒→ Qj : [t, ℓj , uj , 1, 1] created from annotated formula afj using qfr .

CLAIM: There exists at least one thread in any cls
For the string s ∈ [0, 1]m+k , let the first m digits correspond with the m constrained
rules and the last k digits correspond with the k annotated formulae.
Create a thread, Th where for any rule, ri if si = 0, set world Th(max(tj ) +
max(∆ti ) · (i − 1)) = wi .
For any formulae, afj where sj = 1, set the world Th(t) = qwj . Set all other worlds
in Th to w∅ . Note that by the axioms, ∀i, fri (Th, Fi , Gi , ∆ti ) = 0 and ∀j 6= i,
frj (Th, Fj , Gj , ∆tj ) = 1. Further, for all annotated formulae where qwj is at time tj ,
(q)

there the thread is in ATSj . For all annotated formula qwj where w∅ is at Th(t),
(q)

the thread is in ATSj .
By the definition of the associated thread subsets, class cls contains at least one
thread.

460

A.2.22

Proof of Corollary 16

Let:
• Constrained APT-Logic program, K =
• Set of annotated formulas, F ACT S =
(q)

• ∀j ∈ [1, k], we define ATSj

Sm

fri

i=1

Sk

{ri } where ri = Fi ֒→ Gi : [∆ti , ℓi , ui , αi , βi ]

j=1

(q)

and ATSj

afj where afj = Qj : [tj , ℓj , uj ]

to be the ATS and ATS for rule r =

qfr

TRUE ֒→ Qj : [t, ℓj , uj , 1, 1] created from annotated formula afj using qfr
• Restrictions 1-5 from Corollary 15
Then, for all subsets of SAM ET IM E ⊆ F ACT S, where for all af1 , af2 ∈ SAM ET IM E,
t1 = t2 ; for all strings s2 ∈ [0, 1]|SAM ET IM E| all frequency equivalence classes, cl that
T
T
(q)
(q)
intersect { s2i =1 ATSi } ∩ { s2i =0 ATSi } are non-empty iff:

∃ world wp such that for all afi ∈ SAM ET IM E where s2i = 1, wp |= Qi and for
all afj ∈ SAM ET IM E where s2j = 0, wp 6|= Qj .
Proof. (⇐) By the definition of associated thread subsets, we can create a thread
Th where the world at time t is wp . Hence, for all afi ∈ SAM ET IM E where
s2i = 1, qfr (Th, TRUE, Qi , ti ) = 1 and for all afj ∈ SAM ET IM E where s2j =
0, qfr (Th, TRUE, Qi , ti ) = 0. As per Corollary 15, all other annotated formulae with different values for t and constrained rules, this thread will have the
appropriate value for the corresponding frequency function. Hence, for all subsets of SAM ET IM E ⊆ F ACT S, where for all aF, aG ∈ SAM ET IM E, t1 =
t2 for all strings s2 ∈ [0, 1]|SAM ET IM E| all equivalence classes, cl that intersect

461

{

T

(q)

s2i =1

ATSi } ∩ {

T

(q)

s2i =0

ATSi } are not empty.

(⇒) Suppose by way of contradiction, we can have a thread in the equivalence
class cl that intersects {

T

(q)

s2i =1

ATSi } ∩ {

T

(q)

s2i =0

ATSi } and there does not exists

a world wp such that for all afi ∈ SAM ET IM E where s2i = 1, wp |= Qi and for
all afj ∈ SAM ET IM E where s2j = 0, wp 6|= Qj . Hence, a thread in such a class
must have one of the following characteristics in the below three cases:

CASE 1: There exists world, wp′ where there exists afi ∈ SAM ET IM E where
s2i = 1, wp′ 6|= Qi and for all afj ∈ SAM ET IM E where s2j = 0, wp′ 6|= Qj and for
thread Th 1 , Th 1 (ti ) = wp′ .
Thread Th 1 cannot possibly be in cl as qfr (Th 1 , TRUE, Qi , ti ) = 0 - it would have
to be 1 to be in cl by the definition of associated thread subsets.

CASE 2: There exists world, wp′ such that for all afi ∈ SAM ET IM E where
s2i = 1, wp′ |= Qi and there exists afj ∈ SAM ET IM E where s2j = 0, wp′ |= Qj
and for thread Th 2 , Th 2 (ti ) = wp′ .
Thread Th 2 cannot possibly be in cl as qfr (Th 2 , TRUE, Qj , tj ) = 1 - it would have
to be 0 to be in cl by the definition of associated thread subsets.

CASE 3: There exists world, wp′ where there exists afi ∈ SAM ET IM E where
s2i = 1, wp′ 6|= Qi and there exists afj ∈ SAM ET IM E where s2j = 0, wp′ |= Qj

462

and for thread Th 3 , Th 3 (ti ) = wp′ .
Thread Th 2 cannot possibly be in cl for reasons described in cases 1-2.

Hence, we have a contradiction and there cannot exist a thread in class cl.
The statement follows.

A.2.23

Proof of Proposition 3.25

If a given frequency equivalence class is empty, WEFE returns EMPTY. If
there is a thread in a given frequency equivalence class, WEFE returns OK.
Proof. CLAIM 1: If a given frequency equivalence class is empty, WEFE returns
EMPTY.
Suppose by way of contradiction, that for a class, cls reported EMPTY by BFECA
actually contains thread Th. The class cls is defined as follows:
) (
(
)
\
\
ATSi ∩
cls =
ATSi
si =0

si =1

By Lemma 3.13, a world-equivalence based thread partition has the same frequency function as all threads in that partition. Hence, by the definition of the
set P CLASSs in steps 4-5 of WEFE, there must be a partition in set P CLASSs
corresponding to a thread in class cls . However, that set is empty and we have a
contradiction.
CLAIM 2: If there is a thread in a given frequency equivalence class, WFE
returns OK.
Suppose by way of contradiction, that for a class, cls reported OK by BFECA actually
463

does not contain a thread. The class cls is defined as follows:
) (
(
)
\
\
ATSi ∩
ATSi
cls =
si =0

si =1

Hence, there does not exist a thread, Th such that for all ATSi such that si = 1,
Th ∈ ATSi and all ATSi such that si = 0, Th ∈ ATSi . Therefore, by Lemma 3.13
and steps 4-5 of WEFE, P CLASSi must be empty. However, by the result of WEFE
it is not, so we have a contradiction.

The statement follows directly from claims 1-2.

A.2.24

Proof of Theorem 4.2

Given an APT-logic program K and an annotated formula, af , deciding if K
entails af is coNP-Hard.
Proof. Intuition: The proof of the above result is by a reduction from SAT.
Let K∅ = ∅ be an APT-logic program. Take SAT formula F and create an annotated
formula af = ¬F : [1, 1, 1]. We say that K∅ entails af iff F is not satisfiable.
(⇒) Suppose BWOC, F is not satisfiable and K∅ does not entail af . Then, there
exists an interpretation I s.t. I |= K∅ and I 6|= af . As F is not satisfiable, we
know that for all worlds w ∈ 2BL , w 6|= F . Hence, for any valid interpretation,
P

Th|Th(1)|=¬F

I(Th) = 1. By the definition of satisfaction, interpretation I |= af –

which is a contradiction.
(⇐) Suppose BWOC, F is satisfiable and K∅ does entails af . By the definition of K∅ ,

∀I,

P

Th∈T

I(th) = 1. Based on the definition of entailment, ∀I,
464

P

Th∈T :th(1)|=¬F

= 1.

Therefore, ∀th → th(1) |= ¬F and ∀th → th(1) 6|= F hence, F is not satisfiable - a
contradiction.

A.2.25

Proof of Proposition 4.3
fr

fr

For unconstrained rule r = F ; G : [∆t, ℓ, u] or constrained rule r = F ֒→
G : [∆t, ℓ, u, α, β] and program K, SLC-ENT return ENTAILS iff K entails r and
returns NOT ENTAILS iff K does not entail r
Proof. To show this, we show that K entails r iff [ℓ̄′ , ū′ ] ⊆ [ℓ, u].
CLAIM 1: If K entails r then [ℓ̄′ , ū′ ] ⊆ [ℓ, u].
Suppose, BWOC, that [ℓ̄′ , ū′ ] 6⊆ [ℓ, u]. Then either ℓ̄′ or ū′ is not in [ℓ, u]. However,
clearly there is a solution to the linear program that assigns a constraint associated
with r a set of variables that sums to either ℓ̄′ or ū′ . Hence, there is an interpretation
that would assign the non-probabilistic portion of the rule r one of those numbers
as a probability. Such an interpretation would not satisfy r, which would be a contradiction.

CLAIM 2: If [ℓ̄′ , ū′ ] ⊆ [ℓ, u] then K entails r.
Suppose, BWOC, that K does not entail r. Then, there must be some interpretation that satisfies the program but not r. However, by the solution of the linear
program, any probability a satisfying interpretation assigns r would fall in [ℓ̄′ , ū′ ] –
a contradiction.

465

A.2.26

Proof of Proposition 81

If K entails r, then ALC-ENT returns ENTAILS. If K does not entail r, then
ALC-ENT returns NOT ENTAILS.
Proof. CLAIM 1: If K entails r, then ALC-ENT returns ENTAILS.
Suppose, by way of contradiction, that there exists interpretation I that satisfies
program K but does not satisfy rule r. If r is constrained, then

P

Th∈T

I(Th) ·

fr(Th, F, G, ∆t) is either less than ℓ or greater than u. If r is constrained, then
P

Th∈T , α≤fr(Th,F,G,∆t)≤β

is either less than ℓ or greater than u. However, by Theorem

3.15 for WELC and Theorem 3.21 for FELC, such an interpretation cannot exist as
[ℓ̄, ū] ⊆ [ℓ, u] when ALC-ENT returns ENTAILS. Therefore, we have a contradiction
and the statement of the claim follows.
CLAIM 2: If K does not entail r, then ALC-ENT returns NOT ENTAILS.
Suppose, by way of contradiction, that all interpretations that satisfy program K
also r. However, as there is a solution to either WELC or FELC such that either ℓ̄ < ℓ
or ū > u, then we know by Theorem 3.15 for WELC and Theorem 3.21 for FELC, that
there is an interpretation that assigns the quantity
P

Th∈T , α≤fr(Th,F,G,∆t)≤β

P

Th∈T

I(Th)·fr(Th, F, G, ∆t) (or

I(Th) if r is constrained) a value either less than ℓ or greater

than u. Therefore, by the definition of satisfaction, there exists an interpretation
that satisfies K and does not satisfy r. Hence, we have a contradiction and the
statement of the claim follows.

466

A.2.27

Proof of Theorem 6.5

Theorem 59. If an interpretation I satisfies MDP L with set of policies L, then it
satisfies APT-Program K generated from MAKE-APT.
Proof. Suppose, by way of contradiction, that there exists an interpretation I that
satisfies (L, P OL) that does not satisfy K. Therefore, I must not satisfy one of the
annotated formulas in K. As s1 is the initial state, obviously all I satisfying the
Markov Process satisfy F (s1 ) : [1, 1, 1]. Therefore, for some state s and time point
t, I 6|= F (si ) : [t, min(SP ML,π (st , t)), max(SP ML,π (st , t))]. Then, by the definition
of satisfaction,

P

Th(t)|=F (si )

I(Th) > min(SP ML,π (si , t)) or

P

Th(t)|=F (si )

I(Th) >

max(SP ML,π (si , t)). However, we notice that s1 →t−1 si is the set of all prefixes
for all sequences that include state si after t − 1 time points. Hence, the sum of
probabilities for all sequences in s1 →t−1 si is equal to the sum of all probabilities of
all sequences that include si after t − 1 time points. Therefore,

P

Th(t)|=F (si )

I(Th)

must fall within the bounds [min(SP ML,π (si , t)), max(SP ML,π (si , t))], which is a
contradiction. The claim follows.

A.2.28

Proof of Corollary 6.6

Corollary 17. An interpretation I satisfies MDP L with policy π, iff it satisfies
APT-Program K generated from MAKE-APT.
Proof. (⇒): Follows directly from Theorem 6.5.
(⇐): By the definition of satisfaction of an MDP and single policy, there exists only
one I such that I |= (L, π). We claim that there is exactly one interpretation for
467

the constructed APT-Program, K, and then use the pigeon hole principle to show
that it is the same interpretation that satisfies (L, π). We prove this by induction
on tmax .
Base case: If tmax = 1, then the only rule in K is F (s1 ) : [1, 1, 1] is necessary (all
other annotated formulas have a t greater than tmax . As F (s1 ) is satisfied by exactly
one world, and the probability bounds are both 1, and there is only one time-point,
there can be only one possible interpretation.
Inductive hypothesis: Assume that K has only one interpretation for tmax − 1.
Inductive step: As K has only one interpretation for tmax − 1, only the annotated
formulas where t ≤ tmax − 1 are included. Let I be the interpretation that satisfies
K for tmax − 1. Let T be the set of threads for tmax − 1.
We add all possible annotated formulas where t = tmax . Let us say that there
are n such annotated formulas. We note that the regular formula in each annotated
formulas is satisfied by exactly one world, and all of the formulas are satisfied by a
different world. Let W be this set of worlds. Therefore, the new set of threads can
have one of n possible worlds at time point tmax . Let T ′ be the new set of threads.
Therefore, for each Th ∈ T , there are n number of threads in T ′ .
For w ∈ W , let p(w) be the probability of w being the world at time tmax . As
all annotated formulas in K have ℓ = u, then there is only one possible value for
p(w). Note that as the ℓ value for all annotated formulas where t = tmax is 1, then
P

w∈W

p(w) = 1. Suppose by way of contradiction that there is a thread Th ′ ∈ T ′

that can be assigned more than one probability. However, there can be only one
probability for the first tmax − 1 worlds of Th ′ . We shall call this initial sequence
468

of worlds thread Th. This is interpretation I (we know this is the only possible
interpretation for the first tmax − 1 worlds of Th ′ by the inductive hypothesis). We
know the probability of a given w at time tmax is p(w). Hence, the only probability
for the thread Th ′ is I(Th) · p(w). Further, as the sum of the probabilities for all
threads in T equal to 1 (based on I), and as

P

w∈W

p(w) = 1, then the sum of the

probabilities for all threads in T ′ is 1. So, we have a contradiction, and exactly one
interpretation for K.
Therefore, as both K and (L, π) have exactly one satisfying interpretation,
then we know by the pigeon-hole principle and Theorem 6.5 that if I |= K then
I |= (L, π).

469

Appendix B
Appendix for Chapter 3

B.1
B.1.1

Complexity Proofs (Section 3.3)
Small-Model Lemma for APT-Logic

The following lemmas are not part of the main text, but are needed to prove
some of the theorems.
Let us define the “size” of a rational number

a
b

(where a, b are relatively prime)

as the number of bits it takes to represent a and b. As stated earlier, for both the
probaiblity bound of rules, as well as the values returned by frequency functions,
we assume that this is a fixed quantity. In [44], the authors provide another result
we can leverage to ensure that there is a solution to a linear program where the
solution can be represented with a polynomial number of bits.
Lemma 27. If a system of r linear inequalities and/or equalities with integer coefficients of length at most l has a nonnegetive solution, then it has a nonnegetive solution with at most r entries positive, and where the size of each solution is
470

O(r · l + r · log(l)). (Lemma 2.7 in [44]).
Lemma 28. APT-program K is consistent iff it has an interpretation that only
assigns non-zero probabilities to at most 2·|K|+1 threads and the probability assigned
to each thread can be represented with O(|K|·size+|K|·log(size)) bits (where size is
the maximum number of bits required to represent the result of a freuqency function
of probability bounds of a rule).
Proof. By Proposition 3.9 of [155], an APT-program is consistent iff there is a solution to the SLC constraints. By Remark 3.10 of [155], there are 2 · |K| + 1 constraints
in SLC. Hence, by Theorem 9, if there is a solution to the SLC constraints, then there
exists a solution where only 2 · |K| + 1 are given positive values. The second part
of the satement follows directly from Lemma 27. The statement of the theorem
follows.

B.1.2

Proof of Theorem 10

Deciding if APT-program K is consistent is NP-Complete if |K| is a polynomial
in terms of |BL |.
Proof. NP-Hardness by Theorem 3.4 of [155]. By Lemma 28, every consistent APTprogram must be associated with a set T ′ of threads, where |T ′ | ≤ 2·|K|+1 and that
there exists an interpretation I ′ which only assigns non-zero probabilities to threads
in T ′ and satisfies K. Hence, we use T ′ as a witness. We can check the witness
in polynomial time by setting up SLC constraints using only threads in T ′ rather
than T . By the statement, such a linear program will have a polynomial number of
471

variables. Hence, K is consistent iff there is a solution to this linear program (which
can be checked in PTIME). The statement follows.

B.1.3

Proof of Theorem 11

Deciding if APT-rule r is entailed by APT-program K is coNP-Complete if |K|
is a polynomial in terms of |BL |.
Proof. coNP-hardness by Theorem 4.2 of [155]. Let [ℓ, u] be the probability bounds
associated with r. Let num ∈ [0, 1] be a real number that is outside of [ℓ, u]. Create
new rule r′ that is the same as r except the probability bounds are [num, num].
Create APT-program K′ = K ∪ {r′ }. Note that if K′ is consistent, then r is not
entailed. Hence, we can check the consistency of K′ using a witness T ′ as described
in Theorem 10 as well as num. Note that this check can still be performed in
PTIME. The statement follows.

B.1.4

Proof of Theorem 12

Given APT-program K, interpretation I, and ptf φ, determining the maximum
ℓ and minimum u such that φ : [ℓ, u] is entailed by K and is satisfied by I is #P hard. Further, for constant ǫ > 0, approximating either the maximum ℓ and/or
minimum u within 2|BL |

1−ǫ

is NP-Hard.

For ease of readability, we divide the above theorem into three leammas. The
statement of the theorem follows directly from Lemmas 29 and 30. Throughout the
proof, we shall define the problem APT-OPT-ENT as follows:

472

APT-OPT-ENT
INPUT: APT-program K, interpretation I, and ptf φ
OUTPUT: maximum ℓ and minimum u such that φ : [ℓ, u] is entailed by K and is
satisfied by I.
Lemma 29. APT-OPT-ENT is #P -hard.
Proof. Intuition Given an instance of #SAT (known to be #P-complete), we can
an instance of APT-ENT-OPT and such that #SAT ≤p APT-ENT-OPT.

Definition of #SAT:
INPUT: Set of atoms BL , formula f .
OUTPUT: Number of worlds in 2BL that satisfy f .

CONSTRUCTION:
1. Set F to be f .
2. Set t = 1.
3. For each a ∈ BL , add a : [1, 0.5, 0.5] to K.
4. Set tmax = 1.
5. We will consider BL (the set of atoms from the input of #SAT) as the set of
atoms used for the
6. input of APT-ENT-OPT.
473

7. Set IC ≡ ∅.
8. Interpretation Iunif orm sets each thread in T a probability of

1
|T |

For this construction, we shall denote the set of all threads formed with
tmax = 1 on set of atoms BL as T .
As step 3 is the only step of the construction that cannot be done in constant time,
but requires O(|BL |) time, so the construction is polynomial.

CLAIM 1: Interpretation Iunif orm satisfies K.
Each thread in T consists of only one world. For some atom a ∈ BL , half of all
possible worlds satisfy a. Hence, as Iunif orm is a uniform probability distribution
among threads, the sum of probabilities for all threads that satisfy a in the first
(and only) time point is 0.5. By the construction of K in step 3 in the construction,
the claim follows.

CLAIM 2: For any annotated formula F : [t, ℓ, u] that is entailed by K and satisfied
by Iunif orm , ℓ must equal u.
As K is satisfied by exactly one interpretation, Iunif orm , the sum of probabilities for
all threads that satisfy F at time t is bounded above and below by the same number.

CLAIM 3: If f is satisfied by exactly m worlds, then f : [1, 2|BmL | , 2|BmL | ] is entailed
by K.
Let W1 , . . . , Wm be the worlds that satisfy f . Let Th 1 , . . . , Th m be all the threads
474

in T where Th i ≡ Wi (Wi is the ith world that satisfies f ). As we have only one
time point, and our threads are created using BL , we know that the following holds:
m
X

Iunif orm (Th i ) =

i=1

m
2|BL |

This is equivalent to the following:
X

Iunif orm (Th)

Th∈T
Th(1)|=f

Hence, by claims 1-2 and the definition of satisfaction, the claim follows.
CLAIM 4: If f : [1, 2|BmL | , 2|BmL | ] is entailed by K, then f is satisfied by exactly m
worlds.
By claims 1-3 and the definition of satisfaction, there are exactly m threads that
satisfy f in the first time point. As there is only one time point per threads, there
are also m worlds that satisfy f . Since BL is the set of atoms for both the instance
of #SAT and APT-ENT-OPT, the statement follows.

The proof of the theorem follows directly from claims 3-4.
Lemma 30. For constant ǫ > 0, approximating APT-ENT-OPT (i.e. approximating outputs ℓ and/or u) within 2|BL |

1−ǫ

is NP-Hard.

Proof. Suppose, by way of contradiction, that approximating a solution within
2|BL |

1−ǫ

is easier than NP-Hard. Then, using the construction from the proof of

Theorem 29, we could approximate #SAT within 2|BL |

1−ǫ

. However, by [145] (The-

orem 3.2), approximating #2MONCNF, a more restricted version of #SAT, within
2|BL |

1−ǫ

is NP-hard. The statement follows.
475

B.2
B.2.1

Supplementary Information for Section 3.4
Proof of Proposition 3.4.1

If F1 : t1 ∧ . . . ∧ Fn : tn ∧ Fn+1 : t′1 ∧ . . . ∧ Fn+m : t′m and G1 : t1 ∧ . . . ∧ Gn :
tn ∧ Gn+1 : t′′1 ∧ . . . ∧ Gn+m : t′′m are time conjunctions, then
(F1 ∧G1 ) : t1 ∧. . .∧(Fn ∧Gn ) : tn ∧Fn+1 : t′1 ∧. . .∧Fn+m : t′m ∧Gn+1 : t′′1 ∧. . .∧Gn+m : t′′m
is also a time conjunction.
Proof. Straightforward from the definitions of satisfaction and time conjunction.

B.2.2

Proof of Proposition 14

For formulas F, G, time ∆t, and time conjunction φ,
EF R(F, G, ∆t, φ) ⊆


poss(φ, F, G, ∆t) + endposs(φ, F, G, ∆t)
cnt(φ, F, G, ∆t) + end(φ, F, G, ∆t)
,
denom(φ, F, G, ∆t) + end(φ, F, G, ∆t) denom(φ, F, G, ∆t) + endposs(φ, F, G, ∆t)

Proof. Straightforward from definitions.

B.2.3

Proof of Theorem 8

1. If I |= φ : [ℓ, u] and ρ : [ℓ′ , u′ ], then I |= φ ∧ ρ : [max(0, ℓ + ℓ′ − 1), min(u, u′ )]
2. If I |= φ : [ℓ, u] and ρ : [ℓ′ , u′ ], then I |= φ ∨ ρ : [max(ℓ, ℓ), min(1, u + u′ )]
3. If I |= φ : [ℓ, u] and φ ⇒ ρ then I |= ρ : [ℓ, 1]
4. If I |= φ : [ℓ, u] and ρ ⇒ φ then I |= ρ : [0, u]
476



5. If I |= φ : [ℓ, u] then I |= ¬φ : [1 − u, 1 − ℓ]
Proof. Adapted from Theorem 1 of [128] and Definition 32, except case 5:
Suppose, BWOC, I |= φ : [ℓ, u] and I 6|= ¬φ : [1 − u, 1 − ℓ]. By the definition of
satisfaction:
ℓ≤

X

Th∈T
Th|=φ

I(Th) ≤ u

By the definitoin of negation, we know that:
X

Th∈T
Th|=¬φ

I(Th) = 1 −

X

I(Th)

Th∈T
Th|=φ

Hence,
ℓ≤

X

Th∈T
Th|=¬φ

I(Th) ≤ u

Which, by the definition of satisfaction, gives a contradiction.

B.2.4

Proof of Theorem 13
ef r

If interpretation I |= φ : [1, 1] where EF R(F, G, ∆t, φ) ⊆ [α, β], I |= F ; G :
[∆t, α, β].
Proof. CLAIM 1: If interpreataion I satisfies φ : [ℓ, u] and EF R(F, G, ∆t, φ) ⊆
ef r

[α, β], then I |= F ֒→ G : [∆t, ℓ, 1, α, β].
ef r

Suppose, BWOC, there exists interpreation I s.t. I |= φ : [ℓ, u] and I 6|= F ֒→ G :
[∆t, ℓ, 1, α, β]. By the definition of satisfaction, we know that:
ℓ≤

X

Th∈T
Th|=φ

I(Th) ≤ u

477

As EF R(F, G, ∆t, φ) ⊆ [α, β], we know that:
X

Th∈T
Th|=φ

I(Th) ≤

X

I(Th)

Th∈T
ef r(Th,F,G,∆t)∈[α,β]

Hence,
ℓ≤

X

I(Th) ≤ 1

Th∈T
ef r(Th,F,G,∆t)∈[α,β]
ef r

So, by the definition of satisfaction, I |= F ֒→ G : [∆t, ℓ, 1, α, β] – a contradiction.
ef r

CLAIM 1.1: If I |= φ[1, 1], then I |= F ֒→ G : [∆t, 1, 1, α, β] (directly from claim
1).

ef r

ef r

CLAIM 2: If interpretation I satisfies F ֒→ G : [∆t, ℓ, u, α, β], then I |= F ;
ef r

G : [∆t, α · ℓ, 1]. Suppose, BWOC, there exists interpreation I s.t. I |= F ֒→ G :
ef r

[∆t, ℓ, u, α, β] and I 6|= F ; G : [∆t, α · ℓ, 1]. By the definition of satisfaction,
ℓ≤

X

Th∈T
ef r(Th,F,G,∆t)∈[α,β]

I(Th) ≤ u

We multiply through by α:
α·ℓ≤

X

Th∈T
ef r(Th,F,G,∆t)∈[α,β]

α · I(Th)

It follows that:
α·ℓ≤

X

Th∈T
ef r(Th,F,G,∆t)∈[α,β]

α · I(Th) +

X

Th∈T
ef r(Th,F,G,∆t)∈[α,β]
/

ef r(Th, F, G, ∆t) · I(Th)

and
X

Th∈T
ef r(Th,F,G,∆t)∈[α,β]

α · I(Th) ≤

X

Th∈T
ef r(Th,F,G,∆t)∈[α,β]

478

ef r(Th, F, G, ∆t) · I(Th)

Hence, it follows that:
α·ℓ≤

X

Th∈T

ef r(Th, F, G, ∆t) · I(Th) ≤ 1
ef r

So, by the definition of satisfaction, I |= F ; G : [∆t, α · ℓ, 1] – which is a contraef r

diction. CLAIM 2.1: If I |= φ[1, 1], then I |= F ; G : [∆t, α, 1]. (follows directly
from claims 1.1 and 2).

ef r

ef r

CLAIM 3: If interpretation I satisfies F ֒→ G : [∆t, 1, 1, α, β], then I |= F ; G :
ef r

ef r

[∆t, 0, β]. Suppose, BWOC, I |=֒→ G : [∆t, 1, 1, α, β] and I 6|= F ; G : [∆t, 0, β].
By the definiton of satisfaction:
X

I(Th) =

Th∈T
ef r(Th,F,G,∆t)∈[α,β]

X

I(Th) = 1

Th∈T

Hence,
X

Th∈T

β · I(Th) = β

We know that:
0≤

X

Th∈T

ef r(Th, F, G, ∆t) · I(Th) ≤

X

Th∈T

β · I(Th)

Which leads to:
0≤

X

Th∈T

ef r(Th, F, G, ∆t) · I(Th) ≤ β

Which, by the definition of satisfaction, gives us a contradiction.
PROOF OF THEOREM: Follows directly from claims 2.1 and 3.

479

B.2.5

Proof of Corollary 2
ef r

If interpretation I |= φ : [ℓ, u] where EF R(F, G, ∆t, φ) ⊆ [α, β], I |= F ; G :
[∆t, α · ℓ, 1].
Proof. Follows directly from the first two claims of Theorem 13.

B.2.6

Proof of Theorem 14

Given time formulas φ, ρ s.t. EF R(F, G, ∆t, φ) ⊆ [α1 , β1 ] and EF R(F, G, ∆t, φ∧
ef r

ρ) ⊆ [α2 , β2 ] and interpretation I that satisfies φ : [1, 1] (see note1 ) and F ; G :
[∆t, ℓ, u]:
1
1. If β2 < β1 , then I |= ρ : [0, min( βℓ−β
, 1)]
2 −β1
1
, 1)]
2. If α2 > α1 , then I |= ρ : [0, min( αu−α
2 −α1

Proof. CLAIM 1: Given time formulas φ, ρ s.t. EF R(F, G, ∆t, φ) ⊆ [α1 , β1 ] and
EF R(F, G, ∆t, φ ∧ ρ) ⊆ [α2 , β2 ] (where β2 < β1 ) and interpretation I that satisfies
ef r

1
, 1)].
φ : [1, 1] and F ; G : [∆t, ℓ, u] (ℓ ≤ β1 ), I |= ρ : [0, min( βℓ−β
2 −β1

1
Assume, BWOC, I 6|= ρ : [0, βℓ−β
]. By the definition of satisfaction, we know
2 −β1

that:
ℓ≤

X

Th∈T

ef r(Th, F, G, ∆t) · I(Th)

As I |= φ : [1, 1] and EF R(F, G, ∆t, φ) ⊆ [α1 , β1 ], we have:
ℓ≤
1

X

Th∈T
ef r(Th,F,G,∆t)∈[α1 ,β1 ]

ef r(Th, F, G, ∆t) · I(Th)

Note that Theorem 13 requires ℓ ≤ β1 and α1 ≤ u

480

We note that all threads either satisfy ρ or not. Hence, we have:
X

X

I(Th) +

I(Th) = 1

Th∈T
ef r(Th,F,G,∆t)∈[α1 ,β1 ]
Th6|=ρ

Th∈T
ef r(Th,F,G,∆t)∈[α1 ,β1 ]
Th|=ρ

Therefore:
ℓ≤

X

Th∈T
ef r(Th,F,G,∆t)∈[α1 ,β1 ]
Th|=ρ

β2 · I(Th) +

X

Th∈T
ef r(Th,F,G,∆t)∈[α1 ,β1 ]
Th6|=ρ

β1 · I(Th)

and:

ℓ ≤ β2 ·

X

Th∈T
ef r(Th,F,G,∆t)∈[α1 ,β1 ]
Th|=ρ

ℓ − β1 ≤ β2 ·

X

I(Th) + β1 · (1 −

Th∈T
ef r(Th,F,G,∆t)∈[α1 ,β1 ]
Th|=ρ

I(Th) − β1 ·

X

I(Th))

Th∈T
ef r(Th,F,G,∆t)∈[α1 ,β1 ]
Th|=ρ

X

I(Th))

Th∈T
ef r(Th,F,G,∆t)∈[α1 ,β1 ]
Th|=ρ

Notice that ℓ − β1 ≤ 0 as ℓ ≤ β1 by the statement. Also, we know that β2 < β1 , the
quantity β2 − β1 is negative. We have the following:
X
ℓ − β1
I(Th)
≥
β2 − β1 Th∈T
Th|=ρ

By the definition of satisfaction, this gives us a contradiction.

CLAIM 2: Given time formulas φ, ρ s.t. EF R(F, G, ∆t, φ) ⊆ [α1 , β1 ] and
EF R(F, G, ∆t, φ ∧ ρ) ⊆ [α2 , β2 ] (α2 > α1 ) and interpretation I that satisfies
ef r

1
, 1)].
φ : [1, 1] and F ; G : [∆t, ℓ, u] (α1 ≤ u or inconsistent), I |= ρ : [0, min( αu−α
2 −α1

481

1
Assume, BWOC, I 6|= ρ : [0, αu−α
]. By the definition of satisfaction, we know that:
2 −α1

X

Th∈T

ef r(Th, F, G, ∆t) · I(Th) ≤ u

Hence, as all threads either satisfy ρ or not, and as I |= φ : [1, 1], we know that all
threads must also have a α1 lower bound for the frequency function, and that the
threads satisfying ρ must have α2 as a lower bound. So, we have the following:
X

Th∈T
Th|=ρ

α2 · I(Th) +

X

Th∈T
Th6|=ρ

α1 · I(Th) ≤ u

As we know the sum of all theads must be 1, we have the following:
α2 ·

X

Th∈T
Th|=ρ

I(Th) + α1 · (1 −

(α2 − α1 ) ·

X

Th∈T
Th|=ρ

X

Th∈T
Th|=ρ

I(Th)) ≤ u

I(Th) ≤ u − α1

As, by the statement, we know the quantities α2 − α1 and u − α1 are positive, we
have the following:
X

Th∈T
Th|=ρ

I(Th) ≤

u − α1
α2 − α1

Which, by the definition of satisfaction, gives us a contradiction.
Proof of theorem: Follows directly from claims 1-2.

B.2.7

Proof of Proposition 15

If for atoms Ai and program K, if BLK(Ai ) :< blki ∈ K and if there exists a
ptf φ : [1, 1] ∈ K such that φ ⇒ Ai : t − blki + 1 ∧ Ai : t − blki + 2 ∧ . . . ∧ Ai : t − 1
then K entails A : t : [0, 0].
482

Proof. Suppose, BWOC, there exists interpretation I s.t. I |= K and I 6|= A :
t : [0, 0]. As I |= K, we know I |= BLK(Ai ) :< blki . Hence, for all therads s.t.
I(Th) 6= 0, there does not exist a series of blki or more consecutive worlds in Th
satisfying atom Ai . We note that as I |= φ : [1, 1], then I |= Ai : t − blki + 1 ∧ Ai :
t − blki + 2 ∧ . . . ∧ Ai : t − 1 : [1, 1] by the statement. Hence, there is a sequence
of blki − 1 consecutive worlds satisfying Ai in every thread assigned a non-zero
probability by I. So, by the definition of satisfaction, we have a contradiction.

B.2.8

Proof of Proposition 16

If for atoms Ai and program K, if OCC(Ai ) : [loi , upi ] ∈ K and if there exists
a ptf φ : [1, 1] ∈ K such that there are numbers t1 , . . . , tupi ∈ {1, . . . , tmax } where
φ ⇒ Ai : t1 ∧ . . . ∧ Ai : tupi then for any t ∈
/ {t1 , . . . , tupi } K entails A : t : [0, 0].
Proof. Suppose, BWOC, there exists interpretation I s.t. I |= K and I 6|= A : t :
[0, 0]. As I |= K, we know I |= OCC(Ai ) : [loi , upi ]. Hence, for all therads s.t.
I(Th) 6= 0, there does not exist more than upi worlds in Th satisfying atom Ai .
We note that as I |= φ : [1, 1], then I |= Ai : t1 ∧ . . . ∧ Ai : tupi : [1, 1] by the
statement. Hence, there are upi worlds satisfying Ai in every thread assigned a nonzero probability by I. So, by the definition of satisfaction, we have a contradiction.

B.2.9

Proof of Proposition 17

Given APT-program K, the following are true:
483

• ∀I s.t. I |= K, I |= Γ(K)
• ∀I s.t. I |= Γ(K), I |= K
Proof. Follows directly from Theorems 13-14 and Corollary 2.

B.2.10

Proof of Proposition 18

One iteration of Γ can be performed in time complexity O(|K|2 · CHK) where
CHK is the bound on the time it takes to check (for arbitrary time formulas φ, ρ if
φ |= ρ is true.
Proof. To compare a given element of K with every other element (not conjuncts of
elements) - we obviously need O(|K| · CHK) time. As we do this for every element
in K, the statement follows.

B.2.11

Proof of Lemma 9

Given ⊥ ≡ {} and ⊤ ≡ inconsistent, then hP ROGBL ,tmax , ⊑i is a complete
lattice.
Proof. We must show that for any subset P ROG′ of P ROGBL ,tmax , that inf (P ROG′ )
and sup(P ROG′ ) exist in P ROGBL ,tmax . We show this for P ROGBL ,tmax as a set
of APT-programs, and the result obviously extends for P ROGBL ,tmax as a set of
equivalence classes of APT-programs.

CLAIM 1: For a set P ROG′ of APT-programs, inf (P ROG′ ) exists and is in
P ROGBL ,tmax .
484

Let P ROG′ = {K1 , . . . , Ki , . . . , Kn }. We create K′ ≡ inf (P ROG′ ) as follows. Consider all φ such that φ : [ℓi , ui ] appears in each Ki . Add φ : [min(ℓi ), max(ui )] to K′ .
ef r

Next, consider all F, G, ∆t s.t. F ; G : [∆t, ℓi , ui ] appears in all Ki . Add F, G, ∆t
ef r

s.t. F ; G : [∆t, min(ℓi ), max(ui )] to K′ . Clearly, for each element in K′ , there
is an element in every Ki with the same or tighter probability bounds. It is also
obvious tha K′ ∈ P ROGBL ,tmax . Assume that there is a K′′ (not equivalent to K′ )
that is below each Ki but above K′ . Then, for all elements in K′ , there must be a
corresponding element (with tighter probability bounds) in K′′ s.t. the probability
bounds is looser than any Ki . However, by the construction, this is clearly not
possible unless K′ ≡ K′′ , so we have a contradiction.

CLAIM 2: For a set P ROG′ of APT-programs, sup(P ROG′ ) exists and is in
P ROGBL ,tmax .
Let P ROG′ = {K1 , . . . , Ki , . . . , Kn }. Let K′ =

S

i {Ki }.

Clearly, by the defini-

tion of ⊑, this is a least upper bound of P ROG′ . We must show that K′ is in
P ROGBL ,tmax . We have two cases. (1) If K′ is inconsistent, then it is equivalent to
⊤ and in P ROGBL ,tmax . (2) If K′ is consistent, then it is also in P ROGBL ,tmax .

B.2.12

Proof of Lemma 10

K ⊑ Γ(K).
Proof. Follows directly from the definition of Γ - all rules and ptf’s in K are in Γ(K)
with equivalent or tighter probability bounds. All IC’s in K remain in Γ(K).
485

B.2.13

Proof of Lemma 11

Γ is monotonic.
Proof. Given K1 ⊑ K2 , we must show Γ(K1 ) ⊑ Γ(K2 ). Suppose, BWOC, there
exists φ : [ℓ, u] ∈ Γ(K1 ) (see note 2 ) s.t. there does not exist φ : [ℓ′ , u′ ] ∈ Γ(K2 )
where [ℓ′ , u′ ] ⊆ [ℓ, u]. Therefore, there must exist a set of ptf’s and/or rules (call
this set K1′ ) in K1 s.t. for each element in K1′ , there does not exist a an element in
K2 s.t. the probability bounds are tighter. However, as K1 ⊑ K2 , this cannot be
possible, and we have a contradiction.

B.2.14

Proof of Theorem 15

Γ has a least fixed point.
Proof. Follows directly from Lemma 10 and Lemma 11.

B.2.15

Proof of Lemma 12
ef r

If APT-logic program K entails rule F ; G : [∆t, ℓ, u] or φ : [ℓ, u] such that
one of the following is true:
•ℓ>u
• ℓ < 0 or ℓ > 1
• u < 0 or u > 1
2

ef r

Resp. F ; G : [∆t, ℓ, u] ∈ Γ(K1 ), we note that the proof can easily be mirrored for rules, we

only show with ptfs here.

486

Then K is inconsistent - i.e. there exists no interpretation I such that I |= K.
Proof. Following directly from the definitions of satisfaciton and entailment, if K
entails such a rule or ptf, there can be no satisfying interpreation.

B.2.16

Proof of Theorem 4

For APT-logic program K, if there exists natural number i such that Γ(K) ↑ i
ef r

that contains rule F ; G : [∆t, ℓ, u] or φ : [ℓ, u] such that one of the following is
true:
•ℓ>u
• ℓ < 0 or ℓ > 1
• u < 0 or u > 1
Then K is inconsistent.
Proof. We know by Propositions 17 that any number of applications of Γ result in
an APT-program entailed by K. Therefore, all of the elemenets of that program
must be entailed by K. By Lemma 12, the statement follows.

B.2.17

Proof of Proposition 19

If there does not exist at least one thread that satisfies all integrity constraints
in an APT-logic program, then that program is inconsistent.
Proof. For an APT-logic program to be consistent, then there must exist a satisfying
interpretation such that the sum of the probabilities assigned to all threads is 1.
487

However, if there is no thread that satisfies all integrity constraints, then the sum of
the probabilities of all threads in a satisfying interpretation is 0 – a contradiction.

B.2.18

Proof of Proposition 20

If loi >

l

(blki −1)·tmax
blki

m

then there does not exist a partial thread for ground

atom Ai such that the single block-size and occurrence IC associated with Ai hold.
Follows directly from the following Proposition:
Proposition 82. For atom ai , block size blki and tmax , if more than

l

(blki −1)·tmax
blki

worlds must be true, then all partial threads will have a block of size blki .
Proof. CLAIM 1: If we require less than (or equal)

l

(blki −1)·tmax
blki

m

m

worlds to satisfy

the atom, there exists at least one partial thread that does not contain a block.
Simply consider blki − 2 sub-sequences of blki − 1 worlds, and one sub-sequence of
≤ blki − 1 worlds satisfying atom ai - each separated by a world that does not satisfy
ai . Obviously, this partial thread does not contain a block.

CLAIM 2: If we require more than

l

(blki −1)·tmax
blki

m

worlds to satisfy the atom, there

can be no sequence of two consecutive worlds that do not satisfy ai , or there exists
a block.
This follows from the pigeon hole principle - if two consecutive worlds satisfy ¬ai ,
then there must exists a sequence of at least blki worlds that satisfy ai .

PROOF OF PROPOSITION: Suppose we have a partial thread with
488

l

(blki −1)·tmax
blki

m

worlds satisfying the atom, and require one additional world to satisfy ai . By claim
2, this world must be between two sub-sequences, as there are no more than two
non-satisfying worlds, hence the statement of the proposition follows.

B.2.19

Proof of Propositon 21
l

(blki −1)·tmax
blki

m

we know
hl
i
m
(blki −1)·tmax
that for numbers of worlds satisfying Ai cannot be in the range
, upi .
blki
For ground atom Ai with (with associated ICs), if upi >

Proof. As, in this case, upi >

l

(blki −1)·tmax
blki

m

, lowering the value of upi will not cause

an inconsistency unless Proposition 20 applies. We note that by Proposition 82, we
cannot have threads with more than this amount of worlds satisfying ai .

B.2.20

Proof of Proposition 22

ThEX can be solved in O(1).
Proof. As the check in Proposition 20 can be performed in O(1) time, the statement
follows.

B.3
B.3.1

Proofs for Section 3.5
Proof of Lemma 13

Given non-ground formulas Fng , Gng , time ∆t, and non-ground time formula
φng . Let (αin , βin ) = EF R IN (Fng , Gng , ∆t, φng ) and
[αout , βout ] = EF R OU T (Fng , Gng , ∆t, φng ). Then the following holds true:
489

1. If Th |= φng , then for all ground instances F, G of Fng , Gng we have
efr(F, G, ∆t, Th) ∈ [αout , βout ]
2. If Th |= φng , then there exists ground instances F, G of Fng , Gng we have
efr(F, G, ∆t, Th) ≥ αin
3. If Th |= φng , then there exists ground instances F, G of Fng , Gng we have
efr(F, G, ∆t, Th) ≤ βin
Proof. CLAIM 1: Part 1 is true..
Suppose, BWOC, there is some thread, Th |= φng s.t. there are ground instances
F, G of Fng , Gng s.t. efr(F, G, ∆t, Th) ∈
/ [αout , βout ]. This directly contradicts Definition 48.
CLAIM 2: Part 2 is true.
This directly contradicts Definition 48.
CLAIM 3: Part 3 is true.
This directly contradicts Definition 48.

B.3.2

Proof of Theorem 16

Given non-ground APT-program K(ng) that contains the following:
ef r

Non-ground rule: Fng ; Gng : [∆t, ℓ, u]
Non-ground ptf:

φng : [1, 1]

−
+
Let (αin , βin ) = EF R IN (Fng , Gng , ∆t, φng ). If we are given αin
≤ αin and βin
≥

βin , then, K(ng) is not consistent if one (or both) of the following is true:
490

−
1. αin
>u

+
2. βin
<ℓ

−
Proof. CLAIM 1: If αin
> u, then K(ng) is not consistent.
−
> u and K(ng) is consistent. Then, by Lemma 13 there
Suppose, BWOC that αin
−
exists ground instances F, G of Fng , Gng s.t. EFR(F, G, ∆t, gnd(φng )) ⊆ [αin
, 1].
ef r

−
Therefore, by Theorem 13, K(ng) entails F ; G : [∆t, αin
, 1]. However, as K(ng)
ef r

ef r

includes Fng ; Gng : [∆t, ℓ, u], then K(ng) also entails F ; G : [∆t, ℓ, u]. As
−
[αin
, 1] ∩ [ℓ, u] = ∅, we know that K(ng) cannot be consistent (by Lemma 12) – a

contradiction.

+
< ℓ, then K(ng) is not consistent.
CLAIM 2: If βin
+
< ℓ and K(ng) is consistent. Then, by Lemma 13 there
Suppose, BWOC, that βin
+
exists ground instances F, G of Fng , Gng s.t. EFR(F, G, ∆t, gnd(φng )) ⊆ [0, βin
].
ef r

+
Therefore, by Theorem 13, K(ng) entails F ; G : [∆t, 0, βin
]. However, as K(ng)
ef r

ef r

includes Fng ; Gng : [∆t, ℓ, u], then K(ng) also entails F ; G : [∆t, ℓ, u]. As
+
[0, βin
] ∩ [ℓ, u] = ∅, we know that K(ng) cannot be consistent (by Lemma 12) – a

contradiction.

491

B.3.3

Proof of Corollary 5

Given non-ground APT-program K(ng) that contains the following:
ef r

Non-ground rule: Fng ; Gng : [∆t, ℓ, u]
φng : [ℓ′ , u′ ]

Non-ground ptf:

−
+
Let (αin , βin ) = EF R IN (Fng , Gng , ∆t, φng ). If we are given αin
≤ αin and βin
≥
−
· ℓ′ > u.
βin , then, K(ng) is not consistent if αin
−
Proof. Suppose, BWOC, αin
· ℓ′ > u and K(ng) is consistent. Then, by Lemma 13

there exists ground instances F, G of Fng , Gng s.t.

EFR(F, G, ∆t, gnd(φng )) ⊆

ef r

−
−
[αin
, 1]. Therefore, by Corollary 2, K(ng) entails F ; G : [∆t, αin
· ℓ′ , 1]. However,
ef r

ef r

as K(ng) includes Fng ; Gng : [∆t, ℓ, u], then K(ng) also entails F ; G : [∆t, ℓ, u].
−
As [αin
· ℓ′ , 1] ∩ [ℓ, u] = ∅, we know that K(ng) cannot be consistent (by Lemma 12)

– a contradiction.

B.3.4

Proof of Proposition 23

If the list returned by NG-INCONSIST-CHK contains any elements, then K(ng)
is not consistent.
Proof. Follows directly from Theorem 16 and Corollary 5.

B.3.5

Proof of Proposition 24

NG-INCONSIST-CHK performs O(|K(ng) |2 ) comparisons.

492

Proof. The algorithm consists of two nested loops. The outer loop considers all ptf’s
in the program – requiring O(|K(ng) |) time, while the inner loop considers all rules
in the program – also requiring O(|K(ng) |) time. The statement follows.

B.3.6

Proof of Lemma 14

K ⊆ ΛK(ng) (K) wrt hP ROGBL ,tmax , ⊑i
Proof. Follows directly from Definition 49.

B.3.7

Proof of Lemma 15

ΛK(ng) is monotonic.
Proof. Given K1 ⊑ K2 (both ground), we must show ΛK(ng) (K1 ) ⊑ ΛK(ng) (K2 ).
Suppose, BWOC, there is an element (rule, ptf, or IC) of ΛK(ng) (K1 ) that either has
a tighter probability bound than a corresponding element in ΛK(ng) (K2 ) or not in
ΛK(ng) (K2 ). However, this is a contradiction as all elements in K1 are in K2 – or
in K2 with a tighter probability bound. Therefore, such an element would be in
ΛK(ng) (K2 ) – a contradiction.

B.3.8

Proof of Theorem 17

ΛK(ng) has a least fixed point.
Proof. Follows directly from Lemma 14 and Lemma 15.

493

B.3.9

Proof of Lemma 16

Given non-ground program K(ng) , and ground program K, lf p(ΛK(ng) (K)) ⊆
ground(K(ng) ) ∪ K.
Proof. Suppose, BWOC, that lf p(ΛK(ng) (K)) 6⊆ ground(K(ng) ) ∪ K. Then, there
must exist a ground rule, ptf, or IC in element in lf p(ΛK(ng) (K)) that is not in
ground(K(ng) ) ∪ K. However, all elements in lf p(ΛK(ng) (K)) are either elements of
K or ground instances of elements in K(ng) – hence a contradiction.

B.3.10

Proof of Theorem 18
ef r

Definition 110 (Tightening). For APT-rule F ; G : [∆t, ℓ, u] or ptf φ : [ℓ, u], for
any [ℓ′ , u′ ] ⊆ [ℓ, u],
ef r

ef r

1. F ; G : [∆t, ℓ′ , u′ ] is a tightening of F ; G : [∆t, ℓ, u]
2. φ : [ℓ, u] is a tightening of φ : [ℓ′ , u′ ]
ef r

Definition 111 (Update). Given ground APT-program K, ground rule r = F ;

G : [∆t, ℓ1 , u1 ], and ground ptf p = φ : [ℓ2 , u2 ], any tightening to the bounds of r or
p causes by an application of the operator Γ is an update.
Definition 112 (Update Widget). Given ground APT-program K, ground rule r =
ef r

F ; G : [∆t, ℓ1 , u1 ], and ground ptf p = φ : [ℓ2 , u2 ], ground atomic time formula
A : t, we define the following update widgets.
ef r

1. Let the ground rule r′ = F ; G : [∆t, ℓ′ , u′ ] be a tightening of r where
ℓ′ = l bnd(F, G, ∆t, K) or u′ = u bnd(F, G, ∆t, K). Then an update widget
494

consists of a graph of a vertex vr′ for r′ (called a top vertex) and set V of
vertices - one vertex for each ground rule and ptf in K that led to the tightening
(as per Definition 41) (called bottom vertices) and directed edges from all
elements in V to vr′ .
2. Let the ground ptf p′ = φ : [ℓ′ , u′ ] be a tightening of φ : [ℓ2 , u2 ] where ℓ′ ∈
{l bnd(φ, K), 1 − u bnd(¬φ, K)} or u′ ∈ {u bnd(φ, K), 1 − l bnd(¬φ, K)}.
Then an update widget consists of a graph of a vertex vp′ for p′ (called
a top vertex) and set V of vertices - one vertex for each ground rule and ptf
in K that led to the tightening (as per Definition 41) (called bottom vertices)
and directed edges from all elements in V to vp′ .
3. If K entails A : t : [0, 0] due to the presence of ptf ’s and IC’s (as per Propositions 15-16), then Then an update widget consists of a graph of a vertex
vA:t:[0,0] for A : t : [0, 0] (called a top vertex) and set V of vertices - one for
each IC and ptf in K that led to the entailment of A : t : [0, 0] (called bottom
vertices) and directed edges from all elements in V to vr′ .
Definition 113 (Deduction Tree). A series of update widgets with the top vertices of
all but one widgets are the bottom vertices for another widget is called a deduction
tree. A vertex that is not a bottom vertex for any widget in the tree is a root and
a vertex that is not top vertex for any widget in the tree is a leaf. For a given
deduction tree, T , let leaf (T ) be the set of ptf ’s or rules corresponding with leaf
nodes in the tree.

495

Definition 114 (Corresponding Deduction Tree). Given ground APT-program K,
for ground ptf p = φ : [ℓ2 , u2 ], s.t. p ∈ lf p(Γ(K)), then the corresponding deduction tree is a deduction tree, rooted in a node representing p s.t. for each update
performed by Γ, there is a corresponding update widget in the tree. For program K
and ptf p, let TK,p be the corresponding deduction tree.
Lemma 31. If φ : [ℓ, u] ∈ lf p(Γ(K ∪ {φ : [0, 1]}) then there exists φ : [ℓ′ , u′ ] ∈
lf p(Γ(leaf (TK,φ:[ℓ,u] ) ∪ {φ : [0, 1]}) s.t. [ℓ′ , u′ ] ⊆ [ℓ, u].
Proof. Suppose, BWOC, that [ℓ′ , u′ ] 6⊆ [ℓ, u]. Then, there must exist an update
performed by Γ that uses some ptf or rule other ∈ K s.t. other ∈
/ leaf (TK,φ:[ℓ,u] ).
However, by the Definition 114 this is not possible as TK,φ:[ℓ,u] accounts for all updates
performed by Γ.
Theorem 18
Given non-ground program K(ng)
φ : [ℓ, u] ∈ lf p(Γ(lf p(ΛK(ng) ({φ : [0, 1]}))))
iff
φ : [ℓ, u] ∈ lf p(Γ(ground(K(ng) ) ∪ {φ : [0, 1]}))
Proof. CLAIM 1: If φ : [ℓ, u] ∈ lf p(Γ(lf p(ΛK(ng) ({φ : [0, 1]})))) then for some
[ℓ′ , u′ ] ⊆ [ℓ, u], φ : [ℓ′ , u′ ] ∈ lf p(Γ(ground(K(ng) ) ∪ {φ : [0, 1]})).
By Lemma 16, we know that lf p(ΛK(ng) ({φ : [0, 1]})) ⊆ ground(K(ng) ) ∪ {φ : [0, 1]},
so the claim follows.

496

CLAIM 2: If φ : [ℓ, u] ∈ lf p(Γ(ground(K(ng) ) ∪ {φ : [0, 1]})) then for some [ℓ′ , u′ ] ⊆
[ℓ, u], φ : [ℓ, u] ∈ lf p(Γ(lf p(ΛK(ng) ({φ : [0, 1]})))).
By Definition 49 and Definition 114, leaf (TK,φ:[ℓ,u] ) ∪ {φ : [0, 1]} ⊆ lf p(ΛK(ng) ({φ :
[0, 1]})). Hence, we can apply Lemma 31 and the claim follows.
The statement of the theorem follows directly from claims 1-2.

B.4
B.4.1

Supplemental Information for Section 3.6
Proof of Proposition 25

OC-EXTRACT runs in time O((n − tmax ) · tmax ).
Proof. This follows directly from the two for loops in the algorithm - the first iterating (n − tmax ) time and a nested loop iterating tmax times.

B.4.2

Proof of Proposition 26

There are no historical threads such that atom ai is satisfied by less than loi
or more than upi worlds when loi , upi are produced by OC-EXTRACT.
Proof. Suppose, by way of contradiction, that there exists a historical thread that
does not meet the constraints. As we examine all possible historical threads in OCEXTRACT and take the minimum and maximum number of times ai is satisfied over
all these threads, we have a contradiction.

497

B.4.3

Proof of Proposition 27

BLOCK-EXTRACT runs in time O(n).
Proof. Follows directly from the for loop in the algorithm - which iterates n times.

B.4.4

Proof of Proposition 28

Given blki as returned by BLOCK-EXTRACT, there is no sequence of blki or
more consecutive historical worlds that satisfy atom ai .
Proof. Suppose there is a sequence of at least blki or more. However, the algorithm
maintains the variable best which is the greatest number of consecutive time points
in the historical data where ai is true – this is a contradiction.

498

Appendix C
Appendix for Chapter 4

C.1
C.1.1

Proofs
Proof of Theorem 19

k-SEP is NP-Complete.
Proof. Geometric Covering by Discs. (GCD)
INPUT: A set P of integer-coordinate points in a Euclidean plane, positive integers
b > 0 and k < |P |.
OUTPUT: “Yes” if there exist k discs of diameter b centered on points in P such
that there is a disc covering each point in P — “no” otherwise.
CLAIM 1: k-SEP is in the complexity class NP.
Suppose a non-deterministic algorithm can guess a set E that is a k-sized simple
(α, β) explanation for O. We can check the feasibility of every element in E in
O(|E|) time and compare every element of E to every element of O in O(|O|2 ) time.
Hence, k-SEP is in the complexity class NP as we can check the solution in poly499

Algorithm 25 (GCD-TO-KSEP)
INPUT: Instance of GCD hS, P, b, ki
OUTPUT: Instance of k-SEP hS, O, feas, α, β, k ′ i
1. Set S to be a set of lattice points in the Euclidean plane that include all points
in P
2. Set O = P
3. Let f eas(x) = TRUE iff x ∈ P
4. Set α = 0
5. Set β = b/2
6. Set k ′ = k

500

nomial time.

CLAIM 2: k-SEP is NP-Hard.
We use the polynomial algorithm GCD-TO-KSEP to take an instance of GCD and
create an instance of k-SEP.

CLAIM 2.1: If there is a k ′ -sized simple (α, β) explanation for O, then there are k
discs, each centered on a point in P of diameter b that cover all points in P .
Let E be the k ′ -sized simple (α, β) explanation for O. Suppose by way of contradiction, that there are not k discs, each centered on a point in P of diameter b
that cover all points in P . As k ′ = k, and all elements of E must be in P by the
definition of feas, let us consider the k discs of diameter b centered on each element of E. So, for these discs to not cover all elements of P , there must exist an
element of P , that is not covered by a disc. As P ≡ O, then there must exist an
element of O outside of one of the discs. Note that all elements of O are within
a distance β of an element of E by the definition of a k ′ -sized simple (α, β) explanation (as α = 0). As β = b/2, each element of O falls inside a disc of diameter
b centered on an element of E, thus falling within a disc and we have a contradiction.

CLAIM 2.2: If there are k discs, each centered on a point in P of diameter b that
cover all points in P then there is a k ′ -sized simple (α, β) explanation for O.
Let set E be the set of points that are centers of the k discs. We note that E ⊆ P .
Assume by way of contradiction, that there is no k ′ -sized simple (α, β) explanation
501

for O. Let us consider if E is a k ′ -sized simple (α, β) explanation for O. As k = k ′ ,
α = 0, and all points of E are feasible, there must be some o ∈ O such that ∀e ∈ E,
d(e, o) > β. As O ≡ P , we know that all points in O fall in a disc centered on a
point in E, hence each o ∈ O must be a distance of b/2 or less from a point in E.
As β = b/2, we have a contradiction.

C.1.2

Proof of Corollary 6

Cost-based Explanation is NP-Complete.
Proof. CLAIM 1: Cost-based Explanation is in the complexity class NP.
This follows directly from Theorem 19, instead of checking the size of E, we only
need to apply the function χ to the E produced by the non-deterministic algorithm
to ensure that χ(E) ≤ v.

CLAIM 2: Cost-based Explanation is NP-Hard.
We show k-SEP≤p CBE. Given an instance of k-SEP, we transform it into an
instance of CBE in polynomial time where χ(E) = |E| and v = k.

CLAIM 2.1: If there is a set E such that χ(E) ≤ v then |E| ≤ k.
Straightforward.

CLAIM 2.2: If there is a set E of size k or less then χ(E) ≤ v
Straightforward.

502

C.1.3

Proof of Corollary 7

WT-SEP is NP-Complete.
Proof. Membership in the complexity class NP follows directly from Theorem 19,
instead of checking the size of E, we check if

P

p∈E

c(p) ≤ v. We also note that

the construction for cost-based explanation in Theorem 19 is also an instance of
WT-SEP, hence NP-hardness follows immediately.

C.1.4

Proof of Theroem 20

TD-SEP is NP-Complete.
Proof. CLAIM 1: TD-SEP is in the complexity class NP.
Given a set E, we can easily determine in polynomial time that it meets the standards of the output specified in the problem statement.

CLAIM 2: TD-SEP is NP-hard.
Consider Euclidean k-Median Problem, as presented and shown to be NP-Complete
in [134], defined as follows:
INPUT: A set P of integer-coordinate points in a Euclidean plane, positive integer
k ′ < |P |, real number v ′ > 0.
OUTPUT: “Yes” if there is a set of points, S ⊆ P such that |S| = k ′ and
P

xi ∈X

minsj ∈S d(xi , sj ) ≤ v ′ — “no” otherwise.

503

Given an instance of the Euclidean k-Median Problem, we create an instance
of TD-SEP as follows:
• Set S to be a set of lattice points in the Euclidean plane that include all points
in P
• Set O = P
• Let f eas(x) = TRUE iff x ∈ P
• Set α = 0
• Set β greater than the diagonal of S ′
• Set k = k ′
• Set v = v ′
CLAIM 2.1: If there is E, a k-sized explanation for O such that
P

P

oi ∈O

minpj ∈E d(oi , pj ) ≤ v, then there is a set S ⊆ P such that |S| = k ′ and

xi ∈P

minsj ∈S d(xi , sj ) ≤ v ′ .

Because of how we set feas and O, E ⊆ P . As α and β do not affect E, the only real
restrictions on E is that its cardinality is k and that

P

oi ∈O

minpj ∈E d(oi , pj ) ≤ v.

Because of how we set k and v, we can see that E meets all the conditions to be a
solution to the Euclidean k-Median problem, hence the claim follows.

CLAIM 2.2: If there is set S ⊆ P such that |S| = k ′ and

P

then there is set E, a k-sized explanation for O such that
504

xi ∈P

P

minsj ∈S d(xi , sj ) ≤ v ′ ,

oi ∈O

minpj ∈E d(oi , pj ) ≤ v.

In the construction, the arguments α, β and feas allow any element of a solution to
the k-Median problem to be a partner for any observation in O. By how we set k
and v, we can easily see that S is a valid solution to TD-SEP. The claim follows.

The statement of the theorem follows directly from claims 1-2.

C.1.5

Proof of Proposition 29

If there is a k-sized simple (α, β) explanation for O, then NAIVE-KSEP-EXACT
returns an explanation. Otherwise, it returns NO.
Proof. CLAIM 1: If there is a k-sized simple (α, β) explanation for O, then NAIVEKSEP-EXACT returns an explantion.
Suppose, by way of contradiction, that there is a k-sized simple (α, β) explanation
for O and NAIVE-KSEP-EXACT returns NO. Then there does not exist k bit strings
such that for all oi ,

Pk

j=1 (ℓj (i))

≥ 1. As each bit string is associated with a point

in S, then by the construction of the bit strings, there are not k points in S such
that each point is feasible and falls no closer than α and no further than β distance
away from each point in O. This is a contradiction.

CLAIM 2: If there is no k-sized simple (α, β) explanation for O, then NAIVE-KSEPEXACT returns NO.
Suppose, by way of contradiction, that there is no k-sized simple (α, β) explanation
for O and NAIVE-KSEP-EXACT returns an explanation. Then there must exist k
505

bit strings such that

Wk

j=1 (ℓj (i))

= 1. As each bit string is associated with a point

in S, then by the construction of the bit strings, there must exist k points in S such
that each point is feasible and falls no closer than α and no further than β distance
away from each point in O. This is a contradiction.

C.1.6

Proof of Proposition 30

1
(π(β 2 − α2 )|O|)(k+1) ).
The complexity of NAIVE-KSEP-EXACT is O( (k−1)!

Proof. Note that as all pointers in M are initially null, thus there is no need to
iterate through every element in M - rather lists in M can only be initialized as
needed. Hence, the cost to set-up M in O(1) and not the size of the matrix.
As each o ∈ O has, at most π(β 2 − α2 ) partners, the total complexity of the inner
loop is π(β 2 − α2 )|O|.
As we have, at most, π(β 2 − α2 )|O| elements in L (recall that L is the subset of
S that can be partnered with elements in O), then there are



π(β 2 −α2 )|O|
k

iterations

taking place in step 5. Each iteration costs k · |O| as we must compare the |O| bits
of each k bit string. So,


=


π(β 2 − α2 )|O|
· k · |O|
k

(π(β 2 − α2 )|O|) · (π(β 2 − α2 )|O| − 1) · . . . · (π(β 2 − α2 )|O| − (k − 1))
· k · |O|
k!
1
(π(β 2 − α2 )|O|)(k+1) )
< O(
(k − 1)!

As this term dominates the complexity of the inner loop, the statement follows.
506

C.1.7

Proof of Theorem 21

k-SEP≤p SET COVER
Proof. We employ the first four steps of NAIVE-KSEP-EXACT. We view the bitstrings in list L as subsets of O where if the ith bit of the string is 1, oi of O is in
the set.

CLAIM 1: If there are k subsets of L that cover O, then there is a k-sized simple
(α, β) explanation for O.
Suppose, by way of contradiction, that there are k subsets of L that cover O and
there is no k-sized simple (α, β) explanation for O. Then, by Proposition 29, for
every combination of k bit strings, there is some bit i such that

Wk

j=1 (ℓj (i))

= 1

does not hold. Hence, by the reduction, a set cover with k sets from L would be
impossible. This is a contradiction.

CLAIM 2: If there there is a k-sized simple (α, β) explanation for O, then there are
k subsets of L that cover O.
Suppose, by way of contradiction, there is a k-sized simple (α, β) explanation for
O and there are not k subsets of L that cover O. Then, for any combination of
k subsets of L, there is at least one element of O not included. Hence, for any
bit-string representation of an element in L, for some bit i,

Wk

j=1 (ℓj (i))

= 1 does

not hold. However, by Proposition 29, this must hold or there is no k-sized simple
(α, β) explanation for O. This is a contradiction.
507

C.1.8

Proof of Proposition 31

NAIVE-KSEP-SC has a complexity of O(∆ · f · |O|2 ) and an approximation
ratio of 1 + ln(f ).
Proof. CLAIM 1: NAIVE-KSEP-SC has a complexity of O(∆ · f · |O|2 ).
The loop at line 3, which reduces the problem to set-covering, takes O(∆ · |O|) time.
The loop at line 4 iterates, at most, |O| times.
The first nested loop at line 4b iterates, at most, ∆ · |O| times.
The second nested loop at line 4(b)ii iterates, at most, f times.
The updating procedure at line 4d, which is still inside the loop at line 4, iterates,
at most, f times.
Hence, by the above statements, the total complexity of NAIVE-KSEP-SC is O(|O| ·
(∆ · |O| · f + f ) + ∆ · |O|), hence the statement follows.
CLAIM 2: NAIVE-KSEP-SC has an approximation ratio of 1 + ln(f ).
Viewing list L as a family of subsets, each subset is the set of observations associated
with a potential partner, hence the size of the subsets is bounded by f . The approximation ratio follows directly from the analysis of the set-covering problem.

C.1.9

Proof of Proposition 32

A solution E to NAIVE-KSEP-SC provides a partner to every observation in O
if a partner exists.
Proof. Follows directly from Theorem 21.

508

C.1.10

Proof of Proposition 33

The complexity of KSEP-TO-DOMSET is O(∆ · |O|).
Proof. Notice that the number of points in S considered for each o ∈ O examined
in the inner loop is bounded by O(∆). As the outer loop is bounded by the size of
O, the complexity of KSEP-TO-DOMSET is O(|O|).

C.1.11

Proof of Theorem 22

k-SEP≤p DomSet.
Proof. We can run KSEP-TO-DOMSET that creates graph GO = (VO , EO ) based on
the set of observations. We show that GO has a dominating set of size k iff there is
a k-sized simple (α, β) explanation for O.

CLAIM 1: If GO has a dominating set of size k or less, then there is a k-sized (or
less) simple (α, β) explanation for O.
Suppose, by way of contradiction, that GO has a dominating set of size k and there
is not a k-sized simple (α, β) explanation for O. Then, there has to be at least one
element oi ∈ O such that there is no feasible p ∈ S where α ≤ d(oi , p) ≤ β. Consider
the nodes Vi from the inner loop of KSEP-TO-DOMSET that are associated with oi .
Note that these nodes form a complete subgraph. As each node in Vi is associated
with oi , no node in Vi can be in the dominating set of GO (if one were, then we
would have a contradiction). However, note that half of the nodes in Vi only have
edges to other nodes in Vi , so there must be an element of Vi in the dominating set.
509

This is a contradiction.
CLAIM 2: If there is a k-sized simple (α, β) explanation for O, then GO has a
dominating set of size k or less.
Suppose, by way of contradiction, that there is a k-sized simple (α, β) explanation
for O, and GO has does not have a dominating set of size k or less. Let E be a
k-sized simple (α, β) explanation for O. Let this also be a subset of the nodes in
GO . By the KSEP-TO-DOMSET, in each set of nodes Vi , there must be at least
one element of E. As each set of vertices Vi is a complete graph, then we have a
dominating set of size k. Hence, a contradiction.

C.1.12

Proof of Proposition 34

Solving k-SEP by a reduction to DomSet utilizing a straight-forward greedy
approach has time-complexity O(∆3 · f · |O|2 ) and an approximation ratio bounded
by O(1 + ln(2 · f · ∆)).
Proof. This is done by a well-known reduction of an instance of DomSet into an
instance of SET COVER. In the reduction, each node is an element, and the subsets
are formed by each node and its neighbors. The Table C.1 shows the quantities:
Hence, the total time complexity of the algorithm is O(8 · ∆3 · f · |O|2 ) and
the complexity part of the statement follows. As the maximum number of elements
per subset, the approximation ratio O(1 + ln(2 · f · ∆)) follows by the well-known
analysis of the greedy set-covering algorithm.

510

Item

Quantity

Number of elements to be covered

2 · ∆ · |O|

(number of nodes in GO )
2 · ∆ · |O|

Number of subsets
(number of nodes in GO )

2·∆·f

Number of elements per subset
(Maximum degree of nodes in GO
determined by the produce of partners per observation
and observations per partner

Table C.1: Quantities for the Greedy-Approach in the DomSet reduction.

C.1.13

Proof of Proposition 35

Solving k-SEP by a reduction to DomSet utilizing the distributed, randomized algorithm presented in [75] has a time complexity O(∆ · |O| + ln(2 · ∆ · |O|) ·
ln(2 · ∆ · f )) with high probability and approximation ratio of O(1 + ln(2 · f · ∆)).
Proof. By Proposition 33, the complexity of KSEP-TO-DOMSET is O(∆·|O|)). The
graph GO has O(2·∆·|O|) nodes, and the maximum degree of each node is bounded
2 · ∆ · f as per Proposition 34. As the algorithm in [75] has a complexity of O(lg(n) ·
lg(d)) (with high probability) where n is the number of nodes and d is the maximum
degree, the complexity of this approach requires O(∆·|O|+ln(2·∆·|O|)·ln(2·∆·f ))
with high probability (the statement follows).

511

As the approach in [75] is greedy, it maintains the O(1 + ln(2 · f · ∆)) (Proposition 34) (the approximation ratio in this case being a factor of the optimal in
expectation).

C.1.14

Proof of Proposition 36

OPT-KSEP-IPC consists of O(|O|π(β 2 − α2 )) variables and 1 + |O| constraints.
Proof. Follows directly from Definition 56.

C.1.15

Proof of Proposition 37

For a given instance of the optimization version k-SEP, if OPT-KSEP-IPC is
solved, then

S

pj ∈L x =1
j

pj is an optimal solution to k-SEP.

Proof. Suppose, by way of contradiction, that
to k-SEP. By the constraint, ∀oi ∈ O,

P

S

pj ∈L

pj ∈L x =1
j

pj is not an optimal solution

xj · str(pj )i ≥ 0, we are ensured that

for each observation, there is a partner pj such that xj = 1. Further, if we associate
xj with the selected parter pj for any solution E to k-SEP, then this constraint must
hold. Hence,

S

pj ∈L x =1
j

pj is a valid explanation. Therefore, the optimal solution to

the instance of k-SEP, we shall call EOP T , must be smaller than
minimization of

P

pj ∈L

xj ensures that the cardinality of

Therefore, |EOP T | cannot be smaller than |
P

pj ∈L

S

pj ∈L x =1
j

S

S

pj ∈L x =1
j

pj ∈L x =1
j

pj . As the

pj is minimized.

pj |, as the constraint ∀oi ∈ O,

xj · str(pj )i ≥ 0 holds for any solution to k-SEP. This is a contradiction.

512

C.1.16

Proof of Proposition 38

NAIVE-KSEP-ROUND returns an explanation for O that is within a factor f
of optimal, where f is the maximum number of possible partners associated with
any observation.
Proof. [68] shows that the solution to the relaxation of the integer program representation of set-cover approximates the optimal solution within a factor of f , which
is the greatest number of sets an element can be found in. For k-SEP, this would
be the greatest number of partners for any given observation, which is bounded by
O(π(β 2 − α2 )), but may be much lower in practice. As OPT-KSEP-IPC employs this
technique, the statement follows directly.

C.1.17

Proof of Proposition 39

GREEDY-KSEP-OPT1 has a complexity of O(∆ · f · |O|) and an approximation
ratio of 1 + ln(f ).
Proof. CLAIM 1: GREEDY-KSEP-OPT1 has a complexity of O(∆ · f · |O|).
This follows the same analysis of NAIVE-KSEP-SC in Proposition 31, except that
line 4 iterates only ∆ times rather than ∆ · |O| times. Hence, the total complexity
is O(|O| · (∆ · f + f ) + ∆ · |O|) and the statement follows.

CLAIM 2: GREEDY-KSEP-OPT1 has an approximation ratio of 1 + ln(f ).
The proof of this claim resembles the approximation proof of the standard greedy
algorithm for set-cover (i.e. see [28] page 1036).
513

Let p1 , . . . , pi , . . . , pn be the elements of E, the solution to GREEDY-KSEPOPT1, numbered by the order in which they were selected. For each iteration, let
set COVi be the subset of observations that are partnered for the first time with
point pi . Note that each element of O is in exactly one COVi . For each oj ∈ O, we
define costj to be

CLAIM 2.1:

P

1
|COVi |

pi ∈E ∗

P

where oj ∈ COVi .

oj ∈O p ,o are partners
i j

costj ≥ |E|

By the definition of costj , exactly one unit of cost is assigned every time a point is
picked for the solution E. Hence,
COST (E) = |E| =

X

costj

oj ∈O

The statement of the claim follows.

CLAIM 2.2: For some point p ∈ L,

P

oj ∈O p,o are partners
j

costj ≤ 1 + ln(f ).

Let P be the subset of O that can be partners with p. At each iteration i of the
algorithm, let uncovi be the number of elements in P that do not have a partner.
Let last be the smallest number such that uncovlast = 0. Let EP = {pi ∈ E|(i ≤
last) ∧ (COVi ∩ P 6≡ ∅)}. From here on, we shall renumber each element in EP
as p1 , . . . , p|EP | by the order they are picked in the algorithm (i.e. if an element is
picked that cannot partner with anything in P , we ignore it and continue numbering
with the next available number, we will use this new numbering for COVi and the
iterations of the algorithm as well, but do not re-define the set based on the new
514

numbering).

We note that for each iteration i, the number of items in P that are partnered
is equal to uncovi−1 − uncovi . Hence,
X

costj =

last
X
uncovi−1 − uncovi
i=1

oj ∈O
p,oj are partners

|COVi |

At each iteration of the algorithm, let P COVi be the subset of observations that are
covered for the first time if point p is picked instead of point pi . We note, that for
all iterations in 1, . . . , last, the point p is considered by the algorithm as one of its
options for greedy selection. Therefore, as p is not chosen, we know that |COVi | ≥
|P COVi |. Also, by the definition of ucovi , we know that |P COVi | = ucovi−1 . This
gives us:
X

oj ∈O
p,oj are partners

costj ≤

last
X
uncovi−1 − uncovi
i=1

ucovi−1

Using the algebraic manipulations of [28] (page 1037), we get the following:
X

oj ∈O
p,oj are partners

costj ≤ H|P |

Where Hj is the jth harmonic number. By definition of the symbol f (maximum
number of observations supported by a single partner), we obtain the statement of
the claim.

(Proof of claim 2): Combining claims 1-2, we get |E| ≤
gives us the claim.
515

P

pi ∈E ∗ (1

+ ln(f )), which

C.1.18

Proof of Proposition 40

GREEDY-KSEP-OPT1 returns a |E|-sized (α, β) explanation for O.
GREEDY-KSEP-OPT1 returns IMPOSSIBLE if there is no explanation for O.
Proof. Suppose by way of contradiction that there exists and element o ∈ O such
that there is no in E. We note that set O′ contains all elements of O and the only
way for an element to be removed from O′ is if a partner for that element is added
to E. Hence, if the program returns a set E, we are guaranteed that each o ∈ O has
a partner in E.

Suppose by way of contradiction that GREEDY-KSEP-OPT1 returns IMPOSSIBLE and there exists a set E that is a valid (α, β) explanation for O. Then, for
every element of O, there exists a valid partner. However, this contradicts line 3b of
NAIVE-KSEP-SC (called by line 4b of GREEDY-KSEP-OPT1) which causes the program to return IMPOSSIBLE only if an element of O is found without any possible
partner.

C.1.19

Proof of Theorem 23

GREEDY-KSEP-OPT2 has a complexity of O(∆ · f 2 · |O| + |O| · ln(|O|)) and
an approximation ratio of 1 + ln(f ).
Proof. CLAIM 1: GREEDY-KSEP-OPT2 has a complexity of O(∆ · f 2 · |O| + |O| ·
ln(|O|)).
Line 1 takes O(∆ · |O|) time.
516

The loop starting at line 4 iterates |O| times.
The nested loop at line 4a iterates ∆ times.
The second nested loop at line 4(a)i iterates f times. The inner body of this loop
can be accomplished in constant time.
In line 5, initializing the Fibonacci heap takes constant time, as does inserting elements, hence this line takes only O(|O|) time.
The loop at line 6 iterates, at most, |O| times.
Viewing the minimum of a Fibonacci heap, as in line 6a can be done in constant
time.
As per the analysis of GREEDY-KSEP-OPT1, line 6b takes ∆ · f iterations. The
updating procedure starts with line 6c which iterates f times.
The removal of an elements in line 6(c)ii from a Fibonacci heap costs O(ln(|O)
amortized time. However, we perform this operation no more than |O| times, hence
we can add |O| · ln(|O|)) to the complexity.
Note that the size of a list pointed to by REL OBS[o′ ] is bounded by ∆ · f - f observations associated with each of ∆ partners - hence line 6(c)iii iterates, at most,
∆ · f times.
We note that decreasing the key of an item in the Fibonacci heap (in line 6(c)iii)
takes constant time (amortized).
Therefore, by the above statements, the complexity of GREEDY-KSEP-OPT2 is
O(|O| · (∆ · f + ∆ · f 2 ) + |O| · ln(|O|) + ∆ · f · |O| + ∆ · |O|) and the statement follows.
CLAIM 2: GREEDY-KSEP-OPT2 has an approximation ratio of 1 + ln(f ).
Follows directly from Proposition 39.
517

C.1.20

Proof of Proposition 41

GREEDY-KSEP-OPT2 returns a |E|-sized (α, β) explanation for O.
GREEDY-KSEP-OPT2 returns a IMPOSSIBLE if there is no explanation for O.
Proof. Mirrors that of Proposition 40.

518

Appendix D
Appendix for Chapter 5

D.1
D.1.1

Proofs
Proof of Lemma 17

Given observations O and the set of regions RO , then a region r ∈ RO subexplains an observation o ∈ O iff is super-explain o.
Proof. CLAIM 1: Any point in a region r ∈ RO is either within distance [α, β] or
outside the distance [α, β] from each o ∈ O.
As RO is created by drawing circles of radii α, β around each observation, the statement follows by the definition of RO .

CLAIM 2: (⇐) There is no r ∈ RO that super-explains some o ∈ O but does not
sub-explain the observation.
Suppose, BWOC, there is some r ∈ RO that super-explains some o ∈ O but does
not sub-explain it. Then, there must be at least one point in r that can be partnered
519

with O and at least one point in r that cannot be partnered with o. However, by
claim 1, this is not possible, hence a contradiction.
CLAIM 3: (⇒) There is no r ∈ RO that sub-explains some o ∈ O but does not
super-explain the observation.
Follows directly from Observation 5.2.1.

D.1.2

Proof of Theorem 24

I-REP ≤p AC-Sup-REP.
AC-Sup-REP ≤p Sup-REP.
Proof. CLAIM 1: I-REP ≤p AC-Sup-REP.
Set up an instance of AC-Sup-REP with the input for I-REP plus the parameter
A = π · (β 2 − α2 ). For direction ⇐, note that a solution to this instance of I-REP
is also a solution to AC-Sup-REP, as any region that sub-explain an observation
also super-explains it for the set of region RO (Lemma 17) and the fact that, by
definition, all regions in the set RO must have an area less than A. For direction ⇒,
we know that only regions that can be partnered with observations are considered
by the area restriction, and by Lemma 17, the all regions in the solution are also
super-explanations for their corresponding observation.

CLAIM 2: AC-Sup-REP ≤p Sup-REP.

Consider the set R from AC-Sup-REP and let set R′ = {r ∈ R| the area of r is less than or equal to
Set up an instance of Sup-REP where the set of regions is R′ and the rest is the

520

input from AC-Sup-REP. or direction ⇐, it is obvious that any solution to AC-SupREP is also a solution to Sup-REP, as R − R′ are all regions that cannot possibly
be in the solution to the instance of AC-Sup-REP. Going the other direction (⇒),
we observe that by the definition of R′ , all regions in the result of the instance of
Sup-REP meet all the requirements of the AC-Sup-REP problem.

D.1.3

Proof of Theorem 25

I-REP is NP-Complete.
Proof. CLAIM 1: I-REP is in-NP.
Given a set of regions, R′ ⊆ RO we can easily check in polynomial time that for each
o ∈ O there is an r ∈ R that is a partner for o. Simply check if each r falls within
the distance [α, β] for a given o ∈ O. The operation will take time O(|O| · |R′ |) which is polynomial.

CLAIM 2: I-REP is strongly NP-hard.
We show that for an instance of the known strongly NP-complete problem, circle
covering (CC), CC ≤p I − REP by the following transformation.
• Set S = S ′
• Set O = P
• Set β = β ′
• Set α = 0
521

• Set k = k ′
This transformation obviously takes polynomial time. We prove correctness with
the following two sub-claims.

CLAIM 2.1: If there is a k-sized solution R′ for I-REP, then there is a corresponding
k ′ -sized solution for CC.
Consider some r ∈ R′ . Let O′ be the subset of O (also of P ) such that all points in
O′ are partnered with r. By definition, all points enclosed by r are of distance β or
less away from each point in O′ . Hence, we can pick some point enclosed by r and
we have the center of a circle that covers all elements in O′ . The statement follows.

CLAIM 2.2: If there is a k ′ -sized solution Q for CC, then there is a corresponding
k-sized set solution for I-REP.
Consider some point q ∈ Q. Let P ′ be the subset of P (also of O) such that all
points in P ′ are of distance β ′ from q. As p is within β of an element of O, it is in
some region of the set RO . Hence, the region that contains p is a partner region for
all elements of P ′ . The statement follows.

D.1.4

Proof of Corollary 8

I-REP-MC cannot be approximated by a fully polynomial-time approximation
scheme (FPTAS) unless P == N P .
Proof. Follows directly from [125] and Theorem 25.
522

D.1.5

Proof of Corollary 9

1. Sub-REP and Sup-REP are NP-Complete.
2. Sub-REP-MC, Sup-REP-MC, I-REP-MC, Sub-REP-ME, Sup-REP-ME, and
I-REP-ME are NP-Hard.
3. Sub-REP-MC, Sup-REP-MC cannot be approximated by a FPTAS unless
P == N P .
Proof. All follow directly from Lemma 17, Theorem 25, and Corollary 8.

D.1.6

Proof of Theorem 26

Sub/Sup-REP-MC ≤p Set-Cover
Sub/Sup-REP-ME ≤p Max-k-Cover
Proof. CLAIM 1: Sub/Sup-REP-MC ≤p Set-Cover
Consider the instance of set-cover hO,
REDUCE-TO-COVERING(O, R).

S

r∈R {Or }i

obtained from

Let H′ be a solution to this instance of set-cover. (⇐) If R′ is a solution to the
instance of Sub/Sup-REP-MC, then the set

S

r∈R′ {Or }

is a solution to set-cover.

Obviously, it must cover all elements of O and a smaller solution to set-cover would
indicate a smaller R′ – a contradiction. (⇒) Given set H′ , let R′′ ≡ {r ∈ R|Or ∈ H′ }.
Obviously, R′′ provides a partner for all observations in O. Further, a smaller solution to Sub/Sup-REP-MC would indicate a smaller H′ is possible – also a contradiction.
523

CLAIM 2: Sub/Sup-REP-ME ≤p Max-k-Cover
Consider the instance of max-k-cover hO,

S

r∈R {Or }, ki

obtained from REDUCE-TO-

COVERING(O, R, k). Let H′ be a solution to this instance of max-k-cover. (⇐) If
R′ is a solution to the instance of Sub/Sup-REP-ME, then the set

S

r∈R′ {Or }

is a

solution to max-k-cover. Obviously, both have the same cardinality requirement.
Further, if there is a solution to max-k-cover that covers more elements in O, this
would imply a set of regions that can be partnered with more observations in O
- which would be a contradiction. (⇒) Given set H′ , let R′′ ≡ {r ∈ R|Or ∈
H′ }. Obviously, R′′ meets the cardinality requirement of k. Further, a solution to
Sub/Sup-REP-ME that allows more observations in O to be partnered with a region
would indicate a more optimal solution to max-k-cover – a contradiction.

D.1.7

Proof of Proposition 42

REDUCE-TO-COVERING requires O(|O| · |R|) time.
Proof. Follows directly from Line 1.

D.1.8

Proof of Proposition 43

GREEDY-REP-ME requires O(k · |R| · f ) time and returns a solution whose
where the number of observations in O that have a partner region in R′ is within a
factor

e
e−1



of optimal.

Proof. The complexity proof mirrors that of Proposition 44 while the approximation
524

guarantee follows directly from the results of [127].

D.1.9

Proof of Proposition 44

GREEDY-REP-ME requires O(|O| · |R| · f ) time and returns a solution whose
cardinality is within a factor of 1 + ln(f ) of optimal.
Proof. The outer loop of the algorithm iterates no more than |O| times, while the
inner loop iterates no more than |R| times. The time to compare the number of
elements in a set Or is O(f ).

The approximation factor of 1 + ln(f ) follows directly from [136].

D.1.10

Proof of Proposition 45

GREEDY-REP-MC2 runs in O(∆ · f 2 · |O| + |O| · ln(|O|) time and returns a
solution whose cardinality is within a factor of 1 + ln(f ) of optimal.
Proof. CLAIM 1: GREEDY-REP-MC2 runs in O(∆ · f 2 · |O| + |O| · ln(|O|) time.
The pre-processing in lines 1-4 can be accomplished in O(∆ + ∆ · f ) as the size of
each GRPo is bound by ∆ and the size of each RELo is bound by ∆ · f .

The outer loop of the algorithm iterates O times. In each loop, the selection
of the minimal element (line 5a) can be accomplished in constant time by use of a
Fibonacci heap [49] (i.e. storing observations in O′ organized by the value keyo ).
The next lines of the inner loop (lines 5b-5c) can be accomplished in O(∆) time.
525

The next line, line 5d requires O(ln(|O|) time per observation using a Fibonacci
heap, as observations partnered with . However, we can be assured that, during
the entire run of the algorithm, this operation is only performed |O| times (hence,
we add an |O| · ln(|O|)). The final loop at line 5e occurs after the inner loop and
iterates, at most f times. At each iteration, it considers, at most f · ∆ elements.
Hence, the overall complexity is:

O(|O| · ∆ + f 2 · ∆ + |O| · ln(|O|))
The statement of the claim follows.

CLAIM 2: GREEDY-REP-MC2 returns a solution whose cardinality is within a factor of 1 + ln(f ) of optimal.
The proof of this claim resembles the approximation proof of the standard greedy
algorithm for set-cover (i.e. see [28] page 1036).

Let r1 , . . . , ri , . . . , rn be the elements of R′ , the solution to GREEDY-REP-MC2,
numbered by the order in which they were selected. For each iteration (of the outer
loop), let set COVi be the subset of observations that are partnered for the first
time with region ri . Note that each element of O is in exactly one COVi . For each
oj ∈ O, we define costj to be

1
|COVi |

where oj ∈ COVi . Let R∗ be an optimal solution

to the instance of Sub/Sup-REP-MC.

CLAIM 2.1:

P

ri ∈R∗

P

oj ∈Ori

costj ≥ |R|
526

By the definition of costj , exactly one unit of cost is assigned every time a region is
picked for the solution R. Hence,
COST (R) = |R| =

X

costj

oj ∈O

The statement of the claim follows.

CLAIM 2.2: For some region r ∈ R,

P

oj ∈Or

costj ≤ 1 + ln(f ).

Let P be the subset of O that can be partners with p. At each iteration i of the
algorithm, let uncovi be the number elements in P that do not have a partner.
Let last be the smallest number such that uncovlast = 0. Let RP = {ri ∈ R|(i ≤
last) ∧ (COVi ∩ P 6≡ ∅)}. From here on, we shall renumber each element in RP
as r1 , . . . , r|RP | by the order they are picked in the algorithm (i.e. if an element is
picked that cannot partner with anything in P , we ignore it and continue numbering
with the next available number, we will COVi and the iterations of the algorithm
as well, but do not re-define the set based on the new numbering).
We note that for each iteration i, the number of items in P that are partnered is
equal to uncovi−1 − uncovi . Hence,
X

oj ∈Or

costj =

last
X
uncovi−1 − uncovi
i=1

|COVi |

At each iteration of the algorithm, let P COVi be the subset of observations that are
covered for the first time if region p is picked instead of region ri . We note, that for
all iterations in 1, . . . , last, the region p is considered by the algorithm as one of its
options for greedy selection. Therefore, as p is not chosen, we know that |COVi | ≤
527

|P COVi |. Also, by the definition of ucovi , we know that |P COVi | = ucovi−1 . This
gives us:
X

oj ∈Or

costj ≤

last
X
uncovi−1 − uncovi
i=1

ucovi−1

Using the algebraic manipulations of [28] (page 1037), we get the following:
X

oj ∈Or

costj ≤ H|P |

Where Hj is the jth harmonic number. By definition of the symbol f (maximum
number of observations supported by a single partner), we obtain the statement of
the claim.

(Proof of Claim 2): Combining claims 1-2, we get |R| ≤
gives us the statement.

D.1.11

P

ri ∈R∗ (1

+ ln(f )), which

Proof of Proposition 10

I-REP-MC-Z ≤p CC
Proof. Follows directly from Theorem 25.

D.1.12

Proof of Proposition 46

The algorithm, FIND-REGION runs O(|O|) time, and region r (associated with
the returned set Or ) encloses p.

528

Proof. PART 1: FIND-REGION consists of a single loop that iterates |O| times.

PART 2: Suppose, the region enclosing point p has a different label. Then, there is
either a bit in label that is incorrectly set to 1 or 0. As only observations which are
≤ from β have the associated bit position set to 1, then all 1 bits are correct. As
we exhaustively consider all observations, the 0 bits are correct. Hence, we have a
contradiction.

D.1.13

Proof of Proposition 11

An α-approximation algorithm for CC is an α-approximation for KREP.
Proof. Follows directly from Theorem 25.

D.1.14

Proof of Proposition 48

REGION-GEN has a time complexity Θ(|O| · f ·

π·β 2
).
g2

Proof. For any given observation, the number of points in the grid that can be in
a partnered region is

π·β 2 −α2
.
g2

L are both bounded by |O| ·

Hence, the first loop of the algorithm and the size of
π·β 2
.
g2

We note that the lookup and insert operations

for the hash table T do not affect the average-case complexity - we assume these
operations take constant time based on [28], hence the statement follows.

529

Appendix E
Appendix for Chapter 6

E.1

MCA where the Solution is an Explanation
In Section 6.5 we study the MCA problem, but do not require the solution

to be an explanation. In fact, it may often not be an explanation. Consider the
following example.
Example E.1.1. Suppose that the drug-enforcement agents from Example 6.5.1
consider the set C ≡ {p45 , p48 , p50 }. Note that p45 can be partnered with observations
o1 , o2 , p48 can be partnered with observations o3 , o5 and p50 can be partnered with
observation o5 . Hence, there is no element in C that can be partnered with o4 – which
means it is not an explanation. However, let us compute the expected agent benefit.
Computing the reward (wrt crf) for each explanation function from Example 6.3.3,
we get the following:
crf(dist) (ex fcn1 (O, 3), {p45 , p48 , p50 }) = 1
crf(dist) (ex fcn2 (O, 3), {p45 , p48 , p50 }) = 1
530

Hence, the expected agent benefit in this case must be 1 – which is optimal (expected
agent benefit must be in the range [0, 1]). Therefore, we have shown that we can
have an optimal solution to MCA that is not an explanation in our example.

We can also construct an instance of the MCA problem where there is no
optimal solution that is also explaining. Stepping away from our running example
for a moment consider the following case of a geospatial abduction problem. Consider
observations o1 , o2 . Let p1 , p2 , p3 , p4 , p5 , p6 be the only feasible points, the first two
being only partnered with o1 and the rest being only partnered with o2 . Consider an
adversary who will pick one of the following explanations as a strategy with uniform
probability:
• {p1 , p3 }
• {p1 , p4 }
• {p2 , p5 }
• {p2 , p6 }
Let us consider the reward function crf with dist = 0 and B = 2. Therefore, the
maximal counter-adversary strategy would be the set {p1 , p2 } - this would give an
expected agent benefit of 0.5. However, this set is not an explanation - observations
o2 is not covered. If we require the counter-adversary strategy to be an explanation,
the set {p1 , p3 } would be optimal. However, the expected agent benefit would only be
0.375 in this case.
531

Hence, we shall also consider a the special case of a maximal counter-adversary
strategy that is also an explanation.
Definition 115 (Maximal Explaining Counter-Adversary Strategy). Given a set of
observations, O, reward function rf and explanation function distribution exfd (of
explanation for O), a maximal explaining counter-adversary strategy, C, an
explanation for O such that EXB(rf) (C, exfd) is maximized.
Again, for the case in which the reward function is monotonic, we shall include
an cardinality requirement B for the set C.
We formalize the optimization problem associated with finding a maximal explaining counter-adversary strategy.

MCA-Exp
INPUT: Space S, feasibility predicate, feas, real numbers α, β, set of observations,
O, natural numbers k, B, reward function rf, and explanation function distribution
exfd.
OUTPUT: The maximal explaining counter-adversary strategy, C.

The below corollary shows us that MCA-Exp is NP-hard.
Corollary 18. MCA-Exp is NP-hard.
We note that the proof of the above corollary follows directly from the result
of Theorem 33. The associated problem is in the complexity class NP – this follows

532

trivially from the membership results for the problem of finding an explanation and
the MCA problem.
An Exact Algorithm For MCA-Exp. A naive, exact, and straightforward approach to the MCA-Exp problem would simply consider all subsets of L pf cardinality ≤ kC and pick the one which maximizes the expected agent benefit and is
an explanation. This is the same as the naive approach we presented for MCA.
Obviously, this approach has a complexity O(

|L|
kC



) - and is not practical. This is

unsurprising as we showed this to be an NP-complete problem.

The following theorem shows that this problem reduces to the maximization
of a submodular function over a uniform matroid - which can imply a practical
algorithm to address this problem.
Theorem 60. MCA-Exp reduces in polynomial time to the maximization of a
submodular function wrt a uniform matroid.
Proof Sketch. Given an instance of MCA-Exp as follows:
Space S, feasibility predicate, feas, real numbers α, β, set of observations, O, natural
numbers k, kC , reward function rf, and explanation function distribution exfd, we
construct an instance of the maximization of a submodular function as follows (L is
the set of all possible partners).
1. Let M be a uniform matroid consisting of all subsets of L of cardinality ≤ kC
2. Let function fsubmod : 2L → ℜ be defined as follows:
fsubmod (C) = EXB(rf) (C, exfd)+2·|{o ∈ O|∃p ∈ C s.t. (d(o, p) ∈ [α, β])∧(feas(p))}|
533

In the remainder of the proof proceeds as follows. First, we show that fsubmod (C)
is submodular. Then, we prove that if there is a solution to MCA-Exp then the
submodular maximization problem returns a value greater than or equal to 2 · |O|.
Then we show that if the submodular maximization problem returns a value greater
than or equal to 2 · |O| then there is a solution to MCA-Exp. Finally, we complete
the proof by showing that if MCA-Exp returns a value b, then the submodular maximization problem returns a value b + 2 · |O| and that if the maximization of fsubmod
returns value b, then MCA-Exp returns a value b − 2 · |O|.

Although, due to the construction of Theorem 60 an
does not necessarily yield an

1
α

1
α



approximation of fsubmod

approximation of MCA-Exp, we still can apply the

local search or greedy algorithms as a heuristic by simply replacing calls to the
function EXB(rf) with calls to fsubmod .

E.2

Proofs

E.2.1

Proof of Lemma 19

#GCD is #P-complete and there is no FPRAS for #GCD unless NP == RP.
Proof. CLAIM 1: #GCD is in #P.
Clearly, as the total number of “yes” answers is bounded by 2K , this problem is in
the complexity class #P.
CLAIM 2: #GCD is #P-hard.

534

We have to show a parsimonious or weakly parsimonious reduction from a known
#P -complete problem. In [71], the authors show that the counting version of the
dominating set problem (#DOMSET) is #P-complete based on a weakly parsimonious reduciton from the counting version of vertex cover. It is important to note
that the consruction used in this proof uses a graph with a maximum degree of three.
This shows that the counting version of the dominating set problem on a graph with
a maximum degree of three is also #P-hard as well. In [123], the authors show a
parsimonious reduction from the dominating set problem (with maximum degree of
three) to GCD. Hence, as the reduction is parsimonuous, and the associated counting
probelm is #P -hard, then the statement of the claim follows.
CLAIM 3: There is no FPRAS for #GCD unless NP == RP.
By Leamm 19 and [71], conisder the following chain of polynomial-time parsimonious
or weakly parsimonious reductions:
#SAT → #3CN F SAT → #P l3CN F SAT
#P l3CN F SAT → #P l1Ex3SAT → #P l1Ex3M onoSAT
#P l1Ex3M onoSAT → #P lV C → #P l3DS → #GCD
Hence, as all of the reductions are PTIME, parsimonious or weakly parsimonious,
and planarity preserving (for planar problems), by the results of [38], the statement
follows.

535

E.2.2

Proof of Theorem 27

The counting version of k-SEP is #P-Complete and has no FPRAS unless
NP=RP.
Proof. Follows directly from the fact that the number of solutions is bounded by 2k
(memebrship) and hardness follows directly from the parsimonious reduction shown
in [158] and Lemma 19.

E.2.3

Proof of Proposition 49

If a reward function meets axioms 1 and 2, then then the incremental increase
obtained by adding a new element decreases on a superset. Formally:
If C ⊆ C ′ , and point p ∈ S s.t. p ∈
/ C and p ∈
/ C ′ , then rf(Egt , C ∪ {p}) − rf(Egt , C) ≥
rf(Egt , C ′ ∪ {p}) − rf(Egt , C ′ ).
Proof. Suppose, BWOC, for C ⊆ C ′ , and point p ∈ S s.t. p ∈
/ C and p ∈
/ C ′ , then
rf(Egt , C ∪ {p}) − rf(Egt , C) < rf(Egt , C ′ ∪ {p}) − rf(Egt , C ′ )
We know that C ′ ∪ {p} ≡ C ′ ∪ (C ∪ {p}). Hence:
rf(Egt , C ∪ {p}) − rf(Egt , C) < rf(Egt , C ′ ∪ (C ∪ {p})) − rf(Egt , C ′ )
Also, we know that C ≡ (C ∪ {p}) ∩ C ′ , so we get:
rf(Egt , C ∪ {p}) − rf(Egt , (C ∪ {p}) ∩ C ′ ) < rf(Egt , C ′ ∪ (C ∪ {p})) − rf(Egt , C ′ )
Which leads to:
rf(Egt , C ′ ) + rf(Egt , C ∪ {p}) − rf(Egt , (C ∪ {p}) ∩ C ′ ) < rf(Egt , C ′ ∪ (C ∪ {p}))
536

Which is a clear violation of Axiom 2, hence we have a contradiction.

E.2.4

Proof of Proposition 50

prf is a valid reward function.
Proof. In this proof, we define pt1(Egt , C), pt2(Egt , C) as follows:
|{p ∈ Egt |∃p′ ∈ C s.t. d(p, p′ ) ≤ dist}|
2 · |Egt |
′
|{p ∈ C| 6 ∃p ∈ Egt s.t. d(p, p′ ) ≤ dist}|
pt2(Egt , C) =
2 · |S|

pt1(Egt , C) =

Hence, prf(dist) (Egt , C) = 0.5 + pt1(Egt , C) − pt2(Egt , C). As we know the maximum value of both pt1(Egt , C), pt2(Egt , C) is 0.5, we know that prf is in [0, 1]. As
pt1(Egt , Egt ) = 0.5 and pt2(Egt , Egt ) = 0, then Axiom 1 is also satisfied. Consider crf (Definition 62). Later, in Proposition 51, we show that this function
is submodular, meeting Axiom 2. By Definitions 62, we can easily show that
pt1(Egt , C) = 0.5 · crf(dist) (Egt , C). As pt1(Egt , C) is a positive linear combination
of submodular functions, it is also submodular. Now consider pt2(Egt , C). Any element added to any set C has the same effect – it either lowers the value by

1
2·|S|

or

does not affect it – hence it is trivially submodular. Therefore, it follows that prf
is submodular as it is a positive-linear combination of submodular functions.

E.2.5

Proof of Proposition 51

crf is a valid, monotonic reward function.

537

Proof. CLAIM 1: crf satisfies reward Axiom 1.
Clearly, if C ≡ Egt , then the numerator is |Egt |, which equals the denominator.

CLAIM 2: crf satisfies reward function Axiom 2.
Suppose, BWOC, there exists explanations C, C ′ s.t.

C ∪ C ′ is an explanation

and crf(dist) (Egt , C ∪ C ′ ) > crf(dist) (Egt , C) + rf(Egt , C ′ ) − rf(Egt , C ∩ C ′ ). Therefore,
card({p ∈ Egt |∃p′ ∈ C ∪ C ′ s.t. d(p, p′ ) ≤ dist}) is greater than card({p ∈ Egt |∃p′ ∈
C s.t. d(p, p′ ) ≤ dist}) + card({p ∈ Egt |∃p′ ∈ C ′ s.t. d(p, p′ ) ≤ dist}) − card({p ∈
Egt |∃p′ ∈ C ∩ C ′ s.t. d(p, p′ ) ≤ dist}). We have a contradiction; indeed, by basic set
theory we see that both sides of this strict inequality are actually equal.

CLAIM 3: crf is zero-starting.
Clearly, if C ≡ ∅, the numerator must be 0, the statement follows.

CLAIM 4: crf is monotonic.
Suppose, BWOC, there exists C ⊆ C ′ s.t. rf(Egt , C) > rf(Egt , C ′ ). Then card({p ∈
Egt |∃p′ ∈ C s.t. d(p, p′ ) ≤ dist}) > card({p ∈ Egt |∃p′ ∈ C ′ s.t. d(p, p′ ) ≤ dist}).
Clearly, this is not possible as C ⊆ C ′ and we have a contradiction.

E.2.6

Proof of Proposition 52

frf is a valid, monotonic reward function.
Proof. CLAIM 1: frf satisfies all reward function axioms (i.e., is valid).

538

Bounds We must show rf(Egt , C) ∈ [0, 1].

For each point p ∈ Egt , let lpC =

minp′ ∈C d(p, p′ )2 . By the definition of the distance function d, we know 0 ≤ lpC <
∞. Now let function f (lpC ) =

1
|Egt |+minp′ ∈C d(p,p′ )2

=

1
.
|Egt |+lpC

Since 0 ≤ lpC < ∞,

we see 0 < f (lpC ) ≤ |E1gt | . Clearly, the summation over |Egt | points p ∈ Egt yields

i
1
an answer in 0, |Egt | · |Egt | = (0, 1] ⊂ [0, 1].
Axiom 1 If C ≡ Egt , for each p ∈ Egt , there exists p′ ∈ C s.t. d(p, p′ ) = 0. Hence,
by the definition of frf, frf(Egt , C) = 1 in this case.
Axiom 2 We must show that our version of the triangle inequality holds, that is
rf(Egt , C ∪ C ′ ) ≤ rf(Egt , C) + rf(Egt , C ′ ) − rf(Egt , C ∩ C ′ ). From above, rf(Egt , C ∪
C ′) =

P

′

p∈Egt

f (lpC∪C ). For each point p ∈ Egt , let p∗ = argminp′ ∈C∪C ′ d(p, p′ )2 .
′

′

Without loss of generality, assume p∗ ∈ C, then lpC = lpC∪C thus f (lpC ) = f (lpC∪C ).
Since p∗ ∈ C, we have p∗ ∈ C ∩ C ′ or p∗ ∈ C ∩ C̄ ′ .
′

If p∗ ∈ C ∩ C ′ : Then f (lpC∩C ) = f (lpC ). However, since p∗ ∈ C ′ we have, as
′

′

above, f (lpC ) = f (lpC ) = f (lpC∪C ). Thus
Xh

p∈Egt

=

Xh

p∈Egt

′

′

′

′

f (lpC ) + f (lpC ) − f (lpC∩C )
′

X

(E.1)

i

(E.2)

f (lpC∪C )

(E.3)

f (lpC∪C ) + f (lpC∪C ) − f (lpC∪C )
=

i

′

p∈Egt

So rf(Egt , C ∪ C ′ ) = rf(Egt , C) + rf(Egt , C ′ ) − rf(Egt , C ∩ C ′ ) for this case.
′

If p∗ ∈ C ∩ C̄ ′ : Then, from above, we are still guaranteed that f (lpC ) = f (lpC∪C ),
thus rf(Egt , C ∪ C ′ ) = rf(Egt , C). This reduces our problem to showing
539

rf(Egt , C ′ ) − rf(Egt , C ∩ C ′ ) ≥ 0. However, rf is monotonic (shown below);
since C ∩ C ′ ⊆ C ′ , then rf(Egt , C ∩ C ′ ) ≤ rf(Egt , C ′ ) and our claim holds.
A similar proof holds for the case p∗ ∈ C ′ .
CLAIM 2: frf is monotonic and zero-starting. The property of zero-starting follows
directly from the definition of frf.
By way of contradiction, assume there is some C ⊂ C ′ s.t. rf(Egt , C) >
rf(Egt , C ′ ). Then, as above,
′

P

C
p∈Egt f (lp ) >

P

′

p∈Egt

f (lpC ). However, since C ⊂ C ′ , we
′

have lpC ≥ lpC for each p ∈ Egt . Similarly, f (lpC ) ≤ f (lpC ) and thus
P

′

p∈Egt

E.2.7

f (lpC ), which is our contradiction.

P

p∈Egt

f (lpC ) ≤

Proof of Proposition 53

wrf is a valid, monotonic reward function.
Proof. CLAIM 1: wrf satisfies all reward function axioms (i.e., is valid).
Domain We must show wrf(W,dist) (Egt , C) ∈ [0, 1]. As (C ∩ Egt ) ⊆ Egt and W only
returns positive values, this function can only return values in [0, 1].
Axiom 1 If C ≡ Egt , then for each p ∈ Egt , there exists p′ ∈ C s.t. d(p, p′ ) = 0.
This causes the numerator to equal

P

p∈C

W (p). As C ≡ Egt , the is equivalent

to the denominator, so wrf(Egt , C) = 1 in this case.
Axiom 2 We must show the inequality wrf(W,dist) (Egt , C ∪C ′ ) ≤ wrf(W,dist) (Egt , C)+
wrf(W,dist) (Egt , C ′ ) − wrf(W,dist) (Egt , C ∩ C ′ ). This proof is similar to the proof
of Axiom 2 in Proposition 51.
540

CLAIM 2: wrf is monotonic and zero-starting.
The property of zero-starting if shown by when C ≡ ∅, the numerator must be 0,
hence, wrf(Egt , ∅) = 0. By way of contradiction, assume there is some C ⊂ C ′ s.t.
wrf(W,dist) (Egt , C) > wrf(W,dist) (Egt , C ′ ). Then
P

{p∈Egt |∃p′ ∈C s.t. d(p,p′ )≤dist}
P
′
p′ ∈Egt W (p )

W (p)

>

P

Since C ⊂ C ′ , we have

P
P

{p∈Egt |∃p′ ∈C ′ s.t. d(p,p′ )≤dist}
P
′
p′ ∈Egt W (p )

{p∈Egt |∃p′ ∈C s.t. d(p,p′ )≤dist}
P
′
p′ ∈Egt W (p )

{p∈Egt |∃p′ ∈C s.t. d(p,p′ )≤dist}
P
′
p′ ∈Egt W (p )

W (p)

+

P

W (p)

W (p)

>

′ |∃p′ ∈(C ′ ∩C) s.t. d(p,p′ )≤dist}
{p∈Egt

P

p′ ∈Egt

W (p)

W (p′ )

′
Where Egt
≡ {p ∈ Egt | 6 ∃p′ ∈ C s.t. d(p, p′ ) ≤ dist}. Hence,
′
0 > wrf(W,dist) (Egt
, C ′ ∩ C)

Which violates the first axiom, which was shown to apply to wrf(W,dist) by Claim
1—a contradiction.

E.2.8

Proof of Theorem 28

OAS is NP-hard.
Proof. CONSTRUCTION: Given an input hP, b, Ki of GCD, we create an instance
of OAS in PTIME as follows:
• Set S to be a grid large enough that all points in P are also points in S.
• feas(p) = TRUE iff p ∈ P
541

• α = 0, β = b, O ≡ P , k = |P |
• Let rf(E1 , E2 ) = 1 if E1 ⊆ E2 , and

|E1 |
|S|

otherwise.

This satisfies reward axiom 1 as E1 ⊆ S, axiom 2 by definition, and the satisfiaction
of axiom 3, along with montoniticity (wrt the second argument) can easily be
shown by the fact that explanations that are not supersets of E1 (lets callthem
E2 , E3 ) that rf(E1 , E2 ) = rf(E1 , E3 ).
• Let ex fcn(O, num) that returns set O when num = |O| and is otherwise undefined. Let exfd(ex fcn) = 1 and 0 otherwise.
CLAIM 1: If Egt as returned by OAS has a cardinality of ≤ K, then the answer to
GCD is “yes”.
Suppose, BWOC, that card(Egt ) ≤ K and GCD answers “no.” This is an obvious
contradiction as Egt is a subset of P (by how feasibility was defined) where all elements of P are within a radius of b and Egt also meets the cardinlality requirement
of GCD.

CLAIM 2: If the answer to GCD is “yes” then Egt as returned by OAS has a
cardinality of less than or equal to K.
Suppose, BWOC, GCD returns “yes” but Egt returned by OAS has a cardinaity
greater than K. By the result of GCD, there exists a set P ′ of cardinality K s.t.
each point in P (hence O) is of a distance ≤ β from a point in P ′ . This, along with
the definitoin of feasibility, make P ′ a valid K-explanation for O. We note that
ex fcn(P, |P |) = P and that exfd assigns this reward function a probability of one.
542

′
′
Hence, the expected adversarial detriment for any explanation Egt
is rf(Egt
, P ). As

P ′ is an explanation of cardinality less than Egt , it follows that rf(P ′ , P ) < rf(Egt , P )
– which is a contradiction.

E.2.9

Proof of Theorem 29

If the reward function is computable in PTIME, then OAS-DEC is NPcomplete.
Proof. NP-harndness follows from Theorem 28. To show NP-completeness, a witness
simply consists of Egt . We note that, as the reward function is computable in PTIME,
finding the expected adversarial detriment for Egt and comparing it to R can also
be accomplished in PTIME.

E.2.10

Proof of Theorem 30

Finding the set of all adversarial optimal strategies that provide a “yes” answer
to OAS-DEC is #P-hard.
Proof. Let us assume that we know one optimal adversarial strategy and can compute the expected adversarial detriment from such a set – let us call this value D.
Given an instance of GCD, we can create an instance of OAS-DEC as in Theorem 28, where we set R = D. Suppose we have an algorithm that produces all
adversarial strategies. If we iterate through all strategies in this set, and count
all strategies with a cardinality ≤ K (the K from the instance of GCD), we have

543

counted all solutions to GCD – thereby solving the counting version of GCD, a #Phard problem that is difficult to approximate by Lemma 19.

E.2.11

Proof of Proposition 55

Setting up the wrf/frf Constraints can be accomplished in O(|EF| · k · |O| · ∆)
time (provided the weight function W can be computed in constant time).
Proof. First, we must run POSS-PART - which reuqires O(|O| · ∆) operations. This
results in a list of size O(|O| · ∆). For each explanation function, ex fcn, we must
compare every element in L with each element of ex fcn(O) - which would require
O(k·|O|·∆) time. As there are |EF| explanation functions, the statement follows.

E.2.12

Proof of Proposition 56

The wrf, frf Constraints have O(|O| · ∆) variables and 1 + |O| constraints.
Proof. As list L is of size O(|O| · ∆), and there is one variable for every element
of L - there are O(|O| · ∆) variables. As there is a constraint for each observation,
plus a constraint to ensure the cardinality requirement (k) is met, there are 1 + |O|
constraints.

E.2.13

Proof of Proposition 54

Given wrf or frf Constraints:
1. Given set Egt ≡ {p1 , . . . , pn } as a solution to OAS with wrf(frf), if variables
X1 , . . . , Xn - corresponding with elements in Egt are set to 1 - and the rest
544

of the variables are set to 0, the objective function of the constraints will be
minimized.
2. Given the solution to the constraints, if for every Xi = 1, we add point pi to
set Egt , then Egt is a solution to OAS with wrf(frf).
′
Proof. PART 1: Suppose BWOC, that there is a set of variables X1′ , . . . , Xm
that

is a solution to the constraints s.t. the value of the objective function is less than
if variables X1 , . . . , Xn were used. Then, there are points p′1 , . . . , p′m in set L that
correspond with the Xi ’s s.t. they cover all observations and that the expected
adversarial detriment is minimized. Clearly, this is a contradiction.
′
PART 2: Suppose BWOC, that there is a set of points Egt
s.t. the expected adver-

sarial detriment is less than Egt . Clearly, Egt is a valid explanation that minimizes
the expected adversarial detriment by the definiton of the constraints - hence a
contradiction.

E.2.14

Proof of Proposition 57

The wrf/frf constraints can be transformed into a purely linear-integer form
in O(|O|2 · ∆) time.
Proof. Obviously, in both sets of constraints, the denominator of the objective function is strictly positive and non-zero. Hence, we can directly apply the CharnesCooper transformation [22] to obtain a purely integer-linear form. This transformation requires O(number of variables×number of constraints). Hence, the O(|O|2 ·∆)
time complexity of the operation follows immediately from Proposition 56.
545

E.2.15

Proof of Proposition 58

Given the constraints of Definition 70 or Definition 71, if we consider the linear
program formed by setting all Xi variables to be in [0, 1], then the value returned by
the objective function will be a lower bound on the value returned by the objective
function for the mixed integer-linear constraints, and this value can be obtained in
O(|O|3.5 · ∆3.5 ) time.
Proof. CLAIM 1: The linear relaxation of Definition 70 or Definition 71 provides a
lower bound on the objective function value for the full integer-linear constraints.
As an optimal value returned by the integer-linear constraints would also be a solution, optimal wrt minimality, for the linear relaxation, the statement follows.
CLAIM 2: The lower bound can be obtained in O(|L|3.5 ) time.
As there is a variable for each element of L, the size of L is O(|O| · ∆), and the claim
follows immediately from the result of [79].

E.2.16

Proof of Porposition 59

Solving Definition 70 or Definition 71, where for some subset L′ ⊂ L, every
variable Xi associated with some pi ∈ L′ is set to 0, the resulting solution will be
an upper bound on the objective function for the constraints solved on the full set
of variables.
Proof. Suppose, BWOC, that the solution for the objective function on the reduced
MILP would be less than the actual MILP. Let X1 , . . . , Xn be the variables set to
1 for the reduced MILP in this scenario. We note, that setting the same variables
546

to the full MILP would also be a solution, and could not possibly be less than a
minimal solution – hence a contradiction.

E.2.17

Proof of Theorem 31

If Egt is an optimal adversarial strategy, there exists a core explanation Ecore ⊆
Egt .
Proof. CLAIM 1: For any explanation E, there is an explanation E ′ ⊆ E s.t. there
are no two elements p, p′ ∈ E ′ such that ∀o ∈ O s.t. o, p are partners, then o, p′ are
also partners.
Consider E. If it does not already have the quality of claim 1, then by a simple
induction, we can remove elements until the resulting set does.
CLAIM 2: If Egt is an optimal adversarial stratgey, there is a no pj ∈ L − Egt s.t.
there exists pi ∈ Egt where constj < consti and ∀o ∈ O s.t. o, pi are partners, then
o, pj are also partners.
Suppose, BWOC, there is a pj ∈ L − Egt s.t. there exists pi ∈ Egt where constj <
consti and ∀o ∈ O s.t. o, pi are partners, then o, pj are also partners.. Consider the
set (Egt −{pi }∪pj . This set is still an explanation and EXR(rf) (exfd, (Egt −{pi }∪pj ) <
EXR(rf) (exfd, Egt ) – which would be a contradiction as Egt is an optimal adversarial
stratgey.
CLAIM 3: There is an explanation E ⊆ Egt s.t. condition 2 of Definition 72 holds.
Consider the set E ≡ {pi ∈ Egt | 6 ∃pj ∈ Egt s.t. (constj < consti ) ∧
(∀o ∈ O s.t. o, pi are partners, then o, pj are also partners)}. Note that any obser547

vation coverd by a point in Egt − E is covered by a point in E – hence E is an
explanation. Further, by the definitoin of E and claim 2, this set meets condition 2
of Definition 72.
CLAIM 4: Set E from claim 3 is a core explanation.
By claim 3, E is a valid explanation and meets condition 2 of Definition 72. As it is
a valid explanation, by claim 1, it also meets condition 1 of Definition 72.

E.2.18

Proof of Theorem 32

If an oracle that for a given k, O, and exfd returns a core eplanation Ecore that
is guaranteed to be a subset of the optimal adversarial strategy associated with k,
O, and exfd, then we can find an optimal adversarial strategy in O(∆ · |O| · log(∆ ·
|O|) + (k − |Ecore |)2 ) time.
Proof. CLAIM 1: For explanation E and point pi ∈ L − E, EXR(rf) (exfd, E) >
EXR(rf) (exfd, E ∪ {pi }) iff consti < EXR(rf) (exfd, E).
If: Suppose consti < EXR(rf) (exfd, E). Let EXR(rf) (exfd, E) = ab . Hence, EXR(rf) (exfd, E∪
{pi }) =
a
b

≤

a+consti
.
b+1

a+consti
.
b+1

Suppose, BWOC, EXR(rf) (exfd, E) ≤ EXR(rf) (exfd, E ∪ {pi }). Then,

This give us a · b + a ≤ a · b + consti · b, which give us EXR(rf) (exfd, E) ≤

consti – a contradiction.
Only-if: Suppose EXR(rf) (exfd, E) > EXR(rf) (exfd, E ∪{pi }). Let EXR(rf) (exfd, E) = ab .
Hence,

a
b

>

a+consti
b+1

- which proves the claim.

CLAIM 2: For explanation E and points pi , pj ∈ L − E where consti < constj ., then
EXR(rf) (exfd, E ∪ {pi }) > EXR(rf) (exfd, E ∪ {pj }).
548

Straightforward algebera similiar to claim 1.
CLAIM 3: Algorithm BUILD-STRAT returns an optimal adversarial strategy.
We know that Ecore must be in the optimal adversarial strategy. Hence, we suppose
BWOC, that for the remaining elements, that ther eis a better set of elements - cardinality between 0 and k − |Ecore | s.t. the expected adversarial detriment is lower.
However, this contradicts claims 1-2.
CLAIM 4: Algorithm BUILD-STRAT runs in time O(∆ · |O| · log(∆ · |O|) + (k −
|Ecore |)2 ).
Sorting the set L − Ecore can be accomplished in O(∆ · |O| · log(∆ · |O|)) time. The
remainder can be accomplished in O((k − |Ecore |)2 ) time.

E.2.19

Proof of Lemma 20

Given an optimal adversarial strategy, Egt , if core explanation Ecore , of size δ,
is a subset of Egt , then Ecore is δ-core optimal.
Proof. Suppose BWOC, that Ecore was not δ-core optimal. Then, given a δ-core
′
′
optimal explanation Ecore
, we could conclude that EXR(rf) (exfd, (Egt −Ecore )∪Ecore
)<

EXR(rf) (exfd, (Egt ) - which cannot be true as Egt is an optimal adversarial strategy –
hence a contradiction.

E.2.20

Proof of Lemma 21

1. If explanation E is δ-core optimal, then E ⊆ L∗∗ .

549

2. If for some natural number δ, there exists an explation of size δ, then there
exists a δ-core optimal explanation E s.t. E ⊆ L∗ .
Proof. Proof of Part 1:
Suppose, BWOC, exists explanation E s.t. for some δ, E is δ-core optimal and
E 6⊆ L∗∗ . Then, there exists some pi ∈ E ∩ (L − L∗∗ ). By the definition of L∗∗ , there
exists a pj ∈ L∗∗ s.t. constj < consti and ∀o ∈ O s.t. o, pi are partners, then o, pj
are also partners. Hence, the set (E − {pi }) ∪ {pj } is also an explanation of size δ
and has a lower expected detriment. From the definition of δ-core optimal, this is a
contradiction.

Proof of Part 2:
Suppose, BWOC, for some δ s.t. there is an explanation of this size, there does not
exist a δ-core optimal explanation E s.t. E ⊆ L∗ . By the proof of part 1, we know
that an δ-core optimal explanation must be within L∗∗ . Further, by the definition
of L∗ , for any point pi ∈ L∗∗ − L∗ , there exists point pj ∈ L∗ s.t. constj = consti
and ∀o ∈ O s.t. o, pi are partners, o, pj are also partners. Hence, for some δ-core
explanation that is not a subset of L∗ , any pi ∈ E ∩ (L∗∗ − L∗ ) can be replace
with some pj ∈ L∗ - and the resulting set is still an explanation, optimal, and of
cardinality δ - a contradiction.

E.2.21

Proof of Proposition 60

The δ-core cosntraints require O(∆ · |O|) variables and 1 + |O| constraints.
550

Proof. Mirrors propositon 54.

E.2.22

Proof of Proposition 61

Given δ-core cosntraints:
1. Given set δ-core optimal explanation Ecore ≡ {p1 , . . . , pn }, if variables X1 , . . . , Xn
- corresponding with elements in Egt are set to 1 - and the rest of the variables
are set to 0, the objective function of the constraints will be minimized.
2. Given the solution to the constraints, if for every Xi = 1, we add point pi to
set Ecore , then Ecore is a δ-core optimal soluton.
Proof. From Lemma 21, we know that for any δ s.t. there exists and explanation of
that size, there is a δ-core explanation E that is a subset of L∗ . Hence, the rest of
the proof mirrors the proof of Proposition 54

E.2.23

Proof of Theorem 33

MCA is NP-hard.
Proof. Consider an instance of GCD consisting of set of points P , integer b, and
integer K. We construct an instance of MCA as follows:
CONSTRUCTION:
• Set S to be a grid large enough that all points in P are also points in S. We will
use M, N to denote the length and width of S.
• feas(p) = TRUE iff p ∈ P
551

• α = 0, and β =

√

M 2 + N 2 , O ≡ P , k = K, and B = K

• Let rf(E1 , E2 ) be crf where dist = b.
• Let functions ex fcn1 , . . . , ex fcn|P | be explanation functions - each ex fcni corresponding to a unique pi ∈ P . Let ex fcni (O, num) = {pi } for all num > 0.
Note that each pi is an explanation for the set P as it is of cardinality ≤ k,
is feasible, and is guarantted to be with [α, β] from all other points in P as
[α, β] = [0,

√

M 2 + N 2]

• Let exfd(ex fcni ) =

1
|P |

for all i.

CLAIM 1: crf(dist) ({pi }, C) = 1 iff there exists p′ ∈ C s.t. a disc of radius b (note
b = dist) centered on p′ covers pi . crf(dist) ({pi }, C) = 0 iff there does not exist p′ ∈ C
s.t. a disc of radius b centered on p′ covers pi .
Follows directly from the definition of crf.

CLAIM 2: If the expected agent benefit is 1, then for all i, crf(dist) ({pi }, C) = 1.
Suppose, BWOC, that the expected agent benefit is 1 and there exists some pi s.t.
crf(dist) ({pi }, C) 6= 1. Then, for a singleton set, crf(dist) ({pi }, C) = 0. Hence, for
the ex fcni associated with pi , crf(dist) (ex fcni (O), C) = 0. So, by the definition of
expected agent benefit, it is not possible for the expected agent benefit to be 1 – a
contradiction.

CLAIM 3: If MCA returns an optimal counter-adversary strategy with an expected
expected agent benefit of 1, then GCD must also return “yes.”
552

Suppose, BWOC, MCA returns a stratgey with an expected agent benefit of 1 and
the corresponding of GCD returns “no.” Then there does not exist a K-sized cover
for the points in P . However, the set C is of cardinlaity K and by claims 1-2 covers
all points in P . Hence, a contradiction.

CLAIM 4: If GCD return ”yes” then MCA must return an optima counter-adversary
strategy with an expected agent benefit of 1.
Suppose, BWOC GCD returns “yes” and MCA reutrns returnsa an optimal strategy
with an expected agent benefit < 1. However, by the answer to GCD, there must
exist P ′ ⊆ P of cardinality k that is within distance b of all points in P . Hence, for
all i, crf(dist) ({pi }, C) = 1 (as b = dist). So, the expected agent benefit must also
be 1. Hence, a contradiction.

Proof of theorem: Follows directly from claims 3-4.

E.2.24

Alternate Proof of Theorem 33

MCA is NP-hard (shown in the case where the reward function is not monotonic and the agent has no budget).
Proof. Consider an instance of GCD consisting of set of points P , integer b, and
integer K. We construct an instance of MCA as follows:
CONSTRUCTION: The construction is the same for the first proof of Theorem 33
in Section E.2.23 (the encoding of GCD) except the reward function is krfdist
k (Egt , C)

553

defined as follows
1 |{p ∈ Egt |∃p′ ∈ C s.t. d(p, p′ ) ≤ b}|
+
2
2 · |Egt |

if |C| ≤ k

1 |{p ∈ Egt |∃p′ ∈ C s.t. d(p, p′ ) ≤ b}| |C| − k
+
−
2
2 · |Egt |
2 · |S|

otherwise

CLAIM 1: Given some k ≥ |A|, the function krf is a valid reward function.
Clearly, krfbk (A, A) = 1. To show submodularity (the second axiom), we must show
the following for C ⊆ C ′ and p ∈
/ C ′:
krfbk (A, C ∪ {p}) − krfbk (A, C) ≥ krfbk (A, C ′ ∪ {p}) − krfbk (A, C ′ )

(E.4)

There are six possible cases:

1. |C ′ ∪ {p}| ≤ k: submodularity follows from the submodularity of crf
2. |C ′ ∪ {p}| > k, |C ′ | ≤ k, |C ∪ {p}| ≤ k: in this case, the left-hand side of
inequality E.4 is positive and the right-hand side is negative, submodularity
immediately follows
3. |C ′ ∪ {p}| > k, |C ′ | > k, |C ∪ {p}| ≤ k: in this case, the left-hand side of
inequality E.4 is positive and the right-hand side is negative, submodularity
immediately follows
4. |C ′ ∪ {p}| > k, |C ′ | ≤ k, |C ∪ {p}| > k, |C| ≤ k: this is the case where C ≡ C ′ ,
both sides of inequality E.4 are equal

554

5. |C ′ ∪ {p}| > k, |C ′ | > k, |C ∪ {p}| > k, |C| ≤ k: the right-hand side of inequality E.4 either increases or decreases by, at most, the amount the left side
decreases by - the left hand side always decreases
6. |C ′ ∪ {p}| > k, |C ′ | ≤ k, |C ∪ {p}| > k, |C| > k: the right-hand side of inequality E.4 either increases or decreases by, at most, the amount the left side
decreases by - the left hand side always decreases
PROOF OF THEOREM: Mirrors the proof in Section E.2.23, as this reward function is maximized (returns a value of 1) for the mixed adversarial strategy in the
construction iff each point is within distance b of some point in the agent’s strategy,
and the agents strategy is of cardinality ≤ k (anything of a greater cardinality would
give a reward less than 1). Therefore, we can follow the remainder of that proof and
obtain the same result.

E.2.25

Proof of Theorem 34

MCA-DEC is NP-complete, provided the reward function can be evaluated
in PTIME.
Proof. CLAIM 1: Membership in NP.
Given an explanation, C, we can evaluate it reward and if it is an explanation in
PTIME.

CLAIM 2: MCA-DEC is NP-hard.
Follows directly from Theorem 33
555

E.2.26

Proof of Theorem 35

Counting the number of strategies that provide a “yes” answer to MCA-DEC
is #P-complete and has no FPRAS unless NP==RP.
Proof. Theorem 33 shows a parsimonious reduction from GCD to MCA. Hence, we
can simply apply Lemma 19 and the statement follows.

E.2.27

Proof of Theoerm 36

For a fixed O, k, exfd, the expected agent benefit, EXB(rf) (C, exfd) has the following properties:
1. EXB(rf) (C, exfd) ∈ [0, 1]
2. For C ⊆ C ′ and some point p ∈ S where p ∈
/ C ∪ C ′ , the following is true:
EXB(rf) (C∪{p}, exfd)−EXB(rf) (C, exfd) ≥ EXB(rf) (C ′ ∪{p}, exfd)−EXB(rf) (C ′ , exfd)
(i.e. expected agent benefit is sub-modular for MCA)
Proof. Part 1 follow directly from the definition of a reward function and expected
agent benefit.

For part 2, for some set C and fixed exfd, we have:
EXB(rf) (C, exfd) =

X

ex fcn∈EF

rf(C, ex fcn(O, k)) · exfd(ex fcn)

Which is a positive, linear combination of submodular functions – hence EXB(rf)
must also be submodualr.
556

E.2.28

Proof of Proposition 62

MCA-LS has time complexity of O( 1ǫ · |L|3 · F (exfd) · lg(|L|) where F (exfd) is
the time complexity to compute EXB(rf) (C, exfd) for some set C ⊆ L.
Proof. We note that one iteration of the algorithm requires O(|L| · F (exfd) + |L| ·
lg(|L|)) time. We shall assume that O(|L| · F (exfd) dominates O(|L| · lg(|L|)). By
Theorem 3.4 of [47], the number of iterations of the algorithm is bounded by O( 1ǫ ·
|L|2 · lg(|L|) where F (exfd), hence the statement follows.

E.2.29

Proof of Proposition 63

MCA-LS is an ( 31 −

ǫ
)-approximation
|L|

algorithm for MCA.

Proof. By Theorem 36, we can be assured that when the “if” statement at line 4c
is TRUE, then there are no further elements in C ∗ that will afford an incremental
increase of > (1 + |L|ǫ 2 ) · EXB(rf) (C, exfd), even if the last element is not yet reached.
Hence, we can apply Theorem 3.4 of [47] and the statement follows.

E.2.30

Proof of Corollary 12

For a fixed O, k, exfd, if the reward function is montonic, then the expected
agent benefit, EXB(rf) (C, exfd) is also montonic and zero-starting.
Proof. The zero-starting aspect of expected agent benefit follows directly from the
definitions of zero-starting and expected agent benefit.

557

Consider the definition of EXB(rf) :
EXB(rf) (C ∪ {p}, exfd) − EXB(rf) (C, exfd) ≥ EXB(rf) (C ′ ∪ {p}, exfd) − EXB(rf) (C ′ , exfd)
As rf is montonic by the statement, and exfd is fixed, EXB(rf) is a positive linear
combination of montonic functions, so the statement follows.

E.2.31

Proof of Proposition 64

The complexity of MCA-GREEDY-MONO is O(B · |L| · F (exfd)) where F (exfd)
is the time complexity to compute EXB(rf) (C, exfd) for some set C ⊆ L of size B.
Proof. The outer loop at line 4 iterates B times, the inner loop at line 4b iterates
O(|L|) times, and at each inner loop, at line 4(b)ii, the function EXB(rf) (C, exfd)
is computed with costs F (exfd). There is an additional O(|L| · lg(|L|)) sorting
operation after the inner loop which, under most non-trivial cases, is dominated by
the O(|L| · F (exfd)) cost of the loop. The statement follows.

E.2.32

Proof of Corollary 13

e
MCA-GREEDY-MONO is an ( e−1
)-approximation algorithm for MCA (when

the reward function is montonic).
First, we define incremental increase:
Definition 116. For a given pi ∈ L at some iteration j of the outer loop of GREEDY(j)

MONO (the loop starting at line 4), the incremental increase, inci , is defined as
follows:
(j)

inci = EXB(rf) (C (j−1) ∪ {pi }, Egt ) − EXB(rf) (C (j−1) , Egt )
558

Where C (j−1) is the set of points in L selected by the algorithm after iteration j − 1.
Proof. CLAIM 1: For any given iteration j of GREEDY-MONO and any pi ∈ L,
(j)

(j+1)

inci ≥ inci

By Definition 116, the statement of the proposition is equivalent to the following:
EXB(rf) (C (j−1) ∪{pi }, Egt )−EXB(rf) (C (j−1) , Egt ) ≥ EXB(rf) (C (j) ∪{pi }, Egt )−EXB(rf) (C (j) , Egt )
Obviously, as C (j−1) ⊆ C (j) , this has to be true by the submodularity of EXB(rf) , as
proved in Theorem 36.

(Proof of Proposition): By claim 1, we can be assured that any point not considered
by the inner loop will not have a greater incremental increase than some point
already considered in that loop. Hence, our algorithm provides the same result as
the greedy algorithm of [127]. We know that the results of [127] state that a greedy
algorithm for a non-decreasing, submodularity function F s.t. F (∅) = 0 is a

e
e−1

approximation algorithm for the associated maximization problem. Theroem 36
and Corollary 12 show that these properties hold for finding a maximal counteradversary startegy when the reward function is montonic. Hence, by [127], the
statement follows.

E.2.33

Proof of Theoerem 37

MCA-GREEDY-MONO provides the best approximation ratio for MCA (when
the reward function is monotonic) unless P == N P .
Proof. The MAX-K-COVER [46] is defined as follows.
559

INPUT: Set of elements, S and a family of subsets of S, H ≡ {H1 , . . . , Hmax }, and
positive integer K.
OUTPUT: ≤ K subsets from H s.t. the union of the subsets covers a maximal
number of elements in S.
In [46], the author proves that for any α <

e
,
e−1

there is no α-approximation algo-

rithm for MAX-K-COVER unless P == N P . We show that an instance of MAXK-COVER can be embedded into an instance of MCA where the reward function
is monotonic and zero-starting in PTIME. By showing this, we can leverage the
result of [46] and Corollary 13 to prove the statement. We shall define the reward
function srf(Egt , C) = 1 iff |Egt ∩ C| ≥ 1 and srf(Egt , C) = 0 otherwise. Clearly,
this reward function meets all the axioms, is zero-starting, and monotonic. We create a space S s.t. the number of points in S is greater than or equal to |H|. For
each subset in H, we create an observation at some point in the space. We shall
call this set OH and say that oH is the element of OH that corresponds with set
H ∈ H. We set feas(p) = true iff p ∈ OH . We set α = 0, β to be equal to the
diagonal of the space, and k = |OH |. Hence, any non-empty subset of OH is a
valid explanation for O. For each x ∈ S, we define explanation function ex fcnx s.t.
ex fcnx (OH , k) = {oH ∈ OH |x ∈ H}. We define the explanation function distribution exfd to be a uniform distribution over all ex fcnx explanation functions. We set
the budget B = K. Clearly, this construction can be accomplished in PTIME. We
note that any solution to this instance of MCA must be subset of OH , for if it is
not, we can get rid of the extra elements and have no change to the expected agent
benefit. Hence, each p ∈ C will correspond to an element of H, so we shall use the
560

notation pH to denote a point in the solution that corresponds with some H ∈ H
(as each o ∈ OH corresponds with some H ∈ H).

CLAIM 1: Given a solution C to MCA, the set {H ∈ H|pH ∈ C} is a solution to
MAX-K-COVER.
Clearly, this solution meets the cardinality constraint, as there is exactly one element in OH for each element of H and C is a subset of OH . Suppose, BWOC, there
is some other subset of H that covers more elements in S. Let H′ be this solution
to MAX-K-COVER and C ′ be the subset of OH that corresponds with it. We note
that for some x ∈ S in C ′ , srf(ex fcnx (OH , k), C ′ ) = 1 iff there is some H ∈ H′
s.t. x ∈ H and srf(ex fcnx (OH , k), C ′ ) = 0 otherwise. Hence, the expected agent
benefit is the fraction of elements in S covered by H′ . If H′ is the optimal solution
to MAX-K-COVER, then C ′ must provide a greater expected agent benefit than C,
which is clearly a contradiction.

CLAIM 2: Given a solution H′ to MAX-K-COVER, the set {oH ∈ OH |H ∈ H′ } is
a solution to MCA.
Again, that the solution meets the cardinality requirement is trivial (mirrors that
part of claim 1). Suppose, BWOC, there is some set C that provides a greater
maximum benefit than {oH ∈ OH |H ∈ H′ }. Let H′′ ≡ {H ∈ H|pH ∈ C}. As with
claim 1, the expected agent benefit for C is equal to the fraction of elements in S
covered by H′′ , which is a contradiction as H′ is an optimal solution to MAX-KCOVER.
561

E.2.34

Proof of Corollary 18

MCA-Exp is NP-hard.
Proof. Consider the construction in Theorem 33. As any non-empty subset of P which are all the feasible points in the space - is an explanation - then solution to
MCA is also a solution to MCA-Exp.

E.2.35

Proof of Theorem 60

MCA-Exp reduces in polynomial time to the maximization of a submodular
function wrt a uniform matroid.
Proof. Given an instance of MCA-Exp as follows:
Space S, feasibility predicate, feas, real numbers α, β, set of observations, O, natural
numbers k, B, reward function rf, and explanation function distribution exfd.
Let L be the set of all possible partners. Consider the following construction.
1. Let M be a uniform matroid consisting of all subsets of L of cardilnality ≤ B
2. Let function fsubmod : 2L → ℜ be defined as follows:
fsubmod (C) = EXB(rf) (C, exfd)+2·|{o ∈ O|∃p ∈ C s.t. (d(o, p) ∈ [α, β])∧(feas(p))}|
CLAIM 1: fsubmod (C) is submodular.
As EXB(rf) (C, exfd), all we will show that 2 · |{o ∈ O|∃p ∈ C s.t. (d(o, p) ∈ [α, β]) ∧
(feas(p))}| is submodular, as a positive linear combination of submoudlar functions
is also submodular. Suppose, BWOC that it is not submodular, hence, for some
562

C ⊂ C ′ and p′′ ∈
/ C ′ , we have the following:
2 · |{o ∈ O|∃p ∈ C ∪ {p′′ } s.t. (d(o, p) ∈ [α, β]) ∧ (feas(p))}| −
2 · |{o ∈ O|∃p ∈ C s.t. (d(o, p) ∈ [α, β]) ∧ (feas(p))}| <
2 · |{o ∈ O|∃p ∈ C ′ ∪ {p′ } s.t. (d(o, p) ∈ [α, β]) ∧ (feas(p))}| −
2 · |{o ∈ O|∃p ∈ C ′ s.t. (d(o, p) ∈ [α, β]) ∧ (feas(p))}|
We can re-write this as follows:
2 · |{o ∈ O|o and p′′ are partners and 6 ∃p′′′ ∈ C that can also be a partner for o}| <
2 · |{o ∈ O|o and p′′ are partners and 6 ∃p′′′ ∈ C ′ that can also be a partner for o}|
Clearly, as C ⊆ C ′ , this cannot hold - hence we have a contradiction.
CLAIM 2: If there is a solution to MCA-Exp then the submodular maximization
problem returns a value greater than or equal to 2 · |O|.

Suppose, BWOC, there is a solution to MCA-Exp, and the submodular maximization problem returns a value less than 2 · |O|. However, any solution to C to
MCA-Exp, we know the following:
2 · |{o ∈ O|∃p ∈ C s.t. (d(o, p) ∈ [α, β]) ∧ (feas(p))}| = 2 · |O|
hence, a contradiction.
CLAIM 3: If the submodular maximization problem returns a value greater than or
equal to 2 · |O| then there is a solution to MCA-Exp.
Suppose, BWOC, claim 3 is false. However, we know that
EXB(rf) (C, exfd) ≤ 1
563

Hence, the only way for the submodular maximization problem returns a value
greater than or equal to 2 · |O| is if the vertices chosen to produce such a value is
an explanation – hence a contradiction.
CLAIM 4: If MCA-Exp returns a value b, then the submodular maximization
problem returns a value b + 2 · |O|.
By claim 2, we know for solution C to MCA-Exp, for some C ′ set of elements that
maximizes fsubmod that:
2 · |{o ∈ O|∃p ∈ C ′ s.t. (d(o, p) ∈ [α, β]) ∧ (feas(p))}| = 2 · |O|
Hence, any set that maximizes fsubmod is an explantion that maximizes the quantity
EXB(rf) (C, exfd) - which, by definition, is also a set that can be a solution to MCAExp.
CLAIM 5: If the maximization of fsubmod returns value b, then MCA-Exp returns
a value b − 2 · |O|.
Consider set C ′ that maximizes fsubmod . By claim 3, this is an explantion that maximizes EXB(rf) (C, exfd). Hence, by the definition of MCA-Exp, it will also give a
solution to MCA-Exp and by the definition of fsubmod , returns a value b − 2 · |O|.

Proof of theorem: follows directly from claims 2-5.

564

Appendix F
Appendix for Chapter 7

F.1

Proofs

F.1.1

Proof of Theorem 38

Given GBGOP (M, s0 , A, C, IC, c, Θin , Θout ), finding an optimal solution SOL ⊆
A × M is NP-hard. This result holds even if for each a ∈ A, p ∈ M, it is the case
that ∀g ′ (p′ ) ∈ a(p), p′ = p - i.e. each action only affects the point is is applied to).
Proof. The known NP-hard problem of SET-COVER [46] is defined as follows.
INPUT: Set of n elements, S and a family of m subsets of S, H ≡ {H1 , . . . , Hm }.
OUTPUT: H′ ⊆ H of minimal cardinality s.t.

S

H∈H′

H ≡ S.

Given an instance of SET-COVER, we embed it in a GBGOP as follows:
• G = {g1 , . . . , gn } - each predicate in G corresponds to an element in S
• M consists of a single point, p
• A = {a1 , . . . , am } - each action in A corresponds to an element in H. Each ai is
565

defined as follows: ai (p) =

S

xj ∈Hi {gj (p)}

• C returns 1 for all aciton-point pairs.
• s0 = ∅, IC = ∅, c = m
• Θin =

S

gi ∈G {gi (p)}

• Θout = ∅
Clearly, this construction can be performed in PTIME. The corecetness of the
embeding follows directly from claims 1-2 below.

CLAIM 1: If H′ ⊆ H is an optimal solution to SET-COVER, then
is an optimal solution to the GBGOP.
First, we show that

S

Hi ∈H′ {(ai , p)}

S

Hi ∈H′ {(ai , p)}

is a solution to the GBGOP. As c is the cardi-

nality of A × M and IC = ∅, the first two requirement is trivially met. To meet
the third requirement, we observe that appl(∅,
by the construction

S

Hi ∈H′

S

Hi ∈H′ {(ai , p)}

=

S

Hi ∈H′

ai (p) and

gi ∈G {gi (p)}

= Θin . Now we show that the

Hi ∈H′ {(ai , p)}.

Suppose, BWOC, there is some

ai (p) =

solution is optimal. Let SOL =

S

S

solution SOL′ ⊆ A × M s.t. |SOL′ | < |SOL|. Hence, there is some H′′ where
SOL′ =

S

Hi ∈H′′ {(ai , p)}.

Hence, |H′′ | < |H′ |. By the construction, H′′ also covers

all elements of S - which implies H′′ is more optimal than H′ - a contradiction.
CLAIM 2: If SOL is an optimal solution to the BMGOP, then {Hi |(ai , p) ∈ SOL}
is an optimal solution to SET-COVER.
Clearly, by the construction, {Hi |(ai , p) ∈ SOL} covers all elements in S. Let H′
566

be this set. Suppose, BWOC, that there is some set H′′ ⊆ H where |H′′ | < |H′ and
H′′ covers all the elements in S. Then, we can construct SOL′ =

S

Hi ∈H′′ {(ai , p)}.

By the first claim, this must also be a solution to GBGOP. Further, it must have a
smaller cardinality than SOL - a contradiction.

F.1.2

2

Proof of Theorem 39

Given BMGOP (M, s0 , B, A, C, IC, k, c), finding an optimal solution SOL ⊆
A is NP-hard.
Proof. The known NP-hard problem of MAX-K-COVER [46] is defined as follows.
INPUT: Set of n elements, S and a family of m subsets of S, H ≡ {H1 , . . . , Hm },
and positive integer K.
OUTPUT: ≤ K subsets from H s.t. the union of the subsets covers a maximal
number of elements in S.
Given an instance of MAX-K-COVER, we embed it in a BMGOP as follows:
• G = {g1 , . . . , gn } - each predicate in G corresponds to an element in S
• M consists of a single point, p
• B is a |BL |-sized vector of 1’s
• A = {a1 , . . . , am } - each action in A corresponds to an element in H. Each ai is
defined as follows: ai (p) =

S

xj ∈Hi {gj (p)}

• C is a |A × M|-sized vector of 1’s
• s0 = ∅, IC = ∅, k = K, c = K
567

Clearly, this construction can be performed in PTIME. The corecetness of the
embeding follows directly from claims 1-2 below.
CLAIM 1: If H′ ⊆ H is an optimal solution to MAX-K-COVER, then
is an optimal solution to the BMGOP.
Suppose, BWOC, there is some solution SOL′ ⊆ A s.t.
P

Ai ∈appl(SOL′ ,s0 ) bi .

P

Ai ∈appl(

S

S

Hi ∈H′ {(ai , p)}

Hi ∈H′ {(ai ,p)},s0 )

bi <

As there is only one point in M (point p), then each action-point

pair in SOL′ must have unique action - let A′ be these actions. By the construction,
each action in A′ is associated with a subset in H - let H∗ be this set of subsets.
Clearly, by the cost vector in the construction, |H∗ | ≤ k, or else SOL′ is not a solution to the BMGOP. We also know that appl(SOL′ , s0 ) = (∅ ∪ {a(p)|(a, p) ∈ SOL′ })
- again, as there is only one point in M, appl(SOL′ , s0 ) can be associated with a
subset of G - let us call this G ′ . Further, by the construction, G ′ is associated with
a subset of S, which we shall denote S ′ . By the construction, S ′ is the union of
all subsets in H∗ . And, by how we defined B, |S ′ | is greater than the number of
elements covered by the optimal solution - which is a contradiction.
CLAIM 2: If SOL is an optimal solution to the BMGOP, then {Hi |(ai , p) ∈ SOL}
is an optimal solution to MAX-K-COVER.
Suppose, BWOC, that there set H′ ⊆ H s.t. |H′ | ≤ k and |

S

Hj ∈H′

Hj | > |

S

Hi |(ai ,p)∈SOL

Let A′ be the subset of actions associated with H′ and SOL′ = {(ai , p)|ai ∈ A′ }.
By the cost vector, we know that |SOL′ | ≤ k which means SOL′ is a valid solution. By the construciton, and the fact there is only one point in M, we know that
appl(SOL′ , s0 ) = |
contradiction.

S

Hi ∈H′

Hi |, which must be larger than appl(SOL, s0 ) - hence a
2
568

Hi |.

F.1.3

Proof of Theorem 40

If for some ǫ > 0, there is a PTIME algorithm to approximate GBGOP within
(1 − ǫ) · ln(|A × M|), then N P ⊂ T IM E(|A × M|O(lg lg |A×M|) ) (NP has a slightly
super-polynomial algorithm).

Proof. Suppose, by way of contradiction, that for some ǫ > 0, there is a PTIME algorithm to approximate GBGOP within (1 − ǫ) · ln(|A × M|) and N P 6⊂ T IM E(|A ×
M|O(lg lg |A×M|) ). By Theorem 38, the same algorithm could approximate SETCOVER withihn (1 − ǫ) · ln(|H|) and we would have N P 6⊂ T IM E(|H|O(lg lg |H|) ).
Howevewr, if we could obtain such an approximation factor for SET-COVER, Theorem 4.4 of [46] tells us that N P ⊂ T IM E(|H|O(lg lg |H|) ) - a contradiction.

F.1.4

2

Proof of Theorem 41

Given BMGOP (M, s0 , B, A, C, IC, k, c), finding an optimal solution SOL of
action-point pairs cannot be approximated in PTIME within a ratio of

e−1
e

+ ǫ for

some ǫ > 0 (where e is the inverse of the natural log) unless P=NP, even when
IC = ∅. (There is no polynomial-time algorithm that can approximate an optimal
solution within a factor of about 0.63 unless P=NP.)

Proof. Suppose, by way of contradiction, that an algorithm existed for finding a
solution to a BMGOP within 1 − 1/e + ǫ of optimal for some ǫ > 0. Then we could
569

use the construction of Theorem 39 to obtain an approximate solution to MAXK-COVER within a factor of 1 − 1/e + ǫ for some ǫ > 0. By Theorem 5.3 of [46],
this would imply P==NP, which contradicts the statement of the theorem.

F.1.5

2

Proof of Theorem 42

Given GBGOP (M, s0 , A, C, IC, c, Θin ,
Θout ), if the cost function and all actions a ∈ A can be polynomially computed,
then determining if there is a solution SOL for the instance of the GBGOP s.t. for
some real number k, |SOL| ≤ k is in-NP.

Proof. As all calculations of actions, and cost can be performed in PTIME, and
checking if a given solution satisfies the integrity constraints can also be performed
in PTIME, the verification of a solution is also achievable in PTIME, which gives
us membership in the complexity class NP.

F.1.6

2

Proof of Theorem 43

Given BMGOP (M, s0 , B, A, C, IC, k, c), if the cost function, benefit function,
and all actions a ∈ A can be polynomially computed, then determining if there
is a solution SOL for the instance of the BMGOP s.t. for some real number val,
P

Ai ∈appl(SOL,s0 ) bi

≥ val is in-NP.

Proof. As all calculations of actions, cost, and benefit can be performed in PTIME,
and checking if a given solution satisfies the integrity constraints can also be per-

570

formed in PTIME, the verification of a solution is also achievable in PTIME, which
gives us membership in the complexity class NP.

F.1.7

2

Proof of Theorem 44

Counting the number of solutions to a GBGOP (under the assumptions of
Theorem 42) is #P-complete.

Proof. CLAIM 1: There is a 1-1 encoding of MONSAT into a GBGOP.
The MONSAT problem is defined as per [145] below. INPUT: Set of m clauses
C, each with K disjuncted literals, no literals are negations, L is the set of atoms,
|L| = n.
OUTPUT: “Yes” iff there is a subset of L such that if the atoms in the subset are
true, all of the clauses in C are satisfied.
We use the following encoding.
• G = {g1 , . . . , gm } - each predicate in G corresponds to an clause in C (predicate
gj corresponds with clause φj )
• M consists of a single point, p
• A = {a1 , . . . , an } - each action in A corresponds to an element in L (action ai
corresponds with lieteral ℓi ) . Each ai is defined as follows: ai (p) = {gj (p)|{ℓi } |=
φj
• C returns 1 for all aciton-point pairs.
571

• s0 = ∅, IC = ∅, c = n
• Θin =

S

gi ∈G {gi (p)}

• Θout = ∅
Clearly, the above construction can be accomplished in PTIME.
CLAIM 1.1 If SOL ⊆ A × M is a solution to GBGOP, then there exists L′ ⊆ L
that is a solution to MONSAT where |SOL| = |L′ |.
Consider the set of literals L′ = {ℓi |(ai , p) ∈ SOL}. Clearly, |L′ | = |SOL|. Suppose,
BWOC, there is a clause φi ∈ C s.t. there is no ℓ ∈ L′ where {ℓ} |= φ. Clearly, the
element gi (p) is in Θin , so there must be some action-point-pair (aj , p) in SOL s.t.
gi (p) ∈ aj (p) (otherwise, SOL is not a solution). This implies there is some ℓj ∈ L′
that corresponds with aj and, by the construction {ℓj |= φ - a contradiction.
CLAIM 1.2 If L′ ⊆ L is a solution to MONSAT then there exists SOL ⊆ A × M
that is a solution to GBGOP where |SOL| = |L′ |.
Consider the set SOL = {(ai , p)|ℓi ∈ L′ }. Clearly |L′ | = |SOL|. As c = n and
IC = ∅, the first two requirements of SOL to be a solution are trivially met. The
set appl(∅, {(ai , p)|ℓi ∈ L′ }) =

S

ℓj ∈L′

gj (p). Hence, as L′ has a literal that satisfies

each clause, and by the construction, we know the third requirement of being a
solution is met.
CLAIM 2: Counting the solutions to a GBGOP is #P -hard.
Using the construction of claim 1, we can embedd the counting version of MONSAT
(number of solutions) into the counting version of a GBGOP (number of solutions).
As there is a 1-1 correspondance, the reduction is parsimonious. Hence, using the
572

construction of claim 1, if we find that there are N solutions to the GBGOP, the
corresponding instance of MONSAT also has exactly N solutions.
CLAIM 3: Counting the solutions to a GBGOP is in the complexity class #P .
We use the two requirements for membership in-#P.
(i) Witnesses must be verifiable in PTIME (shown in Theorem 42).
(ii) The number of solutions to GBGOP x∆ - where x is depends on the input and ∆
is a constant. We know that the number of solutions is bounded by
which is less than γ · |A × M||A×M| for some constant γ.

F.1.8

P|A×M|
i=0

|A×M|
i



2

Proof of Theorem 45

For some ǫ > 0, approximating the number of solutions to a GBGOP within
a factor of 2|A×M|

1−e

is NP-hard.

Proof. Suppose, BWOC, there is some ǫ > 0 s.t. there is a PTIME algorithm
to approximate the number of solutions to a GBGOP with cardinality ≤ k within
a factor of 2|A×M|

1−e

. Hence, the same algorithm could be used to approximate

counting the solution to MONSAT (using the construction of Theorem 44 within a
factor of 2n

F.1.9

1−e

. However, this contradicts Theorem 3.2 of [145].

2

Proof of Lemma 22

Given GBGOP Γ = (M, s0 , A, C, IC, c, Θin , Θout ), for any optimnal solution
SOL ⊆ R, there is an optimal solution SOL′ ⊆ R∗ .

573

Proof. We show this by proving that for any set W = SOL ∩ (R − R∗ ), there is
some set W ′ ⊆ R∗ − (R∗ ∩ SOL) s.t. (SOL − W ) ∪ W ′ is also a solution. Hence,
|(SOL − W ) ∪ W ′ | = |SOL|. By Definition 86, for any (ai , pi ) ∈ R − R∗ , there
is some (aj , pj ) ∈ R∗ s.t. cj ≤ ci , (aj , pj ) appears in the same or fewer integrity
constraints, and ai (pi ) − (s0 ∩ ai (pi )) ⊆ aj (pj ). Hence, for any (ai , pi ) ∈ W , there is
a corresponding element in W ′ that we can use to replace (ai , pi ) without increasing
cost, violating any integrity constraints, or not covering an element of Θin .

F.1.10

2

Proof of Proposition 66

Suppose Γ = (M, s0 , A, C, IC, c, Θin , Θout ) is a GBGOP and IP (Γ) is its corresponding integer program. We can create such a program with a variable for every
element of R∗ (instead of R) and the statement of Proposition 65 still holds true.
Proof. Follows directly from Lemma 22 and Proposition 65.

574

2

Appendix G
Appendix for Chapter 8

G.1

Proofs for Section 8.3

G.1.1

Proof of Proposition 70

If agg is positive-linear, then it is montonic.
Proof. Follows directly from Definitions 97-98.

G.1.2

Proof of Proposition 71

If a SNOP-query is not zero-starting w.r.t. a social network S and a GAP
Π ⊇ ΠS , and the aggregate is positive-linear, it can be expressed as a zero-starting
SNOP-query in linear time while still maintaining a positive-linear aggregate.
Proof. CONSTRUCTION: Let C = value(∅).
Create a new SNOP query with aggregate agg ′ (X) = agg(X) − C.

575

We shall use the notation value′ to refer to the value function for the above
construction.

CLAIM For any set V′ , value(V′ ) = value(V′ ) + C.
Follows directly from the construction.

G.1.3

Proof of Lemma 23

Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP Π ⊇ ΠS ), if
agg is monotonic (Definition 97), then value (defined as per Q and Π) is montonic.
Proof. By the definition of T, the annotation of any vertex atom montonically
increases as we add more facts of the form g(V ) ← to the logic program. Hence, by
the monotonicity of agg, the statement follows.

G.1.4

Proof of Lemma 24

Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP Π ⊇ ΠS ),
if V C is applied a-priori (as per Definition 101), the set of pre-answers (to query Q)
is a uniform matroid.
Proof. Let Vcond be the set of veritces in V s.t. for each v ∈ Vcond , g(v) : 1 ∧
V

pred∈ℓvert (v)

pred(v) : 1 |= V C[V /v].

CLAIM 1: For an a-priori V C SNOP query, any subset of Vcond of cardinality ≤ k
is a pre-answer.
Suppose, BWOC, some subset of V′ ⊆ Vcond of cardinality ≤ k is not a pre-answer.
576

Obvouisly, all such subsets meet the cardinality requirement. Then, there must exist
some v ′ ∈ V′ s.t. g(v ′ ) : 1∧
this is a contradiction.

V

pred∈ℓvert (v ′ )

pred(v ′ ) : 1 6|= V C[V /v ′ ]. By Definition 101,

CLAIM 2: There is no subset V′ ⊆ V where V′ ∩ (V − Vcond ) 6≡ ∅ that is a preanswer.
Clearly, this would have an element that would not satisfy the a-priori V C, and
hence, not be a pre-answer.

Proof of lemma: Any subset of size ≤ k of Vcond is a uniform matroid by definition.
Also, from claims 1-2, we know that this family of sets also corresponds exactly with
the set of pre-answers. Hence, the statement of the lemma follows.

G.1.5

Proof of Theorem 47

Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP Π ⊇ ΠS )
if the following criteria are met:
• Π is a linear GAP
• V C is applied a-priori
• agg is positive linear,
then value (defined as per Q and Π) is sub-modular.
In other words, for Vcond ≡ {v ′ |v ′ ∈ V and (g(v ′ ) : 1 ∧
577

V

pred∈ℓvert (v ′ )

pred(v ′ ) : 1 |=

V C[V /v ′ ])} and sets V1 ⊆ V2 ⊆ Vcond and v ∈ Vcond , v ∈
/ V1 ∪ V2 , the following
holds:
value(V1 ∪ {v}) − value(V1 ) ≥ value(V2 ∪ {v}) − value(V2 )
Proof. CLAIM 1: For some V′ , if Ai : µi ∈ T{Π ∪ {g(v′ ):1← | v′ ∈V′ } s.t. there is no
µ′i > µi where Ai : µ′i ∈ T{Π ∪ {g(v′ ):1← | v′ ∈V′ } then, there exists a polynomial of the
following form:
fi (X1 , . . . , X|V| ) = λ1 · X1 + . . . + λ|V| · X|V| + λ|V|+1
s.t. if each Xi where Vi ∈ V′ is set to 1 and each Xi where Vi ∈
/ V′ is set to 0, then
fi (X1 , . . . , X|V| ) = µi .
(Proof of claim 1): Consider all of the rules in {Π ∪ {g(v ′ ) : 1 ←. If Ai : µi ∈
T{Π ∪ {g(v′ ):1← | v′ ∈V′ } , then there must exist a rule that causes the annotation of Ai
to equal µi . As the annotation in all rules is a linear function, we can easily re-write
it in the above form, based on the presence of annotated atoms in the body formed
with the goal predicate.

CLAIM 2: For some V′ , if Ai : µi ∈ T{Π ∪ {g(v′ ):1← | v′ ∈V′ } ↑ j, s.t. there is no µ′i > µi
where Ai : µ′i ∈ T{Π ∪ {g(v ′ ) : 1 ← | v ′ ∈ V′ } ↑ j then, there exists a polynomial
of the following form:
fi (X1 , . . . , X|V| ) = λ1 · X1 + . . . + λ|V| · X|V| + λ|V|+1
s.t. if each Xi where Vi ∈ V′ is set to 1 and each Xi where Vi ∈
/ V′ is set to 0, then
fi (X1 , . . . , X|V| ) = µi .
578

(Proof of claim 2): We will show that if the statement of the claim is true for the
j − 1 application of T, then it is true for application j. The proof of the claim
relies on this subclaim along with claim 1. If the claim holds for application j − 1,
then for each annotated atom A′i : µ′i , there is an associated polynomial as per the
statement. Consider the rule that fires in the jth application of the operator that
causes rule Ai to be annotated with µi . We can re-write this as a polynomial of the
above form, simply by substituting the polynomial for each annotation associated
with A′i from the previous iteration. As all of the polynomials are being substituted
into variable positions of a polynomial, the result is still a polynomial, which can
easily be re-arranged to resemble that of the claim.

CLAIM 3: For some V′ , if Ai : µi ∈ lf p(T{Π ∪ {g(v′ ):1← | v′ ∈V′ } ), s.t. there is no µ′i > µi
where Ai : µ′i ∈ lf p(T{Π ∪ {g(v ′ ) : 1 ← | v ′ ∈ V′ }) then, there exists a polynomial
of the following form:
fi (X1 , . . . , X|V| ) = λ1 · X1 + . . . + λ|V| · X|V| + λ|V|+1
s.t. if each Xi where Vi ∈ V′ is set to 1 and each Xi where Vi ∈
/ V′ is set to 0, then
fi (X1 , . . . , X|V| ) = µi .
(Proof of claim 3): Follows directly from claims 1-2.

CLAIM 4: For some Vi ⊆ V, there exists a polynomial of the following form:
fi (X1 , . . . , X|V| ) = λ1 · X1 + . . . + λ|V| · X|V| + λ|V|+1
s.t. if each Xi where Vi ∈ V′ is set to 1 and each Xi where Vi ∈
/ V′ is set to 0, then
579

fi (X1 , . . . , X|V| ) = value(Vi ).
(Proof of claim 4): Consider all atoms formed with predicate goal in the lf p where
the annotation is maximum. By claim 3, each is associated with a polynomial. A
positive linear combination of all these polynomials is a polynomial of the form in
this claim, and is equivalent to value.

CLAIM 5: value(V1 ∪ {v}) − value(V1 ) ≥ value(V2 ∪ {v}) − value(V2 ).
(Proof of claim 5): By the definition of value, as V C is applied a-priori, we know
that value is defined on all subsets of Vcond .
We define the following polynomial functions, which are associated with value for the
various subsets of V in claim 5 (with some re-arrangement, Greek letters resemble
constants, X variables can be either 0 or 1 - signifying if the associated subscript is
includes in the associated set).
1. f1 (XV1 , X{v} , XV2 −V1 ) = α1 · XV1 + β1 · X{v} + γ1 · XV2 −V1 + λ1
value(V1 ∪ {v}) = f1 (1, 1, 0) = α1 + β1 + λ1
2. f2 (XV1 , X{v} , XV2 −V1 ) = α2 · XV1 + β2 · X{v} + γ2 · XV2 −V1 + λ2
value(V1 ) = f2 (1, 0, 0) = α2 + λ2
3. f3 (XV1 , X{v} , XV2 −V1 ) = α3 · XV1 + β3 · X{v} + γ3 · XV2 −V1 + λ3
value(V2 ∪ {v}) = f3 (1, 1, 1) = α3 + β3 + γ3 + λ3
4. f4 (XV1 , X{v} , XV2 −V1 ) = α4 · XV1 + β4 · X{v} + γ4 · XV2 −V1 + λ4
value(V2 ) = f4 (1, 0, 1) = α4 + γ4 + λ4

580

CLAIM 5.1: α4 + γ4 + λ4 ≥ α2 + γ3 + λ2
(Proof of claim 5.1): We note that the constants in the fi ’s defined earlier all correspond directly with constants seen in rules. Hence, as f4 (1, 0, 1) corresponds with
the maximum possible value for value(V2 ), there can be no constants other than
α4 , γ4 , λ4 that sum to a value greater than value(V2 ). The statement of claim 5.1
immediately follows.

CLAIM 5.2: α1 + β1 + λ1 ≥ α3 + β3 + λ3
(Proof of claim 5.2): Mirrors claim 5.1, (in this case, value(V1 ∪ {v}) is the maximum possible value of f1 (1, 1, 0)).

(Completion of claim 5 / theorem): Suppose, BWOC, claim 5 is not true. Then, it
must be the case that
value(V1 ∪ {v}) − value(V1 ) < value(V2 ∪ {v}) − value(V2 )
This would imply:
α1 + β1 + λ1 + α4 + γ4 + λ4 < α3 + β3 + γ3 + λ3 + α2 + λ2
By claim 5.2, we have the following:
α 4 + γ 4 + λ4 < γ 3 + α 2 + λ 2
Which contradicts claim 5.1. The statement of the theorem follows.

581

G.1.6

Proof of Theorem 48

Finding an answer to SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and
GAP Π ⊇ ΠS ) is NP-hard (even if Π is a linear GAP, V C = ∅, agg = SU M and
value is zero-starting).
Proof. The known NP-hard problem of max k-cover [46] as follows.
MAX K-COVER
INPUT: Set of elements, S and a family of subsets of S, H ≡ {H1 , . . . , Hmax }, and
positive integer K.
OUTPUT: ≤ K subsets from H s.t. the union of the subsets covers a maximal
number of elements in S.

We shall make the following assumptions of MAX-K-COVER
1. |H| > K
2. There is no H ∈ H s.t. H ≡ ∅
CONSTRUCTION: Given MAX K-COVER input S, H, K we create a SNOPquery as follows.
1. Set up social network S as follows:
(a) EP ≡ {edge}
(b) VP ≡ {vertex}
(c) For every element of H, and every element of S, we create an element of V .
We shall denote subsets of V , VS and VH as the vertices corresponding
582

with S and H respectively. For some s ∈ S, vs is the corresponding
vertex. For some H ∈ H, vH is the corresponding vertex. Note that set
V ≡ VS ∪ VH
(d) For each H ∈ H, if s ∈ H draw add edge (vH , vs ) to set E
(e) For each v ∈ V , ℓvert (v) = vertex
(f) For each (v, v ′ ) ∈ E, ℓedge (v, v ′ ) = edge
(g) For each (v, v ′ ) ∈ E, w(v, v ′ ) = 1
2. Set up program Π as follows:
(a) Embed S into Π.
(b) Add diffusion rule vertex(V ) : X ← vertex(V ′ ) : X ∧ edge(V ′ , V ) : 1 to
Π
3. Set up SNOP-query Q as follows:
(a) agg = SU M
(b) V C = true
(c) k = K (the K from SET COVER)
(d) g = vertex
Additionally, we will use the following notation:
1. V ′ is a pre-answer to the constructed query
2. value(V ′ ) is the value of the constructed query for pre-answer V ′
583

′
3. Vans
is an answer to the constructed query

CLAIM 1: The construction can be performed in PTIME.
Straightforward.

CALIM 2: Program Π is a linear GAP.
Follows directly form Definition 96.

′
CLAIM 3: An answer Vans
to the SNOP query cannot contain a vertex in vs ∈ VS

and a vertex in vH ∈ VH s.t. s ∈ H.
BWOC, an optimal solution could have an element vs as described in the claim. By
assumption 1, there are more than K elements in VH and all of them have an edge
to some element of VS by assumption 2. It is obvious that vs will be annotated with
′
a 1 in the fixed point, and that no elements of VH − Vans
will be annotated with 1
′
in the fixed point. Hence, we can pick any element of VH − Vans
and value will be

at least one greater than the “optimal” solution – hence a contradiction.

′
CLAIM 4: If an answer Vans
∩ VS 6≡ ∅, then we can construct an alternative optimal
′
solution such that Vans
∩ VS ≡ ∅.
′
As no element in Vans
∩ VS 6≡ ∅ has an outgoing neighbor, and by assumption 1,
′
′
we can be assured that |Vans
− VH | > |Vans
∩ VS |, we can replace the elements of
′
′
′
Vans
∩ VS in Vans
with elements from Vans
− VH and still be ensured of an optimal

solution.

584

CLAIM 5: Given a set H′ ⊆ H that ensures an optimal solution to MAX-K′
COVER, we can construct an optimal Vans
to the SNOP query.

CASE 1 (claim 5): |H′ | = K.
Let OP T be the number of elements of S covered in the optimal solution of MAXK-COVER. For each H ∈ H′ , we pick the corresponding element of VH . Obviously,
′
value(Vans
) = OP T + K. Suppose, we could pick a different element of V and get

a solution with a higher value. As no element of S has an outgoing edge, replacing
one of the elements from the constructed set with one of these will not ensure a
′
greater solution. If we could pick an element from VH − Vans
, then this would ob-

viously imply a solution to MAX-K-COVER s.t. more than OP T elements of S
are covered – clearly this is a contradiction as H′ is an optimal cover.

CASE 2 (claim 5): |H′ | < K.
Create H′′ with all of the elements of H′ and K − |H′ | elements of H − H′ . Clearly,
this is also an optimal solution to MAX-K-COVER (as cardinality is not optimized, just needs to be below K). We can now apply case 1 of this claim.

′
CLAIM 6: Given Vans
, we can constructively create a subset of H that, if picked,

ensures an optimal solution to MAX-K-COVER.

′
CASE 1 (claim 6): Vans
⊆ VH

585

′
′
Simply pick each H associated with each vH ∈ Vans
. Let OP T ′ = value(Vans
) note

that OP T ′ = K + SP READ where SP READ corresponds with the number of
1-annotated elements of VS in the fixed point. If there is a different subset of H that
can be picked, (i.e. a more optimal solution to MAX-K-COVER), then we can
create a solution to the SNOP query where some SP READ′ > SP READ elements
of VS become annotated with 1 in the fixed point. Clearly, this would imply a more
optimal solution to the SNOP query – a contradiction.

′
CASE 2 (claim 6): VS − Vans
6≡ ∅

From this solution, we can use claim 4 to create an optimal solution s.t. case 1
applies.

The proof of the theorem follows directly from claims 5-6.

G.1.7

Proof of Theorem 49

Finding an answer to a decision problem associated with SNOP query Q =
(agg, V C, k, g(V )) (w.r.t. SN S and GAP Π ⊇ ΠS ) where agg and the functions in
F are polynomially computable is in-NP.
Proof. We utilize the following decision problem:
Definition 117 (SNOP-DEC). An instance of the decision problem related to a
SNOP-query accepts the input for the query plus real number target. The decision
problem returns “yes” iff there exists pre-answer V ′ s.t. value(V ′ ) ≥ target and
586

“no” otherwise.
CLAIM 1: SNOP-DEC is NP-hard.
We do this by a reduction from SET COVER.

CONSTRUCTION: Given instance S, H, K of SET COVER, we create K instances
of SNOP-DEC, each identified with index i ∈ [1, K], that each use the same construction used to show the NP-hardness of a SNOP query with the following two
exceptions:
• Set k in SNOP-DEC to i
• Set target in SNOP-DEC to i + |S|
CLAIM 1.1: The construction can be performed in PTIME.
Straightforward. CLAIM 1.2: If there is a solution to the set cover problem, at least
one of the constructed instances of SNOP-DEC will return “yes.”
Suppose, that there is a solution to the set-cover problem, that causes the selection
of m elements of H (where m ≤ K). By the construction, there exists an instance of
SNOP-DEC such that target = m + |S| and k = m. We simply pick the k vertices
in VH corresponding with the covers, and by the construction, after running Π, all
of the vertices in VS will have an annotation to the vertex atoms formed by marked
of 1. Hence, the aggregate will be m + |S| - which is greater than target, so that
instance of SNOP-DEC returns “yes.”
CLAIM 1.3: If there is no solution to the set cover problem, all of the instances of
SNOP-DEC will return “no.”
587

Suppose there is no solution to SET COVER and one of the constructed instances
of SNOP-DEC returns “yes.” Then, for some i ∈ [1, K], there are i vertices that
can be picked to change the annotation of the vertex vertex atoms to ensure that
the aggregate is greater than or equal to i + |S|. As, at most, only i vertex atoms
can be picked, and only atoms in VS can change annotation due to Π, all i vertices
associated with the vertex atoms must be in VH to ensure that we have the most
possible vertex atoms formed with vertex that have a non-zero annotation. However, in order for all of the vertices in VS to have the annotations of the associated
vertex vertex atom increase to 1, there must be at least one incoming edge to each
element of VS from one of the i atoms from VH . By how S is constructed, this would
imply a set-cover of size i, which would be a contradiction.
PROOF OF CLAIM 1: Follows directly from claims 1.1-1.3.

CLAIM 2: SNOP-DEC is in-NP (with the conditions in the statement).
Suppose, we are given a set V ′ . We can easily verify this solution in PTIME as
follows: (i) verify V ′ is a valid pre-answer can easily be done in PTIME by checking
that |V ′ | ≤ k and that ∀v ′ ∈ V ′ , V C(v ′ ) is true. (ii) by the assumptions about agg
and the functions in F, we can compute value(V ′ ) in PTIME as well. the statement
follows.

588

G.1.8

Proof of Theorem 50

Answering a SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP
Π ⊇ ΠS ), cannot be approximated in PTIME within a ratio of

e−1
e

+ ǫ for some

ǫ > 0 (where e is the inverse of the natural log) unless P==NP – even if Π is a
linear GAP, V C = ∅, agg = SU M and value is zero-starting.
(That is, there is no polynomial-time algorithm that can approximate value
within a factor of about 0.63 under standard assumptions.)
Proof. Suppose, BWOC, there is an α-approximation algorithm for an SNOP query.
Hence, we can approximate value returned by SNOP within a factor of 1 − 1/e + ǫ
for some ǫ > 0. Using the MAX-K-COVER reduction in Theorem 48, for SNOP
′
answer Vans
, the cardinality of the covered elements of S in MAX-K-COVER is
′
value(Vans
) − K. Hence, this approximation algorithm would provide a solution to

MAX-K-COVER within a factor of 1 − 1/e + ǫ for some ǫ > 0. By Theorem
5.3 of [46], this would imply P==NP, which contradicts the statement of the
theorem.

G.1.9

Proof of Theorem 51

Counting the number of answers to SNOP query Q = (agg, V C, k, g(V )) (w.r.t.
SN S and GAP Π ⊇ ΠS ) is #P-complete.

Follows directly from Lemmas 32 and 33.

589

Lemma 32. The counting version of the SNOP query answering problem (we shall
call it #SNOP) is #P-hard.
Proof. We now define the known #P-Complete problem, MONSAT [145] and a variant of it used in this proof:
Counting K-Monotone CNF Sat. (#MONSAT)
INPUT: Set of clauses C, each with K disjuncted literals, no literals are negations,
L is the set of atoms.
OUTPUT: Number of subsets of L such that if the atoms in the subset are true, all
of the clauses in C are satisfied.

Counting K-Monotone CNF Sat. - Exact (#MONSAT-EQ)
INPUT: Set of clauses C, each with K disjuncted literals, no literals are negations,
L is the set of atoms and natural number m.
OUTPUT: Number of subsets of L - each with cardinality of exactly m - such that
if the atoms in the subset are true, all of the clauses in C are satisfied.

We now define the following problem used in the proof:
#SNOP-EQ
INPUT: Same as SNOP-DEC.
OUTPUT: Number of pre-answers V ′ that would causes a “yes” answer to SNOPDEC and |V ′ | = k.

590

CLAIM 1: #MONSAT≤p #MONSAT-EQ and #MONSAT-EQ is #P-hard Consider
the following construction (CONSTRUCTION 1):
Let L be the set of atoms associated with #MONSAT. Create |L| instances of
#MONSAT-EQ - each with a cardinality constraint (m) in [1, |L|], and the remainder
of the input the same as #MONSAT.
(Proof of claim 1): The sum of the solution to the |L| instances of #MONSAT-EQ
is equal to the solution to #MONSAT.
Every possible satisfying assignment counted as a solution to #MONSAT has a
unique cardinality associated with it, which is in [1, |L|]. The claim follows trivially
from this fact and construction 1 (which can be performed in PTIME).

CLAIM 2: #MONSAT-EQ≤p #SNOP-EQ and #SNOP-EQ is #P-hard
Consider the following construction (CONSTRUCTION 2):
Given #MONSAT-EQ input (C, K, L, m), we create an instance of #SNOP-EQ as
follows.
1. Set up social network S as follows:
(a) EP ≡ {edge}
(b) VP ≡ {vertex}
(c) For every element of C, and every element of L, we create an element of V .
We shall denote subsets of V , VC and VL as the vertices corresponding
with C and L respectively. For some a ∈ C, va is the corresponding
vertex. For some b ∈ L, vb is the corresponding vertex.
591

(d) For each a ∈ C, if b is in clause C, add edge (vb , va ) to set E
(e) For each v ∈ V , ℓvert (v) = vertex
(f) For each (v, v ′ ) ∈ E, ℓedge (v, v ′ ) = edge
(g) For each (v, v ′ ) ∈ E, w(v, v ′ ) = 1
2. Set up program Π as follows:
(a) Embed S into Π
(b) For each v ∈ V , add fact vertex(v) : 0 to Π
(c) Add diffusion rule vertex(v) : 1 ← vertex(v ′ ) : 1 ∧ edge(v ′ , v) : 1 to Π
3. Set up SNOP-query Q as follows:
(a) agg = SU M
(b) V C = ∅
(c) k = m (the m from #MONSAT-EQ)
(d) g = vertex
(e) target = |C| + k
CLAIM 2.1: Construction 2 can be performed in PTIME.
Straightforward.

CLAIM 2.2: If there is a solution to given an instance of MONSAT-EQ, then given
construction 2 as input, SNOP-EQ will return “yes”. For each a ∈ L in the solution to MONSAT-EQ, change the annotation of vertex(va ) to 1 in Πf acts . There are
592

m = k such vertices. By the construction, this will cause the |C| vertices of VC to
increase their annotation - resulting in an aggregate of |C| + k, causing SNOP-EQ
to return “yes”.

CLAIM 2.3: If, given construction 2 as input, SNOP-EQ returns “yes”, then a solution to given an instance of MONSAT-EQ such that k is the cardinality of the
solution.
We note that selecting any vertex in V ′ not in VL will result in an value(V ′ ) < |C|+k,
as fewer than |C| nodes will have their annotation increase after running Π. The
only way to achieve an value(V ′ ) = |C| + k is if there exists a set of k vertices in
VL such that there is an outgoing edge from at least one of the picked vertices to
each node in VC . This is only possible if there exists a solution to the MONSAT-EQ
problem.

CLAIM 2.4: There is a 1-1 correspondence between solution to MONSAT-EQ and
SNOP-EQ using construction 2.
As each literal in a MONSAT-EQ solution corresponds to exactly one vertex in a
SNOP-EQ, and by claims 2.2-2.3, the claim follows.

PROOF OF CLAIM 2: Follows directly from claims 2.1-2.4.

CLAIM 3: #SNOP-EQ≤p #SNOP, #SNOP is #P-hard
Consider the following construction (CONSTRUCTION 3):
593

Let k be the cardinality constraint associated with #SNOP-EQ. Create two instances of #SNOP, one with a cardinality constraint of k and one with the constraint
of k − 1, and the remainder of the input is the same as #SNOP-EQ.
PROOF OF CLAIM 3: First, note that construction 3 can be performed in PTIME.
We show that the solution to #SNOP with cardinality constraint k − 1 subtracted
from the solution to #SNOP with cardinality constraint k is the solution to #SNOPEQ. As the solution to #SNOP with cardinality constraint k − 1 is the number of
all V ′ ’s that are a solution with cardinality of k − 1 or less, and the solution to
#SNOP with cardinality constraint k is the number of all V ′ ’s that are a solution
with cardinality of k or less, the difference is the number of all V ′ ’s with a cardinality
of exactly k.

PROOF OF LEMMA: Follows directly from claims 3.
Lemma 33. If the aggregate function agg is polynomially computable and functions
in F are polynomially computable, then #SNOP is in-#P.
Proof. We use the two requirements for membership in-#P as presented in [87].
(i) Witnesses must be verifiable in PTIME (shown in the NP-Completness of a
SNOP-query).
′

(ii) The number of solutions to #SNOP is bounded by x′k - where k ′ is a constant.
We know that the number of solutions is bounded by
c · |V |k for some constant c.

594

P

i≤k

|V |
i



which is less than

G.1.10

Proof of Theorem 52

Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP Π ⊇ ΠS ),
finding

S

′ ∈ans(Q)
Vans

′
Vans
is NP-hard.

Proof. We shall refer to the problem of finding

S

′ ∈ans(Q)
Vans

′
Vans
as SNOP-ALL. We

show that SNOP-ALL is ≤p solving a SNOP-query.
Given set an instance of SNOP-ALL and vertex set V ∗ , |V ∗ | ≤ k let SNOPALL(V ∗ ) be the modification of of the instance of SNOP-ALL where the value k is
reduced by |V ∗ | and for each vj∗ ∈ V ∗ , the fact g(vi ) : 1 is added to Π.
Consider the following informal algorithm (FIND-SET) that takes an instance
of SNOP-ALL (Q) and some vertex set V ∗ , |V ∗ | ≤ k.
1. If |V ∗ | = k, return V ∗
2. Else, solve SNOP-ALL(V ∗ ), returning set V ′′ .
(a) If V ′′ − V ∗ ≡ ∅, return V ∗
(b) Else, pick v ∈ V ′′ − V ∗ and return FIND-SET(Q, V ∗ ∪ v)
Note, that the above algorithm can only iterate k times.
CLAIM 1: The V ∗ returned by FIND-SET is a valid solution to the SNOP-query
(with the same input for Q).
First, we number the elements in V ∗ as v1 , . . . , vsize - where v1 is picked as the first
element in the solution and vertex vi is added at the ith recursive call of FIND-SET.
We know that size ≤ k
BASE CASE: There is a set of vertices of size ≤ size that is a solution to the
595

SNOP-query s.t. vertex v1 is in that set - follows directly from the definition of
SNOP-ALL.
INDUCTIVE HYPOTHESIS: For some k ′ ≤ size, we assume that for vertices
v1 , . . . , vk′ −1 there is some set of vertices of size ≤ k that is a solution to the SNOPquery s.t. vertices v1 , . . . , vk′ −1 are in that set.
INDUCTIVE STEP: For some k ′ ≤ size, consider vertices v1 , . . . , vk′ . By the inductive hypothesis, vertices v1 , . . . , vk′ −1 are in a ≤ k-sized solution. By the construction, and the definition of SNOP-ALL, we know that vertex vk′ must also be
in that set as well.

CLAIM 2: Given some V ′ as a solution to the SNOP-query, the algorithm FIND-SET
can be run in such a way to return that set.
Number each vertex in V ′ as v1 , . . . , vsize . By the definition of SNOP-ALL, upon
the i’th call to FIND-SET, we are guaranteed that the vertices vi , . . . , vsize will be
in set V ′′ . Simply pick vertex vi follow the algorithm to the next recursive call, the
claim immediately follows.
PROOF OF PROPOSITION: Note the construction can be accomplished in PTIME.
The proposition follows directly from claims 1-2.

G.1.11

Proof of Theorem 53

Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP Π ⊇ ΠS ),
finding

S

′ ∈ans(Q)
Vans

′
Vans
reduces to |V | + 1 SNOP-queries.

596

Proof. We set up |V | SNOP-queries as follows:
• Let kall be the k value for the SNOP-ALL query and and for each SNOP-query i,
let ki be the k for that query. For each query i, set ki = kall − 1.
• Number each element of vi ∈ V such that g(vi ) and V C(vi ) are true. For the ith
SNOP-query, let vi be the corresponding element of V
• Let Πi refer to the GAP associated with the ith SNOP-query and Πall be the
program for SNOP-ALL. For each program Πi , add fact g(vi ) : 1
• For each SNOP-query i, the remainder of the input is the same as for SNOP-ALL.
After the construction, do the following:
1. We shall refer to a SNOP-query that has the same input as SNOP-ALL as the
′ (pri)
′ (pri)
be an answer to this query and value(Vans
)
“primary query.” Let Vans

be the associated value.
′ (i)
′ (i)
be an answer and value(Vans
) be the
2. For each SNOP-query i, let Vans

associated value.
3. Let V ′′ , the solution to SNOP-ALL be initialized as ∅.
′ (i)
′ (pri)
4. For each SNOP-query i, if value(Vans
) = value(Vans
), then add vertex vi

to V ′′ .
′ (i)
′ (pri)
CLAIM 1: If for the ith SNOP-query, if value(Vans
) = value(Vans
), then vi

must be in the solution to SNOP-ALL.
597

′ (i)
′ (pri)
Suppose, by way of contradiction, that for the ith query, value(Vans
) = value(Vans
),

but vi is not in the solution to SNOP-ALL. Then, there is no V ′ of size ≤ k s.t.
vi ∈ V ′ and V ′ is an answer to a the primary SNOP-query. However, this is a contradiction, as given vi and the vertices returned by the ith query, we are guaranteed
this to be a valid answer to the primary query.
CLAIM 2: For each vi in a solution to SNOP-ALL, the ith SNOP query returns a
′ (i)
′ (pri)
value s.t. value(Vans
) = value(Vans
).

Suppose, by way of contradiction, that there is some vi in the solution to SNOPALL s.t. the ith query returns a value that is not equal to the value returned by
the primary. However, by the definition of SNOP-ALL, this is not possible, hence a
contradiction.
PROOF OF PROPOSITION: Note the construction can be accomplished in PTIME.
The proposition follows directly from claims 1-2.

G.2

Proofs for Section 8.5

G.2.1

Proof of Proposition 72

Suppose Π is any GAP. Then:
1. SΠ is monotonic.
2. SΠ has a least fixpoint lf p(SΠ ) and lf p(TΠ ) = grd(lf p(SΠ )).
That is, lf p(SΠ ) is a non-ground representation of the (ground) least fixpoint
operator TΠ .
598

Proof. Part 1 follows directly from the definition – for a given atom A and interpretation I, S(I)(A) ≥ I(A).
Part 2 follows directly from the definitions of S and T.

G.2.2

Proof of Theorem 54

Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP Π ⊇ ΠS ),
if agg is monotonic then:
• There is an answer to the SNOP-query Q w.r.t. the GAP Π iff SNOPMon(Π, agg, V C, k, g(V )) does not return NIL.
• If SNOP-Mon(Π, agg, V C, k, g(V )) returns any result other than NIL, then
that result is an answer to the SNOP-query Q w.r.t. the GAP Π.
Proof. Part 1 (⇐): Suppose there is an answer to the query and SNOP-Mon returns
NIL. Then there is some set of vertices, sol of cardinality ≤ k, s.t. Π ∪

S

v∈sol

g(v) :

1 |= V C. However, such a set would obviously have been added as a tuple into T odo
at step 2 or step 4(c)iB. Hence, a contradiction.
Part 1 (⇒): Suppose there is no answer to the query and SNOP-Mon returns NIL.
Then, there is no set of vertices, sol of cardinality ≤ k, s.t. Π∪

S

v∈sol

g(v) : 1 |= V C.

SNOP-Mon performs such a check at line 4b. Hence, a contradiction.

Part 2: Suppose, BWOC, there exists a set of vertices that is a solution, sol, of
cardinality ≤ k, s.t.
value(Π∪

S

v∈sol

S

v∈sol

g(v) : 1 is not what is returned by SNOP-Mon and

g(v) : 1 is greater than bestV al. We note that SNOP-Mon considers

599

most sets of vertices of cardinality ≤ k. Further, the monotonicity of agg and
line 4(c)i tell us that the only solutions not considered are ones guaranteed to have
a value less than bestV al – hence, a contradiction.

G.2.3

Proof of Proposition 73

Given SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP Π ⊇ ΠS ),
the complexity of GREEDY-SNOP is O(k · |V| · F (|V|)) where F (|V|) is the time
complexity to compute value(V ′ ) for some set V ′ ⊆ V of size k.
Proof. The outer loop at line 2 iterates k times, the inner loop at line 2b iterates
O(|V|) times, and at each inner loop, at line 2(b)i, the function value is computed
with costs F (|V|). The statement follows.

G.2.4

Proof of Theorem 55

If SNOP query Q = (agg, V C, k, g(V )) (w.r.t. SN S and GAP Π ⊇ ΠS ) meets
the following criteria:
• Π is a linear GAP
• V C is applied a-priori
• agg is positive linear
• value is zero-starting.
e
Then GREEDY-SNOP is an ( e−1
)-approximation algorithm for the query.

600

Proof. The results of [127] state that a greedy algorithm for a non-decreasing, submodularity function F s.t. F (∅) = 0 is a

e
e−1

approximation algorithm for the

associated maximization problem. In Section 8.3, we show that a query meeting the
criteria of the statement satisfies the requirements. The statement follows.

G.2.5

Proof of Proposition 74

For all ground atoms A and vertices v, INCi−1 (v)(A) ≥ INCi (v)(A).
(alg)

(alg)

Proof. Consider the following values: Ii−1 (v)(A), Ii−2 (A), Ii (v)(A), Ii−1 (A). These
correspond with the following sets of vertices, respectively: SOLi−2 ∪{v}, SOLi−2 , SOLi−2 ∪
{v}∪(SOLi−1 −SOLi−2 ), SOLi−2 ∪(SOLi−1 −SOLi−2 ). Hence, by claim 3 of Theo(alg)

(alg)

rem 47, we can associate the values Ii−1 (v)(A), Ii−2 (A), Ii (v)(A), Ii−1 (A) with linear functions with three variables corresponding to the sets SOLi−2 , {v}, (SOLi−1 −
SOLi−2 ). If the variables corresponding to the set of vertices are set to 1 and the rest
zero, then the function corresponds to the value assigned to A by that interpretation.
Consider the following four functions:
f1 (X1 , X2 , X3 ) = a1 · X1 + b1 · X2 + c1 · X3 + d1
f2 (X1 , X2 , X3 ) = a2 · X1 + b2 · X2 + c2 · X3 + d2
f3 (X1 , X2 , X3 ) = a3 · X1 + b3 · X2 + c3 · X3 + d3
f4 (X1 , X2 , X3 ) = a4 · X1 + b4 · X2 + c4 · X3 + d4

601

Where X1 , X2 , X3 correspond to SOLi−2 , {v}, (SOLi−1 − SOLi−2 ) respectively.
f1 (1, 1, 0) = Ii−1 (v)(A) = a1 + b1 + d1
(alg)

f2 (1, 0, 0)

= Ii−2 (A)

= a2 + d 2

f3 (1, 1, 1)

= Ii (v)(A)

= a3 + b 3 + c 3 + d 3

f4 (1, 0, 1)

= Ii−1 (A)

(alg)

= a4 + c 4 + d 4

Note 1: We note, using the same techniques as claims as 5.1-5.2 of Theorem 47,
that there is no i1 , i2 , i3 not equal to 1 where ai1 + bi2 + di3 > a1 + b1 + d1 and no
i1 , i2 , i3 not equal to 4 where ai1 + ci2 + di3 > a4 + c4 + d4 .

So, suppose, BWOC, the statement of the proposition does not hold. Then,
we have:
a1 + b1 + d1 − a2 − d2 < a3 + b3 + c3 + d3 − a4 − c4 − d4
a1 + b 1 + d 1 + a4 + c 4 + d 4 < a 3 + b 3 + c 3 + d 3 + a2 + d 2
And by Note 1,
a1 + b 1 + d 1 > b 3 + a2 + d 2
Which, subtracting from both sides, gives us:
a4 + c4 + d4 < a3 + c3 + d3
Which contradicts Note 1. The statement of the proposition follows.
602

G.2.6

Proof of Lemma 25

For all programs Π and any atom A,
lf p(SP ROG(Π) )(A) = lf p(SΠ )(A)
Proof. Follows directly from Definition 105.

G.2.7

Proof of Lemma 26

If Π3 ≡ Π1 ∪ Π2 , then for any atom A,
lf p(SΠ3 )(A) = lf p(SP ROG(Π1 )∪P ROG(Π2 ) )(A)
Proof. CLAIM 1: lf p(SΠ3 )(A) ≥ lf p(SP ROG(Π1 )∪P ROG(Π2 ) )(A)
By the monotonicity of S, we know that for all A, lf p(SΠ3 )(A) ≥ lf p(SΠ1 )(A) and
lf p(SΠ3 )(A) ≥ lf p(SΠ2 )(A). Further, as Π1 , Π2 ⊆ Π3 , it follows that
P ROG(Π1 ), P ROG(Π2 ) ⊆ P ROG(Π3 ), meaning that P ROG(Π1 ) ∪ P ROG(Π2 ) ⊆
P ROG(Π3 ).

By the monotonicity of S, it follows that for any atom A, lf p(SΠ3 )(A) ≥ lf p(SP ROG(Π1 )∪P ROG(Π2 ) )(A

CLAIM 2: lf p(SΠ3 )(A) ≤ lf p(SP ROG(Π1 )∪P ROG(Π2 ) )(A)
Going the other direction, by Definition 105, Π1 ⊆ P ROG(Π1 ) and Π2 ⊆ P ROG(Π2 ).
Therefore, for all A, lf p(SΠ1 ∪Π2 )(A) ≤ lf p(SP ROG(Π1 )∪P ROG(Π2 ) )(A), which means
that lf p(SΠ3 )(A) ≤ lf p(SP ROG(Π1 )∪P ROG(Π2 ) )(A).
The statement of the lemma follows directly from claims 1-2.

603

G.2.8

Proof of Proposition 75

If Π3 ≡ Π1 ∪ Π2 , then for any atom A,
lf p(SΠ3 )(A) = lf p(SP ROG(P ROG(Π1 )∪P ROG(Π2 )) )(A)
Proof. By Lemma 25,
lf p(SP ROG(P ROG(Π1 )∪P ROG(Π2 )) )(A) = lf p(SP ROG(Π1 )∪P ROG(Π2 ) )(A)
By Lemma 26, the statement of the proposition follows.

G.2.9

Proof of Proposition 76
(opt)

inci

(opt)

≤ inci−1 .

Proof. This proposition is equivalent to the statement for all V′ ⊆ V and all v, v ′ ∈
/
V′ , then
value(V′ ∪ {v, v ′ }) − value(V′ ∪ {v ′ }) ≤ value(V′ ∪ {v}) − value(V′ )
Where v is the vertex added by the greedy algorithm at iteration i − 1 and v ′ is the
vertex added by the greedy algorithm at iteration i. Obviously, as V′ ∪ {v} ⊇ V′ ,
this is a special case of submoduarity, which is proved for this special case of queries
in Theorem 47.

G.2.10

Proof of Corollary 14

inci (v) ≤ inci−1 (v).

604

Proof. This proposition is equivalent to the statement for all V′ ⊆ V and all v, v ′ ∈
/
V′ , then
value(V′ ∪ {v, v ′ }) − value(V′ ∪ {v ′ }) ≤ value(V′ ∪ {v}) − value(V′ )
Where v ′ is the vertex added at iteration i − 1. The statement of the corollary holds
as a result of Proposition 76.

G.2.11

Proof of Proposition 77

For j ≤ i,




′

inci (v) ≤ agg {min 1, INCj (v)(g(v )) +

(alg)
Ii−1 (g(v ′ ))



−

(alg)
Ii−1 ((g(v ′ )))|v ′


∈ V}

Proof. Follows directly from Observation 1 and Proposition 74.

G.2.12

Proof of Theorem 57
′

(ǫ)

If the nodes in GSi (cand(ǫ) i ) corresponding with elements of cand(ǫ) i are an
(ǫ)

independent set of GSi (cand(ǫ) i ), then the greedy algorithm can select all vertices
′

in cand(ǫ) i and still obtain a solution within

eǫ −1
eǫ

of optimal.

Proof. By the definition of an independent set and vertex spread, for any v, v ′ ∈
′

(ǫ)

(ǫ)

cand(ǫ) i , we know that spreadi (v) ∩ spreadi (v ′ ) ≡ ∅ as there is no edge between
them in the spread-graph. Hence, if v is selected on iteration i, we know we can
(ǫ)

(ǫ)

(ǫ)

(ǫ)

select v ′ on iteration i + 1 as inci+1 (v ′ ) ≥ inci (v ′ ) as spreadi (v) ∩ spreadi (v ′ ) ≡ ∅.
′

We also know, on iteration i + 1, the set cand(ǫ) i − {v, v ′ } is an independent set of
′

the spread graph of cand(ǫ) i+1 , so we can select every other element of cand(ǫ) i as
well.
605

G.2.13

Proof of Proposition 78

The complexity of GREEDY-SNOP2 is O(k · |V| · F (|V|)) where F (|V|) is the
time complexity to compute value(V ′ ) for some set V ′ ⊆ V of size k.
Proof. There are two main operations that incur a cost additional to GREEDY-SNOP
(see Proposition 73, however they are both dominated by other operations.
1. At each iteration of the loop at line 4, inc(up) (v) is computed for each vertex,
giving an upper bound of the incremental increase for the iteration. There are
O(|V|) of these operations and each operations costs less than the computation
of the fixed point, so they are dominated by line 4e.
2. After the completion of the inner loop at line 4e, the algorithm may create
a spread graph and find an independent set. Under the assumption that
GREEDY-INDEP-SET or a similar algorithm is used, this operation is also
dominated by the inner loop at line 4e.

G.2.14

Proof of Proposition 79

Given a SNOP-query meeting the following criteria:
• Π is a linear GAP
• V C is applied a-priori
• agg is positive linear
606

• value is zero-starting
Then GREEDY-SNOP2 is an

eǫ
-approximation
eǫ −1

algorithm for the query.

Proof. Below we note the main differences between GEEDY-SNOP and GREEDYSNOP2 as show how they still allow the approximation guarantee of the statement:
1. The least fixed point is computed using saved logic programs that capture
previously computed annotations. By Proposition 75, this has no effect on the
approximation ratio.
2. Ignoring vertices whose associated upper bound on the incremental increase
is below this quantity for vertices already considered does not affect approximation ratio by Corollary 14. Further, this upper bound on the incremental
increase associated with a vertex is correct as per Proposition 77.
3. Picking a vertex whose associated incremental increase is within ǫ of optimal
give the approximation ratio of the statement by Theorem 56 and the upper
bound used to specify this is correct by Observation 2
4. Selecting multiple vertices that comprise an independent set of the spread
graph of all vertices whose incremental increase is within ǫ of optimal allows
for the approximation guarantee of the statement by Theorem 57.

607

RETURN-SET(G = (V, E), V ′ ⊆ V, v ∈ V ) returns V ′′ ⊂ V
1. V ′′ = V ′ ∪ {v}
2. For all v ′ ∈ V s.t. (v, v ′ ) ∈ E:
(a) If v ′ ∈
/ V ′ , do the following:
i. Set V ∗ = RETURN-SET(G, v ′ , V ′′ )
ii. V ′′ = V ′′ ∪ V ∗
3. Return V ′′

FIND-ALL-DNS-SETS(G = (V, E)) returns V1 , . . . , Vn ⊆ V
1. n = 0, Vrem = V
2. While Vrem 6≡ ∅
(a) n + +, Vn = ∅
(b) Pick a vertex v ∈ Vrem .
(c) Vn = RETURN-SET(G, ∅, v)
(d) Vrem = Vrem − Vn
3. Return V1 , . . . , Vn

608

G.2.15

Algorithm for Finding Disjoint Node Sets

G.2.16

Proof of Proposition 80

Given a SNOP-query meeting the following criteria:
• Π is a linear GAP
• V C is applied a-priori
• agg is positive linear
• value is zero-starting
Then GREEDY-SNOP-DIV is an

eǫ
-approximation
eǫ −1

algorithm for the query.

Proof. We prove the statement by showing that for any instance of GREEDYSNOP-DIV, the solution returned is the same as that returned by an instance of
GREEDY-SNOP2 – thus assuring the approximation guarantee. In this proof we
shall use GREEDY-SNOP2i to refer to an instance of GREEDY-SNOP2 that considers vertices only in some DN Si , as called by GREEDY-SNOP-DIV. We shall use
GREEDY-SNOP2all to refer to an instance of GREEDY-SNOP2 on the same input as
GREEDY-SNOP-DIV.
CLAIM 1: If the first vertex (vertex v) picked by GREEDY-SNOP2i is also picked
by GREEDY-SNOP2all , then the incremental increase for that vertex is the same for
both algorithms.
We note that vertex v is independent from any vertex v ′ ∈
/ DN Si , so by the proof

609

of Theorem 57, the statement of the claim follows.

CLAIM 2: If vertex vj is picked by GREEDY-SNOP2i at some iteration j, then it
is picked by GREEDY-SNOP2all only if GREEDY-SNOP2all picks all other vertices
selected by GREEDY-SNOP2i before iteration j.
We show this by induction on j.
BASE CASE: j = 2
Consider v1 , v2 . Note that on the first iteration of GREEDY-SNOP2i , the algorithm
found that the incremental increase of v1 is more “optimal” than v2 . Hence, by
claim 1, this vertex would also be picked by GREEDY-SNOP2all .
INDUCTIVE HYPOTHESIS:
If GREEDY-SNOP2all picks vj , it also selects vertices v1 , . . . , vj−2 picked by GREEDY-SNOP2i
on iterations 1, . . . , j − 2.
INDUCTIVE STEP:
If GREEDY-SNOP2all , then by the inductive hypothesis, it selects v1 , . . . , vj−2 . Suppose, BWOC, it picks vertex vj before vj−1 . However, as GREEDY-SNOP2i picks
vertex vj−1 first, we know it is “more optimal” than vj on GREEDY-SNOP2i . As
the only vertices that picked GREEDY-SNOP2all which are not independent were the
same ones picked by GREEDY-SNOP2i , we know that GREEDY-SNOP2all will also
find vj−1 “more optimal” than vj – hence a contradiction.

CLAIM 3: Any vertex picked by GREEDY-SNOP2all contributes the same incremental increase as if it were picked by GREEDY-SNOP2i .
610

Follows from the fact that vertices in each instance are independent from each other
as well as claims 1-2.

Proof of Proposition: Follows directly from claims 1-3.

611

Bibliography
[1] N. Agmon, S. Kraus, and G.A. Kaminka. Multi-robot perimeter patrol in
adversarial settings. In Proc. IEEE Int. Conf. on Robotics and Automation
(ICRA-2008), pages 2339–2345, 2008.
[2] N. Agmon, S. Kraus, G.A. Kaminka, and V. Sadov. Adversarial uncertainty
in multi-robot patrol. In Proc. 21st Int. Joint Conf. on Artificial Intelligence
(IJCAI-2009), pages 1811–1817, 2009.
[3] James F. Allen and George Ferguson. Actions and events in interval temporal
logic. J. of Logic and Computation, 4:531–579, 1994.
[4] Ethem Alpaydin. Introduction to Machine Learning. MIT Press, 2 edition,
2010.
[5] Roy M. Anderson and Robert M. May. Population biology of infectious diseases: Part i. Nature, 280(5721):361, 1979.
[6] T. Antal, S. Redner, and V. Sood. Evolutionary dynamics on degreeheterogeneous graphs. Physical Review Letters, 96(18):188104, 2006.
[7] Shyamanta M. Hazarika Anthony G. Cohn. Qualitative spatial representation
and reasoning: An overview. volume 46, pages 1–29, 2001.
[8] K. Apt. Principles of constraint programming. Cambridge University Press,
2003.
[9] Sinan Aral, Lev Muchnik, and Arun Sundararajan. Distinguishing influencebased contagion from homophily-driven diffusion in dynamic networks. Proceedings of the National Academy of Sciences, 106(51):21544–21549, December
2009.
[10] V Asal, J Carter, and J Wilkenfeld. Ethnopolitical violence and terrorism in
the middle east. In J Hewitt, J Wilkenfeld, and T Gurr, editors, Peace and
Conflict 2008. Paradigm, 2008.
[11] Yossi Azar and Iftah Gamzu. Efficient submodular function maximization under linear packing constraints. (submitted, preprint avaialbe from
http://www.cs.tau.ac.il/ iftgam/papers/SubmodularPacking.pdf ), 2010.

612

[12] Adnan Aziz, Vigyan Singhal, Felice Balarin, Robert K. Brayton, and Alberto L. Sangiovanni-vincentelli. It usually works: The temporal logic of
stochastic systems. pages 155–165. Springer, 1995.
[13] C. Baral, N. Tran, and L. Tuan. Reasoning about actions in a probabilistic
setting. In Proc. AAAI 2002, pages 507–512, 2002.
[14] Sugato Basu, Ian Davidson, and Kiri Wagstaff. Constrained Clustering: Advances in Algorithms, Theory, and Applications. Chapman & Hall/CRC, 2008.
[15] Paul Brantingham and Patricia Brantingham. Crime Pattern Theory. In
Richard Wortley and Lorraine Mazerolle, editors, Enviromental Criminology
and Crime Analysis, pages 78–93. 2008.
[16] Herv Brnnimann and Michael T. Goodrich. Almost optimal set covers in finite
vc-dimension. Discrete Comput. Geom, 14:293–302, 1995.
[17] Matthias Broecheler, Paulo Shakarian, and V.S. Subrahmanian. A scalable
framework for modeling competitive diffusion in social networks. Social Computing / IEEE International Conference on Privacy, Security, Risk and Trust,
0:295–302, 2010.
[18] Matthias Broecheler, Gerardo I. Simari, and V. S. Subrahmanian. Using histograms to better answer queries to probabilistic logic programs. In ICLP
’09: Proceedings of the 25th International Conference on Logic Programming,
pages 40–54, Berlin, Heidelberg, 2009. Springer-Verlag.
[19] Tom Bylander, Dean Allemang, Michael C. Tanner, and John R. Josephson.
The Computational Complexity of Abduction, 1991.
[20] Meeyoung Cha, Alan Mislove, Ben Adams, and Krishna P. Gummadi. Characterizing social cascades in flickr. In WOSP ’08: Proceedings of the first
workshop on Online social networks, pages 13–18, New York, NY, USA, 2008.
ACM.
[21] Meeyoung Cha, Alan Mislove, and Krishna P. Gummadi. A Measurementdriven Analysis of Information Propagation in the Flickr Social Network.
In In Proceedings of the 18th International World Wide Web Conference
(WWW’09), Madrid, Spain, April 2009.
[22] A. Charnes and W. Cooper. Programming with linear fractional functionals.
Naval Research Logistics Quarterly, 9(3):163–297, 1962.
[23] Wei Chen, Chi Wang, and Yajun Wang. Scalable influence maximization for
prevalent viral marketing in large-scale social networks. In Proceedings of
the 16th ACM SIGKDD international conference on Knowledge discovery and
data mining, KDD ’10, pages 1029–1038, New York, NY, USA, 2010. ACM.
[24] Vaek Chvatal. Linear Programming. W.H.Freeman, New York, 1983.
613

[25] R. Cleaveland, P. Iyer, and M. Narasimha. Probabilistic Temporal Logics
via the Modal Mu-Calculus. Theoretical Computer Science, 342(2-3):316–350,
2005.
[26] Luca Console, Luigi Portinale, and Daniele Theseider Dupré. Focussing Abductive Diagnosis. AI Commun., 4(2), 1991.
[27] Luca Console, Maria Luisa Sapino, and Daniele Theseider Dupré. The Role
of Abduction in Database View Updating. Journal of Intelligent Information
Systems, 4(3):261, 1995.
[28] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. Introduction to
Algorithms. MIT Press, second edition, 2001.
[29] Robin Cowan and Nicolas Jonard. Network structure and the diffusion of
knowledge. Journal of Economic Dynamics and Control, 28(8):1557 – 1575,
2004.
[30] J. Lang D. Dubois and H. Prade. Timed possibilistic logic. Fundamenta
Informaticae, XV:211–234, 1991.
[31] C. Damasio, L. Pereira, and T. Swift. Coherent well-founded annotated logic
programs. In Proc. Intl. Conf. on Logic Programming and Non-Monotonic
Reasoning, pages 262–276. Springer Lecture Notes in Computer Science Vol.
1730, 1999.
[32] Ian Davidson and S. S. Ravi. Clustering with constraints: Feasibility issues
and the k-means algorithm. In SDM, 2005.
[33] Munmun De Choudhury, Hari Sundaram, Ajita John, and Dorée Duncan Seligmann. Can blog communication dynamics be correlated with stock market
activity? In HT ’08: Proceedings of the nineteenth ACM conference on Hypertext and hypermedia, pages 55–60, New York, NY, USA, 2008. ACM.
[34] Alex Dekhtyar, Michael I. Dekhtyar, and V. S. Subrahmanian. Temporal
probabilistic logic programs. In ICLP 1999, pages 109–123, Cambridge, MA,
USA, 1999. The MIT Press.
[35] J.P. Dickerson, G.I. Simari, V.S. Subrahmanian, and Sarit Kraus. A GraphTheoretic Approach to Protect Static and Moving Targets from Adversaries.
In Proc. 9th Int. Conf. on Autonomous Agents and Multiagent Systems
(AAMAS-2010), pages 299–306, 2010.
[36] Jürgen Dix, Sarit Kraus, and V. S. Subrahmanian. Heterogeneous temporal
probabilistic agents. ACM TOCL, 7(1):151–198, 2006.
[37] Silvio do Lago Pereira and Leliane Nunes de Barros. Planning with abduction:
A logical framework to explore extensions to classical planning. In Lecture
Notes in Computer Science Advances in Artificial Intelligence SBIA, 2004.
614

[38] Martin Dyer, Leslie A Goldberg, Catherine Greenhill, and Mark Jerrum. On
the relative complexity of approximate counting problems. Technical report,
Coventry, UK, UK, 2000.
[39] T. Eiter, J. Lu, and V.S. Subrahmanian. Computing non-ground representations of stable models. In Proc. Intl. Conf. on Logic Programming and NonMonotonic Reasoning, pages 198–217. Springer Lecture Notes in Computer
Science Vol. 1265, 1997.
[40] T Eiter, V.S. Subrahmanian, and G. Pick. Heterogeneous Active Agents, I:
Semantics. Artificial Intelligence Journal, 108(1-2):179–255, 1999.
[41] Thomas Eiter and Georg Gottlob. The complexity of logic-based abduction.
J. ACM, 42(1):3–42, 1995.
[42] E. A Emerson and Joseph Y. Halpern. “sometimes” and “not never” revisited:
on branching versus linear time. Technical report, Austin, TX, USA, 1984.
[43] Ronald Fagin and Joseph Y. Halpern. Reasoning about knowledge and probability. Journal of the ACM, 41:340–367, 1994.
[44] Ronald Fagin, Joseph Y. Halpern, and Nimrod Megiddo. A logic for reasoning
about probabilities. Information and Computation, 87:78–128, 1990.
[45] H. Cruz F.C. Coelho, C. Codeco. Epigrass: A tool to study disease spread in
complex networks. Source Code for Biology and Medicin, 3(3), 2008.
[46] Uriel Feige. A threshold of ln n for approximating set cover.
45(4):634–652, 1998.

J. ACM,

[47] Uriel Feige, Vahab S. Mirrokni, and Jan Vondrak. Maximizing non-monotone
submodular functions. In FOCS ’07: Proceedings of the 48th Annual IEEE
Symposium on Foundations of Computer Science, pages 461–471, Washington,
DC, USA, 2007. IEEE Computer Society.
[48] Massimo Franceschetti, Matthew Cook, and Jehoshua Bruck. A geometric
theorem for network design. IEEE Transactions on Computers, 53(4):483–
489, 2004.
[49] Michael L. Fredman and Robert E. Tarjan. Fibonacci heaps and their uses
in improved network optimization algorithms. J. ACM, 34(3):596–615, July
1987.
[50] David Freedman, Roger Purves, and Robert Pisani. Statistics. W.W. Norton
and Co., 4 edition, 2007.
[51] Thom Frühwirth. Annotated constraint logic programming applied to temporal reasoning. In PLILP: Programming Language Implementation and Logic
Programming, Madrid, 1994. Springer.
615

[52] Bin Fu, Zhixiang Chen, and Mahdi Abdelguerfi. An almost linear time 2.8334approximation algorithm for the disc covering problem. In AAIM ’07: Proceedings of the 3rd international conference on Algorithmic Aspects in Information
and Management, pages 317–326, Berlin, Heidelberg, 2007. Springer-Verlag.
[53] I. Fujiwara, Y. Hirose, and M. Shintani. Can News be a Major Source of
Fluctuation: A Bayesian DGSE Approach, volume Discussion Paper Nr. 2008E-16. Institute for Monetary and Economic Studies, Bank of Japan, 2008.
[54] Michael R. Garey and David S. Johnson. Computers and Intractability; A
Guide to the Theory of NP-Completeness. W. H. Freeman & Co., New York,
NY, USA, 1979.
[55] Els Gijsbrechts, Katia Campo, and Tom Goossens. The impact of store flyers
on store traffic and store sales: a geo-marketing approach. Journal of Retailing,
79(1):1 – 16, 2003.
[56] Rob J. Van Glabbeek, Scott A. Smolka, and Bernhard Steffen. Reactive,
generative, and stratified models of probabilistic processes. Information and
Computation, 121:130–141, 1995.
[57] Jack A. Goldstone, Robert Bates, Ted Robert Gurr, Michael Lustik, Monty G.
Marshall, Jay Ulfelder, and Mark Woodward. A global forecasting model of
political instability. In Proc. Annual Meeting of the American Political Science
Association, 2005.
[58] Teofilo F. Gonzalez. Covering a set of points in multidimensional space. Inf.
Process. Lett., 40(4):181–188, 1991.
[59] Georg Gottlob, Sherry Marcus, Anil Nerode, Gernot Salzer, and V. S. Subrahmanian. A non-ground realization of the stable and well-founded semantics.
Theor. Comput. Sci., 166(1-2):221–262, 1996.
[60] P.R. Goundan and A.S. Schultz. Revisiting the greedy approach to submodular set function maximization. Technical report, Massachusetts Institute of
Technology, 2007.
[61] Mark Granovetter. Threshold models of collective behavior. The American
Journal of Sociology, 83(6):1420–1443, 1978.
[62] P. Haddawy. Representing plans under uncertainty: A logic of time, chance
and action. PhD Thesis, Univ. of Illinois, 1991.
[63] J. Halpern and M. Tuttle. Knowledge, probability, and adversaries. In IBM
Thomas J. Watson Research Center Tech Report, 1992.
[64] H. Hansson and B. Jonsson. A logic for reasoning about time and probability.
Formal Aspects of Computing, 6:512–535, 1994.
616

[65] Hans Hansson and Bengt Jonsson. A logic for reasoning about time and
reliability. Formal Aspects of Computing, 6:102–111, 1994.
[66] S. Hart and M. Sharir. Probabilistic propositional temporal logic. Information
and Control, 70:97–155, 1986.
[67] Herbert W. Hethcote. Qualitative analyses of communicable disease models.
Mathematical Biosciences, 28(3-4):335 – 356, 1976.
[68] Dorit S. Hochbaum. Approximation Algorithms for the Set Covering and
Vertex Cover Problems. SIAM Journal on Computing, 11(3):555–556, 1982.
[69] Dorit S. Hochbaum. Approximation Algorithms for NP-Complete Problems.
PWS Publishing Co., 1997.
[70] Dorit S. Hochbaum and Wolfgang Maass. Approximation schemes for covering
and packing problems in image processing and vlsi. J. ACM, 32:130–136, 1985.
[71] Harry B. Hunt, III, Madhav V. Marathe, Venkatesh Radhakrishnan, and
Richard E. Stearns. The complexity of planar counting problems. SIAM
J. Comput., 27(4):1142–1167, 1998.
[72] ISW. Map of Special Groups Activity in Iraq, Institute for the Study of War.
2008.
[73] M. Jackson and L. Yariv. Diffusion on social networks. In Economie Publique,
volume 16, pages 69–82, 2005.
[74] Robert Jeansoulin, Odile Papini, Henri Prade, and Steven Schockaert. In
Robert Jeansoulin, Odile Papini, Henri Prade, and Steven Schockaert, editors,
Methods for Handling Imperfect Spatial Information, volume 256 of Studies in
Fuzziness and Soft Computing. Springer Berlin / Heidelberg, 2010.
[75] Lujun Jia, Rajmohan Rajaraman, and Torsten Suel. An efficient distributed
algorithm for constructing small dominating sets. Distrib. Comput., 15(4):193–
205, 2002.
[76] D.S. Johnson. The np-completeness column: An ongoing guide. Journal of
Algorithms, 3(2):182–195, 1982.
[77] A. C. Kakas and P. Mancarella. Database updates through abduction. In
VLDB90, 1990.
[78] K. Kanazawa. A logic and time nets for probabilistic inference. In Proc. AAAI
1991, 1991.
[79] N. Karmarkar. A new polynomial-time algorithm for linear programming.
Combinatorica, 4(4):373–395, 1984.

617

[80] Richard Karp. Reducibility Among Combinatorial Problems. In R. E. Miller
and J. W. Thatcher, editors, Complexity of Computer Computations, page
85103. 1972.
[81] David Kempe, Jon Kleinberg, and Éva Tardos. Maximizing the spread of
influence through a social network. In KDD ’03: Proceedings of the ninth ACM
SIGKDD international conference on Knowledge discovery and data mining,
pages 137–146, New York, NY, USA, 2003. ACM.
[82] Gabriele Kern-Isberner and Thomas Lukasiewicz. Combining probabilistic
logic programming with the power of maximum entropy. Artif. Intell., 157(12):139–202, 2004.
[83] Samir Khuller, Maria Vanina Martinez, Dana Nau, Gerardo I. Simari, Amy
Sliva, and Venkatramanan Siva Subrahmanian. Action probabilistic logic programs. Annals of Mathematics and Artificial Intelligence, 51(2–4):295–331,
2007.
[84] W. Kiessling, H. Thone, and U. Guntzer. Database support for problematic
knowledge. In Proceedings of EDBT 1992, Springer LNCS Volume 580, pages
421–436, 1992.
[85] Michael Kifer and Eliezer L. Lozinskii. A logic for reasoning with inconsistency.
Journal of Automated Reasoning, 9(2):179–215, 1992.
[86] Michael Kifer and V.S. Subrahmanian. Theory of generalized annotated logic
programming and its applications. J. Log. Program., 12(3&4):335–367, 1992.
[87] Dexter Kozen. The Design and Analysis of Algorithms. Springer-Verlag, New
York, 1991.
[88] Stanislav Krajci, Rastislav Lencses, and Peter Vojts. A comparison of fuzzy
and annotated logic programming. Fuzzy Sets and Systems, 144(1):173 – 192,
2004.
[89] Fabian Kuhn and Roger Wattenhofer. Constant-time distributed dominating
set approximation. In In Proc. of the 22 nd ACM Symposium on the Principles
of Distributed Computing (PODC, pages 25–32, 2003.
[90] Benjamin Kuipers. A hierarchy of qualitative representations for space. In
Working papers of the Tenth International Workshop on Qualitative Reasoning
about Physical Systems, 1996.
[91] M. Kwiatkowska, G. Norman, and D. Parker. Verifying randomized distributed algorithms with PRISM. In Proc. Workshop on Advances in Verification (Wave’2000), July 2000.

618

[92] Marta Kwiatkowska, Gethin Norman, and David Parker. Prism: probabilistic model checking for performance and reliability analysis. SIGMETRICS
Perform. Eval. Rev., 36(4):40–45, 2009.
[93] Laks V.S. Lakshmanan and F. Sadri. Modeling uncertainty in deductive
databases. In Proceedings of DEXA 1994, pages 724–733. Springer LNCS
Vol. 856, 1994.
[94] Laks V.S. Lakshmanan and F. Sadri. Probabilistic deductive databases. In
Proceedings of the Intl. Logic Programming Symposium (ILPS). MIT Press,
1994.
[95] Laks V.S. Lakshmanan and Nematollaah Shiri. A parametric approach to
deductive databases with uncertainty. IEEE Transactions on Knowledge and
Data Engineering, 1997.
[96] Leslie Lamport. “sometime” is sometimes “not never”: on the temporal logic
of programs. In POPL 1980, pages 174–185, New York, NY, USA, 1980. ACM.
[97] Kim G. Larsen and Arne Skou. Bisimulation through probabilistic testing.
Inf. Comput., 94(1):1–28, 1991.
[98] D. Lehmann and S. Shelah. Reasoning about time and chance. Information
and Control, 53:165–198, 1982.
[99] Nicola Leone, Francesco Scarcello, and V.S. Subrahmanian. Optimal models
of disjunctive logic programs: Semantics, complexity, and computation. IEEE
Transactions on Knowledge and Data Engineering, 16:487–503, 2004.
[100] Jure Leskovec, Daniel Huttenlocher, and Jon Kleinberg. Predicting positive
and negative links in online social networks. In Proceedings of the 19th international conference on World wide web, WWW ’10, pages 641–650, New
York, NY, USA, 2010. ACM.
[101] Jure Leskovec, Andreas Krause, Carlos Guestrin, Christos Faloutsos, Jeanne
VanBriesen, and Natalie Glance. Cost-effective outbreak detection in networks. In KDD ’07: Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 420–429, New York,
NY, USA, 2007. ACM.
[102] Kevin Leyton-Brown and Yoav Shoham. Essentials of Game Theory: A Concise, Multidisciplinary Introduction. Morgan and Claypool Publishers, 2008.
[103] S. Li and M. Ying. Region connection calculus: Its models and composition
table. Artif. Intell., 145:121 – 146, 2003.
[104] Chen Liao and Shiyan Hu. Polynomial time approximation schemes for minimum disk cover problems. Journal of Combinatorial Optimization.
619

[105] Erez Lieberman, Christoph Hauert, and Martin A. Nowak. Evolutionary dynamics on graphs. Nature, 433(7023):312–316, 2005.
[106] J. W. Lloyd. Foundations of Logic Programming, Second Edition. SpringerVerlag, 1987.
[107] J. Lu. Logic programs with signs and annotations. Journal of Logic and
Computation, 6(6):755–778, 1996.
[108] James J. Lu, Anil Nerode, and V.S. Subrahmanian. Hybrid knowledge bases.
IEEE Transactions on Knowledge and Data Engineering, 8(5):773–785, 1996.
[109] J.J. Lu, N.V. Murray, and E. Rosenthal. Signed formulas and annotated
logics. In Multiple-Valued Logic, 1993., Proceedings of The Twenty-Third International Symposium on, pages 48–53, May 1993.
[110] Thomas Lukasiewicz. Probabilistic logic programming. In ECAI, pages 388–
392, 1998.
[111] Thomas Lukasiewicz. Many-valued disjunctive logic programs with probabilistic semantics. In In Proceedings of the 5th International Conference on Logic
Programming and Nonmonotonic Reasoning, volume 1730 of LNAI, pages
277–289. Springer, 1999.
[112] Thomas Lukasiewicz, Thomas Lukasiewicz, Gabriele Kern-isberner, and
Gabriele Kern-isberner. Probabilistic logic programming under maximum entropy. In In Proc. ECSQARU-99, LNCS 1638, pages 279–292. Springer, 1999.
[113] Carsten Lund and Mihalis Yannakakis. On the hardness of approximating
minimization problems. J. ACM, 41(5):960–981, 1994.
[114] A. Martelli M. Falaschi, G. Levi and C. Palamidessi. A new declarative semantics for logic languages. In Proc. 5th Internat. Conf. Symp. on Logic
Programming, page 9931005, 1988.
[115] Wolfgang Maass. On the complexity of nonconvex covering. SIAM J. Comput.,
15(2):453–467, 1986.
[116] J. B. MacQueen. Some methods for classification and analysis of multivariate
observations. In L. M. Le Cam and J. Neyman, editors, Proc. of the fifth
Berkeley Symposium on Mathematical Statistics and Probability, volume 1,
pages 281–297. University of California Press, 1967.
[117] Paolo Mancarella, Alessandra Raffaetà, and Franco Turini. Temporal annotated constraint logic programming with multiple theories. In DEXA ’99:
Proceedings of the 10th International Workshop on Database & Expert Systems Applications, 1999.

620

[118] A. Mannes, M. Michaell, A. Pate, A. Sliva, V.S. Subrahmanian, and J. Wilkenfeld. Stochastic Opponent Modelling Agents: A Case Study with Hezbollah.
In Proc. 2008 First Intl. Workshop on Social Computing, Behavioral Modeling
and Prediction. Springer Verlag, April 1-2, 2008.
[119] Aaron Mannes, Amy Sliva, V.S. Subrahmanian, and Jonathan Wilkenfeld.
Stochastic Opponent Modeling Agents: A Case Study with Hamas. In Proc.
2008 Intl. Conf. on Computational Cultural Dynamics, pages 49–54. AAAI
Press, Sep. 2008.
[120] V. Martinez, G.I. Simari, A. Sliva, and Venkatramanan Siva Subrahmanian.
The SOMA Terror Organization Portal (STOP): Social Network and Analytic
Tools for the Real-Time Analysis of Terror Groups. In Huan Liu and John
Salerno, editors, Proceedings of the First International Workshop on Social
Computing, Behavioral Modeling and Prediction, 2008.
[121] V. Martinez, G.I. Simari, A. Sliva, and V.S. Subrahmanian. CONVEX:
Similarity-Based Algorithms for Forecasting Group Behavior. IEEE Intelligent Systems, 23(4):51–57, 2008.
[122] V. Martinez, G.I. Simari, A. Sliva, and V.S. Subrahmanian. CAPE: Automatically Predicting Changes in Terror Group Behavior. to appear in Mathematical
Methods in Counterterrorism (ed. N. Memon), 2009.
[123] S. Masuyama, T. Ibaraki, and T. Hasegawa. The computational complexity of
the m-center problems on the plane. Trans. IECE of Japan, E84:57–64, 1981.
[124] P. Mateus, A. Pacheco, J. Pinto, A. Sernadas, and C. Sernadas. Probabilistic
situation calculus. AMAI, 32:393–431(39), 2001.
[125] Nimrod Megiddo and Kenneth J. Supowit. On the complexity of some common
geometric location problems. SIAM Journal of Computing, 13(1):182–196,
1984.
[126] A. Pentland N. Eagle and D. Lazer. Mobile phone data for inferring social
network structure. In Proc. 2008 Intl. Conference on Social and Behavioral
Computing, pages 79–88. Springer Verlag, 2008.
[127] G. L. Nemhauser, L. A. Wolsey, and M.L. Fisher. An analysis of approximations for maximizing submodular set functionsi. Mathematical Programming,
14(1):265–294, 1978.
[128] Raymond T. Ng and V. S. Subrahmanian. Probabilistic logic programming.
Information and Computation, 101(2):150–201, 1992.
[129] Raymond T. Ng and Venkatramanan Siva Subrahmanian. A semantical
framework for supporting subjective and conditional probabilities in deductive databases. In Koichi Furukawa, editor, Proceedings of ICLP ’91, pages
565–580. The MIT Press, 1991.
621

[130] Raymond T. Ng and Venkatramanan Siva Subrahmanian. Probabilistic logic
programming. Information and Computation, 101(2):150–201, 1992.
[131] Nils Nilsson. Probabilistic logic. Artificial Intelligence, 28:71–87, 1986.
[132] Susan Owicki and Leslie Lamport. Proving liveness properties of concurrent
programs. ACM Trans. Program. Lang. Syst., 4(3):455–495, 1982.
[133] Maurice Pagnucco. The Role of Abductive Reasoning within the Process of Belief Revision. PhD thesis, Basser Department of Computer Science, University
of Sydney, Australia, 1996.
[134] Christos H. Papadimitriou. Worst-Case and Probabilistic Analysis of a Geometric Location Problem. SIAM J. Comput., 10(3):542–557, 1981.
[135] P. Paruchuri, M. Tambe, F. Ordóñez, and S. Kraus. Security in multiagent
systems by policy randomization. In Proc. 5th Int. Conf. on Autonomous
Agents and Multiagent Systems (AAMAS-2006), 2006.
[136] Vangelis T. Paschos. A survey of approximately optimal solutions to some
covering and packing problems. ACM Comput. Surv., 29(2):171–209, 1997.
[137] Charles S. Peirce. Philosophical writings of Peirce, selected and edited with an
introd. by Justus Buchler. Dover Publications New York,, 1955.
[138] Yun Peng and James A. Reggia. Plausibility of Diagnostic Hypotheses. In
Proceedings, 5th National Conference on AI (AAAI-86), pages 140–145, 1986.
[139] J. Pita, M. Jain, F. Ordóñez, M. Tambe, S. Kraus, and R. Magori-Cohen.
Effective solutions for real-world stackelberg games: When agents must deal
with human uncertainties. In Proc. 8th Int. Conf. on Autonomous Agents and
Multiagent Systems (AAMAS-2009), pages 369–376, 2009.
[140] M. L. Puterman. Markov Decision Processes. Wiley, 1994.
[141] James A. Reggia and Yun Peng. Abductive inference models for diagnostic
problem-solving. Springer-Verlag New York, Inc., New York, NY, USA, 1990.
[142] J. Renz and B. Nebel. On the complexity of qualitative spatial reasoning: A
maximal tractable fragment of the region connection calculus. Artif. Intell.,
108:69 – 123, 1999.
[143] Thomas Hewitt Rich, Mildred Adams Fenton, and Carroll Lane Fenton. The
fossil book: a record of prehistoric life. Dover Publications, 2 edition, 1996.
[144] D. Kim Rossmo and Sacha Rombouts. Geographic Profiling. In Richard Wortley and Lorraine Mazerolle, editors, Enviromental Criminology and Crime
Analysis, pages 136–149. 2008.

622

[145] Dan Roth. On the hardness of approximate reasoning. Artificial Intelligence,
82:273–302, 1996.
[146] Stuart Russell and Peter Norvig. Artificial Intelligence: A Modern Approach.
Prentice-Hall, Englewood Cliffs, NJ, 2nd edition edition, 2003.
[147] Jan Rychtář and Brian Stadler. Evolutionary dynamics on small-world networks. International Journal of Computational and Mathematical Sciences,
2(1), 2008.
[148] Eugene Santos and Joel D. Young. Probabilistic temporal networks: A unified framework for reasoning with time and uncertainty. Inter. Journal of
Approximate Reasoning, 20, 1999.
[149] Paulo Santos and Murray Shanahan. Hypothesising object relations from
image transitions. In Proc. ECAI02, 2002.
[150] Thomas C. Schelling. Micromotives and Macrobehavior. W.W. Norton and
Co., 1978.
[151] P. Schrodt and D.J. Gerner. Cluster analysis as an early warning technique for
the middle east. Preventive Measures: Building Risk Assessment and Crisis
Early Warning Systems (eds. John L. Davies and Ted Robert Gurr), 1998.
[152] P. Shakarian, M. Broecheler, and V.S. Subrahmanian. Using generalized annotated programs to solve social network optimization problems. (submitted),
2011.
[153] P. Shakarian and V.S. Subrahmanian. Region-based Geospatial Abduction
with Counter-IED Applications. In U. Kock Wiil, editor, Counterterrorism
and Open Source Intelligence (to appear). Springer, 2010.
[154] Paulo Shakarian, John Dickerson, and V.S. Subrahmanian. Adversarial geosptaial abudction. (submitted), 2011.
[155] Paulo Shakarian, Austin Parker, Gerardo Simari, and V.S. Subramanian. Annotated probabilstic temporal logic. ACM Transactions on Computational
Logic, 12(2), 2011.
[156] Paulo Shakarian, Gerardo Simari, and V.S. Subramanian. Annotated probabilistic temporal logic: Approximate fixpoint implementation. ACM Transactions on Computational Logic (accepted), 2011.
[157] Paulo Shakarian, V.S. Subrahmanian, and Maria Luisa Sapino. SCARE: A
Case Study with Baghdad. In Proceedings of the Third International Conference on Computational Cultural Dynamics. AAAI, 2009.
[158] Paulo Shakarian, V.S. Subrahmanian, and Maria Luisa Sapino. GAPs:
Geospatial Abduction Problems. ACM Transaction on Intelligent Systems
and Technology (accepted), 2010.
623

[159] Paulo Shakarian, V.S. Subrahmanian, and Maria Luisa Sapino. Using generalized annotated programs to solve social network optimization problems.
In Manuel Hermenegildo and Torsten Schaub, editors, Technical Communications of the 26th International Conference on Logic Programming, volume 7
of Leibniz International Proceedings in Informatics (LIPIcs), pages 182–191,
Dagstuhl, Germany, 2010. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik.
[160] M. Shanahan. Noise and the common sense informatic situation. In Proc.
AAAI96, page 1098, 1996.
[161] David B. Shmoys, Eva Tardos, and Karen Aardal. Approximation algorithms
for facility location problems (extended abstract). In In Proceedings of the
29th Annual ACM Symposium on Theory of Computing, pages 265–274, 1998.
[162] V. Sood, Tibor Antal, and S. Redner. Voter models on heterogeneous networks. Physical Review E (Statistical, Nonlinear, and Soft Matter Physics),
77(4):041121, 2008.
[163] R.K. Srihari. Automatic indexing and content-based retrieval of captioned
images. Computer, 28(9):49 –56, September 1995.
[164] John F. Stollsteimer. A Working Model for Plant Numbers and Locations.
45(3):631–645, Aug. 1963.
[165] Bogdan Stroe and V. S. Subrahmanian. First order heterogeneous agent computations. In AAMAS ’03: Proceedings of the second international joint conference on Autonomous agents and multiagent systems, pages 217–224, New
York, NY, USA, 2003. ACM.
[166] V. S. Subrahmanian and Diego Reforgiato Recupero. AVA: Adjective-VerbAdverb Combinations for Sentiment Analysis. IEEE Intelligent Systems,
23(4):43, 2008.
[167] Eric Sun, Itamar Rosenn, Cameron Marlow, and Thomas Lento. Gesundheit!
modeling contagion through facebook news feed. In Proceedings of the Third
International Conference on Weblogs and Social Media, San Jose, CA, May
2009. AAAI Press, AAAI Press.
[168] K. Thirunarayan and M. Kifer. A theory of nonmonotonic inheritance based
on annotated logic. Artificial Intelligence, 60(1):23–50, 1993.
[169] S. Rebecca Thomas. The placa agent programming language. In ECAI-94:
Proceedings of the workshop on agent theories, architectures, and languages on
Intelligent agents, pages 355–370, New York, NY, USA, 1995. Springer-Verlag
New York, Inc.
[170] US Army. Intelligence Preparation of the Battlefiled (US Army Field Manual),
FM 34-130 edition, 1994.
624

[171] US Army. Counterinsurgency (US Army Field Manual), FM 3-24 edition,
2006.
[172] Pascal Van Hentenryck. Constraint logic programming. The Knowledge Engineering Review, 6(03):151–194, 2009.
[173] Moshe Y. Vardi. Automatic verification of probabilistic concurrent finite state
programs. Symp. on Foundations of Comp. Sci., 0:327–338, 1985.
[174] Vijay V. Vazirani. Approximation Algorithms. Springer, March 2004.
[175] J. Venneksn, S. Verbaeten, and M. Bruynooghe. Logic programs with annotated disjunctions. In Proc. Intl. Conf. on Logic Programming, pages 431–445.
Springer Lecture Notes in Computer Science Vol. 3132, 2004.
[176] Kiri Wagstaff, Claire Cardie, Seth Rogers, and Stefan Schrödl. Constrained
k-means clustering with background knowledge. In ICML ’01: Proceedings of
the Eighteenth International Conference on Machine Learning, pages 577–584,
San Francisco, CA, USA, 2001. Morgan Kaufmann Publishers Inc.
[177] D.J. Watts and J. Peretti. Viral marketing for the real world. Harvard Business
Review, May 2007.
[178] Duncan J. Watts. Networks, dynamics, and the small-world phenomenon. The
American Journal of Sociology, 105(2):493–527, 1999.
[179] Y. Weiss and E.H. Adelson. A unified mixture framework for motion segmentation: incorporating spatial coherence and estimating the number of models.
In Computer Vision and Pattern Recognition, 1996. Proceedings CVPR ’96,
1996 IEEE Computer Society Conference on, pages 321 –326, June 1996.
[180] WEKA.
2009.

WEKA 3 Data Mining, http://www.cs.waikato.ac.nz/ml/weka/.

[181] Jonathan Wilkenfeld, Victor Asal, Carter Johnson, Amy Pate, and Mary
Michael. The use of violence by ethnopolitical organizations in the middle
east. Technical report, National Consortium for the Study of Terrorism and
Responses to Terrorism, February 2007.

625

BioSystems 111 (2013) 136–144

Contents lists available at SciVerse ScienceDirect

BioSystems
journal homepage: www.elsevier.com/locate/biosystems

A novel analytical method for evolutionary graph theory problems
Paulo Shakarian a,∗ , Patrick Roos b , Geoffrey Moores a
a
b

Network Science Center and Department of Electrical Engineering and Computer Science, United States Military Academy, West Point, NY 10996, United States
Department of Computer Science, University of Maryland, College Park, MD 20740, United States

a r t i c l e

i n f o

Article history:
Received 4 September 2012
Received in revised form 5 January 2013
Accepted 10 January 2013
Keywords:
Evolutionary dynamics
Moran process
Complex networks

a b s t r a c t
Evolutionary graph theory studies the evolutionary dynamics of populations structured on graphs. A
central problem is determining the probability that a small number of mutants overtake a population.
Currently, Monte Carlo simulations are used for estimating such ﬁxation probabilities on general directed
graphs, since no good analytical methods exist. In this paper, we introduce a novel deterministic framework for computing ﬁxation probabilities for strongly connected, directed, weighted evolutionary graphs
under neutral drift. We show how this framework can also be used to calculate the expected number
of mutants at a given time step (even if we relax the assumption that the graph is strongly connected),
how it can extend to other related models (e.g. voter model), how our framework can provide non-trivial
bounds for ﬁxation probability in the case of an advantageous mutant, and how it can be used to ﬁnd a
non-trivial lower bound on the mean time to ﬁxation. We provide various experimental results determining ﬁxation probabilities and expected number of mutants on different graphs. Among these, we show
that our method consistently outperforms Monte Carlo simulations in speed by several orders of magnitude. Finally we show how our approach can provide insight into synaptic competition in neurology.
Published by Elsevier Ireland Ltd.

1. Introduction
Evolutionary graph theory (EGT), introduced by Lieberman et al.
(2005), studies the problems related to population dynamics when
the underlying structure of the population is represented as a
directed, weighted graph. This model has been applied to problems in evolutionary biology (Zhang et al., 2007), physics (Sood
et al., 2008), game theory (Pacheco et al., 2006), neurology (Turney
and Lichtman, 2012), and distributes systems (Jiang et al., 2012). A
central problem in this research area is computing the ﬁxation probability – the probability that a certain subset of mutants overtakes
the population. Although good analytical approximations are available for the undirected/unweighted case (Antal et al., 2006; Broom
et al., 2010), these break down for directed, weighted graphs as
shown by Masuda and Ohtsuki (2009). As a result, most work dealing with evolutionary graphs rely on Monte Carlo simulations to
approximate the ﬁxation probability (Rychtář and Stadler, 2008;
Broom and Rychtář, 2009; Barbosa et al., 2010). In this paper we
develop a novel deterministic framework to compute ﬁxation probability in the case of neutral drift (when mutants and residents have
equal ﬁtness) in directed, weighted evolutionary graphs based on
the convergence of “vertex probabilities” to the ﬁxation probability

∗ Corresponding author. Tel.: +1 845 938 3642.
E-mail address: paulo@shakarian.net (P. Shakarian).
0303-2647/$ – see front matter. Published by Elsevier Ireland Ltd.
http://dx.doi.org/10.1016/j.biosystems.2013.01.006

as time approaches inﬁnity. We then show how this framework
can be used to calculate the expected number of mutants at a given
time, how the framework can be modiﬁed to do the same for related
models, how it can provide non-trivial bounds for ﬁxation probability in the case of an advantageous mutant, and how it can provide
a non-trivial lower bound on the mean time to ﬁxation. We also
provide various experiments that show how our method can outperform Monte Carlo simulations by several orders of magnitude.
Additionally, we show that the results of this paper can provide
direct insight into the problem of synaptic competition in neurology.
Our method also ﬁlls a few holes in the literature. First, it allows
for deterministic computation of ﬁxation probability when there
is an initial set of mutants – not just a singleton (the majority
of current research on evolutionary graph theory only considers
singletons). Second, it allows us to study how the mutant population changes as a function of time. Third, we show (by way of
rigorous proof) that ﬁxation probability, under the case of neutral
drift is a lower bound for the case of the advantageous mutant –
conﬁrming simulation observations by Masuda (2009). Fourth, we
show (also by way of rigorous proof) that ﬁxation probability under
neutral drift is additive (even for weighted, directed graphs), which
extends the work of Broom et al. (2010) that proved this for undirected/unweighted graphs. Fifth, we provide a non-trivial lower
bound for the computation of mean time to ﬁxation in the general case – which has only previously been explored for well-mixed

P. Shakarian et al. / BioSystems 111 (2013) 136–144

populations (Antal and Scheuring, 2006) and special cases of graphs
(Broom et al., 2009).
This paper is organized as follows. In Section 2 we review the
original model of Lieberman et al., introduce the idea of “vertex
probabilities” and show how they can be used to ﬁnd the ﬁxation probability. We then show how this can be used to determine
the expected number of mutants at a given time in Section 3.
This is followed by a discussion of how the framework can be
extended to other update rules in Section 4 and then for bounding ﬁxation probability in the case of an advantageous mutant in
Section 5. We then discuss how our approach can be adopted to
bound mean time to ﬁxation in Section 6. We use the results of
the previous sections to create an algorithm for computing ﬁxation probability and introduce a heuristic technique to signiﬁcantly
decrease the run-time. The algorithm and several experimental
evaluations are described in Section 7. In Section 8, we show how
our framework can be applied to neurology to gain insights into
synaptic competition. Finally, we discuss related work in Section 9
and conclude.

graph theory is to determine the ﬁxation probability. Given set of
mutants C at time 0, the ﬁxation probabilty is deﬁned as follows.
FC = lim PV,t|C

(1)

t→∞

This is the probability that an initial set C of mutants takes over the
entire population as time approaches inﬁnity. Similarly, we will use
the term the extinction probability, F C , to be lim P∅,t|C . If the graph if
t→∞

strongly connected, then we have FC + F C = 1. Hence, for a strongly
connected graph, a mutant either ﬁxates or becomes extinct. Typically, this problem is studied using Monte Carlo simulation. This
work uses the idea of a vertex probabilities to create an alternative
to such an approach. The vertex probability is the probability that
a certain vertex is a mutant at a certain time given an initial conﬁguration. For vertex i at time t, we denote this as Pi,t|C . Often, for
ease of notation, we shall assume that the probabilities are conditioned on some initial conﬁguration and drop the condition, writing
Pi,t instead of Pi,t|C . We note that Pi,t can be expressed in terms of
probabilities of conﬁgurations as follows.
Pi,t =



V

2. Directly calculating ﬁxation probability

137

∈

PV  ,t

(2)

2V

s.t. i ∈ V 
The classic evolutionary model known as the Moran process is a
stochastic process used to describe evolution in a well-mixed population (Moran, 1958). All the individuals in the population are either
mutants or residents. The aim of such work was to determine if a set
of mutants could take over a population of residents (achieving “ﬁxation”). In Lieberman et al. (2005), evolutionary graph theory (EGT)
is introduced, which generalizes the model of the Moran process
by specifying relationships between the N individuals of the population in the form of a directed, weighted graph. Here, the graph
will be speciﬁed in the usual way as G = (V, E) where V is a set of
nodes (individuals) and E ⊆ V × V. In most literature on evolutionary graph theory, the evolutionary graph is assumed to be strongly
connected. We make the same assumption and state when it can be
relaxed.
(i)
(i)
For any node i, the numbers kin and kout are the in- and outdegrees respectively. We will use the symbol N to denote the sized
of V. Additionally, we will specify weights on the edges in set E
using a square matrix denoted W = [wij ] whose side is of size N.
Intuitively, wij is the probability that member of the population
j is

w =1
replaced by i given that member i is selected. We require
j ij
(i)

and that (i, j) ∈ E iff wij > 0. If for all i, j, we have wij = 1/kout , then the
graph is said to be “unweighted.” If for all (i, j) ∈ E, we have (j, i) ∈ E
the graph is said to be “undirected.” Though our results primarily
focus on the general case, we will often refer to the special case of
undirected/unweighted graphs as this special case is quite common
in the literature (Antal et al., 2006; Broom et al., 2010).
In this paper we will often consider the outcome of the evolutionary process when there is a set of initial mutants as opposed to
a singleton. Hence, we say some set (often denoted C) is a conﬁguration if that set speciﬁes the set of mutants in the population (all
other members in the population then are residents). We assume
all members in the population are either mutants or residents and
have a ﬁtness speciﬁed by a parameter r > 0. Mutants have a ﬁtness
r and residents have a ﬁtness of 1. At each time step, some individual i ∈ V is selected for “birth” with a probability proportional to its
ﬁtness. Then, an outgoing neighbor j of i is selected with probability
wij and replaced by a clone of i. Note if r = 1, we say we are in the
special case of neutral drift.
We will use the notation PV  ,t to refer to the probability of being
in conﬁguration V after t timesteps and PV  ,t|C to be the probability
of being in conﬁguration V at time t conditioned upon initial conﬁguration C. Perhaps the most widely studied problem in evolutionary

Viewing the probability that a speciﬁc vertex is a mutant at a given
time has not, to our knowledge, been studied before with respect
to evolutionary graph theory (or in related processes such as the
voter model). The key insight of this paper is that studying these
probabilities sheds new light on the problem of calculating ﬁxation
probabilities in addition to providing other insights into EGT. For
example, it is easy to show the following relationship.
Proposition 1. Let V be a subset of V and t be an arbitrary time
point. Iff for all i ∈ V , Pi,t = 1 and for all i ∈
/ V , Pi,t = 0, then PV  ,t = 1 and
/ V , PV  ,t = 0.
for all V ∈ 2V s.t. V ≡
It is easy to verify that FC > 0 iff ∀i ∈ V, lim Pi,t > 0. Hence, in
t→∞

this paper, we shall generally assume that lim Pi,t > 0 holds for all
t→∞

vertices i and speciﬁcally state when it does not. As an aside, for a
given graph, this assumption can be easily checked: simply ensure
for j ∈ V − C that exists some i ∈ C s.t. there is a directed path from i
to j.
Now that we have introduced the model and the idea of vertex
probabilities we will show how to leverage this information to compute ﬁxation probability. It is easy to show that as time approaches
inﬁnity, the vertex probabilities for all vertices converge to the
ﬁxation probability when the graph if strongly connected.
Theorem 1.

∀i, lim Pi,t|C = FC
t→∞

Now let us consider how to calculate Pi,t for some i and t. For t = 0,
where we know that we are in the state where only vertices in
a given set are mutants, we need only appeal to Proposition 1 –
which tells us that we assign a probability of 1 to all elements in
that set and 0 otherwise. For subsequent timesteps, we have developed Theorem 2 shown next (the proof of which is included in the
supplement).
Theorem 2.
Pi,t = Pi,t−1 +



wji (Pj,t−1 · S(j,t)|(j,t−1) − Pi,t−1 · S(j,t)|(i,t−1) )

(j,i)∈E

(S(j,t)|(i,t−1) is the probability that j is picked for reporduction at time t
given that i was a mutant at time t − 1.)
We believe that a concise, tractable analytical solution for S(j,t)|(i,t−1)
is unlikely. However, for neutral drift (r = 1), these conditional

138

P. Shakarian et al. / BioSystems 111 (2013) 136–144

probabilities are trivial – speciﬁcally, we have for all i, j, t,
S(j,t)|(i,t−1) = 1/N as this probability of selection is independent of the
current set of mutants or residents in the graph. Hence, in the case
of neutral drift, we have the following:

 wji

Pi,t = Pi,t−1 +

(j,i)∈E

N

· (Pj,t−1 − Pi,t−1 )

(3)

Studying evolutionary graph theory under neutral drift was a central theme in several papers on EGT in the past few years (Broom
et al., 2010; Masuda, 2009) as it provides an intuition on the effects
of network topology on mutant spread. In Section 5 we examine
the case of the advantageous mutant (r > 1). Neutral drift allows us
to strengthen the statement of Eq. (1) to a necessary and sufﬁcient
condition – showing that when the probabilities of all nodes are
equal, then we can determine the ﬁxation probability.
Theorem 3. Assuming neutral drift (r = 1), given initial conﬁguration
C with ﬁxation probability FC , if at time t the quantities Pi,t|C are equal
(for all i ∈ V), then they also equal FC .
Therefore, under neutral drift, we can determine ﬁxation probability when Eq. (3) causes all Pi,t ’s to be equal. We can also use Eq.
(3) to ﬁnd bounds on the ﬁxation probability for some time t by the
following result that holds for any time t under neutral drift.
minPi,t ≤ FC ≤ maxPi,t
i

(4)

i

Under neutral drift, we can show that ﬁxation probability is
additive for disjoint sets. Broom et al. proved a similar result the a
special case of undirected/unweighted evolutionary graphs (Broom
et al., 2010). However, our proof (contained in the supplement)
differs from theirs in that we leverage Eq. (3). Further, unlike the
result of Broom et al., our result applies to the more general case of
weighted, directed graphs.
Theorem 4.

When r = 1 for disjoint sets C, D ⊆ V, FC + FD = FC∪D .

In addition to allowing for the calculation of ﬁxation probability,
our framework can also be used to observe how the expected num(t)
ber of mutants changes over time. We will use the notation ExC to
denote the expected number of mutants at time t given initial set
C. Formally, this is deﬁned below.
(t)



Pi,t

(5)

i∈V

Unlike ﬁxation probability, which only considers the probability
(t)
that mutants overtake a population, ExC provides a probabilistic
average of the number of mutants in the population under a ﬁnite
time horizon. For example, is has been noted that graph structures
which amplify ﬁxation normally also increase time to absorption
(Broom et al., 2011; Paley et al., 2007). Hence, ﬁnding the expected
number of mutants may be a more viable topic in some areas of
research where time is known to be limited. Following from Eq.
(3) where we showed how to compute Pi,t for each node at a given
time, we have the following relationship concerning the expected
number of mutants at a given time under neutral drift.
(t−1)

(t)

(t−1)

ExC = ExC

+

ExC

N

−

1
wji · Pi,t−1
N

Update rule

Intuition

Birth–death (BD) (a.k.a.
invasion process (IP))

(1) Node i selected
(2) Neighbor of i, node j selected
(3) Offspring of i replaces j
(1) Node i selected

Death–birth (DB) (a.k.a. voter
model (VM))

(2) Neighbor of i, node j selected
(3) Offspring of j replaces i
Link dynamics (LD)

(1) Edge (i, j) selected
(2) The offspring of one node in the
edge replaces the other node



(Lieberman et al., 2005): Ti =
w . Intuitively, nodes with a higher
j ji
temperature change more often between being a mutant and being
a resident than those with lower temperature. Re-writing Eq. (6) in
terms of temperature we have the following:
(t−1)

(t)

(t−1)

ExC = ExC

+

ExC

N

−

1
Ti · Pi,t−1
N

(7)

i∈V

Hence, if the preponderance of high temperature nodes are
likely to be mutants, then most likely the average number of
mutants will decrease at the next time step. We also note that
Theorem 2 and Eqs. (3) and (6) do not depend on the assumption
that the underlying graph is strongly connected. Therefore, as such
is the case, we can study the relationship of time vs. expected number of mutants for any evolutionary graph (under neutral drift). This
could be of particular interest to non-strongly connected evolutionary graphs that may have trivial ﬁxation probabilities (i.e. 1 or 0) but
may have varying levels of mutants before achieving an absorbing
state.
4. Applying the framework to other update rules

3. Calculating the expected number of mutants

ExC =

Table 1
Different families of update rules.

(6)

i∈V (j,i)∈E

Based on Eq. (6), we notice that for r = 1, at each time-step,
the number of expected mutants increases by at most the average ﬁxation probability and decreases by a quantity related to the
average “temperature.” The temperature of vertex i (denoted Ti ) is
deﬁned for a given node is the sum of the incoming edge weights

The results of the last two sections not only apply to the original
model of Lieberman et al. (2005), but several other related models in
the literature. Viewing an evolutionary graph problem as a stochastic process, where the states represent different mutant-resident
conﬁgurations, it is apparent that the original model speciﬁes the
transition probabilities. However, there are other ways to specify
the transition probabilities known as update rules. Several works
address different update rules (Antal et al., 2006; Sood et al., 2008;
Masuda, 2009). Overall, we have identiﬁed three major families
of update rules – birth–death (a.k.a. the invasion process) where
the node to reproduce is chosen ﬁrst, death–birth (a.k.a. the voter
model) where the node to die is chosen ﬁrst, and link dynamics,
where an edge is chosen. We summarize these in Table 1.
We have already shown how our methods can deal with
the original model of Lieberman et al., often referred to as the
birth–death (BD) process. In this section, we apply our methods
to the neutral-drift (non-biased) cases of death–birth and linkdynamics. In these models, the weights of the edges are typically
not considered. Hence, in order to align this work with the majority
of literature on those models, we will express vertex probabilities
(i)
in terms of node in-degree (kin ) and the set of directed edges (E).
We note that these results can be easily extended to a more general
case with an edge-weight matrix as we used for the original model
of EGT.
4.1. Death–birth updating
Under the death–birth model (DB), at each time step, a vertex i is selected for death. With a death-bias (DB-D), it is selected

P. Shakarian et al. / BioSystems 111 (2013) 136–144

proportional to the inverse of its ﬁtness, with a birth-bias (DB-B)
it is selected with a probability 1/N, which is also the probability
under neutral drift. Then, an incoming neighbor (j) is selected either
proportional to the ﬁtness of all incoming neighbors (birth-bias), or
with a uniform probability (in the case death-bias or neutral drift).
The selected neighbor then replaces i. Here, we compute Pi,t under
this dynamic with r = 1.
Pi,t = (1 − N

−1

(i)
)Pi,t−1 + (Nkin )−1



Pj,t−1

BD-B :F{i} ≤ r(r +



wji )−1

(10)

j

⎛
BD-D :F{i} ≤ ⎝

DB-B :F{i} ≤

We note that the proof of convergence still holds for death–birth
– that is for some time t, ∀i, the value Pi,t is the same, then Pi,t = FC .
Further, Theorem 4 holds for DB under neutral drift as well, specifically, for disjoint sets C, D ⊆ V, FC + PD = PC∪D .

⎞−1





j

wji
r − rwji + wji

⎠

(11)

rwij (1 − wij + rwij )−1

(12)

j

DB-D :F{i} ≤ r



wij

(13)

j

6. A lower bound for mean time to ﬁxation

4.2. Link-dynamics
With link dynamics (LD), at each time step an edge (i, j) is
selected either proportional to the ﬁtness of i or the inverse of the
ﬁtness of j. It has previously been shown that LD under birth bias
is an equivalent process to LD with a death bias (Masuda, 2009).
Under neutral drift, the probability of edge selection is 1/|E| (where
|E| is the cardinality of set E). Then, i replaces j. Now, we compute
Pi,t under this dynamic with r = 1.
Pi,t = (1 − kin |E|−1 )Pi,t−1 +
(i)

1
|E|



Pj,t−1

(9)

(j,i)∈E

Again, convergence and additivity of the ﬁxation probability still
hold under link dynamics just as with BD and DB.
5. Bounding ﬁxation probability for r > 1
So far we have shown how our method can be used to ﬁnd ﬁxation probabilities under the case of neutral drift. Here, we show
how our framework can be useful in the case of an advantageous
mutant (when the value for r, the relative ﬁtness, is greater than 1).
First, we show that our method provides a lower bound. We then
provide an upper bound on the ﬁxation probability that can be used
in conjunction with our framework when studying the case of the
advantageous mutant. We note that certain parts of these proofs
are speciﬁc for diffent update rules, and we identify them using
the abbreviations from the last section (DB-D, DB-B, and LD). The
update of the original model of Lieberman et al. (2005) is known as
the “birth–death” model and abbreviated BD. If the ﬁtness bias is
on a birth event, we denote it as BD-B and if the bias is on a death
event we denote it as BD-D.
Masuda observes experimentally (through simulation) that the
ﬁxation probability computed with neutral drift appears to be
a lower bound on the ﬁxation probability for an advantageous
mutant (Masuda, 2009). We were able to prove this result analytically – the proof is included in the supplementary materials.
Theorem 5.

the following non-trivial upper bounds of ﬁxation probability for
individual nodes in various update rules.

(8)

(j,i)∈E

139

(1)

For a given set C, let FC

be the ﬁxation probability

(r)

under neutral drift and FC be the ﬁxation probability calculated using
a mutant ﬁtness r > 1. Then, under BD-B, BD-D, DB-B, DB-D, or LD
(1)
(r)
dynamics, FC ≤ FC .
(r  )

(r)

This proof leads to the conjecture that r > r implies FC ≥ FC .
However, we suspect that proving this monotonicity property will
require a different technique than used in Theorem 5. Next, to ﬁnd
an upper bound that corresponds with the lower bound above, we
use the proof technique introduced in Díaz et al. (2012), to obtain

Another important, although less-studied problem with respect
to evolutionary graph theory is the mean time to ﬁxation – the average time it takes for a mutant to take over the population. Closely
related to this problem are mean time to extinction (average time
for the resident to take over) and mean time to absorption (average
time for either mutant or resident to take over). This has been previously studied under the original Moran process for well mixed
populations (Antal and Scheuring, 2006) as well as some special
cases of graphs (Broom et al., 2009). However, to our knowledge,
a general method to compute these quantities (without resorting
to the use of simulation) has not been previously studied. Here we
take a “ﬁrst step” toward developing such a method by showing
how the techniques introduced in this paper can be used to compute a non-trivial lower bound for mean time to ﬁxation (and easily
modiﬁed to bound mean time to extinction and absorption).
Let Ft|C be the probability of ﬁxation at time t. Therefore,
Ft|C − Ft−1|C is the probability of entering ﬁxation at time t. The symbol tC is the mean time. By the results of Antal and Scheuring (2006),
we have the following:
Theorem 6.
1
t · (Ft|C − Ft−1|C )
FC
∞

tC =

t=1

Our key intuition is noticing that at each time step t, Ft|C ≤
minPi,t . From this, we use the accounting method to provide a rigi

orous proof for the following theorem that provides a non-trivial
lower-bound for the mean time to ﬁxation. This result can be easily
modiﬁed for mean time to extinction and absorption as well.

∞

1
t · (Pmin,t − Pmin,t−1 ) ≤
Theorem 7.
FC
t=1
Ft−1|C ) where Pmin,t = min Pi,t .

1
FC

∞

t=1

t · (Ft|C −

i

7. Algorithm and experimental evaluation
We leverage the ﬁnding of the previous sections in Algorithm
1. As described earlier, our method has
found the exact ﬁxation
probability when all the probabilities in i {Pi,t } (represented in the
pseudo-code as the vector p) are equal. We use Eq. (4) to provide
a convergence criteria based on value , which we can prove to be
the tolerance for the ﬁxation probability.
Proposition 2.
within ±.
Algorithm 1.
probabilities

Algorithm 1 returns the ﬁxation probability FC
Our novel solution method to compute ﬁxation

140

P. Shakarian et al. / BioSystems 111 (2013) 136–144

Input: Evolutionary Graph N, V, W, conﬁguration C ⊆ V,
natural number R > 0, and real number  ≥ 0.
Output: Estimate of ﬁxation probability of mutant.
pi is the ith position in vector p corresponding with vertex i ∈ V.
1:
2:
Set pi = 1 if i ∈ C and pi = 0 otherwise. {As per Proposition 1}
3:
q ← p {q will be p from the previous time step.}
4:
 ←1
5:
while  >  do
fori ∈ V {This loop carries out the calculation as per Eq. (3)}
6:
do
7:
sum ← 0
8:
m ← {j ∈ V |wji > 0}
9:
forj ∈ m do
sum = sum + wji · (qj − qi )
10:
end for
11:
pi ← qi + 1/N · sum
12:
13:
end for
14:
q←p
15:
 ← (1/2) · (max p − min p) {Ensures error bound based on Eq. (4)}
end while
16:
return (min p) + 
17:

Our novel method for computing ﬁxation probabilities on
strongly connected directed graphs allows us to compute nearexact ﬁxation probabilities within a desired tolerance. The running
time of the algorithm is highly dependent on how fast the vertex
probabilities converge. In this section we experimentally evaluate
how the vertex probabilities in our algorithms converge. We also
provide results from comparison experiments to support the claim
that Algorithm 1-ACC ﬁnds adequate ﬁxation probabilities order
of magnitudes faster than Monte Carlo simulations. We also show
how the algorithm can be used to study the expected number of
mutants as well as bound mean time to ﬁxation.
7.1. Convergence of vertex probabilities
We ran our algorithm to compute ﬁxation probabilities on randomly weighted and strongly connected directed graphs in order
to experimentally evaluate the convergence of the vertex probabilities. We generated the graphs to be scale-free using the standard
preferential attachment growth model (Barabási and Albert, 1999)
and randomly assigned an initial mutant node. We replaced all
edges in the graph given by the growth model with two directed
edges and then randomly assigned weights to all the edges.
To compare Algorithm 1 with the Monte Carlo approach, we
should set the parameter R in that algorithm to be comparable

with  in Algorithm 1. As  is the provable error of a solution to
Algorithm 1. Based on the commonly accepted deﬁnition of estimated standard error from statistics, we can obtain the estimated
standard error for the solution returned by Monte Carlo approach
with the following expression (where R is the number of simulation
runs).

	

FC (1 − FC )
R−1

(14)

We can use Eq. (14) to estimate the parameter R for the Monte
Carlo approach as follows. We set  equal to the estimated standard
error as per Expression 14 and manipulate it algebraically. This
gives us R ≈ ((S(S − 1))/2 ) + 1 where S is the solution to Algorithm
1,  is the input parameter for Algorithm 1 and R is the number of
simulation runs in the Monte Carlo approach that we estimate to
provide a comparable error bound. We also note, that as the vertex probabilities converge, the standard deviation of the p vector
in Algorithm 1 could be a potentially faster convergence criteria.
Note that using standard deviation of p and returning the average
vertex probability would no longer provide us of the guarantee in
Proposition 2, however it may provide good results in practice. The
modiﬁcations to the algorithm would be as follows: line 15 would
be  ← st.dev(p) and line 17 would be return avg(p). We will refer to
this as Algorithm 1 with alternate convergence criteria or Algorithm
1-ACC for short.
Fig. 1 (left) shows the convergence of the minimum, maximum,
and the average of vertex probabilities toward the ﬁnal ﬁxation
probability value for a small graph of 100 nodes. We can observe
that the average converges to the ﬁnal value at a logarithmic rate
and much faster than the minimum and maximum vertex probability values. This suggests that while Algorithm 1-ACC does not
give the same theoretical guarantees as Algorithm 1, it is much
preferable for speed since the minimum and maximum vertex
probabilities take much longer to converge to the ﬁnal solution
than the average. The fact that the average of the vertex probabilities is much preferable as a fast estimation of ﬁxation probabilities
is supported by the logarithmic decrease of the standard deviation of vertex probabilities (see Fig. 2). Convergences for other and
larger graphs are not shown here but are qualitatively similar to
the relative convergences shown in the provided graphs.

Fig. 1. Left: convergence of the minimum (MinP), maximum (MaxP), and average (AvgP) of vertex probabilities toward the ﬁnal ﬁxation probability as a function of our
algorithm’s iterations t for a graph of 100 nodes. Right: average speedup (on a log scale) for ﬁnding ﬁxation probabilities achieved by our algorithm vs. Monte Carlo simulation
for graphs of different sizes.

P. Shakarian et al. / BioSystems 111 (2013) 136–144

141

ﬁxation probability estimates from our algorithm exited the window of standard error (from simulations) once they entered it.
We can observe from our experiments that computing ﬁxation
probabilities using Monte Carlo simulations showed to be a very
time-expensive process, highlighting the need for faster solution
methods as the one we have presented. Especially for larger graph
sizes, the time complexity of our solution to achieve similar results
to Monte Carlo simulation has shown to be orders of magnitude
smaller than the standard method.
7.3. Monitoring the expected number of mutants

Fig. 2. Standard deviation of vertex probabilities as a function of our algorithm’s
iterations for the same 100 node graph of Fig. 1 (left).

7.2. Speed comparison to monte carlo simulation
In order to compare our method’s speed compared to the
standard Monte Carlo simulation method, we must determine how
many iterations our algorithm must be run to ﬁnd a ﬁxation probability estimate comparable to that of the Monte Carlo approach.
Thankfully, as we have seen, we can get a standard error on the
ﬁxation probability returned by the Monte Carlo approach as per
Eq. (14). While we did not theoretically prove anything about how
smoothly ﬁxation probabilities from our methods approach the
ﬁnal solution, the convergences of the average and standard deviation as shown above strongly suggest that estimates from our
method approach the ﬁnal solution quite gracefully. In fact, in the
following experiments, once our method has arrived at a ﬁxation
probability estimate within the standard error of simulations, the
estimate never again fell outside the window of standard error
(although the estimate did not always approach the ﬁnal estimate
monotonically). This is in stark contrast to Monte Carlo simulations, from which estimations can vary greatly before the method
has completed enough single runs to achieve a good probability
estimate.
We generated a number of randomly weighted and strongly
connected directed graphs of various sizes on which we compare
our solution method to Monte Carlo approximation of ﬁxation
probabilities. The graphs were generated as in our convergence
experiments. For each graph of a different size, we generated a
number of different initial mutant conﬁgurations. We found ﬁxation probabilities both using Monte Carlo estimation with 2000
simulation runs and our direct solution method, terminating when
we have reached within the standard error of the Monte Carlo estimation. Since the average vertex probability proved to be such
a good fast estimate of the true ﬁxation probability, we used
Algorithm 1-ACC.
Fig. 1 (right) shows the speedup our solution provides over
Monte Carlo simulation. Here speedup is deﬁned as the ratio of the
time it takes for simulations to complete over the time it takes our
algorithm to ﬁnd a ﬁxation probability within the standard deviation. The often extremely low number of iterations needed by our
algorithm to ﬁnd ﬁxation probabilities within the standard error
of simulations may prompt the concern that the probabilities fall
within this window so soon by mere chance. However, our experiments have shown that the ﬁxation probability estimation found by
our algorithm at each iteration approach the ﬁnal ﬁxation probability after termination smoothly at a logarithmic rate, asymptotically
approaching the true ﬁxation probability. While in this case the
ﬁxation probability estimate slightly crosses over the true ﬁxation probability and then slowly approaches it again, none of the

As observed in Section 3, our method not only allows for the
calculation of the ﬁxation probability of a mutant, but also allows
us to study how the expected number of mutants change over time.
In this section, we present experimental results exploring the trajectory of the expected number of mutants over time on various
undirected/unweighted graphs and under different initial mutant
placement conditions.
First, we note that the expected number of mutants (as time
approaches inﬁnity) in an unweighted/undirected graph with
respect to a single initially infected vertex i can be computed by
modifying the result of Broom et al. (2010) (for BD updating) to
obtain the following.
(t)

lim Ex{i} =

t→∞

1
ki k−1 

(15)

where k−1  is the average inverse of the degree for the graph.
Hence, we can determine whether a node ampliﬁes or suppresses
(t)
selection by observing if lim Ex{i} is greater or less than 1 respect→∞

tively: if ki < 1/k−1  selection is ampliﬁed and if ki > 1/k−1  it is
suppressed. We have used our algorithm to compare the trajectory of the expected number of mutants over time when the initial
mutant is placed on ampliﬁers vs. suppressors under different
graph topologies and BD updating. We note that similar comparisons can be obtained with our algorithm for the other update rules.
We also note that by Theorem 5, an ampliﬁer for BD (with no bias)
will also be an ampliﬁer for the (biased) BD-B and BD-D where r > 1.
Fig. 3 shows the trajectories of the expected number of mutants
over time on random (Barabási and Albert, 1999) preferential
attachment (BAR), ER (Erdős and Rényi, 1960), and small world
graphs (NWS) (Newman and Watts, 1999), each for when the initial mutant is placed on a suppressor (highest degree node of graph)
and ampliﬁer (lowest degree node of graph). Graphs are all of equal
size at 100 nodes. We note that the highest degree nodes are especially strong suppressors on BAR graphs, less so for NWS graphs, and
even less so for ER graphs. This makes sense when one considers
the degree distribution of the different graph topologies, which are
scale-free or power-law (P(k) ∼ k−3 ) for BR, roughly Poisson-shaped
for NWS, and relatively uniform for ER graphs. For lowest degree
ampliﬁers, the expected number of mutants grows faster early on in
Barabási–Albert graphs, but it plateaus earlier than and is eventually surpassed by the slower growing expected number of mutants
in the Erdős–Rényi, and Newmann–Watts–Strogatz graphs. Such
insights into the evolutionary process may be crucial in applications, e.g. when one may be more interested in achieving highest
number of mutants in a short amount of time rather than highest
number of mutants as t→ ∞ or vice versa.
Finally, thus far we have only considered strongly connected
graphs in which the vertex probabilities converge as t→ ∞, but this
is not the case for some non-strongly connected graphs. We have
thus also investigated the expected number of mutants over time
for some simple cases of such graphs. Consider a random graph
that is strongly connected, and then have a resident node (rn) and
mutant node (mn) connected with only directed edges into the

142

P. Shakarian et al. / BioSystems 111 (2013) 136–144

Fig. 3. Expected number of mutants over time starting with a single mutant placed on a graph for Barabási–Albert preferential attachment (BAR), Erdős–Rényi (ERD), and
Newmann–Watts–Strogatz small world (NWS) graphs. Lines are averages over 50 random graphs of each type. In the left graph, mutants are placed at the highest degree
nodes, which are suppressors. In the right graph, mutants are placed at lowest degree nodes, which are ampliﬁers.

strongly connected graph. Clearly, the vertex probabilities cannot
converge, since ∀t, Pmn,t = 1 and Prn,t = 0. Our experimental results
in Fig. 4 show however that while the vertex probabilities do not
converge, the value for the expected number of mutants given by
our algorithm seems to converge. What value the expected number of mutants converges to depends on the relative degrees of
the nodes that the mutant node mn and resident node rn connect
to. We shall call these nodes con mn and con rn, respectively. If
kcon mn ≈ kcon rn , the expected value of mutants converges at around
50% of the graph’s nodes. If kcon mn > kcon rn , the expected value of
mutants is less than 50% of the graph’s nodes, and conversely,
if kcon mn < kcon rn , it is greater. These results are intuitive because
lower degree nodes are better spreaders under BD updating. These
results are also interesting because the expected value converges
– even though the graphs are not strongly connected. By an examination of Eq. (6), this convergence is possible. However, we have
not proven that convergence always occurs. An interesting direction for future work is to identify under what conditions will the
expected number of mutants converges in a non-strongly connected graph.

7.4. Experimentally computing the lower bound of the mean time
to ﬁxation
We also performed experiments to examine the lower bound on
mean time to ﬁxation (discussed in Section 6) as compared to the
average ﬁxation time determined from simulation run. In doing so,
we were able to conﬁrm the lower-bound experimentally. We were
able to use Algorithm 1-ACC to compute the lower bound with a
few changes (noted in the supplement).
We generated random (ER) graphs of size 10, 20, 50 and 100
nodes, creating ﬁve different graphs for each number of nodes. The
graphs were generated as in our convergence experiments, and our
comparison to Monte Carlo testing are shown in Fig. 5 where we
demonstrate experimentally that our algorithm produces a lower
bound. Our algorithm was run until the standard deviation of ﬁxation probabilities for all vertices was 2.5 × 10−6 . The Monte Carlo
simulations were each set at 10,000 runs.
8. Application: competition among neural axons
In recent work, Turney and Lichtman (2012) created a model for
synaptic competition based on death–birth updating under neutral

Fig. 4. Expected number of mutants over time for an Erdős–Rényi graph of 100
nodes, with an extra muntant node (mn) and resident node(rn) with directed edges
to con mn and con rn respectively. The value that the expected number of mutants
converges to depends on the relative degrees of con mn and con rn, as shown in
the legend.

Fig. 5. Mean-time-to-ﬁxation comparison between algorithm and simulation. Note
that the y-axis is a logarithmic scale.

P. Shakarian et al. / BioSystems 111 (2013) 136–144

drift. They noted that the model aligns well with their empirical
observations. In the model, the graph represents a synaptic junction and the nodes represent sites in the junction. For every two
adjacent sites in the synaptic junction, there is an undirected edge
between the corresponding two nodes in the graph. Hence, in- and
out-degrees of each node are the same. Initially, there are K different axon types located in the junction conﬁgured in a manner
where all sites are initially occupied by one axon type. At each time
step, an axon occupying one of the sites is eliminated – making the
site open. The selection of the axon for elimination (death) is with a
uniform probability. Hence, there is no bias in this model. Following
the elimination of an axon, an adjacent axon grows into the site. The
adjacent axon is selected with a uniform probability of the eliminated axon’s neighbors. Hence, based on the results of this paper,
we can provide the following insights into synaptic competition.
1. After t axons are eliminated,1 the probability of any site being
occupied by an axon of a certain type can be calculated directly
by Eq. 8. Even though there are K axon types, this theorem still
applies as it only considers the probability of a node being a
mutant (resp. a site being a one of the K axon types).
2. Using point 1 above, we can determine the expected number of
axons of a given type after t axons being eliminated.
3. After t axons are eliminated, the probability of any set of sites
being occupied by a certain axon type is simply the sum of the
probabilities of the individual sites being occupied by that axon.
As a result, the ﬁxation probability is additive.
4. Leveraging point 3 above combined with an easy modiﬁcation
of the result of Broom et al. (2010) for the BD model, the ﬁxation
probability of an axon originating at site i is ki /2 ·  where ki
is the number of sites adjacent to site i (hence the degree of
node i in the corresponding graph) and  is the total number of
adjacencies in the synapse (hence, half the number of directed
edges in the corresponding graph).
5. Based on item 4 above and the results from Section 3, we can
conclude that for a given axon type (let’s call it “axon type A”)
occupying a set of sites, that if the average adjacencies of those
sites is greater than (resp. less than) the overall average adjacencies for the sites in the entire synaptic junction, then as the
number of eliminated axons approaches inﬁnity, we can expect
the number of axon type A in the synaptic junction will increase
(resp. decrease) in expectation.
6. We can directly apply Theorem 7 to ﬁnd a lower-bound on the
number of eliminated axons before ﬁxation occurs.
We note that the results stated above are either precise mathematical arguments or calculations that can be found exactly with a
deterministic algorithm. They are not theoretical approximations
and do not rely on simulation. As such is the case, we can make more
precise statements about synaptic competition (given the model)
and can avoid the variance that accompanies simulation results.
Insights such as these may lead to future biological experiments.
9. Related work
Evolutionary graph theory was originally introduced in
Lieberman et al. (2005). Previously, we have compiled a comprehensive review (Shakarian et al., 2012) for a general overview of
the work in this exciting new area.
While most work dealing with evolutionary graphs rely on
Monte Carlo simulation, there are some good analytical approximations for the undirected/unweighted cased based on the

1
Note that the number of axons eliminated corresponds directly to the number
of timesteps in the model.

143

degree of the vertices in question. Antal et al. (2006) use the
mean-ﬁeld approach to create these approximations for the undirected/unweighted case. Broom et al. (2010) derive an exact
analytical result for the undirected/unweighted case in neutral
drift, which agrees with the results of Antal et al. They also show
that ﬁxation probability is additive in that case (a result which
we extend in this paper using a different proof technique). However, the results of Masuda and Ohtsuki (2009) demonstrate that
mean-ﬁeld approximations break down in the case of weighted,
directed graphs. Masuda (2009) also studied weighted, directed
graphs, but does so by using Monte Carlo simulation. Rychtář and
Stadler (2008) derive exact computation of ﬁxation probability
through means of linear programming. However, that approach
requires an exponential number of both constraints and variables
and is intractable. The recent work of Voorhees (2012) introduces
a parameter called graph determinacy which measures the degree
to which ﬁxation or extinction is determined while starting from
a randomly chosen initial conﬁguration. This property is then
used to analyze some special cases of evolutionary graphs under
birth–death updating. There has been some work on algorithms for
ﬁxation probability calculation that rely on a randomized approach
(Barbosa et al., 2010; Díaz et al., 2012). Barbosa et al. (2010) present
a heuristic technique for speeding up Monte Carlo simulations by
early termination while Díaz et al. (2012) present utilize simulation runs in a fully polynomial randomized approximation scheme.
However, our framework differs in that it does not rely on simulation at all and provides a deterministic result. Further, our
non-randomized approach also allows for additional insights into
the evolutionary process – such as monitoring the expected number of mutants as a function of time. Recently, Houchmandzadeh
and Vallade (2011) study the related problem of determining the
probability of ﬁxation given a single, randomly placed mutant in the
graph where the vertices are “islands” and there are many individuals residing on each island in a well-mixed population. They use
quasi-ﬁxed points of ODE’s to obtain an approximation of the ﬁxation probability and performed experiments with a maximum of
5 islands (vertices) containing 50 individuals each. This continuous
approximation provides the best results when the number of individuals in each island is much larger than the number of islands.
As the problem of this paper can be thought of as a special case
where each island has just one individual, it seems unlikely that the
approximation of Houchmandzadeh and Vallade’s approach will
hold here.
Some of the results in this paper were previously presented
in conferences by the authors (Shakarian and Roos, 2011; Moores
and Shakarian, 2012). The analysis and experiments concerning the
expected number of mutants at a given time, the extension of the
framework for other update rules (beyond birth–death), the use of
the framework for the case of r > 1, and the neurology applications
are all new results appearing for the ﬁrst time in this paper.
10. Conclusion
In this paper, we introduced a new approach to deal with
problems relating to evolutionary graphs that rely on “vertex probabilities.” Our presented analytical method is the ﬁrst deterministic
method to compute ﬁxation probability and provides a number of
novel uses and results for EGT problems:
• Our method can be used to solve for the ﬁxation probability under
neutral drift orders of magnitude faster than Monte Carlo simulations, which is currently the presiding employed method in
EGT studies. We have extended the method to all of the commonly used update processes in EGT. The special case of neutral
drift is not only of interest in the literature (Broom et al., 2010;

144

•

•

•

•

P. Shakarian et al. / BioSystems 111 (2013) 136–144

Masuda, 2009) but also it has been applied to problems in neurology (Turney and Lichtman, 2012).
While the presented method is currently constrained to the case
of neutral drift, we have demonstrated how it can inform cases
of non-neutral drift by using it to provide both a lower and
upper bound for this case. Combined with our analytical method’s
speed, this means that it can be used to acquire useful knowledge
to guide general EGT studies interested in the case of advantageous mutants.
We have shown how our analytical method can be used to calculate a non-trivial lower bound to the mean time to ﬁxation,
providing a ﬁrst step for a general method to computing this and
related quantities that is lacking in the current literature.
We have shown how our method can be used to calculate deterministically the expected number of mutants, which is useful for
applications that require predictions on the number of mutants
in the population under a speciﬁc ﬁnite time horizon. We have
also provided results on the expected number of mutants on
different common graph topologies, showing differences in the
growth trajectories of ampliﬁers and suppressors on these different topologies. These results may prove highly signiﬁcant in
the recent application of EGT to distributed systems (Jiang et al.,
2012) where the problem of information diffusion is considered
among computer systems. In such a domain, it may be insufﬁcient to guarantee ﬁxation in the limit of time – which may be
impractical – but rather to make guarantees on the outcome of
the process after a ﬁnite amount of time.
Finally, we have shown how our method can provide insight
when applied to the problem of synaptic competition in neuroscience.

Though evolutionary graph theory is still a relatively new
research area, it is actively being studied in a variety of disciplines
(Lieberman et al., 2005; Shakarian et al., 2012; Zhang et al., 2007;
Sood et al., 2008; Pacheco et al., 2006; Turney and Lichtman, 2012;
Jiang et al., 2012). We believe that more real-world applications will
appear as this area gains more popularity. As illustrated by recent
work (Turney and Lichtman, 2012; Jiang et al., 2012), experimental
scientists with knowledge of EGT may be more likely to recognize
situations where the model may be appropriate. As these cases
arise, deterministic methods for addressing issues related to EGT
may prove to be highly useful. However, this paper is only a starting
point – there are still many important directions for future work.
Foremost among such topics are scenarios where the topology of
the graph also changes over time or where additional attributes of
the nodes/edges in the graph affect the dynamics.
Acknowledgments
P.S. is supported by ARO projects 611102B74F and 2GDATXR042
as well as OSD project F1AF262025G001. P.R. is supported by ONR
grant W911NF0810144. P.S. would like to thank Stephen Turney
(Harvard University) for several discussions concerning his work.
The opinions in this paper are those of the authors and do not necessarily reﬂect the opinions of the funders, the U.S. Military Academy,
the U.S. Army, or the U.S. Navy.

Appendix A. Supplementary data
Supplementary data associated with this article can be found,
in the online version, at http://dx.doi.org/10.1016/j.biosystems.
2013.01.006.
References
Antal, T., Redner, S., Sood, V., 2006. Evolutionary dynamics on degree-heterogeneous
graphs. Phys. Rev. Lett. 96 (18), 188104.
Antal, T., Scheuring, I., 2006. Fixation of strategies for an evolutionary game in ﬁnite
populations. Bull. Math. Biol. 68, 1923–1944.
Barabási, A., Albert, R., 1999. Emergence of scaling in random networks. Science 286
(5439), 509–512.
Barbosa, V.C., Donangelo, R., Souza, S.R., 2010. Early appraisal of the ﬁxation probability in directed networks. Phys. Rev. E 82 (October (4)), 046114.
Broom, M., Hadjichrysanthou, C., Rychtář, J., 2009. Evolutionary games on graphs and
the speed of the evolutionary process. Proc. R. Soc. A 466 (2117), 1327–1346.
Broom, M., Hadjichrysanthou, C., Rychtář, J., Stadler, B.T., 2010 Apr. Two results on
evolutionary processes on general non-directed graphs. Proc. R. Soc. A: Math.
Phys. Eng. Sci. 466 (2121), 2795–2798.
Broom, M., Rychtář, J., 2009. An analysis of the ﬁxation probability of a mutant on
special classes of non-directed graphs. Proc. R. Soc. A 464 (May), 2609–2627.
Broom, M., Rychtář, J., Stadler, B., 2011. Evolutionary dynamics on graphs – the effect
of graph structure and initial placement on mutant spread. J. Stat. Theory Pract.
5 (3), 369–381.
Díaz, J., Goldberg, L., Mertzios, G., Richerby, D., Serna, M., Spirakis, P., January
2012. Approximating ﬁxation probabilities in the generalized Moran process.
In: Proceedings of the ACM-SIAM Symposium on Discrete Algorithms (SODA),
Kyoto, Japan. ACM.
Erdős, P., Rényi, A., 1960. On the Evolution of Random Graphs. Mathematical Institute
of the Hungarian Academy of Sciences, pp. 17–61.
Houchmandzadeh, B., Vallade, M., 2011. The ﬁxation probability of a beneﬁcial mutation in a geographically structured population. New J. Phys. 13 (July (7)), 073020
http://stacks.iop.org/1367-2630/13/i=7/a=073020
Jiang, C., Chen, Y.C., Liu, K.J.R., December 2012. Distributed Adaptive Networks: A
Graphical Evolutionary Game-Theoretic View. arXiv:1212.1245.
Lieberman, E., Hauert, C., Nowak, M.A., 2005. Evolutionary dynamics on graphs.
Nature 433 (7023), 312–316.
Masuda, N., 2009. Directionality of contact networks suppresses selection pressure
in evolutionary dynamics. J. Theor. Biol. 258 (2), 323–334.
Masuda, N., Ohtsuki, H., 2009. Evolutionary dynamics and ﬁxation probabilities in
directed networks. New J. Phys. 11 (3), 033012 (15 pp.).
Moores, G., Shakarian, P., 2012. A fast and deterministic method for mean time to
ﬁxation in evolutionary graphs. Presented at INSNA Sunbelt XXXII, Redondo
Beach, CA.
Moran, P., 1958. Random processes in genetics. Math. Proc. Cambridge Philos. Soc.
54 (01), 60–71.
Newman, M., Watts, D., 1999. Renormalization group analysis of the small-world
network model. Phys. Lett. A 263 (4–6), 341–346.
Pacheco, J.M., Traulsen, A., Nowak, M.A., 2006. Active linking in evolutionary games.
J. Theor. Biol. 243 (December (3)), 437–443.
Paley, C.J., Taraskin, S.N., Elliott, S.R., 2007. Temporal and dimensional effects in
evolutionary graph theory. Phys. Rev. Lett. 98, 098103.
Rychtář, J., Stadler, B., 2008. Evolutionary dynamics on small-world networks. Int. J.
Comput. Math. Sci. 2 (Winter (1)).
Shakarian, P., Roos, P.,November 2011. Fast and deterministic computation of ﬁxation probability in evolutionary graphs. In: CIB’11: The Sixth IASTED Conference
on Computational Intelligence and Bioinformatics. IASTED.
Shakarian, P., Roos, P., Johnson, A., 2012. A review of evolutionary graph theory with applications to game theory. Biosystems 107 (2), 66–80 http://www.
sciencedirect.com/science/article/pii/S0303264711001675
Sood, V., Antal, T., Redner, S., 2008. Voter models on heterogeneous networks. Phys.
Rev. E 77 (4), 041121.
Turney, S., Lichtman, J., 2012. Reverseing the outcome of synapse elimination at
developing neuromuscular junction in vivo: evidence for synaptic competition
and its mechanism. PLoS Biol. 10 (June).
Voorhees, B. Birth–death ﬁxation probabilities for structured populations. Proc. R.
Soc. A: Math. Phys. Eng. Sci., in press.
Zhang, P.A., Nie, P.Y., Hu, D.Q., Zou, F.Y., 2007. The analysis of bi-level evolutionary
graphs. Biosystems 90 (3), 897–902.

KSGM: Keynode-driven Scalable Graph Matching
Xilun Chen, K. Selçuk Candan

Maria Luisa Sapino

Paulo Shakarian

Arizona State University
Tempe, AZ, USA
{xilun.chen, candan}@asu.edu

University of Torino
Torino, Italy
marialuisa.sapino@unito.it

Arizona State University
Tempe, AZ, USA
shak@asu.edu

ABSTRACT
Understanding how a given pair of graphs align with each other
(also known as the graph matching problem) is a critical task in
many search, classification, and analysis applications. Unfortunately, the problem of maximum common subgraph isomorphism
between two graphs is a well known NP-hard problem, rendering
it impractical to search for exact graph alignments. While there
are several heuristics, most of these analyze and encode global and
local structural information for every node of the graph and then
rank pairs of nodes across the two graphs based on their structural
similarities. Moreover, many algorithms involve a post-processing
(or refinement) step which aims to improve the initial matching
accuracy. In this paper 1 we note that the expensive refinement
phase of graph matching algorithms is not practical in any application where scalability is critical. It is also impractical to seek
structural similarity between all pairs of nodes. We argue that a
more practical and scalable solution is to seek structural keynodes
of the input graphs that can be used to limit the amount of time
needed to search for alignments. Naturally, these keynodes need to
be selected carefully to prevent any degradations in accuracy during the alignment process. Given this motivation, in this paper,
we first present a structural keynode extraction (SKE) algorithm and
then use structural keynodes obtained during off-line processing
for keynode-driven scalable graph matching (KSGM). Experiments
show that the proposed keynode-driven scalable graph matching algorithms produce alignments that are as accurate as (or better than)
the state-of-the-art algorithms, with significantly faster online executions.

1.

!"#$%&'&

!"#$%&(&

Figure 1: Graph matching/alignment problem seeks a maximum common subgraph isomorphism between two input graphs
they represent the pairwise relationships between the nodes of the
graph. Edges can be directed or undirected, meaning that the relationship can be non-symmetric or symmetric, respectively. Nodes
and edges of the graph can also be labeled or non-labeled. The
label of an edge, for example, may denote the name of the relationship between the corresponding pair of nodes or may represent
other meta-data, such as the certainty of the relationship or the cost
of leveraging that relationship within an application.
Due to the success of the graph model as a powerful and flexible data representation, graph analysis and search tasks are also
increasingly critical in many application domains. In particular,
understanding how a given set of graphs align with each other (also
known as the graph matching/alignment problem, Figure 1) forms
the core task in many search, classification, and analysis applications. Unfortunately, the problem of maximum common subgraph
isomorphism between two graphs is a well known NP-hard problem [24], making it impractical to search for exact or maximal
graph alignments. As a result, while there are some attempts to
improve the performance of exact maximum common subgraph
matching solutions [23], most of the recent efforts in the area have
focused on seeking approximate/inexact graph alignments [3, 18,
22, 19, 29].
While these algorithms differ in their specific techniques, most
of them rely on a four phase process:

INTRODUCTION

Graphs have been used to represent a large variety of complex
data, from multimedia objects, social networks, hypertext/Web,
knowledge graphs (RDF), mobility graphs,to protein interactions.
Let D be a set of entities of interest, a graph, G(V, E), defined over
V = D describes the relationships between pairs of objects in D.
The elements in the set V are referred to as the nodes or vertices of
the graph. The elements of the set E are referred to as the edges and
1
This work is supported by NSF Grants #1339835 and #1318788.
This work is also supported in part by NSF grant #0856090.

1. First, the matching algorithm analyzes and encodes the
global structural information (for example a spectral signature [23]) corresponding to the nodes of the graph.
2. Secondly, the algorithm analyzes and encodes the local structural information (such as neighborhood degree distribution [29]) for the nodes of the graph.
3. Once these global and local signatures are encoded, the
matching algorithm compares the signatures of pairs of
nodes across the given graphs to rank these pairs of nodes
(for example using a stable matching algorithm, like the Hungarian algorithm [16]) based on their overall structural similarities.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from Permissions@acm.org.
CIKM’15, October 19–23, 2015, Melbourne, Australia.
c 2015 ACM. ISBN 978-1-4503-3794-6/15/10 ...$15.00.

DOI: http://dx.doi.org/10.1145/2806416.2806577.

1101

)&

)&
)&

)&

)&
)&

*&

)&
)&

!"#$%&'&

)&

)&
)&

)&

!"#$%&(&

Figure 2: Keynode selection problem for scalable graph matching: the nodes marked with "*" are keynodes of the input
graphs that can be used to reduce the amount of time needed to
search for alignments
4. Finally, a post-processing, or refinement, step (involving, for
example, a vertex cover operation) is used to improve the
accuracy of the initial matching [29].

2.

BACKGROUND AND RELATED WORK

In this section, we review key concepts related to the graph
matching problem and discuss the existing algorithms.
Graph Isomorphism: Given two graphs G and H, G is isomorphic to H if there exists a bijective mapping from the nodes of G
to the nodes H that preserves the edge structure [13]: for any two
vertices that are adjacent on G, the vertices they are mapped to are
also adjacent on H, and vice versa.
Subgraph Isomorphism: Subgraph isomorphism seeks a bijective
function, f , such that there is a subgraph G0 of G and a subgraph
H 0 of H, such that G0 is isomorphic to H 0 , with respect to f .
Maximum Common Subgraph Isomorphism: Maximum common subgraph isomorphism seeks the largest subgraph of G isomorphic to a subgraph of H [24]. Intuitively, the larger the maximum common subgraph of two graphs is, the more similar the
graphs are to each other.
One of the first exact graph matching algorithms was proposed
by Ullman [24]. An alternative way to search for a matching between two graphs is to rely on graph edit distance algorithms:
given two graphs the corresponding graph edit distance is the least
cost sequence of edit operations that transforms G1 into G2 . Commonly used graph edit operations include substitution, deletion, and
insertion of graph nodes and edges. Unfortunately, the graph edit
distance problem is also known to be NP-complete [24]. In fact,
even approximating graph-edit distance is very costly; the edit distance problem is known to be APX-hard [8]. [8] shows that graph
isomorphism, subgraph isomorphism, and maximum common subgraph problem are special instances of the graph edit distance computation problem. Many subgraph isomorphism search algorithms
have been developed, such as [15, 29, 14].
Approximate Graph Matching: In order to be applicable to large
graphs, many heuristic and approximate graph matching algorithms
have been proposed.
While, as we discussed above, graph matching through edit distance computation is an expensive task, there are various heuristics
that have been developed to perform this operation more efficiently.
GraphGrep [14] is one such technique, relying on a path-based
representation of graphs. GraphGrep takes an undirected, nodelabeled graph and for each node in the graph, it finds all paths that
start at this node and have length up to a given, small upper bound,
lp . Given a path in the graph, the corresponding id-path is the list
of the ids of the nodes on the path. The corresponding label-path is
the list of the labels of the nodes on the path. The fingerprint of the
graph, then, is a hash table, where each row contains the hash of the
label-path and the corresponding number of id-paths in the graph.
Irrelevant graphs are filtered out by comparing the numbers of idpaths for each matching hash key and by discarding those graphs
which have at least one value in its fingerprint less than the corresponding value in the fingerprint of the query. Matching sub-graphs
are found by focusing on the parts of the graph which correspond
to the label-paths in the query. After, the relevant id-path sets are

Unfortunately, many of these steps result in significant scalability
challenges in terms of the matching time needed to compare the
pairs of nodes:
• In particular, the expensive refinement phase of graph matching algorithms is not practical in applications where scalability of the graph matching operation is critical.
• Moreover, especially in very large graphs, it is also impractical to seek pairwise structural similarities for all node pairs
during the graph matching process.

1.1

Organization of this Paper

The paper is organized as follows: in the next section, we first
introduce basic concepts and review existing graph matching algorithms. In Section 3, we provide overviews of the general graph
matching process as well as the proposed keynode-driven scalable
graph matching (KSGM) algorithm. Then, in Section 4, we present
our structural keynode extraction (SKE) algorithm. In Sections 5
and 6, we discuss how to use these structural keynodes for obtaining graph alignments. We discuss the complexity of the proposed algorithms and parallelization opportunities in Section 7. We
present experimental evaluations with various real and synthetic
data sets in Section 8. These confirm that the proposed approximate graph matching algorithm is highly effective and efficient.
Finally, we conclude the paper in Section 9.

)&

)&
)&
)&

1.2

)&

Contributions of this Paper

Based on these observations, in this paper, we argue that a more
practical and scalable solution would be to seek structural keynodes of the input graphs that can be used to reduce the amount of
time needed to search for alignments (Figure 2). Of course, these
keynodes must be selected carefully to prevent any degradations in
accuracy during the alignment process, especially because, as mentioned above, refinement post-processes are detrimental to scalability of matching algorithms.
Given this motivation, in this paper, we first present a highly efficient and effective structural keynode extraction (SKE) algorithm.
The SKE algorithm, which is executed off-line, relies on a 3-step
process:
1. In the first step, a PageRank algorithm [7] is ran to associate
a structural score to each node in the graph.
2. In the second step, a scale-space (based on a difference-ofGaussians (DoG) function defined over different scales of the
graph) is constructed.
3. In the third step, keynode candidates are extracted by analyzing the resulting scale-space for extrema of the DoG function and a subset of these candidates are selected as structural
keynodes.
We then propose a graph matching algorithm that uses these structural keynodes (obtained during off-line processing) for keynodedriven scalable graph matching (KSGM). In particular, KSGM extracts only local signatures and relies on the structural keynodes for
fast node-to-node similarity searching. In addition, we also show
that this keynode-driven approach not only reduces the number of
comparisons that need to be performed online, but it also enables
effective matching, even without having to rely on an expensive assignment algorithm, like the Hungarian algorithm (with O(|V |3 )
complexity). Experiment results show that the proposed structural
keynode extraction and keynode-driven scalable graph matching
algorithms produce alignments that are as accurate as (or better
than) the state-of-the-art algorithms, while requiring significantly
less online execution time without refinement.

1102

Algorithm 1 Overview of keynodes based graph matching
Input:
A set G = {G1 , G2 , ...Gg } of graphs
A query graph Gq ∈ G.
Output:
Rank Gi ∈ G in terms of matching quality
Offline process:
1: for all Gi ∈ G (including Gq ) do
2:
Perform structural keynode extraction (SKE) for Gi
3:
Extract local-signatures for all nodes in Gi
4:
(Optional) Extract global-signatures for all nodes in Gi
5: end for
Online process:
6: for all Gi ∈ G do
7:
Compute local similarities for keynode pairs from Gi and
Gq .
8:
(Optional) Compute global similarities for keynode pairs
from Gi and Gq and combine these with local similarities.
9:
Select anchors to obtain a base matching
10:
Expand the base matching to obtain Mq,i
11:
Compute matching quality, quality(Mq,i )
12: end for
13: Rank Gi ∈ G in terms of quality(Mq,i )

selected and overlapping id-paths are found and concatenated to
build matching sub-graphs.
A common method to obtain an approximate graph matching
is to use the eigenvectors derived from the adjacency matrix of
the graph [23]: intuitively, two similar graphs should have similar eigenvectors; moreover, if we construct a |V | × |V | matrix (for
example the Laplacian of the graph or a matrix encoding node distances) and decompose it into three matrices of |V | × c, c × c,
and c × |V | elements using an eigen-decomposition technique like
SVD, the c-length vector corresponding the node v ∈ V can be
used as a global-signature corresponding to node v. Once node-tonode similarities are computed, an assignment is usually found using an assignment algorithm, such as the Hungarian algorithm [16],
which uses a primal-dual strategy to solve this problem in O(|V |3 )
time. This simple observation, led to several works leveraging different global-signatures for identifying node matches across different graphs [3, 18, 22, 19, 29]. [28] formulates the labeled weighted
graph matching problem in the form of a convex-concave program,
which searches for appropriate permutation matrices by solving a
least-square problem. In addition, feature selection techniques are
used for more accurate calculation [11, 12, 20]. In order to improve
matching accuracy, [29] proposes to enrich the global-signatures
associated to the graph nodes with local-signatures, encoding the
properties of the immediate neighborhood of each node.

3.

OVERVIEW OF KEYNODE-DRIVEN
GRAPH MATCHING

combines (by multiplying) the global and local similarities
of each pair of nodes into a single value, thereby quantifying
the overall similarity of the pair.
4. Once the overall similarities for |Vq | × |Vi | pairs of nodes
are computed, [29] drops node pairs with small degrees and,
then, expands the remaining set of anchor pairs by adding,
in an iterative manner, immediate good nearby pairs to this
anchor set.
5. When no more pairs can be added to the anchor set, [29] uses
the Hungarian algorithm to identify an initial node matching
in O(max{|Vq |, |Vi |}3 ) time.
6. Finally, as a post-processing step, [29] applies a vertex cover
based refinement, which explores different subsets of the
nodes and searches for better alignments than the one initially identified. In particular, the algorithm seeks small vertex covers, which are likely to give the mismatched nodes additional chances to be refined. Note that since the minimum
vertex cover problem is known to be NP-hard, the algorithm
searches for minimal vertex covers in O(m×n3 ) time, where
m = min{|Eq |, |Ei |} and n = max{|Vq |, |Vi |}.

Given a set G = {G1 , G2 , ..., Gg } of graphs and a query graph
Gq ∈ G, in this paper, we seek the maximum graph matching between Gq and all Gi ∈ G (i 6= q). Note that the exact solution for
this problem is NP-hard [24]. Since we treat scalability as a key
constraint, we consider inexact solutions and rely on the matching quality measure proposed in [29] to evaluate the accuracies of
the resulting alignments: Let Gq (Vq , Eq ) be a query graph and let
Gi (Vi , Ei ) be a graph in G. Let Mq,i (Vq,i , Eq,i ) be a subgraph of
both Gq and Gi , returned by an inexact subgraph search algorithm.
[29] defines the matching quality function as follows:
quality(Mq,i ) =

|Eq,i |
,
min(|Eq |, |Ei |)

Intuitively, the quality function describes how similar the given
query graph Gq and known graph Gi are by using the ratio of
matched edges and the maximum number of edges that can be possibly matched, which is equal to the minimum number of edges between two graphs. In other words, the larger the number of edges
in the graph Mq,i , the better is the quality of the matching (or the
more similar the two graphs are).

3.1

This process includes a number of very expensive steps: The first
two steps, involving global and local analysis are expensive, but can
be performed off-line and indexed for later reuse assuming that the
graphs are available ahead of time. The last four steps, however,
need to be performed on-line, yet they consist of operations that
are quadratic or higher. In particular, the last refinement step, with
O(m × n3 ) time cost is impractical for most large data graphs.
In this paper, we note that Step 3 can be significantly sped up
if the similarity computations are limited to only a small subset of
the vertices in Vq and Vi (which we refer to as keynodes of Vq and
Vi ). However, the use of keynodes for node similarity computation
is not sufficient to reduce the overall complexity as, once the keynodes are identified and the keynode pairs set is expanded, solving
the assignment problem needed to return the matching would still
take O(max{|Vq |, |Vi |}3 ) time, if we were to apply the Hungarian
algorithm on the extracted keynodes. Therefore, we also need to reduce the time complexity of this step significantly. It is especially
important that the initial keynode based similarity computation is
accurate as we cannot afford a cubic algorithm like Hungarian algorithm to return a high-quality matching.

Challenges

Given a query graph Gq , our goal is to rank the graphs in G according to their matching similarities against Gq (and eventually
return the top few matches to the user). [29] solves this problem by
relying on a 6-step process, common to many graph search algorithms:
1. [29], first, analyzes the global structure of each graph
through eigen-decomposition of the graph Laplacian matrix
and encodes this in the form of a c-length vector associated
to each node in the graph.
2. Secondly, [29] encodes the structural information local to
each node, vj , in the form of an sj -length degree distribution vector, where sj is the number of nodes in the kneighborhood of the node.
3. Given the global and local signatures of all nodes in Gq and
Gi , [29] then computes the global and local similarities for
each pair of nodes from the two graphs, in O(|Vq | × |Vi | × c)
and O(|Vq | × |Vi | × maxvj (sj )) time, respectively. It then

1103

3.2

Outline of KSGM
Algorithm 1 illustrates an overview of the keynode-driven scalable graph matching (KSGM) process. In the rest of the paper, we
study each step in detail. First, in the next two sections, we focus on
the offline steps of KSGM, which involve identifying keynodes and
extracting local-signatures. The online steps of the KSGM algorithm
are discussed in Section 6.
4.

4.2

We note that the above alternative has a number of disadvantages:
• First of all, many of the structural significance measures,
such as PageRank, are not entirely robust against modifications in the graph. The PageRank score of a node, for example, can jump significantly, if a new edge connects the
sub-graph in which the node is contained to a high PageRank node in the graph.
• Secondly, common structural significance measures, like
PageRank, capture the significance of a node in the whole
graph and favor nodes that are overall central. However, this
may be disadvantageous as there is a possibility that smaller
scale, but distinct (and, therefore, useful for matching) structural features of the graph may be missed.
We therefore argue that we need a better alternative, which is both
robust and multi-scale. We build the proposed SKE algorithm based
on three key insights:
• Robustness: Even when the PageRank scores of the nodes
themselves vary due to graph transformations, such as edge
insertions and removals, a given node’s PageRank score relative to the scores of the nodes in its neighborhood is likely
to be stable.
• Structural distinctiveness: A node is structurally distinctive
in its neighborhood, if "the relationship between its PageRank score to the PageRank scores of its neighbors" is different from the "relationships between the node’s neighbors’ PageRank scores and the PageRank scores of their own
neighbors".
• Multi-scale: Since we do not know the scale of the structurally distinctive features of the graph, we need to search
for features of potentially different sizes.
It is important to note that similar requirements also exist in
other application domains. For example, algorithms for extracting such robust, local features have been developed for 2D images
(SIFT [21]), uni-variate time series [9], and multi-variate time series [25]. In this paper, we argue that a similar process can be used
to identify keynodes (corresponding to robust, multi-scale structural features) of a graph, if the nodes are annotated with PageRank
scores ahead of the time. Let G(V, E, p) be a PageRank-labeled
graph, where p() is a mapping from the nodes to the corresponding PageRank scores. What makes the problem of extracting local features from PageRank-labeled graphs challenging is that the
concepts of neighborhood, gradient, and smoothing are not welldefined for graphs.
Therefore, before we describe the keynode extraction process,
we describe how to smooth a PageRank-labeled graph. Intuitively,
smoothing the graph with respect to the scores associated to the
graph nodes creates versions of the given graph at different resolutions and, thus, helps identify features with different amounts of
details.

STRUCTURAL KEYNODE EXTRACTION

In this section, we propose an off-line structural keynode extraction (SKE) algorithm which identifies Θ% (where Θ is a user
provided parameter) of the nodes in V as the keynode set, K, of
a given graph, G(V, E) to support scalable graph matching. The
proposed SKE algorithm has a number of advantages: (a) First of
all, the identified keynodes are robust against noise, such as random edge insertion/removal; and (b) the identified nodes represent
structural features of the graph of different sizes and complexities
(i.e., correspond to neighborhoods of different sizes).

4.1

Proposed Solution - Robust Keynode Extraction through Scale Space Analysis

Naive Solution - Selecting Structural
Keynodes based on Node Significance

As described above, the keynodes of the graph need to represent
the structural properties of the graph well (i.e., extracted keynodes
need to be structurally significant in the graph) to support effective
matching. Therefore, the first alternative is to rely on traditional
node significance measures.
Measures like betweenness [26] and the centrality/cohesion [5],
help quantify how significant any node is on a given graph based on
the underlying graph topology. The betweenness measure [26], for
example, quantifies the number of shortest paths that pass through
a given node. The centrality/cohesion [5] measures quantify how
close to a clique the given node and its neighbors are. Other authority, prestige, and prominence measures [4, 7, 5] quantify the
significance of the node in the graph through eigen-analysis or random walks, which help measure how reachable a node is in the
graph. PageRank [7] is one of the most widely-used random-walk
based methods for measuring node significance and has been used
in a variety of application domains, including web search, biology,
and social networks. The basic thesis of PageRank is that a node
is important if it is pointed to by other important nodes – it takes
into account the connectivity of nodes in the graph by defining the
score of the node vi ∈ V as the amount of time spent on vi in a sufficiently long random walk on the graph. Given a graph G(V, E),
the PageRank scores are represented as ~r, where
~r = αTG~r + (1 − α)~t
where TG is a transition matrix corresponding to the graph G, ~t is
a teleportation vector (such that ~t[i] = |V1 | ), and α if the residual
probability (or equivalently, (1 − α) is the so-called teleportation
probability). Unless the graph is weighted, the transition matrix,
TG , is constructed such that for a node v with k (outgoing) neighbors, the transition probability from v to each of its (outgoing)
neighbors will be 1/k. If the graph is weighted, then the transition probabilities are adjusted in a way to account for the relative
weights of the edges.
Therefore, as the first alternative, we consider a PageRank based
keynode selection scheme: in this scheme, given a graph G(V, E),
we would (a) first identify the PageRank scores, p(vi ), of all vi ∈
V , then (b) we would rank the nodes in non-increasing order of
PageRank scores, and finally, (c) we would return the top Θ% of
the nodes in V as the keynode set, K.

4.2.1

Gaussian Smoothing of a PageRank-Labeled
Graph

1D or 2D data are commonly smoothed by applying a convolution operation with a Gaussian window. For example, if Y =
ht0 , t1 , . . . , tl i is a time series data and σ is a smoothing parameter,
its smoothed version, Ỹ (t, σ), is obtained through G(t, σ) ∗ Y (t)
where ∗ is the convolution operation in t and G(t, σ) is the Gaussian function
−t2
1
G(t, σ) = √
e 2σ2 .
2πσ
Essentially, the Gaussian smoothing process takes a weighted
average of values of the points in the vicinity of a given point, t.

1104

The closer a point to t, the higher is the weight. Therefore, in order
to implement a similar Gaussian smoothing of the given graph, we
first need to define a distance function to measure how close different nodes are to each other. Common applicable definitions of
node distance include the hop distance (determined by the shortest
edge distance between the nodes on the given graph) or hitting distance [10]. In this paper, we use hop distance to measure how far
nodes are to each other:

!"#$%"&'()"*+$,(,-../0$1(23/0(4#$%"&'4!"((

6!"77(6.8(9$)$*(!"
!"#$%"&'()"*+$,(,-../0$1(23/0(4!75(

• Nj , for j ≥ 0, is an n × n 0, 1-valued matrix, where for a
given node vi in the graph, G, the ith row in the matrix, Nj
is 1 only for nodes that have node distance exactly j from the
node vi , and

!#

!"""""#

D EFINITION 1 (N ODE D ISTANCE M ATRIX ). Let us be given
a graph G(V, E) with n nodes. The ordering among the nodes is
described through a set of node distance matrices, Nj , where

6!75(77(6.8(9$)$*(;!75<(

6:(77(6.8(9$)$*(:(

!"#$%"&'()"*+$,(,-../0$1(23/0(45(

65(77(6.8(9$)$*(5(
!"#$%"&'()"*+$,(,-../0$1(23/0(4-3&(

• Nj , for j ≤ 0, is an n × n 0, 1-valued matrix, where for a
given node vi , the ith column in the matrix, N(j, G) = 1
only for nodes that have distance exactly j on the inverted
graph, where all edges are inverted.


Figure 3: Computing the Difference-of-Gaussian (DoG) series
of the PageRank values of a graph

Intuitively, the cell Nj [v1 , v2 ] = 1 if the node v2 is exactly j hops
from v1 . When j is positive the hop-distance is measured following
outgoing edges, whereas when j is negative, incoming edges are
followed. Given this, we construct multiple scales of the given
graph G by using a Gaussian graph smoothing function defined as
follows.

Intuitively, the smoothing function S applies Gaussian smoothing
on the X values (associated with the nodes, vi ∈ V ) based on the
hop-distances between nodes and returns a vector
SG,σ (X) = hx̃(v1 ), x̃(v2 ), . . . , x̃(vn )i

D EFINITION 2 (G AUSSIAN G RAPH S MOOTHING F UNCTION ).
Let us be given a labeled graph G(V, E, x) and let
• σ be a smoothing parameter.
• X = hx(v1 ), x(v2 ), ..., x(vn )i be a vector encoding the labels associated with the nodes, vi ∈ V .
Then, if G is a directed graph, the non-normalized Gaussian graph

smoothing function, SG,σ
() is defined as
n
X

G(j, σ)Nj X
SG,σ (X) = G(0, σ)IX +

encoding the smoothed X values associated with the graph nodes.
Note that, since at a given hop distance there may be more than
one node, all the nodes at the same distance have the same degree
of contribution and the degree of contribution gets progressively
smaller as we get further away from the node for which the smoothing is performed.
Therefore, given a PageRank-labeled graph, G(V, E, p), and a
corresponding PageRank vector, P = hp(v1 ), p(v2 ), ..., p(vn )i,
encoding PageRank scores associated with the nodes, vi ∈ V , the
vector
SG,σ (P ) = hp̃(v1 ), p̃(v2 ), . . . , p̃(vn )i,

j=1

+

n
X

encodes the σ-smoothing of the PageRank-annotated graph,
G(V, E, p). We also say that SG,σ (P ) encodes the PageRank
scores of G at scale σ.
We next describe how to construct a scale-space for the given
graph through an iterative smoothing process leveraging the PageRank vector and the structure of the graph.

G(j, σ)Nj X,

j=1

where G(0, σ) is a Gaussian function with zero mean and σ standard deviation. If, on the other hand, G is an undirected graph, then
the non-normalized Gaussian graph smoothing function is

SG,σ
(X)

= G(0, σ)IX +

n
X

4.2.2

Graph Scale-Space Construction

The first step in identifying robust graph features is to generate a
scale-space representing versions of the given graph with different
amounts of details. In particular, building on the observation that
features are often located where the differences between neighboring regions (also in different scales) are large, we seek structural
features of the given graph at the extrema of the scale space defined
by the difference-of-the-Gaussian (DoG) series. More specifically,
given
• a PageRank-labeled graph, G(V, E, p),
• the corresponding vector, P = hp(v1 ), p(v2 ), ..., p(vn )i encoding the scores associated with the nodes, vi ∈ V ,
• a minimum smoothing scale, σmin ,
• a maximum smoothing scale, σmax ,
• the number, l, of levels of the scale space,
then, we compute a difference-of-Gaussians (DoG) series,
D(G, P, σmin , σmax , l) = {D1 , D2 , ..., Dl }, where each Di encodes the differences of two nearby scales separated by a multiplicative factor k:

2G(j, σ)Nj X.

j=1

Intuitively, S  applies Gaussian-based weighted averaging to the
entries of vector X based on the hop-distances2 . However, unlike
the basic Gaussian smoothing, during (non-normalized) relationship smoothing, there may be more than one node at the same distance and all such nodes have the same degree of contribution. As
a consequence, the sum of all contributions may exceed 1.0. Therefore, the normalized Gaussian graph smoothing function, S(G, σ),
discounts weights based on the number of nodes at a given distance:

 



SG,σ (X) = SG,σ
X ÷ SG,σ
1(n) ,
where 1(n) is an n-vector such that all values are 1 and “÷” is a
pairwise division operation.

2
In practice, since the Gaussian function drops fast as we move
away from the mean, we need to consider only a small window, w,
of hops

Di = SG,ki σmin (P ) − SG,ki−1 σmin (P ),

1105

56'
-2'

-3'

• DoG-neighbors numbered #2 and #7 correspond to the
DoG values of the same node at the previous and next levels of the scale space. Therefore, we have

!"#$%&'(),+'

-4'

Nhvi ,σj i [2] = Di−1 [j] and Nhvi ,σj i [7] = Di+1 [j].

!"#$%&'()'

-0'

7)869'

-+'

-.'

-1'
!"#$%&'()*+'

• In contrast, DoG-neighbors #3, #5, and #8 correspond to
the (average) DoG values of the forward neighbors of the
node vj , at the previous, current, and next levels of the scale
space, respectively. Therefore, we have

-/'

Nhvi ,σj i [3] = (FDi−1 ) [j],

Figure 4: Extrema detection

Nhvi ,σj i [5] = (FDi ) [j], Nhvi ,σj i [8] = (FDi+1 ) [j],
where k =

q
l

σmax
.
σmin

Figure 3 visualizes the process:

where, F is a row-normalized adjacency matrix accumulating
the (averaged) contributions of the nodes to their neighbors
along the forward edges.

• On the left hand side of the figure, we have the incrementally smoothed versions of the PageRank vector, P . Here,
the lowest level, SG,σmin (P ), corresponds to the most detailed version of the graph (with the least amount of smoothing), whereas SG,σmax (P ) corresponds to the least detailed
(most smoothed) version of the graph. In other words, σmin
determines the sizes of the smallest structural features we
can locate and σmax = kl σmin determines the sizes of the
largest structural features we can identify. In particular, since
under Gaussian smoothing, a diameter of 6σ would cover
∼ 99.73% of the weights, the diameter of the smallest structural feature that can be identified using SKE is ∼ 6σmin
hops, whereas the diameter of the largest feature would be
∼ 6σmax hops.

• Similarly, DoG-neighbors #1, #4, and #6 correspond to
the (average) DoG values of the backward neighbors at the
previous, current, and next levels of the scale space. Therefore, we have
Nhvi ,σj i [1] = (BDi−1 ) [j],
Nhvi ,σj i [4] = (BDi ) [j], Nhvi ,σj i [6] = (BDi+1 ) [j],
where, B is a row-normalized backward-adjacency matrix
(where all edges are reversed) accumulating the (averaged)
contributions of the nodes to their neighbors along the backward direction of the edges.
Given these, the pair hvj , σi i is an extremum (i.e., vj is a keynode
candidate at scale σi ), iff Di [j] is a local maximum

The number of levels, l, denotes the number of detail levels
(or scales) we explore between σmin and σmax . Intuitively,
each of these levels corresponds to a different target size for
the structural features of the graph.

Di [j] ≥ M AX Nhvj ,σi i [h]
1≤h≤8

• On the right hand side of the figure, we have the resulting
Difference-of-Gaussian (DoG) series, consisting of vectors,
D1 through Dl .

or it is a local minimum
Di [j] ≤ M IN Nhvj ,σi i [h].
1≤h≤8

Note that, intuitively, Di [j] measures how different the PageRank
values of the neighborhood around vj at scale σi−1 (= ki−1 σmin )
are from the PageRank values of the neighborhood around vj at
scale σi (= ki σmin ).
Therefore, a large Di [j] value would indicate a major structural
change when neighborhoods of different size around vj are considered (e.g., a node with a high PageRank score is included when
considering a neighborhood of larger scale). In contrast, a small
Di [j] indicates that there is minimal structural change when considering neighborhoods of different scales.

4.2.3

Intuitively, since Di [j] measures how different the PageRank values of the neighborhood around vj at scale σi are from the PageRank values of the neighborhood around vj at scale σi−1 , a local
maximum corresponds to a highly scale-sensitive region (amidst
relatively scale-insensitive regions), whereas a local minimum corresponds to a scale-insentive region (amidst more scale-sensitive
regions), of the graph.

4.2.4

Selecting the Best Keynodes

In the final step, we need to rank the keynode candidates and
Θ
return the top 100
× |V | of them, where Θ is a user provided parameter, as the keynode set, K. We propose Extremum Ranking to
select the best keynodes.
Since keynodes are located at the local extrema of the DoG series, we can rank the keynode candidates based on their extremum
score defined as follows: Let the pair hvj , σi i be a local extremum.
The corresponding extremum score, ξ(hvj , σi i), is defined as




if hvj , σi i is max.
 Di [j] − M AX Nhvj ,σi i [h]


1≤h≤8





 M IN Nhv ,σ i [h] − Di [j] if hvj , σi i is min.
j i

Identifying Keynode Candidates

As we mentioned earlier, our intuition is that a graph node is
structurally distinctive in its neighborhood, if "the relationship between its PageRank score to the PageRank scores of its neighbors"
is different from the "relationships between the node’s neighbors’
PageRank scores and the PageRank scores of their own neighbors,
at multiple scales". Therefore, to locate the keynode candidates,
we focus on the local extrema of the difference-of-Gaussian (DoG)
series D. More specifically, we identify hvj , σi i pairs where the
DoG value for node vj at scale, σi = ki σmin , is an extremium
(maximum and/or minimum) with respect to the neighbors of vj in
the same scale as well as neighbors in the previous and next levels
of the scale space.
In order to verify if the pair hvj , σi i is an extremium or not,
we compare Di [j] with the values corresponding to eight DoGneighbors in the scale-space, as visualized in Figure 4:

1≤h≤8

Intuitively, the higher the extremum score is, the better local extremum (and, thus, a better keynode) is hvj , σi i.

1106

5.

LOCAL NODE SIGNATURES

nbhd_sim(vi , vj ) proposed by [29] accounts for the alignment between the degree distributions in these neighborhood graphs3 :

The next step in the process is to extract the local signatures (to
be used to compute local node similarities) for the nodes in the
graph. Note that this process is also offline.
While there are different local signatures proposed in the literature, in our work we build on the k-neighborhood degree distribution based local signature proposed in [29] (both because it is
simple and effective and also because this helps us compare our
keynode-driven approach to the approach proposed in [29] more
directly). Briefly, for each node vj ∈ V and for a user provided k,
[29] first identifies the set, Nk (vj ) ⊆ V , of nodes that are at most
k hops from vj and extracts a subgraph, Gk (vj ) ⊆ G, induced by
vj and its k-hop neighbors. Then the degree sequence,

nbhd_sim(vi , vj ) =
where

dmin = min{degree(vi ), degree(vj )}
nmin = min{νi , νj }
P min −1
min{di,h , dj,h }
dmin + n
h=1
.
D(vi , vj ) =
2

Node Pair Ranking with Extended Similarity.

κj = [dj,1 , dj,2 , . . . , dj,|Nk (vj )| ]

While the local neighborhood similarity computation we use is
similar to the one proposed in [29], we rank pairs of nodes differently. Let vi and vj be two nodes (from two different graphs). In
particular, [29] ranks the pair hvi , vj i of nodes based on their neighborhood similarities, nbhd_sim(vi , vj ). We, however, argue that
neighborhood similarity is not sufficient for accounting for how effective the node pair is in supporting expansion. More specifically,
we observe that a pair, hvi , vj i, is likely to be a better anchor for
expansion than the pair hva , vb i if not only (a) the neighborhoods
of vi and vj are more similar to each other than the pair, va and
vb , but also (b) if vi and vj have degrees that are more aligned with
each other than va and vb . Based on this observation, instead of applying a degree threshold, we propose that the pair hvi , vj i should
be ranked based on the ranking function

consisting of the degrees of nodes in Gk (vj ) (excluding vj ), sorted
in non-increasing order, along with the degree of the node vj and
the numbers of vertices and edges in its k-hop neighborhood, form
the local signature of node vj :
local_signature(vj ) = hκj , degree(vj ), νj , εj i,
where νj = |Nk (vj ) ∪ {vj }| is the number of nodes in Gk (vj ) and
εj = |Ek (vj )| is the number of edges.
Note that, while we use a local signature similar to that proposed
in [29], we extend the node pair ranking function to better account
for the node degrees as discussed later in Section 6.1.1. As we see
in Section 8, this extension provides a significant boost in accuracy.

6.

(KEYNODE-BASED) GRAPH MATCHING

ρ(vi , vj ) = nbhd_sim(vi , vj )×

As discussed in Section 3 and outlined in Algorithm 1, once the
keynodes are extracted and local signatures are computed offline,
the next steps of the algorithm are to

6.1.2

We now describe how these steps are implemented in the keynodedriven scalable graph matching (KSGM) algorithm.

Keynode pair Selection

[29] uses the Hungarian algorithm to identify an initial node
matching in O(n3 ) time, where n = max{|V1 |, |V2 |}. To reduce
the execution time, [29] prunes those node pairs for which the similarity is ≤ 0.5. Since, instead of considering the node pairs in
V1 × V2 , we only need to consider pairs of nodes in K1 × K2 , and
since |K1 |  |V1 | and |K2 |  |V2 |, keynode-driven processing
is likely to be faster even without using the threshold. However,
the cubic time of the Hungarian algorithm is still prohibitive and
impractical for scalable graph matching. Therefore, we propose a
greedy anchor selection algorithm, which (as we see in Section 8)
performs very well when used along with keynodes selected in Section 4 and the proposed ranking function, ρ(). In particular, we first
include all keynode pairs in K1 × K2 into a queue in the order of
their ranks based on ρ(), then, until the queue is empty, we remove
and consider the keynode pair, hv, ui at the head of the queue. If
neither v nor u has been marked anchored, we include hv, ui as
an anchor and we mark v and u as anchored, otherwise, we drop
the pair, hv, ui.
Note that this process has O((|K1 | × |K2 |) × log(|K1 | × |K2 |))
time cost (instead of the cubic cost of the Hungarian algorithm) and,

Anchor Set Selection

Let G1 (V1 , E1 ) and G2 (V2 , E2 ) be two graphs and let K1 ⊆ V1
and K2 ⊆ V2 be the corresponding keynodes identified by the SKE
algorithm proposed in Section 4. The next step is to select a subset,
A, of the pairs of nodes in K1 × K2 as the anchor set of alignments
based on a ranking function (a) evaluating how structurally similar
a pair of nodes are and (b) how likely they are to lead to an effective
expansion process to discover other alignments.

6.1.1

min{degree(vi ), degree(vj )}
.
max{degree(vi ), degree(vj )}

Note that [29] simply drops node pairs where the minumum of the
two node degrees is smaller than the larger average degree of the
two input graphs. We, however, argue that such node pairs may
be useful, especially if the degrees in the graph are not uniformly
distributed and the maximum matching occurs at the sparse portions of the graph. Therefore, we keep such pairs as long as they
rank highly based on ρ(). We evaluate this ranking function in Section 8.

• compare the signatures of pairs of nodes across the given
graphs to rank these pairs of nodes,
• select a set of pairs of keynodes (we refer it as anchor set)
that serve as the base matching, and
• expand this base matching to obtain Mq,i .

6.1

nmin + D(vi , vj )
,
(νi + εi )(νj + εj )

Node Similarity Matching and Node Pair
Ranking

As we discussed in Section 5, KSGM uses a local node signature similar to the one proposed by [29]: hκj , degree(vj ), νj , εj i,
where νj is the number of nodes in the neighborhood of
vj , εj is the number of neighborhood edges, and κj =
[dj,1 , dj,2 , . . . , dj,|Nk (vj )| ] consists of the degrees of nodes in the
k-neighborhood of vj (excluding vj ), sorted in non-increasing order.

3
In addition to using local similarities, [29] also extracts global
signatures along with the local-signatures to compute node similarities. As we see in Section 8, the proposed keynode-driven graph
matching algorithm achieves good results without having to rely on
such global-signatures.

Local Neighborhood Similarity.
Let vi and vj be two nodes (from two different graphs)
and let Gk (vi ) and G0k (vj ) be the corresponding induced
k−neighborhood graphs.
Then, local similarity function

1107

as we see in Section 8, performs very well in practice. Furthermore,
the nature of Hungarian algorithm, which forces to pair all possible
nodes to produce the optimal bipartite matching for the given two
sets of nodes, is not guaranteed to provide a better matching in this
case. Since the extracted keynodes are not all necessarily perfectly
paired with each other, some keynodes can be a unique feature of
the given graph, which does not align with other graphs, by forcing
them to pair with other keynodes, it in fact introduces a bad initial
base matching, and thus expand into an even worse matching. The
proposed greedy matching algorithm, however, only consider the
highly aligned keynodes, which in practice provides better results
than the optimal bipartite matching.

6.2

more efficient randomized algorithms exist [27]. Once the node
distances have been computed, we construct the scale-space in
O(l × |V | × max_w_nbhd_size), as for each of the l scales, the
score of each node needs to be smoothed considering the scores
of the vertices in its w-hop neighborhood (w is the Gaussian window size and max_w_nbhd_size is the size of the largest w-hop
neighborhood in G).
Once the scale-space is constructed, next, we identify the keynode candidates. This involves O(l × |V |) time, because for each
of the l scales, each node needs to be compared with a constant
number (8) of DoG-neighbors in the scale-space.
Finally, we rank the keynode candidates to select the top K =
Θ
V many as the keynodes to bootstrap the online matching pro100
cess. Let there be C many keynode candidates. Computing the
ranking scores for these takes O(C) time, because each keynode
candidate needs to be compared with a constant number of DoGneighbors and obtaining the top K takes O(C × log(K)) time.

Matching List Expansion

Because keynodes are inherently sparsely localized, the anchor
set, A, is not necessarily a good final matching for graphs G1 and
G2 . We therefore need to expand this anchor list. Here, we follow [29]’s recommendation and expand the list incrementally by
considering the neighbors (and their neighbors) until no effective
expansion is possible (but we use the ranking function ρ() instead
of the node similarity function):

7.1.2

1. we first include all node pairs in A into a ranked queue (i.e.,
max-heap) in the order of their ranks based on the ranking
function, ρ(),
2. then, for each node pair hv, ui ∈ A, we also include the node
pairs in neighbors(u) × neighbors(v) in the same ranked
queue

7.2

Online Time Complexity

Let G1 (V1 , E1 ) and G2 (V2 , E2 ) be two graphs. The online process includes the following operations.

3. then, until the ranked queue is empty, we remove and consider the node pair, hv, ui at the head of the ranked queue

7.2.1

Local Similarity Computation for Keynodes

This process has O(|K1 | × |K2 | × compare_length) complexity, where
compare_length = min{max_k_nbhd_size1 , max_k_nbhd_size2 })
since signatures (of length are compared for each pair of nodes in
the keynode sets K1 and K2 .

(a) if either v or u has not yet been marked matched, then
i. we include the pair, hv, ui, in the expanded matching list, L,
ii. we mark both v and u as matched, and
iii. then, the pairs in neighbors(u) × neighbors(v)
are included in the ranked queue
(b) otherwise, we drop the pair, hv, ui

7.2.2

Anchor Set Selection

This greedy process has O((|K1 | × |K2 |) × log(|K1 | × |K2 |))
time cost as each pair off nodes among the keynode sets need to be
considered only once in ranked order.

Once the anchor list is expanded, [29] relies on a post-process,
with time complexity, O(m × n3 ), where m = min{|E1 |, |E2 |}
and n = max{|V1 |, |V2 |}. This step is not scalable due to its prohibitive time complexity. Therefore, the proposed keynode-driven
scalable graph matching (KSGM) algorithm omits this refinement
post-process, due to its high time complexity4 . Instead, the set,
L, of node pairs remaining after the expansion process is directly
returned as the aligned nodes of the matching, M1,2 , for the input
graphs, G1 and G2 .

7.2.3

Anchor Set Expansion

This has O((|V1 | × |V2 |) × log(|V1 | × |V2 |)) worst case time
cost, as in the worst case, all pairs of vertices across the two graphs
may need to be considered for expansion in ranked order.

8.

EXPERIMENTS

In this section, we present experimental evaluations of the proposed keynode-driven scalable graph matching (KSGM) algorithm.
In particular, we compare KSGM to the graph matching algorithm
presented in [29] in terms of efficiency and accuracy.

7. TIME COMPLEXITY ANALYSIS
7.1 Offline Time Complexity

8.1

Let G(V, E) be a graph to be indexed in the database.

7.1.1

Local Signature Extraction

Since the local signature extraction process needs to extract the
k-hop neighborhoods around the nodes, the complexity of this step
is O(|V | × max_k_nbhd_size), where max_k_nbhd_size is the
size of the largest k-hop neighborhood in G. Note that this step
can also leverage the node distance matrix constructed during the
offline keynode extraction process.

8.1.1

Structural Keynode Extraction

Data Sets
Facebook Data Graph

The first data set we used is the Facebook social circles data
graph obtained from the Stanford Large Network Dataset Collection [2]. This is a connected graph with 4039 nodes and 88234
edges. The graph has a diameter of 8 and a 90-percentile effective
diameter of 4.7. For the experiments, we constructed 10 subgraphs
by uniformly sampling connected subsets, containing 60 − 70% of
the original graph nodes. Once the subgraphs are obtained, each
of the subgraphs is used as a query against the rest. We report the
averages of execution time and accuracy.

The first step in structural keynode extraction is to obtain the
PageRank scores for the nodes of the two graphs. While, this is an
expensive operation (involving a matrix inversion with O(|V |2.373 )
complexity for a graph with |V | nodes), there are many efficient,
approximate implementations of PageRank, including sublinear approximations [6].
The second step is the creation of an l-layer scale-space for
G. To construct the scale space, we first construct a node distance matrix, which requires an all-pairs shortest path computation, with complexity O(|V |3 ) for a graph with |V | nodes, but

8.1.2

4

Synthetic Graph Data Sets

In addition to the Facebook graph, we also used synthetic graphs,
where we controlled the topology, size, and node degree to explore

Though, in cases where scalability is not critical, this refinement
can be implemented without any change in the rest of the algorithm.

1108

Table 1: Synthetic graph topologies and configurations
Graph topology
Erdos-Renyi (ER)
Power law (PL)

Number of nodes
5000, 7500 (plus 1 to 10%)
5000, 7500 (plus 1 to 10%)

the advantages and disadvantages of the algorithms under different
scenarios.
We generated the synthetic graphs using the well known random
graph generating tool, NetworkX [1]. We consider two common
graph topologies: the Erdos-Renyi (ER) model and the power law
topology (PL) under the Barabasi-Albert model. Table 1 lists the
number of nodes and average degree settings that we used for assessing our algorithms. For each configuration, we generated 10
graphs. Note that, in addition to the base sizes (of 5000 and 7500),
we randomly created an additional 1 to 10% more nodes to ensure
that the different graphs in the data set have slightly different numbers of nodes. As before, once the 10 graphs are obtained for each
configuration, each of the subgraphs is used as query against the
rest. We report the averages of execution time and accuracy.

8.2

Table 2: Experiment results for the Facebook Graph (default
parameters)

Average degree
4, 8, 16
4, 8, 16

KSGM
6.4
38.0%

PR
7.25
34.12%

Random
6.0
15.4%

Extraction time (offline, sec.)

11.5

110.4

0.39

-

Matching time (online, sec.)
Accuracy

2%
6.5
37.6%

3%
6.4
38.0%

4%
6.3
38.7%

6%
6.4
36.4%

8%
7.2
33.2%

Table 4: Impact of the node-pair ranking function, ρ(), for the
Facebook Graph
Matching time (online sec.)
Accuracy

ρ()
6.4
38.0%

w/o Degree
6.0
31.8%

with Global
4.0
22.9%

Table 5: Impact of the local-signature neighborhood size, k, for
the Facebook Graph

Evaluation Criteria

Matching time (online, sec.)
Accuracy

2 hops (default)
6.4
38.0%

3 hops
5.5
33.9%

4 hops
4.3
23.3%

processing, its online matching time is 3× faster than that of [29].
Moreover, the matching accuracy of KSGM is 1.2× better than that
of the competitor, through it does not use global signatures, nor it
relies on the optimal Hungarian algorithm for anchor selection.
The table also lists the performance of KSGM when using top
PageRank (PR) scored nodes instead of those returned by the SKE
algorithm. As we see here, while the offline process is faster when
using PageRank scoring nodes, the runtime performance (both in
terms of execution time and accuracy) is worse when using SKE
keynodes. In addition, to see whether it is possible to achieve a
competitive accuracy if we were to select a similar percentage of
node randomly, in Table 2, we also include results where random
keynodes are used in the matching online phase. As we can see, the
accuracy drops significantly when we use random keynodes instead
of using robust structural keynodes extracted by the proposed SKE
algorithm6 . These indicate that SKE is indeed effective in extracting
structurally distinct and useful keynodes.

Execution Time

We report both offline and online execution times. As shown in
Algorithm 1 in Section 3, for KSGM, the offline execution includes
structural keynode and local-signature extraction steps. Online execution includes similarity computation, anchor selection, and expansion steps. [29] does not perform structural keynode extraction;
instead, offline execution includes eigen-decomposition for global
signatures.
For both KSGM and [29], we omit the refinement step as its complexity is prohibitive for scalable graph matching. For instance, for
the Facebook graph for which KSGM takes ∼ 6 seconds for online
processing for a pair of graphs, refinement takes ∼ 30 minutes –
i.e., it causes a ∼ 260× slowdown5 .

8.3

[29]
19.2
35.4%

Table 3: Impact of the keynode percentage, Θ, for the Facebook
Graph

All experiments were conducted using a 4-core Intel Core i52400, 3.10GHz, machine with 8GB memory, running 64-bit Windows 7 Enterprise. The codes were executed using Matlab 2013b
and Visual Studio 2012. To evaluate accuracy, we use the matching
quality defined in Section 3.

8.2.1

Matching time (online, sec.)
Accuracy

Experiment Parameters

The default parameters for the structural keynode extraction
(SKE) algorithm are as follows:

8.4.2

Impact of the Keynode Percentage

Table 3 studies the impact of the percentage, Θ, of the nodes used
as keynodes. As we see, up to a point, the more keynodes we use,
the more accurate and faster the matching becomes. Beyond that
point, however, additional keynodes become disadvantageous. This
indicates that top keynodes are the most effective in serving as good
starting points and, as expected, below a certain rank they loose
distinctiveness, resulting in increased cost and loss in accuracy.

• PageRank teleportation probability (1−α) = 0.15 (as is commonly assumed),
• least smoothing factor (σmin ) = 0.275, corresponding to ∼
2-hop neighborhoods,
• maximum smoothing factor (σmax ) = 0.777, corresponding
to ∼ 5-hop neighborhoods, and
• number (l) of smoothing levels = 6.

8.4.3

In addition, for KSGM, the default percentage (Θ) of keynodes selected from the graph was set to 3%. Also, for all algorithms, local
signatures were extracted from 2-hop neighborhoods (i.e., k = 2),
as recommended by the authors of [29].

Impact of the Node-Pair Ranking Function

Table 2 lists the online and offline processing times and accuracy for the Facebook graph under the default parameter settings.
As we see here, while KSGM spends more time in one-time, offline

Table 4 studies the impact of the node-pair ranking function,
ρ(). In particular, we compare the performance of the ranking
function proposed in Section 6.1.1, to the ranking function without
degree extension and ranking function including additional globalsignature similarity as proposed in [29]. As we see here, the proposed node-pair ranking function provides the best expansion opportunities (and thus provides the highest accuracy, with slight expansion time overhead). Also, the "with Global" optional provides
a much worse matching. Thus, while the algorithm allows, we encourage the users not to use "with Global" option.

5
For this data configuration, when using expensive refinement postprocessing, KSGM and [29]’s accuracies are 0.72 and 0.696, respectively.

6
The slight time gain when using random keynodes is due to the
fact that random keynodes are not good starting points for expansion and, thus, the expansion process ends earlier.

8.4
8.4.1

Results for the Facebook Graph
Default Configuration

1109

gorithm works faster than the state-of-the-art algorithms without
refinement, yet produces alignments that are as good or better.

Table 6: Experiment results for the synthetic data sets (avg.
degree=4, varying models and number of nodes)
KSGM Online time (sec.)
[29] Online time (sec.)
KSGM Accuracy
[29] Accuracy

PL(5000)
6.9
99.3
45.3%
42.9%

PL(7500)
13.9
223.7
45.1%
42.8%

ER(5000)
6.5
746.7
45.7%
46.3%

ER(7500)
14.5
745.1
51.2%
53.0%

KSGM Offline time (sec.)
[29] Offline time (sec.)

130.0
23.8

284.7
82.8

134.8
24.9

270.8
84.5

Acknowledgments
We thank the authors of [29] for sharing their source code and data.

10.

Table 7: Impact of the average node degree (number of
nodes=5000, power law model)
KSGM Online time (sec.)
[29] Online time (sec.)
KSGM Accuracy
[29] Accuracy

degree=4
6.9
99.3
45.3%
42.9%

degree=8
7.5
116.7
25.2%
25.1%

degree=16
9.3
141.2
13.9%
14.1%

KSGM Offline time (sec.)
[29] Offline time (sec.)

130.0
23.8

199.1
27.9

396.7
53.2

8.4.4

Impact of the Neighborhood Size, k, for LocalSignatures

Table 5 studies the impact of the neighborhood size, k, for localsignature extraction. As we see in the table, the highest accuracy is
at 2 hops7 , increasing the neighborhood size negatively affects the
accuracy, indicating that unless locally meaningful signatures are
used, the resulting node-pair ranking is not effective for expansion.
This shows the keynode matching process is more accurate when
keynodes are easy to localize and this requires them to be distinct
and locally representative. Large neighborhoods potentially violate
both. Note that this is in line with the observation in Table 4.

8.5

Results for the Synthetic Data Sets

In this subsection, we consider the impacts of graph topology,
size, and node degree using ER and PL topologies. We omit discussions of the impacts of the other parameters, as they mirror those
presented in Tables 3 through 5.

8.5.1

Default Configurations

Table 6 lists the performances of KSGM and [29] for synthetic
graphs for different topologies and numbers of nodes under the default parameter settings. As we see here, the online execution time
of KSGM is significantly (10× to 115×) faster than that of [29], especially for the ER topology. Moreover, on both Erdos-Renyi (ER)
and power law (PL) topologies, the accuracy is highly competitive, with KSGM providing non-negligible accuracy gains for the PL
model (where it is relatively easier to identify effective keynodes).

8.5.2

Impact of Average Node Degree

Table 6 studies the impact of average node degree on matching
accuracies for the power law graph. As we see in the table, both
algorithms see a drop in the matching accuracy with larger node
degrees. However, KSGM stays competitive in terms of accuracy,
whereas it provides more gains in terms of online execution time.

9.

REFERENCES

[1] http://networkx.github.io/
[2] http://snap.stanford.edu/index.html
[3] X. Bai, H. Yu, and E. R. Hancock. Graph matching using
spectrament. ICPR 2004.
[4] A. Balmin, et al. ObjectRank: Authority-based keyword search in
databases. VLDB, 2004.
[5] M.G. Borgatti, et al. Network measures of social capital.
Connections 21(2):27-36, 1998.
[6] C. Borgs, M. Brautbar, J. T. Chayes, S.-H. Teng. Multiscale
Matrix Sampling and Sublinear-Time PageRank Computation.
Internet Mathematics 10(1-2): 20-48, 2014.
[7] S. Brin, et al. The anatomy of a large-scale hypertextual Web
search engine. Computer Networks and ISDN Systems 30:
107-117, 1998.
[8] H. Bunke. Error correcting graph matching: On the influence of
the underlying cost function. IEEE TPAMI, 21(9):917–922, 1999.
[9] K. S. Candan, R. Rossini, M. L. Sapino, X. Wang. sDTW:
Computing DTW Distances using Locally Relevant Constraints
based on Salient Feature Alignments. PVLDB, 1519-1530, 2012.
[10] M. Chen, J. Liu, and X. Tang. Clustering via random walk hitting
time on directed graphs. AAAI 2008.
[11] Xilun Chen, K. Selcuk Candan. LWI-SVD: Low-rank,
Windowed, Incremental Singular Value Decompositions on
Time-Evolving Data Sets. KDD 2014.
[12] Xilun Chen, K. Selcuk Candan. GI-NMF: Group Incremental
Non-Negative Matrix Factorization on Data Streams. CIKM 2014.
[13] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein.
Introduction to Algorithms. 2001.
[14] R. Giugno and D. Shasha. Graphgrep: A fast and universal
method for querying graphs. ICPR, pp. 112-115, 2002.
[15] W. S. Han, J. Lee, and J. H. Lee. TurboISO: Towards ultrafast and
robust subgraph isomorphism search in large graph databases.
SIGMOD 2013
[16] R. Jonker and T. Volgenant.Improving the Hungarian assignment
algorithm. Oper. Res. 171-175. 1986.
[17] G. Karypis and V. Kumar "A fast and high quality multilevel
scheme for partitioning irregular graphs". SIAM Journal on
Scientific Computing 20 (1), 1999.
[18] D. Knossow, A. Sharma, D. Mateus, and R. Horaud. Inexact
matching of large and sparse graphs using laplacian eigenvectors.
GbRPR, 2009.
[19] W.-J. Lee and R. P. W. Duin. An inexact graph comparison
approach in joint eigenspace. In SSPR/SPR, 35-44, 2008.
[20] Jundong Li, Xia Hu, Jiliang Tang, Huan Liu. Unsupervised
Streaming Feature Selection in Social Media. CIKM 2015
[21] D. G. Lowe. Distinctive Image Features from Scale-Invariant
Keypoints. Int. Journal of Computer Vision, 60, 2, 2004.
[22] K. Riesen, X. Jiang, and H. Bunke. Exact and inexact graph
matching: Methodology and applications. Managing and Mining
Graph Data, pages 217-247, 2010.
[23] S. Umeyama. An eigen decomposition approach to weighted
graph matching problems. IEEE TPAMI, 10(5):695-703, 1988.
[24] J. R. Ullman. An algorithm for subgraph isomorphism, JACM
Vol. 23, No. 1, pp. 31-42. 1976
[25] X. Wang, K. S. Candan, M. L. Sapino: Leveraging metadata for
identifying local, robust multi-variate temporal (RMT) features.
ICDE, 2014.
[26] White D.R., et al. Betweenness centrality measures for directed
graphs. Social Networks, 16, 335-346,1994.
[27] R. Williams. Faster all-pairs shortest paths via circuit complexity.
STOC, 664-673. 2014.
[28] M. Zaslavskiy, F. R. Bach, and J.-P. Vert. A path following
algorithm for the graph matching problem. IEEE Trans. Pattern
Anal. Mach. Intell., 31(12):2227-2242, 2009.
[29] Y. Zhu, L. Qin, J. X. Yu, et al. High Efficiency and Quality: Large
Graphs Matching. CIKM, pp. 1755-1764. 2011.

CONCLUSIONS

Noticing that existing solutions to the graph matching problem
face major scalability challenges, we argue that it is impractical to
seek alignment among all pairs of nodes. Given these observations,
in this paper, we first presented an offline structural keynode extraction (SKE) algorithm and then discussed how to use these structural keynodes in a novel keynode-driven scalable graph matching
(KSGM) algorithm. Keynodes are selected carefully especially because a post refinement step is not feasible due to scalability requirements. Experiment results show that the proposed KSGM al7
Coincidentally, this also is the scale at which the SKE algorithm
located an overwhelming majority of the keynodes for this graph.

1110

Annotated Probabilistic Temporal Logic
PAULO SHAKARIAN, AUSTIN PARKER, GERARDO SIMARI,
and VENKATRAMANA (V. S.) SUBRAHMANIAN
University of Maryland

The semantics of most logics of time and probability is given via a probability distribution over
threads, where a thread is a structure specifying what will be true at different points in time (in
the future). When assessing the probabilities of statements such as “Event a will occur within
5 units of time of event b,” there are many different semantics possible, even when assessing the
truth of this statement within a single thread. We introduce the syntax of annotated probabilistic
temporal (APT) logic programs and axiomatically introduce the key notion of a frequency function
(for the first time) to capture different types of intrathread reasoning, and then provide a semantics for intrathread and interthread reasoning in APT logic programs parameterized by such
frequency functions. We develop a comprehensive set of complexity results for consistency checking
and entailment in APT logic programs, together with sound and complete algorithms to check consistency and entailment. The basic algorithms use linear programming, but we then show how to
substantially and correctly reduce the sizes of these linear programs to yield better computational
properties. We describe a real world application we are developing using APT logic programs.
Categories and Subject Descriptors: I.2.3 [Artificial Intelligence]: Deduction and Theorem
Proving—Uncertainty, “fuzzy” and probabilistic reasoning; I.2.4 [Artificial Intelligence]: Knowledge Representations Formalisms and Methods—Temporal logic; D.1.6 [Programming Techniques]: Logic Programming
General Terms: Algorithms, Languages
Additional Key Words and Phrases: Probabilistic and temporal reasoning, threads, frequency functions, imprecise probabilities
ACM Reference Format:
Shakarian, P., Parker, A., Simari, G., and Subrahmanian, V. S. 2011. Annotated probabilistic temporal logic. ACM Trans. Comput. Logic 12, 2, Article 14 (January 2011), 44 pages.
DOI = 10.1145/1877714.1877720 http://doi.acm.org/10.1145/1877714.1877720

1. INTRODUCTION
There are numerous applications where we need to make statements of the
form “Formula G becomes true with 50−60% probability 5 time units after
Some of the authors of this article were funded in part by AFSOR grant FA95500610405, ARO
grant W911NF0910206, and ONR grant N000140910685.
Authors’ address: V. S. Subrahmanian; email: vs@cs.umd.edu.
Permission to make digital or hard copies of part or all of this work for personal or classroom use
is granted without fee provided that copies are not made or distributed for profit or commercial
advantage and that copies show this notice on the first page or initial screen of a display along
with the full citation. Copyrights for components of this work owned by others than ACM must be
honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers,
to redistribute to lists, or to use any component of this work in other works requires prior specific
permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn
Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212) 869-0481, or permissions@acm.org.

C 2011 ACM 1529-3785/2011/01-ART14 $10.00
DOI 10.1145/1877714.1877720 http://doi.acm.org/10.1145/1877714.1877720
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14

14:2

•

P. Shakarian et al.

Fig. 1. Kstock , an APT-Logic Program modeling the behavior to reactions of stock-related news
feeds. As all of these rules are constrained, this is a constrained program. The English translation
of each rule is also provided.

formula F became true.” We now give four examples of how such statements
might be applied.
Stock Market Prediction. There is ample evidence [Fujiwara et al. 2008]
that reports in newspapers and blogs [De Choudhury et al. 2008] have an impact on stock market prices. For instance, major investment banks invest a lot
of time, effort and money attempting to learn predictors of future stock prices
by analyzing a variety of indicators together with historical data about the values of these indicators. As we will show later in Figure 1, we may wish to write
rules such as “The probability that the stock of company C will drop by 10% at
time (T + 2) is over 70% if at time T , there is a news report of a rumor of an
SEC investigation of the company and (at time T ) there is a projected earnings
increase of 10%. It is clear that such rules can be learned from historical data
using standard machine learning algorithms. Financial companies have the
means to derive large sets of such rules and make predictions based on them.
Reasoning about Terror Groups. Our group has extensively dealt with
historical data on over 40 terrorist groups from the Minorities at Risk
project [Wilkenfeld et al. 2007] and has published detailed analyses of some of
these groups’ behaviors (Hezbollah [Mannes et al. 2008a] and Hamas [Mannes
et al. 2008b]). Our SOMA Terror Organization Portal [Martinez et al. 2008b]
has registered users from over 12 US government agencies and contains thousands of automatically extracted rules about the behaviors of these groups.
For such groups, we might want to say: “Hezbollah targets domestic government security institutions/lives with a probability of 87 to 97% within 3 years
(time periods) of years when their major organizational goals were focused
on eliminating ethnic discrimination and when representing their interests to
government officials was a minor part of their strategy.” Figure 2 provides a
list of such rules associated with Hezbollah. Clearly, analysts all over the world
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:3

Fig. 2. A sample of the rules extracted by APT-Extract from the Hezbollah dataset. Each atom
in the rules is represented as a variable and its value. A plain English explanation of each rule is
also provided.

engaged in counterterrorism efforts need to be able to reason with such rules
and make appropriate forecasts; we have also done extensive work on making
such forecasts [Martinez et al. 2008a, 2009].
Reasoning about Trains. All of us want to reason about train schedules and
plane schedules. More importantly, railroad companies, airlines, and shipping
companies have an even more urgent need to do such reasoning, as it directly
impacts their planning process. In such settings, a railroad company may learn
rules of the form “If train 1 is at station A at time T , then it will be at station
B at time (T + 4) with over 85% probability.” Once such rules are learned from
historical data, various types of reasoning need to be performed in order for
the railroad company to make its plans. Figure 3 shows a small toy example of
rules associated with trains.
Reasoning about a Power Grid. Utility companies need to reason constantly
about power grids. Decisions about which lines and transformers should be
repaired next are based not only on the costs of these repairs, but also when
these components are likely to fail, and many other factors. Thus, for example,
a power company may derive rules of the form “if the transformer tr and power
line ln are functioning at time T , then there is a probability of over 95% that
they will continue to be functioning at time (T + 3).” Figure 4 shows a small
toy example of rules associated with power grids.
These examples illustrate the syntax of an APT-logic program; we will give
the formal details as we develop the technical material in the article. While
it is possible for designers to write such programs manually, we expect that
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:4

•

P. Shakarian et al.

Fig. 3. Ktrain , an APT-Logic Program modeling rail transit. Items 1–3 are APT-Rules while
items 4–5 are annotated formulas. The English translation of each rule is also provided.

Fig. 4. Kpower , an APT-Logic Program modeling a power grid. Items 1–4 are APTRules, while
item 5 is an annotated formula. The English translation of each rule is also provided.

machine learning programs can be used to automatically learn such programs
from historical data using standard machine learning algorithms, as we did
previously in our work on ap-programs [Khuller et al. 2007]. Though this is
not claimed as a major contribution of this article, in order to show that it
is possible to automatically learn APT-programs, we have developed a simple
algorithm called APT-Extract and used it to learn models of certain behaviors
exhibited by 18 terror groups.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:5

Table I. Summary of General Complexity Results
Problem

General Complexity Results
Complexity

Consistency of Single Unconstrained Rule
Consistency of Single Constrained Rule
Consistency of a mixed PCD Program with
additional restrictions on lower probability bounds
Entailment of an annotated formula by a program

NP-complete
NP-complete
Guaranteed
consistent
coNP-hard

Reference
Thm 3.2
Thm 3.4
Thm 3.7
Thm 4.2

This article proceeds as follows. In Section 2 we introduce the syntax and
semantics of APT-logic programs, including a quick treatment of our notion of
a frequency function, a structure unique to APT-logic. In Section 3 we introduce
several methods to check consistency of APT-logic programs, along with appropriate complexity analysis. We introduce several algorithms for consistency
checking: one that straightforwardly applies the semantics, one that exploits
the relationships between formulas in the heads and bodies of APT-rules, and
one that works only on specific sorts of APT-rules but often offers substantial
speedup when possible. These techniques can also be applied to the problem
of entailment, which is covered in Section 4. In Section 5, we explore some applications of APT-logic programs and finally, we spend a great deal of effort in
Section 6 distinguishing this logic from other probabilistic logics. In particular,
we examine the relationship between APT-logic programs and Markov Decision Processes (MDPs for short) [Puterman 1994], showing that one can create
APT-logic programs equivalent to a given MDP and policy, but under natural
assumptions, there is no MDP equivalent to certain APT-logic programs. We further address the relationship between APT-logic and a well known logic called
Probabilistic Computation Tree Logic (PCTL for short) [Hansson and Jonsson
1994a] and provide examples demonstrating that PCTL cannot express various
things expressible in APT-logic programs.
The entire set of complexity results for APT-logic programs derived in this
article is summarized in Table I. Consistency of APT-logic programs is determined by solving certain linear programs. In this article, we develop successively more sophisticated linear programs that try to use different types of
equivalence classes to collapse multiple variables in the linear program into
one variable; Table II summarizes the main results related to linear program
size reduction for consistency checking. Table III also provides an analogous
summary related to reduction of size of the linear program when considering
entailment by APT-logic programs.
2. APT-LOGIC PROGRAMS
In this section, we will first define the syntax of APT-logic programs, and then
define the formal semantics.
2.1 Syntax
We assume the existence of a first order logical language L, with a finite set
Lcons of constant symbols, a finite set Lpred of predicate symbols, and an infinite
set Lvar of variable symbols. Each predicate symbol p ∈ Lpred has an arity
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:6

•

P. Shakarian et al.
Table II. Comparison of Linear Constraints for Consistency, see Section 3

Type of Linear
Constraints

Number of
Constraints

Number of
Variables

Cost of Identifying Equivalence Classes

SLC
WELC
FELC using BFECA
to identify classes
FELC using WEFE
to identify classes
FELC w.
PCD restrictions on K

2|K| + 1
2|K| + 1
2|K| + 1

2|BL |tmax
22|K|tmax
2|K|

(equivalence classes not used)


O 22|K|+BL
 |B |t

O 2 L max · F(tmax ) · |K|

2|K| + 1

2|K|

2|K| + 1

2|K|



O 22|K|·tmax · tmax · |K| +
O 22|K|+BL
(equivalence classes guaranteed)

Table III. Comparison of Linear Constraints for Entailment
Algorithm

Intuition

Reference

SLC-ENT

Determining both the minimization and maximization
of a constraint wrt SLC
Determining both the minimization and maximization
of a constraint wrt FELC or WELC

Section 4

ALC-ENT

Section 4

(denoted arity(p)). A (ground) term is any member of Lcons ∪ Lvar (resp. Lcons ); if
t1 , . . . , tn are (ground) terms, and p ∈ Lpred , then p(t1 , . . . , tn) is a (resp. ground)
atom. A formula is defined recursively as follows.
Definition 2.1. A (ground) atom is a (ground) formula. If f1 and f2 are
(ground) formulas, then f1 ∧ f2 , f1 ∨ f2 , and ¬ f1 are (ground) formulas.
We use BL to denote the Herbrand base (set of all ground atoms) of L. It is easy
to see that BL is finite.
We assume that all applications reason about an arbitrarily large, but fixed
size window of time, and that τ = {1, . . . , tmax } denotes the entire set of time
points we are interested in. tmax can be as large as an application user wants,
and the user may choose his granularity of time according to his needs. For
instance, in the stock market and power grid examples, the unit of time used
might be days, and tmax may be arbitrarily set to, say 1,095, denoting interest
in stock market and power grid movements for about 3 years. In the case of the
train example, however, the unit of time might be seconds, and the application
developer might set tmax to 93,600, reflecting that we are only interested in
reasoning about one day at a time, but at a temporal resolution of one second.
In the case of the terrorism application, on the other hand, our temporal
resolution might be one month, and tmax might be 360 reflecting an interest in
events over a 30-year time span.
Definition 2.2 (Annotated Formula). If F is a formula, t ∈ τ is a time point,
and [, u] is a probability interval, then F : [t, , u] is an annotated formula.
Intuitively, F : [t, , u] says F will be true at time t with probability in [, u].1
1 Assumption.

Throughout the article we assume, for both annotated formulas and APT-rules, that
the numbers , u can be represented as rationals a/b where a and b are relatively prime and the
length of the binary representations of a and b is fixed.

ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:7

Example 2.1. Let us reconsider the program Ktrain from Figure 3. The annotated formula at station(train1, stnB) : [4, 0.85, 1] says that the probability
that train1 will be at station stnB at time point 4 is between 85 and 100%.
Throughout this article, we assume the existence of a finite set F of symbols
called frequency function symbols. Each of these symbols will denote a specific
frequency function to be defined later when we define our formal APT semantics.
We are now ready to define the syntax of Annotated Probabilistic Temporal
(APT for short) rules and logic programs, which will form the main topic of
study for this article.
Definition 2.3 (APT Rule). Let F, G be two formulas, t be a time interval,
, u be a probability interval, fr ∈ F be a frequency function symbol and α, β ∈
[0, 1].
fr

(1) F ; G : [t, , u] is called an unconstrained APT rule.
fr

(2) F → G : [t, , u, α, β] is called a constrained APT rule.
An APT logic program is a finite set of APT rules and annotated formulas.
fr

Note that we use the symbol ‘;’ for unconstrained APT rules with frequency
fr
function symbol fr, while the symbol ‘→’ is used for constrained rules with
frequency function fr. The formal semantics of these rules is quite complex and
will be explained shortly. But informally speaking, both types of rules try to
check the probability that a formula F is true t units before a formula G
becomes true.
Figures 1, 2, 3, and 4 respectively show the APT-logic programs associated
with our stock market, counterterrorism, trains, and power grid applications.
We now define three types of APT-logic programs.
Definition 2.4 (Types of APT-Logic Programs).
—An unconstrained APT-Logic Program consists only of unconstrained APTrules.
—A constrained APT-Logic Program consists only of constrained APT-rules.
—A mixed APT-Logic Program consists both of constrained and unconstrained
APT-rules.
From this example, we see that Kstock is a constrained APT-logic program,
Ktrains , Kpower , and Kterror are unconstrained APT-logic programs.2
2.2 Semantics of APT-Logic Programs
In this section, we will provide a formal declarative semantics for APT-logic
programs. As the syntax of these programs is quite complex, we will do this
one step at a time. We start with the well known definition of a world.
2 Notably

absent from this list of types of APT-Logic Programs are annotated formulas. We will
show later in Theorem 2.20 that APT-rules can be used to express annotated formulas and hence
there is no loss of expressive power.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

•

14:8

P. Shakarian et al.

Fig. 5. Example thread for the train scenario from Figure 3, where only one train is present.

Definition 2.5.

A world is any set of ground atoms.

The power set of BL (denoted 2 BL) is the set of all possible worlds. Intuitively,
a world describes a possible state of the real world or real world phenomenon
being modeled by an APT-logic program. The following are examples of worlds.
Example 2.2. Consider the atoms present in the program Ktrain from
Figure 3. A few possible worlds are: {at station(train1, stnA), at station(train2,
stnB)}, {at station(train1, stnB)}, and {}.
As worlds are just ordinary Herbrand interpretations [Lloyd 1987], we use
w |= F to denote the standard definition of satisfaction of a ground formula F
by world w as expressed in Lloyd [1987].
Definition 2.6 (Satisfaction of a formula by a world). Let f be a ground
formula and w be a world. We say that w satisfies f (denoted w |= f ) if and
only if:
— If
— If
— If
— If

f
f
f
f

= a for some ground atom a, then a ∈ w.
= ¬ f  for some ground formula f  , then w does not satisfy f  .
= f1 ∧ f2 for formulas f1 and f2 , then w satisfies f1 and w satisfies f .
= f1 ∨ f2 for formulas f1 and f2 , then w satisfies f1 or w satisfies f2 .

We say a formula f is a tautology if for all w ∈ 2 BL , w |= f . We say f is a
contradiction if for all w ∈ 2 BL , w |= ¬ f .
A thread, defined below, is nothing but a standard temporal interpretation [Emerson and Halpern 1984; Lamport 1980] in temporal logic.
Definition 2.7 (Thread).

A thread is a mapping Th : {1, . . . , tmax } → 2 BL .

Th(i) implicitly says that according to the thread Th, the world at time i will be
Th(i). We will use T to denote the set of all possible threads, and Th∅ to denote
the null thread—the thread that assigns ∅ to all time points.
Example 2.3. Consider the train scenario shown in Figure 3 and the worlds
described in Example 2.2. Let τ = {0, . . . , 9} represent one-hour time periods in
a day from 9:00am to 6:00pm: 0 represents 9-10am, 1 represents 10-11am, and
so forth. Figure 5 shows a sample thread for this setting, where only one train
is present. According to this thread, the train is at station A at 9 o’clock; at
10 o’clock the thread has an empty world, since the train is still between
stations, reaching station B at 12. The thread shows how the train moves
throughout the rest of the day.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:9

Fig. 6. Example thread, Th with worlds Th(1), . . . , Th(8). This figure shows each world that
satisfies formula F or formula G.

A thread represents a possible way the domain being modeled (e.g., where
the train is) will evolve over all time points. A temporal probabilistic (tp) interpretation gives us a probability distribution over all possible threads.
Definition 2.8 (Temporal-Probabilistic Interpretation). A temporal-probabilistic (tp) interpretation
I is a probability distribution over the set of all

possible threads: th∈T I(th) = 1.
Thus, a tp-interpretation I assigns a probability to each thread. This reflects
the probability that the world will in fact evolve over time in accordance with
what the thread says about the state of the world at various points in time.
Example 2.4. Consider once again, the setting of Figure 3. A very simple example of a tp-interpretation is the probability distribution that assigns
probability 1 to the thread from Figure 5, and 0 to every other possible
thread. Another example would be a distribution that assigns probability 0.7
to the thread from Figure 5, and 0.3 to the thread Th defined as follows:

Th (1) = {at station(train1, stnA)}, Th (2) = {}, Th (3) = {}, Th (4) = {}, Th (5) =
{at station(train1, stnB)}, Th (6) = {at station(train1, stnC)}, Th (7) = {}, Th (8) =
{at station(train1, stnB)}, Th (9) = {}, Th (10) = {at station(train1, stnA)}; this
thread specifies that the train’s trip from station A to station B takes one time
unit longer than specified by the previous thread (Th).
We now define what it means for a tp-interpretation to satisfy an annotated
formula.
Definition 2.9 (Satisfaction of an Annotated Formula). Let F : [t, , u] be
an annotated formula, and I be a tp-interpretation.
 We say that I satisfies
F : [t, , u], written I |= F : [t, , u], if and only if  ≤ Th∈T ,Th(t)|=F I(Th) ≤ u.
Thus, to check if I satisfies F : [t, , u], we merely sum up the probabilities
assigned to those threads Th ∈ T that make F true at time t. If this sum is in
[, u] then I satisfies F : [t, , u].
2.3 Frequency Functions
When defining the syntax of APT-logic programs, we defined frequency function
symbols. Each frequency function symbol denotes a frequency function. The
basic idea behind a frequency function is to represent temporal relationships
within a thread. For instance, we are interested in the frequency with which
G will be true t units after F is true. When we study this with respect to
a specific thread Th, we need to identify when F was true in thread Th, and
whether G really was true t units after that. For instance, consider the thread
shown in Figure 6. Here, F is true at times 1, 3, 6, and 8. G is true at times 2,
4, 5, and 7. F and G should be true at the indicated times.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:10

•

P. Shakarian et al.

— The probability (within the thread of Figure 6) that G follows F in exactly
two units of time is 0.33 if we ignore the occurrence of F at time 8. If, on the
other hand, we do count that occurrence of F at time 8 (even though no times
beyond that are possible), then the probability that G follows F in exactly
two units of time is 0.25.
— The probability that G follows F in at most 2 units of time is 100% if we
ignore the occurrence of F at time 8; otherwise it is 0.75.
Each of these intuitions leads to different ways to measure the frequency
(within a thread) with which G follows F. As we will show shortly, many other
possibilities exist as well. To the best of our knowledge, no past work on reasoning with time and uncertainty deals with frequencies within threads; as a
consequence, past works are not able to aggregate frequencies across multiple
threads in T or with respect to tp-interpretations. This capability, we will show,
is key for the types of applications described in the Introduction of this article.
We see that there are many different ways to define this frequency from a
given body of historical data. Rather than make a commitment to one particular way and in order to allow applications and users to select the frequency
function that best meets their application needs, we now define axioms that any
frequency function must satisfy. Later, we will define some specific frequency
functions.3
Definition 2.10 (Frequency Function). Let Th be a thread, F and G be formulas, and t > 0 be an integer. A frequency function fr is one that maps
quadruples of the form (Th, F, G, t) to [0, 1] such that it satisfies the following
axiom.
(FF1) If G is a tautology, then fr(Th, F, G, t) = 1.
(FF2) If F is a tautology and G is a contradiction, then fr(Th, F, G, t) = 0.
(FF3) If F is a contradiction, fr(Th, F, G, t) = 1.
(FF4) If G is not a tautology, and either F or ¬G is not a tautology, and
F is not a contradiction, then there exist threads Th1 , Th2 ∈ T such that
fr(Th1 , F, G, t) = 0 and fr(Th2 , F, G, t) = 1.
Axiom FF1 says that if G is a tautology, then fr(Th, F, G, t) must behave
like material implication and assign 1 to the result. Likewise, if F is a tautology
and G is a contradiction, then FF2 says that fr(Th, F, G, t) must behave like
implication and have a value of 0 ( A → B is false when A is a tautology
and B is a contradiction). Axiom FF3 requires fr(Th, F, G, t) to be 1 when F
is a contradiction, also mirroring implication. Axiom FF4 ensures that in all
cases not covered here, the frequency function will be nontrivial by allowing at
least one thread that perfectly satisfies (probability 1) and perfectly contradicts
(probability 0) the conditional. Note that any function not satisfying Axiom FF4
can be made to do so as long as it returns distinct values: simply map the lowest
3 Throughout

this article, we will assume that a frequency function for a given thread can be
computed in polynomial time (O(|BL | · tmax )). Additionally, we shall assume that a frequency
function will return a number that can be represented as a rational number a/b, where a and b are
relatively prime and the length of the binary represenations of a and b is fixed.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:11

value returned, to 0 and the highest value returned, to 1. We now give examples
of two frequency functions.
Definition 2.11 (Point Frequency Function). Let Th be a thread, F and G
be formulas, and t ≥ 0 be an integer. A Point Frequency Function, denoted
pf r(Th, F, G, t), is defined as:
pfr(Th, F, G, t) =

|{t : Th(t) |= F ∧ Th(t + t) |= G}|
.
|{t : (t ≤ tmax − t) ∧ Th(t) |= F}|

If there is no t ∈ [0, tmax − t] such that Th(t) |= F, then we define pfr to be 1.
The point frequency function expresses a simple concept—it specifies how frequently G follows F in t time points. Mathematically, this is done by finding
all time points from [1, tmax − t] at which F is true and of all such time points
t, then finding those for which G is true at time t + t. The ratio of the latter
to the former is the value of pfr. The following lemma says that this is a valid
frequency function. Note that the denominator of the point frequency function
does not include times when the thread satisfies F after tmax − t because the
“end of time” of our finite time model comes before t units elapse after F
becomes true.
LEMMA 2.12.

pfr satisfies Axioms FF1-FF4.

Example 2.5 (Point Frequency Function). Consider thread Th from Figure 5. Suppose we want to calculate pfr(Th, at station(train1, stnB), at
station(train1,stnC), 2). In English, this is the ratio of time at station(train1, stnB)
is followed by at station(train1, stnC) in two units of time in thread Th. We can see
that at station(train1, stnB) is satisfied by two worlds: Th(4) and Th(8). We also
notice that Th(6) |= at station(train1, stnC) and Th(10) |= at station(train1, stnC).
Hence, the pfr is simply 0.5.
Our second type of frequency function, called an existential frequency function, does not force G to occur exactly t units of time after F is true. It can
occur at or before t units of time elapse after F becomes true.
Definition 2.13 (Existential Frequency Function). Let Th be a thread, F
and G be formulas, and t ≥ 0 be an integer. An Existential Frequency Function, denoted e f r(Th, F, G, t), is defined as follows.4
efn(Th, F, G, t, 0, tmax )

.
efr(Th, F, G, t) = 
{t : (t ≤ tmax − t) ∧ Th(t) |= F} + efn(Th, F, G, t, tmax − t, tmax )

If the denominator is zero (if there is no t ∈ [0, tmax − t] such that Th(t) |= F
and efn(Th, F, G, t, tmax − t, tmax ) = 0), then we define efr to be 1.
Note that in the denominator of efr, after time tmax − t, we only count
satisfaction of F if it is followed by satisfaction of G within [tmax − t, tmax ].
LEMMA 2.14.

efr satisfies Axioms FF1-FF4.

e f n(Th, F, G, t, t1 , t2 ) = |{t : (t1 ≤ t ≤ t2 ) and Th(t) |= F and there exists t ∈ [t +
1, min(t2 , t + t)] such that Th(t ) |= G}|.

4 Where

ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:12

•

P. Shakarian et al.

The point frequency function expresses what is desired in situations where
there is a precise temporal relationship between events (if one drops an object
from a height of 9.8 meters in a vacuum, it will hit the ground in exactly
√
2 seconds). However, it can be very brittle. Consider mail delivery where one
knows a package will arrive in at most 5 business days 95% of the time. The
existential frequency function efr allows for the implied√
condition to fall within
some specified period of time rather than after exactly 2 seconds as before.
Example 2.6 (Existential Frequency Function).
Example 2.4. Suppose we want to calculate:

Consider thread Th from

efr(Th , at station(train1, stnB), ¬at station(train1, stnC), 2).
In English, this is the ratio of times that at station(train1, stnB) is followed
by ¬at station(train1, stnC) in two units of time in thread Th . We can see that
formula at station(train1, stnB) is satisfied by two worlds: Th (5) and Th (8). Consider world Th (6), which occurs one time unit after world Th (5). We can easily
see that Th (6) |= ¬at station(train1, stnC). However, Th (7), two units later, does
satisfy ¬at station(train1, stnC). As Th (9) also satisfies ¬at station(train1, stnC),
we have a world within two time units after every world that satisfies
at station(train1, stnB). Hence, the efr is 1 in this case.
Properties of pfr. Because of the requirement for F2 to be satisfied after a
specific t, pfr has several properties (all formulas F1 , F2 below are assumed
to be satisfiable).
(1) pfr(Th, F1 , F2 ∨ F3 , t) ≥ max(pfr(Th, F1 , F2 , t), pfr(Th, F1 , F3 , t)) (valid
for efr as well).
(2) pfr(Th, F1 , F2 ∧ ¬F3 , t) = pfr(Th, F1 , F2 ∧ F3 , t) − pfr(Th, F1 , F3 , t).
(3) pfr(Th, F1 , F2 , t) ≤ pfr(Th, F1 ∧ F3 , F2 , t) ⇒ pfr(Th, F1 ∧ ¬F3 , F2 , t) ≤
pfr(Th, F1 , F2 , t).
(4) pfr(Th, F1 , F2 ∧ F3 , t) ≤ min(pfr(Th, F1 , F2 , t), pfr(Th, F1 , F3 , t)).
(5) If pfr(Th, F1 , F2 , t) = a and pfr(Th, F1 , F3 , t) = b then
pfr(Th, F1 , F2 ∧ F3 , t) ≥ a + b − 1.
Properties of efr: efr satisfies all of the same properties as pfr. In addition,
efr has the property that:
efr(T h, F1 , F2 , t) ≥ efr(T h, F1 , F2 , t − 1).
The following result provides some links between pfr and efr.
PROPOSITION 2.15.

Let Th be a thread, F and G be formulas,

(1) Let t1 and t2 be two positive integers. If t1 ≤ t2 , then:
pfr(T h, F, G, t1 ) ≤ efr(T h, F, G, t2 ).
(2) Let t be a temporal interval. The following inequality always holds:
efr(T h, F, G, t) ≤

t


pfr(T h, F, G, i)

i=1
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:13

2.4 Satisfaction of Rules and Programs
We are now ready to define satisfaction of an Annotated Probabilistic Temporal
(APT) rule.
Definition 2.16 (Satisfaction of APT rules). Let r be an APT rule with frequency function fr and I be a tp-interpretation.
fr

(1) For r = F ; G : [t, , u], we say that I satisfies r (denoted I |= r) if and
only if

≤
I(Th) · fr(Th, F, G, t) ≤ u.
Th∈T
fr

(2) For r = F → G : [t, , u, α, β], we say that I satisfies r (denoted I |= r), if
and only if

≤
I(Th) ≤ u.
Th∈T ,
α≤fr(Th,F,G,t)≤β
fr

Intuitively, the unconstrained APT rule F ; G : [t, , u] evaluates the probability that F leads to G in t time units as follows: for each thread, it
finds the probability of the thread according to I and then multiplies that
by the frequency (in terms of fraction of times) with which F is followed
by G in t time units according to frequency function fr. This product is
a little bit like an expected value computation in statistics where a value
(frequency) is multiplied by a probability (of the thread). It then sums up
these products across all threads in much the same way as an expected value
computation.
On the other hand, in the case of constrained rules, the probability is computed by first finding all threads such that the frequency of F leading to G in t
time units is in the [α, β] interval, and then summing up the probabilities of all
such threads. This probability is the sum of probabilities assigned to threads
where the frequency with which F leads to G in t time units is in [α, β]. To
fr
satisfy the constrained APT rule F → G : [t, , u, α, β], this probability must
be within the probability interval [, u].
Example 2.7. Coming back to the train scenario from Figure 3, the following are examples of an unconstrained rule (r1 ) and a constrained rule (r2 ).
efr

r1 : at station(train1,stnC) ; at station(train1,stnB) : [2, 0.85, 1]
efr

r2 : at station(train1,stnB) → at station(train1,stnC) : [2, 0.9, 1, 0.5, 1]
Consider the second tp-interpretation from Example 2.4, which we will call I.
By analyzing the two threads considered possible by I, it is clear that I |= r1 ,
since both threads have the property that after being at station C the train
reaches station B within two time units, and thus the probability of this event
is 1. A similar analysis leads us to confirm that I |= r2 , but we must now verify
that the constraints placed by the rule on the threads hold; these constraints
require that at least half of the times in which the train is at station B, station C
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:14

•

P. Shakarian et al.

be reached within 2 time units. This is indeed the case, since the train stops
twice at station B, once going towards C and once going towards A on its way
back. As before, the sum of probabilities of reaching the station within 2 time
units is 1. Finally, consider the rule:
efr

r3 : at station(train1,stnA) ; at station(train1,stnC) : [2, 0.5, 0.6].
Clearly, I |= r3 , since neither of the threads considered possible by the tpinterpretation satisfy the condition that the train reaches station C within two
time units of being at station A.
The following proposition says that any tp-interpretation that satisfies certain kinds of constrained or unconstrained APT-logic programs also satisfies
a certain APT rule that can be easily constructed from the APT-rules in the
original APT-logic program.
PROPOSITION 2.17. Let I be a temporal interpretation, F and G be formulas,
and t be a temporal interval.
t
pfr
efr
(1) If I |=
{F ; G : [i, i , ui ]} then I |= F ; G : [t, max(i ),
t i=1
min( i=1 ui , 1)].
fr

(2) If I |= F → G : [t,  p, up, a, b] then ∀a , b , au, bu such that a ≤ a ≤ au
fr

fr

and b ≤ b ≤ bu we have I |= F → G : [t,  p, 1, a , bu] and I |= F → G :
[t, 0, up, au, b ].
Note that in unconstrained APT-rules, the , u probability bounds account
for the frequency function as well. In the case of constrained APT-rules, the
, u probability bounds do not account for the frequency function. We now
show that using a special frequency function called a query frequency function, we can use constrained and unconstrained rules to express annotated
formulas.
Definition 2.18 (Query Frequency Function). Let Th be a thread, F and G
be formulas, and t ≥ 0 be an integer. A query frequency function, denoted
qfr(Th, F, G, t) is defined as follows.
(1)
(2)
(3)
(4)
(5)

If G is a tautology then qfr(Th, F, G, t) = 1.
If F is a tautology and G is a contradiction, then qfr(Th, F, G, t) = 0.
If F is a contradiction then qfr(Th, F, G, t) = 1.
If Th(1) |= F and Th(t) |= G then qfr(Th, F, G, t) = 1.
Else, qfr(Th, F, G, t) = 0.

The following result shows that qfr is a valid frequency function.
LEMMA 2.19.

qfr satisfies Axioms FF1-FF4.

qfr allows us to construct constrained and unconstrained rules that are equivalent to arbitrary annotated formulas.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

THEOREM 2.20.
interpretation.

•

14:15

Let q = Q : [t, , u] be an annotated formula, and I be an
qfr

(1) For constrained rule r = TRUE → Q : [t, , u, 1, 1], I |= q if and only if
I |= r.
qfr

(2) For unconstrained rule r = TRUE ; Q : [t, , u], I |= q if and only if I |= r.
The following is an example of how an annotated formula can be expressed
as a rule using qfr.
Example 2.8. Consider the train setting from Figure 3. One of the annotated formulas given in this example was at station(train1, stnA) : [1, 0.5, 0.5].
By applying Theorem 2.20, this formula is equivalent to the constrained rule
r1 and the unconstrained rule r2 :
qfr

r1 : TRUE → at station(train1, stnA) : [1, 0.5, 0.5, 1, 1]
qfr
r2 : TRUE ; at station(train1, stnA) : [1, 0.5, 0.5]
3. CONSISTENCY
3.1 Complexity of Consistency Checking
We are now ready to study the complexity of the problem of checking consistency
of APT-logic programs. We say that an APT-logic program K is consistent if and
only if there is a tp-interpretation I such that I |= K. Before stating complexity
results, we give results that hold for any frequency function and any APT-rule.
The first result follows from axioms FF1-FF4 on frequency functions.
LEMMA 3.1.

fr

Consider the APT-Program {r = F ; G : [t, , u]}.

(1) If G is a tautology, then {r} is consistent if and only if u = 1.
(2) If F is a tautology and G is a contradiction, then {r} is consistent if and only
if  = 0.
(3) If F is a contradiction, then {r} is consistent if and only if u = 1.
(4) If F is not a contradiction, G is not a tautology, and either F is not a
tautology or G is not a contradiction, then {r} is consistent.
Using this lemma, we can show that for any unconstrained APT-rule, the problem of determining if an APT-logic program consisting of just that APT-rule is
consistent using any frequency function is NP-complete.
THEOREM 3.2. Deciding the consistency of an APT-logic program containing
a single unconstrained APT-rule is NP-complete in the size of BL .
The proof of hardness is by reduction from the SAT problem, while membership
in NP relies on manipulating Lemma 3.1.
In deciding the consistency of a single constrained rule, we take a slightly
different approach. The intuition is that if the lower probability bound is not
zero, we must have a thread whose frequency function value falls within [α, β].
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:16

•

P. Shakarian et al.

Otherwise, there is no thread available that would ensure a nonzero probability mass as per the definition of satisfaction. The idea of classifying threads
in this manner for constrained rules comes into play later when we present
consistency-checking algorithms in Section 3.4.
fr

LEMMA 3.3. Let K = {r = F → G : [t, , u, α, β]} be a constrained APTlogic program consisting of a single rule. K is consistent if and only if at least
one of the following conditions hold.
— u = 1 and there exists a thread Thin such that α ≤ fr(Thin, F, G, t) ≤ β.
—  = 0 and there exists a thread Thout such that either α > fr(Thout , F, G, t)
or β < fr(Thout , F, G, t).
— There exists a thread Thin such that α ≤ fr(Thin, F, G, t) ≤ β and a thread
Thout such that either α > fr(Thout , F, G, t) or β < fr(Thout , F, G, t).
Lemma 3.3, used in conjunction with the frequency function axioms, allows
us to prove that deciding the consistency of a single constrained rule is also
NP-complete.
THEOREM 3.4. Deciding the consistency of an APT-logic program containing
a single constrained APT-rule is NP-complete in the size of BL .
The NP-hardness of consistency checking for APT programs (whether constrained, unconstrained, or mixed) with more than one rule follows trivially
from Theorems 3.2 and 3.4. We suspect that the problem of consistency checking for a general APT program is not in NP.
However, if we assume that certain conditions hold, we can show that consistency for an APT-logic program containing multiple APT-rules can be guaranteed. These restrictions are termed Pre-Condition Disjoint, or PCD; intuitively,
they refer to an APT-Program such that there exists a unique world that satisfies exactly one of the rule preconditions (the F formulas). Hence, we say that
the preconditions are “disjoint” from each other. Perhaps such conditions could
be specified by a a tool used to learn the rules from the data-set.
Definition 3.5 (Precondition Disjoint (PCD) APT-Logic Program). Let K be
fr
an APT-Logic Program such that K = {r1 , . . . , rn}, where ri = Fi ; Gi :
fr
[ti , i , ui ] or ri = Fi → Gi : [ti , i , ui , αi , βi ]. K is Precondition Disjoint (PCD)
if the following conditions hold true.
(1)
(2)
(3)
(4)
(5)
(6)
(7)

∀i, if ri is constrained, then βi = 1.
∀i, ti ≥ 1.
∀i there exists a world wi such that wi |= Fi and ∀ jwhere j = i, wi |= F j .
∀i, fri is equal to either pfr, or efr.
tmax ≥ |K| · max(ti ) (where tmax is the length of each thread).
∃ world w∅ such that ∀i w∅ |= Fi and w∅ |= Gi .
∀ri ∈ K, ui = 1.

ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:17

While somewhat limiting, this restriction still allows APT-Logic Programs that
are useful. Consider the following example.
Example 3.1. Consider the set of rules shown in Figure 3. These rules do
not constitute a PCD program for various reasons. For instance, the upper
bound on the probability of the second rule is not 1. Likewise, condition 3 is not
satisfied, since the first and third rules have the same antecedent. However,
the following set of rules satisfies all of the conditions for being a PCD program.
efr

at stn(trn1, stnA) ∧ ¬at stn(trn1, stnB) ∧ ¬at stn(trn1, stnC) ;
at stn(trn1, stnB) : [4, 0.85, 1]
pfr
at stn(trn1, stnB) ∧ ¬at stn(trn1, stnA) ∧ ¬at stn(trn1, stnC) ;
at stn(trn1, stnC) : [2, 0.75, 1]
efr
at stn(trn1, stnC) ∧ ¬at stn(trn1, stnA) ∧ ¬at stn(trn1, stnB) ;
at stn(trn1, stnB) : [3, 0.9, 1]
Conditions 1, 2, 4, and 7 are trivially satisfied, and tmax can be easily chosen
to satisfy condition 5. Condition 3 can be seen to hold by noting that no two
antecedents of rules can be satisfied at once. Finally, condition 6 holds since
the empty world does not satisfy any of the formulas involved in the rules.
The useful feature in a PCD program is that based on the axioms, we are
guaranteed threads with certain frequency function values for each rule. Consider Lemma 3.6, where for any subset of a given APT-program, we are guaranteed the existence of a thread whose frequency is 1 according to the rules in
the subset and is 0 according to the other rules.
fri

LEMMA 3.6. Consider APT-Program K = {r1 , . . . , ri , . . . , rn}, where ri = Fi →
fr
Gi [ti , i , ui , αi , βi ] or ri = Fi ;i Gi : [ti , i , ui ], depending on whether ri is a
constrained or unconstrained rule. If K is PCD, then for any disjoint partition of rules, K1 , K2 , there exists a thread Th such that for all rules ri ∈ K1 ,
fri (Th, Fi , Gi , ti ) = 1, and for all rules ri ∈ K2 , fri (Th, Fi , Gi , ti ) = 0.
The PCD conditions add a one-tailed requirement (the first requirement of
Definition 3.5) to the constrained rules so that β is always one. This allows us
to be guaranteed the existence of threads in the [α, β] bounds. As it turns out,
if the lower bounds on the probabilities are less than a certain amount, we can
create an interpretation to guarantee the consistency of the PCD program.
THEOREM 3.7. For a mixed PCD APT-Program K = {r1 , . . . , ri , . . . , rn}, if for
|K| − 1
all ri , i ≤
, then K is consistent.
|K|
In the appendix, we show how PCD assumptions can be leveraged for a significant reduction in complexity for constrained APT-programs.
3.2 Linear Constraints for Consistency Checking
A straightforward algorithm to find a satisfying interpretation given an APTlogic program K is a brute-force approach that considers each thread. Given
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:18

•

P. Shakarian et al.

k atoms and tmax timepoints, there are 2k possible worlds at each timepoint,
and 2k·tmax possible threads. For ease of notation, we shall refer to the number
of threads as n. Hence, note that a function that is linear in the number of
threads is exponential in the number of atoms.
Let T = {Th1 , . . . , Thi , . . . , Thn} be the set of threads. In our linear program,
we will use the variables V = {v1 , . . . , v j , . . . , vn}. Each vi represents the as
yet unknown probability of thread Thi . We will design the linear program so
that solutions of the linear program are in a one to one correspondence with
interpretations that satisfy the APT-logic program. Thus, if θ is a solution of
the linear program, we want to be sure that the tp-interpretation Iθ such that
Iθ (Thi ) = θ (vi ) is an interpretation that satisfies K.
Hence, given an APT-logic program K, we will construct a set of straightforward linear constraints SLC(K) over variables V = {v1 , . . . , v j , . . . , vn}, such
that the interpretation Iθ associated as in the preceding with any solution θ ,
satisfies K. The set of constraints is as follows.
Definition 3.8 (Straightforward Linear Constraints (SLC)). Let K be an
APT-logic program; the set of straightforward linear constraints contains exactly the following.
n
(1)
j=1 v j = 1.
fr

(2) For each
unconstrained rule Fi ;i Gi : [ti , i , ui ] ∈ K.
(a) i ≤ nj=1 fri (Th j , Fi , Gi , ti ) · v j .

(b) ui ≥ nj=1 fri (Th j , Fi , Gi , ti ) · v j .
fri

(3) For each
constrained rule Fi → Gi : [ti , i , ui , αi , βi ] ∈ K.
vj.
(a) i ≤ Th j ∈T
αi ≤fri (Th j ,Fi ,Gi ,ti )≤βi

vj.
(b) ui ≥ Th j ∈T
αi ≤fri (Th j ,Fi ,Gi ,ti )≤βi

We refer to this set as SLC(K).
The first constraint says that the threads are exhaustive. The second constraint
is derived from the formula for satisfaction of an unconstrained rule, while the
third constraint is derived from the formula for satisfaction of a constrained
rule. Note that the coefficient of v j in constraints (2) and (3) are both constants
(after the calculations are performed), so these constraints are all linear.
Example 3.2. Recall the program Kpower from Figure 4. In this simple example, we supposed the power plant delivers power to a transformer (named
tr), which is in turn connected via a power line (named ln) to a home. Hence, the
atoms func(tr) and func(ln) denote that the various components are functioning,
and the home receives power only if both tr and ln are func. Therefore, we have
four possible worlds: w0 = {func(tr), func(ln)}, w1 = {func(tr)}, w2 = {func(ln)},
and w3 = ∅. If we set the time limit to 4 days, then there are 44 = 256 possible
threads (each world may occur at each time point). We name these threads
Th0 , ..., Th255 so that the world at time point t of thread Thi is ((i/4t ) mod 4)
(i.e. Th25 is 
w1 , w2 , w1 , w0 ) and associate the variable vi with I(Thi ). We now
show the constraints in SLC(Kpower ).
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:19

Algorithm 1 Compute consistency of K using SLC
SLC-CONSISTENT(APT−Program K)
(1) Construct SLC(K).
(2) Attempt to solve SLC(K).
(3) If solvable, return consistent, otherwise, inconsistent.

(1)
(2)
(3)
(4)
(5)

i<256

vi = 1.

0.025 ≤ i<256
i=0 pfr(Thi , func(tr) ∧ func(ln), ¬(func(tr) ∧ func(ln)), 1) · vi ≤ 0.03.
i<256
0.95 ≤ i=0 efr(Thi , ¬(func(tr) ∧ func(ln)), func(tr) ∧ func(ln), 3) · vi ≤ 1.

0.05 ≤ i<256
i=0 pfr(Thi , func(ln), ¬func(ln), 1) · vi ≤ 0.1.
i<256
0.99 ≤ i=0 efr(Thi , ¬func(ln), func(ln), 2) · vi ≤ 1.
i=0

Given a solution θ of these constraints, we can see immediately that Iθ
satisfies K.
We provide the following proposition about correctness of this procedure for
mixed programs.
PROPOSITION 3.9. For mixed APT-Logic Program K, K is consistent if and
only if SLC(K) has a solution.
The size of the linear program for SLC follows immediately from the definition. As each rule requires two linear constraints, and one linear constraint is
required to ensure the variables sum to 1, we have 2|K| + 1 constraints. The
number of variables is equal to the number of threads.
Remark 3.10.

SLC contains 2|K| + 1 constraints and 2|BL |·tmax variables.

Using SLC we can create Algorithm 1, which is guaranteed to give a correct
answer to the question of consistency for any APT-Logic Program. However,
the linear program’s size is exponential in terms of |BL | · tmax , making it a
very expensive operation in many situations. There are several obvious ways
to reduce this cost. One such way would be to consider the set of atoms to be
only the atoms present in the rules. An obvious method to reduce the other
factor in the exponent, tmax , would be to adjust the granularity of time used.
For example, convert all time to hours instead of minutes. However, this would
only provide a correct result in terms of the new granularity. This is an issue
we intend to explore in future research.
It turns out that for arbitrary sets of rules and annotated formulas, one need
not use one variable for each of the 2|BL |·tmax threads. Some threads are equivalent, and may in fact be considered together. We provide two such methods
that consider equivalent threads. One reduces the number of worlds based on
world equivalence and one reduces the number of threads based on frequency
equivalence.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:20

•

P. Shakarian et al.

3.3 World Equivalence
World equivalence uses the following intuition. When two worlds satisfy exactly the same formulas from the APT-program, they are identical from the
APT-program’s point of view. By partitioning the set of worlds into classes of
identical worlds, and working with the classes instead of the individual worlds,
we can create smaller linear programs by associating just one variable with
each equivalence class (rather than one variable with each world, as is the case
of SLC).
fr

Consider the rule F → G : [t, , u, α, β]. The four world-based equivalence
classes resulting from this rule would be the sets of worlds that satisfy F ∧ G,
F ∧ ¬G, ¬F ∧ G, and ¬F ∧ ¬G. We apply this concept to APT-Logic Programs
and divide the set of worlds accordingly. We can treat these resulting equivalence classes as worlds, create world-based thread equivalence classes, and use
them instead of threads. This reduces the number of linear constraints for an
algorithm similar to SLC. One must note, however, that the equivalence classes
must be computed first, which we will show to be NP-complete.
As world equivalence for APT-Logic is based on the formulas found in APTRules and annotated formulas, we will formalize the set of formulas associated
with a program. We introduce the notation formula(K) to denote the set of all
formulas present in an APT-logic program.
fr

formula(K) = {F, G | F → G : [t, , u, α, β] ∈ K} ∪
fr

{F, G | F ; G : [t, , u] ∈ K}.
Example 3.3.
(Kpower ) is then:

Recall the program Kpower from Figure 4. The set formula

{func(ln), ¬func(ln), func(tr) ∧ func(ln), ¬(func(tr) ∧ func(ln))},
since these are the only formulas appearing in Kpower .
The cardinality of formula(K) for a given APT-Logic Program is bounded
by 2|K| since APT-Rules have two formulas, F and G. We notice that for each
world w in 2 BL there is a subset of formula(K) that w satisfies, and a disjoint
subset of formula(K) that w does not satisfy. Hence, with respect to a given set
of formulas, certain worlds are indistinguishable; that is, they satisfy exactly
the same formulas from the set. We call such worlds K-equivalent.
Definition 3.11 (World Equivalence). For APT-logic program K, a world w
is K-equivalent to a world w  (denoted w ≡K w  ) if and only if for all F ∈
formula(K), w |= F if and only if w  |= F.
Example 3.4. Continuing with Kpower from Figure 4, recall the 4 worlds:
w0 = {func(tr), func(ln)}, w1 = {func(tr)}, w2 = {func(ln)}, and w3 = ∅ and the
formula from Kpower :
formula(Kpower ) = {func(ln), ¬func(ln), func(tr) ∧ func(ln), ¬(func(tr) ∧ func(ln))}.

Here w1 is Kpower -equivalent to w3 , since both w1 and w3 do not satisfy the first
formula, do satisfy the second formula, do not satisfy the third formula, and do
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:21

satisfy the fourth formula. However, w1 is not Kpower -equivalent to w2 since w1
satisfies ¬func(ln) (the second formula), while w2 does not.
The relation ≡K can be extended to threads in the obvious way.
Definition 3.12 (Thread Equivalence). For APT-logic program K, a thread
Th1 is K-equivalent to a thread Th2 (denoted Th1 ≡K Th2 ) if and only if for all
time points t, the world Th1 (t) is K-equivalent to world Th2 (t).
Example 3.5. In Example 3.4, we saw that w1 is Kpower -equivalent to w3 .
Assuming four time points, then the thread Th = 
w3 , w1 , w1 , w0  will be equivalent to Th = 
w1 , w3 , w3 , w0 , since at every time point t, Th(t) is a world that
is K-equivalent to world Th (t).
The relation ≡K is an equivalence relation (it is transitive, reflexive, and
symmetric) both for threads and for worlds; therefore, it can be used to construct
a partitioning of threads into equivalence classes. Let T [≡K ] = {P1 , . . . , Pm} be
that partitioning. All threads in each Pi are K-equivalent. The following result
states that these partitions have the useful property that all threads in any
partition Pi have the same value for pfr, efr, or qfr for formulas in formula(K):
LEMMA 3.13. For APT-logic program K, partitioning P1 , . . . , Pm of T induced
by ≡K , for all threads Th, Th ∈ Pi , all F, G ∈ formula(K), and all t:
(1) pfr(Th, F, G, t) = pfr(Th , F, G, t).
(2) efr(Th, F, G, t) = efr(Th , F, G, t).
(3) qfr(Th, F, G, t) = qfr(Th , F, G, t).
Lemma 3.13 tells us that each partition Pi has a unique value for pfr, efr,
and qfr (for each F, G, and t). We introduce the notation pfr(Pi , F, G, t),
efr(Pi , F, G, t), and qfr(Pi , F, G, t) to denote these values. For technical reasons, we associate a label with each thread Th such that all threads in the
same partition Pi have the same label. To define the label, we first order the
set formula(K) = {F1 , · · · , Fn}. Then, for a thread Th, we assign label(Th) to be
a length tmax · n bitstring where bit t · i (1 ≤ t ≤ tmax and 1 ≤ i ≤ n) is 1 if
Th(t ) |= Fi and 0 if Th(t ) |= Fi .
Clearly, all Th, Th in the same partition Pi have the same label. Also, all
partitions Pi have a unique label equivalent to the labels of the contained
threads and denoted label(Pi ). There are at most as many partitions as there
are length tmax · n bitstrings, and determining if there is a partition associated
with a given bitstring b can be done by checking if there is thread whose label
is b.
Example 3.6.
follows.


Using Kpower from Figure 4, we number formula(Kpower ) as

	
F1 = func(ln), F2 = ¬func(ln), F3 = func(tr) ∧ func(ln), F4 = ¬(func(tr) ∧ func(ln)) .

Here, the label for Th = 
w3 , w1 , w1 , w0  (worlds wi defined in Example 3.4) is
0101

  
 0101

  
 1010

  
 .

  
 0101
w3

w1

w1

w0

ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:22

•

P. Shakarian et al.

To see this, consider the first four digits 0101 for world w3 . World w3 does not
satisfy F1 , hence the first 0. It does, however, satisfy F2 and F4 causing the
second and fourth digits to be 1.
The thread Th = 
w1 , w3 , w1 , w0  has the same label: 0101010101011010;
any two threads which are Kpower -equivalent will have the same labels.
We immediately notice that the number of thread partitions is potentially
smaller than the number of threads. While there are 2 BL ·tmax threads, there
are only 2|formula(K)|·tmax ≤ 22|K|·tmax partitions. Therefore, using these partitions,
rather than threads, is preferable in designing linear constraints. We can use
Lemma 3.13 to construct smaller sets of linear constraints than SLC. For these
constraints, we introduce the variable v̂lbl , where lbl is a length tmax ·|formula(K)|
mass assigned
bitstring (lbl ∈ {0, 1}|formula(K)|tmax ) representing the probability

to the set of threads in the partition labeled lbl (v̂lbl = Th∈Pi ,label(Pi )=lbl I(Th)).
We can now define the first alternative set of linear constraints.
Definition 3.14 (World Equivalence Linear Constraints (WELC)). Let K be
an APT-logic program that uses only the frequency functions pfr and efr; the
set of World Equivalence Linear Constraints, WELC(K), contains exactly the
following.

(1)
i v̂i = 1.
fr

(2) For 
F → G : [t, , u, α, β],
(a) lbl∈{l|α≤ f r(Pi ,F,G,t)≤β∧l=label(Pi )} v̂lbl ≥ .
(b)
lbl∈{l|α≤ f r(Pi ,F,G,t)≤β∧l=label(Pi )} v̂lbl ≤ u.
fr

(3) For 
F ; G : [t, , u],
(a)  Pi f r(Pi , F, G, t)v̂label(Pi ) ≥ .
(b)
Pi f r(Pi , F, G, t)v̂label(Pi ) ≤ u.
(4) For all lbl ∈ {0, 1}|formula(K)|·tmax for which there is no Pi such that lbl =
label(Pi ), v̂lbl = 0.
Example 3.7. WELC(Kpower ) (based on program Kpower from Figure 4) is constructed using variables v̂lbl for each of the 24·4 = 65, 536 possible labels. Due to
constraint 4, at most 256 of these variables will be nonzero, since there are 256
worlds to populate these 65, 536 possible equivalence classes. We will therefore
be able to eliminate all but at most 256 of the variables from the representation
altogether, since they will be known to be zero in every possible solution. As
such, we only need to use the variables not eliminated via constraint 4 when
constructing WELC(Kpower ), and we will do so in this example. The only labels
that will have associated threads are those that are combinations of the labels
for the worlds w0 , w1 , w2 , and w3 (defined in Example 3.2). With formula(Kpower )
being



	
F1 = func(ln), F2 = ¬func(ln), F3 = func(tr) ∧ func(ln), F4 = ¬(func(tr) ∧ func(ln)) ,

these labels are lbl(w0 ) = 1010, lbl(w1 ) = 0101, lbl(w2 ) = 1001 and lbl(w3 ) =
0101. So, for any label lbl, each four digit sequence must be 1010, 0101, or 1001.
Otherwise there cannot possibly be a thread Th such that label(Th) = lbl. In
fact, since there are only 3 labels for the worlds (w1 and w2 , being Kpower ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:23

Algorithm 2 Compute consistency of K using WELC
WELC-CONSISTENT (APT−Program K)
(1) Construct WELC(K).
(2) Attempt to solve WELC(K).
(3) If solvable, return consistent, otherwise, inconsistent.

equivalent, share a label), we know that when there are four time-points, there
are only 34 = 81 variables that can be nonzero in our linear program (one label
at each
 time-point). So, leaving out the zeroing constraints and supposing each
sum lbl sums over those 81 variables not known to be zero via the zeroing
constraints, the set of linear constraints is as follows.
WELC(Kpower ) =
(1)
(2)
(3)
(4)
(5)



v̂lbl = 1

0.025 ≤ lbl pfr(Thi , func(tr) ∧ func(ln), ¬(func(tr) ∧ func(ln)), 1) · v̂lbl ≤ 0.03

0.95 ≤ lbl efr(Thi , ¬(func(tr) ∧ func(ln)), func(tr) ∧ func(ln), 3) · v̂lbl ≤ 1

0.05 ≤ lbl pfr(Thi , func(ln), ¬func(ln), 1) · v̂lbl ≤ 0.1

0.99 ≤ lbl efr(Thi , ¬func(ln), func(ln), 2) · v̂lbl ≤ 1
lbl

Note that this set of linear constraints is substantially smaller than
SLC(Kpower ), which used 256 variables, where WELC(Kpower ) uses only 81 variables and exactly the same number of constraints (after removal of trivial
zeroing constraints).
PROPOSITION 3.15.
if K is consistent.

For any APT-program K, WELC(K) is solvable if and only

This approach can provide a substantial speedup. As we noted earlier, the
number of partitions is bounded by 22|K|·tmax , which will often be much smaller
than the number of threads, 2|BL |·tmax . Further, the number of partitions is bound
by the number of threads, regardless of the size of K.
PROPOSITION 3.16.
variables.

WELC requires 2|K| + 1 constraints and at most 22|K|tmax

This suggests Algorithm 2 for checking consistency of K. The complexity of
Algorithm 2 comes from both creating and solving WELC. Proposition 3.16 gives
the number of constraints required of a linear program to implement WELCCONSISTENT. Building WELC is also difficult. We have constraint 4, which
requires the inclusion of the constraint v̂lbl = 0 if there is no nonempty partition
in T [≡K ] with label lbl. Unfortunately, this is an NP-complete operation.
THEOREM 3.17. For APT-Logic Program, K, and label lbl, determining if
there is nonempty Pi ∈ T [≡K ] such that label(Pi ) = lbl is NP-complete.
To properly construct WELC, we must solve SAT for every subset of
formula(K). As formula(K) ≤ 2|K|, this amounts to O(22|K| ) calls to a SAT
solver. Assuming O(2|BL | ) operations per SAT solution procedure, this operation
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:24

•

P. Shakarian et al.

Fig. 7. For a set of atoms consisting of scandal, and tmax of 3 time points, this chart shows
pfr

the pfr for all possible threads based on a program consisting only of rule scandal → ¬scandal :
[1, 0.89, 0.93, 0.8, 1.0] from Figure 1. Figure 8 groups these threads in frequency equivalence classes
based on pfr.

will take time O(22|K|+|BL | ). However, as for most linear program implementations, the running time for WELC-CONSISTENT will be exponential in terms
of 7|K|tmax [Karmarkar 1984], the generation of world equivalence classes will
be dominated by WELC itself. Therefore, in most cases, Algorithm 2 will have a
better big-O run time than solving the set of straightforward linear constraints.
3.4 Frequency Equivalence
For constrained rules it is possible to develop a different set of linear constraints. Rather than considering equivalent worlds, we develop a partition of
the set of threads based on the value of the frequency function with respect to
each rule in the program. We will then create a new set of linear constraints
based on this equivalence, as with WELC, in order to improve performance.
Therefore, the partitions will depend on the thread’s relationship to the
probability interval [α, β], which we shall refer to as the frequency bounds for
a given rule. Due to the requirement of considering the frequency bounds, this
type of thread equivalence will be referred to as frequency equivalence and
apply only to constrained rules, though there are manipulations one can apply
to include annotated formulas; we first define an equivalence relation over
threads.
Definition 3.18 (Frequency Equivalence). For threads Th1 and Th2 , and
fr
constrained rule r = F → G : [t, , u, α, β], we say Th1 is r-frequencyequivalent to Th2 (denoted Th1 ∼r Th2 ) if and only if (α ≤ fr(Th1 , F, G, t) ≤
β ⇔ α ≤ fr(Th2 , F, G, t) ≤ β). For APT-Logic Program K containing only constrained conditionals, we say Th1 is K-frequency-equivalent to Th2 (denoted
Th1 ∼K Th2 ) if and only if for all rules r ∈ K, Th1 ∼r Th2 .
pfr

Example 3.8. Consider rule scandal → ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]
from Figure 1, where we used APT-Rules to represent the behavior of stock
price based on news reports. Let K f r−ex be an APT-program containing exactly
this rule. We will consider the set of atoms to consist only of scandal and tmax
to be 3. In Figure 7 we compute the pfr based on this single rule for all possible
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:25

pfr

Fig. 8. For a program consisting only of rule scandal → ¬scandal : [1, 0.89, 0.93, 0.8, 1.0] from
Figure 1, we have frequency equivalence classes E1 and E2 based on the pfr for all possible threads
seen in Figure 7.

threads. In Figure 8 we can then group these threads into two equivalence
classes, those whose pfr is within [0.8, 1], and those whose frequency is outside
this range.
For instance, threads 
scandal, scandal, scandal and 
scandal, scandal,
¬scandal both have a pfr less than 0.8. Therefore, we have that

scandal, scandal, scandal ∼K f r−ex 
¬scandal, scandal, scandal.
The relation ∼K satisfies several common properties of relations.
PROPOSITION 3.19. For any constrained APT-logic program K, ∼K is reflexive,
symmetric, and transitive.
Therefore ∼K is an equivalence relation, and we can partition T (the set
of all possible threads) into equivalence classes according to a given ∼K . We
let T [∼K ] be this partitioning, where each set E ∈ T [∼K ] contains only Kfrequency-equivalent threads. We then assign each set E a binary string str(E)
of length m (the number of constrained formulas in K), where digit i is 1 if for
all Th ∈ E, αi ≤ fr(Th, Fi , Gi , ti ) ≤ βi , and 0 otherwise.
Example 3.9. In Figure 8 we see a partitioning of the threads T [∼K f r−ex ]
with two partitions: E1 and E2 . The associated binary strings are: str(E1 ) = 1
and str(E2 ) = 0. Notice that we only have two frequency equivalence classes of
threads, which is only 25% of the 8 threads we had originally.
In the following linear program, we introduce variables v̄b for each binary
string b of length |K|.
Definition 3.20 (Frequency-Equivalence Linear Constraints). For
constrained APT-Logic Program K, the set of Frequency-Equivalence Linear
Constraints FELC(K) contains only the following.

(1)
E∈T [∼K ] v̄str(E) = 1 (where str(E) is the binary number that labels frequency equivalence class E).
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:26

•

P. Shakarian et al.

Algorithm 3 Compute consistency of K using FELC
FELC-CONSISTENT (APT−Program K)
(1) Construct FELC(K).
(2) Attempt to solve FELC(K).
(3) If solvable, return consistent, otherwise, inconsistent.

(2) For all length |K| binary strings b if there is no E ∈ T [∼K ] such that
str(E) = b, then v̄b = 0.

fr
(3) For all Fi → Gi : [ti , i , ui , αi , βi ] ∈ K, i ≤ s∈[0,1]m,si =1 v̄s ≤ ui .
THEOREM 3.21. For constrained APT-Logic Program K, K is consistent if
and only if there is a solution to FELC(K).
As FELC provides a correct result for consistency, we can use it to develop the
consistency-checking algorithm FELC-CONSISTENT shown in the following.
If the frequency equivalence classes of threads for a given program are
known, FELC also offers an improvement in complexity over SLC.
PROPOSITION 3.22.

FELC requires 2|K| + 1 constraints and 2|K| variables.

Example 3.10. Consider the APT-Program Kstock from Figure 1. Let BL be
the set of atoms seen in that program (hence |BL | = 5). We consider a tmax of 4.
From Proposition 3.10, we know that using SLC to determine the consistency of
Kstock would require 7 constraints and 220 = 1,048,576 variables. We show in the
following a set of linear constraints based on FELC that requires 7 constraints
and only 23 = 8 variables. For the program Kstock , we have the following linear
constraints.
pfr

— For rule scandal → ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]
0.89 ≤ v̄001 + v̄011 + v̄101 + v̄111 ≤ 0.93.
pfr

— For rule sec rumor ∧ earn incr(10%) → stock decr(10%) : [2, 0.65, 0.97,
0.7, 1.0] 0.65 ≤ v̄010 + v̄011 + v̄110 + v̄111 ≤ 0.97.
— For rule
pfr
sec rumor ∧ earn incr(10%) → stock decr(10%) ∧ cfo resigns : [2, 0.68, 0.95,
0.7, 0.8]
0.68 ≤ v̄100 + v̄101 + v̄110 + v̄111 ≤ 0.95.
— v̄000 + v̄001 + v̄010 + v̄011 + v̄100 + v̄101 + v̄110 + v̄111 = 1.
The running time of consistency checking via FELC is independent of the
number of atoms or time points or number of worlds. Thus, even though it
runs in time exponential in |K|, it will in many cases run faster than SLC,
which runs in time linear in |K|, and exponential in the number of worlds or
the number of time points. Further, since the size of K, the number of worlds,
and the number of time points are all known in advance, one can tell which
approach will be faster dynamically, and dispatch the smaller, faster linear
program.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:27

Algorithm 4 Find Frequency Equivalence Classes of Constrained Program K
BFECA(APT−Program K)
(1) Generate all possible threads.
(2) For each thread, Th, for all i, compute fri (Th, Fi , Gi , ti ).
(3) Determine for each thread, Th, for each rule, ri , if the associated frequency function,
fri for Th falls within the range [αi , βi ].
(4) Based on the result of step 3, determine which frequency equivalence class Th
belongs to.
(5) After all threads are generated, return EMPTY if there are no threads found for a
given frequency equivalence class is empty and OK otherwise.

However, as with WELC, significant computation cost is required to construct
the linear constraints, specifically in identifying the frequency equivalence
classes that are empty. We refer to the obvious, exhaustive, and exact method for
identifying empty frequency equivalence classes as the Brute Force Frequency
Equivalence Class Algorithm or BFECA.
As BFECA exhaustively considers all threads, we have the following trivial
proposition concerning correctness.
PROPOSITION 3.23. For each frequency equivalence class C, if C is empty
BFECA returns EMPTY; otherwise, if C contains at least one thread, BFECA
returns OK.
For each thread, BFECA calculates the frequency function with regard to each
rule. Hence, for each of the 2|BL |tmax threads, it calculates |K| frequency functions.
This leads us to the following complexity result.
PROPOSITION 3.24.

The complexity of BFECA is:


O 2|BL |tmax · F(tmax ) · |K| ,

where F(tmax ) is defined as follows. Suppose timei is the time required to compute
fri (Th, Fi , Gi , ti ), then F(tmax ) equals maxi (timei ).
Note that if F(tmax ) is linear, then the complexity of finding the frequency
equivalence classes and then performing FELC is still better than SLC. The
dominating term in the complexity of FELC has an exponent of |BL | · tmax when
BFECA is used. SLC, on the other hand, will have an exponent of 3.5·|BL |·tmax for
most linear program solvers [Karmarkar 1984]. The following example shows
how BFECA works.
Example 3.11.

Consider the FELC constraints set up for Kstock in Exampfr

ple 3.10. Look at rules sec rumor ∧ earn incr(10%) → stock decr(10%) :
pfr

[2, 0.65, 0.97, 0.7, 1.0] and sec rumor ∧ earn incr(10%) → stock decr(10%) ∧
cfo resigns: [2, 0.68, 0.95, 0.7, 0.8]. For a given thread, Th, consider the pfrs
associated with those rules. Let p1 = pfr(Th, sec rumor ∧ earn incr(10%),
stock decr(10%), 2), and p2 = pfr(Th, sec rumor ∧ earn incr(10%), stock
decr(10%) ∧ cfo resigns, 2).
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:28

•

P. Shakarian et al.

Algorithm 5 World Equivalence for finding Frequency Equivalence Classes of
Constrained Program K
WEFE(APT−Program K)
(1)
(2)
(3)
(4)

Find the world equivalence classes based on formula(K).
Generate all world-equivalence based thread partitions for K.
For each world-equivalence thread partition, P, for all i, compute fri (P, Fi , Gi , ti ).
For each rule, ri let I Ni be the set of thread partitions such that αi ≤
fri (P, Fi , Gi , ti ) ≤ βi . For each rule, let OU Ti be all partitions not in I Ni .
 


(5) For string s ∈ [0, 1]|K| let the set PC LASSs be defined as
si =1 I Ni ∩
si =0 OU Ti .

(6) For each class cls return EMPTY if PC LASSs ≡ ∅ and OK otherwise.

We note that p2 must be less than or equal to p1 as the G formula for both
rules differs only by one conjuncted atom. Therefore, there is no possible Th
such that p2 > p1 . Hence, variables v̄100 and v̄101 from the FELC constraints in
Example 3.10 must be set to zero.
To find such variables, BFECA calculates the frequency function for all possible threads. However, with SLC-CONSISTENT, the dominating term in this
example requires 270 operations, where BFECA requires only 220 operations.
Note that the complexity of BFECA often will dominate the complexity of FELCCONSISTENT.
As suggested earlier, FELC can be used on programs that consist of both
constrained rules and annotated formulas. We can include annotated formulas
in our constrained program by writing rules that are essentially equivalent to
annotated formulas, as described earlier through use of the Query Frequency
Function in Definition 2.18.
Note that if the PCD conditions are met (Definition 3.5), we can often be
guaranteed that all FELC equivalence classes will be nonempty, making the
BFECA algorithm unnecessary. See the Appendix for a complete discussion of
this special case.
3.5 Combining World and Frequency Equivalence
We have introduced two improved methods for computing consistency: FELCCONSISTENT/BFECA and WELC-CONSISTENT. We now introduce a hybrid
approach that uses the world-equivalence classes of WELC to ease the computation necessary to compute the frequency-equivalence classes needed in FELC.
World-equivalence can be used to determine if a frequency equivalence class
is empty or not. The intuition is simple: we follow the approach of BFECA,
generating the set of threads and finding the frequency function for each one.
However, rather than generating the set of threads, we generate the set of
world-based thread partitions and find their frequency functions. As shown
in the discussion of WELC, the number of world-based thread partitions can
be considerably less than the number of threads. Hence, we present worldequivalence for finding frequency equivalence, or WEFE.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:29

As WEFE exhaustively considers all world-equivalence-based thread partitions, and each thread belongs to exactly one partition, WEFE provides a correct
answer.
PROPOSITION 3.25. If a given frequency equivalence class is empty, WEFE
returns EMPTY. If there is a thread in a given frequency equivalence class,
WEFE returns OK.
The computational complexity of this algorithm is dependent upon the number of thread-partitions resulting from world-equivalence. As stated before,
this is 22|K|·tmax . Further, the cost of calculating the frequency function for each
thread is only O(tmax ), as checking the satisfiability of the F and G formulas in
a rule by a world equivalence class is a trivial operation, since the satisfaction
is predetermined when the world-equivalence classes are generated.
PROPOSITION 3.26.

The complexity of WEFE is


O 22|K|·tmax · tmax · |K|

when the set of world-equivalence classes for K is known.
WEFE/FELC-CONSISTENT is generally preferable for checking the consistency of constrained programs. Because it considers threads on a worldequivalence basis rather than individually, it should generally have a shorter
run time than BFECA even taking into account the costs of constructing worldequivalence classes. We illustrate this in the following example.
Example 3.12. Suppose we want to build FELC constraints for Kstock as we
did in Example 3.10, where tmax = 4. We note that formula(Kstock ) consists of
the following:
(1)
(2)
(3)
(4)
(5)

scandal;
¬scandal;
sec rumor ∧ earn incr(10%);
stock decr(10%);
stock decr(10%) ∧ cfo resigns.

Although the number of world equivalence classes, based on formula(Kstock )
would be 25 , which is also the number of worlds, since there are only 5 atoms
referenced in the program, we note that many of the world equivalence classes
are empty. For example, we know that there can be no world that satisfies
both of the first two formulas, which immediately reduces our number of world
equivalence classes by a factor of two. Further, there can be no world that does
not satisfy stock decr(10%) but satisfies stock decr(10%) ∧ cfo resigns. Hence,
the number of world equivalence classes is 12 in this case, a significant reduction from the 32 worlds originally considered.
Therefore, WEFE only considers 124 = 20, 736 world-equivalent threads,
as opposed to BFECA, which considers 324 =1,048,576 threads. Note that if
the world-equivalence classes are known, this cost of WEFE may still dominate FELC-CONSISTENT. This is a vast improvement over the 270 operations
required by SLC-CONSISTENT.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:30

•

P. Shakarian et al.

4. ENTAILMENT BY APT-LOGIC PROGRAMS
Now that we have dealt with consistency, we can explore the issue of entailment,
which is defined in the usual way.
Definition 4.1 (Entailment). Let K be an APT-logic program, r be a rule,
and af be an annotated formula. We say that K entails af if and only if for all
models I of K, I |= af , and that K entails r if and only if for all models I of K,
I |= r.
Example 4.1 (Entailment).
following APT-Program.

Recall that in Example 3.8 we presented the
pfr

K f r−ex = {scandal → ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]}.
Suppose we form the following rule as a hypothesis.
pfr

rhyp = scandal → ¬scandal : [1, 0.88, 0.94, 0.8, 1.0].
Does K f r−ex entail rhyp ? A quick examination of the only rule in the program
and the hypothesis tells us that except for the probability bounds, they are the
same. Notice that the rule in K f r−ex has probability bounds [0.89, 0.93] and
the probability bounds of rhyp are a superset, [0.88, 0.94]. Therefore, we know
that any interpretation in which the sums of the probabilities of threads with
a frequency ratio between [0.8, 1.0] sum to a quantity in [0.89, 0.93], are also
in [0.88, 0.94]. So, by the definitions of satisfaction and entailment, we can say
that K f r−ex entails rhyp .
The following result shows that checking entailment of an annotated formula
by an APT-logic program is coNP-hard.
THEOREM 4.2. Given an APT-logic program K, and an annotated formula,
af , deciding if K entails af is coNP-hard in |BL | (the number of atoms).

4.1 Linear Constraints for Entailment
We shall now provide algorithms for computing entailment based on the linear
constraints SLC, WELC, and FELC. In all cases, the method is straightforward:
we determine the minimal and maximal probability for the annotated formula
in interpretations satisfying the original knowledgebase by minimizing and
maximizing the appropriate sum subject to some set of linear constraints. Due
to the fact that any annotated formula can be viewed as a constrained rule, we
will not describe the entailment of annotated formulas in this section.
We can show Algorithm 6 to be correct and to take time exponential in |B |
(as expected due to Theorem 4.2).
PROPOSITION 4.3 (CHECKING ENTAILMENT USING SLC). For unconstrained rule
fr
fr
r = F ; G : [t, , u] or constrained rule r = F → G : [t, , u, α, β] and
program K, SLC-ENT returns ENTAILS if and only if K entails r and returns
NOT ENTAILS if and only if K does not entail r.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

•

Annotated Probabilistic Temporal Logic

14:31

Algorithm 6 Entailment of Rule r by Program K with SLC
SLC-ENT(APT−Program K)
fr

fr

(1) If r is unconstrained, (r = F ; G : [t, , u]), create rule r  = F ; G : [t,  , u ]
where  , u are variables.
fr

fr

(2) If r is constrained, (r = F → G : [t, , u, α, β]) create rule r  = F → G :
[t,  , u , α, β] where  , u are variables.
(3) Create set of linear constraints SLC(K ∪ {r  }).
(4) Let ¯ be the minimization of  subject to SLC(K ∪ {r  }).
(5) Let ū be the maximization of u subject to SLC(K ∪ {r  }).
(6) If [¯  , ū ] ⊆ [, u] return ENTAILS otherwise return NOT ENTAILS.

PROPOSITION 4.4. SLC-ENT requires solving at most two linear programs.
Each linear program has 2|K| + 1 constraints and 2|BL ·|tmax variables.
We now give an example of how Algorithm 6 will run in practice.
Example 4.2. Consider APT-Program Kstock introduced in Figure 1 with
tmax = 4. Suppose we want to see if Kstock entails the annotated formula query =
earn decr(10%) : [3, 0.50, 0.80].
qfr

First, we rewrite the query as a rule using q f r. Hence, queryrule = TRUE →
earn decr(10%) : [3, 0.50, 0.80, 1, 1]. From this rule, we create queryrule =
qfr

TRUE → earn decr(10%) : [3,  , u , 1, 1].
We now consider all possible threads given Kstock ∪ {queryrule } and tmax = 4.
As there are 6 atoms in the union of the program and query, we have 224 =
16, 777, 216 possible threads (|T | = 224 ). Hence, we set up the following linear
constraints.
pfr
—For rulescandal → ¬scandal : [1, 0.89, 0.93, 0.8, 1.0]
vj
0.89 ≤ Th j ∈T
0.8≤ pf r(Th j ,scandal,¬scandal,1)≤1.0

0.93 ≥ Th j ∈T
vj
0.8≤ pf r(Th j ,scandal,¬scandal,1)≤1.0

pfr

—For rule sec rumor ∧ earn incr(10%) → stock decr(10%) : [2, 0.65, 0.97,
0.7, 1.0]
vj
0.65 ≤ Th j ∈T
0.7≤ pf r(Th j ,sec rumor∧earn incr(10%),stock decr(10%),2)≤1.0

0.97 ≥ Th j ∈T
vj
0.7≤ pf r(Th j ,sec rumor∧earn incr(10%),stock decr(10%),2)≤1.0

—For rule
pfr
sec rumor ∧ earn incr(10%) → stock decr(10%) ∧ cfo resigns : [2, 0.68, 0.95,
0.7, 0.8]
vj
0.68 ≤ Th j ∈T
0.7≤ pf r(Th j ,sec rumor∧earn incr(10%),stock decr(10%)∧cfo resigns,2)≤0.8

0.95 ≥ Th j ∈T
vj
0.7≤ pf r(Th j ,sec rumor∧earn incr(10%),stock decr(10%)∧cfo resigns,2)≤0.8
qfr



queryrule

—For rule
= TRUE → earn decr(10%) : [3,  , u , 1, 1]

vj
 ≤ Th j ∈T
1≤q f r(Th j ,TRUE,earn decr(10%),3)≤1.0


u ≥ Th j ∈T
vj
1≤q f r(Th j ,TRUE,earn decr(10%),3)≤1.0
 j<224
— j=0 v j = 1.

ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

•

14:32

P. Shakarian et al.

Algorithm 7 The APT-Extract Algorithm
APT-Extract(T , ActCond, MaxBody, , SuppLB, σ ,STAT-Test)
(1) Rules := ∅;
(2) for each combination (environment variable, value) choose 1, . . . , MaxBody {
(3)

let Body be the current combination; supportBody:= 0; supportBoth:= 0;

(4)

for t = 1 to maxTime(T) {

(5)

bodyHappened:= false;

(6)

if Body is true at time t then

(7)

bodyHappened:= true; actHappened:= false;
for d = 1 to  {

(8)

if ActCond is true at time t + d then actHappened:= true;

(9)
(10)

break for;

(11)

}

(12)

if bodyHappened then supportBody:= supportBody + 1;

(13)
(14)

if bodyHappened and actHappened then supportBoth:= supportBoth + 1;
}

(15)

if supportBody <> 0 then confidence:= supportBoth / supportBody;

(16)

else confidence:= 0;

(17)

if (supportBoth > suppLB) ∧ STAT TEST(Body, ActCond) then

(18)

pfr

add Body ; ActCond : [, confidence − σ, confidence + σ ] to Rules;

(19) }
(20) return Rules;

As it turns out, the minimization of  is 0 and the maximization of u is 1. Since
[0, 1] ⊂ [0.5, 0.8], we can say that Kstock does not entail query.
SLC-ENT uses the SLC set of linear constraints. However, one could easily
substitute WELC or FELC for SLC in SLC-ENT. We present an algorithm for
alternate linear constraints, ALC-ENT, that mirrors SLC-ENT and leverages
these other constraints in the appendix.
There is a further improvement that can be made in practice: if we solve the
linear program once, and find that the minimization of  is less than , we have
determined that the rule is not entailed by the program, and solving the linear
program again is not necessary to decide entailment.
5. APPLICATIONS OF APT LOGIC
APT-logic programs have many possible applications; in this section we will
briefly describe an effort to learn conditions under which various terror groups
took various actions, in the form of APT-programs. We assume that the data
is given in the form of a table that contains two kinds of attributes: action
and environment, and that each tuple represents the values of each of these
attributes for a certain time point. A good example of this kind of data is
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:33

the Minorities at Risk Organizational Behavior (MAROB) data set [Wilkenfeld
et al. 2007]. This data set has identified around 150 parameters to monitor
for about 300 groups around the world that are either involved in terrorism or
are at risk of becoming full-fledged terrorist organizations. The 150 attributes
describe aspects of these groups, such as whether or not the group engaged
in violent attacks, if financial or military support was received from foreign
governments, and the type of leadership the group has. It was a simple task to
divide the attributes into actions that could be taken by the group (bombings,
kidnappings, armed attacks, etc.) and environmental conditions (the type of
leadership, the kind and amount of foreign support, whether the group has
a military wing, etc.). Values for these 150 parameters are available for up
to 24 years per group, though it is less for some groups (e.g., groups that have
been around for a shorter duration). For each group, MAROB provides a table
whose columns correspond to the 150 parameters and the rows correspond to
the years. There are many social science data sets that use such data. These
include the KEDS data set from the University of Kansas that tracks country
stability data (rather than terror group data) [Schrodt and Gerner 1998] and
the Political Instability Task Force (PITF) data [Goldstone et al. 2005].
The APT-Extract algorithm provides a basic approach to extracting APTrules.5 The inputs are: a table of historic data, a condition on an action variable
(variable name and value), a maximum size for the body, a value for , a
lower bound for the support of the rule, a real number σ ∈ [0, 1] that will
determine the width of the probability annotations for the extracted rules,
and an arbitrary statistical test (e.g., a t-test or something based on p-values
in statistics) selected by the user, which measures the correlation between
the values of the body of a possible rule and the head. We use the standard
measurements of support and confidence from the literature on association
rules: given table T , the support of a condition C in T is the number of tuples
for which C is true; given conditions C1 and C2 , the confidence in the fact that
C1 is accompanied by C2 is the ratio of the support of C1 ∧ C2 to the support of
C1 . As an example of the kind of rules that can be extracted by this algorithm,
some of the rules extracted from the data for Hezbollah are given in Figure 2.
6. RELATED WORK
In addition to the authors’ past work on probabilistic logic programming [Ng
and Subrahmanian 1992, 1991], probabilistic logic programs were studied
in Kiessling et al. [1992], Kifer and Subrahmanian [1992] and Lakshmanan and
Sadri [1994a, 1994b] and Lakshmanan and Shiri [1997], who showed how to introduce various probabilistic dependencies into probabilistic LPs. Lukasiewicz
[1999] and Lukasiewicz et al. [1999] made major contributions to bottom-up
computations of probabilistic LPs.
Lehmann and Shelah [1982] and Hart and Sharir [1986] were among the
first to provide a logic to integrate time and probability. Kanazawa [1991]
5 Note that this algorithm is not a novel one, and simply performs calculations to capture interesting

relationships present in the data in order to build rules. More complex algorithms for rule extraction
are outside the scope of this article.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:34

•

P. Shakarian et al.

also studied the integration of time and probability in order to facilitate efficient planning. He was primarily interested in how the probability of facts
and events change over time. Haddawy [1991] developed a logic for reasoning
about actions, probability, and time, using an interval time model. Dubois, D
and Prade [1991] developed methods to extend possibilistic logic to handle temporal information. This logic associates, with each formula of possibilistic logic,
a set of time points describing when the formula has a possibilistic truth value.
Halpern and Tuttle [1992] studied the semantics of reasoning about distributed
systems where uncertainty is present using a logic where a process has knowledge about the probability of events for decision making by the process. Fagin
et al. [1990] and Fagin and Halpern [1994] developed logics of time and belief
to model the behavior of distributed systems, while Thomas [1995] developed
a framework that integrates beliefs, time, commitment, desires, and multiple
agents. Baral et al. [2002] developed a language to reason about actions in a
probabilistic setting; their models use static and dynamic causal laws together
with background (unknown) variables whose values are determined by factors
not in the model. Building on top of past work by Dekhtyar et al. [1999], Dix
et al. [2006] introduce heterogeneous temporal probabilistic agents to model
agent behavior and develop a model theory and fixpoint semantics focusing on
agents built using legacy code.
Though there has been extensive work on temporal reasoning, the key difference between APT logic programs and past works in verification [Lamport
1980; Emerson and Halpern 1984; Vardi 1985; Cleaveland et al. 2005; Glabbeek
et al. 1995; Larsen and Skou 1991] is the use of frequency functions in our work
to define the frequency with which a given formula G holds some given time
after a given formula F holds. We show that such a definition can be given
in many different ways, and rather than committing to one such definition,
we provide axioms that any frequency function should satisfy. A result of our
introduction of the frequency function is that the probability an event occurs
at time t is dependent on the events that occur in interval [1, t] and interval
[t, tmax ].
APT-Logic distinguishes itself from other temporal logics in the following
ways.
(1) It provides for reasoning about probability of events within a sequence of
events and probabilistic comparison between sequences of events.
(2) Future worlds can depend on more than just the current world.
(3) It provides bounds on probabilities rather than just a point probability.
(4) It does not make any independence assumptions.
6.1 Markov Decision Processes
Many temporal logics, whether probabilistic or not, make use of some sort
of state transition system as an underlying structure. A state-transition system is said to conform to the Markov Property if each transition probability
only depends on the current state [Russell and Norvig 2003]. We demonstrate
that while APT-Logic Programs maintain much of the expressiveness of most
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:35

state-transition systems, they also have the ability of expressing nonMarkovian sequences of events. The semantic structures used in APT-Logic
(worlds, threads, interpretations) can be represented by state transition systems when the following restrictions are applied.
(1) As APT-Logic only deals with finite temporal sequences, only the first tmax
states generated by an MDP will be considered.
(2) By definition, each world represents a unique set of atoms. Therefore, a
corresponding state transition system must have the restriction that each
state is uniquely labeled; that is, each state in the MDP represents exactly
one world.
(3) Each transition in the MDP takes one unit of time.
Our notation for an MDP most resembles the reactive probabilistic labeled
transition system (RPLTS) [Cleaveland et al. 2005; Glabbeek et al. 1995; Larsen
and Skou 1991]. In the following, we will formally define an MDP with respect
to a set of actions Act, and a set of atomic propositions, BL . When comparing
MDPs to APT-Programs, we will assume that the APT-Program uses the same
set of ground atoms, and that each state in an MDP has a unique atomic label.
In this manner, we can equate MDP states with worlds in tp-interpretations.
Hence, an MDP is defined as follows.
Definition 6.1 (MDP). A Markov Decision Process (MDP) consists of a
4-tuple L = (S, δ, P, lbl, s1 ) where
— S is a finite set of states.
—δ ⊆ S × Act × S is the transition relation.
— P : δ → [0, 1] is the transition
probability distribution, which satisfies:


— ∀s ∈ S, ∀a ∈ Act s :(s,a,s )∈δ P(s, a, s
) ∈ [0, 1];


— ∀s ∈ S, ∀a ∈ Act (∃s (s, a, s ) ∈ δ) ⇒ s :(s,a,s )∈δ P(s, a, s ) = 1.
—lbl : S → 2 BL is the labeling of each state that specifies the set of propositions
that are true in a state. Each state has a unique set of propositions.
—s1 ∈ S is the initial state.
When an MDP is employed with policy π , it means that in state si , action
π (si ) is taken. An MDP that uses only a single policy is often referred to as
a Stochastic Process, or Markov Process. With the definition of an MDP and
notion of a policy, we can now state what it means for a tp-interpretation to
satisfy an MDP.
Definition 6.2. Let L be an MDP, π be a policy, I be a tp-interpretation,
and tmax be the maximum value of time. We say that I satisfies the pair (L, π ) if
and only if: for all sequences of n = tmax states, seq ≡ s1 → . . . → si → . . . → sn,
there exists a thread Th such that
—for every si in seq, a ∈ lbl(si ) if and only if a ∈ Th(i).
n−1
— i=1
P(si , π (si ), si+1 ) = I(Th).
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:36

•

P. Shakarian et al.

Further, we say that an interpretation I satisfies an MDP L and set of policies
POL if and only if there exists a policy π ∈ POL such that I |= (L, π ).
We can extend the notion of entailment described earlier to MDPs and describe entailment relationships between MDPs and APT-Programs. Based on
this idea, we now can define a notion of equivalence between an MDP and an
APT-Program as follows.
Definition 6.3 (Equivalence/Entailment). An MDP L and set of policies
POL is equivalent to APT-Program K when tp-interpretation I |= (L, POL)
if and only if I |= K. (L, POL) is said to entail K if for all tp-interpretations
I, if I |= (L, POL), then I |= K. Finally, K is said to entail (L, POL) if for all
tp-interpretations I, if I |= K, then I |= (L, POL).
With this notion, given an MDP and policy, we can now create an APT-Logic
Program such that the set of satisfying interpretations for the MDP and policy
is the same as the set of satisfying interpretations for the APT-Logic Program.
We use these notions of entailment and equivalence to specify the semantic
relationship between APT-Logic and MDPs: if for any APT-Program there is
an equivalent MDP and a set of policies, then we will consider APT-Logic to be
no more expressive than MDPs. Soon we will see this is not the case, and that
APT-Logic is in fact more expressive than MDPs.
First however, we provide the following
F is a mapping

 formula notation.
of states to formulas such that F(s) ≡ ( a∈lbl(s) a) ∧ ( b/∈lbl(s) ¬b). Second, we
provide the following probability measurement of a t-length sequence starting
with state s1 and ending with state st . We use the notation s →t s to denote the
set of sequences of t transitions from s to s .
Definition 6.4 (Sequence Probability Measure). Let L be an MDP, π be a
policy, s1 , st be states, and t be a positive integer. The sequence probability
measure, SP M is defined as follows.

 t−1


SP ML,π (st , t) =
P(si , π (si ), si+1 ) .
s1 →t−1 st

i=1

So, the SPM totals the probabilities of all sequences from the initial state to st
in t − 1 transitions.
Next, we will present Algorithm 8, which given an MDP and set of policies (L, POL), creates an APT-Program K such that (L, POL) entails K. This
construction is guaranteed to be correct by the following theorem.
THEOREM 6.5. If an interpretation I satisfies MDP L with set of policies L,
then it satisfies APT-Program K generated from MAKE-APT.
Clearly, if we restrict the MDP to a single policy, then we can create an
APT-Program using MAKE-APT, which is equivalent to the MDP and single
policy.
COROLLARY 6.6. An interpretation I satisfies MDP L with policy π , if and
only if it satisfies APT-Program K generated from MAKE-APT.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:37

Algorithm 8 Generate APT-Program that is entailed by a given MDP and set
of policies
MAKE-APT(MDP L, PolicySet POL)
(1) Create annotated formula F(s1 ) : [1, 1, 1].
(2) For each state s, and each time point t, there are |POL| SPM’s, one for each policy.
Let min(SP ML,π (s, t)) be the minimum such SPM.
(3) For each state s, and each time point t, let max(SP ML,π (s, t)) be the maximum SPM.
(4) For each time point
t ∈ [1, tmax ], and each state si , create

 the following annotated
formula: F(si ) : t, min(SP ML,π (si , t)), max(SP ML,π (si , t)) .

It is interesting to note, however, that although we can create an APT-Logic
Program that is entailed by a given MDP and set of policies, we cannot always
create an APT-Logic Program that entails an MDP and a set of policies. The
intuition is that, in certain circumstances we are guaranteed that an APT-Logic
Program has an infinite number of satisfying interpretations. If an MDP and
set of policies are created such that these circumstances hold, then creating
an APT-Program that entails the given MDP and set of policies is impossible.
Hence, we first make the claim of the special circumstance that guarantees
an infinite number of satisfying interpretations. The claim is that for APTProgram K, if there exists satisfying tp-interpretations for K, I1 , I2 , such that
for threads Th1 , Th2 , I1 (Th1 ) = 1, and I2 (Th2 ) = 1, then there is an infinite
number of satisfying interpretations for K. We describe why this is true in the
following paragraph.
Let c ∈ (0, 1) and b ∈ (c, 1). Let I3 represent an infinite number of interpretations such that I3 (Th1 ) = b and I3 (Th2 ) = (1 − b). K is then satisfied by an
infinite number of interpretations if all possible I3 interpretations satisfy K.
Suppose by way of contradiction that some I3 does not satisfy K. We have two
cases.
—Case 1. There exists an unconstrained rule, r such that I3 |= r. Let
fr
r = F ; G : [t, , u]. Let a1 = fr(Th1 , F, G, t) and a2 = fr(Th2 , F, G, t).
Let a1 ≤ a2 . By the definition of satisfaction, we
 know that [a1 , a2 ] ⊆ [, u]. By
thedefinition of satisfaction, we know that Th∈T I3 (Th)fr(Th, F, G, t) < 
or Th∈T I3 (Th)fr(Th, F, G, t) > u as I3 |= r. Therefore, b · a1 + (1 − b) · a2 < 
or b · a1 + (1 − b) · a2 > u. However, clearly, b · a1 + (1 − b) · a2 ⊆ (a1 , a2 ), which
implies b · a1 + (1 − b) · a2 ⊆ [, u]. Hence, we have a contradiction.
fr

—Case 2. There exists a constrained rule, r such that I3 |= r. Let ri = F → G :
[t, , u, α, β]. We have three cases.
— Case 2.1. Th1 , Th2 ∈ ATSi . Then,  ≤ 1 ≤ u and the probabilities of
both threads summed together must fall in these probability bounds. As
I3 (Th1 ) + I3 (Th2 ) = 1, I3 then must satisfy ri , so we have a contradiction.
— Case 2.2. Either Th1 ∈ ATSi or Th2 ∈ ATSi . If  = 1, then there exists
c ∈ (0, 1) such that there is an infinite number of interpretations as per
the definition of I3 such that I3 |= ri . If  = 1, then either I1 or I2 does not
satisfy ri . Hence, we have a contradiction.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:38

•

P. Shakarian et al.

— Case 2.3. Th1 , Th2 ∈
/ ATSi . In this case, any interpretation that assigns
probabilities only to Th1 and Th2 satisfies ri . Therefore, I3 must satisfy
ri .
Now we consider a very simple MDP with only two policies. We see that this
MDP causes these circumstances to occur. Hence, we cannot construct an APTProgram that entails the MDP and set of policies.
Let L be an MDP, the set of atoms, BL , be {a}, S = {s1 , s2 } be such that
lbl(s1 ) ≡ {a} and lbl(s2 ) ≡ ∅, Act = {x, y}, P(s1 , x, s1 ) = 1 and P(s1 , x, s2 ) = 0,
P(s1 , y, s1 ) = 0, and P(s1 , y, s2 ) = 1. We define the set of policies, POL = {π1 , π2 }
such that π1 (s1 ) = x and π2 (s1 ) = y. Let tmax = 2. We claim that it is impossible
to construct an APT-Program that entails (L, POL).
So, we can see why there does not exist an APT-Program that entails the
MDP described we have. Assume by way of contradiction that we can create an
APT-Logic Program K such that all interpretations that satisfy (L, π1 ) or (L, π2 )
satisfy K. As each MDP-policy tuple is satisfied by exactly one interpretation,
we have the following threads and interpretations based on the set of worlds
W = {w1 , w2 }, where w1 ≡ lbl(s1 ) and w2 ≡ lbl(s2 ).
— Thread Th1 ≡ 
w1 , w2 . Let I1 be an interpretation such that I1 (Th1 ) = 1 and
sets the probability of all other threads to zero.
— Thread Th2 ≡ 
w1 , w1 . Let I2 be an interpretation such that I2 (Th2 ) = 1 and
sets the probability of all other threads to zero.
Hence, APT-Logic Program K must be satisfied by exactly I1 and I2 . However, by
our claim, any program satisfied by these two interpretations is also satisfied
by an infinite number of interpretations, so we have a contradiction.
So, based on the earlier definition of equivalence, while we can construct an
equivalent APT-Program for an MDP and a single policy, we cannot do so for
an MDP and set of policies. However, is the opposite true? It is. It would be
trivial to construct an MDP that entails an APT-Program, since the null MDP
can accomplish this. This highlights a difference between MDPs and APT-Logic
Programs: we cannot have rules that say this relationship holds with probability p1 or probability p2 . However, we can express ranges of probabilities.
While we cannot create an APT-Program that entails a given MDP and set of
policies, APT-Programs can be satisfied by tp-interpretations that cannot satisfy any MDP. In other words, there are APT-programs and tp-interpretations
that satisfy those APT-programs where there is no MDP that is satisfied by
that tp-interpretation. Consider the set of ground atoms BL = {a} and tmax = 4
and the following APT-Logic Program, K.
— a : [1, 1, 1].
pfr

pfr

— a ; ¬a : [1, 0.5, 0.5] (or a → ¬a : [1, 0.5, 0.5, 1, 1]).
We included an alternate second rule to illustrate that this type of expressiveness result is true about both constrained and unconstrained programs.
Consider worlds w1 ≡ {a} and w2 ≡ ∅. Let I be an interpretation that assigns
probabilities to the threads following.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:39

Fig. 9. Left. Unrolled MDP in an attempt to create an MDP that satisfies interpretation I in
the text. Notice how the sequence 
{a}, {}, {a}, {a} must be assigned a nonzero probability. Right.
A standard representation of the MDP on the left. Notice that the MDP must allow for non-zero
probability of threads that are given a zero probability in interpretation I.

—Th1 ≡ 
w1 , w2 , w1 , w2 , , I(Th1 ) = 0.5.
—Th2 ≡ 
w1 , w1 , w1 , w1 , , I(Th2 ) = 0.5.
It is trivial to show that I |= K. We claim that it is impossible to build an MDP
L with set of policies POL such that tp-interpretation I |= (L, POL).
Let S = {s1 , s2 } such that lbl(s1 ) ≡ w1 and lbl(s2 ) ≡ w2 . Suppose by way of
contradiction that I |= (L, POL). Therefore, there exists a policy, π ∈ POL such
that I satisfies (L, π ). Hence, the following must be true.
— P(s1 , π (s1 ), s2 ) · P(s2 , π (s2 ), s1 ) · (s1 , π (s1 ), s2 ) = I1 (th1 ) = 0.5.
— P(s1 , π (s1 ), s1 ) · P(s1 , π (s1 ), s1 ) · (s1 , π (s1 ), s1 ) = I1 (th2 ) = 0.5.
Refer to the left side of Figure 9 for a graphical representation of what follows.
Let P(s1 , π (s1 ), s2 ) = p. Then, by the definition of an MDP, P(s1 , π (s1 ), s1 ) = 1− p.
By these equalities, 1− p > 0. Let P(s2 , π (s2 ), s1 ) = r. Therefore, p2 ·r = 0.5. Now
consider the sequence seq ≡ s1 → s2 → s1 → s1 . The probability of this sequence
must be set to zero, by the definition of I. Then, P(seq) = p · r · (1 − p) = 0.
However, we know that p · r cannot be zero and we know that 1 − p > 0. Hence,
we have a contradiction.
This discussion illustrates the differences between MDPs and APT-Logic.
One could argue that the use of policies is overly restrictive for an MDP, that
is, that perhaps the action should be decided based on time, or a combination
of time and the current state. However, we can easily modify the claim based
on time or actions based on time and current state and obtain the same result.
We suspect that it is not possible to have an MDP that replicates an APT-Logic
Program without breaking the Markov Property, or causing a massive increase
in the number of states, which also would change the assumption about the
relationship between worlds and states.
6.2 Comparison with Probabilistic Computation Tree Logic (PCTL)
In this section, we show that APT-Logic rules differ significantly in meaning
from similar structures presented in PCTL [Aziz et al. 1995; Hansson and
Jonsson 1994b], a well-known probabilistic temporal logic.
A derived operator in LTL with an intuition similar to that of our APT-Rules
was introduced by Susan Owicki and Leslie Lamport in Owicki and Lamport
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:40

•

P. Shakarian et al.

[1982]. The operator, known as leads-to and an equivalent LTL formula are
shown ( p and q are state formulas).
( p  q) ≡ G( p ⇒ F(q)).
This formula intuitively says that if p is true in a state, then q must be true
in the same (or future) state. As Owicki and Lamport’s operator is based on
LTL, it does not describe the correlation between p and q with probabilities or
with reference to a specific time interval; q merely must happen sometime after
(or with) p. A probabilistic version of CTL, known as PCTL [Aziz et al. 1995;
Hansson and Jonsson 1994b] introduces another operator based on a similar
intuition; the authors refer to this operator as “leads-to” as well. This derived
operator, and the equivalent PCTL formula, are shown here ( f1 and f2 are state
formulas).
 

≤t
f1 ≤t
≥ p f2 ≡ G ( f1 ⇒ F≥ p f2 ) >1 .
Intuitively, this operator reads as “ f2 follows f1 within t periods of time with
a probability of p or greater.” As PCTL formulas are satisfied by a Markov
Process (an MDP with a single policy), satisfaction is determined by the transition probabilities. So, to determine if a Markov Process satisfies the leads-to
formula, we must compute the minimum probability of all sequences that start
in a state satisfying f1 and satisfying f2 in t units of time or less. Note that
this is determined by the transition probabilities of the Markov Process; hence,
whether a Markov Process satisfies the lead-to operator depends on the interval between f1 and f2 , but not on the total length of the sequence of states. So,
if we limit the number of states being considered, using an operator such as
max
G≤t
≥1 , which PCTL provides to limit consideration to only the first tmax states,
the Markov Process will satisfy the formula regardless of the value of tmax . Note
max
placed at the head of the PCTL has no effect on the satisfaction of
that G≤t
≥1
the formula as there is already a G path-quantifier included at the beginning
of the leads-to operator.
As previously described, the frequency function is often highly sensitive to
tmax . Our two primary examples of frequency functions, pfr and efr, are based
on ratios of numbers of worlds in a given thread. For example, if we create a
thread Th on a single atom a, we can see that for thread 
{a}, {a}, {}, the value
of pfr(Th, a, ¬a, 1) is much greater than if Th were 
{a}, {a}, {}, {a}, {a}, {a}, {a}.
The fact that the length of the thread has an effect on the frequency function
further illustrates how APT-Logic allows for reasoning beyond the restrictions
of the Markov Property. The limited thread length forces us to consider worlds
before and after a time-point we wish to reason about. If our probabilities were
fixed, based on transition probabilities, they would not, and we would conform
to the Markov Property.
Even though there are syntactic similarities, in the Appendix we provide a
short example illustrating semantic differences between APT-rules and PCTL.
7. CONCLUSION
Statements of the form “Formula G is/was/will be true with a probability in the
range [, u] in/within t units of time after formula F became true” are common.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:41

In this article, we have provided examples from four domains (stock markets,
counterterrorism, reasoning about trains, and power grids), but many more
examples exist. They could be used, for instance, to describe when the health
or environmental effects of industrial pollution may arise after a polluting event
occurred, to the time taken for a medication to produce (with some probability)
some effects. In the same way, they can be used in domains as widely divergent
as industrial control systems to effects of educational investment on improved
grades or graduation rates.
In this article, we have provided the concept of Annotated Probabilistic
Temporal (APT) logic programs within which such statements can be expressed. APT-logic programs consist of two kinds of rules: unconstrained and
constrained rules with an expected value style semantics and a more ordinary semantics. Both types of rules are parameterized by the novel concept
of a frequency function. Frequency functions capture the probability that
G follows F in exactly (or within) T time units within a thread (temporal
interpretation). We show that this notion of “follows” can intuitively mean
many different things, each leading to a different meaning. We propose an
axiomatic definition of frequency functions, which is rich enough to capture
these differing intuitions and then provide a formal semantics for APT-logic
programs.
We then study the problems of consistency and entailment for APT-logic
programs. We show that the consistency problem is computationally intractable
and is naturally solved via linear programming. We develop three successively
more sophisticated linear programs for consistency checking and show that
they lead to smaller linear programs (though not always). We also develop a
suite of complexity results characterizing the entailment problem and provide
algorithms to solve the entailment problem.
A natural question that arises in any probabilistic logic framework is “Where
do the probabilities come from?” In order to answer this question, we develop
the straightforward APT-Extract algorithm, which shows how APT-logic programs can be derived from certain types of databases. We have applied APTExtract to extract APT-rules about 18 terror groups.
Last, but not least, we have developed a detailed comparison between
our APT-framework and two well known frameworks: Markov decision processes [Puterman 1994] and probabilistic computation tree logic [Hansson and
Jonsson 1994a]. We show the former can be captured within the APT-logic
program framework (but not vice versa). The latter has a more complex relationship with APT-logic programs, but cannot express intrathread properties
of the type expressed via APT-logic programs.
There is much work that remains to be done in order to reduce APT-logic
programs to practice. We are implementing APT-logic programs within our
SOMA Terror Organization Portal [Martinez et al. 2008b], which has registered users from 12 US government organizations. Initially, users will be able
to browse the APT-logic programs associated with a given terror group’s behavior. Consistency checks are expensive, but need to be performed only once.
In contrast, entailment checks are needed when answering queries against
such programs. Scaling the entailment checks is a major priority that needs
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:42

•

P. Shakarian et al.

to be achieved. We plan to leverage some of the scaling methods developed
for SOMA programs (which are similar to APT-logic programs, but with no
temporal component) [Khuller et al. 2007].
ELECTRONIC APPENDIX
The electronic appendix for this article can be accessed in the ACM Digital
Library.

REFERENCES
AZIZ, A., SINGHAL, V., BALARIN, F., BRAYTON, R. K., AND SANGIOVANNI-VINCENTELLI, A. L. 1995. It
usually works: The temporal logic of stochastic systems. In Proceedings of the International
Conference on Computer Aided Verification, Springer, 155–165.
BARAL, C., TRAN, N., AND TUAN, L. 2002. Reasoning about actions in a probabilistic setting. In
Proceedings of the Conference on Artificial Intelligence AAAI. 507–512.
CLEAVELAND, R., IYER, S. P., AND NARASIMHA, M. 2005. Probabilistic temporal logics via the modal
mu-calculus. Theor. Comput. Sci. 342, 2-3, 316–350.
DE CHOUDHURY, M., SUNDARAM, H., JOHN, A., AND SELIGMANN, D. D. 2008. Can blog communication
dynamics be correlated with stock market activity? In Proceedings of the 19th ACM Conference
on Hypertext and Hypermedia (HT). ACM, New York, NY, 55–60.
DEKHTYAR, A., DEKHTYAR, M. I., AND SUBRAHMANIAN, V. S. 1999. Temporal probabilistic logic programs. In Proceedings of the International Conference on Logic Programming (ICLP). MIT Press,
Cambridge, MA, 109–123.
DIX, J., KRAUS, S., AND SUBRAHMANIAN, V. S. 2006. Heterogeneous temporal probabilistic agents.
ACM Trans. Comput. Logic 7, 1, 151–198.
DUBOIS, D., LONG, J., AND PRADE, H. 1991. Timed possibilistic logic. Fundamenta Informaticae XV,
211–234.
EMERSON, E. A. AND HALPERN, J. Y. 1984. “sometimes” and “not never” revisited: on branching
versus linear time. Tech. rep., University of Texas, Austin, TX.
FAGIN, R. AND HALPERN, J. Y. 1994. Reasoning about knowledge and probability. J. ACM 41,
340–367.
FAGIN, R., HALPERN, J. Y., AND MEGIDDO, N. 1990. A logic for reasoning about probabilities. Inform.
Computation 87, 78–128.
FUJIWARA, I., HIROSE, Y., AND SHINTANI, M. 2008. Can News be a Major Source of Fluctuation:
A Bayesian DGSE Approach. Vol. Discussion Paper Nr. 2008-E-16. Institute for Monetary and
Economic Studies, Bank of Japan.
GLABBEEK, R. J. V., SMOLKA, S. A., AND STEFFEN, B. 1995. Reactive, generative, and stratified
models of probabilistic processes. Inform. Comput. 121, 130–141.
GOLDSTONE, J. A., BATES, R., GURR, T. R., LUSTIK, M., MARSHALL, M. G., ULFELDER, J., AND WOODWARD, M.
2005. A global forecasting model of political instability. In Proceedings of the Annual Meeting
of the American Political Science Association.
HADDAWY, P. 1991. Representing plans under uncertainty: A logic of time, chance and action.
PhD Thesis, University of Illinois.
HALPERN, J. AND TUTTLE, M. 1992. Knowledge, probability, and adversaries. Tech. rep. in IBM
Thomas J. Watson Research Center.
HANSSON, H. AND JONSSON, B. 1994a. A logic for reasoning about time and probability. Formal
Aspects Comput. 6, 512–535.
HANSSON, H. AND JONSSON, B. 1994b. A logic for reasoning about time and reliability. Formal
Aspects Comput. 6, 102–111.
HART, S. AND SHARIR, M. 1986. Probabilistic propositional temporal logic. Inform. Contr. 70, 97–
155.
KANAZAWA, K. 1991. A logic and time nets for probabilistic inference. In Proceedings of the AAAI
Conference on Artificial Intelligence.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Annotated Probabilistic Temporal Logic

•

14:43

KARMARKAR, N. 1984. A new polynomial-time algorithm for linear programming. In Proceedings
of the 16th Annual ACM Symposium on Theory of Computing (STOC). ACM, New York, NY,
302–311.
KHULLER, S., MARTINEZ, M. V., NAU, D., SIMARI, G. I., SLIVA, A., AND SUBRAHMANIAN, V. S. 2007. Action
probabilistic logic programs. Annals Mathem. Artif. Intel. 51, 2–4, 295–331.
KIESSLING, W., THONE, H., AND GUNTZER, U. 1992. Database support for problematic knowledge. In
Proceedings of the International Conference on Extending Database Technology (EDBT), Lecture
Notes in Computer Science, Vol. 580, Springer-Verlag, 421–436.
KIFER, M. AND SUBRAHMANIAN, V. 1992. Theory of generalized annotated logic programming and
its applications. J. Logic Program. 12.
LAKSHMANAN, L. V. AND SHIRI, N. 1997. A parametric approach to deductive databases with uncertainty. IEEE Trans. Knowl. Data Eng..
LAKSHMANAN, V. AND SADRI, F. 1994a. Modeling uncertainty in deductive databases. In Proceedings
of the International Conference on Database and Expert Systems Applications (DEXA). Lecture
Notes in Computer Science, Vol. 856, Springer-Verlag, 724–733.
LAKSHMANAN, V. AND SADRI, F. 1994b. Probabilistic deductive databases. In Proceedings of the
Intlligence Logic Programming Symposium (ILPS). MIT Press.
LAMPORT, L. 1980. “Sometime” is sometimes “not never”: on the temporal logic of programs. In
Proceedings of the Symposium on Principles of Programming Languages (POPL). ACM, New
York, NY, 174–185.
LARSEN, K. G. AND SKOU, A. 1991. Bisimulation through probabilistic testing. Inform. Comput. 94, 1, 1–28.
LEHMANN, D. AND SHELAH, S. 1982. Reasoning about time and chance. Inform. Contr. 53, 165–198.
LLOYD, J. W. 1987. Foundations of Logic Programming, 2nd Ed. Springer-Verlag.
LUKASIEWICZ, T. 1999. Many-valued disjunctive logic programs with probabilistic semantics. In Proceedings of the 5th International Conference on Logic Programming and Nonmonotonic Reasoning. Lecture Notes in Artificial Intelligence, Vol. 1730, Springer-Verlag,
277–289.
LUKASIEWICZ, T., LUKASIEWICZ, T., KERN-ISBERNER, G., AND KERN-ISBERNER, G. 1999. Probabilistic
logic programming under maximum entropy. In In Proceedings of the Europeon Conference on
Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU). Lecture
Notes in Computer Science, Vol. 1638, Springer, 279–292.
MANNES, A., MICHAELL, M., PATE, A., SLIVA, A., SUBRAHMANIAN, V., AND WILKENFELD, J. April 1-2,
2008a. Stochastic opponent modelling agents: A case study with Hezbollah. In Proceedings
of the 1st International Workshop on Social Computing, Behavioral Modeling and Prediction.
Springer-Verlag.
MANNES, A., SLIVA, A., SUBRAHMANIAN, V., AND WILKENFELD, J. 2008b. Stochastic opponent modeling
agents: A case study with Hamas. In Proceedings of the International Conference on Computational Cultural Dynamics. AAAI Press, 49–54.
MARTINEZ, V., SIMARI, G., SLIVA, A., AND SUBRAHMANIAN, V. 2008a. Convex: Similarity-based algorithms for forecasting group behavior. IEEE Intell. Syst. 23, 4, 51–57.
MARTINEZ, V., SIMARI, G., SLIVA, A., AND SUBRAHMANIAN, V. 2009. Cape: Automatically predicting
changes in terror group behavior. Mathematical Methods in Counterterrorism. (ed. N. Memon).
Springer, New York, To appear.
MARTINEZ, V., SIMARI, G., SLIVA, A., AND SUBRAHMANIAN, V. S. 2008b. The SOMA terror organization
portal (stop): Social network and analytic tools for the real-time analysis of terror groups. In
Proceedings of the 1st International Workshop on Social Computing, Behavioral Modeling and
Prediction. H. Liu and J. Salerno, Eds.
NG, R. T. AND SUBRAHMANIAN, V. S. 1991. A semantical framework for supporting subjective and
conditional probabilities in deductive databases. In Proceedings of the International Conference
on Logic Programming (ICLP), K. Furukawa, Ed., MIT Press, 565–580.
NG, R. T. AND SUBRAHMANIAN, V. S. 1992. Probabilistic logic programming. Inform. Comput. 101, 2,
150–201.
OWICKI, S. AND LAMPORT, L. 1982. Proving liveness properties of concurrent programs. ACM Trans.
Program. Lang. Syst. 4, 3, 455–495.
PUTERMAN, M. L. 1994. Markov Decision Processes. Wiley.
ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

14:44

•

P. Shakarian et al.

RUSSELL, S. AND NORVIG, P. 2003. Artificial Intelligence: A Modern Approach, 2nd Ed., PrenticeHall, Englewood Cliffs, NJ.
SCHRODT, P. AND GERNER, D. 1998. Cluster analysis as an early warning technique for the middle
east. In Preventive Measures: Building Risk Assessment and Crisis Early Warning Systems.
(J. L. Davies and Ted Robert Gurr), Eds.
THOMAS, S. R. 1995. The PLACA agent programming language. In Proceedings of the Workshop
on Agent Theories, Architectures, and Languages on Intelligent Agents (ECAI). Springer-Verlag,
NY, 355–370.
VARDI, M. Y. 1985. Automatic verification of probabilistic concurrent finite state programs. In
Proceedings of the Symposium on Foundations of Computer Science, 327–338.
WILKENFELD, J., ASAL, V., JOHNSON, C., PATE, A., AND MICHAEL, M. 2007. The use of violence by
ethnopolitical organizations in the middle east. Tech. rep., National Consortium for the Study of
Terrorism and Responses to Terrorism.
Received August 2009; revised March 2010; accepted April 2010

ACM Transactions on Computational Logic, Vol. 12, No. 2, Article 14, Publication date: January 2011.

Darknet and Deepnet Mining for Proactive
Cybersecurity Threat Intelligence
Eric Nunes, Ahmad Diab, Andrew Gunn, Ericsson Marin , Vineet Mishra,
Vivin Paliath, John Robertson, Jana Shakarian, Amanda Thart, Paulo Shakarian

arXiv:1607.08583v1 [cs.CR] 28 Jul 2016

Arizona State University
Tempe, AZ 85281, USA
Email: {enunes1, ahmad.diab, andrewgunn, ericsson.marin, vvmishra,
vivin.paliath, jj.robertson, jshak, amanda.thart, shak} @asu.edu

Abstract—In this paper, we present an operational system
for cyber threat intelligence gathering from various social platforms on the Internet particularly sites on the darknet and
deepnet. We focus our attention to collecting information from
hacker forum discussions and marketplaces offering products and
services focusing on malicious hacking. We have developed an
operational system for obtaining information from these sites for
the purposes of identifying emerging cyber threats. Currently, this
system collects on average 305 high-quality cyber threat warnings
each week. These threat warnings include information on newly
developed malware and exploits that have not yet been deployed
in a cyber-attack. This provides a significant service to cyberdefenders. The system is significantly augmented through the use
of various data mining and machine learning techniques. With
the use of machine learning models, we are able to recall 92%
of products in marketplaces and 80% of discussions on forums
relating to malicious hacking with high precision. We perform
preliminary analysis on the data collected, demonstrating its
application to aid a security expert for better threat analysis.

I.

I NTRODUCTION

Pre-reconnaissance cyber threat intelligence refers to information gathered before a malicious party interacts with
the defended computer system. An example demonstrating the
importance of cyber threat intelligence is shown in Table 1.
A Microsoft Windows vulnerability was identified in Feb.
2015. The release of the vulnerability was essentially Microsoft
warning its customers of a security flaw. Note that at this time,
there was no publicly known method to leverage this flaw in a
cyber-attack (i.e. an available exploit). However, about a month
later an exploit was found to be on sale in darknet market. It
was not until July when FireEye, a major cybersecurity firm,
identified that the Dyre Banking Trojan designed to steal credit
cards exploited this vulnerability - the first time an exploit
was reported. This vignette demonstrates how threat warnings
gathered from the darknet can provide valuable information
for security professionals. The average global exposure of the
Dyre Banking Trojan was 57.3% along with another banking
malware Dridex1 . It means that nearly 6 out of 10 organizations
in the world were affected, and this is a significantly high
number on a global level.
In this paper, we examine how such intelligence can be
gathered and analyzed from various social platforms on the In1 https://www.fireeye.com/blog/threat-research/2015/06/evolution

of dridex.html

TABLE 1: Exploit example.
Timeline

Event

Feb. 2015

Microsoft identifies Windows vulnerability MS15010/CVE 2015-0057 for remote code execution. There
was no publicly known exploit at the time the vulnerability was released.

April 2015

An exploit for MS15-010/CVE 2015-0057 was found
on a darknet market on sale for 48 BTC (around
$10,000-15,000).

July 2015

FireEye identified that the Dyre Banking Trojan, designed to steal credit card number, actually exploited
this vulnerability1 .

ternet particularly sites on the darknet and deepnet. In doing so,
we encounter several problems that we addressed with various
data mining techniques. Our current system is operational and
actively collecting approximately 305 cyber threats each week.
Table 2 shows the current database statistics. It shows the total
data collected and the data related to malicious hacking. The
vendor and user statistics cited only consider those individuals
associated in the discussion or sale of malicious hackingrelated material, as identified by the system. The data is
collected from two sources on the darknet/deepnet: markets
and forums.
TABLE 2: Current Database Status

Markets

Forums

Total Number

27

Total products

11991

Hacking related

1573

Vendors

434

Total Number

21

Topics/Posts

23780/162872

Hacking related

4423/31168

Users

5491

We are providing this information to cyber-security
professionals to support their strategic cyder-defense planning
to address questions such as, 1) What vendors and users
have a presence in multiple darknet/deepnet markets/ forums?
2)What zero-day exploits are being developed by malicious
hackers? 3) What vulnerabilities do the latest exploits target?

Specific contributions of this paper include, 1) Description
of a system for cyber threat intelligence gathering from various
social platforms from the Internet such as deepnet and darknet
websites. 2) The implementation and evaluation of learning
models to separate relevant information from noise in the
data collected from these online platforms. 3) A series of
case studies showcasing various findings relating to malicious
hacker behavior resulting from the data collected by our
operational system.
Background: Many of the individuals behind cyber-operations
– originating outside of government run labs or military
commands – rely on a significant community of hackers.
They interact through a variety of online forums (as means
to both stay anonymous and to reach geographically dispersed
collaborators).
Darknet and Deepnet Sites: Widely used for underground
communication, “The Onion Router” (Tor) is free software
dedicated to protect the privacy of its users by obscuring
traffic analysis as a form of network surveillance [9]. The
network traffic in Tor is guided through a number of volunteeroperated servers (also called “nodes”). Each node of the
network encrypts the information it blindly passes on neither
registering where the traffic came from nor where it is headed
[9], disallowing any tracking. Effectively, this allows not
only for anonymized browsing (the IP-address revealed will
only be that of the last node), but also for circumvention
of censorship2 . Here, we will use “darknet” to denote the
anonymous communication provided by crypto-networks like
“Tor”, which stands in contrast to “deepnet” which commonly
refers to websites hosted on the open portion of the Internet
(the “Clearnet”), but not indexed by search engines [15].
Markets: Users advertise and sell their wares on marketplaces.
Darknet marketplaces provide a new avenue to gather information about the cyber threat landscape. The marketplaces
sell goods and services relating to malicious hacking, drugs,
pornography, weapons and software services. Only a small
fraction of products (13% in our collected data to date) are
related to malicious hacking. Vendors often advertise their
products on forums to attract attention towards their goods
and services.
Forums. Forums are user-oriented platforms that have the
sole purpose of enabling communication. It provides the opportunity for the emergence of a community of like-minded
individuals - regardless of their geophysical location. Administrators set up Darknet forums with communication safety
for their members in mind. While structure and organization
of Darknet-hosted forums might be very similar to more
familiar web-forums, the topics and concerns of the users
vary distinctly. Forums addressing malicious hackers feature
discussions on programming, hacking, and cyber-security.
Threads are dedicated to security concerns like privacy and
online-safety - topics which plug back into and determine the
structures and usage of the platforms.
II.

SYSTEM OVERVIEW

Fig. 1 gives the overview of the system. Through search
engines and spider services on the Tor network, human analysts
2 See

the Tor Project’s official website (https://www.torproject.org/)

were able to find forums and marketplaces populated by
malicious hackers. Other platforms were discovered through
links posted on forums either on the Tor-network or on the
Clearnet. The system consists of three main modules built
independently before integration. The system is currently fully
integrated and actively collecting cyber threat intelligence.
Crawler: The crawler is a program designed to traverse the
website and retrieve HTML documents. Topic based crawlers
have been used for focused crawling where only webpages of
interest are retrieved [17], [6]. More recently, focused crawling
was employed to collect forum discussions from darknet [10].
We have designed separate crawlers for different platforms
(markets/forums) identified by experts due to the structural
difference and access control measures for each platform. In
our crawler, we address design challenges like accessibility,
unresponsive server, repeating links creating a loop etc. to
gather information regarding products from markets and discussions on forums.
Parser: We designed a parser to extract specific information
from marketplaces (regarding sale of malware/exploits) and
hacker forums (discussion regarding services and threats).
This well-structured information is stored in a relational
database. We maintain two databases, one for marketplaces
and the other for forums. Like the crawler, each platform
has its own parser. The parser also communicates with
the crawler from time to time for collection of temporal
data. The parser communicates a list of relevant webpages
to the crawler, which are re-crawled to get time-varying
data. For markets we collect the following important products fields: {item title, item description, vendor name, shipping details, item reviews, items sold, CVE, items left, transaction details, ratings}. For forums we collect the following
fields: {topic content, post content, topic author, post author,
author status, reputation, topic interest}.
Classifier: We employ a machine learning technique using an
expert-labeled dataset to detect relevant products and topics
from marketplaces and forums respectively discussed in Section III. These classifiers are integrated into the parser to filter
out products and topics relating to drugs, weapons, etc. not
relevant to malicious hacking.
III.

E VALUATION

We consider the classification of identifying relevant products in darknet/deepnet marketplaces and relevant topics on
forum post containing communication relevant to malicious
hacking in this paper. It is a binary classification problem
with the data sample (in this case products/forum topics)
being relevant or not. We look at both supervised and semisupervised approaches to address the classification.
A. Machine Learning Approaches
In this work, we leverage a combination of supervised
and semi-supervised methods. Supervised methods include
the well-known classification techniques of Naive Bayes
(NB), random forest (RF), support vector machine (SVM)
and logistic regression (LOG-REG). However, supervised
techniques required labeled data, and this is expensive and
often requires expert knowledge. Semi-supervised approaches
work with limited labeled data by leveraging information
from unlabeled data. We discuss popular semi-supervised

Fig. 1: System overview

approaches used in this work. We perform a grid search to
find optimal parameters for the learning techniques.

description. This, in tandem with standard stop-word removal,
greatly improved classification performance.

Label propagation (LP). The label propagation approach
[22] has been widely used for semi-supervised classification
task [3], [16], [21], [8]. It estimates the label values based
on graph Laplacian [1] where the model is represented by a
weighted graph G = (V, E) , where V indicates the vertices
representing the samples, while the edges E are the weights
indicating the similarity between points. A subset of these
vertices are labeled and these vertices are then used to estimate
the labels of the remaining under the assumption that the edges
are able to capture the similarity between samples. Hence,
the performance of these methods depends on the similarity
measure used. The most commonly used similarity measures
include k-NN and Gaussian kernel.

Misspellings and Word Variations. Misspellings frequently
occur on forums and marketplaces, which is an obstacle for the
standard bag-of-words classification approach. Additionally,
with the standard bag-of-words approach, variations of words
are considered separately (e.g. hacker, hack, hackers, etc.).
Word stemming mitigates these issue of word variations, but
fails to fix the issue of misspellings. To address this we use
character n-gram features. As an example of character n-gram
features, consider the word “hacker”. If we were using tri-gram
character features, the word “hacker” would yield the features
“hac”, “ack”, “cke”, “ker”. The benefit of this being that the
variations or misspellings of the word in the forms “hack”,
“hackz”, “”hackker”, will all have some common features.
We found that using character n-grams in the range (3, 7)
outperformed word stemming in our experiments.

Co-training (CT). The Co-training approach was proposed
by Blum and Mitchell [4]. In this approach, the feature set is
divided into two sets (assumed to be independent), and two
classifiers are trained using the limited labeled set denoted by
L . These trained classifiers are then used to estimate the labels
for the unlabeled points. High confidence label estimates from
classifier-1 are added to the labeled set L of classifier-2 and
vice versa. For the current setting we set the confidence to
70%. Every time the labeled set L is updated, the classifiers
are retrained. This procedure repeats until all of the unlabeled
points are labeled. It can be viewed as two classifiers teaching
each other.
B. Experiments: Marketplaces
Marketplaces sell goods and services that do not relate to
malicious hacking, including drugs, pornography, weapons and
software services. Only a small fraction of products (13%)
are related to malicious hacking. We thus require a model
that can separate relevant products from the non-relevant ones.
The data collected from marketplaces is noisy and hence not
suitable to use directly as input to a learning model. Hence,
the raw information undergoes several steps of automated data
cleaning. We now discuss the challenges associated with the
dataset obtained and the data processing steps taken to address
them. We note that similar challenges occur for forum data.
Text Cleaning. Product title and descriptions on marketplaces
often have much text that serves as noise to the classifier
(e.g. *****SALE*****). To deal with these instances, we first
removed all non-alphanumeric characters from the title and

Large Feature Space. In standard bag-of-words approach, as
opposed to the character n-gram approach, the feature matrix
gets very large as the number of words increase. As the number
of unique words grow, this bloated feature matrix begins to
greatly degrade performance. Using n-gram features further
increases the already over-sized feature matrix. To address
this issue, we leveraged the sparse matrix data structure in
the scipy3 library, which leverages the fact that most of the
entries will be zero. If a word or n-gram feature is not present
in a given sample, there is simply no entry for that feature in
the sparse matrix.
Preserving Title Feature Context. As the title and description
of the product are disjoint, we found that simply concatenating
the description to the product title before extracting features
led to sub-optimal classification performance. We believe that
by doing a simple concatenation, we were losing important
contextual information. There are features that should be
interpreted differently should they appear in the title versus the
description. Initially, we used two separate classifiers: one for
the title and one for the description. With this construction,
when an unknown product was being classified, we would
pass the title to the title classifier and the description to the
description classifier. If either classifier returned a positive
classification, we would assign the product a positive classification. However, we believe that this again led to the loss of
important contextual information. To fix this, we independently
extract character n-gram features from the title and description.
3 http://www.scipy.org/

TABLE 3: Markets and Number of products collected.
Markets

Products

Markets

Products

Market-1

439

Market-6

497

Market-2

1329

Market-7

491

Market-3

455

Market-8

764

Market-4

4018

Market-9

2014

Market-5

876

Market-10

600

and time investment can be reduced by applying a semisupervised approach which leverages the unlabeled data to
aid in classification. It takes approximately one minute for a
human to label 5 marketplace products or 2 topics on forums as
relevant or not, highlighting the costliness of manual labeling.
The experimental setup is similar to the supervised approach,
but this time we also utilize the large unlabeled data from each
marketplace (75%) for training.
1

Results: We consider 10 marketplaces to train and test our
learning model. A summary of these marketplaces is shown
in Table 3. Table 4 gives an instance of products defined as
being relevant or not. With the help of security experts we label
25% of the products from each marketplace. The experimental
setup is as follows. We perform a leave-one-marketplace-out
cross-validation. In other words, given n marketplaces we
train on n − 1 and test on the remaining one. We repeat
this experiment for all the marketplaces. For the supervised
experiment, we only use the 25% labeled data from each
marketplace. We evaluate the performance based primarily
on three metrics: precision, recall and unbiased F1. Precision
indicates the fraction of products that were relevant from the
predicted ones. Recall is the fraction of relevant products
retrieved. F1 is the harmonic mean of precision and recall.
The results are averaged and weighted by the number of
samples in each market. In this application, a high recall is
desirable as we do not want to omit relevant products. In the
supervised approaches, SVM with linear kernel performed the
best, recalling 87% of the relevant products while maintaining
a precision of 85% (Fig. 2). SVM performed the best likely due
to the fact it maximizes generality as opposed to minimizing
error.

0.9

Average

This step yields a title feature vector and a description feature
vector. We then horizontally concatenate these vectors, forming
a single feature vector which includes separate feature sets for
the title and description.

0.8

0.7

0.6

Precision
LP
CT-NB

Recall
CT-LOG-REG
CT-RF

F1
CT-SVM

Fig. 3: Average Precision, Recall and F1 comparisons for LP, CT-NB, CT-LOG-REG,
CT-RF and CT-SVM for product classification.

Fig. 3 shows the performance comparison for the semisupervised approaches. For the co-training approach, we divide
the feature space into two sets. The two feature sets used are
both based on character n-grams. However, the set of words
from which the character n-grams are derived are disjoint
between the two sets. In this way, the two corresponding
feature vectors can be treated as being independent from
one another. Hence we get two views of the same sample.
Co-training with Linear SVM is able to recall 92% of the
relevant products as compared to label propagation and other
variants of co-training while maintaining a precision of 82%,
which is desirable. In this case, the unlabeled data aided
the classification in improving the recall to 92% without
significantly reducing the precision.
C. Experiment: Forums

TABLE 4: Example of Products.
Product Title

Relevant

20+ Hacking Tools (Botnets Keyloggers Worms and More!)

YES

5 gm Colombian Cocaine

NO

0.9

Average

0.8

0.7

0.6

0.5

Precision

Recall
NB

LOG-REG

RF

F1
SVM

Fig. 2: Average Precision, Recall and F1 comparisons for NB, LOG-REG, RF and SVM
for product classification.

As stated, only 25% of the data is labeled, as labeling
often requires expert knowledge. However, this significant cost

In addition to the darknet/deepnet marketplaces that we
have already discussed, there are also numerous darknet forums on which users discuss malicious hacking related topics.
Again, there is the issue that only a fraction of these topics with
posts on these forums contain information that is relevant to
malicious hacking or the trading of exploits. Hence, we need a
classifier to identify relevant topics. This classification problem
is very similar to the product classification problem previously
discussed, with similar set of challenges.
We performed evaluation on two such English forums.
The dataset consisted of 781 topics with 5373 posts. Table 5
gives instance of topics defined as being relevant or not.
We label 25% of the topics and perform a 10-fold cross
validation using supervised methods. We show the results
from the top two performing supervised and semi-supervised
methods. In the supervised setting, LOG-REG performed the
best with 80% precision and 68% recall (Fig. 4). On the other
hand, leveraging unlabeled data in a semi-supervised technique
improved the recall while maintaining the precision. We note
that in this case the 10-fold cross validation was performed
only on the labeled points. In the semi-supervised domain

co-training with LOG-REG improved the recall to 80% with
precision of 78%.

TABLE 6: Example of Zero-day exploits.

TABLE 5: Example of Topics.
Topic

Relevant

Bitcoin Mixing services

YES

Looking for MDE/MDEA shipped to Aus

NO

0.9

Average

0.8

0.7

0.6

0.5

Precision
LOG-REG

Recall
SVM

CT-LOG-REG

F1
CT-SVM

Fig. 4: Average Precision, Recall and F1 comparisons for LOG-REG, SVM, CT-LOGREG, and CT-SVM for English forum topic classification.

IV.

C ASE S TUDIES

We analyze the data with the purpose of answering the
questions raised in the Section I. We will be using the following key security terms. Vulnerability is a security flaw that
allows an attacker to compromise a software or an operating
system. Exploit is a piece of software that takes advantage of
a vulnerability in a piece of software or operating system to
compromise it. Patch is a piece of software used to improve
existing software by fixing vulnerabilities to improve security.
We discuss the following case-studies.

Zero-day exploit

Price (BTC)

Internet Explorer 11 Remote Code Execution 0day

20.4676

Android WebView 0day RCE

40.8956

cross-site connections that were previously unstudied. We are
able to produce this connected graph using the “usernames”
used by vendors and users in each domain. A subgraph of
this network containing some of the individuals who are
simultaneously selling products related to malicious hacking
and publishing in hacking related forums is shown in Fig. 5.
In most cases, the vendors are trying to advertise/discuss their
products on the forums, demonstrating their expertise. Using
these integrated graphic representations, one can visualize
the individuals’ participation in both domains, making the
right associations that lead to a better comprehension of the
malicious hacker networks. It is helpful in determining social
groups within the forums of user interaction. The presence
of users on multiple markets and forums follows a power law.
From Fig. 6, majority of users only belong to a single market or
forum. We note that there are 751 users that are present in more
than two platforms. Fig. 7 considers one such user/vendor. The
vendor is active in 7 marketplaces and 1 forum . The vendor
offers 82 malicious hacking related products and discusses
these products on the forum. The vendor has an average rating
of 4.7/5.0, rated by customers on the marketplace with more
than 7000 successful transactions, indicating the reliability of
the products and the popularity of the vendor.

A. Discovery of Zero-Day Exploits.

Fig. 5: Vendor/User network in marketplace and forum.

10000

Number of Users (Log scale)

Over a 4 week period, we detected 16 zero-day exploits
from the marketplace data. Zero-day exploits leverage vulnerabilities that are unknown to the vendor. Table 6 shows a
sample of zero-day exploits with their selling price in Bitcoin.
The Android WebView zero-day affects a vulnerability in the
rendering of web pages in Android devices. It affects devices
running on Android 4.3 Jelly Bean or earlier versions of the
operating system. This comprised of more than 60% of the
Android devices in 2015. After the original posting of this
zero-day, a patch was released in Android KitKit 4.4 and
Lollipop 5.0 which required devices to upgrade their operating
system. As not all users have/will update to the new operating
system, the exploit continues to be sold for a high price.
Detection of these zero-day exploits at an earlier stage can help
organizations avoid an attack on their system or minimize the
damage. For instance, in this case, an organization may decide
to prioritize patching, updating, or replacing certain systems
using the Android operating system.

1000
100
10

1
0

2

4
Number of Platforms

6

8

Fig. 6: Users in multiple markets and
forums.
Fig. 7: A centric network of a Vendor.

B. Users having presence in markets/ forums.
Previous studies on darknet crawling [10], [2] explore a
single domain, namely forums. We create a social network
that includes both types of information studied in this paper:
marketplaces and forums. We can thus study and find these

V.

R ELATED W ORK

Web crawling is a popular way of collecting large amounts
of data from the Internet. In many applications, researchers

are interested in specific topics for their application. Hence,
the need for a topic-based crawler popularly referred to as
a focused crawler [6], [5]. Most of the focused crawlers are
designed to collect information from the surface web with
little concentration on the darknet websites. More recently,
a focused crawler concentrating on dark web forums was
designed [10]. This research primarily concentrated on forums,
collecting data over a period of time and then performing
static analysis to study online communities. The authors also
describe different data mining techniques for these forums
in [7]. We, on the other hand, not only look at darknet forums
but also collect information from marketplaces hosting a range
of products relating to malicious hacking. Another application
of leveraging darknet information to counter human trafficking
is developed by DARPA through the Memex program4 - a
program with different goals than the work described in this
paper.
Previous work leverages the exploit information from
marketplaces in a game theoretic framework to formulate
system configurations that minimize the potential damage of
a malicious cyber attack [19]. Work analyzing hacker forums
to detect threats that pose great risk to individuals, businesses,
and government have been discussed in [2]. It further states
that knowledge is distributed in forums. That minimally skilled
people could learn enough by simply frequenting such platforms. Studying these hacker communities gives insights in
the social relationships. Also, the distribution of information
amongst users in these communities based on their skill level
and reputation [13], [14], [11]. These forums also serve as markets where malware and stolen personal information are shared
/ sold [12]. Samtani et al. analyze hacker assets in underground
forums [20]. They discuss the dynamics and nature of sharing
of tutorials, source code, and “attachments” (e.g. e-books,
system security tools, hardware/software). Tutorials appear to
be the most common way of sharing resources for malicious
attacks. Source code found on these particular forums was
not related to specific attacks. Additionally underground (not
malicious hacking related) forums have also been analyzed
to captures the dynamic trust relationships forged between
mutually distrustful parties [18].
VI.

[2]

[3]

[4]

[5]

[6]

[7]
[8]
[9]

[10]

[11]

[12]

[13]

[14]
[15]

[16]

C ONCLUSION

In this paper, we implement a system for intelligence
gathering related to malicious hacking. Our system is currently
operational. We are in the process of transitioning this system
to a commercial partner. We consider social platforms on
darknet and deepnet for data collection. We address various
design challenges to develop a focused crawler using data
mining and machine learning techniques. The constructed
database is made available to security professionals in order
to identify emerging cyber-threats and capabilities.
Acknowledgments: Some of this work is supported by ONR NEPTUNE, ASU GSI, ASU ISSR and CNPq-Brazil.

[17]

[18]

[19]
[20]

[21]

R EFERENCES
[1]

M. Belkin and P. Niyogi. Using manifold structure for partially labelled
classification. In Advances in NIPS, 2002.

4 http://opencatalog.darpa.mil/MEMEX.html

[22]

V. Benjamin, W. Li, T. Holt, and H. Chen. Exploring threats and
vulnerabilities in hacker web: Forums, irc and carding shops. In
Intelligence and Security Informatics (ISI), 2015 IEEE International
Conference on, pages 85–90. IEEE, 2015.
C. M. Bishop and I. Ulusoy. Object recognition via local patch labelling.
In Deterministic and Statistical Methods in Machine Learning, pages
1–21, 2004.
A. Blum and T. Mitchell. Combining labeled and unlabeled data with
co-training. In Proceedings of the Eleventh Annual Conference on
Computational Learning Theory, COLT’ 98, pages 92–100, New York,
NY, USA, 1998. ACM.
S. Chakrabarti, K. Punera, and M. Subramanyam. Accelerated focused
crawling through online relevance feedback. In Proceedings of the 11th
international conference on World Wide Web, pages 148–159. ACM,
2002.
S. Chakrabarti, M. Van den Berg, and B. Dom. Focused crawling: a new
approach to topic-specific web resource discovery. Computer Networks,
31(11):1623–1640, 1999.
H. Chen. Dark web: Exploring and data mining the dark side of the
web, volume 30. Springer Science & Business Media, 2011.
H. Cheng, Z. Liu, and J. Y. 0001. Sparsity induced similarity measure
for label propagation. In ICCV, pages 317–324. IEEE, 2009.
R. Dingledine, N. Mathewson, and P. Syverson. Tor: The secondgeneration onion router. In Proceedings of the 13th Conference on
USENIX Security Symposium - Volume 13, SSYM’04, pages 21–21,
2004.
T. Fu, A. Abbasi, and H. Chen. A focused crawler for dark web
forums. Journal of the American Society for Information Science and
Technology, 61(6):1213–1231, 2010.
T. J. Holt. Subcultural evolution? examining the influence of on-and offline experiences on deviant subcultures. Deviant Behavior, 28(2):171–
198, 2007.
T. J. Holt and E. Lampke. Exploring stolen data markets online:
products and market forces. Criminal Justice Studies, 23(1):33–50,
2010.
T. J. Holt, D. Strumsky, O. Smirnova, and M. Kilger. Examining the
social networks of malware writers and hackers. International Journal
of Cyber Criminology, 6(1):891–903, 2012.
T. Jordan and P. Taylor. A sociology of hackers. The Sociological
Review, 46(4):757–780, 1998.
D. Lacey and P. M. Salmon. It’s dark in there: Using systems analysis
to investigate trust and engagement in dark web forums. In D. Harris,
editor, Engineering Psychology and Cognitive Ergonomics, volume
9174 of Lecture Notes in Computer Science, pages 117–128. Springer
International Publishing, 2015.
A. Levin, D. Lischinski, and Y. Weiss. A closed form solution to natural
image matting. In Proceedings of the 2006 IEEE Computer Society
Conference on Computer Vision and Pattern Recognition - Volume 1,
CVPR ’06, pages 61–68, Washington, DC, USA, 2006. IEEE Computer
Society.
F. Menczer, G. Pant, and P. Srinivasan. Topical web crawlers: Evaluating
adaptive algorithms. ACM Transactions on Internet Technology (TOIT),
4(4):378–419, 2004.
M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G. M. Voelker.
An analysis of underground forums. In Proceedings of the 2011 ACM
SIGCOMM conference on Internet measurement conference, pages 71–
80. ACM, 2011.
J. Robertson, V. Paliath, J. Shakarian, A. Thart, and P. Shakarian. Data
driven game theoretic cyber threat mitigation. In IAAI, 2016.
S. Samtani, R. Chinn, and H. Chen. Exploring hacker assets in
underground forums. In Intelligence and Security Informatics (ISI),
2015 IEEE International Conference on, pages 31–36. IEEE, 2015.
C. Wang, S. Yan, L. Z. 0001, and H.-J. Zhang. Multi-label sparse
coding for automatic image annotation. In CVPR, pages 1643–1650.
IEEE, 2009.
X. Zhu, J. Lafferty, and Z. Ghahramani. Combining active learning and
semi-supervised learning using gaussian fields and harmonic functions.
In ICML 2003 workshop on The Continuum from Labeled to Unlabeled
Data in Machine Learning and Data Mining, pages 58–65, 2003.

A Comparison of Methods for Cascade Prediction
Ruocheng Guo, Paulo Shakarian

arXiv:1606.05730v1 [cs.SI] 18 Jun 2016

Arizona State University
Tempe, AZ
Email: {rguosni,shak}@asu.edu

Abstract— Information cascades exist in a wide variety of
platforms on Internet. A very important real-world problem is
to identify which information cascades can “go viral”. A system
addressing this problem can be used in a variety of applications
including public health, marketing and counter-terrorism. As a
cascade can be considered as compound of the social network
and the time series. However, in related literature where methods
for solving the cascade prediction problem were proposed, the
experimental settings were often limited to only a single metric
for a specific problem formulation. Moreover, little attention was
paid to the run time of those methods. In this paper, we first
formulate the cascade prediction problem as both classification
and regression. Then we compare three categories of cascade
prediction methods: centrality based, feature based and point
process based. We carry out the comparison through evaluation
of the methods by both accuracy metrics and run time. The
results show that feature based methods can outperform others
in terms of prediction accuracy but suffer from heavy overhead
especially for large datasets. While point process based methods
can also run into issue of long run time when the model can not
well adapt to the data. This paper seeks to address issues in order
to allow developers of systems for social network analysis to select
the most appropriate method for predicting viral information
cascades.

I. I NTRODUCTION
Identifying when a piece of information goes “viral” in social media is an important problem in social network analysis.
This is often referred to as “cascade prediction”. Recently,
the cascade prediction problem attracted considerable attention from researchers from communities of machine learning,
data mining and statistics. Researchers attempted to predict
the final size of information cascades based on approaches
inspired by knowledge in various areas. Pei et al. [1] measured
influence of the root node by k-shell number and related
heuristics. Weng et al. [2] and Guo et al. [3] uitilized features
describing both structural and temporal properties of earlystage cascades. The work described in [4] and [5] modelled
cascades by one-dimensional point process. However, in this
line of research, the experimental settings varied from paper
to paper. Furthermore, as the cascade prediction problem
can be treated as either classification or regression, most of
previous work only dealt with one or the other and using
just a single evaluation metric.With deployment of a counterextremism messaging system (i.e. an enhanced version of [6])
as one of the primary goals in our group, cascade prediction
can play a crucial role in detection of early-stage extremism
message that is potential to go viral on social network sites.
Other applications include the spread of information following
a disaster, promotion of health behaviors and applications

to marketing. Therefore, it is important to understand how
well the existing methods stemming from different research
area could perform in near real-world experimental settings.
An ideal cascade prediction method for counter-extremism
messaging system should provide acceptable accuracy with
ability to make near real-time prediction.
In this paper, we compare performance of a variety of
cascade prediction methods originating from different research
areas as both classification and regression problems with
multiple evaluation metrics. We also measure the run time
of the tasks required by the methods to complete cascade
prediction – another key deployment concern not explored in
most research.
In this paper, the main contribution can be summarized as:
• We compare cascade prediction methods in three categories: centrality based, feature based and point process
based, therefore providing comparison between methods
orginating from different research areas.
• The cascade prediction problem is considered from both
the aspect of regression and classification. we also conduct a comprehensive comparison between methods by
various evaluation metrics.
• We also compare the run time of tasks needed for the
cascade prediction methods are also measured in a task
by task style.
The rest of this paper is organized as the follows: In Section II,
definitions relevant to the methods considered in this paper are
introduced along with a formal problem statement of cascade
prediction. Section III summarizes the mechanism of the three
categories of cascade prediction methods. Section IV and V
presents the setup of experiments and performance of each
method in terms of both accuracy and run time. Section VI
reviews related work. At last, Section VII concludes the paper
and discusses the main issues of these methods.
II. T ECHNICAL P RELIMINARIES
In this section, related concepts for the three categories of
methods are defined. Then we formulate the cascade prediction
problem as regression and classification respectively.
A. Definitions
Network and Cascade: The social network is a directed
graph G = (V, E) where each node v ∈ V represents a
user and each edge eij = (vi , vj ) denotes that user vi is
followed by user vj . Identified by the original message or the
corresponding hashtag, a cascade is a time-variant subgraph of

the social network d(t) = (V (t), E(t)). Each node v ∈ V (t)
denotes a user reposted the original message of cascade d(t)
(for the Aminer dataset [7]) or a user posted the hashtag
defining cascade d(t) (for the Twitter dataset [2]) within time
t. The time variable t denotes number of time units since the
microblog including the original message or the hashtag. For
each node v ∈ V (t) we record their adoption time of cascade
d(t) as tv . For v ∈ V (t), tv ≤ t while for v 6∈ V (t) we define
tv = ∞. Thus we can get an ascendingly sorted vector tv (t)
including all tv ≤ t for each cascade, which plays an important
role in both feature based methods and point process based
methods for cascade prediction. The kth element of tv (t) can
be denoted as tv (t)[k]. For convenience, we use tend to denote
the time when the last adoption of a cascade happened.
Besides the cascade d(t) = (V (t), E(t)), the neighborhood
of V (t) also can provide information about the potential of
the cascade. Here we define the out-neighborhood reachable
by any node in V (t) in step i as ith surface Fi (t). To show
how ’fresh’ the cascade is for a node v ∈ Fi (t), we define a
function f∆t : v → ∆t that maps such a node to the number of
time units since v become a member of first surface to current
time t. As time makes a big difference in social influence and
diffusion, we divide the first surface F1 (t) into two sets of
nodes depends on f∆t (v) for all v ∈ F1 (t). With a selected
threshold tλ . The first set named as frontiers includes all
nodes v ∈ F1 (t) such that f∆t (v) ≤ tλ and the other set nonadopters consists the other nodes v ∈ F1 (t) with f∆t (v) > tλ .
In this paper, |x| denotes absolute value of scaler x and |x|
denotes cardinality of set x.
Communities: We can treat a community partition of a social
network as a function fC : V → C which maps a set of
nodes V to a set of communities C. With this function, given
a cascade d(t) = (V (t), E(t)), it enables us to describe the
distribution of nodes over communities by features such as
|fC (V )|, the number of communities among set V .
Point Process: Each adoption in a cascade can be represented
as an event from the aspect of point process as in [4]. Thus,
for cascade prediction, we can use tv (t − ∆t) to describe the
history of a point process strictly before t. The core of a point
process is the conditional density function λ(t). Conditioned
on tv (t − ∆t), the conditional density is the limit of expected
number of adoptions would happen in time interval [t, t + ∆t]
by taking ∆t → 0+ :
λ(t) = lim E {|V (t + ∆t)| − |V (t)|}
∆t→0+

(1)

Given the density function λ(t) and target prediction time
t0 , the predicted cascade size can be computed by:
Z t0
ˆ
0
|V (t )| = |V (t)| +
λ(τ )dτ
(2)
t

B. Problem Statement
In this paper, we focus on comparison of different methods
which can solve the cascade prediction problem. This problem can be formulated as either a regression problem or a
classification problem:

Regression Problem: Given a early stage cascade d(t) =
(V (t), E(t)) and the corresponding node attribute vector tv (t)
with constraint |V (t)| = n, the target is to predict the final
size of the cascade |V (tend )|.
Classification Problem: A threshold T hres is selected to
label each cascade. For a given cascade if its |V (tend )| ≥
T hres, we define it as a viral sample labeled as 1, otherwise,
we label it as non-viral labeled as 0. Then the problem is to
classify a given early-stage cascade d(t) to the viral class or
the non-viral class.
III. M ETHODS
In this section we introduce several recently published
methods for solving the cascade prediction problem. Diffusion
process in social network includes information of time series,
network structure, sometimes with microblog content and node
attributes, therefore, methods originated from knowledge in
various research area like social network analysis, random
point process and non-linear programming can be applied. The
methods can be categorized into: centrality based methods,
feature based methods and point process based methods.
A. Centrality Based Methods
Previous work [1] discovered that the k-shell value of a node
is highly correlated to the average cascade size it initiates.
In this paper, we also consider eigenvector centrality, outdegree and Pagerank of the root node of cascades to deal with
the cascade prediction problem. We refer to centrality based
approaches as method C in this paper.
B. Feature Based Methods
In this paper, we consider two recently proposed methods
[3] and [2] and call them method A and method B respectively
for convenience. The features computed by the two methods
can be categorized into network features, community based
features and temporal features.
Both of the feature based methods require to take advantage
of community detection algorithms. Given the social network,
community detection algorithms such as [8] and [9] can
be applied to it and assign each node to one or multiple
communities. Based on the communities detected, features can
be computed to numerically describe how the nodes that participate in a cascade are distributed over communities. Thus,
we can quantitatively measure structural diversity from [10]
or influence locality from [7] as features.
Network Features: In method B proposed by [2], the authors
consider several types of network features:
• Neighborhood size, including first surface (|F1 (Vt )|) and
second surface (|F2 (Vt )|).
• Path length, consisting average step distance and coefficient of variation of it, and diameter of the cascade.
Step distance is the length of shortest path between two
consecutive adopters vi and vi+1 .
Where coefficient of variation is defined as the ratio of the
standard deviation to the mean.

Community Based Features: In both [3] and [2], community
features are extracted and contribute to the predictive methods.
• Community features for adopters, including the number
of communities (|fC (V (t))|), entropy and gini entropy.
• Community features for frontiers and non-adopters, including the number of communities (|fC (F1 (t))|), entropy and gini entropy.
• The number of shared communties between any two
groups of adopters, frontiers and non-adopters.
Temporal Features: In [3], the authors computed average of
tv (t) while average step time and its corresponding coefficient
of variation are calculated in [2] as two features.
C. Point Process Based Methods
To discover patterns in the temporal dynamics of cascades,
authors of both [5] and [4] both consider a cascade as an
instance of one-dimensional point process in time space. They
proposed novel density functions to characterize time series
of cascades. The two methods are quite similar, in terms of
the formulation of conditional density function λ(t). In both
cases, λ(t) consists of an element modeling the popularity of
the cascade and another describing the probablity distribution
of an adoption behavior over time.
The Reinforced Poisson Process (RPP) Method: In [5], the
authors consider the density function for a cascade d as a
product of three elements:
λd (t) = αd fd (t; θd ) |V (t)|

(3)

For cascade d, αd denotes the intrinsic attractiveness, fd (t; θd )
is defined as the relaxation function which models how likely
an adoption would happen at time t without considering αd
and |V (t)|. For each cascade d, parameters αd and θd are
learned by maximization of the likelihood of tv (t). Thus, the
predicted cascade size at time t0 > t can be computed by:
Z t0
|V̂ (t0 )| = |V (t)| +
αd fd (τ ; θd ) |V (τ )| dτ
(4)
t

The SEISMIC Method: In [4], authors model the density
function as a modified Hawkes Process made up of three elements: infectiousness pt , node degree ni and human reaction
time distribution φ(s):
|V (t)|

λ(t) = pt

X

ni φ(t − tvi )

(5)

i=1

Where tvi ∈ tv (t) is the time when each adoption happens.
Similar to αd in the Reinforced Poisson Process model, pt is
computed by maximization of the likelihood function:
|V (t)|−1

pt = arg max
pt

Y

λ(tvi ) exp−

R tvi+1
tvi

λ(τ )dτ

(6)

i=0

While the human reaction time distribution φ(s) is formulated
as a piece-wise function consists of a constant piece and a
power-law piece with parameter c and θ:
(
c
s ≤ s0
(7)
φ(s) =
s −(1+θ)
s > s0
c( s0 )

TABLE I: Dataset Statistics
Property
Directed
Nodes
Edges
Number of communities
Modularity
Average Out-degree
Average Eigenvector Centrality
Average K-shell
Average Pagerank
Cascades (≥ 50 nodes)

Twitter Dataset

Weibo Dataset

undirected
595,460
7,170,209
24,513
0.7865
47.94
0.001783

directed
1,787,443
216,511,564
2,802
0.5581
231.3381
0.0186

24.6032
1.6794e−6
14,607

52.3064
5.596e−7
99,257

As φ(s)R is a probability distribution function, with the con∞
straint 0 φ(s)ds = 1 and power-law decay factor θ estimated by training data, c can be computed. With the density
function λ(t), the predicted cascade size can be computed by
equation (2).
IV. E XPERIMENTAL S ETUP
For comprehensiveness, we evaluate the performance of
each method by treating cascade prediction problem as both
regression and classification problem. We only consider cascades that end up with at least 50 adopters. Thus we can treat
first 50 nodes of each cascade as its early stage. In this section,
an introduction of the datasets is followed by descriptions
of setup of the classification and regression experiments. All
the experiments are carried out on an Intel(R) Xeon(R) CPU
E5-2620 @ 2.40 GHz machine with 256GB RAM running
Windows 7. All the methods are implemented in Python 2.7.
A. Dataset Description
The statistics of the two datasets used in this paper for
evaluation of the cascade prediction methods are shown in
Table I.
Twitter Dataset: Twitter1 is the most well-known microblog
platform throughout the world. The dataset was used in [2].
This dataset includes a friendship network with undirected
edges, cascades identified by hashtags and corresponding
mentions and retweets.
Weibo Dataset: Sina Weibo2 is the largest Chinese microblog
social network. The dataset was used in [7]. It consists of a
directed followership network and retweet cascades.
B. Regression
For the regression problem, the m × 1 ground truth vector
y is made up of final size of each cascade (|V (tend )|), where
m is the number of cascade. Each regression model is able
to output a m × 1 vector ŷ. Thus each element ŷi ∈ ŷ
is the predicted size of the ith cascade. For point process
models, with different prediction time, the predicted results
can change. Thus, for each early-stage cascade, we set t as
1 https://twitter.com
2 https://weibo.com

the time when we observed the 50th adoption and prediction
time as {2, 4, 6, 8, 10} × tv (t)[50]. To evaluate a method for
the regression problem, the difference between its prediction
results ŷ and the ground truth y can be described by various
error functions. In addition, ŷtop10% denotes the set of top
10% cascades in prediction result while ytop10% is the set
top of 10% cascades of ground truth. In this paper we choose
following metrics to compare the prediction made by different
methods, as they are widely used in related literatures such as
[11], [5], [12] and [4]:
Pm |yˆi −yi |
1
• APE (average percentage error): m
i=1
yi
• RMSE (root mean square error):
r Pm
2
i=1 (yˆi − yi )
m
• RMLSE (root mean logrithm square error):
r Pm
2
i=1 (log yˆi − log yi )
m


10 
ŷtop10% ∩ ytop10% 
• Top 10% coverage:
m

C. Classification
For classification, we apply three predetermined thresholds
(50th, 75th and 90th percentiles) to final size of cascades to
assign each of them a class label, which provides the m × 1
ground truth vector L = {l0 , ..., lm−1 } one for each threshold.
The cascades with size larger than threshold are labelled as
viral class with li = 1. Table II shows the thresholds and
counts of samples for both classes. Then the methods for
solving the classification problem can output predicted label
vector L̂. Comparing L with L̂ results in standard metrics:
precision, recall and F1 score. To examine the effectivess of
the methods, we focus on reporting the metrics on the minority
class (viral) as it is more difficult to do good predictions for
it than the other.
Specially, for point process based mothods, as they are capable to predict the final cascade size without being trained with
class labels (once parameters are determined and prediction
times are selected), we carry out the evaluation on them in this
way: prediction results (by setting different prediction times)
are treated as features for each sample. As the time when each
cascade stop growing is not easy to determine.
D. Run time
We also take the run time of tasks into account for the cascade prediction methods. To understand how computationally
expensive the methods are in terms of run time, it is necessary to analyze the procedure of them. For centrality based
methods, the prediction can be divided into three steps: computation of centrality, training and prediction. Similarly, for
feature based methods, computation of features, training and
prediction are required to be done. In addition, preprocessing
like community detection, computation of shortest path length
are needed, which can be computationally expensive. While
point process based methods require little preprocessing. For
each cascade, parameters are computed independently through

TABLE II: Thresholds for Classification
Percentile

Threshold

Viral samples

Non-viral samples

Twitter Dataset
50%
75%
90%

106
226
587

50%
75%
90%

152
325
688

7,303
3,652
1,461

7,304
10,955
13,146

Weibo Dataset
49,628
24,814
9,925

49,629
74,443
89,332

MLE of the observed time vector tv (t) and properties of the
adopters V (t). Then prediction is made by integral of density
functions. Thus, we consider the following processes one by
one and then combine them to estimate the run time of a
certain method.
Proprecessing: There are three types of proprecessing considered: loading the graph, computation of centralities and
community detection.
Computation of Features: For feature based methods, we
measure the run time of computation of the features , which
takes the product of preprocessing as input.
Training and Prediction: For centrality and feature based
methods, the run time of training and prediction is measured
for ten-folds. For point process based methods, we measure
the run time of parameter estimation and prediction for the
whole batch of data.
V. E XPERIMENTAL R ESULTS
In this section we show the experimental results including
both accuracy of cascade prediction and the run time for each
method. For convenience, we call method of [3], [2] and the
centrality based method as method A, B and C respectively.
For method A, B and C, 10-fold cross-validation is applied.
For results where we compare these three methods, we report
only the best-performing centrality measure amongst outdegree, Pagerank, Shell number and eigenvector centrality as
the method C for each dataset. As shown in Fig. 1, eigenvector
centrality outperforms others in the classification task when
the two classes are imbalanced. Thus we take eigenvector
centrality as the method C. The results for regression is not
shown here for limited space as the difference between results
produced by different centralities is trivial. For the Reinforced
Poisson Process (RPP) method [5], as the parameter estimation
task for each cascade is independent of others, the crossvalidation is skipped and predictions are made by parameters
learned from first 50 nodes of each cascade. For the SEISMIC
method [4], we also skip the 10-fold cross-validation. We set
the cutoff time s0 = 30000(s) for the Twitter dataset and
s0 = 300(s) for the Weibo dataset then fit the parameters
(θ, c) for the human reaction time distribution function φ(s)
with all samples in the dataset. While in the original paper [4],
the authors set θ and c just by 15 tweets they manually
picked. The power-law fitting is done as per [13], which

Out-degree
Pagerank
Shell Number
Eigenvector

1.0
0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

Precision

Recall

Out-degree
Pagerank
Shell Number
Eigenvector

1.0
0.8

0.0

F1 Score

(a) Twitter Dataset: 50th percentile

0.4

0.2

0.2

0.0

0.0

Recall

F1 Score

(c) Twitter Dataset: 90th percentile
Out-degree
Pagerank
Shell Number
Eigenvector

1.0
0.8

200.0%

Recall

0.0%

F1 Score

Out-degree
Pagerank
Shell Number
Eigenvector

(a) Twitter Dataset: APE
2.0
1.5

Precision

Recall

(d) Weibo Dataset: 50th percentile
Out-degree
Pagerank
Shell Number
Eigenvector

1.0
0.8
0.6
0.4

100.0%

0.2

0.2
F1 Score

(e) Weibo Dataset: 75th percentile

0.0

Precision

Recall

F1 Score

SEISMIC
RPP

(b) Twitter Dataset: RMSE

0.30
0.25
0.20

A(SVR)
B(SVR)
C(DTR)

SEISMIC
RPP

0.10
0.05
0.00

(c) Twitter Dataset: RMSLE
200.0%

A(SVR)
B(SVR)
C(DTR)

0.15

0.0

F1 Score

0.4

Recall

SEISMIC
RPP

0.5

0.6

Precision

A(SVR)
B(SVR)
C(DTR)

1.0

150.0%

0.0

3000
2500
2000
1500
1000
500
0

A(SVR)
B(SVR)
C(DTR)
SEISMIC
RPP

50.0%
Precision

0.8

0.4

250.0%

100.0%

1.0

0.6

300.0%

150.0%

(b) Twitter Dataset: 75th percentile

0.6

Precision

Out-degree
Pagerank
Shell Number
Eigenvector

1.0

A(SVR)
B(SVR)
C(DTR)
SEISMIC
RPP

(d) Twitter Dataset: Top 10% Coverage
2000

A(SVR)
B(SVR)
C(DTR)

SEISMIC
RPP

1500
1000

50.0%

500

0.0%

0

(f) Weibo Dataset: 90th percentile

Fig. 1: Classification results of centrality based methods: error
bar stands for one standard deviation.

(e) Weibo Dataset: APE
2.0
1.5

A(SVR)
B(SVR)
C(DTR)

SEISMIC
RPP

1.0

−5

returns (θ, c) = (0.440, 1.018e ) and (0.282, 7.332e
the Twitter dataset and Weibo dataset respectively.

−4

) for

A. Regression
For centrality based methods, we apply linear regression
with least squared error. We carry out the training and prediction with random forest regressor, SVR and linear regression
model provided by [14] for feature based methods. We only
show the results produced by SVR as it outperformes others.
For the point process based mothods, we only report the best
result among prediction time out of {2, 4, 6, 8, 10}×tv (t)[50].
For the Twitter dataset, Fig. 2a, 2b, 2c and 2d show the
experimental results for the regression problem. Feature based
methods and SEISMIC outperform RPP and method C w.r.t.
APE. Concerning RMSE, method A shows more predictive
power than others. As to RMSLE, feature based methods result
in less error than the other two categories. From the aspect of
Top 10% coverage, RPP, method A are more likely to track
the trending cascades than others.
Fig. 2e, 2f, 2g and 2h show the regression result for the
Weibo dataset, Regarding APE, SEISMIC, method A and B
have comparable performance and outperform others. In terms
of RMSE, method A, B are measured to be more predictive
than the rest. Feature based methods also make predictions
with least RMSLE. For top 10% coverage, RPP is more likely
to detect popular cascades than others.
An interesting observation is that the prediction accuracy
measured by different error metrics can be contrary to each
other. For example, in Fig. 2a, compared to SEISMIC, prediction made by method C results in more error measured by

0.5
0.0

(g) Weibo Dataset: RMSLE

(f) Weibo Dataset: RMSE

0.35
0.30
0.25
0.20
0.15
0.10
0.05
0.00

A(SVR)
B(SVR)
C(DTR)

SEISMIC
RPP

(h) Weibo Dataset: Top 10% Coverage

Fig. 2: Regression results

APE, however, comparable error w.r.t. RMSE and less error
regarding RMSLE (See Fig. 2b and 2c). This implies that it
is better for researchers to show more than one type of error
for evaluation of regression results.
B. Classification
We show the precision, recall and F1 score for the viral
class with all the three percentile thresholds. For each dataset,
we choose the 50th, 75th and 90th percentile of the final size
of all cascades as the thresholds for assigning the cascades
into viral or non-viral class. The number of samples in
each class is shown in Table II. Thus we can evaluate the
cascade prediction methods with balanced and imbalanced
classes. For each method, we only show the best result among
those produced by different classifiers or various training
methods. As a result, for feature based methods, random forest
outperforms others. While for point process based methods
we treat cascade size predicted by setting prediction time as
{2, 4, 6, 8, 10}×tv (t)[50] as features. Here we show the results
produced by classifiers trained by these features.
Fig. 3a, 3b and 3c show the classification results for
the Twitter dataset. With all three thresholds, feature based
methods A and B outperform others. In addition, they also

1.0

A(RF)
B(RF)

C(DT)
SEISMIC

RPP

1.0

0.8

0.8

0.6

0.6

0.4

0.4

0.2
0.0

Recall

F1 Score

A(RF)
B(RF)

C(DT)
SEISMIC

RPP

0.0

1.0
0.8

0.6

0.6

0.4

0.4

0.2

0.2
Precision

Recall

F1 Score

(c) Twitter Dataset: 90th percentile
1.0

A(RF)
B(RF)

C(DT)
SEISMIC

RPP

0.0

1.0
0.8

0.6

0.6

0.4

0.4

0.2

Precision

Recall

F1 Score

A(RF)
B(RF)

Precision

C(DT)
SEISMIC

Recall

RPP

F1 Score

(d) Weibo Dataset: 50th percentile

0.8

0.0

RPP

(b) Twitter Dataset: 75th percentile

0.8

0.0

C(DT)
SEISMIC

0.2
Precision

(a) Twitter Dataset: 50th percentile
1.0

A(RF)
B(RF)

A(RF)
B(RF)

C(DT)
SEISMIC

RPP

0.2
Precision

Recall

F1 Score

(e) Weibo Dataset: 75th percentile

0.0

Precision

Recall

F1 Score

(f) Weibo Dataset: 90th percentile

Fig. 3: Classification results: error bar stands for one standard
deviation.

show more robustness than others to imbalance of two classes
in dataset. In terms of point process based methods, SEISMIC
outperforms RPP especially when the two class are imbalanced. RPP suffers from relatively large standard deviation,
as the Newton’s method is not always able to achieve convergence. Thus the parameters learned through the MLE approach
can vary as a result from random initialization. Method C
(eigenvector centrality) shows little predictive power with any
of the three thresholds for the Twitter dataset, even if it
outperforms other centrality based methods.
For the Weibo dataset, as shown in Fig. 3d, 3e and 3f,
feature based methods outperform others again with all three
thresholds. Regarding point process based methods, contrary
to the results for Twitter dataset, RPP achieves better F1 score
than SEISMIC when threshold value becomes large. Method
C (eigenvector centrality) performs comparably to RPP.
C. Run time
In this subsection, we show the run time of tasks for the
cascade prediction methods considered in this paper. On one
hand, preprocessing, computation of centralities and features
suffer from high overhead as immense amount of data needs
to be loaded. The run time of these tasks are listed in Table III.
On the other hand, training and prediction tasks barely have
the overhead issue.
Preprocessing: We carry out the community detection task by
the java implementation of Louvain algorithm [15] with 10
random start and 10 iterations for each start. For computation
of centralities, we load edgelist of the social networks as a
graph object in igraph-python [16]. As shown in Table III,

community detection, computation of Pagerank and loading
graph are the tasks suffer the most when the size of dataset
increases. Community detection, computation of Pagerank and
loading graph for the Weibo dataset take 80.32, 66.855 and
19.80 times the run time of those for the Twitter dataset
respectively.
Computation of Features: As shown in Table III, for the
feature computation task, it takes method B 12.37 and 8 times
the run time method of A for the Twitter Dataset and the
Weibo Dataset respectively. To explain this observation, an
analysis of what computation is carried out in each iteration for
method A and B. For method A, computation of the features
can be done without loading the graph (a heavy overhead).
Moreover, for each cascade, method B also requires expensive
computation of shortest path length for each pair of nodes in
cascade subgraphs and size of 2-hop neighborhood.
Training and Prediction: The run time of training and prediction is not directly related to the size of the social network.
On one hand, it is correlated to the number of cascades for
training and prediction. On the other hand, it is decided by the
complexity of the method: for example, number of parameters
to be learned, the complexity for learning each paramter and
the comsumption to work out the prediction. Here we only
measure the run time for solving the classification problem.
We run each method with single process, overhead run time
such as graph loading is ignored. For feature based methods
the training and prediction time are also correlated to the
number of features. For centrality based methods, we only
show the run time for k-shell (method C) as all methods in this
category are trained and tested with one feature: the centrality
measure of the root node. Compared to RPP, SEISMIC is a
deterministic method with closed form solution. The run time
for each sample can be distributed with little variance. For the
RPP method, as the log-likelihood function is non-convex, it is
not guaranteed that global maximum can be reached in limited
number of iterations. Therefore, the run time for a sample
running out of the maximum number of iterations can be
thousands times that of another, which reaches the convergence
condition in the first iteration. As the log-likelihood function of
RPP is twice-differentiable, Newton’s method can be applied.
In our experiments, with the maximum number of iterations
setted as 100, the convergence is more likely to be achieved by
Newton’s method than gradient descent. Thus we only show
the run time of RPP with Newton’s method.
Fig. 4 shows the run time for each method to complete
training and prediction tasks for all cascades in the two
datasets. For feature based methods, it shows the run time
needed for random forest (RF), SVM and logistic regression
(LR). For method C, it shows that of decision tree (DT), SVM
and logistic regression (LR).
Concerning the Twitter dataset (See Fig. 4a), taking advantage of decent implementation of classifiers, feature based
methods comparable run time to point process based methods
w.r.t. the training and prediction task with random forest and
SVM (rbf kernel).
For the Weibo dataset, as shown in Fig. 4b, the run time

TABLE III: Run time: Preprocessing & Feature Computation
Type

Task

Twitter Dataset
Louvain
275
Loading Graph
60.033
Degree
0.016
K-shell
2.757
Eigenvector
20.444
Pagerank
26.298
A
267.144
B
3252.7562
Weibo Dataset
Louvain
22087
Loading Graph
1188.486
Degree
0.045
K-shell
139.128
Eigenvector
391.140
Pagerank
1758.164
A
11181.453
B
87651.213

Feature
Computation

Preprocessing

Feature
Computation

Run time (seconds)

10 2

A(RF)
A(LR)
A(SVM)
B(RF)

B(LR)
B(SVM)
C(DT)
C(LR)

C(SVM)
SEISMIC
RPP

10 6
10 5

Run time (seconds)

Preprocessing

10 3

Total time (s)

A(RF)
A(LR)
A(SVM)
B(RF)

Time
per
sample (s)
–
–
–
–
–
–
0.018
0.2227
–
–
–
–
–
–
0.110
0.883
B(LR)
B(SVM)
C(DT)
C(LR)

C(SVM)
SEISMIC
RPP

10 4
10 3

10 1

10 2

10 0

10 1
10 0

10 -1

(a) Twitter Dataset

(b) Weibo Dataset

Fig. 4: Run Time of Trainig and Prediction

feature based methods comsume is comparable to SEISMIC
with random forest. But the SVM with rbf kernel suffers from
the order-of-magnitude increase of the number of training and
testing samples. Thus leads to the observation that the run time
becomes approximately 10 times that of random forest.
Comparing Fig. 4b with Fig. 4a, the run time of RPP method
increases the most. This means it is much more difficult for
the Newton’s method to converge for samples in the Weibo
datasets. There are two possible reasons to explain this: 1).
the uniform distribution used in random initialization can not
produce good initial values that are closed to local optimal
points; 2). the choice of log-norm distribution as function
fd (t; θd ) can not provide fairly good description of cascades
in this dataset.
VI. R ELATED W ORK
Influence Maximization Since the proposal of Influence maximization problem by Kempe et al. [17], related work emerged,
focusing on estimation of influence for a selected set of nodes
that can be measured by expected number of infectees under
a certain influence model, such as [18] and [19]. Recently,
a scalable randomized algorithm designed by Du et al. [20]
estimates influence initiated by selected source nodes and thus
select seed set with maximum expected influence.

Cascade Prediction Although in [1], k-shell and heuristics
of k-shell were shown to be effective indicator of long-term
influence of nodes, in [21], experimental results showed that
the shell number of the root node is not effectively predictive in
the cascade by cascade scenario. Feature based methods from
Jenders et al. [22] Chen et al. [23] were designed to solve the
cascade prediction problem formulated as binary classification
on balanced dataset, however, these methods are more or less
dependent on content features from specific social media sites.
Ma et al. [24] focused on applying content features to classify
hashtag cascades by how much their size increases. Regarding
to point process based methods, model designed with the
intuition of mutual exciting nature of social influence, Zhou
et al [25] applied multi-dimensional Hawkes process to rank
cascades (memes) by their popularity. Recently, the model
introducted by Yu et al. [11] combined feature engineering
and human reaction time distribution function widely used
in point process based methods to aggregate adoptions in
subcascades for cascade prediction. Besides feature based
methods and point process based methods studied in this
paper, knowledge from related research fields could also be
applied to cascade prediction. Goyal et al. [26] proposed the
credit distribution model to learn pair-wise influence based
on IC model proposed by Kempe et al. [17]. Cui et al. [27]
proposed a feature selection approach for binary classification
of cascades. Wang et al. [28] proposed a model to decouple
the influence measured in a pair-wise way into two latent
vectors representing influence and susceptibility of a node.
This work differs from all the past efforts in that it is the most
thorough comparison of methods general enough to be applied
to different datasets without relying on features specific to a
certain social media site.
VII. D ISCUSSION AND C ONCLUSION
In this paper, we evaluate three categories of recently
proposed methods with both the classification and regression
formulaton of cascade prediction. Feature based methods
generally provide better prediction accuracy for the cascade
prediction problem, no matter it is considered as classification
or regression. However, they suffer from heavy overhead
such as community detection and computation of features.
Random point process based methods enable us to achieve the
prediction with little preprocessing but are shown to be less
accurate than feature based methods. The run time of methods
in this category can also suffer from the situation when the
data can not be well modelled by the proposed density function
λ(t).
In regression experiments, we find the inconsitancy between
evaluation with different error metrics. A method that performs
well w.r.t. one metric could result in large error measured by
another. A predictive method should be able to perform fairly
well measured by various error metrics.
How to deal with changes in the social network and progress
of cascades to update features is the biggest issue that both
centrality based and feature based methods encounter. The

heavy overhead introduced by preprocessing and computation
of features limits these methods from near real-time prediction.
Point process based methods require little preprocessing
and the training and prediction process are parallelable as
they consider each cascade is indenpendent of others. This
advantage in terms of run time over feature based methods
can also be amplified as the size of the social network and the
number of cascades. Moreover, point process based methods
encounter little cold start problem. These two characteristics of
point process based methods make them more suitable for realtime cascade prediction task. But how to secure the accuracy
of prediction is the biggest issue for them. The point process
based models are faced with two more problems: sensitivity
to scale of time unit and requirement of prediction time as an
input variable. In real-world application, given a early stage
cascade, estimation of when it will stop progressing is a nontrivial problem.
On balance, this paper explored various methods in the
academic literature of predicting viral information cascades
in a more comprehensive manner. Our aim is to provide important insights into which methods based on graph topology
or temporal dynamics performed best - as these results can
generalize to a variety of application domains. In our ongoing
work on developing a deplyable system for identifying viral
extremist messages, this represents an important consideration.
Our next step is to consider microblog content as well - which
tends to be more domain specific.
ACKNOWLEDGMENTS
Some of the authors are supported through the AFOSR
Young Investigator Program (YIP) grant FA9550-15-1-0159,
ARO grant W911NF-15-1-0282, the DoD Minerva program
and the EU RISE program.
R EFERENCES
[1] S. Pei, L. Muchnik, J. S. Andrade Jr, Z. Zheng, and H. A. Makse,
“Searching for superspreaders of information in real-world social media,” Scientific reports, vol. 4, 2014.
[2] L. Weng, F. Menczer, and Y.-Y. Ahn, “Predicting successful memes
using network and community structure,” in Eighth International AAAI
Conference on Weblogs and Social Media, 2014.
[3] R. Guo, E. Shaabani, A. Bhatnagar, and P. Shakarian, “Toward order-ofmagnitude cascade prediction,” in Proceedings of the 2015 IEEE/ACM
International Conference on Advances in Social Networks Analysis and
Mining 2015. ACM, 2015, pp. 1610–1613.
[4] Q. Zhao, M. A. Erdogdu, H. Y. He, A. Rajaraman, and J. Leskovec,
“Seismic: A self-exciting point process model for predicting tweet
popularity,” in Proceedings of the 21th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining. ACM, 2015,
pp. 1513–1522.
[5] H. Shen, D. Wang, C. Song, and A.-L. Barabási, “Modeling and
predicting popularity dynamics via reinforced poisson processes,” in
Twenty-Eighth AAAI Conference on Artificial Intelligence, 2014.
[6] N. Kim, S. Gokalp, H. Davulcu, and M. Woodward, “Lookingglass: A
visual intelligence platform for tracking online social movements,” in
Advances in Social Networks Analysis and Mining (ASONAM), 2013
IEEE/ACM International Conference on. IEEE, 2013, pp. 1020–1027.
[7] J. Zhang, B. Liu, J. Tang, T. Chen, and J. Li, “Social influence locality
for modeling retweeting behaviors.” in IJCAI, vol. 13, 2013, pp. 2761–
2767.
[8] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast
unfolding of communities in large networks,” Journal of statistical
mechanics: theory and experiment, vol. 2008, no. 10, p. P10008, 2008.

[9] M. Rosvall and C. T. Bergstrom, “Maps of random walks on complex
networks reveal community structure,” Proceedings of the National
Academy of Sciences, vol. 105, no. 4, pp. 1118–1123, 2008.
[10] J. Ugander, L. Backstrom, C. Marlow, and J. Kleinberg, “Structural
diversity in social contagion,” Proceedings of the National Academy
of Sciences, vol. 109, no. 16, pp. 5962–5966, 2012.
[11] L. Yu, P. Cui, F. Wang, C. Song, and S. Yang, “From micro to
macro: Uncovering and predicting information cascading process with
behavioral dynamics,” arXiv preprint arXiv:1505.07193, 2015.
[12] S. Gao, J. Ma, and Z. Chen, “Modeling and predicting retweeting
dynamics on microblogging platforms,” in Proceedings of the Eighth
ACM International Conference on Web Search and Data Mining. ACM,
2015, pp. 107–116.
[13] J. Alstott, E. Bullmore, and D. Plenz, “powerlaw: a python package for
analysis of heavy-tailed distributions,” PloS one, vol. 9, no. 1, p. e85777,
2014.
[14] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, “Scikit-learn: Machine learning in Python,” Journal of Machine
Learning Research, vol. 12, pp. 2825–2830, 2011.
[15] L. Waltman and N. J. van Eck, “A smart local moving algorithm
for large-scale modularity-based community detection,” The European
Physical Journal B, vol. 86, no. 11, pp. 1–14, 2013.
[16] G. Csardi and T. Nepusz, “The igraph software package for complex
network research,” InterJournal, vol. Complex Systems, p. 1695, 2006.
[Online]. Available: http://igraph.org
[17] D. Kempe, J. Kleinberg, and É. Tardos, “Maximizing the spread of
influence through a social network,” in Proceedings of the ninth ACM
SIGKDD international conference on Knowledge discovery and data
mining. ACM, 2003, pp. 137–146.
[18] W. Chen, Y. Wang, and S. Yang, “Efficient influence maximization in
social networks,” in Proceedings of the 15th ACM SIGKDD international
conference on Knowledge discovery and data mining. ACM, 2009, pp.
199–208.
[19] A. Goyal, W. Lu, and L. V. Lakshmanan, “Celf++: optimizing the greedy
algorithm for influence maximization in social networks,” in Proceedings
of the 20th international conference companion on World wide web.
ACM, 2011, pp. 47–48.
[20] N. Du, L. Song, M. Gomez-Rodriguez, and H. Zha, “Scalable influence
estimation in continuous-time diffusion networks,” in Advances in neural
information processing systems, 2013, pp. 3147–3155.
[21] P. Shakarian, A. Bhatnagar, A. Aleali, E. Shaabani, and R. Guo,
Diffusion in Social Networks. Springer, 2015.
[22] M. Jenders, G. Kasneci, and F. Naumann, “Analyzing and predicting
viral tweets,” in Proceedings of the 22nd international conference
on World Wide Web companion.
International World Wide Web
Conferences Steering Committee, 2013, pp. 657–664.
[23] J. Cheng, L. Adamic, P. A. Dow, J. M. Kleinberg, and J. Leskovec,
“Can cascades be predicted?” in Proceedings of the 23rd international
conference on World wide web. ACM, 2014, pp. 925–936.
[24] Z. Ma, A. Sun, and G. Cong, “On predicting the popularity of newly
emerging hashtags in twitter,” Journal of the American Society for
Information Science and Technology, vol. 64, no. 7, pp. 1399–1410,
2013.
[25] K. Zhou, H. Zha, and L. Song, “Learning social infectivity in sparse lowrank networks using multi-dimensional hawkes processes,” in Proceedings of the Sixteenth International Conference on Artificial Intelligence
and Statistics, 2013, pp. 641–649.
[26] A. Goyal, F. Bonchi, and L. V. Lakshmanan, “A data-based approach to
social influence maximization,” Proceedings of the VLDB Endowment,
vol. 5, no. 1, pp. 73–84, 2011.
[27] P. Cui, S. Jin, L. Yu, F. Wang, W. Zhu, and S. Yang, “Cascading outbreak
prediction in networks: a data-driven approach,” in Proceedings of the
19th ACM SIGKDD international conference on Knowledge discovery
and data mining. ACM, 2013, pp. 901–909.
[28] Y. Wang, H. Shen, S. Liu, and X. Cheng, “Learning user-specific latent
influence and susceptibility from information cascades,” in Twenty-Ninth
AAAI Conference on Artificial Intelligence, 2015.

Reducing Gang Violence Through Network Influence
Based Targeting of Social Programs
Paulo Shakarian
Arizona State University
Tempe, AZ 85281

pshakari@asu.edu

Joseph Salmento and
William Pulleyblank
Network Science Center
U.S. Military Academy
West Point, NY 10996

John Bertetto
Chicago Police Dept.
Chicago, IL 60653

john.bertetto@chicagopolice.org

joseph.salmento@usma.edu
william.pulleyblank@usma.edu
ABSTRACT

Algorithms, Experimentation

focused on the allocation of law enforcement resources to increase arrests and deter criminal behavior. In this paper we
focus on a use of “smart policing” in a diﬀerent manner: we
wish to intelligently target individual gang members with
incentives to leave a gang. While “pulling levers” or encouraging dis-enrollment from a gang, is already a tactic employed in cities such as Boston and Chicago, the selection
of which speciﬁc gang members to focus on is still largely
unanswered - and hence currently based on ad-hoc methods. In this paper, we study this emerging application as
a variant of a social network inﬂuence maximization problem [14] that we refer to as the “social incentive inﬂuence”
(SII) problem. We study this problem both formally and
in the context of law enforcement. Then, using new techniques from unconstrained submodular maximization [7], we
develop an approximation algorithm for SII and present a
suite of experimental results - including tests on real-world
police data.
The paper is organized as follows. In Section 2 we discuss
some current methods in law-enforcement used for social
program targeting. In Section 3 we introduce the SII problem an associated technical preliminaries. This is followed
by a discussion of our algorithmic approach in Section 4 and
associated experimental results in Section 5. Finally, we
discuss related work in the literature in Section 6.

Keywords

2.

In this paper, we study a variant of the social network
maximum inﬂuence problem and its application to intelligently approaching individual gang members with incentives
to leave a gang. The goal is to identify individuals who
when inﬂuenced to leave gangs will propagate this action.
We study this emerging application by exploring speciﬁc
facets of the problem that must be addressed when modeling this particular situation. We formulate a new inﬂuence maximization variant - the “social incentive inﬂuence”
(SII) problem and study it both formally and in the context of the law-enforcement domain. Using new techniques
from unconstrained submodular maximization, we develop
an approximation algorithm for SII and present a suite of
experimental results - including tests on real-world police
data from Chicago.

Categories and Subject Descriptors
Applied Computing [Law, social and behavioral sciences]: Sociology

General Terms

BACKGROUND

Recent successes with so called “pulling levers” (gang membership dis-enrollment) approaches to deterring violence include the Boston Gun Project and Operation CeaseFire as
well as Project Safe Neighborhoods in Chicago, and continue with the on-going Group Violence Reduction Strategy in Chicago. Using this approach, law enforcement partners work with social service providers and victims advocacy
groups to attempt to abate gang violence by ‘pulling’ whatever ‘levers’ need to be applied to street gangs. The types of
levers applied, and the degree to which they are employed,
depend upon the particular gang. Adjustments are made
so that the application is both customized to the speciﬁc
situation and, hopefully, more successful.
To facilitate these interactions between law enforcement,
social service providers, victim’s advocacy groups, and street
gang members, two approaches are commonly employed. In
the case of the ﬁrst, law enforcement engages known street
gang members on the street as part of regular patrol activities. While performed under the auspices of focused de-

complex networks, network diﬀusion, propagation in networks

1. INTRODUCTION
Violent street gangs are a major cause of criminal activity
in the United States [2, 5]. A recent trend has been toward development of “smart policing” tactics to reduce the
eﬀectiveness of these gangs. Typically, these strategies have

(c) 2014 Association for Computing Machinery. ACM acknowledges that this contribution was authored or co-authored by an employee, contractor or affiliate of the
United States government. As such, the United States Government retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so,
for Government purposes only.
KDD’14, August 24–27, 2014, New York, NY, USA.
Copyright 2014 ACM 978-1-4503-2956-9/14/08 ...$15.00.
http://dx.doi.org/10.1145/2623330.2623331.

1829

terrence, this type of interaction is likely to have the least
impact. Time spent with the gang member may be limited, the remaining levers (social service providers, victims
groups, etc.) are absent so that the message conveyed to the
street gang member is incomplete or biased toward criminal
enforcement aspect. Moreover, the selection of target gang
members is often random – the result of opportunity as the
gang member is seen on the street.
In the second approach, gang members are subjected to a
“call-in.” The call-in sessions are prearranged meetings organized by law enforcement, social service providers, and victims groups during which messages of non-violence are conveyed. The call-in is a full-spectrum eﬀort: law enforcement
makes clear to attendees that further violence will be met
with relentless police operations and enforcement eﬀorts, social service providers oﬀer information on how members can
exit the street gang and obtain educational and vocational
training, and victims groups tell stories of loss in an eﬀort
to make an emotional plea for violence cessation.
Attendees for call-in sessions are typically chosen in two
ways: compulsory attendance and invitation. Gang members currently on probation or parole are compelled to attend. The remaining attendees are invitees, and it is here
where the selection criteria may become a bit vague. Invitees
may be selected via some form of social network analysis (as
in [5]) however such concerted eﬀorts are not entirely relied
upon. Often, a large amount of discretion is aﬀorded local
law enforcement in selecting invitees. This allows for local
gang experts and command staﬀ members to identify those
gang members whom they know or suspect to be inﬂuential
or key members of the gang and invite them to the call-in.
This can be a very successful process if the agency has access
to these experts or knowledge of the gang’s organizational
structure. However, there is no guarantee that those persons invited are, in fact, genuinely inﬂuential in the gang or
are just the “most well known to law enforcement” members
of the gang. In law enforcement, where ﬁnancial, personnel,
and time resources are increasingly constrained, turning a
more objective and analytical eye toward invitee selection
grows more important.
A key aim of gang dis-enrollment programs is to enable
law enforcement to invite to call-ins those gang members
who, should the eﬀorts to dis-enroll them be successful, are
most likely to pull additional gang members out with them.
However, there is a key challenge: are inﬂuential members
also easy to encourage to leave the gang? A recent empirical
study exploring non-criminal online social networks suggests
that highly inﬂuential individuals are typically not susceptible [1]. However, we argue that taking both inﬂuence and
susceptibility into account are necessary; identifying individuals (or groups of individuals) that possess both qualities is
needed for the behavior to spread.
Though, to the best of our knowledge, inﬂuence maximization techniques have not been applied to law enforcement before, there is some anecdotal evidence that such approaches
could bear fruit. For instance, there have been cases where
gang members thought to be “inﬂuential” successfully convinced others to dis-enroll from the gang. In one case, in
Chicago (in the summer of 20130, the district personnel (local plainclothes gang oﬃcers) knew this person to be an
inﬂuential and as such targeted him for intervention. When
he was contacted he indicated that he had already gotten a
job, but knew several fellow gang members who could use

the oﬀered social services and dis-enrollment opportunities.
He personally contacted 20 fellow gang members, of which
7 walked into the local social services facility.
In this paper we frame the problem of “pulling levers” formally as a variant of the social network maximum inﬂuence
problem [14] in what we call the “social incentive inﬂuence”
(SII) problem. However, there are some key nuances of the
“pulling levers” strategy that we integrated into our framework that are not inherently considered in the maximum
inﬂuence problem. We list these items here and address our
technical approach to each in the next section.
1. Duration of the diﬀusion process. One key diﬀerence SII has from other maximum inﬂuence formulations is the length of time it takes for the diﬀusion
process to occur. The reason for this is that gang
dis-enrollment is a major life decision for an individual, hence the spread of this idea will likely take time.
Further complicating the matter is that there may be
changes to social network structure while the diﬀusion
process occurs - based on events such as arrests, homicides, gang conﬂict and cooperation, etc.
2. Interaction with the population during the diffusion process. Not only does the diﬀusion process
take time to occur in this domain, but also the law enforcement personnel will often make multiple attempts
to “pull levers” as the diﬀusion occurs.
3. Geographic locations and strength of connections. Often, law enforcement data has an inherent
geospatial component. In this work, we leverage this
information to inform the strength of connections in
the social network - as the street gangs are also inherently territorial.
4. Notion of cost. Cost also becomes an important
factor in SII as the law enforcement personnel are attempting to encourage a major change in the life of the
gang members. Conducting a call-in session with certain members costs time, money, and other resources.
We also note that not all gang members will be equally
susceptible to this type of intervention - some may require more or less eﬀort to dis-enroll. Further, there
are real costs associated with encouraging dis-enrollment.
For example, in North Carolina personalized letters
are created for the gang members that show the individual how his association with others involved in
violence puts him or her at risk. A similar tactic is
used in Chicago, where the letters are often delivered
to the homes of the gang members. This utilizes police
manpower and resources hence further increasing the
cost.
5. Proﬁt maximization. As we consider cost, we also
model “beneﬁt” in SII - which is the value of each expected infectee to the diﬀusion process. This allows
us to adopt a proﬁt-maximizing model (similar to the
ProMax problem of [15]) where we look to maximize
the expected beneﬁt minus the cost.

1830

3. TECHNICAL PRELIMINARIES
AND ANALYSIS

model [11], and the value function of the logic-programming
framework of [20] are all valid diﬀusion process functions.
We also note that these previous studies focused only on
maximizing the number of expected infectees (subject to a
cardinality constraint). In this work, we disregard the cardinality constraint and instead seek to maximize proﬁt, which
we formally deﬁne below.

Throughout this paper we assume the existence of a social
network G = (V, E) where V is a set of vertices and E is a
set of directed edges. We let n and m denote the cardinality
of V and E respectively. For any node v ∈ V , the set of
incoming neighbors is ηvin , and the set of outgoing neighbors
is ηvout . The cardinalities of these sets (and hence the in- and
out-degrees of node v) are denoted by kvin , kvout respectively.
For each node v, we assume a cost of marketing to that
node denoted by cv ∈ ℜ+ . We let C denote the vector
of costs indexed by V . We let ⟨c⟩ denote the average cost
∑
+
v cv /n. We also assume a beneﬁt value, b ∈ ℜ , which is
the associated beneﬁt for having marketed to a given node.
We assume that each node in G has an associated geolocation and there exists a distance function d : V × V → ℜ+
that meets the normal axioms: d(u, u) = 0, d(u, v) = d(v, u),
and d(u, w) ≤ d(u, v) + d(v, w).
Using this distance function, we shall assume a level of
inﬂuence puv for each edge (u, v) ∈ E that we deﬁne using
an exponential distance-decay model [23, 16, 22] as follows:
puv = e−(d(u,v)/γ)

Definition 3.3 (Profit). ∑
Proﬁt, pft : 2V → ℜ is deﬁned by pft(X) = b × dpf(X) − v∈X cv
The SII Problem. We now have all components necessary to formally deﬁne the social incentive inﬂuence (SII)
problem:
Definition 3.4 (SII Problem). We are given diﬀusion
process function dpf, social network G = (V, E), cost vector
C and beneﬁt value b. Find SII(dpf, G, C, b) = V ∗ ⊆ V
such that pft(V ∗ ) ≥ pft(V ′ ) for all V ′ ⊆ V .
Not surprisingly, the social incentive inﬂuence problem is
NP-hard.
Theorem 3.1. SII is NP-hard.
Proof. We show NP-hardness by reducing SIMPLE MAX
CUT [13] to SII. The SIMPLE MAX CUT problem takes as
input a graph G = (V, E) and returns sets V1 , V2 ⊆ V such
that |{(u, v) ∈ E : u ∈ V1 , v ∈ V2 }| is maximized. The following construction
can be performed in polynomial time.
∑
Let dpf(X) = v∈X fv (X) where fv (X) = 1 if v ∈ X and
|ηvin ∩ X| otherwise. Note that dpf(∅) = 0 and, because
each fv is submodular, dpf is submodular.
For each v set
∑
cv = 1 and set b = 1. Then pft(X) = v∈V \X : ηvin ∩ X| =
|{(u, v) ∈ E|u ∈ X, v ∈ V \ X}|. Hence pft becomes equivalent to the objective function for SIMPLE MAX CUT.

r

where γ, r are parameters in the interval (0, ∞) and e is the
base of the natural logarithm. The parameter γ is used as
a scaling parameter - and we shall set it to be the average
distance between two nodes connected with an edge. The
parameter r controls the shape of the distance decay curve,
and we shall typically use r = 2. The use of the distance
decay function as a proxy for inﬂuence is the primary way we
address the geographic nature of the law-enforcement data
in this application.
Diﬀusion Process. A key property that we utilize in our
study is submodularity, which we review below:

However, note that our proﬁt function pft is submodular.
Proposition 3.1. pft is submodular.
Proof. It is well known that subtracting a supermodular
function from a submodular function yields a submodular
function. Since dpf is submodular (and b is positive) and the
sum of costs is supermodular, the proposition follows.

Definition 3.1 (Submodularity). Function f : 2 →
ℜ+ is submodular if for every A ⊆ B ⊆ U and u ∈ U :
f (A ∪ {u}) − f (A) ≥ f (B ∪ {u}) − f (B).
U

Intuitively, the idea of submodularity represents a notion
of diminishing returns: adding an element u to a set B can
provide no greater beneﬁt than that gained by adding it to
any proper subset of B.
Equivalently, function f : 2U → ℜ+ is submodular if for
every A, B ⊆ U , f (A) + f (B) ≥ f (A ∪ B) + f (A ∩ B).
A set function is supermodular if its negation is submodular.
Next, we deﬁne a diﬀusion process function (dpf) which
accepts an initial set of vertices (called the “seed set”) and
returns the expected number of infectees once the diﬀusion
process completes. In this paper, we shall require this function to be sub-modular and normalized. We provide a formal
deﬁnition below.
Definition 3.2 (Diffusion Process Function). A diffusion process function, dpf : 2V → [0, n], is any function such that: (1.) dpf(∅) = 0 and (2.) ∀V1 , V2 ⊆ V :
dpf(V1 ) + dpf(V2 ) ≥ dpf(V1 ∪ V2 ) + dpf(V1 ∩ V2 ).
We argue that, in general, these are reasonable restrictions. For instance, the σ function of the independent cascade and linear threshold models [14], the oracle of the MIA

One-Step Diﬀusion. As stated earlier, two key challenges
in this domain are the duration of the diﬀusion process and
the eﬀect of the law-enforcement personnel interacting during the diﬀusion process. This has led us to model the diﬀusion process as a “one-step” inﬂuence model where we only
consider the immediate eﬀect of the diﬀusion process one
time step in the future. Our envisioned use case is that
the law-enforcement analysts will use the most current data
available to make a decision as to which gang members to
reach-out to based on this model. Attempts will be made
to inﬂuence those individuals, after which changes to the
social network (both resulting the outreach and other external factors) will be incorporated before repeating the cycle. Because we expect the time for diﬀusion to generally
take longer, the repetition of the cycle will generally occur after about one time period. We formally deﬁne the
following“one-step” inﬂuence model.
Definition 3.5. The one-step diﬀusion model, σ1 :
2V → ℜ+ is deﬁned as follows:
∑(
∏
)
σ1 (V ′ ) =
1−
(1 − puv )
u∈V

1831

in ∩V ′
u∈ηv

Algorithm 1 SII-Approx[7]
INPUT: Social network G = (V, E), cost vector C, beneﬁt
b, distance function d.
OUTPUT: Approximation V ′ to SII.

Note that we also assume that a node v is infected by a
node u independently of which others of its incoming neighbors were previously infected. An easy proof shows that σ1
is a valid diﬀusion process function.
Proposition 3.2. σ1 is a valid diﬀusion process.

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

Proof. Clearly,
∏σ1 (∅) = 0 by inspection. Next, we show
that the quantity u∈ηin ∩V ′ (1−puv ) is supermodular. Supv
pose, by way of contradiction, that it is not, then we have
′
for V and nodes q, r ∈
/ V ′ the following for each v ∈ V :
∏
∏
(1 − puv ) −
(1 − puv ) <
in ∩(V ′ ∪{q,r})
u∈ηv

in ∩(V ′ ∪{r})
u∈ηv

∏

(1 − puv ) −

in ∩(V ′ ∪{q})
u∈ηv

∏

(1 − puv )

in ∩V ′
u∈ηv

Let us assume that q, r are both neighbors of v (the other
cases cause both sides to be equal). This gives us the following:
∏
∏
)
(
(1 − puv ) <
(1 − puv ) −
(1 − prv )
∏

∏

in ∩(V ′ ∪{q})
u∈ηv

of optimal. Note that pft can potentially provide a solution
with negative value. However, we can leverage their results
to provide the following approximation guarantee:

in ∩V ′
u∈ηv

in ∩(V ′ ∪{q})
u∈ηv

(1 − puv ) −
∏

∏

V ′ = ∅, V ′′ = V
for v ∈ V do
a = pft(V ′ ∪ {v}) − pft(V ′ )
b = pft(V ′′ \ {v}) − pft(V ′′ )
if a ≥ b then
V ′ = V ′ ∪ {v}
else
V ′′ = V ′′ \ {v}
end if
end for
return V ′ .

Corollary 4.1. Given VALG as returned by SII-Approx
for an instance of SII and optimal soluition VOP T we have
the following relationship:

(1 − puv )

in ∩V ′
u∈ηv

As u∈ηin ∩(V ′ ∪{q}) (1−puv ) ≤ u∈ηin ∩V ′ (1−puv ), we have
v
v
1 < 1 − prv which is clearly a contradiction. Note that the
supermodularity
of this quantity implies the submodularity
∏
of 1 − u∈ηin ∩V ′ (1 − puv ). The rest of the statement follows
v
from the fact that σ1 is a positive linear combination of
submodular functions.

pft(VOP T )
n
− (⟨c⟩ − b) ≤ pft(VALG )
3
3
Proof. In the proof of Theorem I.1 of [7], the authors
show that pft(VOP T ) ≤ 3pft(VALG ) − pft(∅) − pft(V ). We
note that, by deﬁnition, pft(∅) = 0 and pft(V ) = bn − ⟨c⟩n =
−n(c − b), which gives the result.
Note that if ⟨c⟩ ≤ b then we recover the 1/3 approximation
of [7].

We note that we can cause nodes in the argument of this
function to be assigned a probability of 1.0 by simply adding
self-directed edges to each node in the network. We also
note, that with many diﬀusion processes functions, the calculation of their outcome may yield an individual probability of activation for each node. Further, the one-step model
also allows for the consideration of beneﬁt as a vector - the
probability for each node can obtained by inspecting the inner summation - this allows for a more customized setting
of beneﬁt on basis of each node (we are currently discussing
this as a possibility with our law enforcement partners). In
this case, we can identify a speciﬁc beneﬁt for each node.
The framework can be easily adapted for such a case.

5.

EXPERIMENTAL RESULTS

All experiments were run on a computer equipped with an
Intel X5677 Xeon Processor operating at 3.46 GHz with a 12
MB Cache and 288 GB of physical memory under the Red
Hat Enterprise Linux version 6.1 operating system. Only
one core was used for experiments. Our implementation of
SII-Approx was written in Python 2.7 using the NetworkX
library1 .
Police Dataset. We used a dataset consisting of arrest
records of individuals from March 2010 - March 2013 in a
single police district in Chicago. This data set included arrest location and relationships among the individuals. From
this data, we were able to construct a social network (“arrest
network”) consisting of 1836 nodes and 2531 edges. Two individuals in the arrest network are connected if they were
arrested together. We note that this is likely an incomplete
picture of the full network, but as we move to deployment
of this approach by integrating it with our GANG/ORCA
analysis software [18], law enforcement personnel can easily
supplement or replace an arrest network with information
from additional intelligence sources, obersvations by police
patrolmen, and data from correctional facilities.
Additionally, for some experiments we also generated simulated networks to supplement our analysis.

4. APPROACH
While the submodularity of the pft function is encouraging, we note that because marketing to each node incurs an
associated cost, it is possible to experience a loss by marketing to additional nodes. For instance, if we market to
an additional individual who provides us no increase in the
diﬀusion process, this reduces our proﬁt and could lead to a
loss. This is not considered in previous diﬀusion models designed to maximize the expected number of infectees. Hence,
the greedy approximation of [17] no longer provides us an
approximation guarantee. Our case can instead be viewed as
an “unconstrained” submodualr function. Recently, a deterministic approximation algorithm was introduced in [7] that
requires only a linear number of evaluations of the function.
We recall their algorithm here (adapted for SII).
For positive, unconstrained submodular maximization, [7]
proves that SII-Approx provides a result that is at least 1/3

1

1832

http://networkx.github.io/

Dataset
Police
Compl.
E-R
SF
FF

Num.
Sams.
20
2
9
27
1

Avg.
Size
13.55
22.5
20
20
15

Min.
Appx.
0.70
1.00
0.84
0.80
1.00

Max.
Appx.
1.00
1.00
1.00
1.00
1.00

Avg.
Appx.
0.92
1.00
0.93
0.98
1.00

Std.
Dev.
0.09
0.00
0.05
0.06
0.00

Table 1: Empirically Determined Approximation
Ratios for SII-Approx (when compared to the optimal solution)

Comparison with Optimal Solution. Our ﬁrst test was
to evaluate SII-Approx compared to an optimal solution found
by enumeration. We did this by sampling the police dataset
and by generating simulated networks. We generated 20
connected samples from the overall police network ranging
in size from 11 to 20 nodes. We deﬁned cost cv = 1 for all
v ∈ V and we set beneﬁt b = 1. The worst approximation
ratio obtained in these tests was 0.70 - more than double
the theoretical bound of 1/3 in this case. The average-case
bound was better still at 0.92. Additionally, we also studied
the behavior of SII-Approx on several standard generated
graph types including complete graphs of size 20 and 25,
Erdos-Reyni (E-R) random graphs, preferential-attachment
generated scale-free graphs (SF), and the “Florentine Families” (FF) network [6]. In all of these tests, we never achieved
an approximation ratio lower than 0.80. The results are
shown in Table 1.

Figure 1: Network size vs. speedup obtained by
SII-Approx over exact approach.

Runtime Evaluation. We evaluated runtime in two ways:
(1) we compared the runtime of SII-Approx with an exact
enumeration based computation and (2) we studied how SIIApprox scaled with network size. Both results are depicted
in Figures 1 and 2. For the comparison with the exact computation, we studied the eﬀect of runtime on our 20 samples
from the police dataset. We studied at the speedup provided
by SII-Approx (deﬁned as the runtime for the exact approach
divided by the runtime for SII-Approx on the same input) as
a function of network size. We found a signiﬁcant speedup
in all cases and that the speedup increased exponentially
with network size (R2 = 0.96) - which is clearly due to the
exponential runtime of the enumeration approach.
Runtime also scaled monotonically with the size of the
network (quadratic ﬁt, R2 = 0.97). Hence, for the size of
the datasets used by the Chicago police department (order
103 nodes), this is a viable approach with the current implementation. However, we think further improvement in
runtime for the heuristic is possible with further practical
modiﬁcations.
Figure 2: Network size vs. runtime for the heuristic
algorithm.

Cost Model Evaluation. One of the more useful characteristics of our framework is the ability to consider node
costs. We studied two variants. First, we studied the case in
which all nodes have the same cost, considering several different values. Second, we set the cost to be proportional to
a network centrality measure. In both cases, we also varied
the value of the beneﬁt. We used the entire police dataset
in these trials. The results for both sets of trials are shown
in Figures 3 and 4.

1833

We examined a ﬁxed/uniform cost model where all nodes
we assigned the same value. We examined cost values from
0.25 to 2.0 in intervals of 0.25 and compared them to uniform
beneﬁt values in the same range. In general, there was a
linear relationship between the beneﬁt and proﬁt for all ﬁxed
cost models examined (R2 values ranged from 0.97 to 0.99).
Further, as expected, decreased cost led to increased proﬁt.
For our centrality-based cost trials, we studied degree centrality (number of adjacent edges), closeness centrality (see
[24]), eigenvector centrality (see [4]), shell number (based on
shell-decomposition, see [19]), and clustering coeﬃcient (see
[24]). Cost was set to be proportional to these values for
each node. We also normalized the cost so that the average
would be 1.0 in each case. Just as with the ﬁxed-cost trials, we compared the proﬁt for various beneﬁt values in the
range [0.25, 2.0] in intervals of 0.25.
For centrality-based cost models, we also observed a linear relationship between beneﬁt and proﬁt (R2 values approaching 1.0). In examining the diﬀerence among centrality measures, we found the most expensive centralities were
degree and shell-number followed by closeness. As these can
be considered radial measures of centrality, meaning they
measure centrality in terms of the number of paths that
originate from a given node, then this result should be expected. Clustering coeﬃcient was less expensive than these
measures, which again was as expected as this measure is
less dependent upon the number of adjacent nodes and more
dependent upon the neighborhood. Perhaps most interesting was that eigenvector centrality was the “least expensive”
cost model. We believe that this is due to the wide distribution of values assigned by this measure which ranged from
1.66 × 10−43 to 166.45 (compared to degree, which ranged
from 0.36 to 6.17).

Figure 3: Proﬁt obtained from SII-Approx for the police dataset for ﬁxed/uniform cost models with various beneﬁt settings.

Figure 4: Proﬁt obtained from SII-Approx for the
police dataset for centrality-based cost models with
various beneﬁt settings.

We note that the idea of a cost model is an important feature in our model as it has previously been shown that inﬂuential nodes are often not those who most susceptible [1].
This may imply that an individuals who may be inﬂuential
in the network from a topological perspective may also be
of high cost. This is why we considered cost models in our
experiment where more central nodes were given a higher
cost.

all of these measures showed some improvement over the
random baseline, they were out performed by ClusterRank
for all beneﬁt values above 0.5. We are currently examining
the performance of centrality-based ordering heuristics on a
variety of inputs for the algorithm.
Iterative Application. We envision real-world police use
of SII-Approx to occur in an iterative manner. One way this
could be done is as follows: we initially consider a uniform
cost model and identify initial nodes to seed. Then, we
calculate the diﬀusion process function based on that seed
set in a manner that yields the probability pv of each node
v being activated. Then, for the next iteration, we remove
from the network all previously seeded nodes (or whichever
subset dis-enrolled from the gang) and set the cost for each
node v to be 1 − pv . The intuition is that it will be less
expensive to seed nodes that already obtained inﬂuence from
other members departing the gang. The process of re-setting
the cost function and social network prior to re-running SIIApprox is then performed continually.
We applied SII-Approx iteratively ﬁve times to the police
dataset in the manner described above and studied the size
of the set targeted as well as the resulting proﬁt (see Figures 6-7). We observed, under the assumption that all previously seeded members left the gang, that the proﬁt gained
decreased monotonically with the number of iterations while
the number of targeted vertices increased slightly in the second iteration, followed by a steep decrease and then converged to zero. The success of the second iteration indi-

Heuristic for Improved Solution Quality. SII-Approx,
as presented in this paper, does not take into account the
order in which the vertices are selected. We found that if
vertices are examined in descending order by their ClusterRank [8] then the algorithm provided a higher-proﬁt solution when compared to our random baseline (average over 10
runs) for the case of uniform cost (∀v ∈ V, cv = 1) and various settings for beneﬁt. The results are depicted in Figure 5.
In [8] nodes of high ClusterRank were shown to encourage
diﬀusion under the SIR model - which is related to the onestep process of this paper. The ClusterRank of node v is
deﬁned as follows:
∑
crv = 10−Cv
(1 + kuout )
out
u∈ηv

Where Cv is the clustering coeﬃcient for node v. This is particularly helpful as the computation of these measures relies
only on local information and can be calculated quickly. Additionally, we examined ordering by degree, clustering coeﬃcient, closeness centrality, shell number, and
∑ weighted degree
centrality (for each v ∈ V the quantity u∈V pvu ). While

1834

Figure 7: Iterative applications of SII-Approx – Proﬁt
obtained at each iteration.

Figure 5: Improvement to proﬁt as returned by SIIApprox when the vertices are ordered by ClusterRank.

relies on the number of an individuals neighbors reaching
a certain threshold. Another issue is that in most of these
models, the diﬀusion process function is diﬃcult to compute
- for instance the dpf for the independent cascade model is
shown to be #P -hard in [11]. As a result, in most other
pieces of work the diﬀusion process is approximated using
simulation, which is as expensive operation. (Most law enforcement agencies we work with have limited computational
power). One notable exception regarding this issue are deterministic models such as that described in [12, 21]. We
note that in our previous work we have looked at utilizing
this model in a law-enforcement setting [18, 3]. However the
results of that work were primarily used to describe characteristics of the gangs and not to make operational decisions.
This work did not study the operational issues associated
with encouraging gang dis-enrollment as considered in this
paper.

Figure 6: Iterative applications of SII-Approx – Number of nodes targetted at each iteration.
cated that viral marketing may be successful in encouraging
neighboring individuals to dis-enroll. However, beyond the
second step, there is limited proﬁt to further marketing for
dis-enrollment. We note that at this point, if successful, approximately half of the gang members are dis-enrolled, which
would be a signiﬁcant reduction. Further, we also note that
topological changes to the network may become more signiﬁcant after the second (and possibly even after the ﬁrst)
round of dis-enrollment.
Iterative application of the algorithm also opens up some
new possibilities for future work. For instance, we can view
our problem as a sequential decision making problem. The
intuition in such an approach would be to not only to maximize the expected number of dis-enrolled gang members
but also to position the law enforcement personnel to more
easily inﬂuence the network in later iterations. Such an approach may also allow us to consider how the topology of
the network will change over time.

7.

CONCLUSION

In this paper we introduced the “social incentive inﬂuence” (SII) problem, a variant of the maximum inﬂuence
problem, designed to help law-enforcement personnel identify members of street gangs that they can encourage to
dis-enroll. We studied this problem both formally and experimentally in the context of the law-enforcement domain.
Utilizing techniques from unconstrained submodular maximization, we developed a heuristic technique to help police
better identify sets of inﬂuential individuals to target with
dis-enrollment incentives. We implemented our approach
and performed an experimental evaluation. We currently
have our approach to the SII problem integrated into our
GANG/ORCA analysis software [18] that is currently in use
by the Chicago Police. Our next goal is to work with law
enforcement personnel to better understand how SII is employed in practice - allowing us to identify components of
this framework that can be adjusted for improved results in
a real-world setting.

6. RELATED WORK
The maximum inﬂuence problem was introduced in [14]
and later studied in work such as [9, 11, 15, 21]. We refer
the reader to the book [10] for a summary of recent work
in this area. However, to our knowledge, no other work addresses all the challenges presented here for the SII problem
simultaneously. For instance, [11] presents a model where
the diﬀusion is restricted to shortest paths - which is a similar restriction to our one-step model, but does not consider
the idea of proﬁt. Likewise, [15] considers the idea of proﬁt,
but only applies it to the linear threshold model - which

8.

ACKNOWLEDGMENTS

The authors are supported by the Army Research Oﬃce
(project 2GDATXR042) and the U.S. Air Force. The opinions in this paper are those of the authors and do not necessarily reﬂect the opinions of the funders, the U.S. Military
Academy, the U.S. Army, the U.S. Air Force, or the U.S.
Department of Defense.

1835

9. REFERENCES

[14] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing
the spread of inﬂuence through a social network. In
KDD ’03: Proceedings of the ninth ACM SIGKDD
international conference on Knowledge discovery and
data mining, pages 137–146, New York, NY, USA,
2003. ACM.
[15] W. Lu and L. Lakshmanan. Proﬁt maximization over
social networks. In Data Mining (ICDM), 2012 IEEE
12th International Conference on, pages 479–488, Dec
2012.
[16] J. C. Nekola and P. S. White. Special Paper: The
Distance Decay of Similarity in Biogeography and
Ecology. Journal of Biogeography, 26(4):867–878, 1999.
[17] G. L. Nemhauser, L. A. Wolsey, and M. Fisher. An
analysis of approximations for maximizing submodular
set functionsı̈£¡i. Mathematical Programming,
14(1):265–294, 1978.
[18] D. Paulo, B. Fischl, T. Markow, M. Martin, and
P. Shakarian. Social network intelligence analysis to
combat street gang violence. In Proceedings of the
2013 IEEE/ACM International Conference on
Advances in Social Networks Analysis and Mining,
ASONAM ’13, pages 1042–1049, New York, NY, USA,
2013. ACM.
[19] S. B. Seidman. Network structure and minimum
degree. Social Networks, 5(3):269 – 287, 1983.
[20] P. Shakarian, M. Broecheler, V. S. Subrahmanian, and
C. Molinaro. Using generalized annotated programs to
solve social network diﬀusion optimization problems.
ACM Trans. Comput. Logic, 14(2):10:1–10:40, June
2013.
[21] P. Shakarian and D. Paulo. Large social networks can
be targeted for viral marketing with small seed sets.
2012 IEEE/ACM International Conference on
Advances in Social Networks Analysis and Mining,
pages 1–8, 2012.
[22] H. Skov-Petersen. Estimation of distance-decay
parameters: GIS-based indicators of recreational
accessibility. In ScanGIS, pages 237–258, 2001.
[23] P. J. Taylor. Distance transformation and distance
decay functions. Geographical Analysis, 3(3):221–238,
1971.
[24] S. Wasserman and K. Faust. Social Network Analysis:
Methods and Applications. Number 8 in Structural
analysis in the social sciences. Cambridge University
Press, 1 edition, 1994.

[1] S. Aral and D. Walker. Identifying inﬂuential and
susceptible members of social networks. Science,
337(6092):337–341, 2012.
[2] J. Bertetto. Countering criminal street gangs: Lessons
from the counterinsurgent battlespace. Law
Enforcement Executive Forum, 12(3):43, 2012.
[3] J. Bertetto. Counter-gang strategy: Adapted coin in
policing criminal street gangs. Law Enforcement
Executive Forum, 13(3), 2013.
[4] P. Bonacich. Factoring and weighting approaches to
status scores and clique identiﬁcation. The Journal of
Mathematical Sociology, 2(1):113–120, 1972.
[5] A. Braga, D. Hureau, and A. Papachristos. Deterring
gang-involved gun violence: Measuring the impact of
bostonâĂŹs operation ceaseﬁre on street gang
behavior. Journal of Quantitative Criminology, pages
1–27, 2013.
[6] R. L. Breiger and P. E. Pattison. Cumulated social
roles: The duality of persons and their algebras. Social
Networks, 8(3):215–256, Sept. 1986.
[7] N. Buchbinder, M. Feldman, J. S. Naor, and
R. Schwartz. A tight linear time (1/2)-approximation
for unconstrained submodular maximization. In
Proceedings of the 2012 IEEE 53rd Annual Symposium
on Foundations of Computer Science, FOCS ’12,
pages 649–658, Washington, DC, USA, 2012. IEEE
Computer Society.
[8] D.-B. Chen, H. Gao, L. LÃij, and T. Zhou. Identifying
inﬂuential nodes in large-scale directed networks: The
role of clustering. PLoS ONE, 8(10):e77455, 10 2013.
[9] N. Chen. On the approximability of inﬂuence in social
networks. SIAM J. Discret. Math., 23:1400–1415,
September 2009.
[10] W. Chen, L. V. Lakshmanan, and C. Castillo.
Information and Inﬂuence Propagation in Social
Networks. Morgan and Claypool Publishers, 2013.
[11] W. Chen, C. Wang, and Y. Wang. Scalable inﬂuence
maximization for prevalent viral marketing in
large-scale social networks. In Proceedings of the 16th
ACM SIGKDD international conference on Knowledge
discovery and data mining, KDD ’10, pages
1029–1038, New York, NY, USA, 2010. ACM.
[12] P. Dreyer and F. Roberts. Irreversible -threshold
processes: Graph-theoretical threshold models of the
spread of disease and of opinion. Discrete Applied
Mathematics, 157(7):1615 – 1627, 2009.
[13] M. R. Garey and D. S. Johnson. Computers and
Intractability; A Guide to the Theory of
NP-Completeness. W. H. Freeman & Co., New York,
NY, USA, 1979.

1836

Mining for Geographically Disperse Communities in Social
Networks by Leveraging Distance Modularity
Paulo Shakarian

Network Science Center and
Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY 10996

Patrick Roos

Dept. of Computer Science
University of Maryland
College Park, MD 20721

roos@cs.umd.edu

paulo@shakarian.net

Devon Callahan,
Cory Kirk

Network Science Center and
Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY 10996

devon.callahan@usma.edu
cory.kirk@usma.edu

ABSTRACT

1. INTRODUCTION

Social networks where the actors occupy geospatial locations are prevalent in military, intelligence, and policing operations such as counter-terrorism, counter-insurgency, and
combating organized crime. These networks are often derived from a variety of intelligence sources. The discovery
of communities that are geographically disperse stems from
the requirement to identify higher-level organizational structures, such as a logistics group that provides support to various geographically disperse terrorist cells. We apply a variant of Newman-Girvan modularity to this problem known
as distance modularity. To address the problem of ﬁnding
geographically disperse communities, we modify the wellknown Louvain algorithm to ﬁnd partitions of networks that
provide near-optimal solutions to this quantity. We apply
this algorithm to numerous samples from two real-world social networks and a terrorism network data set whose nodes
have associated geospatial locations. Our experiments show
this to be an eﬀective approach and highlight various practical considerations when applying the algorithm to distance
modularity maximization. Several military, intelligence, and
law-enforcement organizations are working with us to further test and ﬁeld software for this emerging application.

In recent years, fueled by the connectivity of our social
world and technological advances that allow for eﬀortless
collection of connectivity data, much eﬀort has been invested
in developing algorithms for the detection of communities in
networks (e.g. [11, 18, 17, 7, 3, 19, 9, 5]). The detection of
communities - subsets of nodes that are highly connected in
globally sparser networks - provides important insights into
the organization of networks and related hidden information
of social networks [11].
In many application domains, apart from the social network information provided by connectivity data, geospatial information is available as well, and community detection algorithms can be improved by leveraging such spatial information. Social networks where the actors occupy
geospatial locations are prevalent in military, intelligence,
and policing operations such as counter-terrorism, counterinsurgency, and combating organized crime. These networks
are often derived from a variety of intelligence sources. Community detection algorithms that speciﬁcally detect geographically dispersed communities are of interest in such application domains to identify higher-level organizational structures, such as a logistics group that provides support to
various geographically disperse terrorist cells. Such communities may be less obvious in solely the available social
network data. Hence, in order to ﬁnd geographically dispersed communities, there exists a need for community detection algorithms that are optimized considering geospatial
information in addition to social network information, and
we address this need in this paper.
Blondel et al. [3] have developed a heuristic method known
as the Louvain algorithm that partitions a social network
into communities while optimizing Newman-Girvan modularity of the partition. Newman-Girvan modularity is a
common performance measure in community detection algorithms that gives a measure of how densely the detected
communities of the partition are connected relative to connections between these communities [18]. More speciﬁcally,
the modularity measure is the “fraction of edges within communities in the observed network minus the expected value
of that fraction in a null model, which serves as a reference
and should characterize some features of the observed network” [14].
In this paper, we use a variant of Newman-Girvan modu-

Categories and Subject Descriptors
Applied Computing [Law, social and behavioral sciences]: Sociology

General Terms
Algorithms, Experimentation

Keywords
complex networks, geospatial reasoning
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
KDD’13, August 11–14, 2013, Chicago, Illinois, USA.
Copyright 2013 ACM 978-1-4503-2174-7/13/08 ...$15.00.

1402

larity with the Louvain algorithm to address the problem of
mining for geographically dispersed communities in application domains where geospatial information is pertinent.
Instead of the original null model used in Newman-Girvan
modularity, we leverage a null model introduced by Liu et al.
[14]. The use of this model results in the distance modularity
measure of community structure.
We test the algorithm on two real-world location-based social networks and a network from a transnational terrorism
data set, the nodes of which have associated geospatial locations. Our experiments show that this approach is eﬀective
at ﬁnding partitions of networks that provide near-optimal
solutions to distance modularity. We also highlight various
practical considerations when applying the algorithm with
these deﬁnitions of modularity. By testing the algorithm
on a social network that is signiﬁcantly larger (ca. 2100
nodes) than the test networks commonly used in the literature on community detection algorithms (typically  600
nodes), we also better demonstrate scalability. Further, our
results on the transnational terrorism network provide some
insight into how our approach will function on the often classiﬁed datasets of our target application. Currently, we are
working with several organizations in the U.S. Department
of Defense and the law enforcement communities to further
study and transition this technology.
Next, in Section 2, we cover some technical preliminaries, including deﬁnitions of modularity. Section 3 describes
the Louvain algorithm and our modiﬁcations to it to optimize for distance modularity. Section 4 describes our experiments and results on various data sets and an application
to transnational terrorism. We review and place our work
within related work in Section 5, and ﬁnally we conclude in
Section 6.

Here, the null model used as a reference for comparison to
a given partition assumes edges are rewired randomly, while
the degree sequence of the input network is preserved, hence
ki kj
Pij = 2m
.
Recently, a measure for modularity that accounts for distance, as well as network topology, was introduced by Liu et
al. [14]. Their modularity, henceforth referred to as distance
modularity, is deﬁned as follows:
Definition 2.2 (Distance Modularity [14]). Given
partition C = {c1 , . . . , cq }, distance modularity,
1 
wij − Pij
Mdist (C) =
2m c∈C i,j∈c
where Pij =



ki kj f (d(vi ,vj ))
,
kq f (d(vq ,vi ))

vq ∈V

and

f :  → (0, 1] is the distance-decay function.
The basic idea behind this distance modularity is that
each node exerts a force on other nodes by generating a
ﬁeld, and the potential of the ﬁeld at any point decreases
with distance from the ﬁeld source (the node generating the
ﬁeld), depending on the distance decay function [13, 14].
The null model then that serves as a reference for comparison here assumes that nodes which are closer according to
the distance function are more likely to be connected. In this
paper we shall assume the existence of a distance function
d : V ×V → + that meets the normal axioms: d(vi , vi ) = 0,
d(vi , vj ) = d(vj , vi ), and d(vi , vj ) ≤ d(vi , vq ) + d(vq , vj ).
Previously, it has been proven that modularity-maximization
is NP-hard [4]. Clearly, setting ∀x, f (x) = 1, distance modularity reduces to NG modularity. As a direct consequence of
this observation, ﬁnding a partition that optimizes distance
modularity is also NP-hard.
Theorem 2.1. Given graph G = (V, E) and distance function d : V × V → + , finding a partition C of V that maximizes MS is NP-hard.

Throughout this paper, we shall model a network as an
undirected graph G = (V, E) where V is a set of nodes
and E is a set of relationships among nodes. We use n, m
to represent the cardninalities of V, E respectively. As the
graph is undirected, we shall assume that (vi , vj ) ∈ E implies (vj , vi ) ∈ E. We also assume that each edge (vi , vj )
has an associated weight wij (again ∀i, j, wij = wji ). For a
given node vi ∈ V , ηi = {vj |(vi , vj ) ∈ E ∨ (vj , vi ) ∈ E} and
ki = |ηi |.
We shall use the notation C = {c1 , . . . , cq } to denote a
partition over set V where eachci ∈ C is a subset of V , for
any ci , cj ∈ C, ci ∩ cj = ∅ and i ci = V .
For a given partion, C, the modularity M (C) is a number in [−1, 1] . The modularity of a network partition can
be used to measure the quality of its community structure.
Originally introduced by Newman and Girvan. [18] this metric measures the density of edges within partitions compared
to the density of edges between partitions. A formal deﬁnition of this modularity (henceforth referred to as NG modularity) for an undirected network is

Throughout this paper, we will use an exponential distancedecay model[14, 5, 16, 20] deﬁned as follows:
2

f (x) = e−(x/σ)

Where σ is a parameter in the interval (0, ∞) and e is the
base of the natural logarithm. One way to interpret σ is
that it is the distance where the force exerted by a point
is reduced by a fraction 1/e (roughly 0.36). We note that
in the limit as σ approaches inﬁnity, geospatial modularity
reduces to NG modularity. In the next section, we test a
variety of settings for σ. Learning parameters such as σ has
previously been explored in various geospatial applications
– see [16, 20] for examples.

3.

APPROACH

This section describes the approach we use to mine for geographically dispersed communities in networks. Although
modularity maximization is NP-hard, a variety of practical approximation routines have been proposed [18, 17, 3]
that experimentally have produced near-optimal partitions.
In this paper, we employ the Louvain heuristic algorithm
of Blondel et al. [3], only instead of using it to maximize
NG-modularity, we use it to maximize distance modularity.
In order to use the Louvain algorithm to maximize distance

Definition 2.1 (NG modularity [18]). Given partition C = {c1 , . . . , cq }, NG modularity,
1 
wij − Pij
M (C) =
2m c∈C i,j∈c
ki kj
2m

Pˆij =

+

2. TECHNICAL PRELIMINARIES

where Pij =

Pˆij +Pˆji
,
2

.

1403

modularity, we must also modify some of it’s steps. We summarize the Louvain algorithm brieﬂy next (for more details
on this algorithm, see [3]) and describe our modiﬁcations
and practical considerations when employing this heuristic
algorithm to optimize distance modularity.

3.1

Table 1: Brightkite Sample Data
Max
Min
Avg

Heuristic Algorithm

The Louvain algorithm is an iterated, hierarchical process
in which two phases are applied repeatedly until maximal
modularity is reached: In the ﬁrst phase, each node vi ∈ V
of the given network is assigned to a community c, creating an initial partition. In [3], the singleton partition was
used. Then, for each vi ∈ V , the gains in modularity that
would result from placing vi to the community of each of
its neighbors vj ∈ ηi are calculated, and vi is removed and
placed into the community for which the maximum gain in
modularity is attained (unless no positive gain in modularity is possible). This sub-process is repeated sequentially for
each vi ∈ V until no individual move will result in a gain
in modularity, marking the end of the ﬁrst phase and giving
a partition C. In the second phase, a new network is built
by using each ci ∈ C as a node in the new network, call
these nodes meta-nodes. Weights on the edges between any
two meta-nodes in the new network are assigned to be the
sum of the weights of the edges between nodes in the two
communities corresponding to the meta-nodes. In this step,
self-loops are created for each meta-node in the new network
from the links between nodes of the community corresponding to that meta-node. After this phase is complete, the
two phases are reapplied iteratively until there are no more
changes.
The eﬃciency of the Louvain algorithm relies on an easy
re-calculation of modularity in the ﬁrst phase of the algorithm. When computing gains in modularity in phase one
of the algorithm, removing any node vi , the overall increase
in modularity (regardless if it is distance or NG) if it is
placed into community c is proportional to:

ki,in −
Pij

Edges
2801
787
1560.40

resulting from a normal run of the Louvain algorithm optimizing for NG modularity, provided better results at the
expense of some runtime. Second, since each node has an
associated geospatial value, a geospatial value must be assigned to the meta-nodes of the new networks being built.
Here we use the centroid of the communities that correspond to the meta-nodes. Throughout the remainder of this
paper, we shall refer to the described modiﬁed version of the
Louvain algorithm (for maximizing distance modularity) as
the Louvain-D algorithm. The implications of these considerations are discussed in more detail in our experimental
results.

4. EXPERIMENTAL RESULTS
For our experiments, we used information extracted from
the Gowalla and Brightkite location-based online social networking sites [6].
We built our implementation in Python 2.6 on top of the
NetworkX library 1 leveraging code from Thomas Aynaud’s
implementation of the Louvain algorithm 2 . Our implementation took approximately 1000 lines of code. The experiments were run on a computer equipped with an Intel X5677
Xeon Processor operating at 3.46 GHz with a 12 MB Cache
running Red Hat Enterprise Linux version 6.1 and equipped
with 70 GB of physical memory. All statistics presented in
this section were calculated using R 2.13.1.

4.1

Distance Modularity Evaulation

In our ﬁrst set of tests, we iteratively selected nodes and
their neighbors from the Brightkite network dataset provided by the authors of [6] to produce 20 small samples (of
at least 300 nodes each). Each sample originated with a
randomly selected node from the network and we iteratively
added neighbors of the selected node(s) to the sample until a
minimum desired sized was achieved. Node and edge counts
for these small networks is listed in Table 1.
On our 20 samples extracted from the Brightkite dataset,
we considered the straight-line distance between nodes in
kilometers. Hence, in calculating geomodularity, we ran experiments σ = {50, 100, 150, . . . , 500}. For each dataset and
each value of σ, we compared the distance modularity returned by three approaches: the Louvain algorithm (which
does not consider any geospatial information), the LouvainD algorithm using singleton nodes as the initial partition,
and the Louvain-D algorithm using the result of the Louvain algorithm as the initial partition.
Both variants of the Louvain-D algorithm returned a partition with a greater average geomodularity for each value
of σ than the partition returned by the Louvain algorithm
(see Figure 1). This aligns well with the previous results
of [9, 5] where space can aﬀect on community structure not

j∈c

The only diﬀerence for distance modularity is that Pij is
deﬁned as per Deﬁnition 2.2 instead of Deﬁnition 2.1. In
terms of time complexity, the ﬁrst phase of the algorithm is
O(n2 ), since for every node in the network, distance modularity must be computed according to Deﬁnition 2.2, which
is O(n) in the denominator of Pˆij . The second phase is again
O(n). Both phases are a multiple of a constant that results
from the number of iterations needed to run to completion.
We note that the input sizes decrease drastically with each
iteration, since communities are iteratively collapsed into
nodes. Hence, the proposition on time complexity follows:
Proposition 3.1. The time complexity of the Louvain algorithm, optimizing for distance modularity, is quadratic in
terms of the number of nodes n of the input network.

3.2

Nodes
331
300
311.25

Practical Considerations

Apart from the main modiﬁcation to use distance modularity instead of NG modularity, there are two steps of the
original Louvain algorithm that we modify when optimizing
for distance modularity. First, we must decide on an initial
partition to use. Blondel et al. [3] use the singleton partition.
However, we have found that using the Louvain partition,

1
2

1404

http://networkx.github.com/
http://perso.crans.org/aynaud/communities/

accounted for in the network topology. However, we noticed
that the percentage increase in modularity decreases with
σ (see Figure 2). This relationship also makes sense as
distance modularity reduces to NG modularity (which the
Louvain algorithm is designed to optimize) as σ approaches
inﬁnity.
Although the Louvain-D algorithm outperformed the Louvain algorithm in terms of ﬁnding geomodularity, it generally returned higher-quality partitions if it was initialized
with the Louvain partition instead of the partition of singleton nodes. Further, when we used the Louvain partition
to initialize the Louvain-D algorithm, we never obtained a
partition with a lower geomodularity than the Louvain algorithm. With the singleton partition, on the other hand, the
Louvain-D was occasionally outperformed by the Louvain
algorithm – particularly for the higher values of σ.

Figure 2: σ (in kilometers) vs. percent improvement in geomodularity (for the partition returned
by the Louvain-D algorithm) when compared to the
distance modularity for the partition returned by
the Louvain (baseline) algorithm. Panel A shows
this relationship when the Louvain-D initially uses
the singleton partition while panel B shows this relationship when the Louvain-D algorithm initially
uses the Louvain partition.

Figure 1: σ (in kilometers) vs.
(average) distance modularity for the partitions returned by the
Louvain-D and Louvain (baseline) algorithms.

As an example of the type of result returned by our approach, we have included Figure 4 that illustrates the differences between a community returned by our approach vs.
the standard Louvain algorithm. The left panel shows a
group of individuals near the San Diego area that the Louvain algorithm identiﬁed as being in the same community.
Likely, in this case, there is a strong correlation between geographic distance and connection in the social network. The
right panel, by contrast, shows that the same individuals are
placed in multiple, diﬀerent communities by the Louvain-D
algorithm. Since relatively high-degree individuals that are
geographically near each other have a higher probability of
connection in the null model, it becomes more likely for the
Louvain-D algorithm to place them in diﬀerent communities.

However, the improvement in the quality when using the
Louvain partition as a starting point comes at the expense of
runtime. While the time to calculate the Louvain partition
was negligible (normally under 1 second in the Brightkite
tests), using it as a starting point appears to cause the
Louvain-D algorithm to take longer to reach convergence
- resulting in a runtime nearly double if the singleton partition is initially used (see Figure 3).
An analysis of variance (ANOVA) reveals that there is a
signiﬁcant diﬀerence in geomodualrity of the partitions returned by the three approaches on the Brightkite dataset
(p-value 2.2 · 10−16 ). Additionally, pairwise analysis conducted using Tukey’s Honest Signiﬁcant Diﬀerence (HSD)
test indicates that both instances of the Louvain-D algorithm provided results that diﬀered signiﬁcantly from the
Louvain algorithm and each other with a probability approaching 1.0 (95% conﬁdence). Additionally, the diﬀerences among runtimes were also signiﬁcant (ANOVA p-value
less than 2.2 · 10−16 ) and pairwise diﬀerent by the HSD with
a probability approaching 1.0 amongst all comparisons (95%
conﬁdence).

1405

Table 2: Gowalla Sample Data
Sample No.
1
2
3
4
5
6
7

Nodes
301
602
876
1201
1501
1801
2101

Edges
416
1550
12373
2680
3854
4887
6445

Figure 3: σ (in kilometers) vs. (average) runtime of
the Louvain-D algorithm (using both singleton and
Louvain partition initially).

Figure 5: Distance modularity of the partition found
using the Louvain (baseline) and Louvain-D algorithms for the Gowalla network samples (see Table 2).

tion 3.1, we expected a quadratic relationship. We veriﬁed
this relationship in our experiment (R2 = 0.9973). These
results are depicted in Figure 6. We note that while considering a network of 2101 nodes required just under two days
of computer time, which is acceptable for our applications,
further scaling will take prohibitively long runtimes. For
example, scaling to 104 nodes would require approximately
three months of runtime based on our regression analysis.
Further scalability is an important direction for future work.

Figure 4: Left: Communities identified using the
Louvain algorithm, Right: Communities found using
Louvain-D (σ = 150)

4.2

Tests on Larger Samples

4.3

In our second set of tests, we iteratively selected nodes and
their neighbors from the Gowala network dataset [6] to produce seven samples ranging in size from 301 to 2101 nodes
each. Samples were collected in the same manner as with the
Brightkite samples previously described. Distances between
nodes are computed in kilometers. Node and edge counts for
these small networks is listed in Table 2. Note that our tests
examine networks signiﬁcantly larger than those considered
in related work where communities are determined based on
geography and network topology (100 nodes in [5] and 571
nodes in [9]).
We evaluated the Louvain-D algorithm on these samples
with σ = 100, initially using the Louvain partition, and
compared the distance modularity of the resulting partition
to that of the partition returned by the standard Louvain
algorithm. With all seven samples, the Louvain-D algorithm
outperformed the standard approach. Improvement ranged
from 2.8-14.2%. The results are depicted in Figure 5.
We also studied the runtime of the Louvain-D algorithm
and compared it to the size of the samples. As per Proposi-

Application: Transnational Terrorism

In this section we use the open-source derived terrorist
network of Medina and Hepner [15] as a proxy for the (often classiﬁed) networks that will be used by this software in
practice. The networks consists of 358 geolocated individuals in a transnational terrorist organization (660 unweighted
edges). A diagram of the network is shown in Figure 7 while
the locations of the individuals are shown in Figure 8.
We ran the Louvain-D algorithm (initially using the Louvain partition) with σ = {50, 100, 150, . . . , 500} and compared the distance modularity of the resulting partition to
that returned by the standard Louvain algorithm. The LouvainD algorithm consistently outperformed the baseline approach
(Figure 9) with the percent improvement ranged from 8.2 −
9.8%. The results are consistent with the other trials, where
the distance modularity of the partition produced by the
Louvain-D partition monotonically decreases with σ, slowly
approaching the distance modularity of the baseline approach.
To better understand how a practitioner would use our approach for analysis, we considered the problem of identifying

1406

Figure 8: Geographic locations of the individuals in
the transnational terrorist dataset of [15].
Figure 6: Networks size (in nodes) vs. runtime (in
hours) for the Gowalla network samples. Note the
strong quadratic fit.

Figure 9: Comparison of distance modularity between Louvain and Louvain-D algorithms for the
transnational terrorism dataset.
to ﬁnd partitions that could nearly maximize this quantity.
An exact method for addressing this optimization problem
was introduced in [4]. However, this method was based on
integer programming and for many problem instances may
take an exponential amount of time to complete. However,
we note that an easy modiﬁcation of that program can be
used to address the problem of this paper as the quantity
Pij can be solved in a pre-processing step and treated as a
constant in the integer program formulation. Note that the
time to complete such a step would be easily dominated by
the overall runtime to even approximate a solution in such a
method. In the same paper, modularity maximization was
also shown to be NP-hard, which precludes an eﬃcient ap-

Figure 7: Network relationships in the transnational
terrorist dataset of [15].

a single, important geographically disperse community. We
can identify such a group of individuals by determining the
quality of a given community. We can derive such a measure
directly from the deﬁnition of modularity. For a given given
community c ⊆ V , we can determine the quality as follows:
1 
Mc =
wij − Pij
(1)
2|c| v ,v ∈c
i

j

We ranked all the communities for the transnational
terrorist organization (over all settings of σ we considered)
and took the top one. We show the visualization of the
network and geolocations of the individuals in Figures 1110. Note that the members of the identiﬁed community
span three continents. Identifying communities such as these
can provide intelligence analysts insight into how various
geographically-disperse terrorist cells interact with higherlevel organizations.

5. RELATED WORK

Figure 10: Geolocations of the individuals in the
top-ranked community from the transnational terrorist network.

The use of modularity maximization for community ﬁnding was ﬁrst introduced in [18] which also described how

1407

the work of [14] and [5], as their null model is based on
an empirically determined probability distribution, it will
not necessarily ensure geographically-disperse communities
- which is our target application. Further, the work of [9]
does not describe practical considerations and their experimental evaluation is restricted to the Belgian phone network
data consisting of 571 nodes.
In addition to the aforementioned approaches, community
detection in networks has also been explored in other manners that could potentially be proved applicable to geospatial applications - though to our knowledge no such application has been presented in the literature. For instance, the
work of [21] identiﬁes communities based on both network
topology and content analysis. Further, there are methods
for community detection other than modularity maximization on networks (that do not consider spatial interactions).
Leveraging one of these other approaches is an important
direction for future work. See [10] for a comprehensive survey.
There has been other recent work where geospatial networks have been explored with respect to problems other
than community ﬁnding. The work of [12] discusses linkprediction and shows that by considering geography that
results for this problem can be improved. The work of [1]
looks at identifying the location of users on Twitter using
network topology. Further, there also have been empirical
studies on social networks with a spatial component such as
[2]. Along such lines, the mobility of users in a locationbased social network is explored in [6, 8]. More domainspeciﬁc empirical studies related to this work are also prevalent in the literature. Pertinent to our application include
studies on terrorist networks [15] and criminal co-oﬀender
networks [19].

Figure 11: Visualization of the network topology of
the community shown in Figure 10.

proaches under current theoretical assumptions. In [3] the
Louvain algorithm is introduced which is shown to provide
partitions that nearly maximize modularity and can scale
to very large networks. The modiﬁcation of the Louvain
algorithm is what we leveraged in this paper.
Modularity was extended to consider geosptial relationships using a distance-decay model in [14] with the introduction of distance modularity which we use in this paper.
Their approach modiﬁes the null model to increase the expected number of edges between close nodes, it will tend
to ﬁnd communities that are more geographically disperse hence meeting the requirement of our presented application.
Our work extends on their theory - providing an algorithm to
ﬁnd an approximately optimal partitions wrt distance modularity, experimental results, and describes practical considerations - none of which were included in [14] which only
introduces the the concept of distance modularity and describes the mathematical properties of their alternative null
model.
The recent work of [5] introduces “spatial modularity”
that also uses a distance-decay function in the null model though somewhat diﬀerent to that introduced in [14]. They
study the diﬀerence among partitions created by attempting to optimize both standard modularity and their alternate deﬁnition on a series of small simulated networks whose
edges are formed based on varying degrees of correlation between space and node similarity (determined by randomly
assigned attributes). The results of that paper have also inspired this work as they indicate that by considering geospatial relationships in the null model often yields diﬀerent community structure than with the original deﬁnition of modularity introduced by [18]. However, unlike this paper, the
work of [5] only studies simulated networks (this paper only
looks at real-world networks). The networks of this paper
are an order of magnitude larger as [5] only considers networks of 100 nodes. Further, [5] does not describe any practical concerns in their approach that must be considered
when creating a real-world system.
Another important result on community ﬁnding in geosptial networks was that of [9] where the authors also modify
modularity. However, in that work, the authors use a null
model that is based on an empirically observed probability distribution of edge existence based on distance. Their
optimization approach was tested on a network of Belgian
communes of phone users and was shown to accurately identify linguistic communities. However, unlike this paper and

6. CONCLUSION
In this paper, we have presented a modiﬁed Louvain algorithm to ﬁnd partitions of networks that provide nearoptimal solutions for both nearness and distance modularity,
providing a way to leverage spatial information in addition
to network connection topology when mining networks for
communities. We have evaluated this algorithm on two realworld location-based social networks, as well as a real-world
transnational terrorism network data set. Our results have
shown that using the Louvain algorithm modiﬁed to optimize for distance modularity to be an eﬀective approach
to the problem of ﬁnding geographically disperse communities, ﬁnding near-optimal solutions to distance modularity.
Our experiments have also shown that using the Louvain
partition instead of a singleton partition in the initial partitioning step of the algorithm generally provides improved
ﬁnal partitions in terms of distance modularity. We have
demonstrated the scalability of the algorithm by considering
networks of up to more than 2000 nodes, a number that is
signiﬁcantly greater than network sizes typically considered
in the related literature. Finally, particularly through our
experiments applying the algorithm to a real-world transnational terrorism network data set, we have found the presented approach be useful for ﬁnding geographically disperse
communities at a time scale that is practical in the application domain.
Currently, examining scalability issues is an immediate
concern for future work, as we have initiated a relationship
with a major American police department to study gang vi-

1408

olence - which will require the examination of networks of
size 105 nodes. In this application domain, the identiﬁcation
of particularly localized communities as opposed to disperse
communities may be of interest as well, thus a modularity
deﬁnition optimizing for this is another potential item for
immediate future work. We are also working with various
agencies in the U.S. Department of Defense to transition
this technology to study networks of hundreds to thousands
of nodes. With this particular user-base, our focus is on
readying the technology for deployment to analysts in a usable system.

7. ACKNOWLEDGMENTS
P.S. would like to thank Richard M. Medina (GMU) for
his help with the terrorist network dataset. The authors are
supported by the Army Research Oﬃce (project 2GDATXR042)
and the Oﬃce of the Secretary of Defense. The opinions in
this paper are those of the authors and do not necessarily reﬂect the opinions of the funders, the U.S. Military Academy,
or the U.S. Army.

8. REFERENCES
[1] S. Abrol, L. Khan, and B. Thuraisingham. Tweeque:
Spatio-temporal analysis of social networks for
location mining using graph partitioning. In Proc.
2012 ASE Intl. Conf. on Social Informatics, Dec. 2012.
[2] M. Barthélemy. Spatial networks. Physics Reports,
499(1):1–101, 2011.
[3] V. Blondel, J. Guillaume, R. Lambiotte, and
E. Lefebvre. Fast unfolding of communities in large
networks. Journal of Statistical Mechanics: Theory
and Experiment, 2008:P10008, 2008.
[4] U. Brandes, D. Delling, M. Gaertler, R. Gorke,
M. Hoefer, Z. Nikoloski, and D. Wagner. On
modularity clustering. Knowledge and Data
Engineering, IEEE Transactions on, 20(2):172 –188,
feb. 2008.
[5] F. Cerina, V. D. Leo, M. Barthelemy, and A. Chessa.
Spatial correlations in attribute communities. PLoS
One, 7(5), May 2012.
[6] E. Cho, S. A. Myers, and J. Leskovec. Friendship and
mobility: user movement in location-based social
networks. In Proceedings of the 17th ACM SIGKDD
international conference on Knowledge discovery and
data mining, KDD ’11, pages 1082–1090, New York,
NY, USA, 2011. ACM.
[7] N. Du, B. Wu, X. Pei, B. Wang, and L. Xu.
Community detection in large-scale social networks. In
Proceedings of the 9th WebKDD and 1st SNA-KDD
2007 workshop on Web mining and social network
analysis, pages 16–25. ACM, 2007.

1409

[8] N. Eagle and A. Pentland. Reality mining: sensing
complex social systems. Personal and Ubiquitous
Computing, 10(4):255–268, 2006.
[9] P. Expert, T. S. Evans, V. D. Blondel, and
R. Lambiotte. Uncovering space-independent
communities in spatial networks. Proceedings of the
National Academy of Sciences, 108(19):7663–7668,
2011.
[10] S. Fortunato. Community detection in graphs. CoRR,
abs/0906.0612, 2009.
[11] M. Girvan and M. Newman. Community structure in
social and biological networks. Proceedings of the
National Academy of Sciences, 99(12):7821–7826,
2002.
[12] N. D. Larusso, B. E. Ruttenberg, and A. K. Singh. A
latent parameter node-centric model for spatial
networks. CoRR, abs/1210.4246, 2012.
[13] D. Li and Y. Du. Artificial intelligence with
uncertainty. Chapman & Hall/CRC, 2007.
[14] X. Liu, T. Murata, and K. Wakita. Extending
modularity by incorporating distance functions in the
null model. CoRR, abs/1210.4007, 2012.
[15] R. M. Medina and G. F. Hepner. Advancing the
understanding of sociospatial dependencies in terrorist
networks. T. GIS, 15(5):577–597, 2011.
[16] J. C. Nekola and P. S. White. Special Paper: The
Distance Decay of Similarity in Biogeography and
Ecology. Journal of Biogeography, 26(4):867–878, 1999.
[17] M. E. J. Newman. Fast algorithm for detecting
community structure in networks. Phys. Rev. E,
69(6):066133, Jun 2004.
[18] M. E. J. Newman and M. Girvan. Finding and
evaluating community structure in networks. Phys.
Rev. E, 69(2):026113, Feb 2004.
[19] D. R. Schaefer. Youth co-oﬀending networks: An
investigation of social and spatial eﬀects. Social
Networks, 34(1):141 – 149, 2012.
[20] H. Skov-Petersen. Estimation of distance-decay
parameters: GIS-based indicators of recreational
accessibility. In ScanGIS, pages 237–258, 2001.
[21] T. Yang, R. Jin, Y. Chi, and S. Zhu. Combining link
and content for community detection: a discriminative
approach. In Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and
data mining, KDD ’09, pages 927–936, New York, NY,
USA, 2009. ACM.

Technical Communications of the International Conference on Logic Programming, 2010 (Edinburgh), pp. 182–191
http://www.floc-conference.org/ICLP-home.html

USING GENERALIZED ANNOTATED PROGRAMS TO SOLVE SOCIAL
NETWORK OPTIMIZATION PROBLEMS
PAULO SHAKARIAN 1 AND V.S. SUBRAHMANIAN 1 AND MARIA LUISA SAPINO 2
1

Univestiy of Maryland
College Park, MD
E-mail address: {pshak,vs}@cs.umd.edu

2

Università di Torino
Torino, Italy
E-mail address: mlsapino@di.unito.it

Abstract. Reasoning about social networks (labeled, directed, weighted graphs) is becoming increasingly important and there are now models of how certain phenomena (e.g.
adoption of products/services by consumers, spread of a given disease) “diffuse” through
the network. Some of these diffusion models can be expressed via generalized annotated
programs (GAPs). In this paper, we consider the following problem: suppose we have a
given goal to achieve (e.g. maximize the expected number of adoptees of a product or
minimize the spread of a disease) and suppose we have limited resources to use in trying
to achieve the goal (e.g. give out a few free plans, provide medication to key people in the
SN) - how should these resources be used so that we optimize a given objective function
related to the goal? We define a class of social network optimization problems (SNOPs)
that supports this type of reasoning. We formalize and study the complexity of SNOPs
and show how they can be used in conjunction with existing economic and disease diffusion
models.

1. Introduction
There is a rapid proliferation of different types of graph data in the world today.
These include social network data (FaceBook, Flickr, YouTube, etc.), cell phone network
data [NE08] collected by virtually all cell phone vendors, email network data (such as
those derived from the Enron corpus or Gmail logs), as well as information on disease networks [FC08, And79]. In addition, the World Wide Consortium’s RDF standard is also a
graph-based standard for encoding semantic information contained in web pages. There
has been years of work on analyzing how various properties of nodes in such networks “diffuse” through the network - different techniques have been invented in different academic
disciplines including economics [Jac05, Sch78], infectious diseases [FC08], sociology [Gra78]
and computer science [Kem03].
1998 ACM Subject Classification: I.2.4 Knowledge Representation Formalisms and Methods.
Key words and phrases: annotated logic programming, optimization queries, social networks.
Some of the authors of this paper were funded in part by AFOSR grant FA95500610405, ARO grant
W911NF0910206 and ONR grant N000140910685.

c P. Shakarian, V.S. Subrahmanian, and M.L. Sapino

CC

Creative Commons Non-Commercial No Derivatives License

Technical Communications of the 26th International Conference on Logic Programming, Edinburgh, July, 2010
Editors: Manuel Hermenegildo, Torsten Schaub
LIPIcs - Leibniz International Proceedings in Informatics. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, Germany
Digital Object Identifier: 10.4230/LIPIcs.ICLP.2010.182

USING GAPS TO SOLVE SOCIAL NETWORK OPTIMIZATION PROBLEMS

183

Many of these methods focus on modeling a specific type of diffusion in an SN and
often, they only rely on the network topology [Wat99, Cow04, Ryc08], rather than on
properties of vertices, and the nature of the relationships between vertices. In this paper,
we first argue that Generalized Annotated Programs (GAPs) [Kif92b, Kif92a, Thi93] and
their variants [Ven04, Kra04, Lu96, Lu93, Dam99] form a convenient method to express
many diffusion models. Next, unlike most existing work in social networks which focus on
learning diffusion models, we focus on reasoning with previously learned diffusion models
(expressed via GAPs). In particular, if we wish to achieve certain goals based on a social
network, how best can we achieve these goals? Two examples are given below.
• (Q1) Cell phone plans. A cell phone company is promoting a new cell phone
plan - as a promotion, it is giving away k free plans to existing customers. Which k
people should they pick so as to maximize the (expected) number of plan adoptees
predicted by a cell phone plan adoption diffusion model they have learned from their
past promotions?
• (Q2) Medication distribution plan. A government combating a disease spread
by physical contact has limited stocks of free medication to give away. Based on
a diffusion model of how the disease spreads (e.g. kids might be more susceptible
than adults, those previously inoculated against the disease are safe, etc.), they want
to find the k people who maximally spread the disease (so that they can provide
immediate treatment to these k people in an attempt to halt the disease’s spread).
Both the above problems are instances of a class of queries that we call SNOP queries.
They differ from queries studied in the past in quantitative (both probabilistic and annotated) logic programming in two fundamental ways: (i) They are specialized to operate on
graph data, (ii) They optimize complex kinds of objective functions. Neither of these has
been studied before by any kind of quantitative logic programming framework, though work
on optimizing objective functions in the context of different types of semantics (minimal
model and stable model semantics) has been studied before[Leo04]. And of course, constraint logic programming[Apt03] has also extensively studied optimization issues as well in
logic programming - however, here, optimization and constraint solving is embedded in the
constraint logic program, whereas in our case, they are part of the query over an annotated
logic program.
This paper is organized as follows. In Section 2, we provide an overview of GAPs (past
work), define a social network, and explain how GAPs can represent some types of diffusion
in SNs. Section 3 formally defines different types of social network optimization problems
and provides results on their computational complexity. Finally, section 4 shows how our
framework can represent several existing diffusion models for social networks including one
each from economics, epidemiology, and computer science.

2. Technical Preliminaries
In this section, we first formalize social networks, then briefly overview generalized
annotated logic programs (GAPs)[Kif92b] and then describe how GAPs can be used to
represent concepts related to diffusion in SNs. Throughout this paper, we assume the
existence of two arbitrary but fixed disjoint sets VP, EP of vertex and edge predicate symbols
respectively. Each vertex predicate symbol has arity 1 and each edge predicate symbol has
arity 2.

184

P. SHAKARIAN, V.S. SUBRAHMANIAN, AND M.L. SAPINO

Definition 2.1. A social network (S) is a 5-tuple (V, E, `vert , `edge , w) where:
(1) V is a set whose elements are called vertices.
(2) E ⊆ V × V is a multi-set whose elements are called edges.
(3) `vert : V → 2VP is a function, called vertex labeling function.
(4) `edge : E → EP is a function, called edge labeling function. 1
(5) w : E × EP → [0, 1] is a function, called weight function.
We now present a brief example of an SN that will be used throughout this paper.
Example 2.2. Let us return to the cell phone example (query (Q1)). Figure 1 shows
a toy SN the cell phone company might use. Here, we might have VP = {male, f emale,
adopters, temp adopter, non adptr} denoting the sex and past adoption behavior of each
vertex; EP might be the set {phone, email, IM } denoting the types of interactions between
vertices. w(v1 , v2 , ep) denotes the percentage of communications of type ep ∈ EP initiated
by v1 that were with v2 (measured either w.r.t. time or bytes). The function `vert is shown
in the figure by the shape (denoting past adoption status) and shading (male/female). The
type of edges (bold for phone, dashed for email, dotted for IM) is used to illustrate `edge .
It is important to note that our definition of social networks is much broader than
that used by several researchers[And79, FC08,
Jac05, Kem03] who often do not consider either `edge or `vert — these can have a significant impact on what we do with such networks.
Note. We note that each social network must
satisfy various integrity constraints. In Example 2.2, it is clear that `vert (V ) should include at most one of male, f emale and at most
one of adopters, temp adopter,non adptr. We
assume the existence of some integrity constraints to ensure this kind of semantic integrity – they can be written in any reasonable syntax to express ICs – in the rest of this
Figure 1: Example cellular network.
paper, we assume that social networks have
associated ICs and that they satisfy them. In
our example, we will assume ICs ensuring that a vertex can be marked with at most one of
male/f emale and at most one of adopters, temp adopter, non adptr.
We now recapitulate the definition of generalized annotated logic programs from [Kif92b].
We assume the existence of a set AVar of variable symbols ranging over the unit real interval
[0, 1] and a set F of function symbols each of which has an associated arity. We start by
defining annotations.
Definition 2.3 (annotation term). (i) Any member of [0, 1] ∪ AVar is an annotation.
(ii) If f is an n-ary function symbol over [0, 1] and t1 , . . . , tn are annotations, then so is
f (t1 , . . . , tn ).
We define a separate logical language whose constants are members of V and whose
predicate symbols consist of VP ∪ EP. We also assume the existence of a set V of variable
1Each edge e ∈ E is labeled by exactly one predicate symbol from EP. However, there can be multiple
edges between two vertices labeled with different predicate symbols.

USING GAPS TO SOLVE SOCIAL NETWORK OPTIMIZATION PROBLEMS

185

symbols ranging over the constants (vertices). No function symbols are present. Terms and
atoms are defined in the usual way (cf. [Llo87]). If A = p(t1 , . . . , tn ) is an atom and p ∈ VP
(resp. p ∈ EP), then A is called a vertex (resp. edge) atom.
Definition 2.4 (annotated atom/GAP-rule/GAP). If A is an atom and µ is an annotation,
then A : µ is an annotated atom. If A0 : µ0 , A1 : µ1 , . . . , An : µn are annotated atoms, then
A0 : µ 0 ← A1 : µ 1 ∧ . . . ∧ An : µ n
is called a GAP rule. When n = 0, the above GAP-rule is called a fact. A generalized
annotated program Π is a finite set of GAP rules.
Every social network SN = (V, E, `vert , `edge , w) can be represented by the GAP ΠSN =
{q(v) : 1 ← | v ∈ V ∧ q ∈ `vert (v)} ∪ {ep(V1 , V2 ) : w(V1 , V2 , ep) ← | (V1 , V2 ) ∈ E ∧
`edge (V1 , V2 ) = ep}.
Definition 2.5 (embedded social network). A social network SN is said to be embedded
in a GAP Π iff ΠSN ⊆ Π.
We see immediately from the definition of ΠSN that all social networks can be represented as GAPs. When we augment ΠSN with other rules — such as rules describing how
certain properties diffuse through the social network, we get a GAP Π ⊇ ΠSN that captures
both the structure of the SN and the diffusion principles. Here is a small example of such
a GAP.
Example 2.6. The GAP Πcell might consist of ΠSN using the social network of Figure 1
plus the GAP-rules:
(1) will adopt(V ) : 0.8 × X + 0.2 ← adopter(V ) : 1 ∧ male(V ) : 1 ∧
IM (V, V 0 ) : 0.3 ∧ f emale(V 0 ) ∧ will adopt(V 0 ) : X.
(2) will adopt(V ) : 0.9 × X + 0.1 ← adopter(V ) : 1 ∧ male(V ) : 1 ∧
IM (V, V 0 ) : 0.3 ∧ male(V 0 ) ∧ will adopt(V 0 ) : X.
(3) will adopt(V ) : 1 ← temp adopter(V ) : 1 ∧ male(V ) : 1 ∧ email(V 0 , V ) : 1 ∧ f emale(V 0 ) :
1 ∧ will adopt(V 0 ) : 1.

Rule ( 1) says that if V is a male adopter and V 0 is female and the weight of V ’s instant
messages to V 0 is 0.3 or more, and we previously thought that V would be an adopter with
confidence X, then we can infer that V will adopt the new plan with confidence 0.8×X +0.2.
The other rules may be similarly read.
GAPs have a formal semantics that can be immediately used. An interpretation I is
any mapping from the set of all grounds atoms to [0, 1]. The set I of all interpretations can
be partially ordered via the ordering: I1  I2 iff for all ground atoms A, I1 (A) ≤ I2 (A). I
forms a complete lattice under the  ordering.
Definition 2.7 (satisfaction/entailment). An interpretation I satisfies a ground annotated
atom A : µ, denoted I |= A : µ, iff I(A) ≥ µ. I satisfies the ground GAP-rule AA0 ←
AA1 ∧ . . . ∧ AAn (denoted I |= AA0 ← AA1 ∧ . . . ∧ AAn ) iff either (i) I satisfies AA0
or (ii) there exists an 1 ≤ i ≤ n such that I does not satisfy AAi . I satisfies a non-ground
atom (rule) iff I satisfies all ground instances of it. GAP Π entails AA, denoted Π |= AA,
iff every interpretation I that satisfies all rules in Π also satisfies AA.
As shown by [Kif92b], we can associate a fixpoint operator with any GAP Π that maps
interpretations to interpretations.

186

P. SHAKARIAN, V.S. SUBRAHMANIAN, AND M.L. SAPINO

Definition 2.8. Suppose Π is any GAP and I an interpretation. The mapping TΠ that
maps interpretations to interpretations is defined as TΠ (I)(A) = sup{µ | A : µ ← AA1 ∧
. . . ∧ AAn is a ground instance of a rule in Π and for all 1 ≤ i ≤ n, I |= AAi }.
[Kif92b] show that TΠ is monotonic and has a least fixpoint lf p(TΠ ). Moreover, they
show that Π entails A : µ iff µ ≤ lf p(TΠ )(A) and hence lf p(TΠ ) precisely captures the
ground atomic logical consequences of Π.
Thus, we see that any social network S can be represented as a GAP ΠS . We will
show (in Section 4) that many existing diffusion models of ΠS can be expressed as a GAP
Π ⊇ ΠS by adding some GAP-rules describing the diffusion process to ΠS .

3. Social Network Optimization (SNOP) Queries
In this section, we develop a formal syntax and semantics for optimization in social
networks, taking advantage of the above embedding of SNs into GAPs. We see from queries
(Q1),(Q2) that a SNOP-query looks for a set V0 of vertices and has the following components: (i) an aggregate operator, (ii) an integer k ≥ 0, (iii) a set of conditions that each
vertex in V0 must satisfy, and (iv) a goal atom g(V ) where g is a vertex predicate and V is
a variable.
Aggregates. It is clear that in order to express queries like (Q1),(Q2), we need aggregate
operators which are mappings agg : FM([0, 1]) → R (R is the set of reals) where FM(X)
denotes the set of all finite multisets that are subsets of X. Relational DB aggregates like
SUM,COUNT,AVG,MIN,MAX are all aggregate operators which can take a finite multiset of
reals as input and return a single real.
Aggregates may be monotonic or not. We first define a partial ordering v on multi-sets
of numbers as follows. X1 v X2 iff there exists an injective mapping β : X1 → X2 such
that (∀x1 ∈ X1 )x1 ≤ β(x1 ). The aggregate agg is monotonic (resp. anti-monotonic) iff
whenever X1 v X2 , it is the case that agg(X1 ) ≤ agg(X2 ) (resp. agg(X2 ) ≤ agg(X1 )).
Vertex condition. A vertex condition is a conjunction V C of annotated vertex atoms
containing at most one variable.
Thus, in our example, male(V ) : 1 ∧ adopter(V ) : 1 is a conjunctive vertex condition,
but male(V ) : 1 ∧ email(V, V 0 ) : 1 is not. We are now ready to define a SNOP-query.
Definition 3.1 (SNOP-query). A SNOP-query is a 4-tuple (agg, V C, k, g(V )) where agg
is an aggregate, V C is a vertex condition, k ≥ 0 is an integer, and g(V ) is a goal atom.
If we return to our cell phone example, we can set agg = SUM, k = 3 (for example),
V C = true and the goal to be adopter(V ). Here, the goal is to find a set X of annotated
ground atoms of the form adopter(v) : µ such that X’s cardinality is 3 or less and such that
SUM{µ | adopter(v) : µ ∈ X} is maximized. Here, the SUM is applied to a multiset rather
than a set.
Definition 3.2 (pre-answer/value). Suppose an SN S = (V, E, `vert , `edge , w) is embedded
in a GAP Π. A pre-answer to the SNOP query Q = (agg, V C, k, g(V )) w.r.t. Π is any
set V0 ⊆ V such that: (i) |V0 | ≤ k, (ii) for all vertices v 0 ∈ V0 , lf p(T{Π ∪ {g(v0 ):1← | v0 ∈V0 } ) |=
V C[V /v 0 ]. We use pre ans(Q) to denote the set of all pre-answers to query Q.
The value, value(V0 ), of a pre-answer V0 is agg({lf p(TΠ ∪ {g(v0 ):1← | v0 ∈V0 } )(g(V )) | V ∈
V}) — here, the aggregate is applied to a multi-set rather than a set. We also note that we

USING GAPS TO SOLVE SOCIAL NETWORK OPTIMIZATION PROBLEMS

187

can define value as a mapping from interpretations to reals based on a SNOP query. We
say value(I) = agg({I(g(v)) | v ∈ V}).
If we return to our cell phone example, V0 is the set of vertices to which the company
is considering giving free plans. The value of this set (value(V0 )) is computed as follows.
Find the least fixpoint of TΠ0 where Π0 is Π expanded with annotated atoms of the form
adopter(V 0 ) : 1 for each vertex V 0 ∈ V0 . For each vertex V ∈ V (the entire set of vertices,
not just V0 now), we now find the confidence assigned by the least fixpoint. Summing up
these confidences gives us a measure of the expected number of plan adoptees.
Definition 3.3 (answer). Suppose an SN S = (V, E, `vert , `edge , w) is embedded in a GAP
Π and Q = (agg, V C, k, g(V )) is a SNOP-query. A pre-answer V0 is an answer to the SNOPquery Q iff the SNOP-query has no other pre-answer V00 such that value(V00 ) > value(V0 ).2
The answer set, ans(Q), to the SNOP-query Q = (agg, V C, k, g(V )) w.r.t. Π is the set
of all answers to Q.
Example 3.4. Consider the GAP Πcell with the social network from Figure 1 embedded and the SNOP-query Qcell = (SU M, true, 3, will adopt). The sets V01 = {v15 , v19 , v6 }
and V02 = {v15 , v18 , v6 } are both pre-answers. In the case of V01 , two applications of
the TΠ operator yield a fixpoint where the vertex atoms formed with will adopt in set
{v15 , v19 , v6 , v12 , v18 , v7 , v10 } are annotated with 1. For V2 , only one application of TΠ is
required to reach a fixpoint, and the corresponding set of vertices (where the vertex atom
formed with will adopt is annotated with 1) is {v15 , v6 , v12 , v18 , v7 , v10 }. As these are the
only vertex atoms formed with will adopt that have a non-zero annotation after reaching
the fixed point, we know that value(V01 ) = 7 and value(V02 ) = 6. As value(V01 ) > value(V02 ),
it is easy to see that V01 is an answer to this SNOP-query.
Theorem 3.5. Answering SNOP-queries is NP-Hard.3
Under some reasonable conditions, the problem of answering SNOP-queries is also in
NP.
Theorem 3.6. If both the aggregate function agg and the functions in F are polynomially
computable, then the problem of finding an answer to a SNOP-query is in NP4.
Most common aggregate functions like SUM, AVERAGE, Weighted average, MIN,
MAX, COUNT are all polynomially computable. Moreover, the assumption that the functions in F are polynomially computable is also reasonable. The counting problem version
of SNOP-query answering seeks to find the number of answers to a SNOP query. Unfortunately, this problem is #P -complete under the same assumptions.
2Throughout this paper, we only treat maximization problems - minimizing an objective function f is

the same as maximizing −f .
3Proof Sketch: Due to space constraints, we only explain the hardness result by reducing SET COVER
to the problem of answering SNOP queries. Given a SET COVER problem instance consisting of a set S, a
family H = {H1 , . . . , Hmax } of subsets of S, and a positive integer K, we can reduce this problem instance
to a SNOP query by polynomially constructing a graph whose vertices correspond to the members of S and
to the Hi ’s - there is an edge from an s ∈ S to Hi iff s ∈ Hi . All edges have a weight of 1. Every vertex
v ∈ S has an associated propositional symbol marked set to “true.” There is only one label and all edges
are labeled with it and there are no integrity constraints. We have a GAP consisting of one rule marked(v) :
1 ← marked(v 0 ) : 1 ∧ (v 0 , v, label) : 1. If we now consider the SNOP-query (SU M, true, K, marked(v)), we
see that solutions to the SNOP-query (which cause certain Hi ’s to get marked) correspond precisely to a
solution of the SET COVER problem.
4By abuse of notation, we refer to the obvious decision problem associated with answering SNOP-queries.

188

P. SHAKARIAN, V.S. SUBRAHMANIAN, AND M.L. SAPINO

Theorem 3.7. The counting version of the SNOP query answering problem is #P-complete.
Although the counting version of the query is #P -hard, finding the union of all answers
to a SNOP query is no harder than a SNOP query. We shall refer to this problem as SNOPALL - and it reduces both to and from a regular SNOP query5.

4. Applying SNOPs to Real Diffusion Problems
In this section, we briefly show how SNOPs may be used to solve two diffusion problems
- one each in economics and disease spread.
The Jackson-Yariv Diffusion Model [Jac05]. In this framework, a set of agents is
associated with each vertex in an undirected graph G0 = (V0 , E0 ). Each agent has a default
behavior (A) and a new behavior (B). Suppose di denotes the degree of a vertex vi . [Jac05]
use a function g : {0, . . . , |V| − 1} → [0, 1] to describe how the number of neighbors of v
affects the benefits to v for adopting behavior B. For instance, g(3) specifies the benefits
(in adopting behavior B) that accrue to an arbitrary vertex v ∈ V0 that has three neighbors.
Let πi denote the fraction of neighbors of vi that have adopted behavior B; Let constants
bi and ci be the benefit and cost for vertex vi to adopt behavior B, respectively. [Jac05]
state that node vi switches to behavior B iff cbii · g(di ) · πi ≥ 1.
Returning to our cell-phone example, one could potentially use this model to describe
the spread of the new plan. In this case, behavior B would be the use of the new plan. The
associated SNOP-query would ask to simply find the nodes given a free plan that would
maximize use of the plan in the network. Cost and benefit could be computed from factors
such as income, time invested in switching plans, etc.
Given a Jackson-Yariv model consisting of G0 = (V0 , E0 ) and g, we can set up an SN
(V0 , E00 , `vert , `edge , w) as follows. We define E00 = {(x, y), (y, x) | (x, y) ∈ E0 }. We have a
single edge predicate symbol edge and `edge assigns 1 to all edges in E00 . Our associated
GAP ΠJY now consists of ΠSN plus the single rule:
P
X
^
bi
j Xj
B(Vi ) : b · g(
Ej ) · P
c←
(edge(Vj , Vi ) : Ej ∧ B(Vj ) : Xj )
ci
j Ej
00
j

Vj |(Vj ,Vi )∈E

It is easy to see that this rule (when applied in conjunction with ΠSN for a social
network SN ) precisely encodes the Jackson-Yariv semantics.
The Kempe-Kleinberg-Tardos
Framework.[Kem03] If we take the above construction,
P
and for each vi replace the

Xj
j Ej

Pj

in the head with a monotone threshold function, fi , we have

embedded the general framework of [Kem03], of which the [Jac05] model is a special case.
It is important to note that the framework of [Kem03] captures a wide variety of diffusion
models seen in social sciences and interacting particle systems. These include the “linear
threshold model” - which is based on models in social science made popular by [Sch78] and
[Gra78] and the “independent cascade model,” introduced in [JG01]. However, this work
provides a further generalization, as we allow for multiple properties to be “activated” on
the vertices, permit labeled edges signifying different relationships, and provide a rule-based
5Our proofs of this statement rely on two constructions. First, a regular SNOP query, where the answer

must be of size k, can be solved with k successive SNOP-ALL queries. Likewise, a SNOP-ALL query can be
answered by solving |V| SNOP queries. Details are omitted due to lack of space.

USING GAPS TO SOLVE SOCIAL NETWORK OPTIMIZATION PROBLEMS

189

framework which can allow for learned diffusion models. Additionally, [Kem03] does not
solve SNOP queries with complex aggregates.
The SIR Model of Disease Spread. The SIR (susceptible, infectious, removed ) model
of disease spread [And79] is a classic disease model which labels each vertex in a graph
G = (V, E) (of humans) with susceptible if it has not had the disease but can receive it from
one of its neighbors, infectious if it has caught the disease and trec units of time have not
expired, and removed where the vertex can no longer catch or transmit the disease. The
SIR model assumes that a vertex v that is infected can transmit the disease to any of its
neighbors v 0 with a probability pv,v0 for trec units of time. We would like to “find k vertices
that would maximize the expected number of vertices that become infected”. These are
obviously good candidates to treat with appropriate medications.
Let S = (V, E, `vert , `edge , w) be an SN where each edge is labeled with the predicate
symbol e and w(v, v 0 , e) = pv,v0 . We use the predicate inf to designate the initially infected
vertices. In order to create a GAP ΠSIR capturing the SIR model of disease spread, we
first define trec predicate symbols rec1 , . . . , rectrec where reci (v) intuitively means that node
v was infected i days ago. Hence, rectrec (v) means that v is “removed.” We embed S into
GAP ΠSIR by adding the following diffusion rules. If trec > 1, we add a non-ground rule
for each i = {2, . . . , trec } - starting with trec :

inf(V ) : (1 − R) · PV 0 ,V

reci (V ) : R ← reci−1 (V ) : R
rec1 (V ) : R ← inf(V ) : R
· (PV 0 − R0 ) ← rectrec (V ) : R ∧ e(V 0 , V ) : PV 0 ,V ∧
inf(V 0 ) : PV 0 ∧ rectrec (V 0 ) : R0 .

The first rule says that if a vertex is in its (i − 1)’th day of recovery with certainty R in
the j’th iteration of the TΠSIR operator, then the vertex is i days into recovery (with the
same certainty) in the j + 1’th iteration of the operator. Likewise, second rule intuitively
encodes the fact that if a vertex became infected with certainty R in the j’th iteration of
the TΠSIR operator, then the vertex is one day into recovery in the j + 1’th iteration of the
operator with the same certainty. The last rule says that if a vertex V 0 has been infected
with probability PV 0 and there is an edge from V 0 to V in the social network (weighted with
probability PV 0 ,V ), and the vertex V 0 has recovered with certainty R0 , given the probability
1−R that V is not already recovered, (and hence, cannot be re-infected)6, then the certainty
that the vertex V gets infected is (1 − R) · PV 0 ,V · (PV 0 − R0 ). Here, PV 0 − R0 is one way
of measuring the certainty that V 0 has recovered (difference of the probability that it was
infected and the probability it has recovered) and PV 0 ,V is the probability of infecting the
neighbor.
To see how this GAP works, we execute a few iterations of the TΠSIR operator and show
the fixpoint that it reaches on a toy sample graph shown in Figure 2. In this graph, the
initial infected vertices are those shown in a shaded circle. The transmission probabilities
weight the edges in the graph.
6Note that the SIS (Susceptible-Infectious-Susceptible) model [Het76], where an individual becomes susceptible to disease after recovering (as opposed to SIR, where an individual acquires immunity) can be easily
represented by a modification to the described construction. Simply change the annotation function in the
head of the third rule to PV 0 ,V · (PV 0 − R0 ). In this way, we do not consider the probability that vertex V
is immune.

190

P. SHAKARIAN, V.S. SUBRAHMANIAN, AND M.L. SAPINO

The SNOP-query is (SU M, true, k, inf ) 0.1
c
i
1 inf(a):1, inf(c):1, inf(d):1
to count the number of infected
2 rec1(a):1, rec1(c):1, rec1(d):1, inf(b):0.2, inf(d):0.3,
0.2
vertices in the least fixpoint of
inf(f):0.3, inf(g):0.05, inf(i):0.1
a 0.2 b
d
3 rec2(a):1, rec2(c):1, rec2(d):1, rec1(b):0.2,
TΠ . This query says “find the
0.3
0.4
0.3
rec1(d):0.3, rec1(f):0.3, rec1(g):0.05, rec1(i):0.1
k vertices in the social network
inf(g):0.08
f
h
g
0.1
0.05
which, if infected, would cause
4 rec2(b):0.2, rec2(d):0.3, rec2(f):0.3, rec2(g):0.05,
vertices are infected.
rec2(i):0.1, rec1(g):0.08
the maximal number of ver- Shaded
Edges are bi-directional,
5 rec2(g):0.08
trec =2
tices to become infected in the
future.” However, the above
set of rules can be easily used
Figure 2: Left: Sample network for disease spread. Right:
to express other things. For inannotated atoms entailed after each applicastance, an epidemiologist may
tion of TΠSIR (maximum, non-zero annotations
not be satisfied with only one
only).
set of k vertices that can cause
the disease to spread to the
maximum extent - as there may be another, disjoint set of k vertices that could cause
the same effect. Note that a single set of vertices may still be sufficient for other applications, such as viral marketing. The epidemiologist may want to find all members of the
population, that if in a group of size k could spread the disease to a maximum extent. This
can be answered using a SNOP-ALL query, described in Section 3.

5. Conclusion
In this paper, we described how General Annotated Logic Programs can be used to
represent a variety of diffusion models in social networks. Based on this formulation, we
presented the social network optimization problem (SNOP) - which queries the GAP for
a set of nodes that cause a given phenomenon to spread through the social network to a
maximum extent - shown here to be NP-Complete. We also showed how several well-known
diffusion models can be represented in our framework. In future work, we intend to explore
heuristic approaches for large sub-classes of SNOPs to answer queries on real-world datasets.

6. Acknowledgments
Some of the authors of this paper were funded in part by AFOSR grant FA95500610405,
ARO grant W911NF0910206 and ONR grant N000140910685.

References
[And79] Roy M. Anderson and Robert M. May. Population biology of infectious diseases: Part i. Nature,
280(5721):361, 1979.
[Apt03] K. Apt. Principles of constraint programming. Cambridge University Press, 2003.
[Cow04] Robin Cowan and Nicolas Jonard. Network structure and the diffusion of knowledge. Journal of
Economic Dynamics and Control, 28(8):1557 – 1575, 2004. doi:DOI:10.1016/j.jedc.2003.04.002.
URL
http://www.sciencedirect.com/science/article/B6V85-4B3K2R3-2/2/
16e1c8fae6818c11bb45325c9b3ea4a1
[Dam99] C. Damasio, L. Pereira, and T. Swift. Coherent well-founded annotated logic programs. In Proc.
Intl. Conf. on Logic Programming and Non-Monotonic Reasoning, pp. 262–276. Springer Lecture
Notes in Computer Science Vol. 1730, 1999.

USING GAPS TO SOLVE SOCIAL NETWORK OPTIMIZATION PROBLEMS

[FC08]
[Gra78]

[Het76]

[Jac05]
[JG01]
[Kem03]

[Kif92a]
[Kif92b]
[Kra04]

[Leo04]

[Llo87]
[Lu93]

[Lu96]
[NE08]
[Ryc08]

[Sch78]
[Thi93]
[Ven04]

[Wat99]

191

H. Cruz F.C. Coelho, C. Codeco. Epigrass: A tool to study disease spread in complex networks.
Source Code for Biology and Medicin, 3(3), 2008.
Mark Granovetter. Threshold models of collective behavior. The American Journal of Sociology,
83(6):1420–1443, 1978. doi:10.2307/2778111.
URL http://dx.doi.org/10.2307/2778111
Herbert W. Hethcote. Qualitative analyses of communicable disease models. Mathematical
Biosciences, 28(3-4):335 – 356, 1976. doi:DOI:10.1016/0025-5564(76)90132-2.
URL
http://www.sciencedirect.com/science/article/B6VHX-4771JSV-9/2/
701b5ad988380270c29b4ab5dcd67bbe
M. Jackson and L. Yariv. Diffusion on social networks. In Economie Publique, vol. 16, pp. 69–82.
2005.
E. Muller J. Goldenberg, B. Libai. Talk of the network: A complex systems look at the underlying
process of word-of-mouth. Marketing Letters, 12(3):211, 2001.
David Kempe, Jon Kleinberg, and Éva Tardos. Maximizing the spread of influence through a
social network. In KDD ’03: Proceedings of the ninth ACM SIGKDD international conference
on Knowledge discovery and data mining, pp. 137–146. ACM, New York, NY, USA, 2003. doi:
http://doi.acm.org/10.1145/956750.956769.
M. Kifer and E. L. Lozinskii. A logic for reasoning with inconsistency. J. Autom. Reasoning,
9(2):179–215, 1992.
Michael Kifer and V.S. Subrahmanian. Theory of generalized annotated logic programming and
its applications. J. Log. Program., 12(3&4):335–367, 1992.
Stanislav Krajci, Rastislav Lencses, and Peter Vojts. A comparison of fuzzy and annotated logic
programming. Fuzzy Sets and Systems, 144(1):173 – 192, 2004. doi:DOI:10.1016/j.fss.2003.10.019.
URL
http://www.sciencedirect.com/science/article/B6V05-49YH3XJ-2/2/
1a631467fa197cb0a6f6ae93c1db1a59
Nicola Leone, Francesco Scarcello, and V.S. Subrahmanian. Optimal models of disjunctive logic programs: Semantics, complexity, and computation. IEEE Transactions on Knowledge and Data Engineering, 16:487–503, 2004. doi:http://doi.ieeecomputersociety.org/10.1109/TKDE.2004.1269672.
John W. Lloyd. Foundations of logic programming. Springer-Verlag New York, Inc., 1987.
J.J. Lu, N.V. Murray, and E. Rosenthal. Signed formulas and annotated logics. In Multiple-Valued
Logic, 1993., Proceedings of The Twenty-Third International Symposium on, pp. 48–53. 1993. doi:
10.1109/ISMVL.1993.289582.
J. Lu. Logic programs with signs and annotations. Journal of Logic and Computation, 6(6):755–778,
1996.
A. Pentland N. Eagle and D. Lazer. Mobile phone data for inferring social network structure. In
Proc. 2008 Intl. Conference on Social and Behavioral Computing, pp. 79–88. Springer Verlag, 2008.
Jan Rychtář and Brian Stadler. Evolutionary dynamics on small-world networks. International
Journal of Computational and Mathematical Sciences, 2(1), 2008.
URL www.waset.org
Thomas C. Schelling. Micromotives and Macrobehavior. W.W. Norton and Co., 1978.
K. Thirunarayan and M. Kifer. A theory of nonmonotonic inheritance based on annotated logic.
Artificial Intelligence, 60(1):23–50, 1993.
J. Venneksn, S. Verbaeten, and M. Bruynooghe. Logic programs with annotated disjunctions. In
Proc. Intl. Conf. on Logic Programming, pp. 431–445. Springer Lecture Notes in Computer Science
Vol. 3132, 2004.
Duncan J. Watts. Networks, dynamics, and the small-world phenomenon. The American Journal
of Sociology, 105(2):493–527, 1999.
URL http://www.jstor.org/stable/2991086

This work is licensed under the Creative Commons Attribution Non-Commercial No Derivatives License. To view a copy of this license, visit http://creativecommons.org/licenses/
by-nc-nd/3.0/.

Malware Task Identification: A Data Driven
Approach
Eric Nunes, Casey Buto, Paulo Shakarian

arXiv:1507.01930v1 [cs.CR] 7 Jul 2015

School of Computing, Informatics and
Decision Systems Engineering
Arizona State University
Tempe, AZ 85281, USA
Email: {enunes1, cbuto, shak} @asu.edu

Christian Lebiere,
Stefano Bennati,
Robert Thomson
Carnegie Mellon University
Pittsburgh, PA 15218
Email: {cl@cmu.edu ,
{sbennati, thomsonr} @andrew.cmu.edu}

Abstract—Identifying the tasks a given piece of malware was
designed to perform (e.g. logging keystrokes, recording video,
establishing remote access, etc.) is a difficult and time-consuming
operation that is largely human-driven in practice. In this paper,
we present an automated method to identify malware tasks.
Using two different malware collections, we explore various
circumstances for each - including cases where the training
data differs significantly from test; where the malware being
evaluated employs packing to thwart analytical techniques; and
conditions with sparse training data. We find that this approach
consistently out-performs the current state-of-the art software for
malware task identification as well as standard machine learning
approaches - often achieving an unbiased F1 score of over 0.9.
In the near future, we look to deploy our approach for use by
analysts in an operational cyber-security environment.

I.

Earlier work has sought to classify malware by similar
“families” which has been explored as a supervised classification problem [2], [15], [16]. However, differences over “ground
truth” for malware families (e.g. Symantec and MacAfee
cluster malware into families differently) and the tendency
for automated approaches to primarily succeed at “easy to
classify” samples [19], [23] are two primary drawbacks of
malware family classification. More recently, there has been
work on directly inferring the tasks a malware was designed to
perform [12]. This approach leverages static malware analysis
(i.e. analysis of the malware sample conducted without execution, such as decompilation) and a comparison with a crowdsource database of code snippets using a proprietary machine
U.S. Provisional Patent 62/182,006. Contact shak@asu.edu for licensing
information.

Sentar Inc.
Huntsville, AL 35805
Email: holger.jaenisch@sentar.com

leaning approach. However, a key shortcoming of the static
method is that it is of limited value when the malware authors
encrypt part of their code – as we saw with the infamous Gauss
malware [14]. This work builds upon recent developments in
the application of cognitive models to intelligence analysis
tasks [18] and our own preliminary studies on applying cognitive models to identify the tasks a piece of malware was
designed to perform [17], [27]. Specifically, the contributions
of this paper include,
•

I NTRODUCTION

Identifying the tasks a given piece of malware was designed
to perform (e.g. logging keystrokes, recording video, establishing remote access, etc.) is a difficult and time consuming task
that is largely human-driven in practice [24]. The complexity
of this task increases substantially when you consider that
malware is constantly evolving, and that how each malware
instance is classified may be different based on each cybersecurity expert’s own particular background. However, automated solutions are highly attractive for this problem as it can
significantly reduce the time it takes to conduct remediation
in the aftermath of a cyber-attack.

Holger Jaenisch

•

•

•

Experimental results illustrating consistent and significant performance improvements (in terms of precision, recall, and F1) of the instance-based cognitive
model approach when compared with various standard
machine learning approaches (including SVM, logistic regression and random forests) for two different
sandboxes and for two different datasets.
Experimental results showing a consistent and significant performance improvement of the instance-based
cognitive model and several other machine learning
approaches when compared to the current state-of-theart commercial technology (which is based on static
analysis).
Experiments where we study cases where the malware
samples are mutated, encrypted, and use different
carriers - providing key insights into how our approach
will cope with operational difficulties.
Experimental results illustrating that a cognitivelyinspired intermediate step of inferring malware families provides improved performance in the machine
learning and rule-based cognitive model (though no
significant change to the instance-based cognitive
model).

This paper is organized as follows. In Section II we state
the technical preliminaries used in the paper. In Section III
we introduce our cognitive-based approaches, describing the
algorithms and explaining our selection of parameter settings.
This is followed by a description of the baseline approaches
that we studied in our evaluation in Section IV-A and a
description of the two different dynamic malware sandbox
environments we used in Section IV-B. In Section V we present
our suite of experimental results which include experiments
involving samples discovered by Mandiant, Inc. in their APT1
report [21] and samples created using the GVDG [11] tool. Fi-

nally, related work and conclusion are discussed in Section VI
and Section VII respectively.
II.

T ECHNICAL P RELIMINARIES

Throughout this paper, we shall assume that we have a set
of malware samples that comprise a historical corpus (which
we shall denote M) and each sample i ∈ M is associated with
a set of tasks (denoted tasks(i)) and a set of attributes (denoted
attribs(i)). Attributes are essentially binary features associated
with a piece of malware that we can observe using dynamic
and/or static analysis while the tasks - which tell us the higherlevel purpose of the malware - must be determined by a human
reviewing the results of such analysis. As M comprises our
historical knowledge, we assume that for each i ∈ M both
tasks(i) and attribs(i) are known. For a new piece of malware,
we assume that we only know the attributes. We also note that
throughout the paper, we will use the notation | · | to denote
the size of a given set. Tables 1 and 2 provide an example of
the attributes and tasks based on the malware samples from
the Mandiant APT1 dataset (created from samples available
at [22], see also [21]). A full description of this dataset is
presented in Section V.
TABLE 1: Attributes extracted through automated malware
analysis

review some of the major concepts of the ACT-R framework
that are relevant to these models and provide a description of
both approaches.
We leveraged features of the declarative memory and
production system of the ACT-R architecture to complete
malware task identification. These systems store and retrieve
information that correspond to declarative and procedural
knowledge, respectively. Declarative information is the knowledge that a person can attend to, reflect upon, and usually
articulate in some way (e.g., by declaring it verbally or by
gesture). Conversely, procedural knowledge consists of the
skills we display in our behavior, generally without conscious
awareness.
Declarative Knowledge. Declarative knowledge is represented
formally in terms of chunks. Chunks have an explicit type, and
consist of an ordered list of slot-value pairs of information.
Chunks are retrieved from declarative memory by an activation
process, and chunks are each associated with an activation
strength which in turn is used to compute an activation
probability. In this paper, chunks will typically correspond to
a malware family. In the version of ACTR-IB where we do
not leverage families, the chunks correspond with samples in
the training data.
For a given chunk i, the activation strength Ai is computed

Attribute

Intuition

usesDLL(X)

Malware uses a library X

regAct(K)

Malware conducts an activity in the registry, modifying key K.

fileAct(X)

Malware conducts an activity on certain file X

proAct

Malware initiates or terminates a process

TABLE 2: Sample of malware tasks
Task

Intuition

beacon

Beacons back to the adversary’s system

enumFiles

Designed to enumerate files on the target

serviceManip

Manipulates services running on the target

takeScreenShots

Takes screen shots

upload

Designed to upload files from the target

Throughout the paper, we will also often consider malware
families, using the symbol F to denote the set of all families.
Each malware sample will belong to exactly one malware
family, and all malware samples belonging to a given family
will have the same set of tasks. Hence, we shall also treat each
element of F as a subset of M.
III.

ACT-R BASED A PPROACHES

We propose two models built using the mechanisms of
the ACT-R (Adaptive Control of Thought-Rational) cognitive
architecture [1]. These models leverage the work on applying
this architecture to intelligence analysis problems [18]. In particular, we look to leverage our recently-introduced instancebased (ACTR-IB) and rule-based (ACTR-R) models [17], [27].
Previous research has argued the ability of instance-based
learning in complex dynamic situations making it appropriate
for sensemaking [10]. On the other hand the rule-based learning is a more compact representation of associating samples
in memory with their respective families. In this section, we

as,
Ai = Bi + Si + Pi

(1)

where, Bi is the base-level activation, Si is the spreading
activation, and Pi is the partial matching score. We describe
each of these in more detail as follows.
Base-Level Activation (Bi ): The base-level activation for
chunk i reflects the frequency of samples belonging to a
particular family in memory . More important, base-level is
set to the log of the prior probability (i.e., the fraction of
samples associated with the chunk) in ACTR-R; for instancebased (ACTR-IB), we set it to a base level constant βi .
Spreading Activation (Si ): The spreading activation for chunk
i is based on a strength of association between chunk i and
the current test malware sample being considered. The strength
of association is computed differently in both approaches and,
in some cognitive model implementations, is weighted (as is
done in ACTR-R of this paper).
Partial Matching (Pi ): A partial matching mechanism computes the similarity between two samples. In this work, it
is only relevant to the instance-based approach. Given a test
sample j, its similarity with a sample i in memory is computed
as a product of the mismatch penalty (mp, a parameter of the
system) and the degree of mismatch Mji . We define the value
of Mji to be between 0 and −1; 0 indicates complete match
while −1 complete mismatch.
As common with models based on the ACT-R framework,
we shall discard chunks whose activation strength is below a
certain threshold (denoted τ ). All the chunks with activation
greater than τ are denoted as Aj . Once the activation strength,
Ai , is computed for a given chunk, we can then calculate
the activation probability, Pri . This is the probability that
the cognitive model will recall that chunk and is computed
using the Boltzmann(softmax) equation [25], which we provide

below.

B. ACT-R Rule-Based Model
Ai
s

(e )
P ri = P Aj
s )
j (e

(2)

Here, e is the base of the natural logarithm and s is momentary
noise inducing stochasticity by simulating background neural
activation (this is also a parameter of the system).

A. ACT-R Instance-Based Model
The instance based model is an iterative learning method
that reflects the cognitive process of accumulating experiences
(in this case the knowledge base of training samples) and
using them to predict the tasks for unseen test samples. Each
malware instance is associated with a set of attributes. When
a new malware sample is encountered, the activation strength
of that sample with each sample in memory is computed
using Equation 1. The spreading activation is a measure of
the uniqueness of the attributes between a test sample i and
a sample j in memory. To compute the spreading activation
we compute the f an for each attribute a (f an(a) finds all
instances in memory with the attribute a) of the test sample
i. The Partial matching is computed as explained above. The
degree of mismatch is computed as the intersection between
the attribute vector of the given malware and each sample
in memory normalized using the Euclidean distance between
the two vectors. The retrieval probability of each sample j
in memory with respect to the test sample i is then computed
using Equation 2. This generates a probability distribution over
families. The tasks are then determined by summing up the
probability of the families associated with that task with an
appropriately set threshold (we set that threshold at 0.5, based
on rationality).
Algorithm 1 ACT-R Instance-based Learning
INPUT: New malware sample i, historical malware corpus
M.
OUTPUT: Set of tasks associated with sample i.
for query malware sample i do
for all j in M do
Bj = βj
Pj = mp × √|attribs(i)∩attribs(j)|

In this version of ACT-R model we classify samples based
on simple rules computed during the training phase. Given a
malware training sample with its set of attributes a, along with
the ground truth value family, we compute pair of conditional
probabilities p(a|f ) and p(a|¬f ) for an attribute in a piece
of malware belonging (or not belonging) to family f . These
probabilistic rules (conditional probabilities) are used to set
the strength of association of the attribute with a family
(sa,f ). We use empirically determined Bayesian priors p(f )
to set the base-level of each family as opposed to using a
constant base-level for instance based. Only two components
of the activation function in Equation 1 are used, namely
base-level and spreading activation. Given the attributes for
current malware , we calculate the probability of the sample
belonging to each family according to Equation 2, generating
a probability distribution over families. The task are then
determined in a similar way to that of instance-based model.
Algorithm 2 ACT-R Rule-based Learning
INPUT: New malware sample i, historical malware corpus
M.
OUTPUT: Set of tasks associated with new sample i.
TRAINING:
S
Let X = j∈M attrib(j)
for all a in X do
Compute the set of rules p(a|f ) and p(a|¬f )
(where p(a|f ) = |{i∈M∩f s.t.|f |a∈attrib(i)}|
s.t. a∈attrib(i)}|
and p(a|¬f ) = |{i∈M−f |M|−|f
)
|
end for
TESTING:
for all f ∈ F do
|f |
)
Bf = log(p(f )) (where p(f ) = |M|
sa,f = 0.0
for all a ∈ attrib(i) do
w×sa,f
p(a|f )
sa,f = log( p(a|¬f
) ); Sf =+ |attribs(i)|
end for
Af = Bf + Sf
end for
Calculate Prf as per Equation 2
tp = {t ∈ T |pf ≥ 0.5}

|attribs(i)|×|attribs(j)|

sij = 0.0
for a ∈ attribs(i) do
if a ∈ attribs(j) then
sij += log( |f|M|
an(a) |)
else
1
sij += log( |M|
)
end if
end for
P
sij
Sj = j |attribs(i)|
Calculate Aj as per Equation 1
end for
Calculate
P Prj as per Equation 2
Prf = j∈f s.t. Aj ≥τ Prj
tp = {t ∈ T | Prf ≥ 0.5}
end for

C. Model Parameter Settings
The two proposed models leverage separate components of
the activation function. Table 3 provides a list of parameters
used for both the ACT-R models - we use standard ACT-R
parameters that have been estimated from a wide range of
previous ACT-R modeling studies from other domains [28] and
which are also suggested in the ACT-R reference manual [3].
The intuition behind these parameters is as follows. The
parameter s injects stochastic noise in the model. It is used to
compute the variance of the noise distribution and to compute
the retrieval probability of each sample in memory. The
mismatch penalty parameter mp is an architectural parameter
that is constant across samples, but it multiplies the similarity
between the test sample and the samples in knowledge base.
Thus, with a large value it penalizes the mismatch samples

more. It typically trades off against the value of the noise s
in a signal-to-noise ratio manner: larger values of mp lead
to more consistent retrieval of the closest matching sample
whereas larger values of s leads to more common retrieval of
poorer matching samples.The activation threshold τ determines
which samples will be retrieved from memory to make task
prediction decisions. The base level constant β is used to avoid
retrieval failures which might be caused due to high activation
threshold. The source activation w is assigned to each retrieval
to avoid retrieval failures for rule-based models.
TABLE 3: Parameters for the Cognitive models
Model

Parameters

Instance Based Learning

β = 20 (base-level constant)
s = 0.1 (stochastic noise parameter)
τ = -10 (activation threshold)
mp = 20(mismatch penalty)

Rule Based learning

s = 0.1 (stochastic noise parameter)
w = 16 (source activation)

IV.

predictors used in combination to classify new unseen samples.
We use a random forest which combines bagging for each
tree with random feature selection at each node to split the
data thus generating multiple decision tree classifiers [4]. Each
decision tree gives its own opinion on test sample classification
which are then merged to generate a probability distribution
over families.
Support Vector Machine (SVM). Support vector machines
(SVM) was proposed by Vapnik [7]. SVM’s work by finding
a separating margin that maximizes the geometric distance
between classes. The separating margin is termed as hyperplane. We use the popular LibSVM implementation [5] which
is publicly available.
Logistic Regression (LOG-REG). Logistic regression classifies samples by computing the odds ratio. The odds ratio
gives the strength of association between the attributes and
the family like simple rules used in the ACT-R rule based
learning. We implement the multinomial logistic regression
which handles multi-class classification.

E XPERIMENTAL S ETUP

A. Baseline Approaches

B. Dynamic Malware Analysis

We compare the proposed cognitive models against a
variety of baseline approaches - one commercial package and
five standard machine learning techniques. For the machine
learning techniques, we generate a probability distribution
over families and return the set of tasks associated with a
probability of 0.5 or greater while the commercial software
was used as intended by the manufacturer. Parameters for all
baseline approaches were set in a manner to provide the best
performance.
Commercial Offering: Invencia Cynomix. Cynomix is a malware analysis tool made available to researchers by Invencia
industries [12] originally developed under DARPA’s Cyber
Genome project. It represents the current state-of-the-art in
the field of malware capability detection. Cynomix conducts
static analysis of the malware sample and uses a proprietary
algorithm to compare it to crowd-sourced identified malware
components where the functionality is known.
Decision Tree (DT). Decision tree is a hierarchical recursive
partitioning algorithm. We build the decision tree by finding
the best split attribute i.e. the attribute that maximizes the
information gain at each split of a node. In order to avoid
over-fitting, the terminating criteria is set to less than 5% of
total samples. Malware samples are tested by the presence and
absence of the best split attribute at each level in the tree till
it reaches the leaf node.
Naive Bayes Classifier (NB). Naive Bayes is a probabilistic
classifier which uses Bayes theorem with independent attribute
assumption. During training we compute the conditional probabilities of a given attribute belonging to a particular family.
We also compute the prior probabilities for each family i.e.
fraction of the training data belonging to each family. Naive
Bayes assumes that the attributes are statistically independent
hence the likelihood for a sample S represented with a
set of attributes a associated
with a family f is given as,
Qd
Pr(f |S) = P (f ) × i=1 Pr(ai |f ), where d is the number
of attributes in a.
Random Forest (RF). Ensemble methods are popular classification tools. It is based on the idea of generating multiple

Dynamic analysis studies a malicious program as it executes on the host machine. It uses tools like debuggers,
function call tracers, machine emulators, logic analyzers, and
network sniffers to capture the behavior of the program. We
use two publicly available malware analysis tools to generate
attributes for each malware sample. These tools make use of
a sandbox which is a controlled environment to run malicious
software.
Anubis Sandbox. Anubis [13] is an online sandbox which
generates an XML formated report for a malware execution in
a remote environment. It generates detailed static analysis of
the malware but provides less details regarding the behavior of
the malware on the host machine. Since it is hosted remotely
we cannot modify its settings.
Cuckoo Sandbox. Cuckoo [6] is a standalone sandbox implemented using a dedicated virtual machine and more importantly can be customized to suit our needs. It generates
detailed reports for both static as well as behavior analysis by
watching and logging the malware while its running on the
virtual machine. These behavior analysis prove to be unique
indicators for a given malware for the experiments.
C. Performance Evaluation
In our tests, we evaluate performance based primarily
on four metrics: precision, recall, unbiased F1, and family
prediction accuracy. For a given malware sample being tested,
precision is the fraction of tasks the algorithm associated with
the malware that were actual tasks in the ground truth. Recall,
for a piece of malware, is the fraction of ground truth tasks
identified by the algorithm. The unbiased F1 is the harmonic
mean of precision and recall. In our results, we report the
averages for precision, recall, and unbiased F1 for the number
of trials performed. Our measure of family accuracy - the
fraction of trials where the most probable family was the
ground truth family of the malware in question - is meant
to give some insight into how the algorithm performs in the
intermediate steps.

R ESULTS

All experiments were run on Intel core-i7 operating at 3.2 GHz
with 16 GB RAM. Only one core was used for experiments.
All experimental results presented in this section are new and
have not been previously introduced.
A. Mandiant Dataset
Our first set of experiments uses a dataset based on the
the T1 cyber espionage group as identified in the popular
report by Mandiant Inc [21]. This dataset consisted of 132
real malware samples associated with the Mandiant report
that were obtained from the Contagio security professional
website [22]. Each malware sample belonged to one of 15
families including BISCUIT, NEWSREELS, GREENCAT and
COOKIEBAG. Based on the malware family description [21],
we associated a set of tasks with each malware family (that
each malware in that family was designed to perform). In
total, 30 malware tasks were identified for the given malware
samples (see Table 2). On average, each family performed 9
tasks.
We compared the four machine learning approaches with
the rule based and instance-based ACT-R models (ACTR-R
and ACTR-IB respectively). We also submitted the samples
to the Cynomix tool for automatic detection of capabilities.
These detected capabilities were then manually mapped to
the tasks from the Mandiant report. Precision and recall
values were computed for the inferred adversarial tasks. On
average the machine learning approaches predicted 9 tasks per
sample, ACTR-R predicted 9 tasks per sample and ACTR-IB
predicted 10 tasks. On the other hand Cynomix was able to
detect on average only 4 tasks.

Average

Leave one out Cross-Validation(LOOCV)
In leave one out cross validation, for n malware samples,
we train on n − 1 samples and test on the remaining one.
This procedure was repeated for all samples and the results
were averaged. We performed this experiment using both
sandboxes and compared the results (see Fig. 1).
1

1

0.9
0.8
0.7
0.6
0.5
Precision

LOG-REG

SVM

Recall

RF

ACTR-R

F1

ACTR-IB

Family
Prediction
INVINCEA

Fig. 2: Average Precision, Recall, F1 and Family prediction
comparisons for LOG-REG, RF, SVM, ACTR-R, ACTR-IB
and INVINCEA.
Fig. 2 compares the performance of the five best performing methods from Fig. 1 and compares it with the Cynomix
tool of Invincea industries. ACTR-IB outperformed LOGREG, SVM, RF and ACTR-R; average F1 = 0.97 vs 0.85 (t
(132) = 7.85, p < .001), 0.9 (t (132) = 4.7, p < .001), 0.89
(t (132) = 5.45, p < .001) and 0.88 (t (132) = 5.2, p < .001)
respectively. Both the proposed cognitive models and machine
learning techniques significantly outperformed the Cynomix
tool in detecting the capabilities (tasks).
These three approaches (LOG-REG, SVM, RF) were
also evaluated with respect to predicting the correct family
(before the tasks were determined). ACTR-IB outperformed
LOG-REG, SVM, RF and ACTR-R; average family prediction
= 0.93 vs 0.84 (t (132) = 3.22, p < .001), 0.86 (t (132) =
3.13, p < .001), 0.86 (t (132) = 3.13, p < .001) and 0.89 (t
(132) = 2.13, p = .03) respectively.

0.6
0.2
F1

Family Prediction

Anubis Sandbox

Average

RF (t (132) = 0.56, p = 0.57), SVM (t (132) = 1.95, p = 0.05),
LOG-REG (t (132) = 1.82, p = 0.07), NB (t (132) = 1.79, p
= 0.08) and DT (t (132) = 0.83, p = 0.4). But the significant
improvement was in the family prediction values with ACTRIB improving by 0.12 from 0.81 to 0.93 (t (132) = 3.86, p
< .001) and ACTR-R by 0.15 from 0.72 to 0.87 (t (132) =
3.78, p < .001) outperforming all other methods. Since having
behavior analysis helps in better task prediction as seen from
the comparison experiment, we use cuckoo sandbox for rest
of our experiments.

Average

V.

1
0.6
0.2
F1

Family Prediction

Cuckoo Sandbox
DT

NB

LOG-REG

SVM

RF

ACTR-R

ACTR-IB

Fig. 1: Average F1 and Family prediction comparisons for DT,
NB, LOG-REG, SVM, RF, ACTR-IB and ACTR-R for Anubis
(top) and Cuckoo (bottom).
The average F1 increases by 0.03 when we use the attributes generated by the Cuckoo sandbox instead of Anubis.
The statistical significance results are as follows: for ACTR-IB
(t (132) = 1.94, p = 0.05), ACTR-R (t (132) = 1.39, p = 0.16),

Task Prediction without inferring families:
In the proposed models we infer the malware family first and
then predict the tasks associated with that family. However,
differences over “ground truth” for malware families in the
cyber-security community calls for a direct inference of tasks
without dependence on family prediction. In this section we
adapt the models to predict tasks directly without inferring
the family.
Fig. 3 shows the performance of the cognitive and machine
learning models without inferring the families. There is no
difference in the performance of ACTR-IB and ACTR-R
approaches as compared to Fig. 2 where we use families. On
the other hand direct task prediction reduces the F1 measure
of machine learning techniques on average by almost 0.1. This
is due to the fact, now instead of having a single classifier
for each family we have multiple classifiers for each task
that a malware sample is designed to perform. This not only
degrades the performance but also adds to the training time

Average

1

0.9

0.8

0.7
Precision
LOG-REG

SVM

Recall
RF
ACTR-R

F1
ACTR-IB

Fig. 3: Average Precision, Recall, and F1 comparisons for
LOG-REG, RF, SVM, ACTR-R and ACTR-IB without inferring families.

200

Training time (sec)

Training time (sec)

for these methods. We compare the training time with increase
in training data for task prediction with/without inferring
families. Inferring families first reduces the training time
(see Fig. 4 (a)). On the other hand predicting tasks directly
significantly increases the training time for the machine
learning methods along for the rule-based ACT-R approach
(Fig. 4 (b)). Due to the issues with respect to performance
and training time, we consider inferring families first for rest
of the experiments. An important point to note is this has no
effect on the Instance-based model for both performance and
computation time.
150
100
50

0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
LOG-REG SVM RF ACTR-R

(a) (a)

200
150
100
50

0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
LOG-REG SVM RF ACTR-R

(b) (b)

Fig. 4: Training time for LOG-REG, SVM, RF and ACTR-R
with(a) / without(b) inferring families.

Fig. 5 shows the GVDG user interface used for the
generation of malware samples. We can select the carrier
type and the tasks that we want the malware sample to
perform on the host machine. The tasks are represented as
payloads, while carrier is a functional template of specific
behavior which are the operational framework supporting and
enabling the task activity. In generating datasets with GVDG,
we specify families based on sets of malware with the same
tasks. Whether or not a family consists of malware with the
same carrier depends on the experiment. Further, GVDG also
has an option to increase “mutation” or variance among the
samples. We perform experiments analyzing the performance
of the proposed methods when the generated samples belong
to different carrier and same carrier types, as well as when
the samples are encrypted and mutated making task prediction
difficult. In all the experiments we consider 60% of the data
for training and 40% for testing. The results are averaged
across 10 trials. The Cynomix tool from Invencia was unable
to detect any tasks for the GVDG dataset, primarily due to
to its inability to find public source documents referencing
GVDG samples and also unable to generalize from similar
samples.
Different Carriers:
In this experiment, we generated 1000 samples for each
carrier type with low mutation. On average each carrier type
performs 7 tasks(payloads). Hence each carrier represents one
family for this experiment. Both random forest and ACTR-IB
model were able to predict the tasks and family with F1
measure of 1.0 outperforming LOG-REG 1 vs 0.91 , SVM
1 vs 0.95 and ACTR-R 1 vs 0.95. All results are statistical
significant with (t (1998) ≥ 8.93, p < .001)(Fig. 6). Also for
family prediction ACTR-IB and RF outperformed LOG-REG
1 vs 0.92, SVM 1 vs 0.92 and ACTR-R 1 vs 0.95 (t (1998)
≥ 8.93, < .001). These results are not surprising given that
different carrier(family) types have high dissimilarity between
them. Also, samples belonging to the same carrier have on
average 60% of similar attributes.
1

Average

B. GVDG Dataset

0.9

0.8
Precision

LOG-REG

Recall

SVM

RF

F1

ACTR-R

Family
Prediction
ACTR-IB

Fig. 6: Average Precision, Recall, F1 and Family prediction
comparisons for LOG-REG,SVM, RF, ACTR-R and ACTRIB for different carrier samples.
Fig. 5: GVDG User Interface
GVDG is a malware generation tool designed for the study
of computer threats [11]. It is capable of generating following
malware threats,
•
•
•
•
•

File-virus
Key-Logger
Trojan-Extortionist
USB-Worm
Web Money-Trojan

Different Carriers-Mutation:
For this case, we generate the same samples as in the previous
experiment but with maximum mutation between samples
belonging to the same carrier. We generated 1000 samples for
each carrier with maximum mutation. In this case ACTR-IB
had an average F1 of 1 outperforming LOG-REG 1 vs 0.83,
SVM 1 vs 0.88 , RF 1 vs 0.96 and ACTR-R 1 vs 0.92 (t (1998)
≥ 7, p < .001)(Fig. 7). Also for family prediction ACTR-IB
outperformed LOG-REG 1 vs 0.85, SVM 1 vs 0.88 , RF 1 vs

1

0.95 and ACTR-R 1 vs 0.92 (t (1998) ≥ 7, p < .001).

Average

Average

1

0.9

0.9

0.8

0.8

Precision
0.7

LOG-REG
Precision

LOG-REG

Recall

SVM

F1

RF

Family
Prediction
ACTR-IB

ACTR-R

Fig. 7: Average Precision, Recall, F1 and Family prediction
comparisons for LOG-REG,SVM, RF, ACTR-R and ACTRIB.
High mutation induces high variance between samples
associated with the same carrier making the classification task
difficult. High mutation samples belonging to same carrier have
only 20% of common attributes as compared to 60% for low
mutation.

RF

ACTR-R

Family
Prediction
ACTR-IB

outperforming LOG-REG 0.95 vs 0.84, SVM 0.95 vs 0.87, RF
0.95 vs 0.90 and ACTR-R 0.95 vs 0.92 (t (678) ≥ 1.52 , p ≤
0.13). Since each family performs exactly one task the family
prediction is similar to F1. Using the same carrier for each
payload makes the task difficult as they have high similarity
between them.
Same Carrier-Encryption:
The GVDG tool provides the option for encrypting the
malware samples for the File-virus carrier type. We use
this option to generate 100 encrypted malware samples
for each task(payload) and use them as test data with the
unencrypted versions from the same carrier experiment as
training samples. From Fig. 10 ACTR-IB had an average F1
of 0.9 outperforming LOG-REG 0.9 vs 0.8, SVM 0.9 vs 0.8,
RF 0.9 vs 0.74 and ACTR-R 0.9 vs 0.88 (t (1698) ≥ 2.36
, p ≤ 0.02). Encrypting malware samples morphs the task
during execution making it difficult to detect during analysis.
Hence the drop in performance as compared to non-encrypted
samples. We note that SVM performs better than RF likely
because it looks to maximize generalization.

0.5
0.4
0.3
0.2
0.1

1

0.9

File-virus

Key-logger

Trojan-E

USB-worm

Web-T

0.5

Average

SVM

F1

Fig. 9: Average Precision, Recall, F1 and Family prediction
comparisons for LOG-REG,SVM, RF, ACTR-R and ACTRIB.

0.4

Average

F1

Leave one carrier out cross-validation:
To see how the models generalize to unseen malware family(carrier), we performed a leave-one-carrier-out comparison
(using high mutation samples), where we test the models
against one previously unseen malware carrier. ACTR-IB performs better or on par with all other baseline approaches for
all the carriers. It clearly outperforms all the approaches in
recalling most of the actual tasks (40%) (see Figure 8). ACTRIB has shown to generalize for unseen malware families [17].
This case is difficult given the fact that the test family is
not represented during training, hence task prediction depends
on associating the test family with the training families that
perform similar tasks.

Recall

0.8
0.7

0.3
0.6

0.2

Precision

0.1
Precision

LOG-REG

Recall

SVM

RF

ACTR-R

F1

ACTR-IB

Fig. 8: Average F1 values for 5 malware carriers (above) and
the average precision, recall and F1 across all carriers (below)
for LOG-REG, SVM, RF, ACTR-R and ACTR-IB..
Same Carrier:
As seen in the previous experiments, different carrier types
makes the task easier because of less similarity between them.
We now test the performance, on same carrier type performing
exactly one task. Since there are 17 tasks in the GVDG tool,
we generate 100 samples for each task for carrier type Filevirus. In this experiment each task represents one family.
Thus in total we have 1700 samples. We do the 60-40 split
experiment. From Fig. 9 ACTR-IB had an average F1 of 0.95

LOG-REG

Recall

SVM

RF

F1

ACTR-R

Family
Prediction
ACTR-IB

Fig. 10: Average Precision, Recall, F1 and Family prediction
comparisons for LOG-REG,SVM, RF, ACTR-R and ACTRIB.
VI. R ELATED W ORK
Identification of malicious software. The identification of
whether or not binary is malicious [8], [26] is important and
can be regarded as a “first step” in the analysis of suspicious
binaries in the aftermath of a cyber-attack. However, we note
that as many pieces of malware are designed to perform
multiple tasks, that successful identification of a binary as
malicious does not mean that the identification of its associated
tasks will be a byproduct of the result - and hence this is
normally the case, which has led to some of the other related
work described in this section.
Malware family classification. There is a wealth of existing

work on malware family identification [2], [15], [16]. The
intuition here is that by identifying the family of a given piece
of malware, an analyst can then more easily determine what
it was designed to do based on previously studied samples
from the same family. However, malware family classification
has suffered from two primary draw-backs: (1) disagreement
about malware family ground truth as different analysts (e.g.
Symantec and MacAfee) cluster malware into families differently; and (2) previous work has shown that some of these
approaches mainly succeed in “easy to classify” samples [19],
[23], where “easy to classify” is a family that is agreed upon
by multiple malware firms. In this paper, we infer the specific
tasks a piece of malware was designed to carry out. While we
do assign malware to a family as a component of our approach,
to avoid the two aforementioned issues as the family partition
is done so probabilistically and the result ground truth is the
focus of our comparison (though we show family prediction
results as a side-result). Further, we also describe and evaluate
a variant of our instance-based method that does not consider
families and yields a comparable performance to our instancebased method that does consider families.
Malware task identification. With regard to direct inference
of malware tasks, the major related work include the software
created by the firm Invincea [12] for which we have included
a performance comparison. Additionally, some of the ideas
in this paper were first introduced in [17], [27]. However, that
work primarily focused on describing the intuitions behind the
cognitive modeling techniques and only included experimental
evaluation on one dataset (the Mandiant APT1 dataset) and
one sandbox environment (Anubis) with a comparison amongst
only the instance based approach, the rule-based cognitive
model, the standard decision tree, and the naive Bayes reasoner. The experimental evaluation in this paper was designed
to be much more thorough to pave the way toward deployment
of the approach for use by cyber-security analysts.
VII.

[2]
[3]
[4]
[5]

[6]
[7]
[8]

[9]
[10]
[11]
[12]

[13]
[14]
[15]
[16]

[17]

[18]

C ONCLUSION

In this paper, we introduced an automated method that
combines dynamic malware analysis with cognitive modeling
to identify malware tasks. This method obtains excellent precision and recall - often achieving an unbiased F1 score of over
0.9 - in a wide variety of conditions over two different malware
sample collections and two different sandbox environments outperforming a variety of baseline methods. Currently, our
future work has three directions. First, we are looking to
create a deployed version of our approach to aid cyber-security
analysts in the field. Second, we look to enhance our malware
analysis to also include network traffic resulting from the
sample by extending the capabilities of the sandbox. Finally,
we also look to address cases of highly-sophisticated malware
that in addition to using encryption and packing to limit static
analysis, also employ methods to “shut down” when run in a
sandbox environment [20]. We are exploring multiple methods
to address this such as the recently introduced technique of
“spatial analysis” [9] that involves direct analysis of a malware
binary.

[19]
[20]

[21]
[22]
[23]
[24]

[25]
[26]

[27]

R EFERENCES
[1]

J. R. Anderson, D. Bothell, M. D. Byrne, S. Douglass, C. Lebiere, and
Y. Qin. An integrated theory of mind. PSYCHOLOGICAL REVIEW,
111:1036–1060, 2004.

[28]

U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kruegel, and E. Kirda.
Scalable, behavior-based malware clustering, 2009.
D. Bothell. Act-r 6.0 reference manual. http:// act-r.psy.cmu.edu/ actr6/
reference-manual.pdf , 2004.
L. Breiman. Random forests. Machine Learning, 45(1):5–32, 2001.
C.-C. Chang and C.-J. Lin. Libsvm: A library for support vector
machines. ACM Trans. Intell. Syst. Technol., 2(3):27:1–27:27, May
2011.
J. B. M. S. Claudio Guarnieri, Alessandro Tanasi. Cuckoo sandbox.
http:// www.cuckoosandbox.org/ , 2012.
C. Cortes and V. Vapnik. Support-vector networks. pages 273–297,
1995.
I. Firdausi, C. lim, A. Erwin, and A. S. Nugroho. Analysis of machine
learning techniques used in behavior-based malware detection. In
Proceedings of the 2010 Second International Conference on ACT, ACT
’10, pages 201–203, Washington, DC, USA, 2010. IEEE Computer
Society.
D. Giametta and A. Potter. Shmoomcon 2014:there and back again:a
critical analysis of spatial analysis, 2014.
C. Gonzalez, J. F. Lerch, and C. Lebiere. Instance-based learning in
dynamic decision making. Cognitive Science, 27(4):591 – 635, 2003.
GVDG. Generator malware gvdg. 2011.
Invencia. Crowdsource: Crowd trained machine learning model for
malware capability detection. http:// www.invincea.com/ tag/ cynomix/ ,
2013.
ISEC-Lab. Anubis: Analyzing unknown binaries. http:// anubis.iseclab.
org/ , 2007.
Kaspersky. Gauss: Abnormal distribution, 2012.
J. Kinable and O. Kostakis. Malware classification based on call graph
clustering. J. Comput. Virol., 7(4):233–245, Nov. 2011.
D. Kong and G. Yan. Discriminant malware distance learning on structural information for automated malware classification. In Proceedings
of the 19th ACM SIGKDD, KDD ’13, pages 1357–1365, New York,
NY, USA, 2013. ACM.
C. Lebiere, S. Bennati, R. Thomson, P. Shakarian, and E. Nunes.
Functional cognitive models of malware identification. In Proceedings
of ICCM, ICCM 2015, Groningen, The Netherlands, April 9-11, 2015,
2015.
C. Lebiere, P. Pirolli, R. Thomson, J. Paik, M. Rutledge-Taylor,
J. Staszewski, and J. R. Anderson. A functional model of sensemaking
in a neurocognitive architecture. Intell. Neuroscience, 2013:5:5–5:5,
Jan. 2013.
P. Li, L. Liu, and M. K. Reiter. On challenges in evaluating malware
clustering, 2007.
M. Lindorfer, C. Kolbitsch, and P. Milani Comparetti. Detecting
environment-sensitive malware. In Proceedings of the 14th International Conference on RAID, RAID’11, pages 338–357, Berlin, Heidelberg, 2011. Springer-Verlag.
Mandiant. Apt1:exposing one of china’s cyber espionage units. http:
// intelreport.mandiant.com/ , 2013.
Mandiant. Mandiant APT1 samples categorized by malware families.
Contagio Malware Dump, 2013.
R. Perdisci and ManChon. Vamo: towards a fully automated malware
clustering validity analysis. In ACSAC, pages 329–338. ACM, 2012.
M. Sikorski and A. Honig. Practical Malware Analysis: The Hands-On
Guide to Dissecting Malicious Software. No Starch Press, 1 edition,
2012.
R. S. Sutton and A. G. Barto. Introduction to Reinforcement Learning.
MIT Press, Cambridge, MA, USA, 1st edition, 1998.
A. Tamersoy, K. Roundy, and D. H. Chau. Guilt by association: Large
scale malware detection by mining file-relation graphs. In Proceedings
of the 20th ACM SIGKDD, KDD ’14, pages 1524–1533. ACM, 2014.
R. Thomson, C. Lebiere, S. Bennati, P. Shakarian, and E. Nunes. Malware identification using cognitively-inspired inference. In Proceedings
of BRIMS, BRIMS 2015, Washington DC, March 31-April 3, 2015, 2015.
T. J. Wong, E. T. Cokely, and L. J. Schooler. An online database of
act-r parameters: Towards a transparent community-based approach to
model development. 2010.

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network
Diffusion Optimization Problems
PAULO SHAKARIAN, United States Military Academy West Point
MATTHIAS BROECHELER and V. S. SUBRAHMANIAN, University of Maryland
CRISTIAN MOLINARO, Università della Calabria
There has been extensive work in many different fields on how phenomena of interest (e.g., diseases, innovation, product adoption) “diffuse” through a social network. As social networks increasingly become a fabric
of society, there is a need to make “optimal” decisions with respect to an observed model of diffusion. For
example, in epidemiology, officials want to find a set of k individuals in a social network which, if treated,
would minimize spread of a disease. In marketing, campaign managers try to identify a set of k customers
that, if given a free sample, would generate maximal “buzz” about the product. In this article, we first show
that the well-known Generalized Annotated Program (GAP) paradigm can be used to express many existing
diffusion models. We then define a class of problems called Social Network Diffusion Optimization Problems
(SNDOPs). SNDOPs have four parts: (i) a diffusion model expressed as a GAP, (ii) an objective function we
want to optimize with respect to a given diffusion model, (iii) an integer k > 0 describing resources (e.g.,
medication) that can be placed at nodes, (iv) a logical condition VC that governs which nodes can have a
resource (e.g., only children above the age of 5 can be treated with a given medication). We study the computational complexity of SNDOPs and show both NP-completeness results as well as results on complexity of
approximation. We then develop an exact and a heuristic algorithm to solve a large class of SNDOPproblems
and show that our GREEDY-SNDOP algorithm achieves the best possible approximation ratio that a polynomial algorithm can achieve (unless P = NP). We conclude with a prototype experimental implementation to
solve SNDOPs that looks at a real-world Wikipedia dataset consisting of over 103,000 edges.

10

Categories and Subject Descriptors: I.2.4 [Knowledge Representation Formalisms and Methods]:
Representations (procedural and rule-based); I.2.3 [Deduction and Theorem Proving]: Logic
programming
General Terms: Theory
Additional Key Words and Phrases: Social network, generalized annotated programs, approximation
algorithms
ACM Reference Format:
Shakarian, P., Broecheler, M., Subrahmanian, V. S. and Molinaro, C. 2013. Using generalized annotated programs to solve social network diffusion optimization problems. ACM Trans. Comput. Logic 14, 2, Article 10
(June 2013), 40 pages.
DOI:http://dx.doi.org/10.1145/2480759.2480762
P. Shakarian is funded under the US Army ACS/West Point Instructor (EECS) program. Some of the authors
of this article were funded in part by AFOSR grant FA95500610405, ARO grant W911NF0910206 and ONR
grant N000140910685
Authors’ addresses: P. Shakarian, Network Science Center and Department of Electrical Engineering and
Computer Science, United States Military Academy West Point; M. Broecheler and V. S. Subrahmanian,
Department of Computer Science, University of Maryland; email: vs@cs.umd.edu; C. Molinaro, DEIS Department, Università della Calabria.
© 2013 Association for Computing Machinery. ACM acknowledges that this contribution was authored or
co-authored by a contractor or affiliate of the U.S. Government. As such, the Government retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for Government
purposes only.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for profit or commercial advantage and that
copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights
for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component
of this work in other works requires prior specific permission and/or a fee. Permissions may be requested
from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212)
869-0481, or permissions@acm.org.
© 2013 ACM 1529-3785/2013/06-ART10 $15.00
DOI:http://dx.doi.org/10.1145/2480759.2480762
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:2

P. Shakarian et al.

1. INTRODUCTION

There is a rapid proliferation of different types of graph data in the world today. These include social network data (FaceBook, Flickr, YouTube, etc.), cell phone
network data [Eagle et al. 2008] collected by virtually all cell phone vendors, email
network data (such as those derived from the Enron corpus1 ), as well as information
on disease networks [Anderson and May 1979; Coelho et al. 2008]. In addition, the
World Wide Consortium’s RDF standard is also a graph-based standard for encoding
semantic information contained in web pages. There has been years of work on analyzing how various properties of nodes in such networks “diffuse” through the network;
different techniques have been invented in different academic disciplines including
economics [Jackson and Yariv 2005; Schelling 1978], infectious diseases [Coelho et al.
2008], sociology [Granovetter 1978] and computer science [Kempe et al. 2003].
Past work on diffusion has several limitations. (i) First, they largely assume that
a social network is nothing but a set of vertices and edges [Cowan and Jonard 2004;
Rychtář and Stadler 2008; Watts 1999]. In contrast, in this article we adopt a richer
model where edges and vertices can both be labeled with properties. For instance, a political campaigner hoping to spread a positive message about a campaign needs to use
demographics (e.g., sex, age group, educational level, group affiliations, etc.) for targeting a political message—a “one size fits all” message will not work. In general, social
network researchers would say that they have several sociomatrices that can be used
for such applications. (ii) Second, past work on diffusion has no notion of “strength”
associated with edges. It may well be the case, in many applications, that the degree
of contact between two vertices (e.g., number of minutes person A spends on the cell
phone with person B) is a proxy for the strength of the relationship between A and
B, which in turn may have an impact of whether A can influence B or not. (iii) Third,
these past frameworks [Coelho et al. 2008; Granovetter 1978; Jackson and Yariv 2005;
Schelling 1978] usually reason about a single diffusion model, rather than develop a
framework for reasoning about a whole class of diffusion models.
Past diffusion models developed in a variety of fields ranging from business [Jackson
and Yariv 2005], economics [Schelling 1978], social science [Granovetter 1978], epidemiology [Anderson and May 1979; Coelho et al. 2008; Hethcote 1976], mobile phone
usage [Aral et al. 2009] show that diffusion models vary dramatically from application
to application. Three broad categories of diffusion models exist.
(1) Cascade models [Anderson and May 1979; Coelho et al. 2008; Hethcote 1976] are
widespread in epidemiology and assume that diffusions are largely based on connectivity between nodes and are largely probabilistic.
(2) Tipping models do not use probabilities, but use various quantitative calculations
to determine when a vertex adopts (or is infected with) a diffusive property. They
are omnipresent in the social sciences and business [Centola 2010; Granovetter
1978; Jackson and Yariv 2005]. Nobel laureate Tom Schelling makes a similar
point that diffusions in many social science applications have a tipping point when
vertices become influenced by the number of neighbors and the strength of commitment the neighbors may have to a certain position. No probabilities are present
in such models.
(3) Homophilic models are ones where similarity between users, rather than networks
effects, dominate diffusion. Similarity is usually calculated using some quantitative model, often related to distance between vectors representing (values of)
properties of nodes. For example, Aral et al. [2009] track adoption of mobile
applications in a study of over 27M users and shows that homophily—similarity
1 http://www.cs.cmu.edu/ enron/


ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:3

between users—is the most compelling diffusion model. There are no probabilities
here, just similarity measures. Another world famous diffusion model focused on
marketing [Watts and Peretti 2007] also is based on homophily and similarity of
nodes’ intrinsic properties rather than a probability.
Moreover, many models use a mix of these forms. For instance, Cha et al. [2009] argue
that the way photos are marked as “favorites” on Flickr is based on a mix of cascading
and homophilic behavior and to study the former, one must also account for the latter.
A similar combination of cascading and tipping is observed in [Zhang 2011]. Another
strong indication of hybrid models in real social networks is the noteworthy experimental study of [Centola 2011] which illustrates how a tipping model combined with
homphilic effects promote diffusion of health behaviors in an online network. Thus,
any general framework for expressing diffusions must have the capability to express
all three types of diffusion models, not just one or the other. In general, a language to
express diffusion models must be capable of expressing a wide variety of quantitative
methods encapsulated in the forms.
In this article, we first show that a class of the well-known Generalized Annotated
Program (GAP) paradigm [Kifer and Lozinskii 1992; Kifer and Subrahmanian 1992;
Thirunarayan and Kifer 1993] and their variants [Damasio et al. 1999; Krajci et al.
2004; Lu 1996; Lu et al. 1993; Vennekens et al. 2004] including Linear GAPs (introduced here) form a convenient method to express many diffusion models. Though there
is no claim that they can express all possible useful diffusion models, they do express
all diffusion models (over 30) we have studied in the literature on a wide variety of
topics. Moreover, Broecheler et al. [2010] provide an algorithm to automatically learn
such diffusion models from historical data, so users do not need to write their diffusion
models by themselves. This provides greater confidence that these diffusion models are
“correct.” Many other papers also focus on learning diffusion models automatically for
different types of applications: [Leskovec et al. 2007a] develop a probabilistic learning algorithm, while [Backstrom et al. 2006] develop a method that takes both the
properties of vertices and the strength of relationships between vertices to learn such
a diffusion model automatically. We expect that in most real-world applications going
forward, diffusion models will be automatically learned rather than being programmed
by logic programmers.
Next, unlike most existing work in social networks which focus on learning diffusion
models, we focus on reasoning with diffusion models (expressed via GAPs) after the
diffusion models have been learned. In particular, we consider the problem of optimal
decision making in social networks which have associated diffusion models expressible
as Linear GAPs, though many of the results in the article apply to arbitrary GAPs as
well. Here are two examples.
— (Q1) Cell phone plans. A cell phone company is promoting a new cell phone plan as a promotion, it is giving away k free plans to existing customers.2 Which set of
k people should they pick so as to maximize the number of plan adoptees predicted
by a cell phone plan adoption diffusion model they have learned from their past
promotions?
— (Q2) Medication distribution plan. A government combating a disease spread by
physical contact has limited stocks of free medication to give away. Based on a
diffusion model of how the disease spreads (e.g., kids might be more susceptible
than adults, those previously inoculated against the disease are safe, etc.), they
2 Our framework allows us to add additional constraints—for instance, that plans can only be given to cus-

tomers satisfying certain conditions, for instance, customers deemed to be “good” according to various business criteria.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:4

P. Shakarian et al.

want to find a set of k people who (jointly) maximally spread the disease when
infected (so that they can provide immediate treatment to these k people in an
attempt to halt the disease’s spread).3 Notice that this query corresponds to only
one of many different policies that can be considered to deal with the disease spread
scenario, that is, we consider the case where a diffusion model expressing how an
infected person can infect other people is available and formulate a query that looks
at the maximum spread when k people are infected. Other queries, possibly leading
to different answers about who should be treated with medications, are possible.
Both these problems are instances of a class of queries that we call Social Network
Diffusion Optimization Problem (SNDOP) queries. They differ from queries studied
in the past in quantitative (both probabilistic and annotated) logic programming in
two fundamental ways: (i) They are specialized to operate on graph data where the
graph’s vertices and edges are labeled with properties and where the edges can have
associated weights, (ii) They find sets of vertices that optimize complex objective functions that can be specified by the user. Neither of these has been studied before by any
kind of quantitative logic programming framework, though work on optimizing objective functions in the context of different types of semantics (minimal model and stable
model semantics) has been studied before [Leone et al. 2004]. And of course, constraint
logic programming [Apt 2003] has also extensively studied optimization issues as well
in logic programming; however, here, optimization and constraint solving is embedded in the constraint logic program, whereas in our case, they are part of the query
over an annotated logic program. Moreover, most measures of importance in social
networks are centrality measures that study the influence of single vertices; Borgatti
and Everett [2006] provide an excellent overview of centrality measures. In contrast,
a set of k nodes each with low individual centrality may often wield greater influence
on a network than the set consisting of the k nodes with highest individual centrality;
intuitively, this is due to the fact that the k nodes with highest individual centrality
may overlap greatly in the nodes they influence, leading to an aggregate number of
influenced nodes that is lower than the one in the first case.
This article is organized as follows. In Section 2, we provide an overview of GAPs
(past work), define a social network (SN for short), and explain how GAPs can represent some types of diffusion in SNs. Section 3 formally defines different types of social
network diffusion optimization problems and provides results on their computational
complexity and other properties. Section 4 shows how our framework can represent
several existing diffusion models for social networks including economics and epidemiology. In Section 5 we present the exact SNDOP-Mon algorithm to answer SNDOP
queries under certain assumptions of monotonicity. We then develop a greedy algorithm GREEDY-SNDOP and show that under certain conditions, it is guaranteed to be
e
an ( e−1
) approximation algorithm for SNDOP queries; this is the best possible approximation guarantee. Last, but not least, we describe our prototype implementation and
experiments in Section 6. Specifically, we tested our GREEDY-SNDOP algorithm on a
real-world social network dataset consisting of over 7000 nodes and over 103,000 edges
from Wikipedia logs. We show that we solve social network diffusion optimization problems over real datasets in acceptable times. We emphasize that much additional work
is required on further enhancing scalability and that research on social network diffusion optimization problems is at its very infancy. Finally, in Section 7, we review
related work.
3 Again, our framework allows us to add additional constraints—for instance, that medication can only be

given to people satisfying certain conditions, for instance, be over a certain age, or be within a certain age
range and not have any conditions that are contra-indicators for the medication in question.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:5

Fig. 1. Example cellular network.

2. TECHNICAL PRELIMINARIES

In this section, we first formalize social networks, then briefly review generalized annotated logic programs (GAPs) [Kifer and Subrahmanian 1992] and then describe how
GAPs can be used to represent concepts related to diffusion in SNs.
2.1. Social Networks Formalized

Throughout this article, we assume the existence of two arbitrary but fixed disjoint
sets VP, EP of vertex and edge predicate symbols respectively. Each vertex predicate
symbol has arity 1 and each edge predicate symbol has arity 2.
Definition 2.1. A social network is a 5-tuple (V, E, vert , edge , w) where:
(1)
(2)
(3)
(4)
(5)

V is a finite set whose elements are called vertices.
E ⊆ V × V is a finite multiset whose elements are called edges.
vert : V → 2VP is a function, called vertex labeling function.
edge : E → EP is a function, called edge labeling function. 4
w : E → [0, 1] is a function, called weight function.

We now present a brief example of an SN.
Example 2.2. Let us return to the cell phone example (query (Q1)). Figure 1 shows
a toy SN the cell phone company might use. Here, we might have VP = {male, female,
adopter, temp adopter, non adopter} denoting the sex and past adoption behavior of
each vertex; EP might be the set {phone, email, IM} denoting the types of interactions
between vertices (phone call, email, and instant messaging respectively). The function
vert is shown in Figure 1 by the shape (denoting past adoption status) and shading
(male/female). The type of edges (bold for phone, dashed for email, dotted for IM)
is used to depict edge . w(v1 , v2 ) denotes the percentage of communications of type
edge (v1 , v2 ) initiated by v1 that were with v2 (measured either w.r.t. time or bytes).
It is important to note that our definition of social networks is much broader than
that used by several researchers [Anderson and May 1979; Coelho et al. 2008; Jackson
and Yariv 2005; Kempe et al. 2003] who often do not consider either edge or vert or
edge weights through the function w; it is well-known in marketing that intrinsic
4 Each edge e ∈ E is labeled by exactly one predicate symbol from EP. However, there can be multiple edges
between two vertices labeled with different predicate symbols.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:6

P. Shakarian et al.

properties of vertices (customers, patients) and the nature and strength of the relationships (edges) is critical for decision making in those fields.
Note. We assume that SNs satisfy various integrity constraints. In Example 2.2, it
is clear that vert (v) should include at most one of male, female and at most one of
adopter, temp adopter,non adopter. We assume the existence of some integrity constraints to ensure this kind of semantic integrity; they can be written in any reasonable syntax to express ICs. In the rest of this article, we assume that social networks
have associated ICs and that they satisfy them. In our example, we will assume ICs
ensuring that a vertex can be marked with at most one of male, female and at most one
of adopter, temp adopter, non adopter.
2.2. Generalized Annotated Programs: A Recap

We now recapitulate the definition of generalized annotated logic programs from Kifer
and Subrahmanian [1992]. We assume the existence of a set AVar of variable symbols
ranging over the unit real interval [0, 1] and a set F of function symbols each of which
has an associated arity. We start by defining annotations.
Definition 2.3 (Annotation). Annotations are inductively defined as follows: (i) Any
member of [0, 1] ∪AVar is an annotation.
(ii) If f ∈ F is an n-ary function symbol and t1 , . . . , tn are annotations, then f (t1 , . . . , tn )
is an annotation.
For instance, 0.5, 1, 0.3, and X are all annotations (here X is assumed to be a variable
in AVar). If +, ∗, / are all binary function symbols in F, then (X+1)∗0.5
is an annotation.5
0.3
We define a separate logical language whose constants are members of V and whose
predicate symbols consist of VP ∪ EP. We also assume the existence of a set V of variable symbols ranging over the constants (vertices). No function symbols are present.
Terms and atoms are defined in the usual way (cf. Lloyd [1987]). If A = p(t1 , . . . , tn ) is
an atom and p ∈ VP (resp. p ∈ EP), then A is called a vertex (resp. edge) atom. We will
use A to denote the set of all ground atoms (i.e., atoms where no variable occurs).
Definition 2.4 (Annotated Atom/GAP-rule/GAP). If A is an atom and μ is an annotation, then A : μ is an annotated atom. If A is a vertex (resp. edge) atom, then A : μ
is also called vertex (resp. edge) annotated atom. If A0 : μ0 , A1 : μ1 , . . . , An : μn are
annotated atoms, then
A0 : μ0 ← A1 : μ1 ∧ . . . ∧ An : μn
is called a GAP rule (or simply rule). When n = 0, this rule is called a fact.6 A generalized annotated program (GAP) is a finite set of rules. An annotated atom (resp. a rule,
a GAP) is ground iff there are no occurrences of variables from either AVar or V in it.
Every social network S = (V, E, vert , edge , w) can be represented by the GAP S =
{q(v) : 1 ← | v ∈ V ∧ q ∈ vert (v)} ∪ {ep(v1 , v2 ) : w(v1 , v2 ) ← | v1 , v2  ∈ E ∧
edge (v1 , v2 ) = ep}.
5 Notice that in Kifer and Subrahmanian [1992] annotations are not restricted to be in [0, 1] but any upper

semi-lattice is allowed; for the purpose of this article we will restrict ourselves to the unit real interval.
6 For notational simplicity, we will often write a fact A : μ ← simply as A : μ ; that is, we drop the symbol
0
0
0
0

←.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:7

Definition 2.5 (Embedded Social Network). A social network S is said to be
embedded in a GAP  iff S ⊆ .
It is clear that all social networks can be represented as GAPs. When we augment S
with other rules, such as rules describing how certain properties diffuse through the
social network, we get a GAP  ⊇ S that captures both the structure of the SN and
the diffusion principles. Here is a small example of such a GAP.
Example 2.6. The GAP cell might consist of S using the social network of
Figure 1 plus the GAP-rules:
(1) will adopt(V0 ) : 0.8 × X + 0.2 ← adopter(V0 ) : 1 ∧ male(V0 ) : 1 ∧
IM(V0 , V1 ) : 0.3 ∧ female(V1 ) : 1 ∧ will adopt(V1 ) : X.
(2) will adopt(V0 ) : 0.9 × X + 0.1 ← adopter(V0 ) : 1 ∧ male(V0 ) : 1 ∧
IM(V0 , V1 ) : 0.3 ∧ male(V1 ) : 1 ∧ will adopt(V1 ) : X.
(3) will adopt(V0 ) : 1 ← temp adopter(V0 ) : 1 ∧ male(V0 ) : 1 ∧ email(V1 , V0 ) : 1 ∧ female(V1 ) :
1 ∧ will adopt(V1 ) : 1.

Rule (1) says that if V0 is a male adopter and V1 is female and the weight of V0 ’s
instant messages to V1 is 0.3 or more, and we previously thought that V1 would be
an adopter with confidence X, then we can infer that V0 will adopt the new plan with
confidence 0.8 × X + 0.2. The other rules may be similarly read.
Suppose S is a social network and  ⊇ S is a GAP. In this case, we call the rules
in  − S diffusion rules. In this article we consider a restricted class of GAPs: every rule with a nonempty body has a vertex annotated atom in the head (Kifer and
Subrahmanian [1992] allow any atom to appear in the head of a rule). Thus, edge
atoms can appear only in rule bodies or facts. This means that neither edge weights
nor edge labels change as the result of the diffusion. However, for the general case, it
is possible for them to change as a result of the diffusion process.
GAPs have a formal semantics that can be immediately used. An interpretation I is
any mapping from the set A of all grounds atoms to [0, 1]. The set I of all interpretations can be partially ordered via the ordering: I1  I2 iff for all ground atoms A,
I1 (A) ≤ I2 (A). I forms a complete lattice under the  ordering.
Definition 2.7 (Satisfaction/Entailment). An interpretation I satisfies a ground annotated atom A : μ, denoted I |= A : μ, iff I(A) ≥ μ. I satisfies a ground GAP-rule r
of the form AA0 ← AA1 ∧ . . . ∧ AAn (denoted I |= r) iff either (i) I satisfies AA0 or
(ii) there exists an 1 ≤ i ≤ n such that I does not satisfy AAi . I satisfies a nonground
annotated atom (rule) iff I satisfies all ground instances of it. I satisfies a GAP iff I
satisfies all rules in it. A GAP  entails an annotated atom AA, denoted  |= AA, iff
every interpretation I that satisfies  also satisfies AA.
As shown by Kifer and Subrahmanian [1992], we can associate a fixpoint operator with
any GAP  that maps interpretations to interpretations.
Definition 2.8. Suppose  is any GAP and I an interpretation. The mapping T
that maps interpretations to interpretations is defined as T (I)(A) = sup{μ | A : μ ←
AA1 ∧ . . . ∧ AAn is a ground instance of a rule in  and for all 1 ≤ i ≤ n, I |= AAi }.
Kifer and Subrahmanian [1992] show that T is monotonic (w.r.t. ) and has a least
fixpoint lfp(T ). Moreover, they show that  entails A : μ iff μ ≤ lfp(T )(A) and
hence lfp(T ) precisely captures the ground atomic logical consequences of . They
also define the iteration of T as follows: T ↑ 0 is the interpretation that assigns 0 to
all ground atoms; T ↑ (i + 1) = T (T ↑ i).
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:8

P. Shakarian et al.

The semantics of GAPs requires that when there are multiple ground instances
of GAP-rules with the same head that “fire,” the highest annotation in any of these
ground rules is “chosen” according to the semantics of GAPs. This might seem restrictive and counter-intuitive to some, but it actually is the source of much power of GAPs.
For instance, one school of thought in probabilistic logic programming [Raedt et al.
2007] is that when multiple ground rules with the same head “fire,” the annotation derived should be the “noisy-or” value derived by combining the values of the annotations
in the heads of firing rules. However, this is just one way of combining evidence from
multiple sources7 - many other triangular co-norms other than noisy-or can be used
and have been used in the literature [Bonissone 1987]. However, such co-norms can be
expressed in our framework. If we have ground rules G1 , G2 , . . . , Gn , each having the
same atom in the head, and we want to combine evidence using a triangular co-norm8
⊕, and if Gi has the form:
A : μi ← Bodyi
then we can replace these rules with the rules:
A : ⊕({μi | i ∈ X}) ←



Bodyi

i∈X

for any subset X ⊆ {1, . . . , n}. Moreover, as we have already remarked, many
real-world diffusion models are nonprobabilistic, making assumptions about how
annotations should be combined harder to justify. However, this discussion shows that
the GAP framework is capable of expressing such rules. Though there is clearly a
cost in terms of difficulty of expressing such methods to combine evidence generated
by multiple rules, algorithms already exist and have been implemented [Broecheler
et al. 2010] to learn GAP-based diffusion rules automatically from social network time
series data.
We will show (in Section 4) that many existing diffusion models for a variety of
phenomena can be expressed as a GAP  ⊇ S by adding some GAP-rules describing
the diffusion process to S .
3. SOCIAL NETWORK DIFFUSION OPTIMIZATION PROBLEM (SNDOP) QUERIES
3.1. Basic SNDOP Queries

In this section, we develop a formal syntax and semantics for optimization in social
networks, taking advantage of the aforementioned embedding of SNs into GAPs.
In particular, we formally define SNDOP queries, examples of which have been
informally introduced earlier as (Q1) and (Q2). We see from queries (Q1) and (Q2)
that a SNDOP query looks for a set V of vertices and has the following components:
(i) an objective function expressed via an aggregate operator, (ii) an integer k > 0, (iii)
a set of conditions that each vertex in V must satisfy, (iv) an “input” atom gI (V), and
(v) an “output” atom gO (V) (here gI and gO are vertex predicate symbols, whereas V is
a variable).
7 Thus far, we have not come across any real-world diffusion models that use noisy-OR combinations or

indeed any triangular co-norm [Bonissone 1987] other than the MAX used in this article to combine values
generated by multiple rules having the same head. However should such diffusion models come to light, it
may be appropriate to explore the use of languages such as ProbLog to see if we can “do better” for those
selected diffusion models.
8 When we apply ⊕ to a set {x , . . . , x }, we use ⊕({x , . . . , x }) as short-hand for ⊕(x , ⊕({x , . . . , x })) which
n
1
1
1
2
k
k
is well defined as all triangular co-norms are commutative and associative.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:9

Aggregates. It is clear that in order to express queries like (Q1) and (Q2), we need
aggregate operators which are mappings agg : FM([0, 1] ) → R+ (R+ is the set of nonnegative reals) where FM(X) denotes the set of all finite multisets that are subsets of X.
Relational DB aggregates like SUM,COUNT,AVG,MIN,MAX are all aggregate operators
which can take a finite multiset of nonnegative reals as input and return a single
nonnegative real.
Vertex condition. A vertex condition is a set of vertex annotated atoms containing
exactly one variable (intuitively, such annotated atoms are conditions that must be
jointly satisfied by a vertex). More formally, a vertex condition VC is a set {p1 (V) :
μ1 , . . . , pn (V) : μn } where each pi ∈ VP, V ∈ V, and each μi ∈ [0, 1]. We use VC[V/v]
to denote the set of ground annotated atoms obtained from VC by replacing each occurrence of V with v, that is VC[V/v] = {p1 (v) : μ1 , . . . , pn (v) : μn }. A GAP  entails
VC[V/v], denoted  |= VC[V/v], iff  |= pi (v) : μi for all 1 ≤ i ≤ n.
Thus, in our example, {male(V) : 1, adopter(V) : 1} is a vertex condition, but
{male(V) : 1, email(V, V  ) : 1} is not. We are now ready to define a SNDOP query.
Definition 3.1 (SNDOP query). A SNDOP query is a 5-tuple (agg, VC, k, gI (V),
gO (V)) where agg is an aggregate, VC is a vertex condition, k > 0 is an integer, and
gI (V), gO (V) are vertex atoms.
Let us consider again the medication distribution plan example. Suppose we have a
diffusion model expressing how a property healthy diffuses in a social network w.r.t.
a property immune (which would hold for a vertex when a medication is given to
it). An interesting query to pose would be to determine a set of at most k people
such that if these people were immune to the disease, then the number of healthy
people would be maximized. Such a query can be expressed with the SNDOP query
(SUM, ∅, k, immune(V), healthy(V)). Here, the goal is to find a set V ⊆ V of vertices
such that |V | ≤ k and the following is maximized:
SUM{lfp(T∪{immune(v ):1 | v ∈V } )(healthy(v)) | v ∈ V}
Here, the SUM is applied to a multiset rather than a set. Note that in the given query
VC = ∅, meaning that the immune property can be assigned to any vertex of the
SN. However, other queries can be expressed where VC imposes restrictions on which
vertices can have property immune. As an example, VC = {adult(V)} would enforce
every vertex in V to be an adult person.
If we return to our cell phone example, we can set agg = SUM, VC = ∅, k = 3 (for
example), gI (V) = will adopt(V), and gO (V) = will adopt(V) (notice that in this case
gI (V) = gO (V)). Here also, the goal is to find a set V ⊆ V of vertices such that |V | ≤ 3
and the following is maximized:
SUM{lfp(T∪{will adopt(v ):1 | v ∈V } )(will adopt(v)) | v ∈ V}
Here, the SUM is applied to a multiset rather than a set. Note that the diffusion
model’s impact is captured via the lfp(T∪{will adopt(v ):1 | v ∈V } )(will adopt(v)) expression which, intuitively, tells us the confidence (according to the diffusion model) that
each vertex v will be an adopter. If we return to an extended version of our cell phone
example and we want to ensure that the vertices in V are “good” customers9 then
we merely can set VC = {good(V) : 1}. This query now asks us to find a set V of
9 We can think of many ways a company may define “good” customers, for example, those who regularly pay

their bills on time, those who buy a lot of services from the company, those who have stayed as customers
for a long time, etc. For our example, the specific definition of “good” is not relevant.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:10

P. Shakarian et al.

three or less vertices—all of which are “good” customers of the company C—such that
SUM{lfp(T∪{will adopt(v ):1 | v ∈V } )(will adopt(v)) | v ∈ V} is maximized.
Our framework also allows the vertex condition VC to have annotations other than
1. So in our cell phone example, the company could explicitly exclude anyone whose
“opinion” toward the company is negative. If opinion is quantified on a continuous [0, 1]
scale (such automated systems do exist [Subrahmanian and Recupero 2008]), then the
vertex condition might be restated as VC = {good(V) : 1, negative opinion C(V) : 0.7}
which says that the company wants to exclude anyone whose negativity about the
company exceeds 0.7 according to an opinion scoring engine such as [Subrahmanian
and Recupero 2008].
Definition 3.2 (Pre-answer/Value). Consider a SN S = (V, E, vert , edge , w) embedded in a GAP . A pre-answer to the SNDOP query Q = (agg, VC, k, gI (V), gO (V)) w.r.t.
 is any set V ⊆ V such that:
(1) |V | ≤ k, and
(2) for all vertices v ∈ V ,  ∪ {gI (v ) : 1 | v ∈ V } |= VC[V/v ].
We use pre ans(Q, ) to denote the set of all pre-answers to Q w.r.t.  (whenever  is
clear from the context we simply write pre ans(Q)).
The value of a pre-answer V is defined as follows:
value(V ) = agg({lfp(T ∪ {gI (v ):1 | v ∈V } )(gO (v)) | v ∈ V}),
where the aggregate is applied to a multiset rather than a set. We also note that we
can define value as a mapping from interpretations to reals based on a SNDOP query.
We say value(I) = agg({I(gO (v)) | v ∈ V}).
If we return to our cell phone example, V is the set of vertices to which the company
is considering giving free plans. value(V ) is computed as follows.
(1) Find the least fixpoint of T where cell is cell expanded with facts of the form
cell
will adopt(v ) : 1 for each vertex v ∈ V .
(2) For each vertex v ∈ V (the entire set of vertices, not just V now), we now find the
confidence assigned by the least fixpoint.
(3) Summing up these confidences gives us a measure of the expected number of plan
adoptees.
Definition 3.3 (Answer). Suppose an SN S = (V, E, vert , edge , w) is embedded in a
GAP  and Q = (agg, VC, k, gI (V), gO (V)) is a SNDOP query. A pre-answer V is an
answer to the SNDOP query Q w.r.t.  iff the SNDOP query has no other pre-answer
V such that value(V ) > value(V ).10
The answer set to SNDOP query Q w.r.t. , denoted ans(Q, ), is the set of all answers to Q w.r.t.  (whenever  is clear from the context we simply write ans(Q)).
It is important to note that an answer to an SNDOP query is a set of vertices that
jointly maximize the objective function specified. Thus, it is entirely possible that if we
set k = 1, we could have two answers {a1 } and {a2 } each of which ties for the highest
value. However, {a1 , a2 } may not be the answer that optimizes the objective function
when k = 2.
Example 3.4. For instance, suppose a1 and a2 are brothers with largely the same
connections. The sets {a1 } and {a2 } both have value 100 each and let us say these
10 Throughout this article, we treat only maximization problems; there is no loss of generality in this because

minimizing an objective function f is the same as maximizing −f .

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:11
Table I. Special Cases of SNDOPs
Type

Special Case

Reference

Special cases of 

Linear GAP
Monotonic
Positive-linear
Zero-starting
A-priori VC

Definition 3.6
Definition 3.7
Definition 3.8
Definition 3.10
Definition 3.12

Special cases of agg
Special cases of value

Table II. Properties That Can Be Proven Given Certain Assumptions
Property

Assumptions

Monotonicity of value (Lemma 3.13)
Multiset {V ⊆ V|V is a pre-answer} is a uniform matroid
(Lemma 3.14)

Monotonicity of agg
A-priori VC

Submodularity of value (Theorem 3.15)

Linear GAP
Positive-linear agg
A-priori VC

constitute an answer (looking at one individual only) w.r.t. an objective function, for
instance, influencing voters in an election to vote for candidate X. As a1 , a2 mostly
influence the same people, they may jointly be able to get only 110 people to vote for
the candidate because of the large overlap in their sphere of influence. However, now
consider persons a3 , a4 . Each of them can only influence 90 voters by themselves, but
only 10 of these voters “overlap.” Thus, they can jointly influence 80 + 80 + 10 = 170
voters to vote for X. It would make more sense (all other things being equal) for the
candidate’s party to invest in {a3 , a4 }.
Example 3.5. Consider the GAP cell of Example 2.6 with the social network from
Figure 1 embedded and the SNDOP query Qcell = (SUM, ∅, 3, will adopt, will adopt).
The sets V1 = {v15 , v19 , v6 } and V2 = {v15 , v18 , v6 } are both pre-answers. In the case of
V1 , two applications of the T operator yields a fixpoint where the vertex atoms formed
with will adopt and vertices in the set {v15 , v19 , v6 , v12 , v18 , v7 , v10 } are annotated with
1. For V2 , only one application of T is required to reach a fixpoint. In the fixpoint,
vertex atoms formed with will adopt and vertices in the set {v15 , v6 , v12 , v18 , v7 , v10 }
are annotated with 1. As these are the only vertex atoms formed with will adopt that
have a nonzero annotation after reaching the fixed point, we know that value(V1 ) = 7
and value(V2 ) = 6.
3.2. Special Cases of SNDOPs

In this section, we examine several special cases of SNDOPs that still allow us to represent a wide variety of diffusion models. Table I illustrates the special cases discussed
in this section, while Table II illustrates various properties we prove (and the assumptions under which those properties are proved).
Special Cases of GAPs. First, we present a class of GAPs called linear GAPs. Intuitively, a GAP is linear if the annotations in the rule heads are linear functions and
the annotations in the body are variables. It is important to note that a wide variety
of diffusion models can be represented with GAPs that meet the requirements of this
special case. We formally define linear GAPs as follows.
Definition 3.6 (Linear GAP). A GAP-rule is linear iff it is of the form:
H0 : c0 + c1 · X1 + · · · + cn · Xn ← A1 : X1 ∧ . . . ∧ An : Xn
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:12

P. Shakarian et al.

n c ∈ [0, 1], and each X is a variable in AVar. A GAP is linear
where each ci ∈ [0, 1], i=1
i
j
iff each rule in it is linear.

Note that linear GAPs allow for a wide variety of models to be expressed. Section 4
will show that several well-known network diffusion models can be embedded into our
framework. Diffusion Models 4.2 and 4.4, reported in Section 4, are linear GAPs while
Diffusion Models 4.1 and 4.3 are not.
Special Aggregates. We define two types of aggregates: monotonic aggregates and
positive-linear aggregates.
To define monotonicity, we first define a partial order  on multisets of numbers as
follows: given two multisets of numbers X1 and X2 , we write X1  X2 iff there exists
an injective mapping β : X1 → X2 such that ∀x1 ∈ X1 , x1 ≤ β(x1 ).
Definition 3.7 (Monotonic Aggregate). An aggregate agg is monotonic iff whenever X1  X2 , it is the case that agg(X1 ) ≤ agg(X2 ).
Definition 3.8 (Positive-Linear Aggregate). An aggregate agg is positive-linear iff
it is defined as follows: agg(X) = c0 + xi ∈X ci · xi , where X is a finite multiset and ci ≥ 0
for all i > 0.
In the previous definition, note that c0 can be positive, negative, or 0. Thus, we require only that the coefficients associated with the elements of the multiset be positive;
we allow for an additive constant to be negative. One obvious example of a positivelinear aggregate is SUM. Moreover, any positive weighted sum will also meet these
requirements.
P ROPOSITION 3.9.
aggregate.

If agg is a positive-linear aggregate, then it is a monotonic

Special cases of the query. We now describe two special cases of the query:
zero-starting and a-priori VC SNDOP queries. Intuitively, zero-starting means that
value(∅) = 0.
Definition 3.10 (Zero-starting). An SNDOP query is zero-starting w.r.t. a given social network S and a GAP  ⊇ S iff value(∅) = 0.
Note that the function value is uniquely defined by a social network, a SNDOP query,
and a diffusion model  and hence this definition is well defined.
The following result states that if an SNDOP query Q with a positive-linear aggregate is not zero-starting, then we can always modify it into an “equivalent” SNDOP
query Q (i.e., ans(Q) = ans(Q )) which is zero-starting and still maintains a positivelinear aggregate.
P ROPOSITION 3.11. Let Q = (agg, VC, k, gI (V), gO (V)) be a SNDOP query which
is not zero-starting w.r.t. a social network S and a GAP  ⊇ S , and where agg is
positive-linear. Let agg (X) = agg(X) − value(∅). Then, Q = (agg , VC, k, gI (V), gO (V))
is a SNDOP query which is zero-starting w.r.t. S and , ans(Q) = ans(Q ), and agg is
positive-linear.
Recall that in order to check if a set of vertices V is a pre-answer, we need to check
for all vertices v ∈ V if  ∪ {gI (v ) : 1 | v ∈ V } |= VC[V/v ] (see condition (2) of
Definition 3.2). Intuitively, a SNDOP query has an A-Priori VC (w.r.t. a given social
network S and a GAP  ⊇ S ) when we can check this condition by looking only at
the original social network S (thereby disregarding ), that is we can check for all
vertices v ∈ V if S ∪ {gI (v ) : 1} |= VC[V/v ]. We formally define this notion as
follows.
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:13
Table III. How the Various Properties are Leveraged in the Algorithms
Algorithm

Property

Exact algorithm with pruning (Section 5.2)

Monotonicity of value
Submodularity
Zero-starting
Uniform matroid for the pre-answers

Approx. Ratio on Greedy Algorithm (Section 5.3)

Definition 3.12 (A-Priori VC). A SNDOP query Q = (agg, VC, k, gI (V), gO (V)) has
an A-Priori VC w.r.t. a given social network S = (V, E, vert , edge , w) and a GAP  ⊇ S
iff for each V ⊆ V the following holds: for each v ∈ V ,  ∪ {gI (v ) : 1 | v ∈ V } |=
VC[V/v ] iff S ∪ {gI (v ) : 1} |= VC[V/v ].
If, in the cell phone example, we require that the free cell phones are given to “good”
vertices, then query (Q1) is a-priori VC because being “good” may be defined statically
and is not determined by the diffusion process. Likewise, if we consider our medical
example, in the case of an a-priori VC query (Q2) saying that an individual below 5
should not get the medicine, this boils down to a static labeling of each node’s age
(below 5 or not) which is not affected by the diffusion process.
3.3. Properties of SNDOPs

In this section, we will prove several useful properties of SNDOPs that use various
combinations of the assumptions presented in the previous section. Later, we will
leverage some of these properties in our algorithms. Table II summarizes the different properties that we prove in this section (as well as what assumptions we make
to prove these properties). Table III shows how these properties are leveraged in the
algorithms that we will present later in the article.
We say that function value is monotonic iff V1 ⊆ V2 implies value(V1 ) ≤ value(V2 )
for any two sets of vertices V1 and V2 . The first property we show is that the value
function is monotonic if agg is monotonic.
L EMMA 3.13. Given a SNDOP query Q = (agg, VC, k, gI (V), gO (V)), a social network S, and a GAP  ⊇ S , if agg is monotonic (Definition 3.7), then value (defined as
per Q and ) is monotonic.
Before introducing the next result we recall the definitions of matroid and uniform
matroid. A matroid is a pair (X, I) where X is a finite set and I is a collection of subsets
of X (called “independent”), satisfying two axioms:
(1) B ∈ I, A ⊂ B ⇒ A ∈ I.
(2) A, B ∈ I, |A| < |B| ⇒ ∃x ∈ B − A s.t. A ∪ {x} ∈ I.
A uniform matroid is a matroid such that independent sets are all sets of size at most
k for some k ≥ 1.
Next, we show that the set of pre-answers is a uniform matroid in the special case
of an a-priori VC query.
L EMMA 3.14. Given a SNDOP query Q = (agg, VC, k, gI (V), gO (V)), a social network S, and a GAP  ⊇ S , if Q is a-priori VC w.r.t. S and , then the set of preanswers is a uniform matroid.
As we will see in Section 5, this lemma (along with other properties; see Theorem 5.8)
enables us to define a greedy approximation algorithm to solve SNDOP queries that
achieves the best possible approximation ratio that a polynomial algorithm can achieve
(unless P = NP).
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:14

P. Shakarian et al.

Fig. 2. Social network corresponding with Example 3.16 concerning disease spread.

An important property in social networks is submodularity whose relationship to the
spread of phenomena in social networks has been extensively studied [Kleinberg 2008;
Leskovec et al. 2007a; Mossel and Roch 2007]. If X is a set, then a function f : 2X → R
is submodular iff whenever X1 ⊆ X2 ⊆ X and x ∈ X − X2 , f (X1 ∪ {x}) − f (X1 ) ≥
f (X2 ∪ {x}) − f (X2 ). The following result states that the value function associated with
a linear GAP and an a-priori VC SNDOP query whose aggregate is positive-linear is
guaranteed to be submodular.
T HEOREM 3.15. Given an SNDOP query Q = (agg, VC, k, gI (V), gO (V)), a social
network S, and a GAP  ⊇ S , if the following criteria are met:
—  is a linear GAP,
— Q is a-priori VC, and
— agg is positive-linear,
then value (defined as per Q and ) is sub-modular.
In other words, for Vcond ≡ {v |v ∈ V and (S ∪ {gI (v ) : 1} |= VC[V/v ] )}, if V1 ⊆ V2 ⊆
Vcond and v ∈ Vcond − V2 , then the following holds:
value(V1 ∪ {v}) − value(V1 ) ≥ value(V2 ∪ {v}) − value(V2 )
P ROOF S KETCH . Consider a linear polynomial with a variable for each vertex in the
set of vertices that meet the a-priori VC, where setting the variable to 1 corresponds
to the vertex being picked and setting it to 0 indicates otherwise. For any subset of
vertices meeting the a-priori VC, there is an associated polynomial of this form such
that when the variables corresponding to the vertices are set to 1 (and the rest set to 0),
the answer is equal to the corresponding value for that set. For a sets V1 , V2 and vertex
v (as per the statement), we show that submodualirty holds by manipulating such
polynomials.
Example 3.16. We now show an example of a SNDOP query and a nonlinear GAP
for which the value function is not sub-modular. Figure 2 shows a social network with
one edge predicate, e – all edges are weighted with 1. Nodes in the network are either
susceptible to the disease (circles) or carriers (diamonds) - the associated predicates are
suc and car respectively. Additionally, we have the predicates inf, exp denoting vertices
that have been infected by or exposed to the disease. No vertex is initially exposed or
infected in the social network of Figure 2.
Let disease be the embedding of this network plus the following diffusion rules.
exp(V) : 1 ← inf(V) : 1
exp(V) : 1 ← e(V  , V) : 1 ∧ inf(V  ) : 1 ∧ suc(V) : 1
 

Ii
inf(V) :  i
(edge(Vi , V) : Ei ∧ inf (Vi ) : Ii )
← exp(V) : 1 ∧
i Ei
Vi |(Vi ,V)∈E

Intuitively, the second rule says that a vertex becomes exposed if that vertex is susceptible and it has at least one incoming neighbor that is infected. The third rule
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:15

states that a vertex becomes infected if it is exposed and all its incoming neighbors are
infected.
Consider the function value defined as per the SNDOP query (SUM, ∅, 2, inf (V),
inf (V)) and disease . Obviously, as the GAP is not linear, it does not meet the requirements of Theorem 3.15 to prove submodularity. We can actually show through counterexample, that this SNDOP query is not submodular. Consider the following:
value({v1 , v5 }) − value({v1 }) = 1
(here value({v1 , v5 }) = 2 and value({v1 }) = 1) and
value({v1 , v7 , v5 }) − value({v1 , v7 }) = 4
(here value({v1 , v7 , v5 }) = 7 and value({v1 , v7 }) = 3).
This shows a clear violation of submodularity.
As an example of how the values above are determined, consider value({v1, v5}).
Notice that the third rule of disease is the only one that can be used to propagate the
inf property, but in order for a vertex V to get infected using this rule, V has to be
exposed first (and all its incoming neighbors have to be infected). When v1 and v5 are
assumed to be infected, v4 gets exposed (v1 and v5 get exposed as well because of the
first rule). At this point, the exposed property cannot be propagated any further, and
no vertex can get infected because no vertex is both exposed and has all its incoming
neighbors infected (notice that v4 cannot get infected because v6 is not infected). Thus,
value({v1 , v5 }) = 2.
3.4. The Complexity of SNDOP Queries

We now study the complexity of answering an SNDOP query. First, we show that
SNDOP query answering is NP-hard by a reduction from max k-cover [Feige 1998].
We show that the problem is NP-hard even when many of the special cases hold.
T HEOREM 3.17. Finding an answer to an SNDOP query Q = (agg, VC,
k, gI (V), gO (V)) (w.r.t. a social network S and a GAP  ⊇ S ) is NP-hard (even if 
is a linear GAP, VC = ∅, agg = SUM and value is zero-starting).
P ROOF S KETCH . The known NP-hard problem of MAX-K-COVER [Feige 1998] is
defined as follows.
INPUT: Set of elements, S and a family of subsets of S, H ≡ {H1 , . . . , Hmax }, and positive integer K.
OUTPUT: Less than or equal to K subsets from H such that the union of the subsets
covers a maximal number of elements in S.
We show that MAX-K-COVER can be embedded into a social network and that the
corresponding SNDOP query gives an optimal answer to MAX-K-COVER. The embedding is done by creating a social network resembling a bipartite graph, where vertices represent either the elements or the subsets from the input of MAX-K-COVER.
For every vertex pair representing a set and an element of that set, there is an
edge from the set vertex to the element vertex. A single vertex and edge predicate
are used - vertex and edge. A single nonground diffusion rule is added to the GAP:
vertex(V) : X ← vertex(V  ) : X ∧ edge(V  , V) : 1. The aggregate is simply the sum of
the annotations associated with the vertex atoms. We show that the picked vertices
that maximize the aggregate correspond with picked subsets that maximize output
of the problem. Also, as we do not use VC, the GAP is linear, and the aggregate is
positive-linear, we know that the value function is submodular.
Under some conditions, the decision problem for SNDOP queries is also in NP.
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:16

P. Shakarian et al.

T HEOREM 3.18. Given a SNDOP query Q = (agg, VC, k, gI (V), gO (V)), a social network S, a GAP  ⊇ S , and a real number target, the problem of checking whether
there exists a pre-answer V s.t. value(V ) ≥ target is in NP under the assumptions that
agg and the functions in F are polynomially computable, and  is ground.
Most common aggregate functions like SUM, AVERAGE, Weighted average, MIN,
MAX, COUNT are all polynomially computable. Moreover, the assumption that the
functions corresponding to the function symbols in F (i.e., the function symbols
that can appear in the annotations of a GAP) are polynomially computable is also
reasonable.
Later in this article, we shall address the problem of answering a SNDOP query
using an approximation algorithm. We now restate the definition of approximation
[Garey and Johnson 1979].
Definition 3.19 (Approximation). Consider a maximization problem and let OPT(I)
denote the value of an optimal solution for an instance I of the problem. An αapproximation algorithm A is an algorithm that for any instance I finds a candidate
solution such that
OPT(I) ≤ α · A(I),
where A(I) denotes the value of the solution found by A for instance I.
Based on this definition, we shall say that V is a α1 -approximation to an SNDOP
query if value(Vopt ) ≤ α · value(V ) (where Vopt is an answer to the SNDOP query).
Likewise, the algorithm that produces V in this case is an α-approximation algorithm.
We note that due to the nature of the reduction from MAX-K-COVER that we used
to prove NP-hardness, we can now show that unless P = NP, there is no PTIMEapproximation of the SNDOP query answering problem that can guarantee that the
approximate answer is better than 0.63 of the optimal value. This gives us an idea
of the limits of approximation possible for a SNDOP query with a polynomial-time
algorithm. Later, we will develop a greedy algorithm that precisely matches this approximation ratio.
T HEOREM 3.20. Answering a SNDOP query Q = (agg, VC, k, gI (V), gO (V)) (w.r.t. a
social network S and a GAP  ⊇ S ) cannot be approximated in PTIME within a ratio
of e−1
e +  for some  > 0 (where e is the inverse of the natural log) unless P = NP – even
if  is a linear GAP, VC = ∅, agg = SUM and value is zero-starting.
In other words, the previous theorem says that there is no polynomial-time
algorithm that can approximate value within a factor of about 0.63 under standard
assumptions.
3.5. Counting Complexity of SNDOP-Queries

In this section, we ask the question: how many answers are there to a SNDOP query
(agg, VC, k, gI (V), gO (V))? In the case of the cell phone example, this corresponds to
asking “How many sets ANS of people are there in the the network such that ANS
has k or fewer people and ANS optimizes the aggregate, subject to the vertex condition
VC?” If there are m such sets ANS1 , . . . , ANSm , this means the cell phone company can
give the free cell phone plan to either all members of ANS1 or to all members of ANS2 ,
and so forth. The “counting complexity” problem of determining m is is #P-complete.
T HEOREM 3.21. Counting the number of answers to a SNDOP query Q (w.r.t. a
social network S and a GAP  ⊇ S ) is #P-complete.
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:17
3.6. The SNDOP-ALL Problem

Suppose the cell phone company wants to identify all the “most influential” users, that
is, the users that when considered individually (and not as a set) yield a maximum
expected number of plan adoptees. This might be computed by taking the union of all
the answers to query (Q1) with k = 1. For instance, if we consider the hypothetical
example of the political candidate (Example 3.4), the candidate may also want to know
all the top influencers when considered individually. In this case, vertices a1 , a2 would
emerge in the answer to a SNDOP-ALL query defined as follows.
Although the counting version of the query is #P-hard, finding the union of all answers to a SNDOP query is no harder than a SNDOP query (w.r.t. polynomial-time
Turing reductions). We shall refer to this problem as SNDOP-ALL; and it reduces both
to and from a regular SNDOP query (w.r.t. polynomial-time Turing reductions).
We start with the following result, showing that we can answer a SNDOP query in
PTIME with an oracle to SNDOP-ALL.
T HEOREM 3.22. Given a SNDOP query Q = (agg, VC, k, gI (V), gO (V)), a social network S, and a GAP  ⊇ S ), there exists a polynomial-time algorithm with an oracle
to SNDOP-ALL which answers Q.
P ROOF S KETCH . We embed a SNDOP query in a SNDOP-ALL query via the following informal algorithm (FIND-SET) that takes an instance of SNDOP-ALL (Q) and
some vertex set V ∗ , |V ∗ | ≤ k.
(1) If |V ∗ | = k, return V ∗
(2) Else, solve SNDOP-ALL(V ∗ ), returning set V  .
(a) If V  − V ∗ ≡ ∅, return V ∗
(b) Else, pick v ∈ V  − V ∗ and return FIND-SET(Q, V ∗ ∪ v)
The following theorem shows that SNDOP-ALL can be answered in PTIME with an
oracle to a SNDOP query.
T HEOREM 3.23. Given a SNDOP query
 Q = (agg, VC, k, gI (V), gO (V)), a social network S, and a GAP  ⊇ S ), finding V ∈ans(Q) V reduces to |V| + 1 SNDOP queries,
where V is the set of vertices of S.
P ROOF S KETCH . Using an oracle that correctly answers SNDOP queries, we can
answer a SNDOP-ALL query by setting up |V| SNDOP queries as follows:
— Let kall be the k value for the SNDOP-ALL query and for each SNDOP query i, let
ki be the k for that query. For each query i, set ki = kall − 1.
— Number each element of vi ∈ V such that gI (vi ) and VC(vi ) are true. For the ith
SNDOP query, let vi be the corresponding element of V
— Let i refer to the GAP associated with the ith SNDOP query and all be the
program for SNDOP-ALL. For each program i , add fact gI (vi ) : 1
— For each SNDOP query i, the remainder of the input is the same as for
SNDOP-ALL.
After the construction, do the following:
(1) We shall refer to a SNDOP query that has the same input as SNDOP-ALL as the
(pri)
(pri)
“primary query.” Let Vans
be an answer to this query and value(Vans
) be the
associated value.
(i)
(i)
(2) For each SNDOP query i, let Vans be an answer and value(Vans ) be the associated value.
(3) Let V , the solution to SNDOP-ALL be initialized as ∅.
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:18

P. Shakarian et al.
(i)

(4) For each SNDOP query i, if value(Vans ) = value(Vans
vi to V .

(pri)

), then add vertex

4. APPLYING SNDOPS TO REAL DIFFUSION PROBLEMS

In this section, we show how SNDOPs can be applied to real-word diffusion problems.
Most diffusion models in the literature fall into one of three categories: tipping models
(Section 4.1), where a given vertex adopts a behavior based on the ratio of how many
of its neighbors previously adopted the behavior, cascade models (Section 4.2), where
a property passes from vertex to vertex solely based on the strength of the relationship between the vertices, and homophilic models (Section 4.3), where vertices with
similar properties tend to adopt the same behavior; irrespective (or in addition to) of
network relationships. None of these approaches solves SNDOP queries; they merely
specify diffusion models rather than performing the kinds of optimizations that we
perform in SNDOP queries.
4.1. Tipping Diffusion Models

Tipping. models [Centola 2010; Granovetter 1978; Schelling 1978] have been studied
extensively in economics and sociology to understand diffusion phenomena. In tipping
models, a vertex changes a property based on the cumulative effect of its neighbors. In
this section, we present the tipping model of Jackon-Yariv [Jackson and Yariv 2005],
which generalizes many existing tipping models.
The Jackson-Yariv Diffusion Model [Jackson and Yariv 2005]. In this framework,
the social network is just an undirected graph G = (V , E ) consisting of a set of
agents (e.g., people). Each agent has a default behavior (A) and a new behavior (B).
Suppose di denotes the degree of a vertex vi . Jackson and Yariv [2005] use a function γ : {0, . . . , |V | − 1} →[0, 1] to describe how the number of neighbors of v affects
the benefits to v for adopting behavior B. For instance, γ (3) specifies the benefits (in
adopting behavior B) that accrue to an arbitrary vertex v ∈ V that has three neighbors. Let πi denote the fraction of neighbors of vi that have adopted behavior B. Let
constants bi and ρi be the agent-specific benefit and cost, respectively, for vertex vi to
adopt behavior B. Jackson and Yariv [2005] state that node vi switches to behavior B
iff bρi · γ (di ) · πi ≥ 1.
i
Returning to our cell-phone example, one could potentially use this model to describe
the spread of the new plan. In this case, behavior A would be adherence to the current
plan the user subscribes to, while B would be the use of the new plan. The associated
SNDOP query would find a set of nodes which, if given a free plan, would jointly maximize the expected number of adoptees of the plan. Cost and benefit could be computed
from factors such as income, time invested in switching plans, etc. We show how the
model of Jackson and Yariv [2005] can be expressed via GAPs.
Diffusion Model 4.1 (Jackson-Yariv model). Given a Jackson-Yariv model consisting of G = (V , E ), we can set up a social network S = (V , E , vert , edge , w) as follows.
We define E = {(x, y), (y, x) | (x, y) ∈ E }. We have a single edge predicate symbol edge
which is assigned by edge to every edge in E , and w assigns 1 to all edges in E . Our
associated GAP JY now consists of S plus one rule of the following form for each
vertex vi :
⎢
⎥
⎛
⎞ 
⎢
⎥


Xj ⎥
⎢ bi
j
⎝
⎠
⎣
⎦←
B(vi ) :
·γ
Ej · 
(edge(vj , vi ) : Ej ∧ B(vj ) : Xj )
ρi
j Ej

j

vj |vj ,vi ∈E

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:19

Fig. 3. Social network of individuals sharing photographs.

It is easy to see that this rule (when applied in conjunction with S for a social
network S) precisely encodes the Jackson-Yariv semantics.
We notice right away that the given GAP is not linear. However, if we eliminate the
floor function and impose certain restrictions on the coefficients appearing in the head
of the rules, then we obtain a linear GAP that represents a variant of this model where
the annotation would represent a “confidence” that an agent adopts behavior B. The
idea of the confidence of an agent represented by a vertex adopting a certain behavior
as a function of his adopting neighbors is suggested in the experiment of Centola [2010]
where he observed that the preference for a new behavior increases monotonically with
the number of incoming neighbors who previously adopted said behavior. Such a linear
GAP model is presented here.
Diffusion Model 4.2 (Linear Jackson-Yariv model). For each vertex vi let
⎛
⎞

bi
1
ci =
·γ ⎝
w(vj , vi )⎠ · 
.
ρi
vj |vj ,vi ∈E w(vj , vi )

vj |vj ,vi ∈E

If for each vertex vi , ci ∈ [0, 1] and |{vj | vj , vi  ∈ E }| × ci ≤ 1, then we can derive a
linear GAP for the Jackson-Yariv model that consists of one rule of the following form
for each vertex vi


B(vi ) : ci
Xj ←
B(vj ) : Xj .
j

vj |vj ,vi ∈E

Notice that this rule is similar to the one in Diffusion Model 4.1, but the floor function has been dropped and restrictions on the ci ’s are imposed to make the rule linear.
Example 4.1. Figure 3 illustrates a social network of individuals who share photographs. Each edge is labeled with the predicate share and has weight 1. The only
vertex predicate we consider in this case is buys camera.
A vendor wishes to sell a camera and wants to see how the popularity of the camera
will spread in the network. He wants to use a Jackson-Yariv style diffusion model.
Suppose the social network is embedded into GAP  which has one Jackon-Yariv style
tipping diffusion rule of the following form for each vertex v:



j Xj
buys camera(v) : 
(shares(vj , v) : Ej ∧ buys camera(vj ) : Xj ).
←
j Ej
vj |vj ,v∈E

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:20

P. Shakarian et al.
Table IV. Comparison between Standard and Linear Jackson-Yariv Models
Vertex Atom
buys
buys
buys
buys
buys
buys
buys
buys
buys
buys

Annotation Assigned by
lfp(Tcamera ∪{buys camera(v2 ):1} )

Annotation Assigned by
lfp(T ∪{buys camera(v2 ):1} )

0.0
1.0
1.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0

0.5
1.0
1.0
0.0
0.0
0.0
0.25
0.5
0.5
0.5

2

4.25

camera(v1 )
camera(v2 )
camera(v3 )
camera(v4 )
camera(v5 )
camera(v6 )
camera(v7 )
camera(v8 )
camera(v9 )
camera(v10 )

SUM

lin

We will call the GAP with this diffusion rule standard . Alternatively, we could have a
linear version of it as follows:


j Xj
buys camera(v) :
buys camera(vj ) : Xj .
←
|{vj |vj , v}|
vj |vj ,v∈E

We will call the GAP formed with the previous kind of diffusion rules lin . In this case,
it is clear that each rule head is annotated with the linear expression:
co + c1 · X1 + . . . + c|{vj |(vj ,v)∈E}| · X|{vj |(vj ,v)∈E}|
Here, c0 = 0 and for all i > 0 we have
ci =

1
.
|{vj |(vj , v) ∈ E}|

Clearly, each ci ∈ [0, 1] and the sum of all these constants is 1, which gives us linearity in accordance with Definition 3.6. Table IV shows the least fixed point for the
two different GAPs (original JY model and the linear version) that arise when we assign an annotation of 1 to vertex atom buys camera(v2 ); it also shows the sum of the
annotations.
4.2. Cascading Diffusion Models

In a cascading model, a vertex obtains a property from one of its neighbors, typically
based on the strength of its relationship with the neighbor. These models were introduced in the epidemiology literature in the early 20th century, but gained increased
notice with the seminal work of Anderson and May [1979]. Recently, cascading diffusion models have been applied to other domains as well. For example, Cha et al. [2008]
(diffusion of photos in Flickr) and Sun et al. [2009] (diffusion of bookmarks in FaceBook) both look at diffusion process in social networks as “social cascades” of this type.
In this section, we present an encoding of the popular SIR model of disease spread in
our framework.
The SIR Model of Disease Spread. The SIR (susceptible, infectious, removed) model
of disease spread [Anderson and May 1979] is a classic disease model which labels each
vertex in a graph G = (V, E) (of humans) with susceptible if it has not had the disease
but can receive it from one of its neighbors, infectious if it has caught the disease and
trec units of time have not expired, and removed when the vertex can no longer catch
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:21

or transmit the disease. The SIR model assumes that a vertex v that is infected can
transmit the disease to any of its neighbors v with a probability pv,v for trec units of
time. It is assumed that becoming infected takes precisely a time unit. We would like
to find a set of at most k vertices that would maximize the expected number of vertices
that become infected. These are obviously good candidates to treat with appropriate
medications.
Diffusion Model 4.3 (SIR model). Let S = (V, E, vert , edge , w) be an SN where each
edge is labeled with the predicate symbol e and w(v, v ) = pv,v assigns a probability of
transmission to each edge. We use the predicate inf to designate the initially infected
vertices. In order to create a GAP SIR capturing the SIR model of disease spread, we
first define trec predicate symbols rec1 , . . . , rectrec where reci (v) intuitively means that
node v was infected i days ago. Hence, rectrec (v) means that v is “removed.” We embed S
into GAP SIR by adding the following diffusion rules. If trec > 1, we add a nonground
rule for each i = {2, . . . , trec } - starting with trec :

inf(V) : (1 − R) · PV  ,V

reci (V) : R ← reci−1 (V) : R
rec1 (V) : R ← inf(V) : R
· PV  · (1 − R ) ← rectrec (V) : R ∧ e(V  , V) : PV  ,V ∧
inf(V  ) : PV  ∧ rectrec (V  ) : R .

The first rule says that if a vertex is in its (i − 1)’th day of recovery with confidence
R in the j’th iteration of the TSIR operator, then the vertex is i days into recovery
(with the same confidence) in the j + 1’th iteration of the operator. Likewise, the second
rule intuitively encodes the fact that if a vertex became infected with confidence R in
the j’th iteration of the TSIR operator, then the vertex is one day into recovery in the
j + 1’th iteration of the operator with the same confidence. The last rule says that if a
vertex V  was infected with confidence PV  and has not been removed with confidence
1 − R , and there is an edge from V  to V in the social network (weighted with PV  ,V ),
given the confidence 1 − R that V has not already been removed, then the confidence
that the vertex V gets infected is (1 − R) · PV  ,V · PV  (1 − R ). Here, PV  (1 − R ) is one
way of measuring the confidence that V  is infected and has not recovered and PV  ,V is
the confidence of infecting the neighbor. Notice that e is a static property of the graph
which does not change over the time, so we do not need time indexes for it. As for inf ,
the reason why we can avoid using time indexes is that we can keep track of how much
time has gone since a vertex got infected with the predicates reci using the second rule.
To see how this GAP works, we execute a few iterations of the TSIR operator and
show the fixpoint that it reaches on the small graph shown in Figure 4. In this graph,
the initial infected vertices are those shown as a shaded circle. The transmission probabilities weight the edges in the graph.
The SNDOP query (SUM, ∅, k, inf , inf ) can be used to compute the expected number
of infected vertices in the least fixpoint of T . This query says “find a set of at most k
vertices in the social network which, if infected, would cause the maximal number of
vertices to become infected in the future.” However, this set of rules can be easily used
to express other things. For instance, an epidemiologist may not be satisfied with only
one set of k vertices that can cause the disease to spread to the maximum extent, as
there may be another, disjoint set of k vertices that could cause the same effect. The
epidemiologist may want to find all members of the population, that if present in a
group of size k could spread the disease to a maximum extent. This can be answered
using a SNDOP-ALL query, described in Section 3.
The SIS Model of Disease Spread. The SIS (Susceptible-Infectious-Susceptible)
model [Hethcote 1976] is a variant of the SIR model where an individual becomes
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:22

P. Shakarian et al.

Fig. 4. Left: Sample network for disease spread. Right: annotated atoms entailed after each application of
TSIR (maximum, nonzero annotations only).

susceptible to disease after recovering (as opposed to SIR, where an individual acquires permanent immunity). SIS can be easily represented by a simple modification
to the SIR model.
Diffusion Model 4.4 (SIS model). Take Diffusion Model 4.3 and change the third
rule to
inf(V) : PV  ,V · PV  · (1 − R ) ← e(V  , V) : PV  ,V ∧ inf(V  ) : PV  ∧ rectrec (V  ) : R .
Here, we do not consider the probability that vertex V is immune – hence the probability of recovery does not change the probability of becoming infected.
Diffusion in the Flickr Photo Sharing Network. The Flickr social network allows
users to share photographs. Users create a list of “favorite” photos that can be viewed
by other users. Cha et al. [2008] use a variant of SIS above to study how photographs
spread to the favorite lists of different users. A key difference is that they do not consider a node “recovered”; that is, once a photo was placed on a favorite list, it was
relatively permanent (the study was conducted over about 100 days). They also found
that photos lower on a favorite list (as the result of a user marking a large number of
photos as “favorite”) for a given user could still spread through the network. A simple
GAP that captures the intuition of how Flickr photos spread according to Cha et al.
[2008] uses just one rule:
Diffusion Model 4.5 (Flickr Photo Diffusion).
photoi (V) : consti · Xi ← connected to(V  , V) : 1 ∧ photoi (V  ) : Xi
In Diffusion Model 4.5, the annotation of the vertex atom photoi (V) is the confidence
that vertex V has marked photo i as one of its favorites. The predicate connected to is
the sole edge label representing that there is a connection from vertex V  to V (users
select other users on this network). Additionally, the value consti is a number in [0, 1]
that determines how a given photo spreads in the network. Notice that this rule is
linear, as the head is a linear combination and consti ∈ [0, 1]. We note that for all of
these models, the annotation functions reflect one interpretation of the confidence that
a vertex is infected or recovered – others are possible in our framework.
4.3. Homophilic Diffusion Models

Recently, Aral et al. [2009] studied the spread of mobile application use on a global
instant-messaging network of over 27 million vertices. They found that network-based
diffusion could overestimate the spread of a mobile application and, for this scenario,
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:23

over 50% of the adopted use of the applications was due to homophily: vertices
with similar properties adopting similar applications. Further, the recent experiment
of Centola [2011] illustrates that homophily plays a role in enhancing adoption under
the tipping model.
These results should not be surprising; the basic idea behind web-search advertising
is that two users with a similar property (search term) will be interested in the same
advertised item. In fact, Cha et al. [2008] explicitly preprocessed their Flickr dataset
with a heuristic to eliminate properties attached to vertices that could not be accounted
for by a diffusion process. We can easily represent homophilic diffusion in a GAP with
the following type of diffusion rule:
Diffusion Model 4.6 (Homophilic Diffusion of a Product).
buys product(V) : 0.5 × X ← property(V) : 1 ∧ exposed to product(V) : X
In Diffusion Model 4.6, if a vertex is exposed to a product (e.g., through mass advertising) and has a certain property, then the person associated with the vertex purchases the product with a confidence of 0.5 × X, where X measures the extent of the
exposure. For this rule, there are no network effects.
Watts and Peretti [2007] propose a “big seed” marketing approach that combines
both homophilic and network effects. They outline a strategy of advertising to a large
group of individuals who are likely to spread the advertisement further through network effects. We now describe a GAP that captures the ideas underlying big seed marketing. Suppose we have a set of vertex predicate symbols AL ⊆ VP corresponding to
people “attributes”—these may be certain demographic characteristics such as education level, race, level of physical fitness, etc.. Suppose we want to advertise to people
having (at least) one of k ≤ |AL| attributes to maximize an aggregate agg with respect
to a goal predicate g (in other words, we want to choose k attributes and advertise to
people having those attributes so that agg with respect to g is maximized). Consider
the following construction.
Diffusion Model 4.7 (Big Seed Marketing). The GAP includes an embedding of the
social network as well as the network diffusion model of the user’s choice. We make
the the following additions to the GAP and the SN:
(1) Add vertex predicate symbol attrib to VP.
(2) For each lbl ∈ AL, add a vertex vlbl to V. We also set vert (vlbl ) = {attrib}.
(3) For each lbl ∈ AL, add the following nonground rule:
g(V) : eff lbl × X ← lbl(V) : 1 ∧ g(vlbl ) : X
where eff lbl is a constant in [0, 1] corresponding to the confidence that, if advertised
to, a vertex v with attribute lbl obtains an annotation of 1 on g(v).
Our SNDOP query is (agg, VC, k, g(V), g(V)), where VC = {attrib(V) : 1}.
Note that in this diffusion model, the vlbl vertices correspond to advertisements directed toward different vertex properties. The VC condition forces the query to only
return vlbl vertices. As an example, a solution like {g(vlbl1 ), g(vlbl2 )} means that we are
targeting people having attribute lbl1 or lbl2 . The diffusion rule, added per label, ensures that the mass advertisement is received and that the vertex acts accordingly
(hence the efflbl constants).
We close this section with a note that while all diffusion models mentioned here have
been developed by others and have been shown to be representable via GAPs, none of
these papers has developed algorithms to solve SNDOP queries. We emphasize that
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:24

P. Shakarian et al.

not only do we give algorithms to answer SNDOP queries in the next section, our
algorithms take any arbitrary diffusion model that can be expressed as a GAP, and an
objective function as input. In addition, our notion of a social network is much more
general than that of many existing approaches.
5. ALGORITHMS

In this section we study how to solve SNDOPs algorithmically.
5.1. Naive Algorithm

The naive algorithm for solving a SNDOP query is to first find all pre-answers to
the query. Then compute the function value for each pre-answer and find the best.
This is obviously an extremely expensive algorithm that is unlikely to terminate in a
reasonable amount of time.
An execution strategy that first finds all vertices in a social network S that satisfy
the vertex condition and then somehow restricts interest to those vertices in the given
computation (where S is embedded in a GAP ) would not be correct for two reasons.
First, lfp(T ) assigns a truth value to each ground vertex atom A that might be different from what is initially assigned within the social network. Second, when we add
a new ground vertex atom A to  (e.g., in our cell phone example, when we consider
the possibility of assigning a free calling plan to a vertex v), it might be the case that
vertices that previously did not satisfy the vertex condition VC do so after the addition
of A to .
5.2. A Nonground Algorithm in the Monotonic Case

There are three major problems with the Naive algorithm. The first problem is that the
aggregate function is very general and has no properties that we can take advantage
of. Hence, we can show that the entire search space might need to be explored if an arbitrary aggregate function is used. The second problem is that it works on the “ground”
instantiation of . The third problem is that the T operator maps all ground atoms
to the [0, 1] interval and there can be a very large number of ground atoms to consider.
For instance, if we have a very small social network with just 1000 vertices and a rule
with 3 variables in it, that rule has 109 possible ground instances: an enormous number. All these problems are further aggravated by the fact that fixpoints might have to
be computed several times.
In this section, we provide an algorithm to compute answers to a SNDOP query under the assumption that our aggregate function is monotonic and under the assumption that all rules in a GAP have the form A : f (μ1 , . . . , μn ) ← B1 : μ1 , ∧ · · · , Bn : μn ,
where each μi is a member of [0, 1] ∪AVar.
In this case, we define a nonground interpretation and a nonground fixpoint operator
S . This leverages existing work on nonground logic programming initially pioneered
by Falaschi et al. [1988] and later adapted to different logic programming extensions
[Eiter et al. 1997; Gottlob et al. 1996; Stroe and Subrahmanian 2003]. We will use A∗ to
denote the set of all atoms (ground and nonground). We start by defining a nonground
interpretation.
Definition 5.1. A nonground interpretation is a partial mapping NG : A∗ →[0, 1].
Every nonground interpretation NG represents an interpretation grd(NG) defined as
follows: grd(NG)(A) = max{NG(A ) | A is a ground instance of A }. When there is no
atom A which has A as a ground instance and for which NG(A ) is defined, then we set
grd(NG)(A) = 0.
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:25

Thus, in a language with just three constants a, b, c and one predicate symbol p, the
nonground interpretation that maps p(X, a) to 0.5 and everything else to 0 corresponds
to the interpretation that assigns 0.5 to p(a, a), p(b, a) and p(c, a) and 0 to every other
ground atom. Nonground interpretations are succinct representations of ordinary interpretations: they try to keep track only of assignments to nonground atoms (not
necessarily all ground atoms) and they do not need to worry about atoms assigned 0.
We now define a fixpoint operator that maps nonground interpretations to nonground interpretations.
Definition 5.2 (Operator S ). The operator S associated with a GAP  maps
a nonground interpretation NG to the nonground interpretation S (NG) where
S (NG)(A ) = max{f (X1 , . . . , Xn ) | A : f (μ1 , . . . , μn ) ← B1 : μ1 ∧ . . . ∧ Bn : μn is a rule
in  and there exist atoms (B1 , . . . , Bn ) such that NG(Bi ) is defined for all 1 ≤ i ≤ n,
(B1 , . . . , Bn ) and (B1 , . . . , Bn ) are simultaneously unifiable via a most general unifier θ,
A = Aθ , and (i) if μi is a constant, then NG(Bi ) ≥ μi —in this case Xi = μi , and (ii) if
μi is a variable, then Xi = NG(Bi )}. (In this definition, without loss of generality, we
assume the variables occurring in rules in  are mutually standardized apart and are
also different from those in NG).
The fixpoint operator S delays grounding to the maximal extent possible by (i) only
looking at the rules in  directly rather than ground instances of rules in  (which
is what T does), and (ii) by trying to assign values to nonground atoms rather than
ground instances, unless there is no other way around it. The following example shows
how S works.
Example 5.3. For illustrative purposes, suppose we have the following GAP :
e(V, a) : 1
p(V) : 0.7
q(V  ) : X ← p(V  ) : X, e(V  , a) : 0.5
Let us apply S till we reach a fixed point. With the first application, we entail the
(nonground) annotated atoms e(V, a) : 1, p(V) : 0.7 (we use the first and second facts).
With the next application, q(V  ) : 0.7 is entailed. In fact, notice that the atoms in
the body of the third rule, namely p(V  ), e(V  , a), can be unified with e(V, a), p(V), for
which the interpretation obtained in the first iteration is defined; moreover, the value
of e(V, a) in the interpretation is greater than 0.5. Notice also that in assigning a value
to q(V  ), the value of p(V  ) in the current interpretation is used, that is, 0.7 is used in
place of X. At this point the least fixed point is reached.
Consider the ordering  defined as follows on nonground interpretations: NG1  NG2
iff grd(NG1 ) ≤ grd(NG2 ). In this case, it it easy to see what follows.
P ROPOSITION 5.4. Suppose  is any GAP. Then
(1) S is monotonic.
(2) S has a least fixpoint lfp(S ) and lfp(T ) = grd(lfp(S )).
That is, lfp(S ) is a nonground representation of the (ground) least fixpoint
operator T .
In short, S is a version of T that tries to work in a nonground manner as much as
possible. We now present the SNDOP-Mon algorithm to compute answers to a SNDOP
query (agg, VC, k, gI (V), gO (V)) when agg is monotonic. The SNDOP-Mon algorithm
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:26

P. Shakarian et al.

ALGORITHM : SNDOP-Mon(, agg, VC, k, gI (V), gO (V))
(1) The variable Curr is a tuple consisting of a GAP and natural number. We initialize
Curr.Prog = ; Curr.Count = 0.
(2) Todo is a set of tuples described in step 1. We initialize Todo ≡ {Curr}
(3) Initialize the real number bestVal = 0 and GAP bestSOL = NIL
(4) while Todo ≡ ∅ do
(a) Cand = first member of Todo
(b) if value(lfp(SCand.Prog )) ≥ bestVal ∧ lfp(SCand.Prog ) |= VC then
i. bestVal = value(lfp(SCand.Prog ); bestSOL = Cand
(c) if Cand.Count < k then
i. For each ground atom gI (v), s.t.  ∃OtherCand ∈ Todo where
OtherCand.Prog ⊇ Cand.Prog,
|OtherCand.Prog| ≤ |Cand.Prog| + 1,
and lfp(SOtherCand.Prog ) |= gI (v) : 1, do the following:
A. Create new tuple NewCand.
Set NewCand.Prog = Cand.Prog ∪ {gI (v) : 1}.
Set New.Count = Cand.Count + 1)
B. Insert NewCand into Todo
ii. Sort the elements of Element ∈ Todo in descending order of value(Element.Prog),
where the first element, Top ∈ Todo, has the greatest such value (i.e. there does not
exist another element Top s.t. value(Top .Prog) > value(Top.Prog))
(d) Todo = Todo − {Cand}
(5) if bestSOL = NIL then return (bestSOL.Prog − ) else return NIL.

Fig. 5. Search tree for Example 5.5.

uses the following notation: value(NG) is the same as value(grd(NG)) and NG satisfies
a formula iff grd(NG) satisfies it.
The following example shows how the SNDOP-Mon algorithm works.
Example 5.5. Consider Example 3.16, where we present a social network and
some diffusion rules for disease spread embedded in program disease . Suppose, we
want to answer a SNDOP query (disease , SUM, true, 2, inf(V), inf(V)). The searchtree in Figure 5 illustrates how SNDOP-Mon searches for an optimal solution to
the query. In the figure, we labeled each node with the set of vertices and a real
number. The vertices correspond to the vertex atoms (annotated with 1) formed
with inf added to GAP in step 4(c)i. The real number corresponds to the value
resulting from this addition. Underlined nodes in the search tree represent potential
solutions where bestVal and bestSOL are updated. Notice, that, for example, the set
{v4 , v1 } is never considered. This is because inf(v1 ) is entailed anytime a candidate
solution includes v4 . The optimal solution is found to be {v7 , v5 }. In this example,
the algorithm considers solutions in the following order: {}, {v4 }, {v4 , v7 }, {v4 , v5 },
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:27

{v4 , v6 }, {v7 },{v7 , v5 }, {v7 , v1 }, {v7 , v2 },{v7 , v3 }, {v5 },{v5 , v6 }, {v5 , v1 }, {v5 , v2 },{v5 , v3 },{v6 },
{v6 , v1 }, {v6 , v2 },{v6 , v3 }, {v1 }, {v2 }, {v3 }.
The following result states that the SNDOP-Mon algorithm is correct.
T HEOREM 5.6. Given SNDOP query Q = (agg, VC, k, gI (V), gO (V)) and a GAP 
embedding a social network S, if agg is monotonic then:
— There is an answer to the SNDOP query Q w.r.t.  iff SNDOPMon(, agg, VC, k, gI (V), gO (V)) does not return NIL.
— If SNDOP-Mon(, agg, VC, k, gI (V), gO (V)) returns any result other than NIL, then
that result is an answer to the SNDOP query Q w.r.t. .
5.3. Approximation Algorithms: GREEDY-SNDOP

Even though SNDOP-Mon offers advantages such as pruning of the search tree and
leverages nonground operations to increase efficiency over the naive algorithm, it
is still intractable in the worst case. Regrettably, Theorem 3.17 precludes an exact
solution in PTIME and Theorem 3.20 precludes a PTIME α-approximation algorithm
e
where α < e−1
. Both of these results hold for the restricted case of linear-GAPs and
positive-linear aggregate functions.
The good news is that we were able to show that (i) for linear-GAPs and apriori VC queries with positive-linear aggregates, the value function is submodular
(Theorem 3.15). (ii) Under these conditions, we can reduce the problem to the maximization of a submodular function over a uniform matroid (the uniformity of the matroid is proved in Lemma 3.14 for a-priori VC queries). (iii) We can leverage the work
e
of Nemhauser et al. [1978], which admits a greedy e−1
approximation algorithm. In
this section, we develop a greedy algorithm for SNDOP queries that leverages these
three results.
The GREEDY-SNDOP algorithm that follows assumes a linear GAP, an a-priori VC
query with positive-linear aggregates, and a zero-starting value function (notice that
the latter requirement can be met as stated by Proposition 3.11). The algorithm proe
vides e−1
approximation to the SNDOP query problem. As this matches the upper
bound of Theorem 3.20, we cannot do better in terms of an approximation guarantee.
ALGORITHM : GREEDY-SNDOP(, agg, VC, k, gI (V), gO (V)) returns SOL ⊆ V




(1) Initialize SOL = ∅ and REM = {v ∈ V| {gI (v) : 1} ∪ pred∈vert (v) {pred(v) : 1} |= VC[V/v] }
(2) While |SOL| < k and REM = ∅
(a) vbest = null, val = value(SOL), inc = 0
(b) For each v ∈ REM, do the following
i. Let incnew = value(SOL ∪ {v}) − val
ii. If incnew ≥ inc then inc = incnew and vbest = v
(c) SOL = SOL ∪ {vbest }, REM = REM − {vbest }
(3) Return SOL

We now analyze the time complexity of GREEDY-SNDOP.
P ROPOSITION 5.7. Given a SNDOP query Q = (agg, VC, k, gI (V), gO (V)), a social
network S, and a GAP  ⊇ S , the complexity of GREEDY-SNDOP is O(k · |V| · F(|V|))
where F(|V|) is the time complexity to compute value(V ) for some set V ⊆ V of size k.
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:28

P. Shakarian et al.
Table V. First Iteration of the Greedy Algorithm
Vertex Atom
buys
buys
buys
buys
buys
buys
buys
buys
buys
buys

camera(v1 )
camera(v2 )
camera(v3 )
camera(v4 )
camera(v5 )
camera(v6 )
camera(v7 )
camera(v8 )
camera(v9 )
camera(v10 )

SUM

v1

v2

v3

v5

v7

v9

v10

1.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.33
0.0

0.5
1.0
1.0
0.0
0.0
0.0
0.25
0.5
0.5
0.5

0.0
0.0
1.0
0.0
0.0
0.0
0.25
0.5
0.33
0.5

0.5
0.0
0.0
0.0
1.0
0.0
0.0
0.0
0.17
0.0

0.0
0.0
0.0
0.0
0.0
0.0
1.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
1.0
0.0

0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.33
1.0

1.33

4.25

2.58

1.67

1.0

1.0

1.33

Table VI. Incremental Increases for Both Iterations of
GREEDY-SNDOP
Vertex

Incremental Increase
on First Iteration

Incremental Increase
on Second Iteration

1.33
4.25
2.58
1.67
1.0
1.0
1.33

0.67
NA
0.0
1.67
0.75
0.5
0.67

v1
v2
v3
v5
v7
v9
v10

We note that most likely, the most expensive operation is the computation of value
at line 2(b)i. One obvious way to address this issue is by using a nonground version of
the fixed-point.
T HEOREM 5.8. Given a SNDOP query Q = (agg, VC, k, gI (V), gO (V)), a social network S, and a GAP  ⊇ S , if
—  is a linear GAP,
— Q is a-priori VC,
— agg is positive-linear, and
— value is zero-starting,
e
then GREEDY-SNDOP is an ( e−1
)-approximation algorithm.

Example 5.9. Consider Example 4.1 and program lin from page 19. Assume we
have an additional vertex predicate symbol pro assigned to professional photographers
(who are depicted with shaded vertices in Figure 3). Consider the SNDOP query where
agg = SUM, VC = {pro(V)}, k = 2, gI (V) = buys camera(V), gO (V) = buys camera(V).
On the first iteration of GREEDY-SNDOP, the algorithm computes the value for all
vertices in the set REM which are v1 , v2 , v3 , v5 , v7 , v9 , v10 . The resulting annotations of
the fixed points and aggregates are shown in Table V.
As value(∅) = 0, the incremental increase afforded by v2 is 4.25 – and clearly the
greatest of all the vertices considered. GREEDY-SNDOP adds v2 to SOL, removes
it from REM and proceeds to the next iteration. Table VI shows the incremental
increases for the second iteration. As v5 provides the greatest increase, it is picked,
and the resulting solution is {v2 , v5 }.
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:29
6. IMPLEMENTATION AND EXPERIMENTS

We have implemented the GREEDY-SNDOP algorithm in 660 lines of Java code by
reusing and extending the diffusion modeling Java library of Broecheler et al. [2010]
(approx. 35K lines of code). Our implementation uses multiple threads in the inner
loop of the GREEDY-SNDOP algorithm to increase efficiency. All experiments were
executed on the same machine with a dedicated 4-core 2.4GHz processor and 22GB
of main memory. Times were measured to millisecond precision and are reported in
seconds.
6.1. Experimental Setting

Dataset. In order to evaluate GREEDY-SNDOP, we used a real-world dataset based
on a social network of Wikipedia administrators and authors. Wikipedia is an online
encyclopedia collaboratively edited by many contributors from all over the world. Selected contributors are given privileged administrative access rights to help maintain
and control the collection of articles with additional technical features. A vote by existing administrators and ordinary authors determines whether an individual is granted
administrative privileges. These votes are publicly recorded. Leskovec et al. [2010]
crawled 2794 elections from the inception of Wikipedia until January 2008. The votes
casted in these elections give rise to a social network among Wikipedia administrators
and authors by representing a vote of user i for user j as a directed edge from node i
to j. In total, the dataset contains 103, 663 votes (edges) connecting more than 7000
Wikipedia users (vertices). Hence, the network is large and densely connected.11
SNDOP-Query. In our experiments, we consider the hypothetical problem of finding
a set of administrators having the highest overall influence in the Wikipedia social
network described. We treat votes as a proxy for the inverse of influence. In other
words, if user i voted for user j, we assume user j (intentionally through lobbying or
unintentionally through the force of his contributions to Wikipedia) influenced user i
to vote for him. All edges are assigned a weight of 1. Our SNDOP queries are designed
as per the following definition.
Definition 6.1 (Wikipedia SNDOP-Query). Given some natural number k > 1, a
Wikipedia SNDOP query, WQ(k) is specified as follows:
— agg = SUM – the intuition is that the aggregate provides us an expected number of
vertices that are influenced.
— VC = ∅ – we do not use a vertex condition in our experiments
— k as specified by the input
— gI (V) = gO (V) = influenced(V)
Diffusion Models Used. We represented the diffusion process with two different models: one tipping and one cascading.
— Cascading diffusion model. We used the Flickr Diffusion Model (Diffusion
Model 4.5) described in Section 4.2. In this model, a constant parameter α represents the “strength” or “likelihood” of influence. The larger the parameter α the
higher the influence of a user on those who voted for her.
11 Our Wikipedia dataset does not include edge weights. However, including edge weights should not appre-

ciably change the experimental results which show that solving SNDOP queries when tipping models are
used is faster, in general, than when cascade models are used.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:30

P. Shakarian et al.

Fig. 6. Runtimes of GREEDY-SNDOP for different values of α and k = 5 in both diffusion models.

— Tipping diffusion model. Cha et al. [2009] show that there is a relationship
between the likelihood of a vertex marking a photo as a favorite and the percentage of their neighbors that also marked that photo as a favorite. This implies a
tipping-model (as in Section 4.1). We apply the Jackson-Yariv model (i.e., Diffusion
Model 4.2) with B equated to influenced. For each vertex vj ∈ V, we set the benefit
b

to cost ratio ( c j ) to 1. Finally, the function γ defined in the Jackson Yariv model is
j
the constant-valued function (for all values of x):
γ (x) = α.
This says that irrespective of the number of neighbors that a vertex has, the benefit
to adopting strategy B (i.e., influenced) is α. Therefore, the resulting diffusion rule
for the linear Jackson-Yariv model is:


j Xj
influenced(vj ) : Xj .
←
influenced(v) : α ·
|{vj |vj , v}|
vj |vj ,v∈E

For both models, we derive a unique logic program for each setting of the parameter
α. The parameter α depends on the application and can be learned from ground truth
data. In our experiments, we varied α to avoid introducing bias.
6.2. Experimental Results

Runtime of GREEDY-SNDOP with varying α and different diffusion models.
Figure 6 shows the total runtime of GREEDY-SNDOP in seconds to find the set of
k = 5 most influential users in the Wikipedia voting network for different values of
the strength of influence parameter α. We varied α from 0.05 (very low level of influence) to 0.5 (very high level of influence) for both the cascading and tipping diffusion model. We observe that higher values of α lead to higher runtimes as expected
since the scope of influence of any individual in the network is larger. Furthermore, we
observe that the runtimes for the tipping diffusion model increase more slowly with α
compared to the cascading model.
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:31

Fig. 7. Runtimes of GREEDY-SNDOP for different values of k and α = 0.2 in both diffusion models.

Fig. 8. Time per iteration of GREEDY-SNDOP for α = 0.2 in both diffusion models.

Runtime of GREEDY-SNDOP with varying k. For the next set of experiments, we
keep the strength of influence fixed to α = 0.2 and varied k which governs the size of
the set of influencers. Figure 7 reports the runtime of GREEDY-SNDOP for the query
WQ(k) with k = 5, 10, 15, 20, 25. For the cascading model, the runtime is approximately linear in k—a curve-fitting analysis using Excel showed a slight superlinear
trend (even though the figure itself looks linear at first sight). Figure 8 shows the time
taken to execute each of the 25 iterations of the outer loop for the query WQ(25) with
α = 0.2. Note that each subsequent iteration is more expensive than the previous one
since the size of the logic programs to consider increases with the addition of each
ground atom influenced(vi ). However, we also implemented the practical improvement
of “lazy evaluation” of the submodular function as described in Leskovec et al. [2007b].
This improvement, which maintains correctness of the algorithms, stores previous improvements in total score and prunes the greedy search for the highest scoring vertex
as discussed. We found that this technique also reduced the runtime of subsequent
iterations.
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:32

P. Shakarian et al.

Our experimental results show that we can answer SNDOP queries on large social
networks. For example, computing the set of five most influential Wikipedia users in
the voting network required approximately 2 hours averaged over the different values
of α in the tipping diffusion model.
7. RELATED WORK

There has been extensive work in reasoning about diffusion in social networks. However, to our knowledge, there is no work on the relationship between logic programming and social networks. Moreover, there is no general framework to solve social
network diffusion optimization problems that can take a broad class of diffusion models as input. We believe this work represents the first deterministic framework for
representing generalized diffusion models that allows for different properties and
weights on vertices and edges. Previously, the authors presented the framework of
SNDOPs in Shakarian et al. [2010]. However, this brief technical communication did
not include either our exact or approximate algorithms, an implementation, experiments, the SNDOP-ALL problem, many of the complexity results, or many of the constructions seen in this article (such as the homophilic diffusion models and big-seed
marketing).
7.1. Related Work in Logic Programming

We first compare our work with annotated logic programming [Kifer and Lozinskii
1992; Kifer and Subrahmanian 1992; Thirunarayan and Kifer 1993] and its many
extensions and variants [Damasio et al. 1999; Kern-Isberner and Lukasiewicz 2004;
Krajci et al. 2004; Lu 1996; Lu et al. 1993; Lukasiewicz 1998; Vennekens et al. 2004].
There has been much work on annotated logic programming and we have built on
the syntax and semantics of annotated LP. [Swift 1999] describes how lattice answer
subsumption can implement GAPs whereas [Swift and Warren 2010] describes its implementation (as well as the implementation of partial order answer subsumption)
in XSB and analyzes its performance showing scalability for applications in social
network analysis, abstract interpretation, and query justification. We also note that
possibilistic logic [Dubois and Prade 1990; Dubois et al. 1991] might be extended to
handle the types of calculations GAPs support. In fact, GAPs may be viewed as such
an extension of possibilistic logic. However, we are not aware of any work on solving
optimization queries (queries that seek to optimize an aggregate function) w.r.t. annotated logic programming.
Raedt et al. [2007] propose a probabilistic version of Prolog, called ProbLog. A
ProbLog program consists of a set of definite clauses (like in Prolog) where each clause
is associated with a probability. Given a ProbLog program T, the authors induce a
probability distribution over the space of definite logic programs L ⊆ LT , where LT
is the definite logic program obtained from
out the probabilities. The
 T by stripping

probability of L ⊆ LT is obtained as ci ∈L pi × ci ∈LT −L (1 − pi ), where pi is the
probability of clause ci . The probability that a query succeeds is the sum of the probabilities of the Prolog programs L ⊆ LT where the query succeeds. The semantics of
ProbLog is called the distribution semantics; it has been borrowed from PRISM [Sato
1995]. Basically, in the distribution semantics all facts are assumed to be mutually
independent [Hommersom and Lucas 2011]. Similar assumptions are made in certain
other logics such as Independent Choice Logic [Poole 2008] and PRISM [Sato 1995;
Sneyers et al. 2010]. Ng and Subrahmanian [1992, 1993] propose probabilistic logic
programs where the independence assumption is not required, but this is computationally expensive though recent approaches [Khuller et al. 2007] based on sampling
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:33

have been shown to scale very well to the case of 100K atoms. In order to compute the
success probability of a query, [Raedt et al. 2007] first builds a monotone DNF formula
(this represents the proofs of the query when probabilities are ignored), and then uses
a BDD based approach to compute the probability. The approach is experimentally
evaluated on biological networks showing good scalability.
The independence assumption is frequently made in many applications; however, in
social networks, assuming independence of node properties and/or diffusions can be
dangerous because the diffusive process explicitly is one of dependency - the probability of vertex A being infected by a neighbor is directly dependent on the probabilities
of one or more of its neighbors being infected. We note that Raedt et al. [2007] do not
provide any results on solving social network optimization problems.
In many logics that incorporate independence assumptions including [Poole 2008;
Raedt et al. 2007; Sneyers et al. 2010], the probability of diffusion from neighbors of
a vertex to a vertex are computed via the independence assumption. In the simplest
sense, consider a vertex v and two vertices a, b such that (a, v), (b, v) are edges in the
graph and suppose there are no other edges of the form (−, v).
Suppose we know that the probability of v being infected by a (resp. b) is 0.7 (resp.
0.5). In this case, the probability of infection of v under the assumption of independence
is 0.7 + 0.5 − 0.7 × 0.5 = 0.85. The reason independence is important here is that
P(E ∨ E ) = P(E) + P(E ) − P(E ∧ E ) and P(E ∧ E ) = P(E) × P(E ) only when the
events E, E are mutually independent.
When independence is not assumed between E and E , one must compute P(E ∧ E )
by either solving a linear program or via some other method. Dekhtyar et al. [Dekhtyar
et al. 1999; Dekhtyar and Subrahmanian 2000] developed methods to not only find
such probabilities when the independence assumption cannot be made, but also suggested how different assumptions on the relationships between events (e.g., positive
correlation, negative correlation, mutual exclusion and independence) could be computed via hybrid logic programs. For example, if we assume that an arbitrary triangular co-norm12 [Bonissone 1987] ⊕ is used to compute the (disjunctive) probability
that vertex v is infected by either a or by b, then we can express the diffusion via the
GAP rule:
inf (v) : V1 ⊕ V2 ← inf (a) : V1 ∧ inf (b) : V2 .
Thus we see that such rules can capture triangular co-norms (including that used to
compute the probability of a disjunct under the independence assumption).
However, though GAPs can be more expressive than many languages such as [Poole
2008; Raedt et al. 2007; Sneyers et al. 2010], there is no guarantee that they will
be more “efficient” or more “intuitive” when additional assumptions such as independence are made. For instance, suppose we consider a more complex situation where
we have three vertices a, b, c and the same vertex v before. And suppose we have
edges (a, v), (b, v), (c, v) in our graph and we want to say that infection propagation

12 A triangular co-norm is a function ⊕ : [0, 1] ×[0, 1] →[0, 1] stating the probability of computing the “or” of
two events whose probabilities are known and are provided as input to ⊕. All triangular co-norms satisfy
the following axioms. (Ax1) ⊕ is associative and commutative. (Ax2) x ⊕ 0 = x. (Ax3) ⊕ is monotone, that
is, if x ≤ x and y ≤ y then x ⊕ y ≤ x ⊕ y . This axiom says that when the probabilities of both events go up
(or stay the same), the probability of the “or” can only go up (or stay the same). Triangular co-norms have
been extensively studied in logic programming as for back as 1988 [Subrahmanian 1988]—max(x, y) and
x + y − x ∗ y are two well known triangular co-norms—and there are many others.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:34

P. Shakarian et al.

is independent. In this case, we can express this as a GAP by writing the rules
shown here:
inf (v) : V ← edge(X, v) : 1 ∧ inf (X) : V.
inf (v) : V1 ⊕ V2 ← edge(X, v) : 1 ∧ edge(Y, v) : 1 ∧
inf (X) : V1 ∧ inf (Y) : V2 ∧ X = Y.
inf (v) : V1 ⊕ V2 ⊕ V3 ← edge(X, v) : 1 ∧ edge(Y, v) : 1 ∧ edge(Z, v) : 1 ∧
inf (X) : V1 ∧ inf (Y) : V2 ∧ inf (Z) : V3 ∧
X = Y ∧ Y = Z ∧ X = Z.
When x ⊕ y = x + y − x ∗ y, then these rules correspond to propagation under an
independence assumption - otherwise ⊕ can be any triangular co-norm.
In this case, we wrote three rules, one for each possible number of infected predecessors of v. The first rule covers the case where we want the infection to pass from
exactly one predecessor to v. The second rule covers all possible combinations of two
predecessors of v passing the infection on. The third rule looks at the case where all
three predecessors pass the infection along. Though this GAP is seemingly larger and
more cumbersome than the simple conditional probability statement governing infections discussed previously, we can show that indeed the third rule is the only one that
is needed and this holds for any triangular co-norm—in fact, the semantics of this
GAP is identical to the semantics of the GAP with just the last rule (plus the social
network). Intuitively, the reason is that the probability of v getting the infection from
all three is always greater than or equal to the probability of v getting it from just one
or just two of its predecessors.
We now generalize the previous observations. When we apply a triangular co-norm
⊕ to a set {x1 , . . . , xk }, we use ⊕({x1 , . . . , xk }) as short-hand for ⊕(x1 , ⊕({x2 , . . . , xn }))
which is well defined as all triangular co-norms are commutative and associative.
The following proposition says a triangular co-norm ⊕ applied to a set S always
gives a value no smaller than the value obtained by applying ⊕ to a subset of S .
P ROPOSITION 7.1. Let S and S be two sets of elements in [0, 1], and ⊕ a triangular
co-norm. If S ⊆ S , then ⊕S ≤ ⊕S .
P ROOF. Suppose S ⊆ S . We show that ⊕S ≤ ⊕(S ∪ S) for any S ⊆ S − S. This
is shown by induction on the cardinality i of S.
Base case i = 0. Straightforward.
Inductive step. Suppose ⊕S ≤ ⊕(S ∪ Si ) for any Si ⊆ S − S such that |Si | = i.
Let Si+1 ⊆ S − S be such that |Si+1 | = i + 1. Consider a set Si s.t. Si ⊆ Si+1
and |Si | = i and let ei be the element in Si+1 but not in Si . Ax2 implies that
⊕(S ∪ Si ) = (⊕(S ∪ Si )) ⊕ 0. By the associative and commutative properties of ⊕
we have ⊕(S ∪ Si+1 ) = (⊕(S ∪ Si )) ⊕ ei . As 0 ≤ ei , then ⊕(S ∪ Si ) ≤ ⊕(S ∪ Si+1 )
by the monotonicity property. As ⊕S ≤ ⊕(S ∪ Si ) (by induction hypothesis), then
⊕S ≤ ⊕(S∪Si+1 ).
Thus, in order to deal with the infection scenario discussed we have it suffices to
write rules of the form:
inf (V) : V1 ⊕ · · · ⊕ Vn ← edge(X1 , V) : 1 ∧ · · · ∧ edge(Xn , V) : 1 ∧
inf (X1 ) : V1 ∧ . . . ∧ inf (Xn ) : Vn ∧

Xi = Xj .
1≤i<j≤n

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:35

Note that one such rule must be generated for each value n s.t. there is a node in the
social network with in-degree n.
Thus, though GAPs provide a general method to express a vast variety of both probabilistic and nonprobabilistic diffusion models, some of these methods can lead to an
increase in the size of the GAP. When certain probabilistic assumptions are warranted
(such as independence) then it may be appropriate to use the techniques for solving social network optimization problems presented in this article in conjunction with frameworks such as ProbLog or Independent Choice Logic that may be able to leverage their
assumptions to produce good solutions under those assumptions. However, much more
experimentation is required to understand the pros and cons of such choices and we
leave this to future work.
There are a few papers on solving optimization problems in logic programming. The
best of these is constraint logic programming [Van Hentenryck 2009] which can embed numerical computations within a logic program. However, CLP does not try to
find solutions to optimization problems involving semantics structures of the program
itself. Important examples of constraint logic programming include [Frühwirth 1994;
Mancarella et al. 1999] where annotated LP is used for temporal reasoning, Leone
et al. [2004] assume the existence of a cost function on models. They present an analysis of the complexity and algorithms to compute an optimal (w.r.t. the cost function)
model of a disjunctive logic program in 3 cases: when all models of the disjunctive logic
program are considered, when only minimal models of the disjunctive logic program
are considered, and when stable models of the disjunctive logic program are considered. In contrast, in this article, there are two differences. First, we are considering
GAPs. Second, we are not looking for models of a GAP that optimize an objective function - rather, we are trying to find models of a GAP together with some additional
information (namely some vertices in the social network for which a goal atom g(v) : 1
is added to the GAP) which is constrained (at most k additional atoms) so that the
resulting least fixpoint has an optimal value w.r.t. an arbitrary value function. In this
regard, it has some connections with abduction in logic programs [Eiter and Gottlob
1995], but there is no work on abduction in annotated logic programs that we are
aware of or work that optimizes an arbitrary objective function.
Our article builds on many techniques in logic programming. It builds upon nonground fixpoint computation algorithms proposed by Falaschi et al. [1988] and later
extended for stable models semantics [Eiter et al. 1997; Gottlob et al. 1996], and extends these nonground fixpoint algorithms to GAPs and then applies the result to
define the SNDOP-Mon algorithm to find answers to SNDOP queries which, to the
best of our knowledge, have not been considered before.
7.2. Work in Social Networks

Kempe et al. [2003] is one of the classic works in this area where a generalized diffusion framework for social networks is proposed. This work presents two basic diffusion models: the linear threshold and independent cascade models. Both models utilize
random variables to specify how the diffusion propagates. These models roughly resemble nondeterministic versions of the tipping and cascading models presented in
Section 4 of this article. Neither model allows for a straightforward representation
of multiple vertex or edge labels as this work does. Additionally, unlike this article,
where we use a fixed-point operator to calculate how the diffusion process unfolds, the
diffusion models of [Kempe et al. 2003] utilize random variables to define the diffusion process and compute the expected number of vertices that have a given property.
Kempe et al. [2003] only approximate this expected value and leave the exact computation of it as an open question. Further, they provide no evidence that their approximation has theoretical guarantees. Moreover, Lemma 7.1 and the discussion immediately
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:36

P. Shakarian et al.

preceding it show how the linear threshold model mentioned in Kleinberg [Kempe
et al. 2003] can be expressed via GAPs with no loss of generality (but with an increase
in the number of rules in the GAP that can affect performance).
The more recent work of Chen et al. [2010] showed this computation to be #P-hard
by a reduction from S-T connectivity, which has no known approximation algorithm.
This suggests that a reasonable approximation of the diffusion process of Kempe et al.
[2003] may not be possible. This contrasts sharply with the fixed-point operator of
Kifer and Subrahmanian [1992], which can be solved in PTIME under reasonable assumptions (which are present in this article). Kempe et al. [2003] focus on the problem
of finding the “most influential nodes” in the graph, which is similar in intuition to a
SNDOP query. However, this problem only looks to maximize the expected number of
vertices with a given property, not a complex aggregate as a SNDOP query does. Further, the approximation guarantee presented for the “most influential node” problem
is contingent on an approximation of the expected number of vertices with a certain
property, which is not shown (and, as stated earlier, was shown by [Chen et al. 2010]
to be a #P-hard problem).
In short, the frameworks of Chen et al. [2010] and Kempe et al. [2003] cannot handle
arbitrary aggregates nor vertex conditions nor edge and vertex predicates nor edge
weights as we do. Nor can they define an objective function using a mix of the aggregate
and the gO (−) predicate specified in the definition of a SNDOP query.
Another well-studied related problem in computer science is the “target set selection” problem [Chen 2009; Chiang et al. 2011; Dreyer and Roberts 2009]. This problem
assumes a deterministic tipping model and seeks to find a set of vertices of a certain
size that optimizes the final number of adopters. Although approximation algorithms
for this problem have been discovered, there is no evidence that they scale well for
large datasets. Further, an easy modification of Diffusion Model 4.1 allows for this
problem to be represented in our framework. While target set selection can be encoded
as an SNDOP query, a straightforward encoding of an SNDOP query into target set
selection is unlikely. This is because the target set selection problem does not consider
multiple vertex and edge labels nor seeks to optimize a complex aggregate.
8. CONCLUSION

Social networks are proliferating rapidly and have led to a wave of research on diffusion of phenomena in social networks. In this article, we introduce the class of Social
Network Diffusion Optimization Problems (SNDOPs for short) which try to find a set
of vertices (where each vertex satisfies some user specified vertex condition) that has
cardinality k or less (for a user-specified k > 0) and that optimizes an objective function specified by the user in accordance with a diffusion model represented via the
well-known Generalized Annotated Program (GAP) framework. We have used specific
examples of SNDOP queries drawn from product adoption (cell phone example) and
epidemiology.
The major contributions of this article include the following.
— We showed that answering SNDOP queries is NP-hard and identified the complexity classes associated with related problems (under various restrictions). We showed
that the complexity of counting the number of solutions to SNDOP queries is #Pcomplete.
— We proved important results showing that there is no polynomial-time algorithm
e
that computes an α-approximation to a SNDOP query when α ≥ e−1
.
— We described how various well-known classes of diffusion models (cascading, tipping, homophilic) from economics, product adoption and marketing, and epidemiology can be embedded into GAPs.
ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:37

— We presented an exact-algorithm for solving SNDOP queries under the assumption
of a monotonic aggregate function.
— We proved that SNDOP queries are guaranteed to be submodular when the GAP
representing the diffusion model is linear and the aggregate is positive-linear. We
were able to leverage this result to develop the GREEDY-SNDOP algorithm that
runs in polynomial-time and that achieves the best possible approximation ratio of
e
e−1 for solving SNDOPs.
— We develop the first implementation for solving SNDOP queries and showed it could
scale to a social network with over 7000 vertices and over 103,000 edges. Our experiments also show that SNDOP queries over tipping models can generally be solved
more quickly than SNDOP queries over cascading models.
Much work remains to be done, and this article merely represents a first step towards the solution of SNDOP queries. Clearly, we would like to scale SNDOP queries
to social networks consisting of millions of vertices and billions of edges. This will require some major advances and represents a big challenge.
ELECTRONIC APPENDIX

The electronic appendix for this article can be accessed in the ACM Digital Library.
REFERENCES
Anderson, R. M. and May, R. M. 1979. Population biology of infectious diseases: Part i. Nature 280, 5721,
361.
Apt, K. 2003. Principles of Constraint Programming. Cambridge University Press.
Aral, S., Muchnik, L., and Sundararajan, A. 2009. Distinguishing influence-based contagion from homophilydriven diffusion in dynamic networks. Proc. Nat. Acad. Sci. U.S.A 106, 51, 21544–21549.
Backstrom, L., Huttenlocher, D. P., Kleinberg, J. M., and Lan, X. 2006. Group formation in large social
networks: Membership, growth, and evolution. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 44–54.
Bonissone, P. 1987. Summarizing and propagating uncertain information with triangular norms. Int. J.
Approx. Reason. 1, 1, 71–101.
Borgatti, S. and Everett, M. 2006. A graph-theoretic perspective on centrality. Social Netw. 28, 4, 466–484.
Broecheler, M., Shakarian, P., and Subrahmanian, V. 2010. A scalable framework for modeling competitive diffusion in social networks. In Proceedings of the International Conference on Social Computing,
295–302.
Centola, D. 2010. The spread ofbehavior in an online social network experiment.. Science 329, 5996,
1194–1197.
Centola, D. 2011. An experimental study of homophily in the adoption of health behavior. Science 334, 6060,
1269–72.
Cha, M., Mislove, A., Adams, B., and Gummadi, K. P. 2008. Characterizing social cascades in flickr. In
Proceedings of the 1st Workshop on Online Social Networks (WOSP’08). ACM, New York, NY, 13–18.
Cha, M., Mislove, A., and Gummadi, K. P. 2009. A Measurement-driven Analysis of Information Propagation in the Flickr Social Network. In Proceedings of the 18th International World Wide Web Conference
(WWW’09).
Chen, N. 2009. On the approximability of influence in social networks. SIAM J. Discrete Math. 23,
1400–1415.
Chen, W., Wang, C., and Wang, Y. 2010. Scalable influence maximization for prevalent viral marketing
in large-scale social networks. In Proceedings of the 16th ACM SIGKDD international conference on
Knowledge discovery and data mining (KDD’10). ACM, New York, 1029–1038.
Chiang, C.-Y., Huang, L.-H., Li, B.-J., Wu, J., and Yeh, H.-G. 2011. Some results on the target set selection
problem. CoRR abs/1111.6685.
Coelho, F., Codeco, C., and Cruz, H. 2008. Epigrass: A tool to study disease spread in complex networks.
Source Code Biol. Med. 3, 3.
Cowan, R. and Jonard, N. 2004. Network structure and the diffusion of knowledge. J. Econ. Dynamics
Control 28, 8, 1557–1575.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:38

P. Shakarian et al.

Damasio, C., Pereira, L., and Swift, T. 1999. Coherent well-founded annotated logic programs. In Proceedings
of the International Coriference on Logic Programming and Non-Monotonic Reasoning. Lecture Notes
in Computer Science, vol. 1730, Springer. 262–276.
Dekhtyar, A. and Subrahmanian, V. S. 2000. Hybrid probabilistic programs. J. Logic Program. 43, 3,
187–250.
Dekhtyar, M. I., Dekhtyar, A., and Subrahmanian, V. S. 1999. Hybrid probabilistic programs: Algorithms
and complexity. In Proceedings of the Conference on Uncertainty in Artificial Intelligence. 160–169.
Dreyer, P. and Roberts, F. 2009. Irreversible -threshold processes: Graph-theoretical threshold models of the
spread of disease and of opinion. Discrete Appl. Math. 157, 7, 1615–1627.
Dubois, D. and Prade, H. 1990. Resolution principles in possibilistic logic. Int. J. Approx. Reason. 4, 1, 1–21.
Dubois, D., Lang, J., and Prade, H. 1991. A brief overview of possibilistic logic. In Proceedings of the European
Conference on Symbolic and Quantifative Approaches to Reasoning with Uncertainty. 53–57.
Eagle, N., Pentland, A., and Lazer, D. 2008. Mobile phone data for inferring social network structure. In
Proceedings of the International Conference on Social and Behavioral Computing. Springer Verlag,
79–88.
Eiter, T. and Gottlob, G. 1995. The complexity of logic-based abduction. J. ACM 42, 1, 3–42.
Eiter, T., Lu, J., and Subrahmanian, V. 1997. Computing non-ground representations of stable models. In
Proceedings of the International Conferente on Logic Programming and Non-Monotonic Reasoning. Lecture Notes in Computer Science, vol. 1265, Springer, 198–217.
Falaschi, M., Levi, G., Martelli, M., and Palamidessi, C. 1988. A new declarative semantics for logic languages. In Proceedings of the 5th Internationa1 Conference and Symposium on Logic Programming.
993–1005.
Feige, U. 1998. A threshold of ln n for approximating set cover. J. ACM 45, 4, 634–652.
Frühwirth, T. 1994. Annotated constraint logic programming applied to temporal reasoning. In Proceedings
of the 6th International Symposium on Programming Language Implementation and Logic Programming. Springer.
Garey, M. R. and Johnson, D. S. 1979. Computers and Intractability; A Guide to the Theory of NPCompleteness. W. H. Freeman & Co., New York, NY, USA.
Gottlob, G., Marcus, S., Nerode, A., Salzer, G., and Subrahmanian, V. S. 1996. A non-ground realization of
the stable and well-founded semantics. Theor. Comput. Sci. 166, 1-2, 221–262.
Granovetter, M. 1978. Threshold models of collective behavior. Amer. J. Sociol. 83, 6, 1420–1443.
Hethcote, H. W. 1976. Qualitative analyses of communicable disease models. Math. Biosci. 28, 3–4, 335–356.
Hommersom, A. and Lucas, P. J. F. 2011. Generalising the interaction rules in probabilistic logic. In Proceedings of the International Joint Conference on Artificial Intelligence. 912–917.
Jackson, M. and Yariv, L. 2005. Diffusion on social networks. In Economie Publique, vol. 16. 69–82.
Kempe, D., Kleinberg, J., and Tardos, E. 2003. Maximizing the spread of influence through a social network.
In Proceedings of the 9th ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining (KDD’03). ACM, New York, 137–146.
Kern-Isberner, G. and Lukasiewicz, T. 2004. Combining probabilistic logic programming with the power of
maximum entropy. Artif. Intell. 157, 1-2, 139–202.
Khuller, S., Martinez, M. V., Nau, D. S., Sliva, A., Simari, G. I., and Subrahmanian, V. S. 2007. Computing
most probable worlds of action probabilistic logic programs: Scalable estimation for 1030,000 worlds.
Ann. Math. Artif. Intell. 51, 2-4, 295–331.
Kifer, M. and Lozinskii, E. L. 1992. A logic for reasoning with inconsistency. J. Autom. Reason. 9, 2, 179–215.
Kifer, M. and Subrahmanian, V. 1992. Theory of generalized annotated logic programming and its applications. J. Logic Program. 12, 3&4, 335–367.
Kleinberg, J. 2008. The convergence of social and technological networks. Comm. ACM 51, 11, 66–72.
Kozen, D. 1991. The Design and Analysis of Algorithms. Springer.
Krajci, S., Lencses, R., and Vojts, P. 2004. A comparison of fuzzy and annotated logic programming. Fuzzy
Sets Syst. 144, 1, 173 – 192.
Leone, N., Scarcello, F., and Subrahmanian, V. 2004. Optimal models of disjunctive logic programs: Semantics, complexity, and computation. IEEE Trans. Knowl. Data Eng. 16, 487–503.
Leskovec, J., Adamic, L. A., and Huberman, B. A. 2007a. The dynamics of viral marketing. ACM Trans.
Web 1, 1.
Leskovec, J., Huttenlocher, D., and Kleinberg, J. 2010. Predicting positive and negative links in online social
networks. In Proceedings of the 19th international conference on World Wide Web (WWW’10). ACM, New
York, 641–650.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems10:39
Leskovec, J., Krause, A., Guestrin, C., Faloutsos, C., VanBriesen, J., and Glance, N. 2007b. Cost-effective
outbreak detection in networks. In Proceedings of the 13th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (KDD’07). ACM, 420–429.
Lloyd, J. W. 1987. Foundations of logic Programming. Springer.
Lu, J. 1996. Logic programs with signs and annotations. J. Logic Comput. 6, 6, 755–778.
Lu, J., Murray, N., and Rosenthal, E. 1993. Signed formulas and annotated logics. In Proceedings of the 23rd
International Symposium on Multiple-Valued Logic. 48–53.
Lukasiewicz, T. 1998. Probabilistic logic programming. In Proceedings of the European Conference on Artificial Intelligence (ECAI’98). 388–392.
Mancarella, P., Raffaetà, A., and Turini, F. 1999. Temporal annotated constraint logic programming with
multiple theories. In Proceedings of the 10th International Workshop on Database and Expert Systems
Applications (DEXA’99).
Mossel, E. and Roch, S. 2007. On the submodularity of influence in social networks. In Proceedings of the
Armual ACM Symposium on Theory of Computing (STOC07). ACM, New York, 128–134.
Nemhauser, G. L., Wolsey, L. A., and Fisher, M. 1978. An analysis of approximations for maximizing submodular set functions – I. Math. Program. 14, 1, 265–294.
Ng, R. T. and Subrahmanian, V. S. 1992. Probabilistic logic programming. Inf. Comput. 101, 2, 150–201.
Ng, R. T. and Subrahmanian, V. S. 1993. A semantical framework for supporting subjective and conditional
probabilities in deductive databases. J. Autom. Reason. 10, 2, 191–235.
Poole, D. 2008. The independent choice logic and beyond. In Probabilistic Inductive Logic Programming.
222–243.
Raedt, L. D., Kimmig, A., and Toivonen, H. 2007. Problog: A probabilistic prolog and its application in link
discovery. In Proceedings of the International Joint Coriference on Artificial Intelligence. 2462–2467.
Roth, D. 1996. On the hardness of approximate reasoning. Artif. Intell. 82, 273–302.
Rychtář, J. and Stadler, B. 2008. Evolutionary dynamics on small-world networks. Int. J. Comput. Math.
Sci. 2, 1.
Sato, T. 1995. A statistical learning method for logic programs with distribution semantics. In Proceedings
of the International Coriference on Logic Programming. 715–729.
Schelling, T. C. 1978. Micromotives and Macrobehavior. W.W. Norton and Co.
Shakarian, P., Subrahmanian, V., and Sapino, M. L. 2010. Using generalized annotated programs to solve
social network optimization problems. In Technical Communications of the 26th International Conference on Logic Programming. M. Hermenegildo and T. Schaub Eds., Leibniz International Proceedings
in Informatics (LIPIcs) Series, vol. 7. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik, Dagstuhl,
Germany, 182–191.
Sneyers, J., Meert, W., Vennekens, J., Kameya, Y., AND Sato, T. 2010. Chr(prism)-based probabilistic logic
learning. J. Theory Pract. Logic Program. 10, 4–6, 433–447.
Stroe, B. and Subrahmanian, V. S. 2003. First order heterogeneous agent computations. In Proceedings of
the 2nd International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS’03).
ACM, New York, NY, USA, 217–224.
Subrahmanian, V. 1988. Generalized triangular norm and co-norm based semantics for quantitate rule
set logic programming. Logic Programming Resbarch Group Tech. rep. LPRG-TR- 88-22, Syracuse
University.
Subrahmanian, V. S. and Recupero, D. R. 2008. AVA: Adjective-verb-adverb combinations for sentiment
analysis. IEEE Intell. Syst. 23, 4, 43.
Sun, E., Rosenn, I., Marlow, C., and Lento, T. 2009. Gesundheit! Modeling contagion through facebook news
feed. In Proceedings of the 3rd International Conference on Weblogs and Social Media. AAAI Press, San
Jose, CA.
Swift, T. 1999. Tabling for non-monotonic programming. Ann. Math. Artif. Intell. 25, 3-4, 201–240.
Swift, T. and Warren, D. S. 2010. Tabling with answer subsumption: Implementation, applications
and performance. In Proceedings of the European Conference on Logics in Artificial Intelligence.
300–312.
Thirunarayan, K. and Kifer, M. 1993. A theory of nonmonotonic inheritance based on annotated logic. Artif.
Intell. 60, 1, 23–50.
Van Hentenryck, P. 2009. Constraint logic programming. Knowl. Engin. Rev. 6, 03, 151–194.
Vennekens, J., Verbaeten, S., and Bruynooghe, M. 2004. Logic programs with annotated disjunctions. In
Proceedings of the International Conference on Logic Programming. Lecture Notes in Computer Science,
vol. 3132, Springer 431–445.

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

i

i

i

i

10:40

P. Shakarian et al.

Watts, D. and Peretti, J. 2007. Viral marketing for the real world. Harvard Bus. Rev..
Watts, D. J. 1999. Networks, dynamics, and the small-world phenomenon. Amer. J. Sociol. 105, 2, 493–527.
Zhang, L., M. P. 2011. Two is a crowd: Optimal trend adoption in social networks. In Proceedings of International Conference on Game Theory for Networks.
Received January 2011; revised June 2012; accepted June 2012

ACM Transactions on Computational Logic, Vol. 14, No. 2, Article 10, Publication date: June 2013.

i

i
i

i

Social Network Intelligence Analysis to Combat
Street Gang Violence

arXiv:1306.6834v1 [cs.SI] 28 Jun 2013

Damon Paulo, Bradley Fischl, Tanya Markow, Michael Martin, Paulo Shakarian
Network Science Center and
Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY 10996
{damon.paulo, bradley.fischl, tanya.markow, michael.martin1} @usma.edu, paulo@shakarian.net

Abstract—In this paper we introduce the Organization,
Relationship, and Contact Analyzer (ORCA) that is designed
to aide intelligence analysis for law enforcement operations
against violent street gangs. ORCA is designed to address
several police analytical needs concerning street gangs using
new techniques in social network analysis. Specifically, it can
determine “degree of membership” for individuals who do not
admit to membership in a street gang, quickly identify sets of
influential individuals (under the tipping model), and identify
criminal ecosystems by decomposing gangs into sub-groups.
We describe this software and the design decisions considered
in building an intelligence analysis tool created specifically for
countering violent street gangs as well as provide results based
on conducting analysis on real-world police data provided
by a major American metropolitan police department who is
partnering with us and currently deploying this system for
real-world use.
Keywords-complex networks; social networks; criminology

I. I NTRODUCTION
Violent street gangs are a major cause of criminal activity
in the United States [1]. In this paper, we present a new
piece of software, Organizational, Relationship, and Contact
Analyzer (ORCA) that is designed from the ground-up to
apply new techniques in social network analysis and mining
to support law enforcement. In particular, we look to enable
improved intelligence analysis on criminal street gangs. The
software combines techniques from logic programming, [2]
viral marketing, [3], [4] and community detection [5], [6]
in a usable application custom-tailored for law enforcement
intelligence support. This work is inspired by recent work
in law enforcement that recognizes similarities between
gang members and insurgents and identifies adaptations
that can be made from current counter-insurgency (COIN)
strategy to counter gang violence. [1], [7] Due to the striking
similarities between gang-violence and COIN, the authors
from the U.S. Military Academy (West Point) responded
to requests from a major metropolitan police department to
transition recent social network mining software. As a result,
several West Point cadets were able to not only conduct

research, but also gain a better understanding of a COIN
environment.
The main contribution of this paper is the ORCA software
which is the first software, to our knowledge, that combine
the aforementioned techniques into a single piece of software
designed for law-enforcement intelligence analysis. The
paper is organized as follows. Section II describes ORCA
and its various components while Section III provides the
results of our preliminary evaluation. Finally, related work
is discussed in Section IV.
II. S YSTEM D ESIGN AND I MPLEMENTATION
The police department we worked with to develop ORCA
described several issues concerning the intelligence analysis
of street gangs. They desired a software system that could
accomplish the following tasks.
1) Ability to ingest police arrest data and visualize network representations of such data. The police data
in question primarily consists of arrest reports which
include the individual’s personal information as well
as claimed gang membership (if disclosed). This data
also includes relationships among individuals arrested
together.
2) Ability to determine degree of group membership.
While many gang members will disclose their gang
affiliation, some will not - likely fearing legal consequences. Hence, to better allocate police efforts and
intelligence gathering resources, it is important to
assign these unaffiliated members to a gang (with a
degree of confidence).
3) Ability to identify sets of influential members. Though
criminal street gangs are decentralized, it is suspected
that there are groups of individuals that can exert influence throughout a given gang - encouraging criminal
activity that is more violent and risky than the norm.
Identifying groups of individuals in this position of influence would provide law enforcement professionals
insight into the ability of these organizations to easily
adopt such behavior.

Arrest
record
data

Create social
y
network

y

Compute degree of
membership
(MANCaLog
framework)

(which are shown later). These visualizations were also
included in the context of intelligence reports automatically
generated by the software (which are based on the subsequently described components).

Determine gang
ecosystems
Partition network to
identify sub-groups
(Louvain Algorithm)

Identify core members
of gangs or factions
(TIP_DECOMP)

Identify
connectors

Report generation

Figure 1.

Overview of components and functions of ORCA.

4) Ability to map the “ecosystem” of a given gang.
Criminal street gangs tend to be highly modular organizations, with identifiable sub-groups. In particular,
“corner crews” - groups of individuals in a gang
who conduct illicit drug transactions on the same
street corner - will form highly connected clusters
in a social network representation of a street gang.
Further, understanding the relationships among these
sub-organizations - both within a given gang and
between different gangs provides substantial insight
into inter/intra gang dynamics as well as in identifying
individuals that connect different organizations.
Note that all of the above described functions were
included in ORCA in a direct response to the needs of
the law enforcement professionals that we have met. These
individuals are directly from our target user population to
whom we are transitioning the software to in mid-2013.
ORCA was written in Python 2.7.3 on top of the NetworkX 1.7 library 1 . In Figure 1 we show our overall
scheme for the design of ORCA to address the above
challenges. The key components we leveraged in building
the system included the MANCaLog framework which we
used to determine degree of membership, TIP DECOMP
was leveraged to find sets of influential members, and the
Louvain algorithm which we built on to map the ecosystems
of the various gangs. We describe how we designed each
major part throughout the remainder of this section.
Police data was ingested into the system in the form of
spreadsheet data that was derived from SQL queries from
a police database. For purposes of development and experimental evaluation, all personally-identifying information
was anonymized. From this data, we utilized the “individual
record” number of each person arrested and created a social
network between two individuals that were arrested together
(co-arrestees). To handle this network data structure, we
utilized the Python library NetworkX mentioned earlier. The
police also required visualizations of these social networks
1 http://networkx.github.io/documentation/latest/index.html

A. Determining Degree of Membership
Analytically associating arrested individuals with a criminal gang is an important piece of intelligence to law
enforcement officials. Even though analysis itself is not
direct evidence against an individual, it may be used as a
starting point to gather further information. Individuals who
do not admit to being in a gang may still have associates that
do admit to membership of a certain gang. Hence, we looked
to contribute to the solution to this problem by assigning
such individuals a degree of membership - a real number in
the interval [0, 1] that represents the confidence that the individuals is in a given gang. A value of 0 may be interpreted
as having no information on the individual’s affiliation with
a given gang while a value of 1 would be interpreted as the
individual as having admitted to being in the gang. To assign
these degree of membership values, we utilize MANCaLog,
a logic-programming based framework [2]. This framework
considers a network represented as a graph G = (V, E)
where V is a set of vertices and E is a set of (undirected)
relationships. For a given i ∈ V , ηi = {j|(i, j) ∈ E} and
di = |ηi |. The vertices can be assigned with a label from the
set L. Each label assigned to a vertex is given a value (in
the interval [0, 1] which associates that label with the vertex
with a degree of confidence. Hence, we use of network
representation of the co-arrestees as the graph and the set
of different gangs are the labels. Individuals who are known
to be in a certain gang are assigned a confidence value of
1 for that gang and 0 for the others. Through MANCaLog,
we can then assign a degree of confidence to the remaining
nodes derived from rules of the following form:
grp 1 ←

_

¬hgrp i , 1i, (grp 1 )ifl

(1)

i

Intuitively, the above rule says that a node will be assigned
to group 1 if it has not already been assigned to another
group (with a confidence of 1) and has a certain number
of neighbors who are also in group 1. A set of such rules
is referred to as a MANCaLog program and denoted P . A
program may also have facts of the form (hgrp i , xi, v) which
means that vertex v has a degree of membership in group i
with a confidence of x.
In the above rule, the confidence value assigned to a node
being in group 1 is based on the influence function (ifl )
which maps natural numbers to reals in the interval [0, 1].
For instance, an influence function may look something like
the following:

Algorithm 1 IFL LEARN

B. Identifying Seed Sets

Require: Group label g, program P

According to the law enforcement professionals we met,
the idea of influence is critical to understanding the behavior
of violent street gangs. Of particular concern is the influence
of radicalizing gang members - charismatic individuals that
not only participate in abnormally risky and violent behavior,
but have the ability to encourage others to do the same.
In order to identify sets of individuals who conduct such
behavior, we consider the idea of influence spread through
the “tipping model” [9]. In such a model, we again consider
a population structured as a social network (G = (V, E))
where each vertex i ∈ V is adjacent to di edges. We
model a social contagion that spreads through the network
as follows: consider unaffected node i. If at least ddi /2e of
i’s neighbors have the contagion, then i has the contagion –
otherwise it does not. A key question regarding this model
is to identify a seed set - a set of vertices in the network
that, if initially infected, will lead to the entire population
receiving the contagion. Identifying a seed set provides the
analyst a set of individuals that, when taken together, are
very influential to the overall network. Further, if the seed
set is of minimal size, then the size of the set can be used as a
proxy to measure how easily the network can be influenced.
Unfortunately, a simple reduction from set cover shows that
finding a seed set of minimal size is an NP-hard problem. [3]
However, we have designed a fast heuristic algorithm that
finds seed sets of very small size in practice. [4] This
algorithm is based on the idea of shell decomposition often
cited in physics literature [10], [11], [12], [13] but modified
to ensure that the resulting set will lead to all nodes being
infected. The algorithm, TIP DECOMP is presented in this
section.

Ensure:
1: Let R be an array indexed from 1 to d∗ (the maximum degree
of the network).
2: for i = 1, . . . d∗ do
3:
Set pos = 0, tot = 0
4:
for v ∈ V do
5:
Set Xv = {v 0 |(v 0 , v) ∈ E ∧ (hg, 1i, v 0 ) ∈ P }
6:
if |Xv | ≥ i then
7:
tot = tot + 1
8:
if (hg, 1i, v) ∈ P then
9:
pos = pos + 1
10:
end if
11:
end if
12:
end for
13:
If i = 0, R[i] = pos/tot − 1.96 ∗ SER(pos, tot),
else R[i] = max(R[i − 1], pos/(pos + neg) − 1.96 ∗
SER(pos, tot)) where SER is the standard error on the
fraction of positive neighbors.
14: end for
15: return R



0.0
ifl(x) = 0.1


0.5

if x = 0
if 1 ≤ x ≤ 3
if x ≥ 4

(2)

In [2], the authors showed that such confidence values
can be assigned to all vertices in the network for all labels
in polynomial time. However, a key issue is to derive the
influence function for the rules. We devised a simple strategy
for learning the influence function for each label (in this case
group) and have included it as algorithm IFL LEARN.
Algorithm IFL LEARN considers one group label (g) and
finds the fraction of neighbors. We view each node as getting
“signals” from its neighbors who are in that group. For
each potential number of signals (which is between one and
the maximum in-degree of the network) Algorithm 1 below
computes the fraction of nodes with at least that number of
signals who are in the group. It then computes the 95% lower
bound confidence interval based on standard error. This is
used as the lower bound of the degree of membership as
returned by the function. Then, based on an assumption of
monotonicity (based on the results of [8]), the algorithm sets
the lower bound to be the maximum between the previous
lower bound and the current.
The algorithm returns a matrix R, and the resulting
influence function is ifl (x) = R[x]. This algorithm is a
simple approach to learning rules from available data and no
novelty is claimed; more complex and general approaches
to rule learning are outside the scope of this paper and are
the topic of ongoing work.

Algorithm 2 TIP DECOMP
Require: Threshold function, θ and directed social network
G = (V, E)
Ensure: V 0
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

For each vertex i, disti = bdi /2c.
FLAG = TRUE.
while FLAG do
Let i be the element of V where disti is minimal.
if disti = ∞ then
FLAG = FALSE.
else
Remove i from G and for each j in ηi , if distj > 0,
set distj = distj − 1. Otherwise set distj = ∞.
end if
end while
return All nodes left in G.

Intuitively, the algorithm proceeds as follows (Figure 1).
Given network G = (V, E),at each iteration, pick the node
for which bdi /2c is the least but positive (or 0) and remove

partitions. A formal definition of this modularity for an
undirected network is defined as follows.
Given partition C = {c1 , . . . , cq }, modularity,
1 XX
M (C) =
wij − Pij
2m
i,j∈c
c∈C

k k

Figure 2. Example of TIP DECOMP for a simple network depicted in
box A. Next to each node label (lower-case letter) is the value for bdi /2c.
In the first four iterations, nodes e, f, h, and i are removed resulting in the
network in box B. This is followed by the removal of node j resulting in
the network in box C. In the next two iterations, nodes a and b are removed
(boxes D-E respectively). Finally, node c is removed (box F). The nodes of
the final network, consisting of d and g, have negative values for bdi /2c
and become the output of the algorithm.

it. Once there are no nodes for which this quantity is positive
(or 0), the algorithm outputs the remaining nodes in the
network.
In addition to providing the seed set for each street
gang, ORCA also provides information about influential
individuals. The shell number for each vertex based on the
process of shell decomposition [10] has been previously
shown to correlate with the vertex’s influence based on the
networked version of various epidemic models. [12]
C. Identifying Ecosystems
Another important capability for ORCA was to decompose street gangs into component organizations. In some
cases, street gangs will not be monolithic organizations, but
rather confederations of various factions - many of which
may be ill identified by authorities. Further, to maintain a
gang’s lines of funding, sub-organizations known as “corner
crews” operate as an informal unit to conduct narcotics sales
within certain parts of a given gang’s territory.
A common method to identify communities in a social
network is to partition it in a way to maximize a quantity known as modularity. [5] We shall use the notation
C = {c1 , . . . , cq } to denote a partition over set V where
each ci ∈ C isSa subset of V , for any ci , cj ∈ C,
ci ∩ cj = ∅ and i ci = V . For a given partition, C, the
modularity M (C) is a number in [−1, 1] . The modularity
of a network partition can be used to measure the quality of
its community structure. Originally introduced by Newman
and Girvan [5], this metric measures the density of edges
within partitions compared to the density of edges between

i j
where Pij = 2m
.
The modularity of an optimal network partition can be
used to measure the quality of its community structure.
Though modularity-maximization is NP-hard, the approximation algorithm of Blondel et al. [6] (a.k.a. the “Louvain
algorithm”) has been shown to produce near-optimal partitions.2 The modularity associated with this algorithm is often
called the “Louvain modularity” and the associated partition
is a “Louvain partition.”
ORCA not only finds the Louvain partition, but also
explores the relationships among the sub-groups within and
between gangs. For a given gang, ORCA generates a graph
showing the relationship among all sub-groups in that gang
and the neighboring sub-groups from different gangs. We
call this the “ecosystem” of a given gang. The ecosystem
is of particular importance to law-enforcement officers for
many reasons. One, in particular, is the issue of gang
retaliation. Consider the following: in the aftermath of a
violent incident initiated by group A against group B, police
enforcement will increase patrols in the territory controlled
by group B. As a result, group B will rely on an allied
organization (group C) to conduct retaliatory action against
group A. Identifying the ecosystem of a given gang helps
provide insight into organizations likely to conduct such
activities.
Further, it identifies individuals who have connections to
various other sub-groups. The intuition behind these individuals is that they connect various organizations together.
We refer to these individuals as “connectors.” Connectors
are also important to law-enforcement personnel as they
are individuals who often connect geographic disparate
sub-groups of a larger gang organization. Another use for
connectors is as a liaison between gangs that cooperate. For
instance, suppose group 1 wants to sell drugs in group 2’s
territory. An agreement is reached between the two groups
that group 1 can conduct these sales provided it pays a tax
to group 2. Hence, a liaison between the two groups may
be a facilitator in such an arrangement.

III. E VALUATION
We evaluated ORCA on a police dataset of 5418 arrests
from a single police district over a three period of time.
There were 11, 421 relationships among the arrests. From
this data, ORCA assembled a social network consisting of
1468 individuals (who were members in one of 18 gangs)
2 Louvain modularity was computed using the implementation available
from CRANS at http://perso.crans.org/aynaud/communities/.

0.8

G197
G258

0.6

G422

G034

0.4

Number of Indviduals

Degree of Membership

200
1

150
100
50

0

G322

Degree of Membership

0.2
8

[0.3,0.4)

Figure 4. Histogram showing the number of individuals assigned a degree
of membership within a certain range.
60

GROUP A

GROUP B

50
40
30
20

10
G846

G815

G814

G809

G651

G383

G237

G197

G034

G986

G672

G626

0
G465

First, we examined the performance of the system in
identifying degree of membership. As stated earlier, this
was determined using our MANCaLog framework that operated in two steps: learning the influence functions and
then applying the MANCaLog inference engine to compute
degree of membership. Figure 3 shows a plot of the influence
functions derived for five of the gangs. Specifically, it shows
the number of neighboring individuals in the given gang on
the x-axis compared to the computed degree of membership
for an individual having that number of gang contacts on the
y-axis. We note that our degree of membership computation
provides a similar result to [8] which studies the related
problem of social contagion.
In the second step required to determine the degree of
membership, the MANCaLog inference engine created logic
programs that utilized the influence functions to determine
degree of membership for individuals who did not admit
to being in a gang. All of the 180 unadmitted individuals
connected to the derived social network (individuals who
did not admit to being in a gang but were arrested with at
least one other individual in the district) were assigned a
non-zero degree of membership based on learned rules. The
majority of these individuals could be assigned a degree
of membership greater than 0.5 for at least one gang (see
Figure 4). We note that many of these individuals were
assigned a degree of membership to multiple gangs. This
may primarily be due to the fact that the included arrest
reports spanned a three-year time-frame - which our police
counterparts state is a relatively long period of time in
street gang culture. In such a time, gang members often
change allegiances and/or form new gangs. Exploring a
longitudinal study where time is explicitly considered is
an important direction for future work. The MANCaLog
framework allows for temporal reasoning as well.

[0.6,1.0)

G422

A. Degree of Membership

[0.2,0.3)

[0.5,0.6)

G336

and 1913 relationships. ORCA was able to complete this
assembly in addition to all analysis (determining degree of
membership, finding seed sets, and developing ecosystems)
took 34.3 seconds on a commodity laptop (Windows 8, B960
2.2 GHz processor with 4 GB RAM).

[0.1,0.2)

[0.4,0.5)

G322

Influence functions for five of the gangs examined by ORCA.

(0.0,0.1)

G258

4
6
Number of Neighbors

G175

Figure 3.

2

Seed Set Size (% of Total)

0

Street Gang

Figure 5. Seed size as a percentage of the total gang membership for
the 18 street gangs analyzed by ORCA organized into two different racial
groups.

B. Seed Set Identification
We also examined the seed sets found by ORCA for each
of the street gangs. These are sets of individuals who can
initiate a social cascade (under the majority threshold tipping
model) that will cause universal adoption in the gang. The
size of the seed set as a percentage of the population of each
gang is shown in Figure 5. The street gangs in the police
district we examined were racially segregated - belonging
to one of two races. Police officers working in the district
have told us that gangs of Racial Group A are known for
a more centralized organizational structure while gangs of
Racial Group B have adopted a decentralized model. These
groups are denoted in Figure 4. We were able to quantify
this observation as the gangs in Racial Group A had (on
average) seed sets 3.86% smaller than those in Group B.
C. Finding Communities and Identifying Ecosystems
As stated earlier, law enforcement personnel have much
interest in identifying sub-organizations of a given street
gang. ORCA tackled this problem using the Louvain algorithm as described in the previous section. For the 18 street
gangs examined in this study, ORCA identified subgroups
for each in an attempt to optimize modularity. As modularity
approaches 1.0, the communities produced by the algorithm
become more segregated. We show the modularity values
in Figure 6. Again, we also noticed a difference in the
organizational structure based on the gang’s race (aligning

GROUP A

GROUP B

G175
G258
G322
G336
G422
G465
G626
G672
G986
G034
G197
G237
G383
G651
G809
G814
G815
G846

Louvain Modularity

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Street Gang

Figure 6. The modularity of the partition found with the Louvain algorithm
for each gang.

with anecdotal police observations). Gangs associated with
Racial Group A (more centralized) had lower modularity
scores (by an average of 11.2%) than gangs associated
with Racial Group B (decentralized). This also corresponds
with police observations that gangs affiliated with Racial
Group B tend to operate in smaller factions (where the gang
organizations server more as a confederation) as opposed
to gangs affiliated with Group A (which are typically more
hierarchical).
The creation of a gang’s ecosystem (as described earlier)
is derived directly from the result of the Louvain partition. Sub-groups identified with the partition are connected
together based on social links between members or by
members who claim to be in more than one gang. Such an
ecosystem is shown in Figure 7. ORCA also provides an analytical report of an ecosystem listing all sub-group relations
and the strength of the relations (based on number of social
ties between organizations) (see Figure 8). Additionally,
ORCA also could identify individuals that connected various
organizations. Example output of this feature is shown in
Figure 9.

Figure 7. An example ecosystem for one of the gangs analyzed by ORCA.

Figure 8. An example ecosystem analysis for one of the gangs analyzed
by ORCA.

D. User Interface
Another priority in developing ORCA was to make the
software accessible to a variety of police personnel. We
created a user interface using the TKinter library version 8.53
and provided network visualizations using Matplotlib 1.2.04 .
As displayed in Figure 10, the users can utilize the interface
to easily run new analysis using arrest and relationship data
taken from the result of a database query. They can also
view the reports generated by completed analyisis. When the
analysis is complete, the law enforcement personnel have the
ability to view a full report that is automatically generated in
a portable document format (PDF) using version 1.7 of the
PyFPDF library5 . This is useful because it is a widely used
format that is familiar to most users. In addition to the full
report, the users can also view specific reports or network
3 http://wiki.python.org/moin/TkInter
4 http://matplotlib.org/
5 https://code.google.com/p/pyfpdf/

Figure 9.
An example report of connectors within one of the gangs
analyzed by ORCA.

visualizations which allows them to easily view the results
of the analysis that has been conducted. Finally, we would
like to note that this is a draft interface that we will refine
throughout the summer of 2013 by conducting studies in the
field as law enforcement personnel utilize the software. We
plan to incorporate the feedback that we gather into further

for use “out of the box” in a general-purpose social network
analysis package such as ORA or NodeXL.
V. C ONCLUSION

Figure 10. The ORCA user interface with network visualization and PDF
report output.

versions of the software so that it becomes a more useful
and usable tool.
IV. R ELATED W ORK
There have been several other pieces of software introduced for both general purpose network analysis as well as
for law enforcement. The main contribution of the software
presented in this paper if the ORCA software. ORCA is that
it is tailor made for specific police requirements dealing with
violent street gangs. Further, it leverage new articiial intellignece and data mining techniques such as MANCALog
and TIP DECOMP. Although ORCA is the first attempt to
combine these techniques in a piece of intelligence analysis
software, there have been other efforts to build software
designed for social network-based intelligence analysis that
we describe below.
Previous software designed to support law-enforcement
through social network analysis include CrimeFighter [14]
and CrimeLink [15]. However, these tools provide complementary capabilities to ORCA. While ORCA is primarily
designed for intelligence analysis with respect to street
gangs, CrimeLink is designed to support investigations while
CrimeFighter is directed more toward targeting of individuals in criminal organizations - rather than understanding
membership in and linkages between sub-groups. Further,
neither of these software packages support degree of membership, seed set identification, or the creation of ecosystems.
General-purpose social network analysis software also
exist, including the Organization Risk Analyzer (ORA) [16],
and NodeXL (an add-on to Microsoft Excel) [17]. While
these tools are very powerful and contain many features,
they do not provide the degree of membership calculation or
the identification of seed sets as ORCA does. ORCA is also
purposely designed for police intelligence analysts to better
understand street gangs, and features such as community
finding in ORCA are designed for with this application in
mind (hence the creation of ecosystems and identification
of inter-group connectors). This nuanced use of community
detection for street gang intelligence analysis is not ready

In this paper we introduced ORCA - the Organizational,
Relationship, and Contact Analyzer - a tool designed from
the ground-up to support intelligence analysis to aide law
enforcement personnel in combating violent street gangs.
We have shown how ORCA can meet various police analysis
needs to include determining degree for gang members of
unknown affiliation, identifying sets of influential individuals
in a gang, and finding and analyzing the sub-organizations
of a gang to determine inter/intra-group relationships.
Our next step with regard to this work is to integrate
geospatial and temporal elements in the analysis - particularly with respect to community finding and degree of
membership. Currently we are working closely with a major
metropolitan police department to transition ORCA for use
in law enforcement. Throughout the summer of 2013, we are
sending project assistants to work closely with the police in
order to identify additional police requirements that can be
addressed with techniques similar to those discussed in this
paper. Currently the police are employing this analysis for
one district. There are plans to expand to other districts in
late 2013.
ACKNOWLEDGMENT
The authors are supported under by the Army Research
Office (project 2GDATXR042) and the Office of the Secretary of Defense. The opinions in this paper are those of
the authors and do not necessarily reflect the opinions of the
funders, the U.S. Military Academy, or the U.S. Army.
R EFERENCES
[1] J. Bertetto, “Countering criminal street gangs: Lessons from
the counterinsurgent battlespace,” Law Enforcement Executive
Forum, vol. 12, no. 3, p. 43, 2012.
[2] P. Shakarian, G. I. Simari, and R. Schroeder, “MANCaLog: A
logic for multi-attribute network cascades,” in Proc. of 26th
Intl. Conf. on Autonomous Agents and Multiagent Systems
(AAMAS), May 2013.
[3] D. Kempe, J. Kleinberg, and E. Tardos, “Maximizing the
spread of influence through a social network,” in KDD
’03: Proceedings of the ninth ACM SIGKDD international
conference on Knowledge discovery and data mining. New
York, NY, USA: ACM, 2003, pp. 137–146.
[4] P. Shakarian and D. Paulo, “Large social networks can be
targeted for viral marketing with small seed sets,” in Proc.
2012 IEEE/ACM Intl. Conf. on Advances in Social Networks
Analysis and Mining (ASONAM-12), Aug. 2012.
[5] M. E. J. Newman and M. Girvan, “Finding and evaluating
community structure in networks,” Phys. Rev. E, vol. 69,
no. 2, p. 026113, Feb 2004.

[6] V. Blondel, J. Guillaume, R. Lambiotte, and E. Lefebvre,
“Fast unfolding of communities in large networks,” Journal
of Statistical Mechanics: Theory and Experiment, vol. 2008,
p. P10008, 2008.
[7] E. Goode, “Combating gang warfare with green beret tactics,”
The New York Times, Apr. 2012.
[8] D. Centola, “The Spread of Behavior in an Online Social
Network Experiment,” Science, vol. 329, no. 5996, pp. 1194–
1197, Sep. 2010.
[9] M. Granovetter, “Threshold models of collective behavior,”
The American Journal of Sociology, no. 6, pp. 1420–1443.
[10] S. B. Seidman, “Network structure and minimum degree,”
Social Networks, vol. 5, no. 3, pp. 269 – 287, 1983.
[11] S. Carmi, S. Havlin, S. Kirkpatrick, Y. Shavitt, and E. Shir,
“From the Cover: A model of Internet topology using k-shell
decomposition,” PNAS, vol. 104, no. 27, pp. 11 150–11 154,
2007. [Online]. Available: http://www.pnas.org/cgi/content/
abstract/104/27/11150
[12] M. Kitsak, L. K. Gallos, S. Havlin, F. Liljeros, L. Muchnik,
H. E. Stanley, and H. A. Makse, “Identification of influential
spreaders in complex networks,” Nat Phys, vol. 6, no. 11, pp.
888–893, Nov. 2010.

[13] G. J. Baxter, S. N. Dorogovtsev, A. V. Goltsev, and J. F. F.
Mendes, “Heterogeneous k-core versus bootstrap percolation
on complex networks,” Phys. Rev. E, vol. 83, May 2011.
[14] R. Petersen, C. Rhodes, and U. Wiil, “Node removal in
criminal networks,” in Intelligence and Security Informatics
Conference (EISIC), 2011 European, Sep. 2011, pp. 360 –
365.
[15] J. Schroeder, J. Xu, and H. Chen, “Crimelink explorer: Using
domain knowledge to facilitate automated crime association analysis,” in Intelligence and Security Informatics, ser.
Lecture Notes in Computer Science, H. Chen, R. Miranda,
D. Zeng, C. Demchak, J. Schroeder, and T. Madhusudan, Eds.
Springer Berlin Heidelberg, 2003, vol. 2665, pp. 168–180.
[16] K. M. Carley, “Ora: Organization risk analyzer,” CMU CASOS, Tech. Rep. January, 2004.
[17] D. Hansen, B. Shneiderman, and M. A. Smith, Analyzing
Social Media Networks with NodeXL: Insights from a Connected World. San Francisco, CA, USA: Morgan Kaufmann
Publishers Inc., 2010.

Belief Revision in
Structured Probabilistic Argumentation
Paulo Shakarian1 , Gerardo I. Simari2 , and Marcelo A. Falappa3

arXiv:1401.1475v1 [cs.LO] 7 Jan 2014

1

2

Department of Electrical Engineering and Computer Science
U.S. Military Academy, West Point, NY, USA
paulo@shakarian.net
Department of Computer Science, University of Oxford, United Kingdom
gerardo.simari@cs.ox.ac.uk
3
Departamento de Ciencias e Ingenierı́a de la Computación
Universidad Nacional del Sur, Bahı́a Blanca, Argentina
mfalappa@cs.uns.edu.ar

Abstract. In real-world applications, knowledge bases consisting of all
the information at hand for a specific domain, along with the current
state of affairs, are bound to contain contradictory data coming from
different sources, as well as data with varying degrees of uncertainty
attached. Likewise, an important aspect of the effort associated with
maintaining knowledge bases is deciding what information is no longer
useful; pieces of information (such as intelligence reports) may be outdated, may come from sources that have recently been discovered to be
of low quality, or abundant evidence may be available that contradicts
them. In this paper, we propose a probabilistic structured argumentation
framework that arises from the extension of Presumptive Defeasible Logic
Programming (PreDeLP) with probabilistic models, and argue that this
formalism is capable of addressing the basic issues of handling contradictory and uncertain data. Then, to address the last issue, we focus on the
study of non-prioritized belief revision operations over probabilistic PreDeLP programs. We propose a set of rationality postulates – based on
well-known ones developed for classical knowledge bases – that characterize how such operations should behave, and study a class of operators
along with theoretical relationships with the proposed postulates, including a representation theorem stating the equivalence between this class
and the class of operators characterized by the postulates.

1

Introduction and Related Work

Decision-support systems that are part of virtually any kind of real-world application must be part of a framework that is rich enough to deal with several
basic problems: (i) handling contradictory information; (ii) answering abductive queries; (iii) managing uncertainty; and (iv) updating beliefs. Presumptions
come into play as key components of answers to abductive queries, and must be
maintained as elements of the knowledge base; therefore, whenever candidate answers to these queries are evaluated, the (in)consistency of the knowledge base

together with the presumptions being made needs to be addressed via belief
revision operations.
In this paper, we begin by proposing a framework that addresses items (i)–
(iii) by extending Presumptive DeLP [1] (PreDeLP, for short) with probabilistic
models in order to model uncertainty in the application domain; the resulting
framework is a general-purpose probabilistic argumentation language that we
will refer to as Probabilistic PreDeLP(P-PreDeLP, for short).
In the second part of this paper, we address the problem of updating beliefs –
item (iv) above – in P-PreDeLP knowledge bases, focusing on the study of nonprioritized belief revision operations. We propose a set of rationality postulates
characterizing how such operations should behave – these postulates are based
on the well-known postulates proposed in [2] for non-prioritized belief revision in
classical knowledge bases. We then study a class of operators and their theoretical
relationships with the proposed postulates, concluding with a representation
theorem.

Related Work. Belief revision studies changes to knowledge bases as a response
to epistemic inputs. Traditionally, such knowledge bases can be either belief sets
(sets of formulas closed under consequence) [3, 4] or belief bases [5, 2] (which are
not closed); since our end goal is to apply the results we obtain to real-world
domains, here we focus on belief bases. In particular, as motivated by requirements (i)–(iv) above, our knowledge bases consist of logical formulas over which
we apply argumentation-based reasoning and to which we couple a probabilistic model. The connection between belief revision and argumentation was first
studied in [6]; since then, the work that is most closely related to our approach
is the development of the explanation-based operators of [7].
The study of argumentation systems together with probabilistic reasoning
has recently received a lot attention, though a significant part has been in the
combination between the two has been in the form of probabilistic abstract argumentation [8–11]. There have, however, been several approaches that combine
structured argumentation with models for reasoning under uncertainty; the first
of such approaches to be proposed was [12], and several others followed, such
as the possibilistic approach of [13], and the probabilistic logic-based approach
of [14]. The main difference between these works and our own is that here we
adopt a bipartite knowledge base, where one part models the knowledge that is
not inherently probabilistic – uncertain knowledge is modeled separately, thus
allowing a clear separation of interests between the two kinds of models. This
approach is based on a similar one developed for ontological languages in the
Semantic Web (see [15], and references within).
Finally, to the best of our knowledge, this is the first paper in which the combination of structured argumentation, probabilistic models, and belief revision
has been addressed in conjunction.

Probabilistic Model (EM)
Analytical Model (AM)
“Malware X was compiled on a system
“Malware X was compiled on a system in
using the English language.”
English-speaking country Y.”
“County Y and country Z are
“Country Y has a motive to launch a
currently at war.”
cyber-attack against country Z
“Malware W and malware X were created “Malware W and malware X are related.
in a similar coding style.”
Table 1. Examples of the kind of information that could be represented in the two
different models in a cyber-security application domain.

2

Preliminaries

The Probabilistic PreDeLP (P-PreDeLP, for short) framework is composed of
two separate models of the world. The first is called the environmental model
(referred to as “EM”), and is used to describe the probabilistic knowledge that
we have about the domain. The second one is called the analytical model (referred
to as “AM”), and is used to analyze competing hypotheses that can account for
a given phenomenon – what we will generally call queries. The AM is composed
of a classical (that is, non-probabilistic) PreDeLP program in order to allow for
contradictory information, giving the system the capability to model competing
explanations for a given query.
Two Kinds of Uncertainty. In general, the EM contains knowledge such as
evidence, uncertain facts, or knowledge about agents and systems. The AM, on
the other hand, contains ideas that a user may conclude based on the information in the EM. Table 1 gives some examples of the types of information that
could appear in each of the two models in a cyber-security application. Note that
a knowledge engineer (or automated system) could assign a probability to statements in the EM column, whereas statements in the AM column can be either
true or false depending on a certain combination (or several possible combinations) of statements from the EM. There are thus two kinds of uncertainty that
need to be modeled: probabilistic uncertainty and uncertainty arising from defeasible knowledge. As we will see, our model allows both kinds of uncertainty to
coexist, and also allows for the combination of the two since defeasible rules and
presumptions (that is, defeasible facts) can also be annotated with probabilistic
events.
In the rest of this section, we formally describe these two models, as well as
how knowledge in the AM can be annotated with information from the EM –
these annotations specify the conditions under which the various statements in
the AM can potentially be true.
Basic Language. We assume sets of variable and constant symbols, denoted
with V and C, respectively. In the rest of this paper, we will use capital letters
to represent variables (e.g., X, Y, Z), while lowercase letters represent constants.
The next component of the language is a set of n-ary predicate symbols; the
EM and AM use separate sets of predicate symbols, denoted with PEM , PAM ,

respectively – the two models can, however, share variables and constants. As
usual, a term is composed of either a variable or constant. Given terms t1 , ..., tn
and n-ary predicate symbol p, p(t1 , ..., tn ) is called an atom; if t1 , ..., tn are constants, then the atom is said to be ground. The sets of all ground atoms for EM
and AM are denoted with GEM and GAM , respectively.
Given set of ground atoms, a world is any subset of atoms – those that belong to the set are said to be true in the world, while those that do not are
false. Therefore, there are 2|GEM | possible worlds in the EM and 2|GAM | worlds
in the AM. These sets are denoted with WEM and WAM , respectively. In order to avoid worlds that do not model possible situations given a particular
domain, we include integrity constraints of the form oneOf(A′ ), where A′ is a
subset of ground atoms. Intuitively, such a constraint states that any world where
more than one of the atoms from set A′ appears is invalid. We use ICEM and
ICAM to denote the sets of integrity constraints for the EM and AM, respectively, and the sets of worlds that conform to these constraints is denoted with
WEM (ICEM ), WAM (ICAM ), respectively.
Finally, logical formulas arise from the combination of atoms using the traditional connectives (∧, ∨, and ¬). As usual, we say a world w satisfies formula
(f ), written w |= f , iff: (i) If f is an atom, then w |= f iff f ∈ w; (ii) if f = ¬f ′
then w |= f iff w 6|= f ′ ; (iii) if f = f ′ ∧ f ′′ then w |= f iff w |= f ′ and w |= f ′′ ;
and (iv) if f = f ′ ∨ f ′′ then w |= f iff w |= f ′ or w |= f ′′ . We use the notation
formEM , formAM to denote the set of all possible (ground) formulas in the EM
and AM, respectively.
2.1

Probabilistic Model

The EM or environmental model is largely based on the probabilistic logic of [16],
which we now briefly review.
Definition 1. Let f be a formula over PEM , V, and C, p ∈ [0, 1], and ǫ ∈
[0, min(p, 1 − p)]. A probabilistic formula is of the form f : p ± ǫ. A set KEM of
probabilistic formulas is called a probabilistic knowledge base.
In the above definition, the number ǫ is referred to as an error tolerance. Intuitively, probabilistic formulas are interpreted as “formula f is true with probability between p − ǫ and p + ǫ” – note that there are no further constraints over
this interval apart from those imposed by other probabilistic formulas in the
knowledge base. The uncertainty regarding the probability values stems from
the fact that certain assumptions (such as probabilistic independence) may not
be suitable in the environment being modeled.
Example 1. Consider the following set KEM :
f1 = a : 0.8 ± 0.1
f2 = b : 0.2 ± 0.1
f3 = c : 0.8 ± 0.1

f4 = d ∧ e
: 0.7 ± 0.2
f5 = f ∧ g ∧ h : 0.6 ± 0.1
f6 = i ∨ ¬j
: 0.9 ± 0.1

′
Throughout the paper, we also use KEM
= {f1 , f2 , f3 }

f7 = k : 1 ± 0



A set of probabilistic formulas describes a set of possible probability distributions Pr over the set WEM (ICEM ). We say that
Pprobability distribution Pr
satisfies probabilistic formula f : p ± ǫ iff: p − ǫ ≤ w∈WEM (ICEM ) Pr (w) ≤ p + ǫ.
We say that a probability distribution over WEM (ICEM ) satisfies KEM iff it
satisfies all probabilistic formulas in KEM .
Given a probabilistic knowledge base and a (non-probabilistic) formula q,
the maximum entailment problem seeks to identify real numbers p, ǫ such that
all valid probability distributions Pr that satisfy KEM also satisfy q : p ± ǫ, and
there does not exist p′ , ǫ′ s.t. [p − ǫ, p + ǫ] ⊃ [p′ − ǫ′ , p′ + ǫ′ ], where all probability
distributions Pr that satisfy KEM also satisfy q : p′ ± ǫ′ . In order to solve this
problem we must solve the linear program defined below.
Definition 2. Given a knowledge base KEM and a formula q, we have a variable
xi for each wi ∈ WEM (ICEM ).
– For each fj : pj ± ǫj ∈ KEM , there is a constraint of the form:
P
pj − ǫj ≤ wi ∈WEM (ICEM ) s.t. wi |=fj xi ≤ pj + ǫj .
P
– We also have the constraint: wi ∈WEM (ICEM ) xi = 1.
P
– The objective is to minimize the function: wi ∈WEM (ICEM ) s.t. wi |=q xi .
We use the notation EP-LP-MIN(KEM , q) to refer to the value of the objective
function in the solution to the EM-LP-MIN constraints.
The next step is to solve the linear program a second time, but instead
maximizing the objective function (we shall refer to this as EM-LP-MAX) – let
ℓ and u be the results of these operations, respectively. In [16], it is shown that
ǫ = u−ℓ
and p = ℓ + ǫ is the solution to the maximum entailment problem.
2
We note that although the above linear program has an exponential number
of variables in the worst case (i.e., no integrity constraints), the presence of
constraints has the potential to greatly reduce this space. Further, there are also
good heuristics (cf. [17, 18]) that have been shown to provide highly accurate
approximations with a reduced-size linear program.
′
Example 2. Consider KB KEM
from Example 1 and a set of ground atoms restricted to those that appear in that program; we have the following worlds:

w1 = {a, b, c}
w5 = {b}

w2 = {a, b}
w6 = {a}

w3 = {a, c}
w7 = {c}

w4 = {b, c}
w8 = ∅

and suppose we wish to compute the probability for formula q = a ∨ c. For each
formula in KEM we have a constraint, and for each world above we have a variable. An objective function is created based on the worlds that satisfy the query
′
formula (in this case, worlds w1 , w2 , w3 , w4 , w6 , w7 ). Solving EP-LP-MAX(KEM
, q)
′
and EP-LP-MIN(KEM , q), we obtain the solution 0.9 ± 0.1.


3

Argumentation Model

For the analytical model (AM), we choose a structured argumentation framework [19] due to several characteristics that make such frameworks highly applicable to many domains. Unlike the EM, which describes probabilistic information about the state of the real world, the AM must allow for competing ideas.
Therefore, it must be able to represent contradictory information. The algorithmic approach we shall later describe allows for the creation of arguments based
on the AM that may “compete” with each other to answer a given query. In this
competition – known as a dialectical process – one argument may defeat another
based on a comparison criterion that determines the prevailing argument. Resulting from this process, certain arguments are warranted (those that are not
defeated by other arguments) thereby providing a suitable explanation for the
answer to a given query.
The transparency provided by the system can allow knowledge engineers
to identify potentially incorrect input information and fine-tune the models or,
alternatively, collect more information. In short, argumentation-based reasoning
has been studied as a natural way to manage a set of inconsistent information – it
is the way humans settle disputes. As we will see, another desirable characteristic
of (structured) argumentation frameworks is that, once a conclusion is reached,
we are left with an explanation of how we arrived at it and information about why
a given argument is warranted; this is very important information for users to
have. In the following, we first recall the basics of the underlying argumentation
framework used, and then go on to introduce the analytical model (AM).
3.1

Defeasible Logic Programming with Presumptions (PreDeLP)

Defeasible Logic Programming with Presumptions (PreDeLP) [1] is a formalism
combining logic programming with defeasible argumentation; it arises as an extension of classical DeLP [20] with the possibility of having presumptions, as
described below – since this capability is useful in many applications, we adopt
this extended version in this paper. In this section, we briefly recall the basics
of PreDeLP; we refer the reader to [20, 1] for the complete presentation.
The formalism contains several different constructs: facts, presumptions, strict
rules, and defeasible rules. Facts are statements about the analysis that can always be considered to be true, while presumptions are statements that may or
may not be true. Strict rules specify logical consequences of a set of facts or
presumptions (similar to an implication, though not the same) that must always
occur, while defeasible rules specify logical consequences that may be assumed
to be true when no contradicting information is present. These building blocks
are used in the construction of arguments, and are part of a PreDeLP program,
which is a set of facts, strict rules, presumptions, and defeasible rules. Formally,
we use the notation ΠAM = (Θ, Ω, Φ, ∆) to denote a PreDeLP program, where
Ω is the set of strict rules, Θ is the set of facts, ∆ is the set of defeasible rules,
and Φ is the set of presumptions. In Figure 1, we provide an example ΠAM . We
now define these constructs formally.

Θ : θ1a = p

θ1b = q

θ2 = r

Ω : ω1a = ¬s ← t

ω1b = ¬t ← s

ω2a = s ← p, u, r, v

Φ : φ1 = y

φ2 = v

φ3 = ¬z

–≺

∆ : δ1a = s –≺ p
δ4 = u –≺ y

–≺

δ1b = t –≺ q
δ5a = ¬u –≺ ¬z

ω2b = t ← q, w, x, v

–≺

δ2 = s –≺ u
δ5b = ¬w –≺ ¬n

δ3 = s –≺ r, v

Fig. 1. An example (propositional) argumentation framework.

Facts (Θ) are ground literals representing atomic information or its negation,
using strong negation “¬”. Note that all of the literals in our framework must
be formed with a predicate from the set PAM . Note that information in the form
of facts cannot be contradicted. We will use the notation [Θ] to denote the set
of all possible facts.
Strict Rules (Ω) represent non-defeasible cause-and-effect information that resembles an implication (though the semantics is different since the contrapositive
does not hold) and are of the form L0 ← L1 , . . . , Ln , where L0 is a ground literal
and {Li }i>0 is a set of ground literals. We will use the notation [Ω] to denote
the set of all possible strict rules.
Presumptions (Φ) are ground literals of the same form as facts, except that
they are not taken as being true but rather defeasible, which means that they
can be contradicted. Presumptions are denoted in the same manner as facts,
except that the symbol –≺ is added.
Defeasible Rules (∆) represent tentative knowledge that can be used if nothing
can be posed against it. Just as presumptions are the defeasible counterpart of
facts, defeasible rules are the defeasible counterpart of strict rules. They are of
the form L0 –≺ L1 , . . . , Ln , where L0 is a ground literal and {Li }i>0 is a set of
ground literals. In both strict and defeasible rules, strong negation is allowed in
the head of rules, and hence may be used to represent contradictory knowledge.
Even though the above constructs are ground, we allow for schematic versions
with variables that are used to represent sets of ground rules. We denote variables
with strings starting with an uppercase letter.
Arguments. Given a query in the form of a ground atom, the goal is to derive
arguments for and against it’s validity – derivation follows the same mechanism of logic programming [21]. Since rule heads can contain strong negation,
it is possible to defeasibly derive contradictory literals from a program. For the
treatment of contradictory knowledge, PreDeLP incorporates a defeasible argumentation formalism that allows the identification of the pieces of knowledge
that are in conflict and, through the previously mentioned dialectical process,
decides which information prevails as warranted. This dialectical process involves

hA1 , si
hA3 , si
hA5 , ui
hA7 , ¬ui

A1
A3
A5
A7

= {θ1a , δ1a }
= {φ1 , δ2 , δ4 }
= {φ1 , δ4 }
= {φ3 , δ5a }

hA2 , si A2 = {φ1 , φ2 , δ4 , ω2a , θ1a , θ2 }
hA4 , si A4 = {φ2 , δ3 , θ2 }
hA6 , ¬si A6 = {δ1b , θ1b , ω1a }

Fig. 2. Example ground arguments from the framework of Figure 1.

the construction and evaluation of arguments, building a dialectical tree in the
process. Arguments are formally defined next.
Definition 3. An argument hA, Li for a literal L is a pair of the literal and
a (possibly empty) set of the EM (A ⊆ ΠAM ) that provides a minimal proof
for L meeting the following requirements: (i) L is defeasibly derived from A;
(ii) Ω ∪ Θ ∪ A is not contradictory; and (iii) A is a minimal subset of ∆ ∪ Φ
satisfying 1 and 2, denoted hA, Li.
Literal L is called the conclusion supported by the argument, and A is the
support of the argument. An argument hB, Li is a subargument of hA, L′ i iff
B ⊆ A. An argument hA, Li is presumptive iff A ∩ Φ is not empty. We will also
use Ω(A) = A ∩ Ω, Θ(A) = A ∩ Θ, ∆(A) = A ∩ ∆, and Φ(A) = A ∩ Φ.
Our definition differs slightly from that of [22], where DeLP is introduced, as
we include strict rules and facts as part of arguments – the reason for this will
become clear in Section 4. Arguments for our scenario are shown next.
Example 3. Figure 2 shows example arguments based on the knowledge base
from Figure 1. Note that hA5 , ui is a sub-argument of hA2 , si and hA3 , si.

Given an argument hA1 , L1 i, counter-arguments are arguments that contradict it. Argument hA2 , L2 i is said to counterargue or attack hA1 , L1 i at a
literal L′ iff there exists a subargument hA, L′′ i of hA1 , L1 i such that the set
Ω(A1 ) ∪ Ω(A2 ) ∪ Θ(A1 ) ∪ Θ(A2 ) ∪ {L2 , L′′ } is contradictory.
Example 4. Consider the arguments from Example 3. The following are some of
the attack relationships between them: A1 , A2 , A3 , and A4 all attack A6 ; A5
attacks A7 ; and A7 attacks A2 .

A proper defeater of an argument hA, Li is a counter-argument that – by
some criterion – is considered to be better than hA, Li; if the two are incomparable according to this criterion, the counterargument is said to be a blocking
defeater. An important characteristic of PreDeLP is that the argument comparison criterion is modular, and thus the most appropriate criterion for the domain
that is being represented can be selected; the default criterion used in classical
defeasible logic programming (from which PreDeLP is derived) is generalized
specificity [23], though an extension of this criterion is required for arguments
using presumptions [1]. We briefly recall this criterion next – the first definition is for generalized specificity, which is subsequently used in the definition of
presumption-enabled specificity.

Definition 4. Let ΠAM = (Θ, Ω, Φ, ∆) be a PreDeLP program and let F be
the set of all literals that have a defeasible derivation from ΠAM . An argument
hA1 , L1 i is preferred to hA2 , L2 i, denoted with A1 ≻P S A2 iff:
(1) For all H ⊆ F , Ω(A1 ) ∪ Ω(A2 ) ∪ H is non-contradictory: if there is a
derivation for L1 from Ω(A2 ) ∪ Ω(A1 ) ∪ ∆(A1 ) ∪ H, and there is no derivation
for L1 from Ω(A1 ) ∪ Ω(A2 ) ∪ H, then there is a derivation for L2 from Ω(A1 ) ∪
Ω(A2 ) ∪ ∆(A2 ) ∪ H; and
(2) there is at least one set H ′ ⊆ F , Ω(A1 ) ∪ Ω(A2 ) ∪ H ′ is non-contradictory,
such that there is a derivation for L2 from Ω(A1 ) ∪ Ω(A2 ) ∪ H ′ ∪ ∆(A2 ), there
is no derivation for L2 from Ω(A1 ) ∪ Ω(A2 ) ∪ H ′ , and there is no derivation for
L1 from Ω(A1 ) ∪ Ω(A2 ) ∪ H ′ ∪ ∆(A1 ).
Intuitively, the principle of specificity says that, in the presence of two conflicting lines of argument about a proposition, the one that uses more of the available information is more convincing. A classic example involves a bird, Tweety,
and arguments stating that it both flies (because it is a bird) and doesn’t fly (because it is a penguin). The latter argument uses more information about Tweety
– it is more specific – and is thus the stronger of the two.
Definition 5 ([1]). Let ΠAM = (Θ, Ω, Φ, ∆) be a PreDeLP program. An argument hA1 , L1 i is preferred to hA2 , L2 i, denoted with A1 ≻ A2 iff any of the
following conditions hold:
(1) hA1 , L1 i and hA2 , L2 i are both factual arguments and hA1 , L1 i ≻P S hA2 , L2 i.
(2) hA1 , L1 i is a factual argument and hA2 , L2 i is a presumptive argument.
(3) hA1 , L1 i and hA2 , L2 i are presumptive arguments, and
(a) Φ(A1 ) ( Φ(A2 ) or,
(b) Φ(A1 ) = Φ(A2 ) and hA1 , L1 i ≻P S hA2 , L2 i.
Generally, if A, B are arguments with rules X and Y , resp., and X ⊂ Y , then A
is stronger than B. This also holds when A and B use presumptions P1 and P2 ,
resp., and P1 ⊂ P2 .
Example 5. The following are some relationships between arguments from Example 3, based on Definitions 4 and 5.
A1 and A6 are incomparable (blocking defeaters);
A6 ≻ A2 , and thus A6 defeats A2 ;
A5 and A7 are incomparable (blocking defeaters).



A sequence of arguments called an argumentation line thus arises from this
attack relation, where each argument defeats its predecessor. To avoid undesirable sequences, which may represent circular argumentation lines, in DeLP an
argumentation line is acceptable if it satisfies certain constraints (see [20]). A
literal L is warranted if there exists a non-defeated argument A supporting L.
Clearly, there can be more than one defeater for a particular argument hA, Li.
Therefore, many acceptable argumentation lines could arise from hA, Li, leading to a tree structure. The tree is built from the set of all argumentation lines

rooted in the initial argument. In a dialectical tree, every node (except the root)
represents a defeater of its parent, and leaves correspond to undefeated arguments. Each path from the root to a leaf corresponds to a different acceptable
argumentation line. A dialectical tree provides a structure for considering all
the possible acceptable argumentation lines that can be generated for deciding
whether an argument is defeated. We call this tree dialectical because it represents an exhaustive dialectical4 analysis for the argument in its root. For a given
argument hA, Li, we denote the corresponding dialectical tree as T (hA, Li).
Given a literal L and an argument hA, Li, in order to decide whether or not a
literal L is warranted, every node in the dialectical tree T (hA, Li) is recursively
marked as “D” (defeated ) or “U” (undefeated ), obtaining a marked dialectical
tree T ∗ (hA, Li) as follows:
1. All leaves in T ∗ (hA, Li) are marked as “U”s, and
2. Let hB, qi be an inner node of T ∗ (hA, Li). Then hB, qi will be marked as “U”
iff every child of hB, qi is marked as “D”. The node hB, qi will be marked as
“D” iff it has at least a child marked as “U”.
Given an argument hA, Li obtained from ΠAM , if the root of T ∗ (hA, Li) is
marked as “U”, then we will say that T ∗ (hA, hi) warrants L and that L is warranted from ΠAM . (Warranted arguments correspond to those in the grounded
extension of a Dung argumentation system [24].) There is a further requirement
when the arguments in the dialectical tree contains presumptions – the conjunction of all presumptions used in even (respectively, odd) levels of the tree must
be consistent. This can give rise to multiple trees for a given literal, as there can
potentially be different arguments that make contradictory assumptions.
We can then extend the idea of a dialectical tree to a dialectical forest. For
a given literal L, a dialectical forest F (L) consists of the set of dialectical trees
for all arguments for L. We shall denote a marked dialectical forest, the set of
all marked dialectical trees for arguments for L, as F ∗ (L). Hence, for a literal
L, we say it is warranted if there is at least one argument for that literal in the
dialectical forest F ∗ (L) that is labeled as “U”, not warranted if there is at least
one argument for the literal ¬L in the dialectical forest F ∗ (¬L) that is labeled
as “U”, and undecided otherwise.

4

Probabilistic PreDeLP

Probabilistic PreDeLP arises from the combination of the environmental and
analytical models (ΠEM and ΠAM , respectively). Intuitively, given ΠAM , every
element of Ω ∪ Θ ∪ ∆ ∪ Φ might only hold in certain worlds in the set WEM –
that is, they are subject to probabilistic events. Therefore, we associate elements
of Ω ∪ Θ ∪ ∆ ∪ Φ with a formula from formEM . For instance, we could associate
formula rainy to fact umbrella to state that the latter only holds when the
probabilistic event rainy holds; since weather is uncertain in nature, it has been
modeled as part of the EM.
4

In the sense of providing reasons for and against a position.

af(θ1a ) = af(θ1b )
af(θ2 )
af(ω1a ) = af(ω1b )
af(ω2a ) = af(ω2b )
af(φ1 )
af(φ2 )

= k ∨ f ∧ h ∨ (e ∧ l)
=i
= True
= True
=c∨a
=f ∧m



af(φ3 )
af(δ1a ) = af(δ1b )
af(δ2 )
af(δ3 )
af(δ4 )
af(δ5a ) = af(δ5b )

=b
= True
= True
= True
= True
= True

Fig. 3. Example annotation function.

We can then compute the probabilities of subsets of Ω ∪ Θ ∪ ∆ ∪ Φ using the
information contained in ΠEM , as we describe shortly. The notion of an annotation function associates elements of Ω ∪ Θ ∪ ∆ ∪ Φ with elements of formEM .
Definition 6. An annotation function is any function af : Ω ∪ Θ ∪ ∆ ∪ Φ →
formEM . We shall use [af ] to denote the set of all annotation functions.
We will sometimes denote annotation functions as sets of pairs (f, af(f )) in
order to simplify the presentation. Figure 3 shows an example of an annotation
function for our running example.
We now have all the components to formally define Probabilistic PreDeLP
programs (P-PreDeLP for short).
Definition 7. Given environmental model ΠEM , analytical model ΠAM , and
annotation function af , a probabilistic PreDeLP program is of the form I =
(ΠEM , ΠAM , af ). We use notation [I] to denote the set of all possible programs.
Given this setup, we can consider a world-based approach; that is, the defeat
relationship among arguments depends on the current state of the (EM) world.
Definition 8. Let I = (ΠEM , ΠAM , af ) be a P-PreDeLP program, argument
hA, Li is valid w.r.t. world w ∈ WEM iff ∀c ∈ A, w |= af(c).
We extend the notion of validity to argumentation lines, dialectical trees,
and dialectical forests in the expected way (for instance, an argumentation line
is valid w.r.t. w iff all arguments that comprise that line are valid w.r.t. w).
We also extend the idea of a dialectical tree w.r.t. worlds; so, for a given world
w ∈ WEM , the dialectical (resp., marked dialectical) tree induced by w is denoted
with Tw hA, Li (resp., Tw∗ hA, Li). We require that all arguments and defeaters in
these trees to be valid with respect to w. Likewise, we extend the notion of
dialectical forests in the same manner (denoted with Fw (L) and Fw∗ (L), resp.).
Based on these concepts we introduce the notion of warranting scenario.
Definition 9. Let I = (ΠEM , ΠAM , af ) be a P-PreDeLP program and L be a
literal formed with a ground atom from GAM ; a world w ∈ WEM is said to be
a warranting scenario for L (denoted w ⊢war L) iff there is a dialectical forest
Fw∗ (L) in which L is warranted and Fw∗ (L) is valid w.r.t. w.

Hence, the set of worlds in the EM where a literal L in the AM must be true
is exactly the set of warranting scenarios – these are the “necessary” worlds:
nec(L) = {w ∈ WEM | (w ⊢war L)}. Now, the set of worlds in the EM where
AM literal L can be true is the following – these are the “possible” worlds:
poss(L) = {w ∈ WEM | w 6⊢war ¬L}. The probability distribution Pr defined
over the worlds in the EM induces an upper and lower bound on the probability
of literal L (denoted PL,Pr ,I ) as follows:
ℓL,Pr ,I =

X

Pr (w),

uL,Pr ,I =

w∈nec(L)

X

Pr (w)

w∈poss(L)

ℓL,Pr ,I ≤ PL,Pr ,I ≤ uL,Pr ,I
Since the EM in general does not define a single probability distribution, the
above computations should be done using linear programs EP-LP-MIN and EPLP-MAX, as described above.
4.1

Sources of Inconsistency

We use the following notion of (classical) consistency of PreDeLP programs: Π
is said to be consistent if there does not exist ground literal a s.t. Π ⊢ a and
Π ⊢ ¬a. For P-PreDeLP programs, there are two main kinds of inconsistency
that can be present; the first is what we refer to as EM, or Type I, (in)consistency.
Definition 10. Environmental model ΠEM is Type I consistent iff there exists
a probability distribution Pr over the set of worlds WEM that satisfies ΠEM .
We illustrate this type of consistency in the following example.
Example 6. The following formula is a simple example of an EM for which there
is no satisfying probability distribution:
rain ∨ hail : 0.3 ± 0;
rain ∧ hail : 0.5 ± 0.1.
A P-PreDeLP program using such an EM gives rise to an example of Type I
inconsistency, as it arises from the fact that there is no satisfying interpretation
for the EM knowledge base.

Assuming a consistent EM, inconsistencies can still arise through the interaction between the annotation function and facts and strict rules. We will refer
to this as combined, or Type II, (in)consistency.
Definition 11. A P-PreDeLP program I = (ΠEM , ΠAM , af ), with ΠAM =
hΘ, Ω, Φ, ∆i, is Type II consistent iff: given any probabilitySdistribution Pr that
satisfies ΠEM , if there exists a world w ∈ WEM such that x∈Θ∪Ω | w|=af(x) {x}
is inconsistent, then we have Pr(w) = 0.

Thus, any EM world in which the set of associated facts and strict rules are
inconsistent (we refer to this as “classical consistency”) must always be assigned
a zero probability. The following is an example of this other type of inconsistency.
Example 7. Consider the EM knowledge base from Example 1, the AM presented
in Figure 1 and the annotation function from Figure 3. Suppose the following
fact is added to the argumentation model:
θ3 = ¬p,
and that the annotation function is expanded as follows:
af (θ3 ) = ¬k.
Clearly, fact θ3 is in direct conflict with fact θ1a – this does not necessarily mean
that there is an inconsistency. For instance, by the annotation function, θ1a holds
in the world {k} while θ3 does not. However, if we consider the world:
w = {f, h)
Note that w |= af (θ3 ) and w |= af (θ2 ), which means that, in this world, two
contradictory facts can occur. Since the environmental model indicates that this
world can be assigned a non-zero probability, we have a Type II inconsist program.

Another example (perhaps easier to visualize) in the rain/hail scenario discussed
above, is as follows: suppose we have facts f = umbrella and g = ¬umbrella,
and annotation function af (f ) = rain ∨ hail and af (g) = wind. Intuitively, the
first fact states that an umbrella should be carried if it either rains or hails,
while the second states that an umbrella should not be carried if it is windy. If
the EM assigns a non-zero probability to formula (rain ∨ hail) ∧ wind, then we
have Type II inconsistency.
In the following, we say that a P-PreDeLP program is consistent if and only
if it is both Type I and Type II consistent. However, in this paper, we focus on
Type II consistency and assume that the program is Type I consistent.
4.2

Basic Operations for Restoring Consistency

Given a P-PreDeLP program that is Type II inconsistent, there are two basic
strategies that can be used to restore consistency:
Revise the EM: the probabilistic model can be changed in order to force the
worlds that induce contradicting strict knowledge to have probability zero.
Revise the annotation function: The annotations involved in the inconsistency
can be changed so that the conflicting information in the AM does not become
induced under any possible world.
It may also appear that a third option would be to adjust the AM – this is,
however, equivalent to modifying the annotation function. Consider the presence

of two facts in the AM: a, ¬a. Assuming that this causes an inconsistency (that
is, there is at least one world in which they both hold), one way to resolve it
would be to remove one of these two literals. Suppose ¬a is removed; this would
be equivalent to setting af(¬a) = ⊥ (where ⊥ represents a contradiction in the
language of the EM). In this paper, we often refer to “removing elements of
ΠAM ” to refer to changes to the annotation function that cause certain elements
of the ΠAM to not have their annotations satisfied in certain EM worlds.
Now, suppose that ΠEM is consistent, but that the overall program is Type
II inconsistent. Then, there must exist a set of worlds in the EM where there is
a probability distribution that assigns each of them a non-zero probability. This
gives rise to the following result.
Proposition 1. If there exists a probability distribution PrSthat satisfies ΠEM
s.t. there exists a world w ∈ WEM where Pr(w) > 0 and x∈Θ∪Ω | w|=af(x) {x}
is inconsistent (Type II inconsistency), then any change made in order to re′
solve
yields a new EM ΠEM
such that
 by modifying only ΠEM
V
V this inconsistency
′
a∈w
/ ¬a : 0 ± 0 is entailed by ΠEM .
a∈w a ∧
Proposition 1 seems to imply an easy strategy of adding formulas to ΠEM
causing certain worlds to have a zero probability. However, this may lead to
′
Type I inconsistencies in the resulting model ΠEM
. If we are applying an EM-only
strategy to resolve inconsistencies, this would then lead to further adjustments
′
to ΠEM
in order to restore Type I consistency. However, such changes could
potentially lead to Type II inconsistency in the overall P-PreDeLP program
′
(by either removing elements of ΠEM
or loosening probability bounds of the
′
sentences in ΠEM ), which would lead to setting more EM worlds to a probability
of zero. It is easy to devise an example of a situation in which the probability
mass cannot be accommodated given the constraints imposed by the AM and
EM together – in such cases, it would be impossible to restore consistency by
only modifying ΠEM . We thus arrive at the following observation:
Observation 1 Given a Type II inconsistent P-PreDeLP program, consistency
cannot always be restored via modifications to ΠEM alone.
Therefore, due to this line of reasoning, in this paper we focus our efforts on
modifications to the annotation function only. However, in the future, we intend
to explore belief revision operators that consider both the annotation function
(which, as we saw, captures changes to the AM) along with changes to the EM,
as well as combinations of the two.

5

Revising Probabilistic PreDeLP Programs

Given a P-PreDeLP program I = (ΠEM , ΠAM , af ), with ΠAM = Ω ∪ Θ ∪ ∆ ∪ Φ,
we are interested in solving the problem of incorporating an epistemic input
(f, af ′ ) into I, where f is either an atom or a rule and af ′ is equivalent to
af , except for its expansion to include f . For ease of presentation, we assume

that f is to be incorporated as a fact or strict rule, since incorporating defeasible
knowledge can never lead to inconsistency. As we are only conducting annotation
function revisions, for I = (ΠEM , ΠAM , af ) and input (f, af ′ ) we denote the
′
′
revision as follows: I • (f, af ′ ) = (ΠEM , ΠAM
, af ′′ ) where ΠAM
= ΠAM ∪ {f }
′′
and af is the revised annotation function.
Notation. We use the symbol “•” to denote the revision operator. We also
slightly abuse notation for the sake of presentation, as well as introduce notation
to convert sets of worlds to/from formulas.
– I ∪ (f, af ′ ) to denote I ′ = (ΠEM , ΠAM ∪ {f }, af ′ ).
– (f, af ′ ) ∈ I = (ΠAM , ΠEM , af ) to denote f ∈ ΠAM and af = af ′ .
– wld(f ) = {w | w |= f } – the set of worlds that satisfy formula f ; and
V
V
– f or(w) = a∈w a ∧ a∈w
/ ¬a – the formula that has w as its only model.

I
– ΠAM
(w) = {f ∈ Θ ∪ Ω | w |= af(f )}

0
I
– WEM
(I) = {w ∈ WEM | ΠAM
(w) is inconsistent}
I
0
– WEM
(I) = {w ∈ WEM
| ∃Pr s.t. Pr |= ΠEM ∧ Pr (w) > 0}
I
Intuitively, ΠAM
(w) is the subset of facts and strict rules in ΠAM whose annota0
tions are true in EM world w. The set WEM
(I) contains all the EM worlds for a
given program where the corresponding knowledge base in the AM is classically
I
inconsistent and WEM
(I) is a subset of these that can be assigned a non-zero
probability – the latter are the worlds where inconsistency in the AM can arise.

5.1

Postulates for Revising the Annotation Function

We now analyze the rationality postulates for non-prioritized revision of belief
bases first introduced in [2] and later generalized in [25], in the context of PPreDeLP programs. These postulates are chosen due to the fact that they are
well studied in the literature for non-prioritized belief revision.

Inclusion: For I • (f, af ′ ) = (ΠEM , ΠAM ∪ {f }, af ′′ ), ∀g ∈ ΠAM , wld af ′′ (g) ⊆
wld(af ′ (g)).
This postulate states that, for any element in the AM, the worlds that satisfy its
annotation after the revision are a subset of the original set of worlds satisfying
the annotation for that element.
Vacuity: If I ∪ (f, af ′ ) is consistent, then I • (f, af ′ ) = I ∪ (f, af ′ )
Consistency Preservation: If I is consistent, then I •(f, af ′ ) is also consistent.
Weak Success: If I ∪ (f, af ′ ) is consistent, then (f, af ′ ) ∈ I • (f, af ′ ).
Whenever the simple addition of the input doesn’t cause inconsistencies to arise,
the result will contain the input.
Core Retainment: For I • (f, af ′ ) = (ΠEM , ΠAM ∪ {f }, af ′′ ), for each w ∈
I
WEM
(I ∪ (f, af ′ )), we have Xw = {h ∈ Θ ∪ Ω | w |= af ′′ (h)}; for each g ∈

ΠAM (w) \ Xw there exists Yw ⊆ Xw ∪ {f } s.t. Yw is consistent and Yw ∪ {g} is
inconsistent.
For a given EM world, if a portion of the associated AM knowledge base is
removed by the operator, then there exists a subset of the remaining knowledge
base that is not consistent with the removed element and f .
I
Relevance: For I • (f, af ′ ) = (ΠEM , ΠAM ∪ {f }, af ′′ ), for each w ∈ WEM
(I ∪
′
′′
(f, af )), we have Xw = {h ∈ Θ ∪ Ω | w |= af (h)}; for each g ∈ ΠAM (w) \ Xw
there exists Yw ⊇ Xw ∪ {f } s.t. Yw is consistent and Yw ∪ {g} is inconsistent.
For a given EM world, if a portion of the associated AM knowledge base is
removed by the operator, then there exists a superset of the remaining knowledge
base that is not consistent with the removed element and f .
I
Uniformity 1: Let (f, af ′1 ), (g, af ′2 ) be two inputs where WEM
(I ∪ (f, af ′1 )) =
′
′
I
I
WEM (I ∪ (g, af 2 )); for all w ∈ WEM (I ∪ (f, af )) and for all X ⊆ ΠAM (w); if
{x | x ∈ X ∪ {f }, w |= af ′1 (x)} is inconsistent iff {x | x ∈ X ∪ {g}, w |= af ′2 (x)}
is inconsistent, then for each h ∈ ΠAM , we have that:
I
{w ∈ WEM
(I ∪ (f, af ′1 )) | w |= af ′1 (h) ∧ ¬af ′′1 (h)} =
I
{w ∈ WEM
(I ∪ (g, af ′2 )) | w |= af ′2 (h) ∧ ¬af ′′2 (h)}.

If two inputs result in the same set of EM worlds leading to inconsistencies in
an AM knowledge base, and the consistency between analogous subsets (when
joined with the respective input) are the same, then the models removed from
the annotation of a given strict rule or fact are the same for both inputs.
I
Uniformity 2: Let (f, af ′1 ), (g, af ′2 ) be two inputs where WEM
(I ∪ (f, af ′1 )) =
′
′
I
I
WEM (I ∪ (g, af 2 )); for all w ∈ WEM (I ∪ (f, af ))and for all X ⊆ ΠAM (w); if
{x | x ∈ X ∪ {f }, w |= af ′1 (x)} is inconsistent iff {x | x ∈ X ∪ {g}, w |= af ′2 (x)}
is inconsistent, then
I
{w ∈ WEM
(I ∪ (f, af ′1 )) | w |= af ′1 (h) ∧ af ′′1 (h)} =
I
{w ∈ WEM
(I ∪ (g, af ′2 )) | w |= af ′2 (h) ∧ af ′′2 (h)}.

If two inputs result in the same set of EM worlds leading to inconsistencies in
an AM knowledge base, and the consistency between analogous subsets (when
joined with the respective input) are the same, then the models retained in the
the annotation of a given strict rule or fact are the same for both inputs.
Relationships between Postulates. There are a couple of interesting relationships among the postulates. The first is a sufficient condition for Core
Retainment to be implied by Relevance.
Proposition 2. Let • be an operator such that I • (f, af ′ ) = (ΠEM , ΠAM ∪
I•(f,af ′ )
I
(w) is a maximal consis{f }, af ′′ ), where ∀w ∈ WEM
(I ∪ (f, af ′ )), ΠAM
′
I∪(f,af )
(w). If • satisfies Relevance then it also satisfies Core
tent subset of ΠAM
Retainment.

Similarly, we can show the equivalence between the two Uniformity postulates
under certain conditions.
Proposition 3. Let • be an operator such that I • (f, af ′ ) = (ΠEM , ΠAM ∪
I∪(f,af ′ )
I•(f,af ′ )
(w). Operator • satisfies Unifor(w) ⊆ ΠAM
{f }, af ′′ ) and ∀w, ΠAM
mity 1 iff it satisfies Uniformity 2.
Given the results of Propositions 2 and 3, we will not study Core Retainment
and Uniformity 2 with respect to the construction of a belief revision operator
in the next section.
5.2

An Operator for P-PreDeLP Revision

In this section, we introduce an operator for revising a P-PreDeLP program. As
I
stated earlier, any subset of ΠAM associated with a world in WEM
(I ∪ (f, af ′ ))
must be modified by the operator in order to remain consistent. So, for such a
world w, we introduce a set of candidate replacement programs for ΠAM (w) in
order to maintain consistency and satisfy the Inclusion postulate.
′
′
′
candP gm(w, I) = {ΠAM
| ΠAM
⊆ ΠAM (w) s.t. ΠAM
is consistent and
′′
′′
′′
′
s.t. ΠAM
is consistent}
∄ΠAM ⊆ ΠAM (w) s.t. ΠAM ⊃ ΠAM

Intuitively, candP gm(w, I) is the set of maximal consistent subsets of ΠAM (w).
Coming back to the rain/hail example presented above, we have:
Example 8. Consider the P-PreDeLP program I presented right after Example 7, and the following EM knowledge base:
rain ∨ hail : 0.5 ± 0.1;
rain ∧ hail : 0.3 ± 0.1;
wind : 0.2 ± 0.
Given this setup, we have, for instance:
candP gm({rain, hail, wind}, I) =

n

	 
	o
umbrella , ¬umbrella .

Intuitively, this means that, since the world where rain, hail, and wind are all
true can be assigned a non-zero probability by the EM, we must choose either
umbrella or ¬umbrella in order to recover consistency.

We now show a series of intermediate results that lead up to the representation theorem (Theorem 1). First, we show how this set plays a role in showing a
necessary and sufficient requirement for Inclusion and Consistency Preservation
to hold together.
Lemma 1. Given program I and input (f, af ′ ), operator • satisfies Inclusion
and Consistency Preservation iff for I • (f, af ′ ) = (ΠEM , ΠAM , af ′′ ), for all
I
(I ∪ (f, af ′ )), there exists an element X ∈ candP gm(w, I ∪ (f, af ′ ))
w ∈ WEM
s.t. {h ∈ Θ ∪ Ω ∪ {f } | w |= af ′′ (h)} ⊆ X.

Next, we investigate the role that the set candP gm plays in showing the necessary and sufficient requirement for satisfying Inclusion, Consistency Preservation, and Relevance all at once.
Lemma 2. Given program I and input (f, af ′ ), operator • satisfies Inclusion,
Consistency Preservation, and Relevance iff for I • (f, af ′ ) = (ΠEM , ΠAM , af ′′ ),
I
for all w ∈ WEM
(I ∪ (f, af ′ )) we have {h ∈ Θ ∪ Ω ∪ {f } | w |= af ′′ (h)} ∈
candP gm(w, I ∪ (f, af ′ )).
The last of the intermediate results shows that if there is a consistent program
where two inputs cause inconsistencies to arise in the same way, then for each
world the set of candidate replacement programs (minus the added AM formula)
is the same. This result will be used as a support of the satisfaction of the first
Uniformity postulate.
Lemma 3. Let I = (ΠEM , ΠAM , af ) be a consistent program, (f1 , af ′1 ), (f2 , af ′2 )
I
I
be two inputs, and Ii = (ΠEM , ΠAM ∪ {fi }, af ′i ). If WEM
(I1 ) = WEM
(I2 ), then
I
for all w ∈ WEM (I1 ) and all X ⊆ ΠAM (w) we have that:
1. If {x | x ∈ X ∪ {f1 }, w |= af ′1 (x)} is inconsistent ⇔ {x | x ∈ X ∪ {f2 }, w |=
af ′2 (x)} is inconsistent, then {X \ {f1 } | X ∈ candP gm(w, I1 )} = {X \
{f2 } | X ∈ candP gm(w, I2 )}.
2. If {X \ {f1 } | X ∈ candP gm(w, I1 )} = {X \ {f2 } | X ∈ candP gm(w, I2 )}
then {x | x ∈ X ∪{f1 }, w |= af ′1 (x)} is inconsistent ⇔ {x | x ∈ X ∪{f2 }, w |=
af ′2 (x)} is inconsistent.
We now have the necessary tools to present the construction of our nonprioritized belief revision operator.
Construction. Before introducing the construction, we define some preliminary
notation. Let Φ : WEM → 2[Θ]∪[Ω ] . For each h there is a formula in ΠAM ∪ {f },
where f is part of the input. Given these elements, we define:
^
newFor(h, Φ, I, (f, af ′ )) = af ′ (h) ∧
¬f or(wi )
I (I∪(f,af ′ )) | h∈Φ(w)
w∈WEM
/

The following definition then characterizes the class of operators called AFO
(annotation function-based operators).
Definition 12 (AF-based Operators). A belief revision operator • is an “annotation function-based” (or af-based) operator (• ∈ AFO) iff given program
I = (ΠEM , ΠAM , af ) and input (f, af ′ ), the revision is defined as I • (f, af ′ ) =
(ΠEM , ΠAM ∪ {f }, af ′′ ), where:
∀h, af ′′ (h) = newFor(h, Φ, I, (f, af ′ ))
where ∀w ∈ WEM , Φ(w) ∈ CandP gmaf (w, I ∪ (f, af ′ )).
As the main result of the paper, we now show that satisfying a key set of
postulates is a necessary and sufficient condition for membership in AFO.

Theorem 1 (Representation Theorem). An operator • belongs to class AFO
iff it satisfies Inclusion, Vacuity, Consistency Preservation, Weak Success, Relevance, and Uniformity 1.
Proof. (Sketch) (If) By the fact that formulas associated with worlds in the set
I
WEM
(I ∪(f, af ′ )) are considered in the change of the annotation function, Vacuity and Weak Success follow trivially. Further, Lemma 2 shows that Inclusion,
Consistency Preservation, and Relevance are satisfied while Lemma 3 shows that
Uniformity 1 is satisfied.
(Only-If) Suppose BWOC that an operator • satisfies all postulates and • ∈
/
AFO. Then, one of four conditions must hold: (i) it does not satisfy Lemma 2
or (ii) it does not satisfy Lemma 3. However, by those previous arguments,
if it satisfies all postulates, these arguments must be true as well – hence a
contradiction.


6

Conclusions

We have proposed an extension of the PreDeLP language that allows sentences to
be annotated with probabilistic events; such events are connected to a probabilistic model, allowing a clear separation of interests between certain and uncertain
knowledge. After presenting the language, we focused on characterizing belief
revision operations over P-PreDeLP KBs. We presented a set of postulates inspired in the ones presented for non-prioritized revision of classical belief bases,
and then proceeded to study a construction based on these postulates and prove
that the two characterizations are equivalent.
As future work, we plan to study other kinds of operators, such as more
general ones that allow the modification of the EM, as well as others that operate
at different levels of granularity. Finally, we are studying the application of PPreDeLP to real-world problems in cyber security and cyber warfare domains.
Acknowledgments. The authors are partially supported by UK EPSRC grant
EP/J008346/1 (“PrOQAW”), ERC grant 246858 (“DIADEM”), ARO project
2GDATXR042, DARPA project R.0004972.001, Consejo Nacional de Investigaciones Cientı́ficas y Técnicas (CONICET) and Universidad Nacional del Sur
(Argentina).
The opinions in this paper are those of the authors and do not necessarily
reflect the opinions of the funders, the U.S. Military Academy, or the U.S. Army.

References
1. Martinez, M.V., Garcı́a, A.J., Simari, G.R.: On the use of presumptions in structured defeasible reasoning. In: Proc. of COMMA. (2012) 185–196
2. Hansson, S.: Semi-revision. J. of App. Non-Classical Logics 7(1-2) (1997) 151–175
3. Alchourrón, C.E., Gärdenfors, P., Makinson, D.: On the logic of theory change:
Partial meet contraction and revision functions. J. Sym. Log. 50(2) (1985) 510–530

4. Gardenfors, P.: Knowledge in flux: modeling the dynamics of epistemic states.
MIT Press, Cambridge, Mass. (1988)
5. Hansson, S.O.: Kernel contraction. J. Symb. Log. 59(3) (1994) 845–859
6. Doyle, J.: A truth maintenance system. Artif. Intell. 12(3) (1979) 231–272
7. Falappa, M.A., Kern-Isberner, G., Simari, G.R.: Explanations, belief revision and
defeasible reasoning. Artif. Intell. 141(1/2) (2002) 1–28
8. Li, H., Oren, N., Norman, T.J.: Probabilistic argumentation frameworks. In: Proc.
of TAFA. (2011) 1–16
9. Thimm, M.: A probabilistic semantics for abstract argumentation. In: Proc. of
ECAI 2012. (2012) 750–755
10. Hunter, A.: Some foundations for probabilistic abstract argumentation. In: Proc.
of COMMA 2012. (2012) 117–128
11. Fazzinga, B., Flesca, S., Parisi, F.: On the complexity of probabilistic abstract
argumentation. In: Proc. of IJCAI 2013. (2013)
12. Haenni, R., Kohlas, J., Lehmann, N.: Probabilistic argumentation systems.
Springer (1999)
13. Chesñevar, C.I., Simari, G.R., Alsinet, T., Godo, L.: A logic programming framework for possibilistic argumentation with vague knowledge. In: Proc. of UAI 2004.
(2004) 76–84
14. Hunter, A.: A probabilistic approach to modelling uncertain logical arguments.
Int. J. Approx. Reasoning 54(1) (2013) 47–81
15. Gottlob, G., Lukasiewicz, T., Martinez, M.V., Simari, G.I.: Query answering under
probabilistic uncertainty in Datalog+/– ontologies. AMAI (2013)
16. Nilsson, N.J.: Probabilistic logic. Artif. Intell. 28(1) (1986) 71–87
17. Khuller, S., Martinez, M.V., Nau, D.S., Sliva, A., Simari, G.I., Subrahmanian, V.S.:
Computing most probable worlds of action probabilistic logic programs: scalable
estimation for 1030,000 worlds. AMAI 51(2-4) (2007) 295–331
18. Simari, G.I., Martinez, M.V., Sliva, A., Subrahmanian, V.S.: Focused most probable world computations in probabilistic logic programs. AMAI 64(2-3) (2012)
113–143
19. Rahwan, I., Simari, G.R.: Argumentation in Artificial Intelligence. Springer (2009)
20. Garcı́a, A.J., Simari, G.R.: Defeasible logic programming: An argumentative approach. TPLP 4(1-2) (2004) 95–138
21. Lloyd, J.W.: Foundations of Logic Programming, 2nd Edition. Springer (1987)
22. Simari, G.R., Loui, R.P.: A mathematical treatment of defeasible reasoning and
its implementation. Artif. Intell. 53(2-3) (1992) 125–157
23. Stolzenburg, F., Garcı́a, A., Chesñevar, C.I., Simari, G.R.: Computing Generalized
Specificity. Journal of Non-Classical Logics 13(1) (2003) 87–113
24. Dung, P.M.: On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games. Artif. Intell. 77
(1995) pp. 321–357
25. Falappa, M.A., Kern-Isberner, G., Reis, M., Simari, G.R.: Prioritized and nonprioritized multiple change on belief bases. J. Philosophical Logic 41(1) (2012)
77–113

2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

Social Network Intelligence Analysis to Combat
Street Gang Violence
Damon Paulo, Bradley Fischl, Tanya Markow, Michael Martin, Paulo Shakarian
Network Science Center and
Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY 10996
{damon.paulo, bradley.fischl, tanya.markow, michael.martin1} @usma.edu, paulo@shakarian.net

Abstract—In this paper we introduce the Organization,
Relationship, and Contact Analyzer (ORCA) that is designed
to aide intelligence analysis for law enforcement operations
against violent street gangs. ORCA is designed to address
several police analytical needs concerning street gangs using
new techniques in social network analysis. Specifically, it can
determine “degree of membership” for individuals who do not
admit to membership in a street gang, quickly identify sets of
influential individuals (under the tipping model), and identify
criminal ecosystems by decomposing gangs into sub-groups.
We describe this software and the design decisions considered
in building an intelligence analysis tool created specifically for
countering violent street gangs as well as provide results based
on conducting analysis on real-world police data provided
by a major American metropolitan police department who is
partnering with us and currently deploying this system for
real-world use.
Keywords-complex networks; social networks; criminology

I. I NTRODUCTION
Violent street gangs are a major cause of criminal activity
in the United States [1]. In this paper, we present a new
piece of software, Organizational, Relationship, and Contact
Analyzer (ORCA) that is designed from the ground-up to
apply new techniques in social network analysis and mining
to support law enforcement. In particular, we look to enable
improved intelligence analysis on criminal street gangs. The
software combines techniques from logic programming, [2]
viral marketing, [3], [4] and community detection [5], [6]
in a usable application custom-tailored for law enforcement
intelligence support. This work is inspired by recent work
in law enforcement that recognizes similarities between
gang members and insurgents and identifies adaptations
that can be made from current counter-insurgency (COIN)
strategy to counter gang violence. [1], [7] Due to the striking
similarities between gang-violence and COIN, the authors
from the U.S. Military Academy (West Point) responded
to requests from a major metropolitan police department to
transition recent social network mining software. As a result,
several West Point cadets were able to not only conduct
ASONAM'13, August 25-29, 2013, Niagara, Ontario, CAN
Copyright 2013 ACM 978-1-4503-2240-9 /13/08 ...$15.00

research, but also gain a better understanding of a COIN
environment.
The main contribution of this paper is the ORCA software
which is the first software, to our knowledge, that combine
the aforementioned techniques into a single piece of software
designed for law-enforcement intelligence analysis. The
paper is organized as follows. Section II describes ORCA
and its various components while Section III provides the
results of our preliminary evaluation. Finally, related work
is discussed in Section IV.
II. S YSTEM D ESIGN AND I MPLEMENTATION
The police department we worked with to develop ORCA
described several issues concerning the intelligence analysis
of street gangs. They desired a software system that could
accomplish the following tasks.
1) Ability to ingest police arrest data and visualize network representations of such data. The police data
in question primarily consists of arrest reports which
include the individual’s personal information as well
as claimed gang membership (if disclosed). This data
also includes relationships among individuals arrested
together.
2) Ability to determine degree of group membership.
While many gang members will disclose their gang
affiliation, some will not - likely fearing legal consequences. Hence, to better allocate police efforts and
intelligence gathering resources, it is important to
assign these unaffiliated members to a gang (with a
degree of confidence).
3) Ability to identify sets of influential members. Though
criminal street gangs are decentralized, it is suspected
that there are groups of individuals that can exert influence throughout a given gang - encouraging criminal
activity that is more violent and risky than the norm.
Identifying groups of individuals in this position of influence would provide law enforcement professionals
insight into the ability of these organizations to easily
adopt such behavior.

1042

2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

(which are shown later). These visualizations were also
included in the context of intelligence reports automatically
generated by the software (which are based on the subsequently described components).
A. Determining Degree of Membership

Figure 1.

Overview of components and functions of ORCA.

4) Ability to map the “ecosystem” of a given gang.
Criminal street gangs tend to be highly modular organizations, with identifiable sub-groups. In particular,
“corner crews” - groups of individuals in a gang
who conduct illicit drug transactions on the same
street corner - will form highly connected clusters
in a social network representation of a street gang.
Further, understanding the relationships among these
sub-organizations - both within a given gang and
between different gangs provides substantial insight
into inter/intra gang dynamics as well as in identifying
individuals that connect different organizations.
Note that all of the above described functions were
included in ORCA in a direct response to the needs of
the law enforcement professionals that we have met. These
individuals are directly from our target user population to
whom we are transitioning the software to in mid-2013.
ORCA was written in Python 2.7.3 on top of the NetworkX 1.7 library 1 . In Figure 1 we show our overall
scheme for the design of ORCA to address the above
challenges. The key components we leveraged in building
the system included the MANCaLog framework which we
used to determine degree of membership, TIP DECOMP
was leveraged to find sets of influential members, and the
Louvain algorithm which we built on to map the ecosystems
of the various gangs. We describe how we designed each
major part throughout the remainder of this section.
Police data was ingested into the system in the form of
spreadsheet data that was derived from SQL queries from
a police database. For purposes of development and experimental evaluation, all personally-identifying information
was anonymized. From this data, we utilized the “individual
record” number of each person arrested and created a social
network between two individuals that were arrested together
(co-arrestees). To handle this network data structure, we
utilized the Python library NetworkX mentioned earlier. The
police also required visualizations of these social networks
1 http://networkx.github.io/documentation/latest/index.html

Analytically associating arrested individuals with a criminal gang is an important piece of intelligence to law
enforcement officials. Even though analysis itself is not
direct evidence against an individual, it may be used as a
starting point to gather further information. Individuals who
do not admit to being in a gang may still have associates that
do admit to membership of a certain gang. Hence, we looked
to contribute to the solution to this problem by assigning
such individuals a degree of membership - a real number in
the interval [0, 1] that represents the confidence that the individuals is in a given gang. A value of 0 may be interpreted
as having no information on the individual’s affiliation with
a given gang while a value of 1 would be interpreted as the
individual as having admitted to being in the gang. To assign
these degree of membership values, we utilize MANCaLog,
a logic-programming based framework [2]. This framework
considers a network represented as a graph G = (V, E)
where V is a set of vertices and E is a set of (undirected)
relationships. For a given i ∈ V , ηi = {j|(i, j) ∈ E} and
di = |ηi |. The vertices can be assigned with a label from the
set L. Each label assigned to a vertex is given a value (in
the interval [0, 1] which associates that label with the vertex
with a degree of confidence. Hence, we use of network
representation of the co-arrestees as the graph and the set
of different gangs are the labels. Individuals who are known
to be in a certain gang are assigned a confidence value of
1 for that gang and 0 for the others. Through MANCaLog,
we can then assign a degree of confidence to the remaining
nodes derived from rules of the following form:
grp 1 ←



¬grp i , 1, (grp 1 )iﬂ

(1)

i

Intuitively, the above rule says that a node will be assigned
to group 1 if it has not already been assigned to another
group (with a confidence of 1) and has a certain number
of neighbors who are also in group 1. A set of such rules
is referred to as a MANCaLog program and denoted P . A
program may also have facts of the form (grp i , x, v) which
means that vertex v has a degree of membership in group i
with a confidence of x.
In the above rule, the confidence value assigned to a node
being in group 1 is based on the influence function (iﬂ)
which maps natural numbers to reals in the interval [0, 1].
For instance, an influence function may look something like
the following:

1043

2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

Algorithm 1 IFL LEARN

B. Identifying Seed Sets

Require: Group label g, program P

According to the law enforcement professionals we met,
the idea of influence is critical to understanding the behavior
of violent street gangs. Of particular concern is the influence
of radicalizing gang members - charismatic individuals that
not only participate in abnormally risky and violent behavior,
but have the ability to encourage others to do the same.
In order to identify sets of individuals who conduct such
behavior, we consider the idea of influence spread through
the “tipping model” [9]. In such a model, we again consider
a population structured as a social network (G = (V, E))
where each vertex i ∈ V is adjacent to di edges. We
model a social contagion that spreads through the network
as follows: consider unaffected node i. If at least di /2	 of
i’s neighbors have the contagion, then i has the contagion –
otherwise it does not. A key question regarding this model
is to identify a seed set - a set of vertices in the network
that, if initially infected, will lead to the entire population
receiving the contagion. Identifying a seed set provides the
analyst a set of individuals that, when taken together, are
very influential to the overall network. Further, if the seed
set is of minimal size, then the size of the set can be used as a
proxy to measure how easily the network can be influenced.
Unfortunately, a simple reduction from set cover shows that
finding a seed set of minimal size is an NP-hard problem. [3]
However, we have designed a fast heuristic algorithm that
finds seed sets of very small size in practice. [4] This
algorithm is based on the idea of shell decomposition often
cited in physics literature [10], [11], [12], [13] but modified
to ensure that the resulting set will lead to all nodes being
infected. The algorithm, TIP DECOMP is presented in this
section.

Ensure:
1: Let R be an array indexed from 1 to d∗ (the maximum degree
of the network).
2: for i = 1, . . . d∗ do
3:
Set pos = 0, tot = 0
4:
for v ∈ V do
5:
Set Xv = {v  |(v  , v) ∈ E ∧ (g, 1, v  ) ∈ P }
6:
if |Xv | ≥ i then
7:
tot = tot + 1
8:
if (g, 1, v) ∈ P then
9:
pos = pos + 1
10:
end if
11:
end if
12:
end for
13:
If i = 0, R[i] = pos/tot − 1.96 ∗ SER(pos, tot),
else R[i] = max(R[i − 1], pos/(pos + neg) − 1.96 ∗
SER(pos, tot)) where SER is the standard error on the
fraction of positive neighbors.
14: end for
15: return R

⎧
⎪
⎨0.0
ifl(x) = 0.1
⎪
⎩
0.5

if x = 0
if 1 ≤ x ≤ 3
if x ≥ 4

(2)

In [2], the authors showed that such confidence values
can be assigned to all vertices in the network for all labels
in polynomial time. However, a key issue is to derive the
influence function for the rules. We devised a simple strategy
for learning the influence function for each label (in this case
group) and have included it as algorithm IFL LEARN.
Algorithm IFL LEARN considers one group label (g) and
finds the fraction of neighbors. We view each node as getting
“signals” from its neighbors who are in that group. For
each potential number of signals (which is between one and
the maximum in-degree of the network) Algorithm 1 below
computes the fraction of nodes with at least that number of
signals who are in the group. It then computes the 95% lower
bound confidence interval based on standard error. This is
used as the lower bound of the degree of membership as
returned by the function. Then, based on an assumption of
monotonicity (based on the results of [8]), the algorithm sets
the lower bound to be the maximum between the previous
lower bound and the current.
The algorithm returns a matrix R, and the resulting
influence function is iﬂ (x) = R[x]. This algorithm is a
simple approach to learning rules from available data and no
novelty is claimed; more complex and general approaches
to rule learning are outside the scope of this paper and are
the topic of ongoing work.

Algorithm 2 TIP DECOMP
Require: Threshold function, θ and directed social network
G = (V, E)
Ensure: V 
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

For each vertex i, disti = 
di /2.
FLAG = TRUE.
while FLAG do
Let i be the element of V where disti is minimal.
if disti = ∞ then
FLAG = FALSE.
else
Remove i from G and for each j in ηi , if distj > 0,
set distj = distj − 1. Otherwise set distj = ∞.
end if
end while
return All nodes left in G.

Intuitively, the algorithm proceeds as follows (Figure 1).
Given network G = (V, E),at each iteration, pick the node
for which 
di /2 is the least but positive (or 0) and remove

1044

2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

partitions. A formal definition of this modularity for an
undirected network is defined as follows.
Given partition C = {c1 , . . . , cq }, modularity,
1 
M (C) =
wij − Pij
2m
i,j∈c
c∈C

k k

Figure 2. Example of TIP DECOMP for a simple network depicted in
box A. Next to each node label (lower-case letter) is the value for di /2.
In the first four iterations, nodes e, f, h, and i are removed resulting in the
network in box B. This is followed by the removal of node j resulting in
the network in box C. In the next two iterations, nodes a and b are removed
(boxes D-E respectively). Finally, node c is removed (box F). The nodes of
the final network, consisting of d and g, have negative values for di /2
and become the output of the algorithm.

it. Once there are no nodes for which this quantity is positive
(or 0), the algorithm outputs the remaining nodes in the
network.
In addition to providing the seed set for each street
gang, ORCA also provides information about influential
individuals. The shell number for each vertex based on the
process of shell decomposition [10] has been previously
shown to correlate with the vertex’s influence based on the
networked version of various epidemic models. [12]
C. Identifying Ecosystems
Another important capability for ORCA was to decompose street gangs into component organizations. In some
cases, street gangs will not be monolithic organizations, but
rather confederations of various factions - many of which
may be ill identified by authorities. Further, to maintain a
gang’s lines of funding, sub-organizations known as “corner
crews” operate as an informal unit to conduct narcotics sales
within certain parts of a given gang’s territory.
A common method to identify communities in a social
network is to partition it in a way to maximize a quantity known as modularity. [5] We shall use the notation
C = {c1 , . . . , cq } to denote a partition over set V where
each ci ∈ C isa subset of V , for any ci , cj ∈ C,
ci ∩ cj = ∅ and i ci = V . For a given partition, C, the
modularity M (C) is a number in [−1, 1] . The modularity
of a network partition can be used to measure the quality of
its community structure. Originally introduced by Newman
and Girvan [5], this metric measures the density of edges
within partitions compared to the density of edges between

i j
where Pij = 2m
.
The modularity of an optimal network partition can be
used to measure the quality of its community structure.
Though modularity-maximization is NP-hard, the approximation algorithm of Blondel et al. [6] (a.k.a. the “Louvain
algorithm”) has been shown to produce near-optimal partitions.2 The modularity associated with this algorithm is often
called the “Louvain modularity” and the associated partition
is a “Louvain partition.”
ORCA not only finds the Louvain partition, but also
explores the relationships among the sub-groups within and
between gangs. For a given gang, ORCA generates a graph
showing the relationship among all sub-groups in that gang
and the neighboring sub-groups from different gangs. We
call this the “ecosystem” of a given gang. The ecosystem
is of particular importance to law-enforcement officers for
many reasons. One, in particular, is the issue of gang
retaliation. Consider the following: in the aftermath of a
violent incident initiated by group A against group B, police
enforcement will increase patrols in the territory controlled
by group B. As a result, group B will rely on an allied
organization (group C) to conduct retaliatory action against
group A. Identifying the ecosystem of a given gang helps
provide insight into organizations likely to conduct such
activities.
Further, it identifies individuals who have connections to
various other sub-groups. The intuition behind these individuals is that they connect various organizations together.
We refer to these individuals as “connectors.” Connectors
are also important to law-enforcement personnel as they
are individuals who often connect geographic disparate
sub-groups of a larger gang organization. Another use for
connectors is as a liaison between gangs that cooperate. For
instance, suppose group 1 wants to sell drugs in group 2’s
territory. An agreement is reached between the two groups
that group 1 can conduct these sales provided it pays a tax
to group 2. Hence, a liaison between the two groups may
be a facilitator in such an arrangement.

III. E VALUATION
We evaluated ORCA on a police dataset of 5418 arrests
from a single police district over a three period of time.
There were 11, 421 relationships among the arrests. From
this data, ORCA assembled a social network consisting of
1468 individuals (who were members in one of 18 gangs)
2 Louvain modularity was computed using the implementation available
from CRANS at http://perso.crans.org/aynaud/communities/.

1045

2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

Figure 3.

Influence functions for five of the gangs examined by ORCA.

Figure 4. Histogram showing the number of individuals assigned a degree
of membership within a certain range.

and 1913 relationships. ORCA was able to complete this
assembly in addition to all analysis (determining degree of
membership, finding seed sets, and developing ecosystems)
took 34.3 seconds on a commodity laptop (Windows 8, B960
2.2 GHz processor with 4 GB RAM).
A. Degree of Membership
First, we examined the performance of the system in
identifying degree of membership. As stated earlier, this
was determined using our MANCaLog framework that operated in two steps: learning the influence functions and
then applying the MANCaLog inference engine to compute
degree of membership. Figure 3 shows a plot of the influence
functions derived for five of the gangs. Specifically, it shows
the number of neighboring individuals in the given gang on
the x-axis compared to the computed degree of membership
for an individual having that number of gang contacts on the
y-axis. We note that our degree of membership computation
provides a similar result to [8] which studies the related
problem of social contagion.
In the second step required to determine the degree of
membership, the MANCaLog inference engine created logic
programs that utilized the influence functions to determine
degree of membership for individuals who did not admit
to being in a gang. All of the 180 unadmitted individuals
connected to the derived social network (individuals who
did not admit to being in a gang but were arrested with at
least one other individual in the district) were assigned a
non-zero degree of membership based on learned rules. The
majority of these individuals could be assigned a degree
of membership greater than 0.5 for at least one gang (see
Figure 4). We note that many of these individuals were
assigned a degree of membership to multiple gangs. This
may primarily be due to the fact that the included arrest
reports spanned a three-year time-frame - which our police
counterparts state is a relatively long period of time in
street gang culture. In such a time, gang members often
change allegiances and/or form new gangs. Exploring a
longitudinal study where time is explicitly considered is
an important direction for future work. The MANCaLog
framework allows for temporal reasoning as well.

Figure 5. Seed size as a percentage of the total gang membership for
the 18 street gangs analyzed by ORCA organized into two different racial
groups.

B. Seed Set Identification
We also examined the seed sets found by ORCA for each
of the street gangs. These are sets of individuals who can
initiate a social cascade (under the majority threshold tipping
model) that will cause universal adoption in the gang. The
size of the seed set as a percentage of the population of each
gang is shown in Figure 5. The street gangs in the police
district we examined were racially segregated - belonging
to one of two races. Police officers working in the district
have told us that gangs of Racial Group A are known for
a more centralized organizational structure while gangs of
Racial Group B have adopted a decentralized model. These
groups are denoted in Figure 4. We were able to quantify
this observation as the gangs in Racial Group A had (on
average) seed sets 3.86% smaller than those in Group B.
C. Finding Communities and Identifying Ecosystems
As stated earlier, law enforcement personnel have much
interest in identifying sub-organizations of a given street
gang. ORCA tackled this problem using the Louvain algorithm as described in the previous section. For the 18 street
gangs examined in this study, ORCA identified subgroups
for each in an attempt to optimize modularity. As modularity
approaches 1.0, the communities produced by the algorithm
become more segregated. We show the modularity values
in Figure 6. Again, we also noticed a difference in the
organizational structure based on the gang’s race (aligning

1046

2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

Figure 6. The modularity of the partition found with the Louvain algorithm
for each gang.

with anecdotal police observations). Gangs associated with
Racial Group A (more centralized) had lower modularity
scores (by an average of 11.2%) than gangs associated
with Racial Group B (decentralized). This also corresponds
with police observations that gangs affiliated with Racial
Group B tend to operate in smaller factions (where the gang
organizations server more as a confederation) as opposed
to gangs affiliated with Group A (which are typically more
hierarchical).
The creation of a gang’s ecosystem (as described earlier)
is derived directly from the result of the Louvain partition. Sub-groups identified with the partition are connected
together based on social links between members or by
members who claim to be in more than one gang. Such an
ecosystem is shown in Figure 7. ORCA also provides an analytical report of an ecosystem listing all sub-group relations
and the strength of the relations (based on number of social
ties between organizations) (see Figure 8). Additionally,
ORCA also could identify individuals that connected various
organizations. Example output of this feature is shown in
Figure 9.

Figure 7. An example ecosystem for one of the gangs analyzed by ORCA.

Figure 8. An example ecosystem analysis for one of the gangs analyzed
by ORCA.

D. User Interface
Another priority in developing ORCA was to make the
software accessible to a variety of police personnel. We
created a user interface using the TKinter library version 8.53
and provided network visualizations using Matplotlib 1.2.04 .
As displayed in Figure 10, the users can utilize the interface
to easily run new analysis using arrest and relationship data
taken from the result of a database query. They can also
view the reports generated by completed analyisis. When the
analysis is complete, the law enforcement personnel have the
ability to view a full report that is automatically generated in
a portable document format (PDF) using version 1.7 of the
PyFPDF library5 . This is useful because it is a widely used
format that is familiar to most users. In addition to the full
report, the users can also view specific reports or network
3 http://wiki.python.org/moin/TkInter
4 http://matplotlib.org/
5 https://code.google.com/p/pyfpdf/

Figure 9.
An example report of connectors within one of the gangs
analyzed by ORCA.

visualizations which allows them to easily view the results
of the analysis that has been conducted. Finally, we would
like to note that this is a draft interface that we will refine
throughout the summer of 2013 by conducting studies in the
field as law enforcement personnel utilize the software. We
plan to incorporate the feedback that we gather into further

1047

2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

for use “out of the box” in a general-purpose social network
analysis package such as ORA or NodeXL.
V. C ONCLUSION

Figure 10. The ORCA user interface with network visualization and PDF
report output.

versions of the software so that it becomes a more useful
and usable tool.
IV. R ELATED W ORK
There have been several other pieces of software introduced for both general purpose network analysis as well as
for law enforcement. The main contribution of the software
presented in this paper if the ORCA software. ORCA is that
it is tailor made for specific police requirements dealing with
violent street gangs. Further, it leverage new articiial intellignece and data mining techniques such as MANCALog
and TIP DECOMP. Although ORCA is the first attempt to
combine these techniques in a piece of intelligence analysis
software, there have been other efforts to build software
designed for social network-based intelligence analysis that
we describe below.
Previous software designed to support law-enforcement
through social network analysis include CrimeFighter [14]
and CrimeLink [15]. However, these tools provide complementary capabilities to ORCA. While ORCA is primarily
designed for intelligence analysis with respect to street
gangs, CrimeLink is designed to support investigations while
CrimeFighter is directed more toward targeting of individuals in criminal organizations - rather than understanding
membership in and linkages between sub-groups. Further,
neither of these software packages support degree of membership, seed set identification, or the creation of ecosystems.
General-purpose social network analysis software also
exist, including the Organization Risk Analyzer (ORA) [16],
and NodeXL (an add-on to Microsoft Excel) [17]. While
these tools are very powerful and contain many features,
they do not provide the degree of membership calculation or
the identification of seed sets as ORCA does. ORCA is also
purposely designed for police intelligence analysts to better
understand street gangs, and features such as community
finding in ORCA are designed for with this application in
mind (hence the creation of ecosystems and identification
of inter-group connectors). This nuanced use of community
detection for street gang intelligence analysis is not ready

In this paper we introduced ORCA - the Organizational,
Relationship, and Contact Analyzer - a tool designed from
the ground-up to support intelligence analysis to aide law
enforcement personnel in combating violent street gangs.
We have shown how ORCA can meet various police analysis
needs to include determining degree for gang members of
unknown affiliation, identifying sets of influential individuals
in a gang, and finding and analyzing the sub-organizations
of a gang to determine inter/intra-group relationships.
Our next step with regard to this work is to integrate
geospatial and temporal elements in the analysis - particularly with respect to community finding and degree of
membership. Currently we are working closely with a major
metropolitan police department to transition ORCA for use
in law enforcement. Throughout the summer of 2013, we are
sending project assistants to work closely with the police in
order to identify additional police requirements that can be
addressed with techniques similar to those discussed in this
paper. Currently the police are employing this analysis for
one district. There are plans to expand to other districts in
late 2013.
ACKNOWLEDGMENT
The authors are supported under by the Army Research
Office (project 2GDATXR042) and the Office of the Secretary of Defense. The opinions in this paper are those of
the authors and do not necessarily reflect the opinions of the
funders, the U.S. Military Academy, or the U.S. Army.

1048

R EFERENCES
[1] J. Bertetto, “Countering criminal street gangs: Lessons from
the counterinsurgent battlespace,” Law Enforcement Executive
Forum, vol. 12, no. 3, p. 43, 2012.
[2] P. Shakarian, G. I. Simari, and R. Schroeder, “MANCaLog: A
logic for multi-attribute network cascades,” in Proc. of 26th
Intl. Conf. on Autonomous Agents and Multiagent Systems
(AAMAS), May 2013.
[3] D. Kempe, J. Kleinberg, and E. Tardos, “Maximizing the
spread of influence through a social network,” in KDD
’03: Proceedings of the ninth ACM SIGKDD international
conference on Knowledge discovery and data mining. New
York, NY, USA: ACM, 2003, pp. 137–146.
[4] P. Shakarian and D. Paulo, “Large social networks can be
targeted for viral marketing with small seed sets,” in Proc.
2012 IEEE/ACM Intl. Conf. on Advances in Social Networks
Analysis and Mining (ASONAM-12), Aug. 2012.
[5] M. E. J. Newman and M. Girvan, “Finding and evaluating
community structure in networks,” Phys. Rev. E, vol. 69,
no. 2, p. 026113, Feb 2004.

2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

[6] V. Blondel, J. Guillaume, R. Lambiotte, and E. Lefebvre,
“Fast unfolding of communities in large networks,” Journal
of Statistical Mechanics: Theory and Experiment, vol. 2008,
p. P10008, 2008.
[7] E. Goode, “Combating gang warfare with green beret tactics,”
The New York Times, Apr. 2012.
[8] D. Centola, “The Spread of Behavior in an Online Social
Network Experiment,” Science, vol. 329, no. 5996, pp. 1194–
1197, Sep. 2010.
[9] M. Granovetter, “Threshold models of collective behavior,”
The American Journal of Sociology, no. 6, pp. 1420–1443.
[10] S. B. Seidman, “Network structure and minimum degree,”
Social Networks, vol. 5, no. 3, pp. 269 – 287, 1983.
[11] S. Carmi, S. Havlin, S. Kirkpatrick, Y. Shavitt, and
E. Shir, “From the Cover: A model of Internet
topology using k-shell decomposition,” PNAS, vol. 104,
no. 27, pp. 11 150–11 154, 2007. [Online]. Available:
http://www.pnas.org/cgi/content/abstract/104/27/11150

[13] G. J. Baxter, S. N. Dorogovtsev, A. V. Goltsev, and J. F. F.
Mendes, “Heterogeneous k-core versus bootstrap percolation
on complex networks,” Phys. Rev. E, vol. 83, May 2011.
[14] R. Petersen, C. Rhodes, and U. Wiil, “Node removal in
criminal networks,” in Intelligence and Security Informatics
Conference (EISIC), 2011 European, Sep. 2011, pp. 360 –
365.
[15] J. Schroeder, J. Xu, and H. Chen, “Crimelink explorer: Using
domain knowledge to facilitate automated crime association analysis,” in Intelligence and Security Informatics, ser.
Lecture Notes in Computer Science, H. Chen, R. Miranda,
D. Zeng, C. Demchak, J. Schroeder, and T. Madhusudan, Eds.
Springer Berlin Heidelberg, 2003, vol. 2665, pp. 168–180.
[16] K. M. Carley, “Ora: Organization risk analyzer,” CMU CASOS, Tech. Rep. January, 2004.
[17] D. Hansen, B. Shneiderman, and M. A. Smith, Analyzing
Social Media Networks with NodeXL: Insights from a Connected World. San Francisco, CA, USA: Morgan Kaufmann
Publishers Inc., 2010.

[12] M. Kitsak, L. K. Gallos, S. Havlin, F. Liljeros, L. Muchnik,
H. E. Stanley, and H. A. Makse, “Identification of influential
spreaders in complex networks,” Nat Phys, vol. 6, no. 11, pp.
888–893, Nov. 2010.

1049

arXiv:1303.4632v1 [cs.DS] 19 Mar 2013

Geospatial Optimization Problems
Paulo Shakarian

V.S. Subrahmanian

Network Science Center
Dept. of Electrical Engineering and
Computer Science
U.S. Military Academy
West Point, NY 10996
paulo[at]shakarian.net

Dept. of Computer Science
University of Maryland
College Park MD
vs[at]cs.umd.edu

Abstract—There are numerous applications which require the
ability to take certain actions (e.g. distribute money, medicines,
people etc.) over a geographic region. A disaster relief organization must allocate people and supplies to parts of a region after
a disaster. A public health organization must allocate limited
vaccine to people across a region. In both cases, the organization
is trying to optimize something (e.g. minimize expected number
of people with a disease). We introduce “geospatial optimization
problems” (GOPs) where an organization has limited resources
and budget to take actions in a geographic area. The actions result
in one or more properties changing for one or more locations.
There are also certain constraints on the combinations of actions
that can be taken. We study two types of GOPs - goal-based
and benefit-maximizing (GBGOP and BMGOP respectively).
A GBGOP ensures that certain properties must be true at
specified locations after the actions are taken while a BMGOP
optimizes a linear benefit function. We show both problems to
be NP-hard (with membership in NP for the associated decision
problems). Additionally, we prove limits on approximation for
both problems. We present integer programs for both GOPs that
provide exact solutions. We also correctly reduce the number of
variables in for the GBGOP integer constraints. For BMGOP, we
present the BMGOP-Compute algorithm that runs in PTIME
and provides a reasonable approximation guarantee in most
cases.

I. I NTRODUCTION
As geo-located social network data becomes more common
with sites such as FourSquare1 and programs such as RealityMining2, it becomes desirable to reason about such data.
There are numerous applications which require the ability to
take certain actions (e.g. distribute money, medicines, people
etc.) over a geographic region. For instance, a disaster relief
organization must allocate people and supplies in a region
after a disaster. A public health organization needs to allocate
limited vaccine stocks to people across the region. A government needs to allocate funds for education or unemployment
training across a region. However, allocating any resource will
cause certain effects - some desirable, some not - based on
the network connections among geographic locations. In this
paper we present a formal framework that allows reasoning
about such geo-located data in order to answer certain queries
where we have some desired goal to achieve as the result of
1 https://foursquare.com/
2 http://realitycommons.media.mit.edu/

Fig. 1.

Locations in a district - contingency groups and unpopulated areas.

our geographically-based resource allocation - all the while
considering the complex interactions among locations.
Figure 1 shows a 2-dimensional map of a region. A political
candidate can only make so many campaign stops and public
appeals. We assume that a map M is discrete (this is a
common assumption in most GIS systems) and has coordinates
drawn from [0, . . . , M ] × [0, . . . N ] where the bottom left
corner of the map is the point (0, 0). The candidate wants to
identify the best places to campaign or make public appeals
to maximize his exposure. Additionally, the map shows unpopulated areas, areas where campaigning costs are high, and
areas dominated by one of two constituent groups. All of these
factors may affect the set of locations the candidate selects to
optimize his exposure.
In this paper, we introduce geographic optimization problems or GOPs that capture and solve problems such as
those mentioned above. This framework allows one to more
prudently position resources in a manner to achieve a goal
while considering the complex interactions between locations
(that may be modeled as a network). The organization and
contribution of the paper is as follows. Section II formally defines GOPs - specifically we introduce goal-based and benefitmaximizing GOPs (GBGOP and BMGOP respectively). Section III shows that both GBGOP and BMGOP are NP-hard
(with the associated decision problems in the complexity class

NP). Additionally, we prove non-trivial theoretical limits on
approximation: if GBGOP were to be approximated within
the logarithm of the input then NP would have a slightly
super-polynomial oracle. BMGOP cannot be approximated
within a guaranteed factor greater than 0.63 unless P=NP.
Section IV presents integer programs to solve both GBGOP
and BMGOP using an IP solver like CPLEX. In Section V,
we show how to correctly reduce the number of variables
in the integer constraints for GBGOP. We then develop the
BMGOP-Compute algorithm in Section VI that can quickly
approximate a BMGOP in polynomial time and provides an
approximation guarantee.
II. GOP S F ORMALIZED
Throughout this paper, we assume that M = [0, . . . , M ] ×
[0, . . . , N ] is an arbitrary, but fixed “map”. We define a logical
language L whose constant symbols are members of M and
that has an infinite set Lvar of variable symbols disjoint from
M. L has a set G = {g1 , . . . , gn } of unary predicate symbols.
As usual, a term is either a constant symbol or variable symbol.
If t is a term, then gi (t) is an atom. If t is a constant, then
gi (t) is ground. Intuitively, if p ∈ M, then gi (p) says that
point p has property gi . We use BL to denote the set of all
ground atoms. Well-formed formulas (wffs) are defined in the
usual way. (i) Every atom is a wff. (ii) If F, G are wffs, then
so are F ∧ G, F ∨ G, ¬F are all wffs.
Example 2.1: Consider the map Mcpgn in Figure 1 with
predicates G = {hi cost, non pop, grp1 , grp2 , hq1 , hq2 }.
The predicate exposure not depicted in the figure corresponds to a candidate receiving exposure in a certain area. hi cost((1, 9)), hq1 ((4, 3)), non pop((8, 1)), and
grp2 ((5, 8)) are all examples of ground atoms.
A state is any subset of BL . We use S to denote the set of
all states. Satisfaction of formulas is defined in the obvious
way. State s satisfies a ground atom A, denoted s |= A, iff
A ∈ s. s |= F ∨ G iff s |= F or s |= G. s |= F ∧ G iff
s |= F and s |= G. s |= ¬F iff s does not satisfy F .
Example 2.2: The shading shown in Figure 1 defines
a state. For example, hi cost((1, 9)) ∈ scpgn while
exposure((1, 9)) ∈
/ scpgn .
An action maps points to sets of ground atoms.
Definition 2.1 (Action): An action is a mapping a : M →
2BL . We use A to denote the set of actions. An action-point
pair is any member of A × M.
An action-point pair (a, p) is executed if action a takes place
at point p. Thus, one can think of (a, p) as saying that action
a occurs at point p. The result of executing a set SOL of
action-point pairs in state s0 is denoted appl(SOL, s0 ) and
is the set (s0 ∪ {a(p) | (a, p) ∈ SOL}).
Example 2.3: Continuing with example 2.6, our candidate
has actions Acpgn = {nor, appeal1 , appeal2 } where nor
refers to a normal campaign stop and appeal1 , appeal2 refer
to public appeals to constituent groups 1 and 2 respectively.
The actions map to ground atoms as follows.
nor(p) =
appeali (p) =

{exposure(p′ )|
{exposure(p′ )|

¬non pop(p′ ) ∧ d(p, p′ ) ≤ 1}
hqi (p) ∧ grpi (p′ )}

The first action says that when a normal campign stop is made
at point p and p′ is a populated place one distance unit or less
from p, then the candidate has exposure at place p′ as well.
The second action says that if the candidate makes an appeal
(action) at point p and p is the headquarters of interest group
grpi , then the candidate has obtained exposure in all places
associated with interest group grpi .
Definition 2.2 (Cost Function): A cost function, C : A ×
M → [0, 1].
Throughout this paper, we assume the cost function is arbitrary
but fixed and can be computed in constant time. We also
assume that if A × M = {(a1 , p1 ), . . . , (am , pm )}, then ci
is used to denote C(ai , pi ).
Example 2.4: The cost function for our example is C(s)
cpgn
and is defined (based on some state s) as follows:
C(s)
cpgn (a, p) = 1 if hi cost(p) ∈ s and 0.5 otherwise.
We also assume the existence of a set of integrity constraints
IC that specify that certain actions cannot be jointly taken if
some conditions hold w.r.t. the state — such constraints were
defined before by [1].
Definition 2.3 (Integrity Constraint): If Φ is a set of actionpoint pairs and χ is a wff, then Φ ←֓ χ is an integrity
constraint.
When Φ ←֓ χ is ground, this says that if χ is true, then only
one action-point pair in Φ may be executed. Formally, suppose
s is a state and Φ′ is a set of action-point pairs and Φ ←֓ χ is
ground. (s, Φ′ ) |= Φ ←֓ χ iff either s 6|= χ or s |= χ and |Φ ∩
Φ′ | ≤ 1. (s, Φ′ ) satisfies an integrity constraint iff it satisfies
all ground instances of it. (s, Φ′ ) |= IC where IC is a set
of integrity constraints iff (s, Φ′ ) satisfies every constraint in
that set. Given a state s and set IC of integrity constraints, we
use ICs to denote the set of all ground instances of integrity
constraints in IC where the associated wff χ is satisfied by
s3 .
Example 2.5: Continuing Example 2.4, let ICcpgn be
{{appeal1((4, 3)), appeal2 ((10, 7))} ←֓ TRUE}. This constraint says that an appeal can be made to either group 1
or group 2 at their center of influence, but not both — for
instance, these two groups may have opposing views.
We now introduce the goal-based geospatial optimization
problem (GBGOP). This problem takes as input a map M,
initial state s0 , set of actions A, cost function C, integrity
constraints IC, positive real number c, and disjoint sets
Θin , Θout ⊆ BL . Intuitively, c restricts the total cost and
Θin (resp. Θout ) is a set of atoms that must be true (resp.
false) after the actions are applied. Our optimality criteria for
a GBGOP is to minimize the cardinality of the action-point
pairs. A GBGOP can be viewed as an abductive inference
problem (i.e. find a set of actions that lead to the current
state) - where minimal cardinality is a common parsimony
requirement.
Definition 2.4 (GBGOP Solution, Optimal Solution): A
solution to a GBGOP (M, s0 , A, C, IC, c, Θin , Θout ) is a
set SOL ⊆ A × M such that: (i) Σ(ai ,pi )∈SOL ci ≤ c,
3 Formally,

ICs = {(Φ ←֓ χ) ∈ IC|s |= χ}

(ii)
V (s0 , SOL)V |= IC, and (iii) appl(s0 , SOL) |=
Aj ∈Θout ¬Aj .
Ai ∈Θin Ai ∧
A solution SOL is optimal iff there is no other solution
SOL′ such that |SOL′ | ≤ |SOL|.
Our next type of problem is a benefit-maximizing geospatial
optimization problem (BMGOP) that also considers a benefit
function, defined as follows.
Definition 2.5 (Benefit Function): The benefit function,
B : BL → ℜ+ maps atoms to positive real numbers.
Example 2.6: In our running example, we use the benefit
function Bcpgn where Bcpgn (A) = 1 if A has the form
exposure() and 0 otherwise.
As with cost, we assume the benefit function to be arbitrary
but fixed and computable in constant time. We also assume that
if BL = {A1 , . . . , An }, then B(Ai ) is denoted bi . A BMGOP
takes as input, M, s0 , A, C, IC, and c - all defined the same
as for a GBGOP. Additionally it takes benefit function B and
natural number k. Here k is a bound on the number of actions
the agent can take as we attempt to maximize benefit as an
optimality criteria.
Definition 2.6 (BMGOP Solution, Optimal Solution):
A solution to a BMGOP (M, s0 , B, A, C, IC, k, c) is a
set SOL ⊆ A × M such that: (i) |SOL| ≤ k and (ii)
Σ(ai ,pi )∈SOL ci ≤ c, and (iii) (s0 , SOL) |= IC.
A solution SOL
P is optimal iff therePis no other solution
SOL′ such that Ai ∈appl(SOL,s0 ) bi < Ai ∈appl(SOL′ ,s0 ) bi .
III. C OMPLEXITY R ESULTS
Here, we provide complexity results for GBGOPs and
BMGOPs. First, we establish both as being at least NP-hard.
Theorem 1: Given GBGOP (M, s0 , A, C, IC, c, Θin ,
Θout ), finding an optimal solution SOL ⊆ A×M is NP-hard.
This result holds even if for each a ∈ A, p ∈ M, it is the case
that ∀g ′ (p′ ) ∈ a(p), p′ = p - i.e. each action only affects the
point is is applied to.
Proof Sketch. We embed the known NP-hard problem of
SET-COVER [2] which takes as input a set of n elements,
S and a family of m subsets of S, H ≡ {H1 , . . . , Hm },
and outputs H′ ⊆ H s.t. the union of the subsets covers
all elements in S and H′ is of minimal cardinality. We
encode this problem into a GBGOP as follows: we set
G = {g1 , . . . , gn } - each predicate in G corresponds to
an element in S, the map, M consists of a single point,
p, the actions A = {a1 , . . . , am } s..t each action ai A
corresponds to an
S element in H and each is defined as
follows: ai (p) = xj ∈Hi {gj (p)}. The
S cost function C returns
1 for each action-point pair, Θin = gi ∈G {gi (p)}, Θout = ∅,
and finally, we set s0 = ∅, IC = ∅, c = n.

Theorem 2: Given BMGOP (M, s0 , B, A, C, IC, k, c),
finding an optimal solution SOL ⊆ A is NP-hard. This result
holds even if for each a ∈ A, p ∈ M, it is the case that
∀g ′ (p′ ) ∈ a(p), p′ = p - i.e. each action only affects the point
is is applied to).
Proof Sketch. We embed the known NP-hard problem of
MAX-K-COVER [2] which takes as input a set of n elements,

S and a family of m subsets of S, H ≡ {H1 , . . . , Hm }, and
positive integer K and outputs ≤ K subsets from H s.t. the
union of the subsets covers a maximal number of elements
in S. We encode this problem into a BMGOP as follows:
we set G = {g1 , . . . , gn } - each predicate in G corresponds
to an element in S, the map, M consists of a single point,
p, the function B returns 1 for each ground atom, the set
A = {a1 , . . . , am } is set s.t. each action in A corresponds
to an element
in H and each ai is defined as follows:
S
ai (p) = xj ∈Hi {gj (p)}. The cost function C returns 1 for
each action-point pair, and finally, we set s0 = ∅, IC = ∅,
k = K, c = K.

One may think that one can solve GOPs efficiently in practice by using fully polynomial time approximation schemes
(FPTAS). However, by the nature of our constructions used in
the NP-hardness results, this is not possible for either type of
GOP under accepted theoretical assumptions.
Theorem 3: If for some ǫ > 0, there is a PTIME algorithm
to approximate GBGOP within (1 − ǫ) · ln(|A × M|), then
N P ⊂ T IM E(|A × M|O(lg lg |A×M|) ) (NP has a slightly
super-polynomial algorithm).
Follows from Theorem 1 and [2, Theorem 4.4].

Theorem 4: Finding an optimal solution to BMGOP cannot
be approximated in PTIME within a ratio of e−1
e + ǫ (approx.
0.63) for some ǫ > 0 (where e is the inverse of the natural
log) unless P=NP, even when IC = ∅.
Follows from Theorem 2 and [2, Theorem 5.3].

Next, under some reasonable assumptions, the decision
problems for GBGOP/BMGOP are in-NP.
Theorem 5: Given GBGOP (M, s0 , A, C, IC, c, Θin ,
Θout ), if the cost function and all actions a ∈ A can be
polynomially computed, then determining if there is a solution
SOL for the instance of the GBGOP s.t. for some real number
k, |SOL| ≤ k is in-NP.
Theorem 6: Given BMGOP (M, s0 , B, A, C, IC, k, c), if
the cost function, benefit function, and all actions a ∈ A
can be polynomially computed, then determining if there is
a solution SOL for
P the instance of the BMGOP s.t. for some
real number val, Ai ∈appl(SOL,s0 ) bi ≥ val is in-NP.
As stated earlier, a GBGOP may also be viewed as an abductive inference problem. Even though finding a solution (not
necessarily optimal) to a GBGOP can trivially be conducted
in PTIME4 , counting the number of solutions is #P-complete.
This counting problem is difficult to approximate.
Theorem 7: Counting the number of solutions to a GBGOP
(under the assumptions of Theorem 5) is #P-complete.
Proof Sketch. The MONSAT problem [3] takes a set C of m
clauses of K disjunct ed literals (no negation) over set L of
atoms (size n) and outputs “yes” iff there is a subset of L
that satisfies all clauses in C. We encode this into finding a
GBGOP as follows: G = {g1 , . . . , gm } - each predicate in G
4 Return

the set {(ai , pi ) ∈ A × M|ai (pi ) ∩ Θout = ∅}

corresponds to an clause in C (predicate gj corresponds with
clause φj ), M consists of a single point, p, A = {a1 , . . . , an }
- each action in A corresponds to an element in L (action ai
corresponds with literal ℓi ). Each ai is defined as follows:
ai (p) = {gj (p)|{ℓi } |= φj }, C returns 1 for all
S action-point
pairs, s0 = ∅, IC = ∅, c = n, Θin = gi ∈G {gi (p)},
Θout = ∅. Based on this PTIME reduction we show a 1-1
correspondence to MONSAT. Hence, we can parsimoniously
reduce the counting version of MONSAT (number of
solutions) to the counting version of GBGOP (number of
solutions). As the counting version of MONSAT is #P-hard
by [3], we have shown that #P-hardness of the counting
version of GBGOP. As there is an obvious bound on the
number of solutions to a GBGOP, and as the solutions are
verifiable in PTIME, membership in #P follows.

Theorem 8: For ǫ > 0, approximating the number of
1−e
solutions to a GBGOP within a factor of 2|A×M|
is NPhard.
Follows from Theorem 7 and Theorem 3.2 of [3].

Due to this issue with achieving a good approximation of
the counting version, in this paper we shall focus only on
determining a single optimal solution to a GBGOP - rather
than all solutions.
IV. I NTEGER P ROGRAMS

FOR

S OLVING GOP S

In this section, we present an integer programming (IP)
algorithms for both GBGOP and BMGOP which provide exact
solutions. Given a GBGOP, the IP associates an integer-valued
variable Xi with each action-point pair (ai , pi ) ∈ A × M
where ai (pi ) ∩ Θout = ∅. Intuitively, Xi = 1 denotes that
action ai is performed at point pi .
Definition 4.1 (GBGOP-IP): Let set R = {(ai , pi ) ∈ A ×
M|ai (pi )∩Θout = ∅}. For each action-point pair (ai , pi ) ∈ R,
create variable Xi ∈ {0, 1}.
min
s.t.

|R|
X

Xi

(1)

i=1

X

Xj ≥ 1

∀Ai ∈ Θin − s0

(2)

aj (pj )|Ai ∈aj (pj )

X

ci · Xi ≤ c

(3)

(ai ,pi )∈R

X

Xi ≤ 1

∀(Φ ←֓ χ) ∈ ICs0

(4)

(ai ,pi )∈Φ

The objective function minimizes the total number of actionpoint pairs. Constraint (2) ensures that every ground atom in
Θin (that does not appear in the initial state) is caused by
at least one of the selected action-point pairs. Constraint (3)
enforces the constraint on cost. Constraint (4) ensures that the
integrity constraints are satisfied. Next we present our integer
constraints for a BMGOP where the IP associates an integervalued variable Xi with each action-point pair (ai , pi ) ∈ A ×
M, and an integer-valued variable Yj with each ground atom
Aj ∈ BL − s0 . The intuition for the Xi variables is the same
as in GBGOP-IP.

Definition 4.2 (BMGOP-IP): For each action-point pair
(ai , pi ) ∈ A × M, create variable Xi ∈ {0, 1}. For each
Ai ∈ BL − s0 create variable Yi ∈ {0, 1}.
X

max

Ai ∈s0

s.t.

X

|BL |−|s0 |

bi +

bi · Y i

(5)

i=1

X

Xj ≥ Yi

∀Ai ∈ BL − s0

(6)

aj (pj )|Ai ∈aj (pj )

X

Xi ≤ k

(7)

ci · Xi ≤ c

(8)

(ai ,pi )∈A×M

X

(ai ,pi )∈A×M

X

Xi ≤ 1

∀(Φ ←֓ χ) ∈ ICso

(9)

(ai ,pi )∈Φ

In the above IP, the objective function looks at each ground
atom and sums the associated benefit if the associated Yi
variable is 1 - meaning that atom Ai is true after the actions
are applied. Constraint (6) effectively sets a Yi variable to 1
if an action that causes Ai to be true occurs. Constraint (7)
enforces the cardinality requirement. Constraints 8-9 mirror
constraints 3-4 of GBGOP-IP. The result below shows that
a solution σ to the above IPs5 , when restricted to the Xi
variables, provides an immediate solution to the GOP.
Prop. 4.1: Suppose Γ is a GBGOP (resp. BMGOP) and
IP (Γ) is its corresponding integer program (GBGOP-IP, resp.
BMGOP-IP). Then:
1) If SOL is a solution to Γ, then there is a solution σ of
IP (Γ) such that σ ⊇ {Xi = 1 | (ai , pi ) ∈ SOL}.
2) If σ is a solution to IP (Γ), then there is a solution SOL
to Γ such that {Xi = 1 | (ai , pi ) ∈ SOL} ⊆ σ.
As integer programming is NP-complete, any algorithm to
solve a GOP using GBGOP-IP or BMGOP-IP using an IP
solver will take exponential time. We note that for GBGOPIP, the number of variables is fairly large – O(|{(ai , pi ) ∈
A × M|ai (pi ) ∩ Θout = ∅}|) variables and O(|Θin − s0 | +
|ICs0 | + 1) constraints. BMGOP-IP has even more variables (though not exponential) - O(|M| · (|A| + |G|)) variables and
O(|M| · |G| + |ICs0 | + 2) constraints. However, BMGOP-IP
has only packing constraints.6 We also note the GBGOP-IP
has both covering (≥) and packing (≤) constraints - another
source of complexity.
V. C ORRECT VARIABLE R EDUCTION

FOR

GBGOP-IP

The set of integer constraints for GBGOP has O(|R|)
variables where R ⊆ A × M. We show how to correctly
reduce the number of variables by considering only a subset
of R - thereby providing a smaller integer program. Our
intuition is that an optimal solution SOL is an irredundant
cover of Θin meaning there is no subset SOL′ ⊂ SOL that
is also a solution. Hence, we can discard certain elements
5 A solution to GBGOP-IP or BMGOP-IP is an assignment of values
to variables that optimizes the objective function. Thus, a solution can be
described as a set of equations assigning values to the variables Xi , Yj .
6 It is trivial to eliminate constraint 6 and re-write 5 as a non-linear objective
function.

of R that cannot possibly be in an optimal solution. First,
for a given GBGOP Γ = (M, s0 , A, C, IC, c, Θin , Θout ), we
introduce QΓ(a,p) = {Φ|(Φ ←֓ χ) ∈ ICs0 ∧ (a, p) ∈ Φ}
and the set of ground atoms each action-point pair affects
AffΓ(a,p) = ai (pi ) ∩ (Θin − (Θin ∩ s0 )). We can now define a
reduced action-point set.
Definition 5.1 (Reduced Action-Point Set): Given GBGOP
Γ = (M, s0 , A, C, IC, c, Θin , Θout ) and set R = {(ai , pi ) ∈
A × M|ai (pi ) ∩ Θout = ∅}, we define reduced action-point
set R∗ = {(ai , pi ) ∈ R| 6 ∃(aj , pj ) ∈ R s.t.
(cj ≤ ci ) ∧ (QΓ(aj ,pj ) ⊆ QΓ(ai ,pi ) ) ∧ (AffΓ(ai ,pi ) ⊆ AffΓ(aj ,pj ) )}
Example 5.1: Consider
the
campaign
scenario
last
discussed
in
Example
2.5.
Suppose
the
candidate wants to optimize the following GBGOP:
cpgn
cpgn )
Γ = (Mcpgn , scpgn , Acpgn , C(s
cpgn , ICcpgn , 4, Θin , ∅)
cpgn
where each A ∈ Θin has the form exposure(p) where p
is a point in one of the two dashed rectangles in Figure 1.
Note that as map Mcpgn contains 187 points, |A| = 3, and
Θout = ∅, the cardinality of R is 561. By contrast, the set
R∗ consists of only 7 elements, 1.2% of the size of R. Here
R∗ = {(nor, (5, 4)), (nor, (5, 3)), (nor, (5, 2)), (nor, (10, 8)),
(nor, (10, 7)), (nor, (10.6)), (appeal1 , (4, 3))}
Intuitively, all elements in R∗ are preferable for membership
in an optimal solution over R − R∗ as they cost less, result in
the same changes to the state, and occur in the same or fewer
integrity constraints. Set R∗ can be found in quadratic time
with a naive algorithm - an operation that is likely dominated
by solving or approximating GBGOP-IP. The next lemma says
that R∗ must contain an optimal solution.any optimal solution
to a GBGOP. This can then be used to correctly reduce the
number of variables in GBGOP-IP.
Lemma 5.1: Given
GBGOP
Γ
=
(M, s0 , A, C, IC, c, Θin , Θout ), for any optimal solution
SOL ⊆ R, there is an optimal solution SOL′ ⊆ R∗ .7
Prop. 5.1: Suppose Γ is a GBGOP and IP (Γ) is its corresponding integer program. We can create such a program
with a variable for every element of R∗ (instead of R) and
Proposition 4.1 still holds true.
VI. T HE BMGOP-C OMPUTE A LGORITHM
While BMGOP-IP can solve a BMGOP exactly, doing so
is computationally intractable. We now present an approximation algorithm that runs in PTIME but provides a lower
approximation ratio than proved in Theorem 4. First, we
show that a BMGOP reduces to an instance of submodular
maximization problem8 with respect to packing constraints.
We then leverage some known methods [4] to solve such
problems and develop a fast, deterministic algorithm to approximate BMGOP with an approximation bounds. Given
BMGOP Γ = (M, s0 , B, A, C, IC, k, c), consider the objective function in BMGOP-IP. We can write that function as
7 Proof Sketch. We show this by proving that for any set W = SOL∩(R−
R∗ ), there is some set W ′ ⊆ R∗ − (R∗ ∩ SOL) s.t. (SOL − W ) ∪ W ′ is
also a solution.
8 Suppose Z is a set. A function f : 2Z → R is said to be submodular
iff for all Z1 , Z2 such that Z1 ⊆ Z2 and all z ∈
/ Z2 , it is the case that
f (Z1 ∪ {z}) − f (Z1 ) ≥ f (Z2 ∪ {z}) − f (Z2 ), i.e. the incremental value
of adding z to the smaller set Z1 exceeds the incremental value of adding it
to the larger set Z2 . Here, R denotes the reals.

a mapping from action-point pairs to reals. We denote this
function (specific
for BMGOP Γ) as fΓ : 2A×M → ℜ+ , where
P
fΓ (S) = Ai ∈appl(S,s0 ) bi , which has certain properties.
fΓ (S) =

X

bi

(10)

Ai ∈appl(S,s0 )

We now show that this function fΓ is submodular and has
some other nice properties as well.
Prop. 6.1: For BMGOP Γ, function fΓ is: (i) submodular,
(ii) monotonic, i.e. Z1 ⊆ Z2 → fΓ (Z1 ) ≤ fΓ (Z2 ) and (iii)
under the condition ∀Ai ∈ BL , bi = 0, we have fΓ (∅) = 0.9
Proof Sketch. Consider S ⊆ S ′ ⊆ A × M and
(a, p) ∈
/ S ′ . We must show fΓ (S ∪ {(a, p)}) − fΓ (S) ≥
′
fΓ (S ∪ {(a, p)}) − fΓ (S ′ ). Suppose, BWOC fΓ (S ∪
′
′
{(a, p)}) − fΓ (S) < fP
Γ (S ∪ {(a, p)}) − fΓ (S ). Then, by
Equation 10, we have Ai ∈appl(S∪{(a,p)},s0 )−appl(S,s0 ) bi <
P
However, by the
Ai ∈appl(S ′ ∪{(a,p)},s0 )−appl(S ′ ,s0 ) bi .
definition of appl, we have appl(S ∪ {(a, p)}, s0 ) −
appl(S, s0 ) ⊇ appl(S ′ ∪ {(a, p)}, s0 ) − appl(S ′ , s0 ), which is
a contradiction.

As our objective function is submodular, and constraints 79 are linear packing constraints, any instance of a BMGOP
can be viewed as maximization of a submodular function wrt
linear packing constraints and hence, methods to solve such
problems can be used here. The BMGOP-Compute algorithm
leverages this idea and illustrated in Example 6.1.
BMGOP-Compute
INPUT: BMGOP (M, s0 , B, A, C, IC, k, c)
OUTPUT: SOL ⊆ A × M
1) Set SOL = ∅, δ to be an infinitesimal,
and set λ = e2−δ · (2 + |ICs0 |).
2) Set w′ = 1/k and w′′ = 1/c. For each (Φi ←֓ χi ) ∈ ICs0 ,
set wi = 1/(2 − δ).
P
3) While k ·w′ +c·w′′ +(2−δ)· i wi ≤ λ and SOL 6= A×M
a) Let (aj , pj ) ∈ A × M −PSOL have minimal
(

P

w′ +w′′ ·cj +

i|(aj ,pj )∈Φi wi
P
Ai ∈appl(SOL∪{(aj ,pj )},s0 ) bi )−( Ai ∈appl(SOL,s0 ) bi )

b) SOL = SOL ∪ {(aj , pj )}
c) Set w′ = w′ · λ1/k , w′′ = w′′ · λcj /c and for each
integrity constraint i s.t. (aj , pj ) ∈ Φi , set
wi = wi · λ1/(2−δ)
4) If SOL is not a valid solution then
P
a) If Ai ∈appl(SOL−{(aj ,pj )},s0 ) bi ≥
P
Ai ∈appl({(aj ,pj )},s0 ) bi ,
then SOL = SOL − {(aj , pj )}
b) Else SOL = {(aj , pj )}
5) Return SOL

Example 6.1: Following
Example
2.5.
Suppose
the
candidate
wants
to
optimize
BMGOP:
cpgn )
(Mcpgn , scpgn , Bcpgn , Acpgn , C(s
In
cpgn , ICcpgn , 3, 2).
this case, we will set δ = 0.001. He wishes to find a set
of 3 action-point pairs to optimize his exposure. BMGOPCompute sets λ = 22.14, w′ = 0.33, w′′ = 0.50, and
9 Henceforth,

we will assume this condition to be true.

w1 = 0.50 in lines 1 and 2. In the first iteration of the
loop at line 3, it finds the action-point pair that minimizes
the quantity at line 3 is (appeal1 , (4, 3)) - which has the
associated value 0.073. Note, other action-point pairs with low
values are (appeal2 , (10, 7)) with 0.083 and (nor, (15, 6))
also with 0.083. It then adds (appeal1 , (4, 3)) to SOL and
updates w′ = 0.93, w′′ = 1.09, and w1 = 2.35. On the next
iteration, the BMGOP-Compute picks (nor, (15, 6)), which
now has a value of 0.164. During this iteration, the value of
(appeal2 , (10, 7)) has increased substantially - to 0.294, so
it is not selected. At the end of the iteration, w′ is updated
to 2.611 and w′′ is updated to 2.364. As (nor, (15, 6)) does
not impact the lone integrity constraint, the value w1 remains
at 2.354. In the third iteration, BMGOP-Compute selects
(nor, (15, 9)) which has a value of 0.421. Again, the value of
(appeal2 , (10, 7)) has increased - but this time only to 0.472.
BMGOP-Compute re-calculates w′ = 7.331, w′′ = 5.128
and w1 remains at 2.354. On the last iteration, BMGOPCompute picks (appeal2 , (10, 7)) as it has the lowest value
– 0.942. After this fourth iteration, it updates w′ = 20.589,
w′′ = 11.124, and w1 = 11.0861 - which now total to 42.799
– exceeding λ (22.14) – causing BMGOP-Compute to exit
the outer loop. Now SOL has 4 elements, exceeding the
cardinality constraint (as well as the integrity constraint). The
checks done in line 4 remove (appeal2 , (10, 7)) from SOL
- making the result feasible. BMGOP-Compute returns
{(appeal1 , (4, 3)), (nor, (15, 6), (nor, (15, 9))} which causes
the benefit to be 45.
Prop. 6.2: Suppose Γ is a BMGOP and SOL is the set
returned by BMGOP-Compute. Then SOL is a solution to
Γ.10
Next, we sho BMGOP-Compute runs in PTIME.
Prop. 6.3: BMGOP-Compute runs in O(k · |M| · |A| ·
|ICs0 |) time.
Proof Sketch. Clearly, the outer loop can iterate no more than
k times. The inner loop iterates for each element of A × M hence requiring time O(|M| · |A|). There are some additional
operations that require O(|ICs0 |) time, however, they are
dominated under the assumption that |M| · |A| >> |ICs0 |,
which we expect in our application.

The following important theorem states that BMGOPCompute provides an approximation guarantee. Because of
Theorem 4 and as BMGOP-Compute is polynomial, we
know that this approximation guarantee cannot be as good
as e−1
e + ǫ. The result leverages Theorem 1.1 of [4] together
with the above theorems. By this result, the approximation
factor of BMGOP-Compute depends on |ICs0 |. We illustrate
this relationship, in Figure 2. For our target applications, we
envision |ICs0 | ≤ 20.
Theorem 9: Under the assumption that k, c ≥ 2 − δ,
BMGOP-Compute provides a solution within a factor of
1
(where δ is an infinitesimal) of optimal.
(2+|ICs0 |)1/(2−δ)
Proof Sketch. BMGOP-Compute follows from Algorithm 1
10 Here,

SOL is not necessarily an optimal solution.

Fig. 2.

|ICs0 | vs. approximation ratio.

of [4] which optimizes a submodular function subject to m
1
where W is the minimum
packing constraints within m1/W
width of the packing constraints - defined as the minimum of
the size of the constraint divided by the cost of an element.
For constraint 7, the W = k. For constraint
8, the W ≥ c.
P
We can replace constraint 9 with:
(ai ,pi )∈Φj Xi ≤ 2 − δ
∀(Φj ←֓ χj ) ∈ ICso which maintains correctness as two
variables to set to 1 and exceeds 2 − δ. The new constraint
has width 2 − δ, which, is the minimum. We then apply
Theorem 1.1 of [4].

Discussion. We note that while a BMGOP reduces to the maximization of a submodular or linear function wrt linear packing
constraints, there are other algorithms available besides the
multiplicative update algorithm of [4]. However, we feel that
this is likely the best approach for several reasons that we list
below.
1) The approximation ratio achieved by the multiplicativeupdate algorithm matches the best approximation ratio
achievable for maximizing a linear function wrt linear
packing constraints (see [5]), hence, it is unlikely that a
better approximation ratio can be achieved using such a
technique.
2) Other methods (such as those presented in [5]) require
solving a relaxation of the associated MILP. In our case,
such an operation would take O((|M| · (|A| + |G|))3.5 )
time (as a consequence of the number of variables in
BMGOP-MILP and the results of [6]). This is significantly more expensive than the O(k · |M| · |A|) of
BMGOP-MU (see Proposition 6.3). If the map, M is
very large, solving a relaxation of BMGOP-MILP may
be unrealistic on most hardware.
3) The algorithm BMGOP-MU is totally deterministic,
which allow us to avoid the issue de-randomization.
4) The algorithm BMGOP-MU is guaranteed to provide a
solution that meets constraints 7-9 - as opposed to only
meeting them probabilistically.
VII. R ELATED W ORK

AND

C ONCLUSIONS

Though spatial reasoning has been studied extensively in AI
[7], [8], [9], [10], many of the paradigms that have emerged
for such reasoning are qualitative in nature. Such qualitative
spatial reasoning efforts include the influential region connection calculus for qualitative reasoning about space. There
has also been work on quantitative methods for reasoning
about space [11] which contains articles on spatial reasoning
in the presence of uncertainty using both logical and fuzzy

methods. Spatial reasoning with quantitative information has
been studied extensively in image processing [12], [13].
However, unlike this vast body of work, this paper focuses
on a different problem. Suppose we are dealing with a map
M, a cost function C, a set A of possible actions, a bound
on the cost c, and a bound on the number of actions we can
take, what set of actions should be taken so as to optimize a
given objective function. Two versions of this problem are
studied in this paper - GBGOP and BMGOP which differ
in what they optimize. Both problems are proved to be NPhard (NP-complete under realistic assumptions) and we further
prove that the number of solutions to GBGOP is #P-complete.
We also find limits on approximating an optimal solution to
BMGOP and GBGOP (in PTIME) under accepted theoretical
assumptions. We develop integer programming formulations
of both problems and then present a way of simplifying the
IP for GBGOP. We further present the BMGOP-Compute
algorithm for BMGOP and show that it is polynomial and has
a guaranteed approximation ratio (though not high enough to
contract the NP-hardness result).
VIII. C ONCLUSION
In this paper, we introduced “geopspatial optimization problems” or GOPs that aide the user in taking certain actions over
a geographic region. We showed these problems to be NP-hard
and provided integer constraints. For the goal-based variant,
we correctly reduce the number of variables. For the benefitmaximizing variant, we provide an approximation algorithm.
In future work, we look to implement this framework and
explore methods to achieve further scalability, as well as utilize geo-located social network data to establish relationships
among locations in order to better implement action-point pairs
and integrity constraints.
R EFERENCES
[1] T. Eiter, V. Subrahmanian, and G. Pick, “Heterogeneous Active Agents,
I: Semantics,” Artificial Intelligence Journal, vol. 108, no. 1-2, pp. 179–
255, 1999.
[2] U. Feige, “A threshold of ln n for approximating set cover,” J. ACM,
vol. 45, no. 4, pp. 634–652, 1998.
[3] D. Roth, “On the hardness of approximate reasoning,” Artificial Intelligence, vol. 82, pp. 273–302, 1996.
[4] Y. Azar and I. Gamzu, “Efficient submodular function maximization
under linear packing constraints,” (submitted, preprint avaialbe from
http://www.cs.tau.ac.il/∼iftgam/papers/SubmodularPacking.pdf), 2010.
[5] A. Srinivasan, “Improved approximation guarantees for packing and
covering integer programs,” SIAM J. Comput, vol. 29, pp. 648–670,
1995.
[6] N. Karmarkar, “A new polynomial-time algorithm for linear programming,” Combinatorica, vol. 4, no. 4, pp. 373–395, 1984.
[7] S. M. H. Anthony G. Cohn, “Qualitative spatial representation and
reasoning: An overview.” Fundam. Inform., vol. 46, no. 1–2, pp. 1–29,
2001.
[8] O. G. M. J. Egenhofer and H.-J. Schek, “Reasoning about binary
topological relations,” in Advances in Spatial Databases, Lecture Notes
in Computer Science, vol. 525, 1991, pp. 143 – 160.
[9] J. Renz and B. Nebel, “On the complexity of qualitative spatial reasoning: A maximal tractable fragment of the region connection calculus,”
Artif. Intell., vol. 108, pp. 69 – 123, 1999.
[10] S. Li and M. Ying, “Region connection calculus: Its models and
composition table,” Artif. Intell., vol. 145, pp. 121 – 146, 2003.

[11] R. Jeansoulin, O. Papini, H. Prade, and S. Schockaert, Methods for
Handling Imperfect Spatial Information, ser. Studies in Fuzziness and
Soft Computing, R. Jeansoulin, O. Papini, H. Prade, and S. Schockaert,
Eds. Springer Berlin / Heidelberg, 2010, vol. 256.
[12] Y. Weiss and E. Adelson, “A unified mixture framework for motion
segmentation: incorporating spatial coherence and estimating the number
of models,” in Computer Vision and Pattern Recognition, 1996. Proceedings CVPR ’96, 1996 IEEE Computer Society Conference on, Jun. 1996,
pp. 321 –326.
[13] R. Srihari, “Automatic indexing and content-based retrieval of captioned
images,” Computer, vol. 28, no. 9, pp. 49 –56, Sep. 1995.

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

Cyber-Deception and Attribution
in Capture-the-Flag Exercises
Eric Nunes, Nimish Kulkarni, Paulo Shakarian

Andrew Ruef, Jay Little

School of Computing, Informatics and
Decision Systems Engineering
Arizona State University
Tempe, AZ 85281, USA
Email: {enunes1, nimish.kulkarni, shak} @asu.edu

Trail of Bits, Inc.
New York, NY 10003, USA
Email: {andrew, jay} @trailofbits.com

Abstract—Attributing the culprit of a cyber-attack is widely
considered one of the major technical and policy challenges
of cyber-security. The lack of ground truth for an individual
responsible for a given attack has limited previous studies. Here,
we overcome this limitation by leveraging DEFCON capture-theflag (CTF) exercise data where the actual ground-truth is known.
In this work, we use various classification techniques to identify
the culprit in a cyberattack and find that deceptive activities
account for the majority of misclassified samples. We also explore
several heuristics to alleviate some of the misclassification caused
by deception.

I.

I NTRODUCTION

Attributing the culprit of a cyber-attack is widely considered one of the major technical and policy challenges of
cyber-security. The lack of ground truth for an individual
responsible for a given attack has limited previous studies. In
this study, we take an important first step toward developing
computational techniques toward attributing the actual culprit
(here hacking group) responsible for a given cyber-attack. We
leverage DEFCON capture-the-flag (CTF) exercise data which
we have processed to be amenable to various machine learning
approaches. Here, we use various classification techniques to
identify the culprit in a cyber-attack and find that deceptive
activities account for the majority of misclassified samples. We
also explore several heuristics to alleviate some of the misclassification caused by deception. Our specific contributions are
as follows:
•

We assemble a dataset of cyber-attacks with ground
truth derived from the traffic of the CTF held at
DEFCON 21 in 2013.

•

We analyze this dataset to identify cyber-attacks where
deception occurred.

•

We frame cyber-attribution as a multi-label classification problem and leverage several machine learning
approaches. We find that deceptive incidents account
for the vast majority of misclassified samples.

explore the deception hypothesis in a cyber-warfare scenario.
When compared to other domains of warfare, there is a much
greater potential for evidence found in the aftermath of cyberattack to be planted by the adversary for purposes of deception.
The policy implications of cyber-attribution have also been
discussed in [10] where the authors point out that anonymity,
ability to launch multi-stage attacks, and attack speed pose
significant challenges to cyber attribution.
In an early survey on cyber-attribution [1], the authors point
out that technical attribution will generally identify machines,
as opposed to a given hacker and his/her affiliations. While
we will use technical information in our approach, we have
ground truth data on the group involved by the nature of
the capture-the-flag data. This will allow our approach to
profile the tactics, techniques, and procedures of a given group
as we have ground-truth information on a hacking group as
opposed to machines. An example of such an approach is the
WOMBAT attribution method [3] which attributes behavior
to IP sources that are potentially linked to some root cause
determined through a clustering technique. Similarly, other
work [9] combines cluster analysis with a component for multicriteria decision analysis and studied an implementation of this
approach using honeypot data – again, this approach lacks any
ground truth of the actual hacker or hacking group.
Concurrently, we have devised a formal logical framework
for reasoning about cyber-attribution [5], [8]. However, we
have not studied how this framework can be instantiated on
a real world dataset and, to date, we have not reported on an
implementation or experiments in the literature. We note that
none of the previous work on cyber-attribution leverages a
data set with ground truth information of actual hacker groups
– which is the main novelty of this paper.
II.

DATASET

We introduce several pruning techniques and show
that they can reduce the effect of deception as well as
provide insight into the conditions in which deception
was employed by the participants of the CTF.

Our dataset consists of events recorded from a Capturethe-flag (CTF) tournament held at DEFCON 21 in 2013.
Briefly, CTF competitions act as educational exercise that
exposes real world attack scenarios to participants. Network
sniffing, analysis of protocols, programming and system level
knowledge, cryptanalysis are some of the instrumental skills
acquired by contestants.

In our text on cyber-warfare [7], we discuss the difficulties
of cyber-attribution and how an intelligence analyst must also

Our data represents attack/defense style, where each team
owns a small network of machines to defend. Teams are judged

•

ASONAM '15, August 25-28, 2015, Paris, France
© 2015 ACM. ISBN 978-1-4503-3854-7/15/08 $15.00
DOI: http://dx.doi.org/10.1145/2808797.2809362

962

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

For each file, we computed an md5 checksum, a byte
histogram, and an ARM instruction histogram. This data was
recorded as a list of tuples (time-stamp, hash, byte-histogram,
instruction-histogram) in a JSON document. These individual
fields of the tuple are listed in Table 1.
TABLE 1: Fields in an instance of network attack

From this pre-processing of the network data (packets) we
have around 10 million network attacks. There are 20 teams
in the CTF competition. In order to attribute an attack to a
particular team, apart from analyzing the payloads used by the
team, we also need to analyze the behavior of the attacking
team towards his adversary. For this purpose we separate the
network attacks according to the team being targeted. Thus
we have 20 such subsets. We represent the 20 subsets (teams)
as T-i, where i = 1, 2, 3...20. An example of an event in the
dataset is shown in Table 2.
TABLE 2: Example event from the dataset

2cc03b4e0053cde24400bbd80890446c

time

2013-08-03T23:45:17

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

T-10

T-8

T-7

T-6

T-5

T-4

T-3

T-2

T-1

T-20
T-20

payload hash

T-19

02345

T-18

svc

T-17

Robot Mafia

T-16

men in black hats

to team

T-15

from team

0

T-14

cmp:12 , svcmi:2, subs:8, movtmi:60 ......

T-13

0×43:245, 0×69:8, 0×3a:9, 0×5d:1, .....

inst hist

200000

T-12

byte hist

400000

T-11

Value

600000

T-1

Field

800000

T-10

indicates the date and time of the attack

T-9

indicates the payload used in the attack (md5)

time

Duplicate attacks: A duplicate attack occurs when the same
team uses the same payload to attack a team at different time
instances. Duplicate attacks can be attributed to two reasons.
First when a team is trying to compromise other systems, it
just does not launch a single attack but a wave of attacks with
very little time difference between consecutive attacks. Second,
once a successful payload is created which can penetrate the
defense of other systems, it is used more by the original
attacker as well as the deceptive one as compared to other
payloads. We group duplicates as being non-deceptive and
deceptive. Non-deceptive duplicate are the duplicates of the
team that first initiated the use of a particular payload. On the
other hand deceptive duplicates are all the attacks from the
teams that are being deceptive. Deceptive duplicates form a
large portion of the dataset as seen in Fig. 2.

T-8

the service that the payload is running

payload hash

Deceptive Attacks

Fig. 1: Unique deceptive attacks directed towards each team.

T-7

the team being attacked by the payload

svc

Teams

Unique Attacks

T-6

the team where the payload originates (attacking team)

to team

0

T-5

histogram of instructions used in the payload

from team

100000

T-4

histogram of byte sequences in the payload

inst hist

200000

T-3

Intuition

byte hist

300000

T-2

Field

400000

Unique Attacks

DEFCON CTF organizers recorded network traffic that
includes network packets generating to and from all participating teams and is available on Internet [4]. Recordings are
stored as archive files of PCAP (packet capture) for each team
(destination as that team) separately. PCAP file contains packet
headers (TCP, SSL, UDP etc.) and respective data as source,
destination, sequence numbers etc. with timestamp having
millisecond precision. Using open source tool tcpflow1 , we
interpreted collection of PCAPs as cumulative data streams.
Tcpflow reconstructs actual data streams from the packets
that proved helpful in protocol analysis and debugging. This
tool produces a file containing the contents of each stream,
representing the data sent between two points in the CTF
system.

attack to a team difficult.
Deception: In the context of this paper we define an attack to
be deceptive when multiple adversaries get mapped to a single
attack pattern. In the current setting we define deception as the
scenario when the same payload is used by multiple teams to
target the same team. Fig. 1 shows the distribution of unique
deception attacks with respect to the total unique attacks in
the dataset based on the target team. These unique deceptive
attacks amount to just under 35% of the total unique attacks.

Total Attacks

based on scores given to attack machines of other teams as well
as defending their own network. Initially, all virtual machines
are configured with specific set of services. These services
are vulnerable to state-of-art hacking techniques. Files can be
considered as form of flag to be captured from other teams or
to be planted to other teams by exploiting those vulnerabilities.

Teams

Non-Deceptive

Deceptive

Total Attacks

Fig. 2: Total attacks and duplicate attacks(Deceptive and
Non-deceptive) directed towards each team

A. Dataset Analysis
We now discuss two important observations from the
dataset, that makes the task of attributing an observed network
1 https://github.com/simsong/tcpflow

963

III.

BASELINE A PPROACHES

From the dataset, we have the ground truth available for
all the samples. Hence we use supervised machine learning

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

0.26

Logistic regression (LOG-REG)

0.31

Support vector machine (SVM)

0.30

Random Forest (RF)

0.37

•

Non-deceptive duplicate attacks attributed to one of
the deceptive teams.

•

Deceptive duplicates attributed to some other deceptive team.

•

Payloads that were not encountered during the training
phase.

The first two sources of error make up the majority of
misclassifications, since a given attack can be attributed to any
of the 19 teams.
1.0

0.8

0.6

0.4

0.2

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

T-10

T-8

T-7

T-6

T-5

T-4

0.0

T-3

For our baseline experiments, we separate the attacks based
on the team being targeted. Thus we have 20 subsets. We then
sort the attack according to time. We reserve the first 90% of
the attacks for training and the rest 10% for testing. Attacker
prediction accuracy is used as the performance measure for
the experiment. Accuracy is defined as the fraction of correctly
classified test samples. Fig. 3 shows the accuracy for predicting
the attacker for each target team. Machine learning techniques
significantly outperform random guessing which would have
an average accuracy of choosing 1 out of 19 teams attacking
yielding an accuracy of 0.053. For this experiment random
forest classifier performs better than logistic regression, support vector machine and decision tree for all the target teams.
Table 3 below summarizes the average performance for each
method.

Average Performance

Decision tree (DT)

T-2

A. Experimental Results

Method

T-1

Decision Tree (DT). For baseline comparisons we first implemented a decision tree classifier. We built the decision tree
by finding the attribute that maximizes the information gain at
each split. In order to avoid over-fitting, the terminating criteria
is set to less than 0.1% of total samples.
Random Forest (RF). We use a random forest which combines bagging for each tree with random feature selection at
each node to split the data thus generating multiple decision
tree classifiers.
Support Vector Machine (SVM). Support vector machines
is a popular supervised classification technique that works
by finding a separating margin that maximizes the geometric
distance between classes. We use the popular LibSVM implementation [2] which is publicly available.
Logistic Regression (LOG-REG). Logistic regression classifies samples by computing the odds ratio. The odds ratio
gives the strength of association between the features and the
class. We implement the multinomial logistic regression which
handles multi-class classification.

TABLE 3: Summary of Prediction results averaged across all
Teams

Fraction of Misclassified Samples

approaches to predict the attacking team. The ground truth
corresponds to a team competing in the competition.

Teams

Non-Deceptive Duplicates

Deceptive Duplicates

Unseen payloads

Fig. 4: Sources of error in the misclassified samples.
Fig. 4 shows the distribution of the above mentioned
sources of misclassification for each team. Deceptive duplicates form the majority of misclassifications. This is not
surprising given the fact that deceptive duplicates make up
almost 90% of the total attacks (see Fig. 2).

0.6

IV.

0.5

We explore different pruning techniques to address
misclassification issues with respect to deceptive and nondeceptive duplicates. The pruning techniques are only applied
to the training data, while the test data is maintained at 10%
as mentioned in Section III-A. We use the random forest
classifier for all the pruning techniques.

0.4

Accuracy

P RUNING

0.3
0.2

0.1

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

T-10

T-8

T-7

T-6

T-5

T-4

T-3

T-2

T-1

0

Teams

LOG-REG

RF

SVM

DT

Fig. 3: Team prediction accuracy for LOG-REG, RF, SVM
and DT.

B. Misclassified Samples
Misclassification can be attributed to the following sources,

964

All-but-majority (P-1): In this pruning technique, for each
payload, we only retain duplicates of the most frequent attacking team and prune the duplicates of all other teams. This
pruned set is then used to train the random forest classifier.
Table 4 shows the classifier performance in comparison with
the baseline method. All-but-majority pruning technique has
better performance on the test set than the baseline approach
for 11 out of 20 teams. Using this pruning technique does
benefit majority of the teams as the prediction accuracy improves for them, but for some teams the performance drops.

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
The reason for the drop in performance for some teams is
due to the fact that training set gets dominated by a single
team which does not have majority in testing set. Since the
majority team gets represented in most of the leaves of the
random forest classifier, it gets predicted more often leading
to high misclassifications.
All-but-K-majority (P-2): In order to address the issue of
one team dominating in the training set, we use the all-but-Kmajority where we consider the K most frequent teams for a
payload under consideration. After trying out different values
of K we select K = 3, which gives the best performance.
For higher values of K, the pruning behaves like the baseline
approach and for lower values it behaves like All-but-majority.
On average each team gains about 40K samples in the training
set as compared to all-but-majority pruning. Table 4 shows
the classifier performance. In this case also pruning performs
better than baseline in 11 out of 20 teams, but as compared to
all-but-majority the performance for most teams is better.
All-but-earliest (P-3): For this pruning we only retain the
duplicates of the team that initiated the attack using a particular
payload. This pruning technique retains all the non-deceptive
duplicates while getting rid of the deceptive ones. Table 4
shows the classifier performance. This pruning technique performs better than the baseline approach for 8 out of 20 teams.
Comparing this result to all-but-majority (including all-butK-majority) pruning indicates that deceptive duplicates are
informative in attributing an attack to a team and should not
be ignored completely.
All-but-most-recent (P-4): In this pruning we repeat a similar
procedure like All-but-earliest but instead of retaining the
duplicates of the team that initiated an attack, we retain the
duplicates of the team that used the payload last in the training
set. Since the data is sorted according to time, the last attacker
becomes the most recent attacker for the test set. Table 4 shows
the classifier performance.

RF

P-1(RF)

P-2(RF)

P-3(RF)

P-4(RF)

T-1

0.45

0.16

0.46

0.15

0.15

T-2

0.22

0.28

0.30

0.15

0.14

T-3

0.30

0.53

0.29

0.57

0.57

T-4

0.26

0.33

0.27

0.31

0.32

T-5

0.26

0.38

0.45

0.40

0.42

T-6

0.50

0.27

0.24

0.31

0.26

T-7

0.45

0.59

0.58

0.19

0.49

T-8

0.42

0.52

0.52

0.51

0.55

T-9

0.41

0.65

0.68

0.52

0.53

T-10

0.30

0.54

0.34

0.55

0.57

T-11

0.37

0.27

0.35

0.27

0.29

T-12

0.24

0.37

0.37

0.25

0.22

T-13

0.35

0.27

0.37

0.29

0.27

T-14

0.42

0.27

0.40

0.30

0.30

T-15

0.30

0.20

0.27

0.21

0.20

T-16

0.42

0.28

0.22

0.32

0.31

T-17

0.43

0.45

0.35

0.43

0.40

T-18

0.48

0.39

0.43

0.41

0.40

T-19

0.41

0.65

0.58

0.54

0.60

T-20

0.48

0.16

0.16

0.16

0.17

0.37

All-but-majority Pruning (RF)

0.40

All-but-K-majority Pruning (RF)

0.42

All-but-earliest Pruning (RF)

0.34

All-but-most-recent Pruning (RF)

0.36

VI.

C ONCLUSION

ACKNOWLEDGMENT

Some of this work was supported by the U.S. Office of
Naval Research and ASU Global Security Initiative (GSI).
R EFERENCES
[1]

[4]
[5]

[6]

[7]
[8]

[9]

965

Average Performance

Baseline Approach (RF)

In this paper, we study cyber-attribution by examining
DEFCON CTF data - which provides us with ground-truth
on the culprit responsible for each attack. We frame cyberattribution as a classification problem and examine it using
several machine learning approaches. We find that deceptive
incidents account for the vast majority of misclassified samples
and introduce heuristic pruning techniques that alleviate this
problem somewhat. Moving forward, we look to employ a
more principled approach to counter deception based on our
previously established theoretical framework for reasoning
about cyber-attribution [5], [8]. In particular we wish to employ
temporal reasoning to tackle the problem of deceptive attacks.
This opens up interesting research questions in particular identifying hacking group from a series of attacks over a period of
time, differentiating between deceptive hacking groups in time
series data. This is a knowledge engineering challenge which
calls for development of efficient and scalable algorithms.

[3]

Table 5 gives the summary of the prediction results for
all the pruning techniques in comparison with the random
forest baseline approach. In the pruning techniques All-butK-majority works best with an average accuracy of 0.42.

Method

V.

[2]

TABLE 4: Pruning technique performance comparison.
Teams

TABLE 5: Summary of Prediction results averaged across all
Teams

[10]

W. E. Boebert. A survey of challenges in attribution. In Proceedings
of a workshop on Deterring CyberAttacks, pages 41–54, 2010.
C.-C. Chang and C.-J. Lin. Libsvm: A library for support vector
machines. ACM Transactions on Intelligent Systems and Technology
(TIST), 2(3):27, 2011.
M. Dacier, V.-H. Pham, and O. Thonnard. The wombat attack attribution
method: some results. In Information Systems Security, pages 19–37.
Springer, 2009.
DEFCON. Defcon: Capture the flag. 2013.
S. Jajodia, P. Shakarian, V. S. Subrahmanian, V. Swarup, and C. Wang.
Cyber Warfare: Building the Scientific Foundation. Springer Publishing
Company, Incorporated, 2015.
H. K. Kalutarage, S. Shaikh, Q. Zhou, A. E. James, et al. Sensing for
suspicion at scale: A bayesian approach for cyber conflict attribution
and reasoning. In Cyber conflict (CYCON), 2012 4th international
conference on, pages 1–19. IEEE, 2012.
P. Shakarian, J. Shakarian, and A. Ruef. Introduction to cyber-warfare:
A multidisciplinary approach. Newnes, 2013.
P. Shakarian, G. I. Simari, and M. A. Falappa. Belief revision in
structured probabilistic argumentation. In Foundations of Information
and Knowledge Systems, pages 324–343. Springer, 2014.
O. Thonnard, W. Mees, and M. Dacier. On a multicriteria clustering
approach for attack attribution. ACM SIGKDD Explorations Newsletter,
12(1):11–20, 2010.
N. Tsagourias. Nicolas politis initiatives to outlaw war and define
aggression, and the narrative of progress in international law. European
Journal of International Law, 23(1):255–266, 2012.

IEEE International Conference on Social Computing / IEEE International Conference on Privacy, Security, Risk and Trust

A Scalable Framework for Modeling Competitive
Diffusion in Social Networks
Matthias Broecheler, Paulo Shakarian, and V.S. Subrahmanian
University of Maryland
College Park, MD
Email: {matthias,pshak,vs}@cs.umd.edu

Tories with 85% certainty) — Section III introduces the “most
probable interpretation” (MPI) problem and explains why the
MPI problem helps answer the above questions. In Section IV,
we show that solving the MPI problem can be done in three
ways: (i) by representing it as a numeric optimization problem
which, for many diffusion models, is polynomially solvable
but expensive, (ii) via a fixpoint computation process which is
also expensive, and (iii) via a novel approach based on graph
partitioning. We call this last algorithm the “competing diffusion engine” (CODE) algorithm and show, in Section VI, that
CODE efficiently and accurately solves diffusion problems in
SNs with over 8 million edges and 2 million vertices.

Abstract—Multiple phenomena often diffuse through a social
network, sometimes in competition with one another. Product
adoption and political elections are two examples where network
diffusion is inherently competitive in nature. For example, individuals may choose to only select one product from a set of
competing products (i.e. most people will need only one cell-phone
provider) or can only vote for one person in a slate of political
candidate (in most electoral systems). We introduce the weighted
generalized annotated program (wGAP) framework for expressing
competitive diffusion models. Applications are interested in the
eventual results from multiple competing diffusion models (e.g.
what is the likely number of sales of a given product, or how
many people will support a particular candidate). We define the
“most probable interpretation” (MPI) problem which technically
formalizes this need. We develop algorithms to efficiently solve
MPI and show experimentally that our algorithms work on
graphs with millions of vertices.

II. W EIGHTED GAP D IFFUSION M ODELS
A weighted generalized annotated program (wGAP) consists of two parts — a generalization of annotated rules [6]
together with a set of integrity constraints (ICs). The rules
describe the certainty that a given property spreads from one
vertex to another, given some information about the vertex
itself (e.g. male/female, age group etc) and the nature of
the links between vertices (e.g. spouse vs. penpal). The ICs
constrain the relationships between properties - for instance, if
a particular vertex will vote for Brown with 75% certainty and
for Cameron with 50% certainty, then this violates a constraint,
since each person has one vote only.

I. I NTRODUCTION
There are numerous applications where multiple competing
phenomena are diffusing through a social network (SN). For
instance, companies might be interested in tracking product
diffusion in a social network. Can we learn how adoption of
the iPhone vs. the Blackberry diffuses through a SN like Facebook? Can we learn how support for a political candidate like
Gordon Brown diffuses through a network in competition with
support for the opposing candidate, David Cameron? Most past
work on social network diffusion has focused on spread of one
phenomenon at a time. Examples include diffusion models for
the spread of diseases [1], viral marketing [2], spread of a
mutant gene [3], spread of information [4], and the spread
of cooperation [5]. There are many applications where we
need to reason about the interplay between these competing
phenomena. We want to know which political candidate is
most likely to win, or how many iPhone adoptions will occur
within a given SN.
This paper makes the following contributions. In Section
II, we introduce Weighted Generalized Annotated Programs
(wGAPs). wGAPs extend the annotated logic paradigm [6]
by the weighing scheme in [7] and provide a declarative
mechanism to express a wide range of diffusion models for
competing phenomena in a coherent framework. The weights
in wGAPs can be automatically learned from historical data
using standard algorithms such as the gradient descent based
perceptron algorithm proposed in [8]. An “interpretation” is
an assignment of truth values (e.g. vertex v1 will vote for the
Labour party with 75% certainty, while vertex v2 will vote for
978-0-7695-4211-9/10 $26.00 © 2010 IEEE
DOI 10.1109/SocialCom.2010.49

A. Syntax
Throughout this paper, we assume the existence of two
arbitrary but fixed disjoint sets VP, EP of vertex and edge
predicate symbols respectively. Each vertex predicate symbol
has arity 1 and each edge predicate symbol has arity 2.
Definition 1: A social network (S) is a 5-tuple
(V, E, `vert , `edge , w) where:
1) V is a set whose elements are called vertices.
2) E ⊆ V × V is a multi-set of edges.
3) `vert : V → 2VP is a vertex labeling function.
4) `edge : E → EP is a edge labeling function. 1
5) w : E × EP → [0, 1] is an edge weight function.
We now present a brief example of a social network (SN).
Example 1 (Election Example): Let VP = {voteLabour,
voteT ory, likeBrown, likeCam, suptBrown, suptCam,
1 Each edge e ∈ E is labeled by exactly one predicate symbol from EP but
there can be multiple edges with different labels between vertices.

295

v6

v2

v1

v10
v5

v13

v8

v7

we would weigh the diffusion of political opinion across
olderRelative edges higher than for knows edges. The use of
weights provides great flexibility - for example, [11] proposes
“big seed” marketing that combines both viral and massmarketing techniques. Our framework is sufficiently general to
allow a user to model both processes simultaneously - allowing
users to fine-tune strategies that can take maximal advantage
of both techniques.3 However, as mentioned earlier, a set of
weighted rules might allow us to infer that a particular vertex
will vote for both Brown and Cameron - which of course is
impossible. Integrity constraints help address this fact.
Definition 4 (integrity constraint/wGAP): Given a set of
annotated atoms (not necessarily ground), {A1 : µ1 , . . . , An :
µn } a function f , inequality/equality symbol op ∈ {=, 6=, <
, >, ≤, ≥}, and real number, c, then {A1 : µ1 , . . . , An : µn } :
f (µ1 , . . . , µn )op c is an integrity constraint.
A weighted GAP (wGAP) is a pair (Π, IC) where Π is a
finite set of rules and IC is a finite set of integrity constraints.
Every social network SN = (V, E, `vert , `edge , w) can be
represented by a wGAP (ΠSN , −) where ΠSN = {q(v) :
1
1
1 ← | v ∈ V ∧ q ∈ `vert (v)} ∪ {ep(V1 , V2 ) : w(V1 , V2 , ep) ←
| (V1 , V2 ) ∈ E ∧ `edge ((V1 , V2 )) = ep}.
Definition 5 (embedded social network): A social network
SN is said to be embedded in a wGAP (Π, IC) iff ΠSN ⊆ Π.
We see from the definition of ΠSN that all social networks
can be represented as wGAPs. When we augment ΠSN with
other rules — such as rules describing how certain properties diffuse through the social network, we get a program
Π ⊇ ΠSN that captures both the structure of the SN and
the diffusion principles. Here is a small example.
Example 2 (elections): The wGAP(Πelect , IC) might consist of ΠSN using the social network of Figure 1 plus the
rules:

v3

v9

v11

v14

v4

v15

v12

v16

Fig. 1.
Example social network. Square vertices are Brown supporters,
diamond vertices are Cameron supporters, solid edges are knows relationships, dashed edges are idol relationships, and dotted edges are olderRel
relationships.

student, employee, young}
denote
properties
of
vertices (which party they vote for, who they
like or actively support, and demographics). Let
EP
=
{knows, mentor, olderRelative, idol} denote
relationships between vertices. Consider the social network in
Figure 1. For square vertices, V , `vert (V ) = {suptBrown},
and for diamond vertices, `vert (V ) = {suptCam}. For
edges, if edge E is a solid line, then `edge (E) = knows,
if a dashed line, `edge (E) = idol, and for a dotted line,
`edge (E) = olderRelative. All edge weights are 1.
Note that our definition of social networks is much broader
than those in [1], [2], [9], [10] which often do not consider
either `edge or `vert . Demographics, party affiliations, and
other properties are all key indicators of how someone might
vote and should not be ignored. Likewise, relationship types
are crucial in determining the possible level of influence
between individuals.
We now recall the definition of annotated terms from [6]
to develop a general logical language for diffusion models.
We assume the existence of a set AVar of variable symbols
ranging over the unit real interval [0, 1] and a set F of function
symbols each of which has an associated arity. We start by
defining annotations.
Definition 2 (annotation term): (i) Any member of [0, 1] ∪
AVar is an annotation. (ii) If f is an n-ary function symbol over
[0, 1] and t1 , . . . , tn are annotations, then so is f (t1 , . . . , tn ).2
We define a separate language whose constants are members
of V and whose predicate symbols consist of VP ∪ EP.
We assume the existence of a set V of variable symbols
ranging over the constants (vertices). No function symbols
are present. A term is any constant (vertex) or variable. If
A = p(t1 , . . . , tn ) is an atom and p ∈ VP (resp. p ∈ EP),
then A is called a vertex (resp. edge) atom. We now define
weighted rules based on the model proposed in [7].
Definition 3 (annotated atom/weighted rule): (i) If A is an
atom and µ is an annotation, then A : µ is an annotated atom.
(ii) If A0 : f (µ1 , . . . , µn ), A1 : µ1 , . . . , An : µn are annotated
atoms and wt is a real number in [0, 1], then
wt
A0 : f (µ1 , . . . , µn ) ← A1 : µ1 ∧ . . . ∧ An : µn

0.7

1) voteLabour(A) : X ← suptBrown(A) : X
0.5
2) voteT ory(A) : X ← likeCam(A) : X
0.1
3) voteLabour(B) : X ← voteLabour(A) : X ∧
knows(B, A) : 1
0.25
4) voteLabour(B) : X ← voteLabour(A) : X ∧
mentor(B, A) : 1 ∧ student(B) : 1
0.15
5) voteT ory(B) : X ← voteT ory(A) : X ∧ mentor(B, A) :
1 ∧ employee(B) : 1
0.7
6) voteLabour(B) : X ← voteLabour(A) : X ∧
olderRel(B, A) : 1
0.8
7) voteT ory(B) : X ← voteT ory(A) : X ∧ idol(B, A) : 1 ∧
young(B) : 1

Rule 1 says that if A supports Brown, then he will vote
for Labour with relative probability 0.4. Rule 2 is similar for
Cameron followers. Other rules, such as 3 depend on the edge
3 Where do rule weights come from? One possibility, is that the user could
arbitrarily select rule weights to determine the outcome of the competitive
diffusion processes under different circumstances. A similar situation occurs
in other, less general diffusion models such as that of [3] where the users
must assign a “fitness” to each of the competitors in the diffusion processes.
When that model is applied to game theory, such as in [12], the authors
relate “fitness” to the payoff associated with a game. A similar intuition could
apply to rule weights in the more general framework presented in this paper.
Additionally, in Section V, we discuss how to learn weights from real-world
data. To our knowledge, there has been no similar scheme to learn the “fitness”
in the context of the competitive diffusion model [3].

is called a weighted rule and wt is the weight of this rule.
When n = 0, the above rule is called a fact.
For instance, we might know that an older relative has more
influence on an individual than a mere acquaintance. Hence,
2 In the following, we assume f to be a conic function but more general
formulations are possible.

296

Hence, an interpretation either satisfies (distance 0) a constraint or not (distance ∞).
Example 4: Suppose interpretation I assigns ground atom
voteLabour(V6 ) value 0.9 and voteT ory(V6 ) value 0.2. As
these two values sum to 1.1, the distance from satisfaction of
I w.r.t constraint 1 from Example 2 is ∞.
Following [7], we now extend distance from satisfaction to a
wGAP. This definition uses an arbitrary distance function δ.4
Definition 9: Given a wGAP (Π, IC) and interpretation I,
the distance from satisfaction, denoted dδ (Π ∪ IC, I), of
(Π, IC) w.r.t. interpretation I is defined as:

relationships in the graph. This rule states that if vertex B
has some outgoing neighbor on a knows edge who votes for
Labour, then vertex B votes for Labour with weight 0.1. The
ICs for this wGAPare:
1) {voteLabour(V ) : X1 , voteT ory(V ) : X2 } : X1 + X2 ≤ 1

Constraint 1 says that the total degree of belief for a vertex
voting for Labour and Tory is less than 1 since a person has
only one vote.
III. T HE M OST P ROBABLE I NTERPRETATION P ROBLEM
Our goal is to compute the most likely result of competitive
diffusion described by a wGAP within a given social network.
An interpretation is one way of assigning certainties to vertex
atoms. Interpretations of course must satisfy the ICs. We will
show how to assign a probability to each interpretation. The
“most probable interpretation” then will be the interpretation
that has the highest probability of being the correct interpretation and hence of being the most likely outcome of
the competitive diffusion process. In our election example,
different interpretations might specify the certainty with which
different voters might vote for Brown vs. Cameron. The most
probable interpretation then is the one that reflects the most
likely outcome.
Definition 6 (Interpretation): Given the set of ground
atoms, atoms, an interpretation I : atoms → [0, 1] is a
mapping of ground atoms to real numbers in [0, 1].
We now define a distancebetween the satisfaction of a rule by
an interpretation – if this number is 0, the rule is fully satisfied
by the interpretation — as the distance increases, the rule is
less and less satisfied by the interpretation.
Definition 7 (Distance from Satisfaction): Given an interwt
pretation I and weighted rule R = A0 : f (µ1 , . . . , µn ) ←
A1 : µ1 ∧ . . . ∧ An : µn , the distance from satisfaction of rule R with respect to interpretation I, d(R, I), is
wt · max(0, f (µ1 , . . . , µn ) − I(A0 )).
Example 3: Consider the following ground-instance of
0.7
rule 1 from Example 2: voteLabour(V11 ) : X ←
suptBrown(V11 ) : X. We shall refer to this ground
rule as R1 . Suppose we have interpretation I where
I(suptBrown(V11 )) = 1.0 and I(voteLabour(V11 )) = 0.5.
Therefore, the distance from satisfaction, d(R1 , I) = 0.7 ×
max(0, 1 − 0.5) = 0.35.
The idea of probability of satisfaction of logical formulas
was introduced in 1964 in [13] and later studied in seminal
papers such as [14] and many other subsequent papers in the
last 45 years. Our notion of distance from satisfaction is a
variant of such efforts.
We now define satisfaction of integrity constraints. Note that
here we apply a more traditional definition of satisfaction.
Definition 8 (Satisfaction of Integrity Constraints):
Given
interpretation
I
and
integrity
constraint
C = {A1 : µ1 , . . . , An : µn } : f (µ1 , . . . , µn )op c
(op ∈ {=, 6=, <, >, ≤, ≥}), the distance from satisfaction
of the constraint C w.r.t. interpretation I, denoted d(C, I), is
0 if f (I(A0 ), . . . , I(An ))op c and ∞ otherwise.

dδ (Π ∪ IC, I)

=


δ [. . . , (Ri , I), . . . , d(Ci , I), . . .]T , 0̃ .

where δ is an arbitrary distance function, R = {R1 , . . . , Rn }
is the set of all ground rules for rules in Π and C =
{C1 , . . . , Cm } is the set of all ground constraints in IC.
Thus, the distances from satisfaction for all ground rules and
constraints are entered in a single vector and we measure its
norm w.r.t. an arbitrary user defined distance function. We can
now use this notion of “distance from satisfaction” to define
a probability distribution over the space of all interpretations.
Definition 10: Given a wGAP (Π, IC), and interpretation
I, the probability of I given Π and IC is defined as:
1
P(I|Π, IC) = exp(−dδ (Π ∪ IC, I))
Z
R
where Z = I 0 exp(−dδ (Π ∪ IC, I 0 )) is the familiar normalizing constant that integrates over possible interpretations.
The higher the distance from satisfaction, the lower the
probability of an interpretation. Note, that an interpretation
which violates any of the constraints in IC has probability 0.
Our key intuition is that the truth values assigned to ground
atoms by a most probable interpretation accurately resemble
the result of the competing diffusion processes. We formalize
this intuition in the Most Probable Interpretation Problem
(MPI): Given a program Π and integrity constraints IC as
input, we want to compute the interpretation I s.t. there does
not exist I 0 such that P(I 0 |Π, IC) > P(I|Π, IC).

IV. A LGORITHMS
In this section, we present two solutions to MPI. The first
algorithm uses non-ground fixpoint computations and numeric
optimization to repeatedly apply the rules in the wGAP until
convergence. This standard algorithm guarantees that we will
always find an exact solution to MPI. In contrast, the CODE
algorithm is highly scalable and partitions a dependency graph
determined by (Π, IC) to come up with a fast approximation
to the correct solution to MPI.
4 A distance function on set X is a binary function s.t. δ(x, x) =
0; δ(x, y) = δ(y, x) and δ(x, z) ≤ δ(x, y) + δ(y, z). In the following we
assume δ to be the Euclidean or Manhattan distance.

297

A. Social Network Fixpoint (SNF) Algorithm
The SNF algorithm attempts to repeatedly apply the rules in
(Π, IC) until a fixpoint is reached, i.e. the diffusion process
converges. We first define non-ground interpretations which
allow the algorithm to only consider those atoms relevant to
the diffusion process and therefore save memory and time.
Definition 11: A non-ground interpretation is a partial
mapping N G : Atoms → [0, 1]. N G represents an interpretation grd(N G) defined as follows: grd(N G)(A) =
max{N G(A0 )|A is a ground instance of A0 }. grd(N G)(A) =
0 when there is no atom A0 which has A as a ground instance
and for which N G(A0 ) is defined,
Thus, non-ground interpretations are compressed representations of interpretations such that the number of atoms N G
keeps track of is always smaller or equal to a that of a ground
interpretation. Before defining our fixpoint operator, we define
an optimization problem which computes the MPI for a fixed
set of ground rules and can be solved by an standard conic
optimization program [15].
Definition 12 (Diffusion Optimization Problem): Given
a wGAP (Π, IC), we define the optimization problem
DOP (Π, IC). For each ground atom Ai , we have a variable
Xi - let X be the set of all such Xi ’s.
• For each ground instance Rθ (where θ is a substitution)
wtj
of the form A0 : f (µ1 , . . . , µn ) ← A1 : µ1 ∧ . . . An :
µn of a rule R in Π, let dr(Rθ) be defined as wt ×
max(0, f (X1 , . . . , Xn ) − X0 ) where Xi is the variable
associated with Ai .
The Diffusion Optimization Problem assumes that all ground
instances of rules in R are enumerated in some arbitrary but
fixed order R1 , . . . , Rk . It is defined as follows:
Min δ([dr(R1 ), . . . , dr(Rk )]T , 0̃) subject to the set of constraints below:
1) For each constraint Cj = {A1 : µ1 , . . . , As :
µs } : fj (µ1 , . . . , µs )op cj , add the constraint
fj (X1 , . . . , Xs )op cj
2) For each Xi ∈ X, 0 ≤ Xi ≤ 1.
Example 5: Consider a program Πsm consisting of the
embedding of Figure 1 and rule R1 from Example 3. Let
ICsm consist of the integrity constraint from Example 2. We
can create DOP(Πsm , ICsm ) as follows: Let variable X1 be
associated with atom voteLabour(V11 ), X2 associated with
voteT ory(V11 ), and X3 associated with suptBrown(V11 ).
Then the objective function for DOP is: δ([0.7 · max(0, X3 −
X1 )]T , 0̃) which is minimized subject to X1 + X2 ≤ 1.
We now define the operator ΓΠ,IC that maps non-ground
interpretations to non-ground interpretations by expanding
them as the diffusion spreads across the network.
Definition 13: Given a wGAP (Π, IC) and nonground interpretation N G, we define ΓΠ,IC (N G)(A) =
DOP (Π0 , IC 0 )(A) where
Π0 = {R|R is a ground instance of rule
wtj
A0 : f (µ1 , . . . , µm ) ← A1 : µ1 ∧ . . . ∧ Am : µm ∈ Π
where ∀i ∈ {1, . . . , m}, N G(Ai ) 6= 0}
And IC 0 = {C|C is a ground instance of integrity constraint

{A1 : µ1 , . . . , Ak : µk } : f (µ1 , . . . , µk )op c ∈ IC
where ∀i ∈ {1, . . . , k}, N G(Ai ) 6= 0}.
Example 6: Suppose there is a vertex V in the social
network of Figure 1 such that student(V ) is annotated with
a non-zero number. As this predicate does not appear in any
rule heads (in the program from Example 2), the annotation
will never change. Hence, using the operator Γ, we never
consider these ground atoms – and have reduced the number
of variables in the DOP constraints by the number of nodes
in the network (not including other, similar vertex atoms).
Let N G∅ be the non-ground interpretation that assigns 0 to all
atoms, then we define multiple iterations of ΓΠ,IC as follows:
• ΓΠ,IC ↑ 0 = ΓΠ,IC (N G∅ ) (Initialization)
• ΓΠ,IC ↑ i + 1 = ΓΠ,IC (ΓΠ,IC ↑ i) (Iteration)
It is obvious that ΓΠ,IC ↑ ω, the diffusion process convergence
state, can be achieved in a finite number of steps that is
equal to the number of ground atoms in the worst case but
typically faster in practice. Hence, the operator achieves the
effect of minimally grounding out Π, IC. As the non-ground
interpretation returned by the operator only assigns values to
ground atoms, the correctness follows immediately.
Proposition 1: Correctness of SNF Algorithm
• If there is a solution to DOP, then the interpretation
N Gsol formed where for each atom Ai , Isol (Ai ) = Xi
is the most probable non-ground interpretation, and the
interpretation grd(N Gsol ) is the most probable interpretation.
• If there is no solution to DOP, then the distance to satisfaction of the the most probable non-ground interpretation
N Gsol and most probable interpretation, grd(N Gsol ) is
∞. And there is no interpretation s.t. the distance to
satisfaction for all integrity constraints is finite.
B. Scalable Algorithm
Though the algorithm presented above is much more efficient than a naive version that grounds out all rules, it still
grows (approximately) linearly with the size of the social network (|V|+|E|) for most diffusion models. Hence, the number
of variables and constraints involved is expected to be of the
order O(|V| + |E|). Taking standard optimization algorithms’
run times into account, we can expect the (polynomial) running
time to be O((|V|+|E|)3.5 ) which is infeasible for larger social
networks.
To improve the scalability of the MPI algorithm, we split the
optimization problem into smaller ones by partitioning the
dependency graph of the wGAP and then iteratively solving
those smaller problems until convergence. By splitting the
dependency graph into relatively small isolated components,
we hope to find a good approximate solution by optimizing
each component independently.
Let (Π, IC) be a ground wGAP. The (rule-atom) dependency graph for (Π, IC) is a weighted bipartite graph GΠ,IC
where each element from Π ∪ IC as well as each ground
atom occurring therein is a vertex – there is an edge from
atom vertex a to a rule or constraint vertex r iff a occurs in r.

298

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22

Fig. 2.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

in |P| smaller optimization problems which are solved
individually to update the interpretation I. If the non-ground
interpretation needs to be expanded, i.e. another atom gets
explicitly grounded because its inferred truth value exceeds
some threshold β, then we also update the set of ground
rules and atoms. The process of graph partitioning, solving
the individual DOP ’s, and updating the interpretation is
repeated until a convergence criterion is satisfied at which
point I is returned as the most probable interpretation. To
test for convergence, we track the number of groundings in
the current and previous iterations through the “expansion”
variable using a discount factor α for each update. In addition,
we compute the change in the interpretation after solving
the DOP ’s for all ground atoms in the interpretation and
accumulate the difference in the “atomChange” variable.
To converge, both metrics must be below certain thresholds
(θA , θB ) or the maximum number of iterations must be
exceeded (θC ). By adjusting these thresholds we can trade-off
efficiency with accuracy of the approximation. We revisit the
issue of convergence criterion and study the trade-off between
fast convergence and optimal solution in the experimental
section.
As we are using non-ground interpretations for efficiency, the
number of ground rules and constraints can increase during
the execution of the algorithm as explained above. In the
scalable algorithm, this does not only affect the the numeric
representation but also the entails changes to the dependency
graph. As new ground atoms, rules, and constraints get added,
we therefore have to repartition the graph.

Algorithm CODE Algorithm
Input: Program Π and integrity constraints IC, initial interpretation I
Output: S
Approximate most probable interpretation I.
Π ← Π R∈Π {r | r is a grounding of R ∧ d(r, I) > 0}
A ← {a | aSis a ground atom ∧ ∃r ∈ Π : a ∈ r}
IC ← IC C∈IC {c | c is a grounding of C ∧ c ⊂ A ∪ domain(I)}
f inalRounds ← 0, expansion ← 0
repeat
GΠ,IC ← (V, E) where V = A ∪ Π ∪ IC,
E = {(a, r) | r ∈ Π ∪ IC ∧ a ∈ A ∩ r}
wE (a, r) ← w(r) if r ∈ Π or φ if r ∈ IC, ∀(a, r) ∈ E
P ← cluster(GΠ,IC , wE , wV = 1, B)
numGrounded ← 0, atomChange ← 0
for each P ∈ P
res ← solveDOP (Π ∩ {r | ∃a ∈ P : a ∈ r},
IC ∩ {c | ∃a ∈ P : a ∈ c})
for each a ∈ P where res(a) > β
numGrounded + +
A ← AS
∪ {a}
Π ← Π R∈Π
S {r | ∃θ : r = Rθ ∧ a ∈ r ∧ r ⊂ A ∪ domain(I)}
IC ← IC C∈IC {c | ∃θ : c = Cθ ∧ a ∈ c ∧ c ⊂ A ∪ domain(I)}
atomChange ← atomChange + |res(a) − I(a)|
I(a) ← res(a)
expansion ← α × expansion + numGrounded
if expansion < θA × |A| then f inalRounds + +
until (expansion < θA × |A|)∧
(atomChange < αB × |A| ∨ f inalRounds > θC )
return I

Scalable CODE algorithm to approximate the MPI

Algorithm Dependency Graph Clustering Algorithm
Input: Dependency Graph GΠ,IC , edge weights wE , vertex weight wV
cluster vertex weight bound B
Output: Partition P which partitions graph GΠ,IC .
(c : V → C) ← ∅; c(v) = {v}∀v ∈ V ;
2W ({u},c(t))−2W ({u},c(u)−u)
∆M (u, t) ← [
−
2|E|
2degw (u)[degW (c(t))−degW (c(u)−u)]
]
2
(2|E|)
P
size(u) ←
x∈c−1 c((u)) wV (x)
repeat
l←0
for all u ∈ V
x ← argmaxt∈ngh(u)∧size(t)+w (u)≤B ∆M (u, t)
V
if ∆M (u, x) > 0
c(x) ← c(x) ∪ {u}; c(u) ← c(u) − {u}; c(u) ← c(x); l ← l + 1
until l < δ × |V |
GC ← (V 0 = C, E 0 ) where
E 0 = {(x, y) | ∃u ∈ c−1 (x), vP
∈ c−1 (y) : P
(u, v) ∈ E}
wE 0 ← E 0 → R where wE 0 ((x, y)) =
u∈c−1 (x)
v∈c−1 (y) w((u, v))
P
0
wV 0 ← V → R where wV 0 (x) =
u∈c−1 (x) wV (x)
if

We now address the issue of partitioning the dependency
graph. Given an undirected graph G = (V, E, wE , wV ) where
E ⊂ V × V is the set of edges, wE : E → R is an
edge weight function and wV : V → R is a vertex weight
function, graph partitioning is typically defined as the problem
of partitioning
S the set of vertices V into k disjoint subsets
P1 , . . . , Pk , i Pi = V , Pi ∩ Pj = ∅, ∀i 6= j, of roughly equal
size such that the totalPweight of edges between partitions,
defined as the edge cut v∈Pi ,u∈Pj ,i6=j w(u, v), is minimized.
In graph partitioning, it is usually assumed that the parameter
k is given. However, what would k be in our case? On the
one hand, we want each partition subgraph to be small so
that the corresponding numeric optimization problem can be
solved quickly. This would suggest we choose a large k. On
the other hand, we need to ensure that the partition subgraphs
are relatively self contained, otherwise we might get poor
approximations or require many iterations to converge. This
suggests we keep k small.
To avoid the problem of having to choose the number of
partition blocks k a priori, we resort to community finding
algorithms which try to determine the densely connected and
relatively isolated subgraphs that comprise a graph. Community finding algorithms are typically studied in the context of
determining the groups or communities within a SN. They do
not require a size parameter and do not guarantee balanced
partitions, but aim to find a “natural” partition of the graph

|C|

>γ
|V |
Px ← {u | c(u) = x}
P ← {Px }x∈C
else
P 0 ← cluster(GC , wE 0 , wV 0 , B)
P ← {PX = {u | c(u) ∈ X}X∈calp0
return P

Fig. 3.

Dependency Graph Clustering Algorithm

When the destination of the edge is a rule, the weight of the
edge is the weight of the rule — otherwise it is a fixed constant
real number φ, e.g. a multiple of the largest rule weight.
The CODE algorithm shown in Figure 2 extends the
SNF algorithm presented above as follows. First, the sets of
ground rules Π, constraints IC, and atoms A are initialized
by considering only those ground atoms that are relevant to
the non-ground interpretation. At each iteration of CODE, we
construct the dependency graph GΠ,IC for the current wGAP
and compute its weight function. We then partition the graph
GΠ,IC into a set of smaller, disjoint subgraphs P of size
at most B using the dependency graph clustering algorithm
shown in Figure 3 and described below. For each subgraph
P ∈ P we construct a numeric optimization model, DOP ,
as before, but only include those ground atoms which are
vertices in P and fix all other atoms a to their truth value I(a)
(i.e. they become constants in the numeric representation)
where I is the current non-ground interpretation. This results

299

16000  

based on its topology. The most commonly used quality
measure to identify such “natural” subgraphs is modularity.
Definition 14 (Modularity): The modularity of a partition
{P1 , . . . , Pk } of an undirected graph G = (V, E, wE ) with
weight function w : E → R is defined as
X  W (Pi , Pi ) degW (Pi )2 
mod({P1 , . . . , Pk }) =
−
2 |E|
(2 |E|)2
Pi
P
where degw (v) =
w((v, x)) is the weighted degree
x∈VP
of vertex v, W (X, Y ) = x∈X,y∈Y w((x, y)) is the sum of
edge weights P
connecting two sets of vertices X, Y ⊂ V , and
degW (X) = x∈X degw (x) is the weighted degree of a set
of vertices X ⊂ V .
Intuitively, modularity measures the difference between
the actual and the expected inter-block edge weight. Our
dependency graph clustering algorithm displayed in Figure 3
is based on greedy modularity optimization. Our approach
leverages the intuition of the algorithm proposed by Blondel
et al. [16], because it also constructs a hierarchy of partitioned
graphs to construct successively larger subgraphs by moving
vertices greedily into the “best” partition according to the modularity measure at each level. Initially, each vertex is assigned
to a unique partition block. The algorithm then repeatedly
iterates over all vertices u in the graph and determines whether
moving u into any neighboring block increases modularity. If
so, u is moved into the block which yields the largest increase
and the assignments to blocks are updated. Once the number of
vertex moves falls below a certain threshold δ, we construct
a contracted version of the graph by collapsing all vertices
assigned to the same block into one and repeat the process until
progress falls below threshold γ. Our algorithm differs from
[16] in that we included a hard constraint to avoid that partition
blocks grow beyond a certain size bound B and relaxed the
convergence criterion to improve efficiency. By enforcing an
upper bound on the size of the clusters we ensure that the
resulting DOP optimization problems are small enough to be
solved efficiently.

Exact  vs  Approximate  Algorithm  
Running  Times  

Time  in  Seconds  

14000  
12000  

Exact  Algorithm  

10000  

Approximate  Algorithm  
with  Parameters  A  

8000  
6000  
4000  
2000  
0  
0  

10000   20000   30000   40000   50000   60000   70000   80000  

#  Edges  in  Graph  

Fig. 4.

Time comparison of approximate versus exact algorithm

and rule annotation functions. For the normalizing constant
(called “partition function”), we apply the frequently used
approximation of the gradient of the log partition function by
the MAP state of the probability distribution, since computing
the expectation is intractable in general. Computing the MAP
state, however, only requires computing the most likely interpretation under the current set of weights.
While we make no contribution to the actual weight learning
algorithm, we note that the CODE algorithm can be used
to efficiently approximate the MAP state and thereby greatly
speed up weight learning on large social networks.
VI. I MPLEMENTATION AND E XPERIMENTS
We implemented the non-ground exact and approximate
MPI algorithms and compared their performance on our
running example voting diffusion model applied to synthetic
social networks of varying size. The algorithms are implemented in Java extending the PSL inference framework [7]
and using the DOGMA graph database library [17] as well
as the MOSEK optimization toolbox (http://www.mosek.com).
We first describe our synthetic network generation method
and experimental setup before we evaluate the experimental
results.
A. Synthetic Multi-relational Network Generation
Our experiments require multi-relational networks, that is,
networks with multiple types of edge labels to distinguish
between the different types of relationships which are
relevant to the diffusion process. Our method for generating
synthetic multi-relation networks relies on well-established
characteristics of social networks, such power-law degree
distribution, and proceeds as follows. The user specifies a
list of edge types, declares each to be of either power-law
or random degree distribution and gives the (approximate)
number of vertices N of the synthetic network to be
generated. For each power-law distributed edge type t, the
user furthermore specifies parameters γ,α and for each of the
N nodes we sample the in- and out-degree for edges of type
t from the distribution D(k) = α × k −γ . We then randomly
connect incoming with outgoing edges of the same type until
no further matches are possible. For randomly distributed
edge types t, the user specifies the expected degree d and we
randomly sample d2 × N pairs (u, v) from the list of vertices
[1, . . . , N ] and create an edge of type t between u and v.

V. D IFFUSION M ODEL F ITTING
Suppose we are given a program Π with unknown weights
and a set of constraints IC. Given an observed diffusion
process that we would like to model with the program Π plus
constraints IC, we can fit the weights to the observation by
following the standard procedure of maximizing the likelihood
of the observation according to the defined probability measure. Observing a diffusion process on a given social network
means that we are given the “true” interpretation IT where
the values IT (A) are known for all ground atoms A. Hence,
we want to maximize the probability P(IT |Π, IC) which is
equivalent to maximizing its logarithm:
log P(IT |Π, IC) = −dδ (Π ∪ IC, I) − log Z
We optimize the above function by the gradient descent based
Perceptron algorithm proposed in [8]. Computing the gradient
of the distance function with respect to a single weight
is simple as it only requires differentiation of the distance

300

Note that we adjust the user specified N by the expected
number of vertices with degree 0 and remove all disconnected
vertices at the end. Hence, the generated network contains
only approximately N vertices.

450  

Time  in  Seconds  

We generated synthetic networks of increasing size with 6
different edge types similar to the ones used in our example:
knows, knows-well, mentor, boss, olderRelative, idol. The
first 5 types were defined to be power-law distributed with
parameter γ between 2 and 3 and parameter α between 0 and
1. The idol relationship was defined as random with parameter
d = 1.8.
The diffusion model we use throughout the experiments is
similar to Example 2 using the relationships defined above,
resulting in 7 rules with weights varying between 0 and 1.
We do not claim that our simple model accurately describes
the diffusion of voter opinion or that the generated networks
closely resemble real social networks. Our experiments focus
on the verification of our hypothesis that we can efficiently
compute competitive diffusion processes on large social networks. Hence, it suffices that our model is non-trivial, i.e.
contains multiple rules with varying edge weights, and that
these rules “cover” the entire network, i.e. all edge types occur
in some rules.
In the experiments we compare versions of the CODE
algorithm for five different parameters settings which are
summarized in Table I. Parameter setting A is the most
conservative setting and E the most relaxed. For all versions
of CODE we set α = 0.2, β = 0.1, γ = 0.9, δ = 0.05, and
B = 50000.
All medium size experiments were executed on identical
hardware with 8 core 2.33 Ghz Intel processors and 8 GB of
RAM. For the large scale experiments, we used a machine with
256 GB of main memory and 24 core Intel CPU. All runtimes
were averaged across three independent runs. The differences
in approximation error or runtime observed for networks
with more than 30000 edges are statistically significant at
p = 0.001.
A
0.0002
0.0004
20

B
0.0002
0.0004
10

C
0.001
0.002
5

D
0.005
0.01
4

Parameters  B  
Parameters  A  
Parameters  C  
Parameters  D  
Parameters  E  

400  

B. Experimental Setup

ID
θA
θB
θC

Running  Time  Comparison  of  
Approximate  Algorithm  

500  

350  
300  
250  
200  
150  
100  
50  
0  
0  

10000   20000   30000   40000   50000   60000   70000   80000  

Number  of  Edges  

Fig. 5.

Time comparison of approximate algorithms on medium networks

Percentage  Rela6ve  Error  

7%  

Rela6ve  Error  compared  to  Exact  
Inference  

6%  
5%  

Parameters  B  
Parameters  A  
Parameters  C  
Parameters  D  
Parameters  E  

4%  
3%  
2%  
1%  
0%  
0  

10000   20000   30000   40000   50000   60000   70000   80000  

Number  of  Edges  

Fig. 6.

Error of approximation on medium-size networks

exact algorithm which quickly becomes intractable on medium
sized networks. Figure 5 compares the running times of the
different versions of the CODE algorithm on the same set
of medium sized networks. Figure 6 shows the relative error
of approximation for all five versions of CODE measured
as the normalized difference in distance from satisfaction
for the interpretation I computed by CODE to the most
probable interpretation I ∗ computed by the exact algorithm,
δ (Π∪IC,I∗)
i.e. dδ (Π∪IC,I)−d
. As expected, more conservative
dδ (Π∪IC,I∗)
parameter settings yield better approximations but also require
more time whereas relaxed parameters allow CODE to terminate much faster at a greater approximation error. To verify
that CODE can scale to networks of interesting size, we ran
the CODE algorithm on networks with 400K to 8 million
edges (up to 2 million vertices). The running times for all
five versions are reported in Figure 7 which is drawn in loglog scale to accomodate the wide range in network size. We
observe that CODE scales approximately linearly in the size
of the network.
As running the exact algorithm is clearly impractical for
networks of this magnitude, we measured the relative error of
approximation compared to the most conservative parameter
setting A. The results are shown in Figure 8 with the x-axis
drawn in log scale. We observe that the error in approximation
seems to remain constant. As before, the different parameters settings highlight the trade-off between computational
efficiency and approximation error.

E
0.02
0.04
3

TABLE I
PARAMETER SETTINGS FOR THE CODE ALGORITHM

C. Experimental Results
In Section IV we argued that the runtime complexity of the
exact, non-ground MPI algorithm is expected to be cubic in the
size of the network, which makes it tractable, but impractical
for larger social networks. Figure 4 shows the runtime of
the exact algorithm compared to the CODE algorithm with
parameters A on networks with 10K to 80K edges. Even in
the most conservative setting, CODE greatly outperforms the

VII. R ELATED W ORK
To our knowledge, this work presents the first generalized
framework for competitive diffusion which scales to large

301

Time  in  Seconds  

40000  

VIII. C ONCLUSIONS

Run?me  Comparison  on  Large  
Networks  
Parameters  B  
Parameters  A  
Parameters  C  
Parameters  D  
Parameters  E  

4000  

400  
3.5E+05  

We presented a general framework that allows for the
modeling of competing diffusion processes. We considered the
non-trivial case of when the spread of a phenomenon to a vertex in the network precludes the spread of another to that same
vertex. We devised and implemented a scalable algorithms for
modeling these processes on social networks with 8 million
edges and 2 million nodes. There are many avenues that we
are considering for future work, such as answering complex
aggregate queries over competitive diffusion processes where
we attempt to find vertices that maximize some objective
function, comparing different diffusion processes on realworld data, and learning competitive diffusion models from
data.

7.0E+05  

1.4E+06  

2.8E+06  

5.6E+06  

Number  of  Edges  

Fig. 7.

Time comparison of approximate algorithms on large networks

Percentage  Rela9ve  Error  

6%  

Rela9ve  Error  on  Large  Networks  

5%  
4%  
3%  

Parameters  B  
Parameters  C  
Parameters  D  
Parameters  E  

R EFERENCES
[1] R. M. Anderson and R. M. May, “Population biology of infectious
diseases: Part I,” Nature, vol. 280, no. 5721, p. 361, 1979.
[2] D. Kempe, J. Kleinberg, and E. Tardos, “Maximizing the spread of
influence through a social network,” in Proceedings of KDD ’03. New
York, NY, USA: ACM, 2003, pp. 137–146.
[3] E. Lieberman, C. Hauert, and M. A. Nowak, “Evolutionary dynamics
on graphs,” Nature, vol. 433, no. 7023, pp. 312–316, 2005.
[4] R. Cowan and N. Jonard, “Network structure and the diffusion of
knowledge,” Journal of Economic Dynamics and Control, vol. 28, no. 8,
pp. 1557 – 1575, 2004.
[5] F. C. Santos, J. M. Pacheco, and T. Lenaerts, “Evolutionary dynamics
of social dilemmas in structured heterogeneous populations,” PNAS, vol.
103, no. 9, pp. 3490–3494, February 2006.
[6] M. Kifer and V. Subrahmanian, “Theory of generalized annotated logic
programming and its applications,” J. Log. Program., vol. 12, no. 3&4,
pp. 335–367, 1992.
[7] M. Broecheler, L. Mihalkova, and L. Getoor, “Probabilistic Similarity
Logic,” UAI (to appear), 2010.
[8] M. Collins, “Discriminative training methods for hidden Markov models:
Theory and experiments with perceptron algorithms,” in Proceedings of
EMNLP-02, 2002.
[9] C. C. F.C. Coelho and H. Cruz, “Epigrass: A tool to study disease spread
in complex networks,” Source Code for Biology and Medicine, vol. 3,
no. 3, 2008.
[10] M. Jackson and L. Yariv, “Diffusion on social networks,” in Economie
Publique, vol. 16, no. 1, 2005, pp. 69–82.
[11] D. Watts and J. Peretti, “Viral marketing for the real world,” Harvard
Business Review, May 2007.
[12] H. Ohtsuki and M. A. Nowak, “The replicator equation on graphs,”
Journal of Theoretical Biology, vol. 243, no. 7, pp. 86–97, Nov. 2006.
[13] H. Gaifman, “Concerning measures in first order calculi,” Israel journal
of mathematics, vol. 2, no. 1, 1964.
[14] D. Scott and P. Krauss, “Assigning probabilities to logical formulas,”
Studies in Logic and the Foundations of Mathematics, vol. 43, 1966.
[15] F. Alizadeh and D. Goldfarb, “Second-order cone programming,” Mathematical Programming, vol. 95, no. 1, pp. 3–51, 2003.
[16] V. Blondel, J. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast unfolding
of communities in large networks,” Journal of Statistical Mechanics:
Theory and Experiment, vol. 2008, p. P10008, 2008.
[17] M. Bröcheler, A. Pugliese, and V. S. Subrahmanian, “DOGMA: A diskoriented graph matching algorithm for RDF databases,” in ISWC, 2009,
pp. 97–113.
[18] T. Carnes, C. Nagarajan, S. M. Wild, and A. van Zuylen, “Maximizing
influence in a competitive social network: a follower’s perspective,” in
ICEC ’07. New York, NY, USA: ACM, 2007, pp. 351–360.
[19] J. Kostka, Y. A. Oswald, and R. Wattenhofer, “Word of mouth: Rumor
dissemination in social networks,” Lecture Notes in Computer Science,
vol. 5058, pp. 185–196, 2008.
[20] P. Shakarian, V. Subrahmanian, and M. L. Sapino, “Using Generalized
Annotated Programs to Solve Social Network Optimization Problems,”
ICLP (to appear), 2010.
[21] R. Kindermann and J. L. Snell, Markov random fields and their
applications. American Mathematical Society Providence, RI, 1980.

2%  
1%  
0%  
3.5E+05  

7.0E+05  

1.4E+06  

2.8E+06  

5.6E+06  

Number  of  Edges  

Fig. 8.

Error of approximation on large networks

social networks. Below, we place our work in the literature.
In [2], a framework for diffusion is also proposed, although
less general than the one presented here. The authors study a
different problem than that presented in this paper - the “most
influential nodes” problem. Additionally, the authors of [2] do
not address competitive diffusion nor scaling to large social
networks. [2] is extended to a competive scenario in [18].
However, the authors only allow one competitor to actively
diffuse while all others must be static. In our work, all competitors are active at the same time. In [19], the authors provide
a theoretical treatment of a problem similar to [18] wrt rumor
spread which did not include an implementation. In biology,
[3] presents a competitive diffusion model in which “mutant”
and “resident” genes attempt to spread in a population. They
view the propagation of the mutants and residents as a stochastic process and are primarily concerned with the “fixation
probability” that a lone mutant overtakes a population. We
allow more than two competitors, different edge labels, more
generalized models, and implemented scalable algorithms that
avoid costly Monte-Carlo style simulations typically used for
such models.
The framework of this paper extends our previous work
[20] on diffusion in social networks. The approach in [20]
does not consider competitive diffusion models, utilizes a less
expressive semantics and does not provide an implementation.
Lastly, the probabilistic model developed in this paper builds
on a large body of related work in energy models from
statistical physics [21]. Such models have been integrated into
a logical framework within machine learning, such as PSL [7],
which is most similar to this work. We extended the core PSL
framework by a more expressive semantics tailored to social
networks and presented a novel, scalable inference algorithm.

302

Ann Math Artif Intell (2016) 76:375–408
DOI 10.1007/s10472-015-9476-4

A quantitative approach to belief revision in structured
probabilistic argumentation
Gerardo I. Simari1 · Paulo Shakarian2 ·
Marcelo A. Falappa1

Published online: 19 September 2015
© Springer International Publishing Switzerland 2015

Abstract Many real-world knowledge-based systems must deal with information coming
from different sources that invariably leads to incompleteness, overspecification, or inherently uncertain content. The presence of these varying levels of uncertainty doesn’t mean
that the information is worthless – rather, these are hurdles that the knowledge engineer must
learn to work with. In this paper, we continue work on an argumentation-based framework
that extends the well-known Defeasible Logic Programming (DeLP) language with probabilistic uncertainty, giving rise to the Defeasible Logic Programming with Presumptions
and Probabilistic Environments (DeLP3E) model. Our prior work focused on the problem
of belief revision in DeLP3E, where we proposed a non-prioritized class of revision operators called AFO (Annotation Function-based Operators) to solve this problem. In this paper,
we further study this class and argue that in some cases it may be desirable to define revision operators that take quantitative aspects into account, such as how the probabilities of
certain literals or formulas of interest change after the revision takes place. To the best of
our knowledge, this problem has not been addressed in the argumentation literature to date.
We propose the QAFO (Quantitative Annotation Function-based Operators) class of operators, a subclass of AFO, and then go on to study the complexity of several problems related
to their specification and application in revising knowledge bases. Finally, we present an

 Gerardo I. Simari

gis@cs.uns.edu.ar
Paulo Shakarian
shak@asu.edu
Marcelo A. Falappa
mfalappa@cs.uns.edu.ar
1

Department of Computer Science and Engineering, Universidad Nacional del Sur (UNS) and
Institute for Computer Science and Engineering (CONICET-UNS), Bahia Blanca, Argentina

2

Arizona State University, Tempe, AZ, USA

376

G. I. Simari et al.

algorithm for computing the probability that a literal is warranted in a DeLP3E knowledge
base, and discuss how it could be applied towards implementing QAFO-style operators that
compute approximations rather than exact operations.
Keywords Structured argumentation · Belief revision · Reasoning under probabilistic
uncertainty
Mathematics Subject Classification 68T30 · 68T27 · 68T37

1 Introduction and motivation
Many real-world knowledge-based systems must deal with information coming from different sources that invariably leads to uncertain content, be it from gaps in knowledge
(incompleteness), overspecification (inconsistency), or because the knowledge is inherently
uncertain (such as weather forecasts or measurements that are necessarily imprecise). Far
from considering such uncertain knowledge useless, knowledge engineers face the challenge of putting it to its best possible use when solving a wide range of problems. In
particular, one basic problem that needs to be investigated in depth is that of revising such
knowledge bases in a principled manner. In this paper, we continue work on that combines
the well-known Defeasible Logic Programming (DeLP) language (actually, an extension
called PreDeLP to handle presumptions) with probabilistic uncertainty, which led to the
development of the DeLP3E model (Defeasible Logic Programming with Presumptions and
Probabilistic Environments). In previous work [38, 40], we studied a class of non-prioritized
belief revision operators called AFO that allows changes to be made only to probabilistic
annotations when addressing the incorporation of an epistemic input into the knowledge
base. Here, we propose a subclass called QAFO that takes quantitative aspects into account
when performing revisions, such as how the probabilities of certain literals or formulas of
interest change after the revision takes place. To the best of our knowledge, this problem
has not been addressed in the argumentation literature to date.
The main contributions presented in this paper are briefly summarized as follows:
–

–

–

As building blocks to be used in our quantitative belief revision operators, we define:
(i) warrant probability functions (WPFs), which have as domains either conjunctions or
disjunctions of ground literals that are mapped to the probability that they are warranted
in the DeLP3E program; and (ii) revision objective functions (ROFs), which take as
input two DeLP3E programs I1 , I2 and an epistemic input and return a numeric score
that is interpreted as the value of obtaining I2 from I1 when revising it by the epistemic
input. ROFs generally include WPFs in their definitions.
We propose the QAFO class of operators, a subclass of AFO that allows modifications
to the annotation function to be carried out as part of the belief revision operation, but
focusing on optimizing a given ROF, as described above.
We study the complexity of several problems related to our approach; in particular, we
present:
(i)
(ii)

A new lower bound on the complexity of deciding the warrant status of a literal
or a conjunction/disjunction of literals in a (classical) PreDeLP program;
Computing WPFs in general is #P-hard;

Quantitative belief revision in structured probabilistic argumentation

377

(iii)

Point (ii) holds even when computing probabilities of worlds in the environmental model can be done in polynomial time;
(iv) Computing WPFs in the special case in which Nilsson’s probabilistic logic [32]
is used is NP-complete;
(v) By combining the intuition behind the proof of point (iv) and further conditions,
we identify a class of instances for which WPFs can be computed in polynomial
time; and
(vi) Under the same conditions as point (v), we show that QAFO revisions are NPcomplete; furthermore, we show that the problem has the same complexity
even when the revision objective function is constrained to be a simple sum of
warranting probabilities for atoms in the AM.

–

We present an algorithm for computing the probability that a literal is warranted
in a DeLP3E knowledge base, and discuss its application towards implementing QAFO-style operators that compute approximations rather than perform exact
operations.

The rest of this paper is organized as follows: Section 2 discusses preliminary concepts
and the DeLP3E framework, which was first introduced in [38, 40]. Section 3 motivates
the specialization of AFO operators to take into account quantitative aspects, and presents
the class QAFO. Section 4 studies the complexity of several problems related to QAFO
and the application of such operators in revising DeLP3E knowledge bases. Section 5
studies a novel approach to reasoning about probabilities of literals in DeLP3E, called
warranting formulas, and their application in the implementation of QAFO-style operators that address the high computational cost issuess by applying heuristics the trade off
optimality for tractability. Finally, Sections 6 and 7 present related work and conclusions,
respectively.
Throughout the entire paper, we illustrate the presentation via a running example that
is inspired on the use of DeLP3E in medical diagnosis, which is the kind of real-world
application in which we envision our work being of most use; we have also explored its
application in the related scenario of solving the attribution problem1 in cyber security
and cyber warfare [39], with encouraging feedback from the community as to its potential
impact.

2 Preliminaries on the DeLP3E framework
The DeLP3E framework is comprised of two distinct, but interrelated models of the world.
The first is called the environmental model (referred to from now on as the “EM”), and
is used to describe uncertain knowledge about the domain that is subject to probabilistic
events. The second one is called the analytical model (referred to as the “AM”), and contains
knowledge that is either strict or defeasible, as described below – this will be useful in the

1 Essentially, given a cyber event of interest, the attribution problem involves finding out who was responsible

for it. This is especially well suited for argumentation and belief revision due to the ease with which a
potential culprit can plant false or misleading clues, hence giving rise to an inconsistent knowledgebase.
See [37] for further discussion.

378

G. I. Simari et al.

analysis of competing hypotheses that can account for a given phenomenon (what we will
generally call queries).
The AM is composed of a classical (that is, non-probabilistic) PreDeLP [31] program
in order to allow for contradictory information, giving the system the capability to model
competing explanations for a given query. In general, the EM contains knowledge such as
evidence, uncertain facts, or knowledge about agents and systems. The AM, on the other
hand, contains knowledge that may or may not be strictly valid, yet it does not depend
on probabilistic events. Indeed, dividing knowledge between the AM and EM is a knowledge engineering task, and its adequate resolution will call for design decisions to be made;
note that this separation also allows for a different kind of uncertainty to be modeled –
defeasible rules and presumptions can be leveraged when there is no probabilistic information available but we still wish to maintain that a specific portion of the knowledge base
is uncertain.
In the rest of this section, we formally describe these two models, as well as how
knowledge in the AM can be annotated with information from the EM – these annotations specify the conditions under which the various statements in the AM can potentially
be true.

Basic Language We assume sets of variables and constants, denoted with V and C, respectively. The language also contains a set of n-ary predicate symbols; the EM and AM use
separate sets of predicate symbols, denoted with PEM and PAM , respectively – the two models can, however, share variables and constants. As usual, a term is composed of either a
variable or a constant. Given terms t1 , ..., tn and n-ary predicate symbol p, p(t1 , ..., tn ) is
called an atom; if t1 , ..., tn are constants, then the atom is said to be ground. The sets of all
ground atoms for EM and AM are denoted with GEM and GAM , respectively; finally, we also
use notation LAM to denote the set of all (ground) literals: {a | a ∈ GAM } ∪ {¬a | a ∈ GAM }.
Note that even though in general the language allows variables, for simplicity we will
assume throughout this paper that all objects are ground (propositional).
Example 1 Consider a medical diagnosis scenario2 in which a patient goes to a hospital
exhibiting certain symptoms: shortness of breath, sporadic fainting (loss of consciousness
for brief periods of time), and some signs of memory loss. Figure 1 shows the predicates
that we will use throughout the paper in the running example.
As shown in the figure (and discussed in more detail below), some of these predicates
comprise the analytical model (AM), while others are part of the environmental model
(EM). For instance, in our example, predicates stating the presence of symptoms such as
memory loss and shortness of breath, as well as those representing diagnoses, such as anxiety and depression, are part of the analytical model. On the other hand, the environmental
model contains predicates that are associated with uncertain events, such as false negatives
coming up when a test is performed or the risk that the patient will be affected by anxietyrelated disorders. Note that in the running example we make use of the term “at risk”

2 This and all related examples in this paper, though inspired by potential real-world applications, make many

simplifying assumptions in order to allow for a concise presentation of the key concepts that we wish to
illustrate.

Quantitative belief revision in structured probabilistic argumentation

379

Fig. 1 Explanation of the meaning of the predicates used in the running example

according to the common use of this expression in the medical domain, i.e., characterized
by high risk or susceptibility, such as to a certain disease.
Given set of ground atoms, a world is any subset of atoms – those that belong to the set
are said to be true in the world, while those that do not are false. Therefore, there are 2|GEM |
possible worlds in the EM and 2|GAM | worlds in the AM. These sets are denoted with WEM
and WAM , respectively. In order to avoid worlds that do not model possible situations given
a particular domain, we include integrity constraints of the form oneOf(A ), where A is a
subset of ground atoms. Intuitively, such a constraint states that any world where more than
one of the atoms from set A appears is invalid. We use ICEM and ICAM to denote the sets of
integrity constraints for the EM and AM, respectively, and the sets of worlds that conform
to these constraints is denoted with WEM (ICEM ) and WAM (ICAM ), respectively.
Finally, logical formulas arise from the combination of atoms using the traditional connectives (∧, ∨, and ¬). As usual, we say that a world λ satisfies formula (f ), written λ |= f ,
iff: (i) If f is an atom, then λ |= f iff f ∈ λ; (ii) if f = ¬f  then λ |= f iff λ  |= f  ;
(iii) if f = f  ∧ f  then λ |= f iff λ |= f  and λ |= f  ; and (iv) if f = f  ∨ f  then
λ |= f iff λ |= f  or λ |= f  . We use the notation formEM , formAM to denote the set of
all possible (ground) formulas in the EM and AM, respectively; finally, we use basicAM to
denote all possible conjunctions or disjunctions of literals from LAM , which we refer to as
basic formulas.

2.1 Environmental model
In this paper, we generalize the approach taken in our previous work [38, 40] for the environmental model – here, we simply assume that we have a probabilistic model defined over
GEM , which represents a probability distribution over WEM .

380

G. I. Simari et al.

Fig. 2 Bayesian network used in the EM of the running example. The names of the random variables are simply the abbreviations of their corresponding atoms: AR  → anx risk, DR  → dep risk, FNAT  → FN anx test,
and FNTS → FN tox screen

Definition 1 (Probabilistic Model) Given sets PEM , V, and C, and corresponding sets GEM
and WEM , a probabilistic model EM is any function Pr : WEM → [0, 1] such that

λ∈WEM Pr (λ) = 1.
Examples of probabilistic models that can be used are Bayesian networks (BNs) [33],
Markov logic networks (MLNs) [36], extensions of first order logic such as Nilsson’s probabilistic logic [32], or even ad-hoc representations of function Pr from Definition 1. The
following is an example of a BN over the running example.
Example 2 Consider the set PEM from Fig. 1. The Bayesian network depicted in Fig. 2
describes the probability distribution Pr over all possible worlds WEM shown in Fig. 3.
So, for instance, the probability that false negatives do not arise in any of the two tests,
and that the patient is at risk for both anxiety- and depression-related disorders (world λ4 )
is 0.29808.

Fig. 3 Probability distribution for the worlds in the running example

Quantitative belief revision in structured probabilistic argumentation

381

2.2 Analytical model
The DeLP3E formalism adopts a structured argumentation framework [35] for the AM.
While the EM contains probabilistic information about the state of the world, the AM
must allow for a different kind of information; in particular, it must be able to represent contradictory knowledge. This approach allows for the creation of arguments that
may compete with each other in order to reach a conclusion regarding a given query.
This is known as a dialectical process, where arguments defeat each other based on
a comparison criterion. Resulting from this process, certain arguments are warranted,
while others are defeated. Argumentation-based reasoning has been proposed and studied in depth as a natural way to manage a set of inconsistent information – its strength
lies in the fact that it closely resembles the way humans settle disputes (consider, for
instance, how convictions are decided in trials). Another highly desirable characteristic
of structured argumentation frameworks is that, once a conclusion is reached, the process also yields an explanation of how we arrived at it, as well as information about
why a given argument is warranted. In the following, we first recall the basics of the
underlying argumentation framework used, and then go on to introduce the analytical
model (AM).

2.2.1 Defeasible logic programming with presumptions (PreDeLP)
PreDeLP, first introduced in [31], is a formalism combining logic programming with defeasible argumentation. We will briefly recall the basics of PreDeLP, and refer the reader to [17,
31] for the complete presentation.
The formalism contains several different constructs: facts, presumptions, strict rules, and
defeasible rules. Facts are statements that always hold (such as a patient’s symptom in our
example), while presumptions are statements that may or may not be true (such as a medical
diagnosis). Strict rules establish logical consequences (similar to material implication in first
order logic, though the semantics is not exactly the same since the contrapositive does not
follow from a strict rule). While strict rules, like facts, always hold, defeasible rules specify
logical consequences that may be assumed to be true when no contradicting information
is available. These components are used in the construction of arguments, and together
comprise PreDeLP programs.
Formally, we use the notation AM = (, , , ) to denote a PreDeLP program,
where:
–
–
–
–

 is the set of strict rules of the form L0 ← L1 , . . . , Ln , where L0 is a ground literal
and {Li }i>0 is a set of ground literals;
 is the set of facts, written simply as atoms;
 is the set of defeasible rules of the form L0 –≺ L1 , . . . , Ln , where L0 is a ground literal
and {Li }i>0 is a set of ground literals, and
 is the set of presumptions, which are written as defeasible without a body.

For simplicity, we will sometimes refer to AM as a set corresponding to the union of its
components.
Recall that all atoms in the AM must be formed with a predicate from the set PAM ,
and note that in both strict and defeasible rules, strong negation (i.e., classical negation
as in first-order logic) is allowed in the head, and thus may be used to represent contradictory knowledge. The following is an example of a PreDeLP program over the running
example.

382

G. I. Simari et al.

Fig. 4 A ground argumentation framework

Example 3 Consider again the medical diagnosis scenario from our running example; the
DeLP3E program in Fig. 4 encodes some basic knowledge that the attending physician
might use to diagnose their patient. For instance, strict rule ω1 states that based on a negative
result when administering a test for toxins in the blood we can conclude that the patient
is not misusing sleeping aids. On the other hand, defeasible rule δ1 states that memory
loss and depression can lead to such a misuse. In this example, the set of presumptions
is empty.
Arguments Given a query in the form of a ground atom, the goal is to derive arguments for
and against its validity – derivation follows the same mechanism of logic programming [29],
and we denote such derivation with the symbol “”. In the following, we say that such a
derivation is “strict” if it only uses facts and strict rules; otherwise, we say that the derivation
is “defeasible”. Likewise, we say that a literal is strictly (defeasible) derived if the derivation
is strict (defeasible). Finally, we say that an argument is “factual” if no presumptions are
used in it.
Since rule heads can contain strong negation, it is possible to defeasibly derive contradictory literals from a program. For the treatment of contradictory knowledge, PreDeLP
incorporates a defeasible argumentation formalism that allows the identification of the
pieces of knowledge that are in conflict and, through the dialectical process discussed
above, decides which information prevails as warranted. This dialectical process involves
the construction and evaluation of arguments, formally defined next.
Definition 2 (Argument) An argument 
A, L for a literal L is a pair of the literal and a
(possibly empty) set of the AM (A ⊆ AM ) that provides a minimal proof for L meeting the
following requirements: (i) L is defeasibly derived from A; (ii) ∪∪A is not inconsistent;
and (iii) A is a minimal subset of  ∪  satisfying (i) and (ii), denoted 
A, L.
Literal L is called the conclusion supported by the argument, and A is the support of the
argument. An argument 
B , L is a subargument of 
A, L  if B ⊆ A. An argument 
A, L
is presumptive if A ∩  is not empty. We will also use (A) = A ∩ , (A) = A ∩ ,
(A) = A ∩ , and (A) = A ∩ .

Quantitative belief revision in structured probabilistic argumentation

383

Fig. 5 Example arguments based on the running example scenario

Our definition differs slightly from that of [41], where DeLP is introduced, as we include
strict rules and facts as part of arguments. We make this change because in our framework
the strict rules and facts used to construct a given argument may only be true in certain
worlds in the EM. Hence, the entire set of facts and strict rules need not be consistent in our
framework. We shall discuss how portions of the AM are assigned EM worlds in the next
section.
Example 4 Figure 5 shows example arguments based on the PreDeLP program from Fig. 4.
Argument A3 uses an additional component not present in the original program, and states
that if we can assume a negative result for a tox screen, we can conclude that the patient is
not misusing sleeping aids.
Given an argument 
A1 , L1 , counter-arguments are arguments that contradict it. Argument 
A2 , L2  is said to counterargue or attack 
A1 , L1  at a literal L iff there exists
a subargument 
A, L  of 
A1 , L1  such that the set (A1 ) ∪ (A2 ) ∪ (A1 ) ∪
(A2 ) ∪ {L2 , L } is inconsistent. A proper defeater of an argument 
A, L is a
counter-argument that – by some criterion – is considered to be better than 
A, L;
if the two are incomparable according to this criterion, the counterargument is said
to be a blocking defeater. An important characteristic of PreDeLP is that the argument comparison criterion is modular, and thus the most appropriate criterion for the
domain that is being represented can be selected; the default criterion used in classical defeasible logic programming (from which PreDeLP is derived) is generalized
specificity [43], though an extension of this criterion is required for arguments using
presumptions [31]. We briefly recall this criterion next – the first definition is for generalized specificity, which is subsequently used in the definition of presumption-enabled
specificity.
Definition 3 (DeLP Argument Preference) Let AM = (, , , ) be a PreDeLP program and let F be the set of all literals that have a defeasible derivation from AM . An
argument 
A1 , L1  is preferred to 
A2 , L2 , denoted with A1 P S A2 if:
(1) For all H ⊆ F , (A1 ) ∪ (A2 ) ∪ H is consistent: if there is a derivation
for L1 from (A2 ) ∪ (A1 ) ∪ (A1 ) ∪ H , and there is no derivation for L1 from
(A1 ) ∪ (A2 ) ∪ H , then there is a derivation for L2 from (A1 ) ∪ (A2 ) ∪ (A2 ) ∪ H ;
and
(2) there is at least one set H  ⊆ F , (A1 ) ∪ (A2 ) ∪ H  is consistent, such that there
is a derivation for L2 from (A1 )∪(A2 )∪H  ∪(A2 ), there is no derivation for L2 from
(A1 )∪(A2 )∪H  , and there is no derivation for L1 from (A1 )∪(A2 )∪H  ∪(A1 ).
Intuitively, the principle of specificity says that, in the presence of two conflicting lines
of argument about a proposition, the one that uses more of the available information is more
convincing. The following extension for presumptive arguments was first introduced in [31].

384

G. I. Simari et al.

Definition 4 (Presumptive Argument Preference) Given PreDeLP program AM =
(, , , ), an argument 
A1 , L1  is preferred to 
A2 , L2 , denoted with A1  A2 if
any of the following conditions hold:
(1) 
A1 , L1  and 
A2 , L2  are both factual and 
A1 , L1  P S 
A2 , L2 .
(2) 
A1 , L1  is a factual argument and 
A2 , L2  is a presumptive argument.
(3) 
A1 , L1  and 
A2 , L2  are presumptive arguments, and
(a) (A1 )  (A2 ) or,
(b) (A1 ) = (A2 ) and 
A1 , L1  P S 
A2 , L2 .
Generally, if A, B are arguments with rules X and Y , resp., and X ⊂ Y , then A is
stronger than B . This also holds when A and B use presumptions P1 and P2 , resp., and
P 1 ⊂ P2 .

Note The specificity criterions used here are not transitive [47], and therefore should not
be assumed to define an ordering over arguments. This, however, does not pose a problem
for our framework, as the criterion is only ever used to compare pairs of arguments to see
which one “wins out”. We remind the reader that the comparison criterion in our framework
is modular; if transitivity is required, the one proposed in [47] is an option.
A sequence of arguments called an argumentation line thus arises from this attack relation, where each argument defeats its predecessor. To avoid undesirable sequences, which
may represent circular argumentation lines, in D E LP an argumentation line is acceptable if it satisfies certain constraints (see [17]). A literal L is warranted if there exists a
non-defeated argument A supporting L.
Clearly, there can be more than one defeater for a particular argument 
A, L. Therefore,
many acceptable argumentation lines could arise from 
A, L, leading to a tree structure.
The tree is built from the set of all argumentation lines rooted in the initial argument. In a
dialectical tree, every node (except the root) represents a defeater of its parent, and leaves
correspond to undefeated arguments. Each path from the root to a leaf corresponds to a different acceptable argumentation line. A dialectical tree provides a structure for considering
all the possible (maximal) acceptable argumentation lines that can be generated for deciding whether an argument is defeated. We call this tree dialectical because it represents an
exhaustive dialectical (in the sense of providing reasons for and against a position) analysis for the argument in its root. For a given argument 
A, L, we denote the corresponding
dialectical tree as T (
A, L).
Given a literal L and an argument 
A, L, in order to decide whether or not a literal
L is warranted, every node in the dialectical tree T (
A, L) is recursively marked as “D”
(defeated) or “U” (undefeated), obtaining a marked dialectical tree T ∗ (
A, L) as follows:
1. All leaves in T ∗ (
A, L) are marked as “U”s, and
2. Let 
B , Lq  be an inner node of T ∗ (
A, L). Then 
B , Lq  will be marked as “U” iff
every child of 
B , Lq  is marked as “D”. The node 
B , Lq  will be marked as “D” iff it
has at least a child marked as “U”.
Given an argument 
A, L obtained from AM , if the root of T ∗ (
A, L) is marked as
“U”, then we will say that T ∗ (
A, L) warrants L and that L is warranted from AM . (Warranted arguments correspond to those in the grounded extension of a Dung argumentation
system [11].) There is a further requirement when the arguments in the dialectical tree contains presumptions – the conjunction of all presumptions used in even (respectively, odd)
levels of the tree must be consistent. This can give rise to multiple trees for a given literal,
as there can potentially be different arguments that make contradictory assumptions.

Quantitative belief revision in structured probabilistic argumentation

385

Fig. 6 An example of an annotation function over the running example

We can then extend the idea of a dialectical tree to a dialectical forest. For a given literal
L, a dialectical forest F (L) consists of the set of dialectical trees for all arguments for L. We
shall denote a marked dialectical forest, the set of all marked dialectical trees for arguments
for L, as F ∗ (L). Hence, for a literal L, we say it is warranted if there is at least one
argument for that literal in the dialectical forest F ∗ (L) that is labeled as “U”, not warranted
if there is at least one argument for the literal ¬L in the dialectical forest F ∗ (¬L) that is
labeled as “U”, and undecided otherwise. We shall refer to whether literal L is warranted,
not warranted, or undecided as L’s “warrant status”, and sometimes refer to the “warranted”
status as “Yes” and the “not warranted” status as “No”.

2.3 The DeLP3E framework
Our framework, originally proposed in [38], is the result of combining the environmental and analytical models (which we denote with EM and AM , respectively). Intuitively,
given AM , every element of  ∪  ∪  ∪  only hold in certain worlds in the set WEM
– i.e., these elements are subject to probabilistic events. Each element of  ∪  ∪  ∪ 
is thus associated with a formula over GEM (using conjunction, disjunction, and negation, as usual) – we use formEM to denote the set of all such formulas. The notion
of an annotation function associates elements of  ∪  ∪  ∪  with elements in
formEM .
Definition 5 (Annotation Function [38]) An annotation function is any function of the
form af :  ∪  ∪  ∪  → formEM . We use [af ] to denote the set of all annotation
functions.
We will sometimes denote annotation functions as sets of pairs (f, af(f )) in order to
simplify the presentation. Figure 6 shows an example of an annotation function for our
running example; for instance, the annotation for rule δ2 means that this rule only holds
whenever the probabilistic event anx risk is true. If annotations are “True”, this means that
they hold in all possible worlds.
Definition 6 (DeLP3E Program) Given environmental model EM , analytical model AM ,
and annotation function af , a DeLP3E program is of the form I = (EM , AM , af ). We
use notation [I ] to denote the set of all possible programs.

386

G. I. Simari et al.

Fig. 7 A depiction of how the DeLP3E program in the running example can be decomposed into one classical
PreDeLP program for each possible EM world (cf. Fig. 3 for the definition of worlds λ1 –λ16 in terms of the
random variables in the EM)

In the following, given DeLP3E program I = (EM , AM , af ) and λ ∈ WEM , we use
notation AM (λ) = {f ∈ AM s.t. λ |= af (f )}. This gives rise to a decomposed view of
DeLP3E programs, as illustrated next.
Example 5 Consider the different examples presented so far: the EM from Example 2 (with
the worlds from Fig. 3), AM from Fig. 4, the arguments in Fig. 5, and the annotation function from Fig. 6 – these components give rise to a DeLP3E program I = (EM , AM , af )
Fig. 7 shows how I can be decomposed into one classical PreDeLP program AM (λ) for
each world λ ∈ WEM .
For instance, AM (λ7 ) contains θ1 , θ2 , θ3 , ω1 , ω2 , ω3 , ω4 , and δ1 because the annotation
function associates condition True to all of these components; it contains δ2 and δ4 because
condition anx risk is true in λ7 , and it does not contain δ3 because condition dep risk is false
in λ7 .
The most direct way of considering consequences of DeLP3E programs is thus to consider what happens in each world in WEM ; that is, the defeat relationship among arguments
depends on the current state of the (EM) world.
Definition 7 (Existence of an Argument in a World) Given DeLP3E program I =
(EM , AM , af ), argument 
A, L is said to exist in world λ ∈ WEM if ∀c ∈ A, λ |= af(c).
The notion of existence is extended to argumentation lines, dialectical trees, and dialectical forests in the expected way (for instance, an argumentation line exists in λ iff all
arguments that comprise that line exist in λ).
Example 6 Consider the different examples presented so far: the worlds in Fig. 3, AM
from Fig. 4, the arguments in Fig. 5, and the annotation function from Fig. 6.
Since argument A1 uses defeasible rule δ3 , and af (δ3 ) = dep risk (while the other two
components have annotation “True”), we can conclude that this argument exists in worlds
in which dep risk is true, i.e., λ1 –λ4 and λ9 –λ12 .

Quantitative belief revision in structured probabilistic argumentation

387

The idea of a dialectical tree is also extended w.r.t. worlds; so, for a given world
λ ∈ WEM , the dialectical (resp., marked dialectical) tree induced by λ is denoted with
Tλ
A,L (resp., T ∗
). We require that all arguments and defeaters in these trees exist
λ
A,L
in λ. Likewise, we extend the notion of dialectical forests in the same manner (denoted
with Fλ (L) and Fλ∗ (L), respectively). Based on these concepts, we introduce the notion of
warranting scenario.
Definition 8 (Warranting Scenario) Given DeLP3E program I = (EM , AM , af ) and
literal L formed with a ground atom from GAM , a world λ ∈ WEM is said to be a warranting
scenario for L (denoted λ war L) if there is a dialectical forest Fλ∗ (L) in which L is
warranted and Fλ∗ (L) exists in λ.
The idea of a warranting scenario is used to formally define DeLP3E entailment. The set
of worlds in the EM where a literal L in the AM must be true is exactly the set of warranting
scenarios — these are the “necessary” worlds: necnec(L) = {λ ∈ WEM | (λ war L)}.
Now, the set of worlds in the EM where AM literal L can be true is the following — these
are the “possible” worlds: poss(L) = {λ ∈ W
war ¬L}.
EM | λ 
In the following we use notation for(λ) = a∈λ a∧ a ∈λ
/ ¬a, which denotes the formula
that
has
λ
as
its
only
model.
We
now
extend
this
notation
to sets of worlds: for(W ) =

λ∈W for(λ). Entailment can then be defined as follows:
Definition 9 (DeLP3E Entailment) Given DeLP3E program I = (EM , AM , af ), AM
literal L and probability interval p ∈ [, u], we say that I entails L with
probability p ∈
[, u]if the probability distribution Pr yielded by EM is such that  ≤ λ∈nec(L) Pr (λ)
and λ∈poss(L)λ Pr (λ) ≤ u.

2.4 Consistency of DeLP3E programs
Finally, one of the central topics of this paper is that of inconsistencies, which can arise in
our framework in more than one way [38]. In this paper, we assume that the probabilistic
model is consistent, and focus on inconsistencies that arise in the AM. Towards this end,
we use the following notion of (classical) consistency: PreDeLP program  is said to be
consistent if there does not exist a ground literal a s.t.   a and   ¬a. For DeLP3E
programs, the interaction between the annotation function and facts and strict rules may
cause conflicts, as defined next.
Definition 10 (Consistency of DeLP3E Programs) A DeLP3E program I =
(EM , AM , af ), with AM = 
, , , , is consistent
 if: given probability distribution
Pr for EM , if there exists a world λ ∈ WEM such that x∈∪ | λ|=af(x) {x} is inconsistent,
then we have Pr (λ) = 0.
The intuition behind this definition is that subsets of facts and strict rules hold under the
circumstances specified by the annotation function – such circumstances can be expressed
as sets of EM worlds. Now, if there exists a world where (at least) two contradictory strict
statements are true, then the EM must assign probability zero to this world.
Example 7 Let us return to the running example; consider AM from Fig. 4, EM from
Fig. 2, and the annotation function from Fig. 6, with the addition of fact θ4 = pos dep test
with af (θ4 ) = True and fact θ5 = neg anx test with af (θ5 ) = ¬FN-anx test. It is now clear

388

G. I. Simari et al.

that 
the program is inconsistent, since there exists world λ3 (among several others) such
that x∈∪ | λ3 |=af(x) {x} warrants both anxiety (via argument with θ4 and ω3 ) and ¬anxiety
(via argument with θ5 and ω2 ).

3 Revision of DeLP3E programs based on quantitative aspects
We have finally arrived at the main problem we address in this paper – revising knowledge bases. This problem can be generically stated as: given DeLP3E program I =
(EM , AM , af ), with AM =  ∪  ∪  ∪  and a pair (f, af  ) where f is either an atom
or a rule and af  is equivalent to af , except for its expansion to include f 3 , obtain a new
program I  called the revised knowledge base that addresses the incorporation of the epistemic input (f, af  ) into the original program; we denote this operation with the symbol “•”
– i.e., I  = I • (f, af  ).
Now, the problem statement as presented above is quite vague, since we did not give any
details as to how the operator “addresses the incorporation” of the epistemic input. There are
many approaches in the literature (cf. Section 6) that address this problem quite differently;
one of the main properties that characterize revision operators is whether or not they satisfy
the Success property, which states that the epistemic input must be a consequence of the
revised knowledge base. Here, we will adopt a cautious stance and assume that this property
does not hold in general; therefore, we focus on so-called non-prioritized revision operators.
The basic issue that revision operators must deal with is inconsistency (we will discuss
this in more depth shortly); as we saw in Section 2.4, inconsistency in DeLP3E programs
involves worlds that have non-zero probability and an associated PreDeLP program that is
inconsistent. In our previous work [38, 40] we identified three basic approaches that can be
taken towards solving this problem:
–

–
–

Modifying the EM: Perhaps the simplest approach is to fix the problem of inconsistency
by forcing the probabilistic model to assign probability zero to all worlds that cause
inconsistencies to arise.
Modifying the AM: Alternatively, for each world in which the corresponding PreDeLP
program is inconsistent, we can modify this program to remove the problem.
Modifying the annotation function. Finally, as a finer-grained approach compared to the
previous one, we can alter the annotation function.

In the following, we will assume that epistemic inputs involve only strict components
(facts or rules), since defeasible components can always be added without inconsistencies
arising. Regarding these three possible approaches, in this paper we will focus on the third
one since it is a generalization of the second – if we only allow removing elements from
the AM, such an operation will have the same effect as not removing the element but modifying the annotation function so that it associates the formula “⊥” to it. The generalization
of annotation function-based revision lies in that there is not always the need for such a
drastic measure; see [40] for further discussions on this, including examples. Furthermore,
operations of the first kind alone do not suffice to perform revisions, as can be seen in the
following simple example.

3 That

is, af  (x) = af (x) for all x ∈ dom(af ), and dom(af  ) = dom(af ) ∪ {f }.

Quantitative belief revision in structured probabilistic argumentation

389

Example 8 Consider the following DeLP3E program, where the EM consists of two worlds
{a} and {¬a}, each with probability 0.5:
ω1 :
θ1 :
ω2 :
θ2 :

p←q
¬p
¬p ← q
p

af (ω1 ) = a
af (θ1 ) = a
af (ω2 ) = ¬a
af (θ2 ) = ¬a

Now, suppose we wish to revise by formula θ3 : q with af (θ3 ) = True. Since both EM
worlds are inconsistent with the formula, it is impossible to change the allocation of the
probability mass in order to avoid inconsistencies; therefore, the only option is to reject the
input.

3.1 A recap of annotation function-based belief revision
Since the quantitative approach that we propose in this paper is related to the AFO class
of revision operators introduced in [38], in this section we provide a brief summary of the
relevant material. After recalling the relevant postulates, we present the construction of AFO
operators.

3.1.1 Rationality postulates
The following properties characterize the behavior of operators for revising annotation functions; we briefly discuss them here in an informal manner, and refer the reader to [40] for
their formal presentation.
–

–
–
–
–

–

Inclusion: For any given element g in the AM, the worlds that satisfy g’s annotation after the revision are a subset of the set of worlds satisfying g’s annotation before
the revision. That is, the constraints in the revised annotations can only become more
restrictive.
Vacuity: If simply adding the input to the program does not lead to inconsistencies,
then the operator does precisely that.
Consistency Preservation: If the original program is consistent, then so is the revised
program.
Weak Success: As in Vacuity, if adding the input to the program does not cause
inconsistencies, then the input must be present “as is” in the revised program.
Relevance: Given a specific EM world, if a part of its associated AM knowledge base
is removed by the operator, then there exists a superset of the remaining knowledge
base that is not consistent with the removed element and the input. That is, removed
elements are always “relevant” to an inconsistency.
AF Uniformity: If two different inputs are such that the same set of EM worlds lead
to inconsistencies in a given AM knowledge base, and it is the case that analogous
subsets taken in conjunction with their respective input lead to equivalent consistency/inconsistency, then the models removed from the annotations elements in the
AM knowledge base are the same for both inputs. In other words, the operator must
behave in the same way when presented with inputs that have an equivalent effect on
the knowledge base.

We now continue briefly recalling the presentation of the annotation function-based operator
of [38] by discussing its construction. In order to do so, we adopt the following notation:
the program to revise is denoted with I = (EM , AM , af ), with AM =  ∪  ∪  ∪ ,

390

G. I. Simari et al.

and the epistemic input is denoted with (f, af  ), where f is either an atom or a rule and af 
is equivalent to af , except for its expansion to include f . We denote the revision as follows:
I • (f, af  ) = (EM , AM , af  ) where af  is the revised annotation function. We will
slightly abuse notation in order to make the presentation clearer, and use notation to convert
sets of worlds to and from formulas. Moreover, we often refer to “removing elements of
AM ” to refer to changes to the annotation function that cause certain elements of the AM
to not have their annotations satisfied in certain EM worlds. As we are looking to change the
annotation function for a specific subset of facts and strict rules, we specify these subsets
with the following notation:
–
–
–

–

–
–
–

I ∪ (f, af  ) to denote I  = (EM , AM ∪ {f }, af  ).
(f, af  ) ∈ I = (AM , EM , af ) to denote f ∈ AM and af = af  .
0 (I ) = {λ ∈ W
I
WEM
EM | AM (λ) is inconsistent} – this set contains all the EM worlds
for a given program where the corresponding knowledge base in the AM is classically
inconsistent.
I (I ) = {λ ∈ W 0 |Pr (λ) > 0} – this is a subset of W 0 (I ) containing worlds
WEM
EM
EM
that are assigned a non-zero probability; i.e., the worlds where inconsistency in the AM
arises.
wld(f ) =
{λ | λ |= 
f } – the set of worlds that satisfy formula f ; and
for(λ) = a∈λ a ∧ a ∈λ
/ ¬a – the formula that has λ as its only model.
IAM (λ) = {f ∈  ∪  | λ |= af(f )} – the subset of facts and strict rules in AM
whose annotations are true in EM world λ.

We will make use of this notation in the next section.

3.1.2 Operator construction
The basis of the construction of the class of so-called annotation function-based operators is
I (I ∪ (f, af  )) must be modithat any subset of AM that is associated with a world in WEM
fied so that consistency is ensured. For each such world λ, we make use of the following set
of “candidate replacement programs” for AM (λ):
CandP gmaf (λ, I ) = {AM | AM ⊆ AM (λ) s.t. AM is consistent and
AM ⊆ AM (λ)s.t. AM ⊃ AM s.t. AM

is consistent}
The intuition is that each maximal consistent subset of IAM (λ) is a candidate for replacing
the inconsistent program for that world. To specify the construction, we need to introduce
some more notation. Let  : WEM → 2[]∪[] ; i.e., a function from EM worlds to subsets
of the strict components of the AM – this function will be used to choose the revised AM
for each world. For each component h in the AM there is a formula in AM ∪ {f }, where f
is part of the epistemic input (i.e., what the operator is revising by). Given these elements,
we define:

newF or(h, , I , (f, af  )) = af  (h) ∧
¬f or(λi )
I (I ∪(f,af  )) | h∈(λ)
λ∈WEM
/

Intuitively, newFor provides a new annotation for each component h ∈ AM ; such formula
can be seen as the result of selecting a maximally consistent subset of AM (λ) for each EM
world λ. We are finally able to introduce the AFO class of operators:

Quantitative belief revision in structured probabilistic argumentation

391

Fig. 8 The DeLP3E program from the running example, after adding facts θ4 and θ5 . The annotation function
is provided in a separate column for convenience

Definition 11 (AF-based Operators [38, 40]) A belief revision operator • is an “annotation
function-based” (or af-based) operator (• ∈ AFO) if given program I = (EM , AM , af )
and input (f, af  ), the revision is defined as I • (f, af  ) = (EM , AM ∪ {f }, af  ), where:
∀h, af  (h) = newFor(h, , I , (f, af  ))
where ∀λ ∈ WEM , (λ) ∈ CandP gmaf (λ, I ∪ (f, af  )).
In [38, 40], we provide a representation theorem that states the equivalence between this
construction and the operators discussed above. We refer the reader to these articles for a
more complete and detailed presentation.

3.2 Towards a quantitative approach
Traditionally, belief revision has been addressed from a qualitative point of view rather than
a quantitative one (cf. Section 6 for a discussion on related work). A simple example of this
is the fact that, faced with the option of removing either both atoms a and b or only atom c,
classical revision operators typically declare both options to be just as good, since neither is
a subset of the other; it could be argued, then, that taking quantitative aspects into account
(such as the number of elements removed) may lead to a better solution – of course, this may
depend on other factors. As we will see, there are different ways in which such quantitative
aspects can be incorporated into revision operations. For instance, in our setting, DeLP3E
programs can be regarded in a world-by-world manner, and changes made in one world
can be compared to those made in another. The AFO operators described in Section 3.1
make decisions for each world independently; we now wish to address the issue of taking
into account different kinds of quantitative aspects when revising DeLP3E programs. The
following example motivates our approach in our medical diagnosis scenario.

392

G. I. Simari et al.

Example 9 Consider again the running example, and suppose the physician has decided to
carry out as a first step two tests, a toxin screen and an anxiety test, and that both tests
yielded negative results. Note that the validity of these tests is subject to probabilistic events
(in this case, false negatives). The new program is reproduced in Fig. 8.
Figure 9 shows the world-by-world decomposition of the new program, and the atoms
that are warranted in each case. From the information in this figure, we can compute the
following probabilities for the hypotheses that the physician is contemplating (depression,
anxiety, and misuse of sleeping aids):
Literal

Probability

depression
sleep aid misuse
¬sleep aid misuse
anxiety
¬anxiety

: 0.06672
: 0.05088
: 0.93324
: 0.06992
: 0.92888

Since they all have low probabilities after performing the tests, the doctor decides to test
for depression and in this case receives a positive result (atom pos dep test). For the sake of
this example, we will assume that the validity of the outcome of this test (unlike the other
two) is not subject to probabilistic events – thus, we have af (pos dep test) = True.
Now, while for the first two tests we were able to simply add the corresponding atoms and
extend the annotation function accordingly, simply adding θ6 = pos dep test with af (θ6 ) =
True causes inconsistencies to arise in eight of the possible worlds (λ3 , λ4 , λ7 , λ8 , λ11 , λ12 ,
λ15 , and λ16 ). Essentially, the problems arise because the negative anxiety test allows us
to conclude that there is no anxiety, while the positive depression test would allow us to
conclude that indeed there is anxiety. Since both derivations only involve strict components,
this leads to an inconsistent AM.
Example 9 shows an interesting case of belief revision in DeLP3E programs; when presented with new information that is in conflict with existing one, we must find a way to
address its incorporation into the existing knowledge – non-prioritized operators are very
flexible, since they always have the option of ignoring the new information. However, this
flexibility also means that – in the case of DeLP3E programs – there is no guidance with
respect to how revisions should be carried out globally, since each world is treated as a separate revision problem. Next, we discuss two kinds of functions that will prove to be useful
in addressing this situation.

3.2.1 Two building blocks
We now introduce warrant probability functions and revision objective functions, which
are later used in the definition of our new class of non-prioritized belief revision
operators.

Warrant Probability Functions As one of the building blocks to our quantitative
approach, given a DeLP3E program I we define warrant probability functions (WPFs, for
short).

Quantitative belief revision in structured probabilistic argumentation

393

Fig. 9 Atoms that are warranted in each possible EM world, given the AM and annotation function in Fig. 8

Before introducing these formulas, we need to present a simple extension to the concept
of “warrant status”, which is up to now defined for literals. The following definition is a
simple extension to conjunctions or disjunctions of literals.
Definition 12 (Warranting a Conjunction/Disjunction of Literals) Let AM be a ground
PreDeLP program and Q be either a conjunction or disjunction of ground literals
L1 , . . . , Ln . The warrant status of Q with respect to AM is defined as follows:
1.
2.

If Q is a single literal L, then the warrant status of Q is the warrant status of L in AM .
If Q = Q1 ∧ Q2 then the warrant status of Q is:
–
–
–

3.

Yes iff the warrant status of both Q1 and Q2 is Yes;
No if the warrant status of either Q1 or Q2 is No; and
Undecided whenever neither of the above cases hold.

If Q = Q1 ∨ Q2 then the warrant status of Q is:
–
–
–

Yes iff the warrant status of either Q1 or Q2 is Yes;
No if the warrant status of both Q1 and Q2 is No; and
Undecided whenever neither of the above cases hold.

Using Definition 12, we can easily extend the nec and poss notations (cf. Page 14) to
conjunctions and disjunctions of literals.
The following result is a consequence of the fact that conflicting literals cannot be
warranted in (Pre)DeLP [17].
Proposition 1 Let AM be a ground PreDeLP program and Q = L1 ∧ . . . ∧ Ln be a
conjunction of ground literals. Then, only one of the following cases holds: (i) P war Q,
(ii) P war ¬Q, or (iii) the warrant status of Q is undecided.
Proof In [17], a corresponding trichotomy result was shown for literals, i.e., the warrant
status for any literal is one and only one of Yes, No, and Undecided. Our result is a direct
consequence of this and Definition 12.

394

G. I. Simari et al.

Fig. 10 Histogram depiction of the entailment probability functions for the programs of Example 9

Warrant Probability Functions are then simply defined as partial mappings with signature:
ϒI : basicAM → [0, 1]


such that for f ∈ basicAM , ϒI (f ) = p if and only if λ∈nec(f ) Pr (λ) = p. 4 When the
program is clear from context, we drop the subscript and write simply ϒ. In the following,
we use notation dom(ϒ) to denote the set of formulas for which ϒ is defined. The table
shown in Example 9 is a simple example of a WPF, whose domain is a handful of literals.
The following is another example along the same vein.
Example 10 Figure 10 shows three examples of WPFs in which the domains are fixed to
the set of literals that can be warranted in the input program. These functions are related
to the revision described in Example 9: the black bars show the original probabilities, the
striped bars give the probabilities yielded by the program obtained by favoring the inclusion
of the positive depression test, while the light gray bars depict the probabilities obtained by
favoring the negative anxiety test. Figure 11 shows the three revised programs.

Revision Objective Functions The other building block allows us to effectively quantify
how good a revision is considered to be. Towards this end, we define revision objective
functions (ROFs, for short) as functions that take two DeLP3E programs I1 and I2 , along
with an epistemic input (f, af ), and returns a positive real number. We keep the definition
of ROFs very general in order to allow different kinds of objectives to be specified. The
following is a simple example of a ROF over our running example, which makes use of
warranting probability functions.

4 Note that this definition can easily be extended to deal with probability intervals as well (i.e., using both
nec and poss); here, for simplicity of presentation, we adopt this definition in order to work with point
probabilities.

Quantitative belief revision in structured probabilistic argumentation

395

Fig. 11 The DeLP3E program from the running example, after performing three revisions: (i) The addition
of the θ4 and θ5 , as discussed in Example 9; (ii) The revision by pos dep test by prioritizing this input; and
(iii) The same revision but prioritizing neg anx test

Example 11 Let us return once again to the medical diagnosis example. Suppose that we
take the three revised programs we presented (Fig. 11) – call them I1 , I2 , and I3 – and that
we wish to compare them with respect to the effect of the last revision over the warranted
atoms, taking the probabilities yielded by I1 as the baseline. So, we define the following
revision objective function:
(I , I  , (f, af  )) = e

−



L∈LAM ,L=f

|ϒI (L)−ϒI  (L)|

where ϒI is the WPF for program I .
Intuitively, this function sums up all the differences between the probabilities of literals entailed by the programs, but ignores the input (if it is a literal). In this way, a distance
between the original program and the two possible revisions is obtained based on the effects
that each revision had on the probabilities with which literals are derived. So, for our
revisions, we get:
(I1 , I2 , (pos dep test, af 2 )) ≈ 0.0547
(I1 , I3 , (pos dep test, af 3 )) ≈ 0.8611
Therefore, we can conclude that the revision yielding I3 is preferred over the one yielding
I2 when this ROF is adopted.
Note that the function presented in Example 11 is just one possibility; the framework
is very flexible and allows the user to express many different functions, depending on the
specific way in which they wish to express distances between the original program and a
given revised program.

396

G. I. Simari et al.

3.2.2 The class QAFO
Given the basic constructs introduced above, we can now define the class of quantitative
annotation function-based revision operators.
Definition 13 (The Class QAFO) Let I = (EM , AM , af ), with AM = ∪∪ ∪  be
a DeLP3E program,  ∈ AFO be an annotation function-based belief revision operator, and
 be a revision objective function. Operator  is said to be a quantitative af-based operator
(denoted  ∈ QAFO) if:
Given an epistemic input (f, af  ), we have that if I  = I  (f, af  ) then there
does not exist DeLP3E program I  = I • (f, af  ) such that (I , I  , (f, af  )) >
(I , I  , (f, af  )),
where • ∈ AFO is an arbitrary operator.
So, this subclass of AFO simply takes a revision objective function and uses it to obtain
the best possible revised program. The following example, based on our previous work on
applications of DeLP3E to problems in the cyber security domain [39], shows how QAFO
operators can be applied to belief revision problems in real-world scenarios other than the
running example.
Example 12 Suppose we are modeling a cyber security scenario in which a computer worm
has been deployed and has infected millions of computers worldwide – by the time the
worm is discovered, it is very difficult to reason about the origin and even the intended
target of the attack. In this kind of situations, analysts are trying to solve the so-called attribution problem: given a cyber operation of interest, determine the party that was ultimately
responsible for carrying it out [37].
Towards this end, we can model all knowledge available by means of a DeLP3E program
I = (EM , AM , af ), in which there is one distinguished predicate condOp(A, O) in the
AM that is intuitively read as “actor A conducted operation O”. Furthermore, if we assume
that only one actor is ever responsible for an operation (an assumption that can easily be
removed), we have an integrity constraint of the form oneOf(C), where C is the set of all
ground atoms built with the condOp predicate.
Given this setup, we can define a WPF with a domain consisting of some formulas of
interest that reflect conditions that the analysts would like to remain relatively unaffected
when incorporating new information. For instance, suppose we define:

dom(ϒ) = ¬condOp(countryA, worm) ∧ ¬condOp(countryB, worm)

condOp(countryD, worm) ,
denoting the fact that neither country A nor country B are responsible for deploying the
worm, and that country D is. If we pair this WPF with the ROF from Example 11, the
corresponding QAFO operator will prefer revisions that do not affect the conclusions already
reached regarding the probabilities assigned to these statements.
In other words, this definition of dom(ϒ), with the ROF in question, causes distances
to be gauged relative to their effect on the probabilities assigned to the suspicions that (i)
neither country A nor country B carried out the attack, and (ii) country D is behind the
attack. Thus, such a setup causes the operator to prefer revisions that keep the probabilities
assigned to such suspicions as close as possible to the ones yielded by the original program.

Quantitative belief revision in structured probabilistic argumentation

397

In the next section, we study the computational complexity associated with this approach
to belief revision in the DeLP3E setting.

4 Computational complexity
In this section, we will focus on some of the computational aspects of quantitative af-based
belief revision operations.
As a first observation, we have that the problem of deciding the warranting status in a
(classical) PreDeLP program has not yet been pinpointed. In [4], the authors present a proof
for the PSPACE-completeness of the problem of marking a given dialectical tree; PSPACE
membership for deciding the warrant status is therefore a direct consequence of this result,
since a dialectical tree can be built within this budget. As a step towards finding a lower
bound for the complexity of the problem in general, we have the following.
Proposition 2 Let AM be a ground PreDeLP program and L be a ground literal. Deciding
AM war L is NP-hard.
Proof By reduction from 3SAT-CNF; we therefore start with an input formula F with n
variables X1 , . . . , Xn and m clauses C1 , . . . , Cm . We produce a PreDeLP program AM
with the following predicates: f , x1 , . . . , xn , and c1 , . . . , cm . We then set:
 = {f, ¬f, x1 , ¬x1 , . . . , xn , ¬xn }
 = {cj –≺ xi | Xi = T makes clause Cj true} ∪
{cj –≺ ¬xi | Xi = F makes clause Cj true} ∪
{f

–≺

ci | for each clause Ci }

= =∅
Next, we set the comparison criterion to specificity (the default in PreDeLP), except for the
following exceptions:

{xi , cj

–≺

xi }, cj  is always preferred over 
{¬xi , cj

–≺

¬xi }, cj 


{¬f }, ¬f  is preferred over 
{f }, f 
Now, we must show that AM war f if and only if there exists a satisfying assumption for formula F . Suppose AM war f ; the only way this can happen is if argument

{¬f }, ¬f  (the only counterargument to 
{f }, ) is defeated, which happens if and only if
all arguments that defeat this argument are in turn undefeated. Note that the only arguments
capable of being in this situation are the ones using the rules with cj in the head. Therefore,
if all such arguments are undefeated it must be the case that either xi or ¬xi can be chosen
for each variable Xi in such a way that all clauses are satisfied, which holds if and only if
there exists a satisfying assumption for F .
As a corollary to Proposition 2, we have that deciding our extended notion of warrant
status remains within the same complexity bounds.
Corollary 1 Let AM be a ground PreDeLP program and Q be either a conjunction or
disjunction of ground literals. Deciding AM war Q is NP-hard and in PSPACE.

398

G. I. Simari et al.

Proof (Sketch) Applying Definition 12, the warrant status of Q can be determined in polynomial time based on the warrant status of its literals; therefore, the same complexity results
for determining the warrant status of a single literal apply.

Assumption Since, as stated above, the precise complexity of deciding the warrant status
of a literal in a PreDeLP program is not yet known, and with the objective of separating
the complexity of this problem from the complexity of the problems inherent to quantitative belief revision in DeLP3E programs, in the following we will make the assumption that
classical warranting in PreDeLP is decidable in polynomial time. This is not an unreasonable assumption if we consider the possibility of pre-compiling inferences [3] or having
tractable approximation algorithms to address the problem. We call this the polynomialtime warranting (PTW) assumption. Note that, even though this assumption does not hold
in general, it is a useful tool in the analysis of the complexity of the problems studied here;
it is also with this spirit that we make use of the PTW assumption.
Unfortunately, our first result regarding the probabilistic extension of PreDeLP tells us
that computing WPFs runs into a computational tractability hurdle.
Theorem 1 Under the PTW assumption, computing the warrant probability function for a
DeLP3E program is #P-hard.

Proof We will prove the statement by reduction from #3CNF-SAT. Given formula F in
3CNF with n variables and m clauses, generate a DeLP3E program as follows: in the AM,
there is one atom f , one atom ci for each clause in F and two atoms for each variable V
in, which we denote with posV and negV . For each clause Ci in F of the form X̂ ∨ Ŷ ∨ Ẑ,
where V̂ denotes either V or ¬V , we have strict rules:
ci ← x̂
ci ← ŷ
ci ← ẑ
where v̂ denotes posV if V is positive in the clause and negV if it is negative. Next, we have
the strict rule:
f ← c1 , . . . , cm
and facts posV and negV for each variable V in the input formula.
In the EM we have atoms event-posV and event-negV for each variable V in F .
The probability distribution assigns probability 0.5 to each individual event, probability 0 to the conjunction of both events for the same variable, and probability 1 to their
disjunction.
Finally, the annotation function θ assigns formula True to all components of the AM,
except the facts, for which we have af (posV ) = event-posV and af (negV ) = event-negV .
Now we can see that, with this DeLP3E program, if the warranting probability function
ϒ assigns probability p to atom f , we have that:

λ∈nec(f ) Pr (λ) = p.
Clearly, from our construction we know that λ ∈ nec(f ) iff λ corresponds to a satisfying assignment for formula F . Therefore, p = 2kn , where k is the number of satisfying
assignments for F . Solving for k, we have k = p · 2n .

Quantitative belief revision in structured probabilistic argumentation

399

The complexity class #P contains problems related to counting solutions (or, in Turing
machine terms, accepting paths) to problems in NP. The decision version of this class is
called PP, and contains problems decidable by a probabilistic Turing machine in polynomial
time, with error probability less than a certain proportion (say, 1/2). Unfortunately, Toda’s
theorem [46] tells us that a polynomial-time Turing machine with either a PP or #P oracle
can solve all problems in the polynomial hierarchy.
Though it might be surmised that the #P-hardness is caused solely by the computation
of probabilities (as is the case in many probabilistic formalisms), by analyzing the proof of
Theorem 1 we can quickly arrive at the following conclusion.
Observation 1 Computing the warrant probability function for a DeLP3E program is #Phard even in the special case in which probabilities associated with EM worlds can be
computed in PTIME.
Though this intractability holds in general, restricting the EM can soften the impact on
complexity. For instance, if we assume that Nilsson’s probabilistic logic [32] is used then
the complexity is lowered, as we show next; first, we introduce a lemma that will be used in
the proof of this result:
Lemma 1 ([6, 12]) If a system of m linear equalities and/or inequalities has a nonnegative
solution, then it has a nonnegative solution with at most m positive variables.
This result was first introduced in [6], and later used in [12] to show that deciding the
validity of a formula in their logic is NP-complete. We can now state our result.
Proposition 3 Under the PTW assumption, and assuming that Nilsson’s probabilistic logic
is used in the EM, computing the warrant probability function for a DeLP3E program is
NP-complete.
Proof
Membership: Lemma 1 states that a solution to a linear program is guaranteed to exist
where only a number of the variables that is linear in the number of constraints in the EM are
set to a non-zero value. This implies the existence of a number of EM worlds with non-zero
probability that is linear in the number of statements in the probabilistic model. A witness
can therefore be verified in polynomial time.
Hardness: NP-hardness is a consequence of the well-known fact that SAT is reducible to
computing probabilities in Nilsson logic (cf. [26] for a detailed proof).
The previous result gives us a hint towards reaching the next one: if we combine
the simplifying assumption that probabilities can be computed tractably with the further
assumption that the number of EM worlds that have non-zero probability is bounded by
a polynomial (condition 1 below), then we are guaranteed that computing WPFs is also
tractable.
Corollary 2 Let I = (EM , AM , af ), with AM = ∪∪ ∪ , be a DeLP3E program.
If we make the following assumptions:
1.
2.
3.

|{λ | λ ∈ WEM and Pr(λ) > 0}| ∈ O(poly(n)), where n represents the size of the input;
Pr(λ) can be computed in PTIME for any λ ∈ WEM ; and
the PTW assumption holds,

400

G. I. Simari et al.

then warrant probability functions for I can also be computed in PTIME.
Proof Direct consequence of the assumption that we have access to the polynomially many
worlds that have non-zero probability. We thus simply keep an accumulator for each element
in the domain of the WPF and iterate through the set of worlds, adding the probability of
the world to each formula’s accumulator if and only if it is warranted in the AM induced by
that world.
Unfortunately, the following result states that even in this scenario we still face an
intractable hurdle when computing optimal revisions.
Theorem 2 Let I = (EM , AM , af ), with AM = ∪∪ ∪ , be a DeLP3E program,
 ∈ QAFO, and  be a revision objective function that can be computed in polynomial time.
If we have that:
1. |{λ | λ ∈ WEM and Pr(λ) > 0}| ∈ O(poly(n)), where n represents the size of the input;
2. Pr(λ) can be computed in PTIME for any λ ∈ WEM ; and
3. the PTW assumption holds,
then deciding if (I , I  (f, af  ), (f, af  )) ≤ k for some k ∈ R, is NP-complete.
Proof
Membership: Given I  , we can check in polynomial whether each world with nonzero probability induces a maximal consistent subset of I in that world; by construction,
AFO operators are only constrained to make such changes in worlds with probability
greater than zero. Furthermore, since by hypothesis we know that  can be computed in polynomial time, we can decide whether or not the witness satisfies the
constraints.
Hardness: By reduction from SUBSET-SUM; we therefore start from an instance of this
problem, which consists of a set of n integers x1 , . . . , xn and another integer c; the goal is
to verify if there exists a subset of the numbers that add up to c. Lets then create an instance
of our problem, starting with a DeLP3E program with one atom numi in the AM for each
xi in the input instance, as well as an auxiliary atom p; there will also be a corresponding
atom event-numi in the EM for each such atom. The probability distribution associated with
these random variables is set to an arbitrary one satisfying the condition that only a number
polynomial in n has non-zero probability.
Add as facts all atoms numi , with the annotation function defined as af (numi ) =
event-numi . Next, add the strict rule:
ω : ¬numi ← p
such that af (ω) = True. Set the epistemic input to fact θin with af (θin ) = event-num1 ∨
. . . ∨ event-numn . Finally, set the function to optimize to:
⎧

⎪
i | numi ∈ AM , af (numi )  |= ⊥}
⎨ 1 if res = {num

is such that numi ∈res xi = c
obj(I , I  ) =
⎪
⎩
0 otherwise.
That is, the objective function only considers the revised DeLP3E program, and takes value 1
if and only if the atoms that belong to this program correspond to numbers that, taken

Quantitative belief revision in structured probabilistic argumentation

401

together, sum up to c. Thus, all we have to do is check if the optimal revision yields a value
of 1 for the objective function in order to decide the given subset-sum instance.
The reader may note that the construction used in the proof of Theorem 2 uses a very
powerful objective function that essentially encodes the NP-hard problem; furthermore, this
objective function is not based on WPFs. We now provide an alternative result that proves
NP-completeness under the same conditions, but assumes that the objective function is simply the sum of the probabilities assigned by the WPF to the set of ground atoms in the
language associated with the AM.
Theorem 3 Let I = (EM , AM , af ), with AM = ∪∪ ∪ , be a DeLP3E program,
 ∈ QAFO, and  be a revision objective function that can be computed in polynomial time.
If we have that:
1. |{λ | λ ∈ WEM and Pr(λ) > 0}| ∈ O(poly(n)), where n represents the size of the input;
2. Pr(λ) can be computed in PTIME for any λ ∈ WEM ; and
3. the PTW assumption holds,
then deciding if 
(I , I  (f, af  ), (f, af  )) ≤ k for some k ∈ R, is NP-complete even when
 is defined as a∈GAM ϒ(a).
Proof
Membership: As the ROF can still be computed in polynomial time, the membership result
of Theorem 2 still holds.
Hardness: We show NP-hardness by reduction from SIMPLE MAX CUT (SMC) [19]. The
SMC problem takes as input an undirected graph G = (V , E) and k ≥ 0, and decides if
there exist sets V1 , V2 ⊆ V such that |{(u, v) ∈ E : u ∈ V1 , v ∈ V2 }| ≥ k.
Let x be a the only atom in GEM . We will define a simple EM that sets the probability of
atom x to 1.0. We specify the atoms in GAM as follows: for each vi ∈ V we create two atoms,
set1 (vi ), set2 (vi ). For each edge (vi , vj ) ∈ E we create atom edge(vi , vj ) (we assume that
each bi-directional edge is specified by one atom an that the order of the arguments for the
edge predicate is arbitrary but consistent). We will also have an additional atom query in
GAM , which will also act as the formula for the epistemic input. We create AM with the
following elements:
–

–

For each vi ∈ V add the following strict rules:
–

set1 (vi ) ← query

–

¬set1 (vi ) ← query

–

set2 (vi ) ← ¬set1 (vi )

For each edge (vi , vj ) ∈ E add strict rules edge(vi , vj ) ← set1 (vi ), set2 (vj ) and
edge(vi , vj ) ← set2 (vi ), set1 (vj )

For each element y ∈ AM , we define the annotation function af (y) = True. For the
epistemic input, let af  be the extension of af such that af  (query) = x. Finally, let the ROF
be defined as in the statement of the theorem. Further, for ease of notation, let af ∗ be the
annotation function returned after the belief revision operation takes place.
Clearly, this construction can be performed in polynomial time. Further, note that the
original program is consistent, since none of the rules in AM ever fire since there are no
facts.

402

G. I. Simari et al.

Observations: We notice right away that any valid belief revision operator must return
an annotation function af ∗ such that {x} |= af ∗ (query) – as this atom is needed to
ensure the objective function has a non-zero value (which is clearly possible). Further, any optimal solution where af ∗ (query) ≡ True can be replaced with a solution
where af ∗ (query) = x. We also note that in any optimal solution, the size of the
set {setX (vi ) | ϒ(setX (vi ) = 1.0} is equal to |V | – this is how we capture the
notion that for each vertex vi , exactly one of set1 (vi ), set2 (vi ) will be warranted under
world {x}); hence, we capture the requirement from the instance of SMC that the sets
V1 , V2 is a partition of V . We also note that the annotation function in the solution
af ∗ must only modify the return values for strict rules of the form set1 (vi ) ← query
and ¬set1 (vi ) ← query.
Claim 1: Let V1 , V2 be an optimal solution to an instance of SMC. Then, the optimal
solution to the corresponding revision problem has an objective function whose value is
greater than or equal to |{(u, v) ∈ E : u ∈ V1 , v ∈ V2 }| + |V | + 1. This can clearly be
achieved by a solution where for each vi ∈ V1 , af ∗ (set1 (vi ) ← query) = x and for each
vi ∈ V2 , af ∗ (¬set1 (vi ) ← query) = ¬x.
Claim 2: Let R be the value of the objective function returned in an optimal solution to
the revision problem. Then, the number of edges returned in the corresponding instance of
SMC is greater than or equal to R − |V | − 1. By the aforementioned observations, this
claim is equivalent to saying that the number of positive literals of the form edge(vi , vj ) that
are warranted in the world {x} is less than or equal to the number of edges returned in the
optimal solution to the corresponding instance of SMC. Suppose, by way of contradiction,
that the number of literals of that form that are warranted under {x} is greater than the
number of edges in the optimal solution to the corresponding instance of SMC. By the
construction, for each literal of the form edge(vi , vj ), exactly one of the following pairs of
literals must also be warranted: set1 (vi ), set2 (vj ) or set2 (vi ), set1 (vj ). Therefore, we can
partition the corresponding vertices from SMC into two sets – V1 , V2 and the number of
edges in the set {(u, v) ∈ E : u ∈ V1 , v ∈ V2 } must then be greater than the number of
edges in the optimal solution to the SMC problem. However, this is not possible, as this is
also (by construction) the same objective function that is optimized in that problem – hence,
we reach a contradiction.
The proof of hardness follows directly from Claims 1 and 2.
So, the proof of Theorem 3 illustrates that the quantified revision problem is still NPhard when the EM and the number of EM worlds, and (hence) the computation of the WPF
is not a source of complexity – even when the ROF used is a simple aggregate over WPFs
of atoms. Further, as we can embed the Simple Max Cut problem, the ROF – even a simple
sum over WPFs – will not necessarily be monotonic, even when using a revision operator
that satisfies the Inclusion postulate (where the set of worlds satisfying af ∗ (y) ⊆ af  (y)).
This also shows NP-completeness when the belief revision operator performs modifications
to AM (by removing elements, as discussed in [40]) as setting af ∗ (y) = ¬x can be viewed
as an operation that is equivalent to removing it from AM .
We also note that the related problem of consolidation or contraction by falsum, where
we start with an inconsistent program and then must adjust the annotation function to
make it consistent, can also be shown to be NP-complete by a simple modification to the
proof: we fix the epistemic input to True, and change the rules of the form set1 (vi ) ←
query, ¬set1 (vi ) ← query to facts of the form set1 (vi ), ¬set1 (vi ).

Quantitative belief revision in structured probabilistic argumentation

403

Fig. 12 An algorithm that takes a classical dialectical forest and computes a logical formula specifying the
possible worlds under which a given literal is warranted

5 Warranting formulas
We now focus on an algorithmic approach that can be used to compute approximate solutions and therefore address the computational intractability that we have seen in the results
above.
In the following, given a dialectical forest
 F (L) and a node V corresponding to argument
A, we will use the notation label(V ) = c∈A af (c). For a given probabilistic argumentation framework, literal, and dialectical tree, Algorithm warrantFormula in Fig. 12 computes
the formula describing the set of possible worlds that are warranting scenarios for the literal.
Intuitively, this algorithm creates a formula for every dialectical tree in the forest associated
with an argument – the algorithm iteratively builds a formula associated with the environmental conditions under which the argument in the root of the tree is undefeated. It then
returns the disjunction of all such formulas in that forest. We refer to this disjunction as the
warranting formula for the literal.
The following result states the correctness of the warrantFormula algorithm.
Proposition 4 Given forest F ∗ (L),



nec(L) = λ ∈ WEM | λ |= warrantFormula F ∗ (L)



poss(L) = λ ∈ WEM | λ  |= warrantFormula F ∗ (¬L) .
Proof (Sketch)
Claim 1: nec(L) ⊆ {λ ∈ WEM | (λ |= warrantFormula(F ∗ (L)))}. To prove
this claim, it suffices to show that if Tλ
A,L is a valid dialectical tree for L then
λ |= warrantFormula(F ∗ (L)). Suppose, BWOC, Tλ
A,L is such a tree where λ  |=
warrantFormula(F ∗ (L)). We note that this tree shares a root and is a subtree of a
tree in F ∗ (L). Also, for each node v in the tree, at line 2, we have λ |= label(v).
Hence, we can continue the proof by replacing line 2 with ∀v, label(v) = f or(λ)
and showing that warrantFormula(F ∗ (L)) = f alse. However, we can conclude that
warrantFormula(F ∗ (L)) = f or(λ) since the tree has an odd depth by definition – this is a
contradiction.
Claim 2: nec(L) ⊇ {λ ∈ WEM | (λ |= warrantFormula(I , L))}. Suppose, by way
of contradiction, that the claim is false. Then there must exist a root-sharing subtree

404

G. I. Simari et al.

Fig. 13 Dialectical forest for literal L = sleep aid misuse composed of trees T1 (left) and T2 (right)

of an element of F ∗ (L) such that for each v, at step 4 λ |= label(v) and does not exist in λ.
However, this is a contradiction by Definition 7.
Claim 3: The second part of the statement follows directly from Claims 1-2 and the fact
that poss(L) = WEM \ nec(¬L).
Even though warranting formulas are another way of solving the problem of computing probabilities exactly, our main motivation for developing it was to explore options for
pursuing tractable algorithms, as discussed next.
The following is an example of the warranting formula approach in the setting of our
running example.
Example 13 Consider the DeLP3E in our running example as shown in Fig. 11 with annotation function af 1 . If we run Algorithm warrantFormula for literal sleep aid misuse, we start
with the dialectical forest shown in Fig. 13.
Suppose that the algorithm begins with tree T1 (on the left); the only leaf of this tree
corresponds to vertex v2 for argument A2 , and its label remains the conjunction of all annotations of elements in the argument – label(v2 ) = ¬F N tox screen. The algorithm then
moves to the next node up, which is already the root, and updates the label by adding the
conjunction with the negation of its child, which yields:


label(v1 ) = dep risk ∧ ¬ ¬F N tox screen = dep risk ∧ F N tox screen.
Processing tree T2 similarly yields:



label(v3 ) = True ∧ ¬ ¬F N tox screen = F N tox screen.

Finally, the algorithm outputs the disjunction of these two formulas, which is simply
F N tox screen.

Outlook: towards tractable computations
By applying the warrantFormula algorithm to the dialectical forest for a given literal L, we
can obtain the sets nec(L) and poss(L) with a running time proportional to the size of
the forest and the annotation formulas – though the worst-time complexity has not been
determined exactly, it is safe to conjecture that the worst case is intractable. However,
the warranting formula approach opens the door to several possibilities for heuristics and
approximate computations that either avoid exhaustively enumerating worlds in WEM or
working with full forests (or both). When combined with existing heuristics for classical

Quantitative belief revision in structured probabilistic argumentation

405

argumentation (the AM) and probabilistic models (the EM), this provides us with a much
more efficient way to compute warranting probability functions. Experimental evaluations
for such hypotheses are currently underway.
The use of the warranting formula approach can have several impacts in the implementation of specific QAFO operators. First, warrant probability functions ϒ in this setting
can now be redefined to map elements in their domain to warranting formulas instead of
probabilities as in their original formulation. Revision objective functions now have at their
disposal formulas instead of raw numbers. This opens up the possibility for specific implementations to leverage optimizations such as applying SAT algorithms to decide whether
Pr I1 (L) ≥ Pr I2 (L) (which can be decided via the SAT check ϒI1 (L) ⇒ ϒI2 (L)). Such an
approach is clearly compatible with heuristic optimizations that may, for instance, sacrifice
precision for greater tractability.
An alternative class of operators can thus be defined based on the same ideas as QAFO
except that approximations are allowed instead of exact computations. There is much work
to be done in this direction, which is outside the scope of the current paper.

6 Related work
This paper continues the research line that began with two works on belief revision in structured probabilistic argumentation. In [38], we introduced the DeLP3E formalism (which
is called P-PreDeLP in that work) and annotation-function based belief revision (the class
AFO), while in [39] we studied a special case of entailment queries and showed how the
framework can be applied to a cyber-attribution problem.
As we have seen, the main problem studied in belief revision is the study of how epistemic states should be changed in response to epistemic inputs. Traditionally, epistemic
states have taken the form of either belief sets (sets of formulas closed under consequence) [1, 18] or belief bases [22, 23] (which are not closed). Our goal is to ultimately
apply our results to real-world domains, and therefore we focus our attention on belief bases.
Epistemic states in our case consist of formulas over which argumentation-based reasoning is carried out and to which we couple a general probabilistic model. The relationship
between argumentation and belief revision can be traced back to [10]; in this regard, the
work that is most closely related to how we approach their combination is that of [14],
where explanation-based revision operators are studied. For a discussion on the relationship
between the two areas of study, see [15] and [13].
Regarding argumentation systems that feature some quantitative form of reasoning under
uncertainty, we point out that the combination of probabilistic reasoning with argumentation systems has been the focus of several works in the recent past. A significant portion of
this work, however, has adopted abstract argumentation systems as the basis for the probabilistic extension [16, 24, 28, 44]. Contrary to structured argumentation systems like the
one adopted in this work, abstract argumentation is focused on the study of attacks among
arguments without inspecting their composition. There are also some works that combine
structured argumentation approaches with models for reasoning under uncertainty – the first
of these was [21]; the work of [27], which was developed even earlier, combines structured
argumentation with abstract uncertainty measures but does not explicitly handle probability. Several other works followed; for instance, in [5], the authors develop a possibilistic
extension to DeLP, and [25] presents an approach based on probabilistic logic. The main
difference between these works and our own is that here we adopt a bipartite knowledge
base, where one part models the knowledge that is not inherently probabilistic – uncertain

406

G. I. Simari et al.

knowledge is modeled separately, thus allowing a clear separation of interests between the
two kinds of models. This kind of approach is not novel; it has been adopted in several
frameworks, such as the Independent Choice Logic [34] or probabilistic ontology languages
for the Semantic Web (see [20], and references within).
From a quantitative take on belief revision, which is the specific topic of this paper, there
hasn’t been much work in the precise direction taken here. Perhaps the earliest proposal
with such an idea in mind is that of maxichoice revision operators [2], which ensure that
minimal changes are made to the knowledge base when revisions are performed; in fact,
our class of AFO operators (and therefore also QAFO) perform maxichoice revision operations in each possible EM world. In the related setting of belief contraction operators, David
Makinson [30] has defended the use of maxichoice operators, explaining that some counterintuitive behaviors that this approach leads to is due to its “misapplication” to belief sets
(which, we recall, are closed under consequence). Another quantitative proposal is the one
presented in [7], where revisions are carried out according to a notion of distance between
worlds, such as the number of propositional symbols that separate one model from another.
These notions, however, do not correspond directly with the one adopted here, since in our
setting we are pursuing a revision that is optimal from the point of view of its effect on the
probabilistic aspect of the consequences of the knowledge base, while the knowledge bases
in [2] are non-probabilistic. Another interesting approach to belief revision from a quantitative standpoint is ranking theory [42], which is a normative theory of the dynamics of belief.
Again, this approach is not directly related to the one taken here; however, exploring how
this well-studied approach can be applied in conjunction with argumentation in the way that
probability theory is applied in this work is an interesting avenue for future work.
Along the same vein of seeking to minimize information loss, and in the closely related
setting of inconsistency management, the work of [20] proposes the notion of preferred
repair based on so-called “consistency scores”; our quantitative approach to performing
belief revision operations is loosely based on this proposal. Also in the inconsistency management literature, the recent work of [8, 9] proposes to resolve conflicts at a global level
to minimize information loss but using incision functions instead. Another work in inconsistency management is that of [45] proposes measures of inconsistency for probabilistic
logics. Apart from [20], this is perhaps the closest work in spirit to the one presented here,
though the underlying language used (probabilistic conditional logic) is quite different and
that work does not address the problem of belief revision – their measures, however, could
be applied to efforts in line with our own. The adaptation of measures of probabilistic inconsistency such as the ones proposed in [45] to DeLP3E and their use in quantitative belief
revision operators is the topic of ongoing and future work.

7 Conclusions and future work
In this work, we tackled the problem of incorporating a new piece of information to an
existing knowledge base; specifically, we adopted the DeLP3E model, which is an extension of the structured argumentation language DeLP with presumptions (PreDeLP) via the
incorporation of annotations that refer to events for which we have underlying probabilistic
information.
The main focus of this paper was to further explore a class of belief revision operators
called AFO (for annotation function-based revision) that we proposed recently in [38, 40]
by considering operators in this class that have the further requirement of “quantitative optimality” – this gave rise to the QAFO class of operators. Though this optimality criterion

Quantitative belief revision in structured probabilistic argumentation

407

was kept as general as possible so that knowledge engineers can specify their preferences,
we explored the computational complexity of the approach in general, arriving at a host of
results that range from intractability for the general case to polynomial-time special cases.
finally, we presented an algorithm designed to compute the probability with which a literal is warranted via so-called warranting formulas, and provide some initial discussion
regarding how this approach could be applied in the implementation of QAFO operators or
approximations of them that trade theoretical guarantees for tractability in practice.
Future work along this line of research involves continuing with efforts to bridge the gap
between the theoretical developments that have been steadily coming from the belief revision community and practical implementations that can be applied in real-world domains
such as medical diagnosis (the topic of our running example) and the related problem of
solving the attribution problem in cyber security and cyber warfare, as proposed in [39].
We are also investigating the use of different kinds of belief revision operators, for instance
ones that are based on argumentation [14]. Finally, we are currently in the final stages of
developing a fully-functional implementation of DeLP3E; incorporating the belief revision
operators developed in [38, 40] and in this paper is the next step in the implementation
effort.

Acknowledgments This work was supported by UK EPSRC grant EP/J008346/1—“PrOQAW”, ERC
grant 246858—“DIADEM”, by NSF grant #1117761, by the Army Research Office under the Science
of Security Lablet grant (SoSL) and project 2GDATXR042, DARPA project R.0004972.001, and funds
provided by CONICET and Universidad Nacional del Sur, Argentina.
The opinions in this paper are those of the authors and do not necessarily reflect the opinions of the
funders, the U.S. Military Academy, or the U.S. Army.

References
1. Alchourrón, C.E., Gärdenfors, P., Makinson, D.: On the logic of theory change: Partial meet contraction
and revision functions. J. Sym. Log. 50(2), 510–530 (1985)
2. Alchourrón, C.E., Makinson, D.: On the logic of theory change: Contraction functions and their
associated revision functions. Theoria 48(1), 14–37 (1982)
3. Capobianco, M., Chesñevar, C.I., Simari, G.R.: Argumentation and the dynamics of warranted beliefs
in changing environments. Intl. Journal on Autonomous Agents and Multiagent Systems (JAAMAS) 11,
127–151 (2005)
4. Cecchi, L.A., Simari, G.R.: El marcado de un árbol dialéctico en DeLP es PSPACE-completo. In:
Proceeding of Congreso Argentino de Ciencias de la Computación (CACIC) (2011)
5. Chesñevar, C.I., Simari, G.R., Alsinet, T., Godo, L.: A logic programming framework for possibilistic
argumentation with vague knowledge. In: Proceeding of UAI 2004, pp. 76–84 (2004)
6. Chvátal, V.: Linear programming. W.H.Freeman, New York (1983)
7. Dalal, M.: Investigations into a theory of knowledge base revision: Preliminary report. In: Proceeding of
AAAI, pp. 475–479 (1988)
8. Deagustini, C.A.D., Martinez, M.V., Falappa, M.A., Simari, G.R.: Improving inconsistency resolution
by considering global conflicts. In: Proceedings of SUM, pp. 120–133 (2014)
9. Deagustini, C.A.D., Martinez, M.V., Falappa, M.A., Simari, G.R.: Inconsistency resolution and global
conflicts. In: Proceedings of ECAI, pp. 991–992 (2014)
10. Doyle, J.: A truth maintenance system. Artif. Intell. 12(3), 231–272 (1979)
11. Dung, P.M.: On the acceptability of arguments and its fundamental role in nonmonotonic reasoning,
logic programming and n-person games. Artif. Intell. 77, 321–357 (1995)
12. Fagin, R., Halpern, J.Y., Megiddo, N.: A logic for reasoning about probabilities. Inf. Comput. 87(1/2),
78–128 (1990)
13. Falappa, M.A., Garcia, A.J., Kern-Isberner, G., Simari, G.R.: On the evolving relation between belief
revision and argumentation. Knowl. Eng. Rev. 26(01), 35–43 (2011)

408

G. I. Simari et al.

14. Falappa, M.A., Kern-Isberner, G., Simari, G.R.: Explanations, belief revision and defeasible reasoning.
Artif. Intell. 141(1/2), 1–28 (2002)
15. Falappa, M.A., Kern-Isberner, G., Simari, G.R.: Belief revision and argumentation theory. In: Argumentation in artificial intelligence, pp. 341–360. Springer (2009)
16. Fazzinga, B., Flesca, S., Parisi, F.: On the complexity of probabilistic abstract argumentation. In:
Proceeding of IJCAI 2013 (2013)
17. Garcı́a, A.J., Simari, G.R.: Defeasible logic programming: an argumentative approach. TPLP 4(1-2), 95–
138 (2004)
18. Gardenfors, P.: Knowledge in flux: modeling the dynamics of epistemic states. MIT Press, Cambridge
(1988)
19. Garey, M., Johnson, D.: Computers and intractability: a guide to the theory of NP-completeness.
Freeman, New York (1979)
20. Gottlob, G., Lukasiewicz, T., Martinez, M.V., Simari, G.I.: Query answering under probabilistic
uncertainty in Datalog +/− ontologies. AMAI (2013)
21. Haenni, R., Kohlas, J., Lehmann, N.: Probabilistic argumentation systems. Springer (1999)
22. Hansson, S.: Semi-revision. J. App. Non-Classical Logics 7(1-2), 151–175 (1997)
23. Hansson, S.O.: Kernel contraction. J. Symb. Log. 59(3), 845–859 (1994)
24. Hunter, A.: Some foundations for probabilistic abstract argumentation. In: Proceeding of COMMA 2012,
pp. 117–128 (2012)
25. Hunter, A.: A probabilistic approach to modelling uncertain logical arguments. Int. J. Approx. Reasoning
54(1), 47–81 (2013)
26. Khuller, S., Martinez, M.V., Nau, D.S., Sliva, A., Simari, G.I., Subrahmanian, V.S.: Computing most
probable worlds of action probabilistic logic programs: scalable estimation for 1030,000 worlds. AMAI
51(2-4), 295–331 (2007)
27. Krause, P., Ambler, S., Elvang-Gørannson, M., Fox, J.: A logic of argumentation for reasoning under
uncertainty. Comput. Intell. 11(1), 113–131 (1995)
28. Li, H., Oren, N., Norman, T.J.: Probabilistic argumentation frameworks. In: Proceeding of TAFA, pp. 1–
16 (2011)
29. Lloyd, J.W. Foundations of logic programming, 2nd edn. Springer (1987)
30. Makinson, D.: On the status of the postulate of recovery in the logic of theory change. J. Philos. Log.
16(4), 383–394 (1987)
31. Martinez, M.V., Garcı́a, A.J., Simari, G.R.: On the use of presumptions in structured defeasible
reasoning. In: Proceeding of COMMA, pp. 185–196 (2012)
32. Nilsson, N.J.: Probabilistic logic. Artif. Intell. 28(1), 71–87 (1986)
33. Pearl, J.: Probabilistic reasoning in intelligent systems: networks of plausible inference (1988)
34. Poole, D.: The independent choice logic for modelling multiple agents under uncertainty. Artif. Intell.
94(1-2), 7–56 (1997)
35. Rahwan, I., Simari, G.R.: Argumentation in artificial intelligence. Springer (2009)
36. Richardson, M., Domingos, P.: Markov logic networks. Mach. Learn. 62, 107–136 (2006)
37. Shakarian, P., Shakarian, J., Ruef, A.: Introduction to cyber-warfare: a multidisciplinary approach.
Syngress (2013)
38. Shakarian, P., Simari, G.I., Falappa, M.A.: Belief revision in structured probabilistic argumentation. In:
Proceeding of FoIKS 2014, pp. 324–343
39. Shakarian, P., Simari, G.I., Moores, G., Parsons, S., Falappa, M.A.: An argumentation-based framework
to address the attribution problem in cyber-warfare. In: Proceeding of Cyber Security 2014 (2014)
40. Shakarian, P., Simari, G.I., Moores, G., Paulo, D., Parsons, S., Falappa, M.A., Aleali, A.: Belief revision
in structured probabilistic argumentation: Model and application to cyber security. Under review (2014)
41. Simari, G.R., Loui, R.P.: A mathematical treatment of defeasible reasoning and its implementation. Artif.
Intell. 53(2-3), 125–157 (1992)
42. Spohn, W.: The laws of belief: ranking theory and its philosophical applications. Oxford University Press
(2012)
43. Stolzenburg, F., Garcı́a, A., Chesñevar, C.I., Simari, G.R.: Computing generalized specificity. J. NonClassical Logics 13(1), 87–113 (2003)
44. Thimm, M.: A probabilistic semantics for abstract argumentation. In: Proceeding of ECAI 2012,
pp. 750–755 (2012)
45. Thimm, M.: Inconsistency measures for probabilistic logics. Artif. Intell. 197, 1–24 (2013)
46. Toda, S.: On the computational power of PP and ⊕P. In: Proceeding of FOCS, pp. 514–519 (1989)
47. Wirth, C., Stolzenburg, F.: David Poole’s specificity revised. In: Proceeding of KR (2014)

Product Offerings in Malicious Hacker Markets
Ericsson Marin, Ahmad Diab and Paulo Shakarian

arXiv:1607.07903v1 [cs.CR] 26 Jul 2016

Arizona State University
Tempe, Arizona
{ericsson.marin, ahmad.diab, shak}@asu.edu

Abstract—Marketplaces specializing in malicious hacking
products - including malware and exploits - have recently become
more prominent on the darkweb and deepweb. We scrape 17
such sites and collect information about such products in a
unified database schema. Using a combination of manual labeling
and unsupervised clustering, we examine a corpus of products
in order to understand their various categories and how they
become specialized with respect to vendor and marketplace. This
initial study presents how we effectively employed unsupervised
techniques to this data as well as the types of insights we gained
on various categories of malicious hacking products.

not trivial, including effort to answer questions, solve puzzles,
mathematical equation or CAPTCHA.
Most related work on darkweb markets such as [3] focus
on a single market and do not restrict their study to malicious
hacking products. Our previous work on markets [4] focused
on a game theoretic analysis of a small subset of the data in
this paper - and did not attempt to categorize the products for
sale. Additionally, there is a complementary lines of work on
malicious hacking forums (i.e. [5], [6], [7], [8], [9], [10], [11],
[12]) - which is a related but different topic from this paper.

I. I NTRODUCTION
Websites on the deepweb and darkweb specializing in
the sale of malicious hacking products - such as malware
platforms, software exploits and botnet rental - have become
the venue of choice for online purchase of these items by cyber
criminals. In this paper, we leverage unsupervised learning
to categorize and study the product offerings of 17 of these
online markets. Specifically, we describe how we used manual labeling combined with clustering techniques to identify
product categories (Section II), and then we analyze the results
both quantitatively and qualitatively (Section III). We identify
categories of products that are highly specialized with respect
to particular vendors and markets. We also highlight other
interesting facets of this ecosystem - for instance, vendors
who habitually cross-list products on multiple sites and nearly
identical products for sale by multiple vendors.
Background and Related Work. The darkweb refers to the
anonymous communication provided by crypto-network tools
such as ”The Onion Router” (Tor), which is free software
dedicated to protect the privacy of its users by obscuring traffic
analysis as a form of network surveillance [1]. On the other
hand, the deepweb refers to sites not indexed by common
search engines due to a variety of reasons (e.g. password
protections), that not necessarily rely on additional protocols.
The sites on the darkweb and deepweb explored in this
study comprise marketplaces [2]. In these websites, vendors
advertise and sell their goods and services relating to malicious
hacking, drugs, pornography, weapons and software services.
Products are most often verified before any funds are released
to the seller. The main engine of these environments is trust.
If a seller is misleading or fails to deliver the appropriate item,
he is banned from the site. Similarly, buyers can be banned
for not complying with the transaction rules. Basically, all
marketplaces in darkweb require a registration and a valid
account to get access. Sometimes, this registration process is

II. M ALICIOUS H ACKING P RODUCT C ATEGORIZATION
In this section, we describe our malicious hacker product
dataset and our use of clustering to identify malicious hacker
product categories. We examined 17 malicious hacker marketplaces crawled over a 6 month period. The crawled information
was then parsed and stored in a relational database. Relevant
tables record the marketplaces themselves, the vendors of the
various products and the items/products for sale. Each item
is associated with a vendor and a marketplace, allowing for
join queries. Some of the more relevant fields for marketplace
items include the price, title, description, rating, posting date.
In this work, we primarily extract features from the product
title/name to generate features.
We note that many items are cross-posted and are nearly
identical. We show the distribution of vendors who use the
same screen-name across multiple marketplaces in Fig. 1(a).
To clean our product data, we identify duplicate (cross-posted)
products and report on the size of our dataset in Table I.
As we collect data from a variety of different sites, there is
inconsistency as to how products are categorized on each site
- if such non-trivial categorization even exists for a given site.
In addition, there is a clear absence of a standardized method
for vendors to register their products. As a consequence, the
great majority of products are unique when compared with
simple matching or regular expression technique. It is valid
even in the case where a pair of vendors with different screen
names post what a human would determine to be the same
product. Fig. 1(b) shows the distribution of products and
number of vendors sharing each product. The distribution
follows a power-law. Note that about 57% of products are
unique by simple comparison methods.
Clustering approach. Using product names, we engineer
features that represent each product as a vector. A set of
pilot experiments suggests that word and character n-grams

TABLE I
S CRAPED DATA FROM M ARKETPLACES IN DARKWEB .
Marketplaces
Products (Total)
Products (Distinct)
Vendors
60

17
16122
9093
1332

Number of Shared Vendors

10000

50
1000

Number of Products

40

100

30
20
10

10

1

0
0

2

4

6

8

10 12 14 16 18

0 2 4 6 8 10 12 14 16 18 20 22 24

Markets

Number of Shared Vendors

(a)

(b)

Fig. 1. Distribution of (a) Shared Vendors over Markets. (b) Products over
Shared Vendors.

Table II shows the performance of each TF-IDF vectorization using Rand-index and entropy, when K-means starts
with the 34 fixed centroids. For Rand-index, character ngrams in the range from 3 to 4, 3 to 5, and 3 to 6, when Kmeans used cosine similarity reached a high best performance
(0.986). In addition, we also found the best entropy (0.067)
when K-means uses the same specification. This way, K-means
configuration with character n-grams in the range from 3 to
6 for vectorization, cosine similarity for distance function and
the 34 points for the starting centroids was our natural choice
to produce the clusters in the entire dataset.
We also examined the performance of our approach using
random centroids. As expected, it performs worse than using
the centroids derived from products. Additionally, we examined products (from the full dataset) with a cosine similarity
of less than 0.1 from the calculated centroids. There were 410
such distinct products (4.51% of the dataset). These were then
manually examined and most were found to be irrelevant to
our target domain - and we did not consider them further.
III. A NALYST I NTERPRETATION OF P RODUCT C LUSTERS

would provide more pure clusters compared with other feature
engineering methods, such as meta-data or domain-specific
keywords. These features were valued using standard term
frequency - inverse document frequency (TF-IDF), after the
elimination of stopping words and the execution of steaming.
We evaluated word n-gram feature vectors of length up to 1
and up to 2 words and many character n-gram features in the
ranges from 3 to 7 and from 4 to 7. This gave us 10 different
feature vectors in all. To verify which of these strategies could
reach the best performance in our dataset, we evaluated the
effect of the different types of feature vectors on the accuracy
and purity of clusters produced by the K-means algorithm.
To determine the best feature vector, we manually labeled
500 samples using 34 labeled groups (listed in Table III). We
used 400 of the samples to determine centroids for each of
the 34 groups, and then we evaluated the resulting clustering
on the remaining 100 samples. We examined the accuracy
of the different approaches when compared to ground truth
using the Rand-index method [13]. This method is defined as
the number of pairs correctly considered in the sameclass or
correctly considered in different classes divided by n2 , where
n is the number of samples. In addition, we used standard
entropy measurements to examine the purity of the clusters.
Entropy measures the amount of disorder in a cluster. A zerovalue for this metric means the clusters are formed by just one
class. The formal definition is as follows:
entropy(Di ) = −

k
X

P ri (cj ) log2 P ri (cj ),

(1)

i=1

where P ri (cj ) is the proportion of class cj data points in
cluster i or Di . The total entropy (considering all clusters) is:
entropytotal (D) =

k
X
|Di |
i=1

|D|

x entropy(Di )

(2)

In this section, we examine the results of clustering based
on character n-grams in the range 3 to 6 using initial centroids
determined from the labeled data. In order to analyze the
information of these clusters, we calculated their entropy with
respect to two different criteria: marketplaces and vendors.
We also checked in the database the number of distinct
marketplaces and vendors inside each cluster. The idea was
to understand the diversity of the clusters regarding these
two facets. A low marketplace entropy for a given cluster
would mean its products were mainly found in a particular
marketplace. Similarly, low vendor entropy would mean the
cluster’s products were mainly sold by a particular vendor.
Table III presents the results.
As shown in Table III, Links holds the lowest entropy when
we analyzed the marketplaces, suggesting the great majority
of products come from the same market. In this cluster, 80%
of products came from only 2 markets. However, when we
check the vendor entropy for this same cluster, we can observe
a higher value, suggesting that many vendors are actually
offering products related to Links. It is possible that many
markets discourage the re-selling of lists of links, as much of
this information can be found on darkweb Wiki’s for free.
Similarly, Hacking Tools holds the lowest entropy for the
vendor criteria. This suggest that only a few vendors are
present in that cluster. Specifically, only 2 vendors author
416(50%) of this type of products. At first glance, this may be
surprising as this appears to be a very general group. However,
upon inspection of the contents, we find that many authors of
these products are actually organizations. These organizations
use similar language in their product description in an effort to
brand their wares. This could indicate the presence of hackingcollectives that author products as well as the limitations of our
text-based approach - which can potentially cluster products
branded in a similar fashion. We also note one of the most

TABLE II
K- MEANS E VALUATION (F IXED C ENTROIDS ).

Cosine
Euclidean

word(1,1)
0.986
0.986

word(1,2)
0.985
0.977

char(3,4)
0.986
0.976

char(3,5)
0.986
0.973

Cosine
Euclidean

0.075
0.224

0.079
0.110

0.067
0.153

0.067
0.156

Rand-index
char(3,6)
char(3,7)
0.986
0.985
0.973
0.974
Entropy
0.067
0.075
0.156
0.141

TABLE III
C LUSTERS E NTROPY.
Rank
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34

Cluster Name
Carding
PayPal-related
Cashing Credit Cards
PGP
Netflix-related
Hacking Tools - General
Dumps - General
Linux-related
Email Hacking Tools
Network Security Tools
Ebay-related
Amazon-related
Bitcoin
Links (Lists)
Banking
Point of Sale
VPN
Botnet
Hacking Groups Invitation
RATs
Browser-related
Physical Layer Hacking
Password Cracking
Smartphone - General
Wireless Hacking
Phishing
Exploit Kits
Viruses/Counter AntiVirus
Network Layer Hacking
RDP Servers
Android-related
Keyloggers
Windows-related
Facebook-related

No of
Products
1263
1103
867
865
846
825
749
561
547
539
472
456
443
422
384
375
272
257
251
249
249
237
230
223
222
218
218
210
205
191
156
143
119
119

No of
Markets
16
16
16
15
14
15
12
16
13
15
15
16
15
12
13
15
12
12
14
15
12
13
13
14
13
13
14
14
14
12
11
13
12
15

Market
Entropy
0.320
0.340
0.351
0.347
0.270
0.331
0.289
0.372
0.335
0.366
0.385
0.391
0.360
0.211
0.349
0.384
0.413
0.291
0.387
0.453
0.380
0.408
0.434
0.408
0.389
0.403
0.413
0.413
0.459
0.405
0.429
0.496
0.464
0.501

No of
Vendors
315
335
256
203
351
132
280
117
196
117
163
197
201
221
186
181
130
110
143
99
134
122
100
110
56
111
91
60
60
124
60
77
50
67

Vendor
Entropy
0.720
0.754
0.738
0.696
0.805
0.516
0.777
0.758
0.738
0.621
0.772
0.825
0.823
0.838
0.840
0.841
0.827
0.796
0.865
0.797
0.857
0.856
0.781
0.816
0.601
0.849
0.795
0.684
0.716
0.895
0.770
0.862
0.717
0.876

prominent vendor in this cluster was itself a marketplace which is also reflected in the low marketplace entropy.
In our analysis of the Facebook and Keylogger clusters, we
can see that they point to the other direction. They have high
values for both entropy, a clear sign about the diversity with
respect to both vendors and markets. For example, in cluster
Facebook, there were 119 products and 67 vendors, and the
most prolific vendor for this cluster authored only 8 products.
In the same cluster, products were also spread across 15
markets - and the most well-represented market was associated
with 30 products. This analysis also indicates widespread
prevalence of keyloggers - which is not surprising as it is
a well established hacking technique. However, observing the
similar trend for the Facebook cluster could be indicative of
an increase in demand for Facebook-directed social media
hacking products and information.
Conclusion and Future Work. In this paper, we conducted
an initial examination of malware products from 17 malicious hacker markets through unsupervised learning. Using
manually-labeled data, we studied the effect of feature vector
on cluster purity using text-based features. We then analyzed
the impurity of clusters in our corpus of over 8, 000 malicious

char(4,4)
0.985
0.975

char(4,5)
0.985
0.975

char(4,6)
0.984
0.977

char(4,7)
0.982
0.971

Random
0.933
0.933

0.072
0.134

0.079
0.134

0.088
0.137

0.088
0.175

0.423
0.423

hacking products with respect to vendor and marketplace, and
finally, we identified several interesting characteristics of how
the products were grouped. Currently, we are examining other
methods for grouping these products using matrix factorization
and supervised techniques. Additionally, we are studying the
underlying social network of vendors through relationships
based on similar product offerings.
Acknowledgments. Some of the authors were supported by the
Office of Naval Research (ONR) Neptune program, the Arizona State
University Global Security Initiative (ASU GSI), and CNPq-Brazil.

R EFERENCES
[1] R. Dingledine, N. Mathewson, and P. Syverson, “Tor: The Secondgeneration Onion Router,” in Proceedings of the 13th Conference on
USENIX Security Symposium - Volume 13, ser. SSYM’04. Berkeley,
CA, USA: USENIX Association, 2004, pp. 21–21.
[2] V. Ciancaglini, M. Balduzzi, R. McArdle, and M. Rösler, “Below the
Surface: Exploring the Deep Web,” 2015.
[3] N. Christin, “Traveling the silk road: A measurement analysis of a
large anonymous online marketplace,” in Proceedings of the 22Nd
International Conference on World Wide Web, ser. WWW ’13. New
York, NY, USA: ACM, 2013, pp. 213–224.
[4] J. Robertson, V. Paliath, J. Shakarian, A. Thart, and P. Shakarian,
“Data Driven Game Theoretic Cyber Threat Mitigation,” in Proc. 28th
Innovative Applications of Artificial Intelligence (IAAI-16), 2016.
[5] C. C. Yang, X. Tang, and X. Gong, “Identifying dark web clusters with
temporal coherence analysis,” in Intelligence and Security Informatics
(ISI), 2011 IEEE International Conference on, July 2011, pp. 167–172.
[6] V. Benjamin, W. Li, T. Holt, and H. Chen, “Exploring threats and
vulnerabilities in hacker web: Forums, irc and carding shops,” in
Intelligence and Security Informatics (ISI), 2015 IEEE International
Conference on, May 2015, pp. 85–90.
[7] M. Macdonald, R. Frank, J. Mei, and B. Monk, “Identifying digital
threats in a hacker web forum,” in Proceedings of the 2015 IEEE/ACM
International Conference on Advances in Social Networks Analysis and
Mining 2015, ser. ASONAM ’15. New York, NY, USA: ACM, 2015,
pp. 926–933.
[8] Z. Zhao, G.-J. Ahn, H. Hu, and D. Mahi, “SocialImpact: Systematic
Analysis of Underground Social Dynamics.” in ESORICS, ser. Lecture
Notes in Computer Science, S. Foresti, M. Yung, and F. Martinelli, Eds.,
vol. 7459. Springer, 2012, pp. 877–894.
[9] H. Chen, “Dark web: Exploring and mining the dark side of the
web,” in Intelligence and Security Informatics Conference (EISIC), 2011
European, Sept 2011, pp. 1–2.
[10] J. Shakarian, P. Shakarian, and A. Ruef, “Cyber attacks and public embarrassment: A survey of some notable hacks,” Elsevier SciTechConnect,
2015.
[11] P. Shakarian and J. Shakarian, “Socio-cultural modeling for cyber threat
actors,” in AAAI Workshop on Artificial Intelligence and Cyber Security
(AICS), 2016.
[12] J. Shakarian, A. Gunn, and P. Shakarian, “Exploring malicious hacker
forums,” in Cyber Deception: Building the Scientific Foundation, S. Jajodia, V. Subrahmanian, V. Swarup, and C. Wang, Eds. Springer, 2016.
[13] W. M. Rand, “Objective Criteria for the Evaluation of Clustering
Methods,” Journal of the American Statistical Association, vol. 66, no.
336, pp. 846–850, Dec. 1971.

A Non-Parametric Learning Approach to Identify
Online Human Trafficking
Hamidreza Alvari
and Paulo Shakarian

arXiv:1607.08691v2 [cs.LG] 2 Aug 2016

Arizona State University
Tempe, Arizona
Email: {halvari,shak}@asu.edu

Abstract—Human trafficking is among the most challenging
law enforcement problems which demands persistent fight against
from all over the globe. In this study, we leverage readily
available data from the website “Backpage”– used for classified
advertisement– to discern potential patterns of human trafficking
activities which manifest online and identify most likely trafficking related advertisements. Due to the lack of ground truth,
we rely on two human analysts –one human trafficking victim
survivor and one from law enforcement, for hand-labeling the
small portion of the crawled data. We then present a semisupervised learning approach that is trained on the available
labeled and unlabeled data and evaluated on unseen data with
further verification of experts.

I. I NTRODUCTION
Human trafficking has received increased national and societal concern over the past decade [1]. According to the
United Nation [2], human trafficking is defined as the modern
slavery or the trade of humans mostly for the purpose of
sexual exploiting and forced labor, via different improper ways
including force, fraud and deception. Human trafficking is
among the challenging problems facing the law enforcement–
it is difficult to identify victims and counter traffickers.
Before the advent of the Internet, pimps were under the risks
of being arrested by law enforcement, while advertising their
victims on the streets [3]. However, the move to the Internet,
has made it easier and less dangerous for both sex buyers and
sellers, especially for the pimps [4] as they no longer needed
to advertise on the streets. There are now plethora of websites
that host and provide sexual services, under categories of
escort, adult entertainment, massage services, etc., which help
pimps, traffickers and sex buyers (a.k.a. “johns”), maintain
their anonymity. Though some services such as Craiglist’s
adult section and myredbook.com were shut down recently,
still there are many websites such as Backpage.com that
provide such services and many new are frequently created.
Traffickers even use dating and social networking websites,
including Twitter, Facebook, Instagram and Tinder to reach
out to the johns and their other followers. Although Internet
has presented new trafficking related challenges for law enforcement, it has also provided readily and publicly available
rich source of information which could be gleaned from online
sex advertisements for fighting this crime [5].

J.E. Kelly Snyder
Find Me Group
Tempe, Arizona
Email: kelly@findmegroup.org

Although, the Internet is being used for many other activities
including attracting the victims, communicating with costumers and rating the escort services, here we only focus on the
online advertisements. In this study, we use data crawled from
the adult entertainment section of the website Backpage.com
and propose a non-parametric learning approach to identify the
most likely human trafficking related online advertisements out
of the escort advertisements. To the best of our knowledge,
this is the first study that employs both data mining and
semi-supervised machine learning techniques to identify the
potential human trafficking related advertisements given only
a small portion of labeled data. We thus make the following
contributions.
1) We collected real posts from the U.S. cities represented
on Backpage.com. The data was then preprocessed and
cleaned.
2) Based on the literature, we created different groups
of features that capture the characteristics of potential
human trafficking activities. The less likely human trafficking related posts were then filtered out using these
features.
3) Due to the lack of ground truth, we relied on human
analysts for hand-labeling small portion of the filtered
data.
4) We trained a semi-supervised learner on labeled and
unlabeled data and sent back the identified highly human trafficking related advertisements to the experts for
further verification. We then validated our approach on
unseen data with further verification of experts.
The rest of the paper is organized as follows. In Section II,
we briefly provide the background of the problem of human
trafficking. Next, we review the prior studies on human trafficking in Section III. Then in Section IV, we explain our data
preparation and feature extraction scheme. Our unsupervised
filtering and expert assisted labeling are explained in Sections
V and VI, respectively. We detail our non-parametric learning
approach in Sections VII. We conclude the paper by providing
future research directions in Section VIII.
II. BACKGROUND
The United States’ Trafficking Victim Protection Act of
2000 (TVPA 2000) [6], was the first U.S. legislation passed

against human trafficking. According to TVPA 2000, sex
trafficking is a severe form of trafficking, where force, fraud
or corecion are primary ways of inducing commercial sex
act. Human Trafficking is a crime against humanity and is
one of the most atrocious crimes of global magnitude. It is
a $150 billion industry of exploitation of children and young
adults, utilizing humans for forced labor and sex trafficking
worldwide. No country is immune and the problem is rapidly
growing with little to no law enforcement addressing the issue
and approximately 161 countries affected. Human trafficking
is considered to be a form of modern day slavery. Humans
are controlled, exploited, abused, forced into prostitution and
labor of servitude in some form and all under the threat of
punishment if they do not perform their required duties.
The Find Me Group (FMG) was founded by retired DEA
Special Agent Jerry “Kelly” Snyder in 2002 primarily to
locate missing persons. The natural evolution of the group
in locating missing persons was to allocate resources for
locating victims in human trafficking, as well as identifying
the persons responsible and reporting these organizations to
law enforcement. The FMG consists of current and retired
law enforcement agents and officers with a wide-range of
investigative expertise, including but not limited to linguistics,
handwriting analysis, body language, missing persons and
homicide. The search and rescue component of the FMG is
also comprised of current and retired law enforcement officers
and agents with 28 years of field management skills in locating
missing persons. The FMG has an additional advantage by
using trained experts/sources that provide detailed location
information of human trafficking victims.
The ultimate goal of the current project is to identify
missing persons which are connected to human trafficking
organizations. This can be done by identifying their locations,
utilizing logistical methodology with an additional focus on
their financial status and reporting assets to worldwide law
enforcement.
III. R ELATED W ORK
Recently, several studies have examined the role of the Internet and related technology in facilitating human trafficking[7],
[8], [9]. For example, the work of [7] studied how closely sex
trafficking is intertwined with new technologies. According
to [8], “The sexual exploitation of women and children is
a global human rights crisis that is being escalated by the
use of new technologies”. Researchers have studied the relationship between new technologies and human trafficking and
advantages of the Internet for sex traffickers. For instance,
according to [9], findings from a group of experts from the
Council of Europe demonstrate that the Internet and sex
industry are closely interlinked and the volume and content
of the material on the Internet promoting human trafficking
are unprecedented.
One of the earliest works which leveraged data mining
techniques for online human trafficking was [9], where the
authors conducted an analysis of data on the adult section
of the website Backpage.com. Their findings confirmed that

the female escort post frequency would increase in Dallas,
Texas, leading up to Super Bowl 2011 event. In a similar
attempt, other studies [10], [11] have investigated the impact
of large public events such as Super Bowl on sex trafficking
by exploring advertisement volume, trends and movement of
advertisements along with the scope and volume of demand
associated with such events. The work of [10], for instance,
concludes that in large events like Super Bowl which attract
significant amount of concentration of people in a relatively
short period of time and in a confined urban area, could be
a desirable location for sex traffickers to bring their victims
for commercial sexual exploitation. Similarly, the data-driven
approach of [11] shows that in some but not all events, one
can see a correlation between the occurrence of the event and
statistically significant evidence of an influx of sex trafficking
activity. Also, certain studies [12] have tried to build large
distributed systems to store and process the available online
human trafficking data in order to perform entity resolution
and create ontological relations between the entities.
Beyond these works, the work of [13], studied the problem
of isolating sources of human trafficking from online advertisements with a pairwise entity resolution approach. Specifically,
they trained a classifier to predict if two ads are from the
same source, using phone numbers as a strong feature. Then,
this classifier was used to perform entity resolution using a
heuristically learned value for the score of classifier. Another
work of [5] used Backpage.com data and extracted most likely
human trafficking spatio-temporal patterns with the help of law
enforcement. Note that unlike our method, this work did not
employ any machine learning methodologies for automatically
identifying the human trafficking related advertisements. The
work of [14] also used machine learning techniques by training
a supervised learning classifier on labeled data (based on the
phone numbers of known traffickers) provided by a victim
advocacy group, for the ad-classification problem. We note that
while phone numbers can provide very precise set of positive
labeled data, there are clearly many posts with previously
unseen phone numbers. In contrast, we do not solely rely on
the phone numbers for labeling the data. Instead, our experts
analyze the whole post’s content to identify whether it is
human trafficking related or not. Indeed, we first filter out
the most likely advertisements using several feature groups
and pass a small sample to the experts for hand-labeling.
Then, we train semi-supervised learner on both labeled and
unlabeled data which in turn let us evaluate our approach on
the new coming (unseen) data as well. We note that our semisupervised approach can also be used as a complementary
method to procedures such as those described in [14] as we can
significantly expand the training set for use with supervised
learning.
IV. DATA C OLLECTION E FFORT
We collected about 20K publicly available listings from
the U.S. posted on Backpage.com in March, 2016. Each post
includes a title, description, time stamp, the poster’s age,
poster’s ID, location, image, video and sometimes audio. The

description usually lists the attributes of the individual(s) and
contact phone numbers. In this work we only focus on the
textual component of the data. This free-text data required
significant cleaning due to a variety of issues common to
textual analytics (i.e. misspellings, format of phone numbers,
etc.). We also acknowledge that the information in data could
be intentionally inaccurate, such as the poster’s name, age and
even physical appearance (i.e. bra cup size, weight). Figure 1
shows an actual post from Backpage.com. To illustrate the
geographic diversity of the listings, we also plot the phone
distribution with respect to the different states in Figure 2.
Note that for brevity, we only show those with a frequency
greater than 5.
Fig. 1.

Fig. 3. An evidence of human trafficking. The boxes and numbers in red,
indicate the features and their corresponding group numbers (see also Table I).

A real post from Backpage.

TABLE I
D IFFERENT GROUPS OF FEATURES USED IN OUR WORK .
No.
1
2
3
4
5
6

Fig. 2.

Phone distribution by different states.

Feature Group
Advertisement Language Pattern
Words and Phrases of Interest
Countries of Interest
Multiple Victims Advertised
Victim Weight
Reference to Website or Spa Massage Therapy

Ref.
[5], [15], [16]
[17], [18], [19]
[1]
[5]
[6], [20]
[5]

for multiple escorts with the first individual coming from Asia
and very young. In the followings, we discuss such common
properties of human trafficking related advertisements, in more
details.
Inspired from literature, we define and extract 6 groups of
features from advertisements, shown in Table I, which could
be amongst the strong indicators of the human trafficking. In
what follows, we briefly describe each group of features used
in our work. Each feature listed is treated as a binary variable.
1) Advertisement Language Pattern: The first group consists of different language related features. For the first and
second features, we identify posts which has third person
language (more likely to be written by someone other than the
escort) and posts which contain first person plural pronouns
such as ‘we’ and ‘our’ (more likely to be an organization) [5].

Next, we explain the most important characteristics of
potential human trafficking advertisements captured by our
feature groups.
A. Feature Engineering
Though many advertisements on Backpage.com are posted
by posters selling their own services without coercion and
intervention of traffickers, some do exhibit many common
trafficking triggers. For example, in contrast to the previous advertisements, Figure 3 shows an advertisement that could be an
evidence of human trafficking. This advertisement has several
potential properties of human trafficking including advertising

To ensure their anonymity, traffickers would deploy techniques to generate diverse information and hence make their
posts look more complicated. They usually do this to avoid being identified by either human analyst or automated programs.
Thus, to obtain the third feature, we take an approach from
complexity theory, namely Kolmogorov complexity which is
defined as the length of the shortest program to reproduce the
advertisement content on a universal machine such as Turing
Machine [15]. We approximate the Kolmogorov complexity of
an advertisement’s content, by simply computing the Entropy
of the content [15] as follows. Let X denote the content and
xi be a given word in the content. We use the following

equation [21] to calculate the Entropy of the content.
H(X) = −

n
X

P (xi ) log2 P (xi )

evidence of human trafficking– this is described in the next
section.
(1)

i=1

We expect higher values of the Entropy correspond to
human trafficking. Finally, we discretize the result by using
the threshold of 4 which was found empirically in our experiments.
Next, we use word-level n-grams to find the common
language patterns of the advertisements, as the character-level
n-grams have already shown to be useful in detecting
unwanted content for Spam detection [16]. We set n = 4
and compute the normalized n-grams (using TF-IDF) of the
advertisement’s content and use threshold of 0.5 to binarize
their values. This gives us 6 more features to include into
our feature set. Overall, we have 9 features related to the
language of the advertisement.
2) Words and Phrases of Interest: Despite the fact that
advertisements on Backpage.com do not directly mention
sex with children, costumers who prefer children, know to
look for words and phrases such as “sweet, candy, fresh,
new in town, new to the game” [17], [18], [19]. We thus
investigate within the posts to see if they contain such words as
they could be highly related with human trafficking in general.

V. U NSUPERVISED F ILTERING
Having detailed our feature set, we now construct feature
vectors for each instance by creating a vector of 15 binary
features that correspond to the important characteristics of
human trafficking related posts.
We obtain 999 instances from our dataset by filtering out
samples that do not posses any of the binary features. We
will refer to this as our filtered dataset. In Figure 4, we
visualize 500 of the 999 samples and an additional 500
samples outside of the filtered dataset (i.e., from the remainder
of the samples) we studied in a 2-D projection (using the tSNE transformation [22]). We clustered the visualized samples
into 2 clusters (using K-means) and found the clusters to be
purely either inside or outside of the sampled data (100% of
samples in cluster 1 were from the identified listings and 100%
of samples in cluster 2 were from outside this group).
Fig. 4. Two clusters of a portion of the filtered data set combined with
random samples from the remainder of the samples, in the trasformed feature
space.

3) Countries of Interest: We identify if the individual
being escorted is coming from other countries such as those
in Southeast Asia (especially from China, Vietnam, Korea
and Thailand, as we observed in our data) [1].
4) Multiple Victims Advertised: Some advertisements
advertise for multiple women at the same time. We consider
the presence of more than one girl as a potential evidence of
organized human trafficking [5].
5) Victim Weight: We take into account weight of the
individual being escorted as a feature (if it is available).
This information is particularly useful assuming that for
the most part, lower body weights (under 110 lbs) correlate
with smaller and underage girls [6], [20] and thereby human
trafficking.
6) Reference to Website or Spa Massage Therapy: The
presence of a link in the advertisement, either referencing
to an outside website (especially infamous ones) or spa
massage therapy, could be an indicator of more elaborate
organization [5]. In case of spa therapy, we observed many
advertisements interrelated with advertising for young Asian
girls and their erotic massage abilities. Therefore, the last
group has two binary features for the presence of both website
and spa.
In order to extract these features, we first clean the original
data and conduct preprocessing. Then we draw 999 instances
out of our dataset for further analysis, as they might be

We then create a second feature space that is used through
the remainder of the paper. Using Latent Drichlet Allocation
(LDA) [23] topic modeling from Python package gensim [24],
we identify 25 most representative topics out of the filtered
dataset. This allows us to uncover the hidden thematic structure in the data. Further, we rely on the document-topic
distribution given by the LDA (here each document is seen as
a mixture of topics) to distinguish the normal advertisements
(outliers) from highly human trafficking related ones. More
specifically, we treat each listing in the filtered data as a vector
of 25 probabilistic values provided by LDA’s document-topic
distribution– this feature space is used in the next step.
Moreover, since we lack ground truth for our data, we rely
on human analysts (experts) for labeling the listings as either
human trafficking or not. In the next section, we select a
smaller yet finer grain subset of this data to be sent to the
experts. This alleviates the burden of the tedious work of handlabeling.

TABLE III
VALIDATED RESULTS ON UNLABELED DATA FOR BOTH KERNELS .

VI. E XPERT A SSISTED L ABELING
We first obtain a sample of 150 listings from the filtered
dataset. This set of listings was labeled by two human experts:
a previous human trafficking victim and a law enforcement
officer who specialized in this type of crime. From this subset,
a law enforcement professional and human trafficking victim
identified 38 and 139 instances (respectively) to be human
trafficking related instances. Among them, there were 31
records for which both experts agreed were highly related to
human trafficking. Thus, we now have 31 confirmed positive
samples, but still have large amounts of unlabeled examples
(849 instances) in our dataset. We summarize the data statistics
in Table II. Any sample for which at least one expert labeled
as negative, we treated as a negative sample.
TABLE II
D ESCRIPTION OF THE DATASET.
Name
Raw
Filtered
Unlabeled
Labeled
Positive
Negative

Expert 1
38
112

Value
20,822
999
849
Expert 2 Intersection
139
31
11
4

Name
Kernel
RBF (Union)
RBF (Intersection)
KNN (Union)
KNN (Intersection)

Positive
(Learner)
145
848
188
849

Value
Negative
Positive
(Learner) (Experts)
704
134
1
661
170
0
-

Precision
(Positive)
92.41%
90.42%
-

and 170 labels out of 145 and 188 positive instances and
achieved precision of 92.41% and 90.42%, respectively. We
further demonstrate the word clouds for the positive instances
assigned by RBF and KNN, in Figure 5 and Figure 6,
respectively.
Fig. 5.

Word cloud for the positive instances assigned by RBF.

Fig. 6.

Word cloud for the positive instances assigned by KNN.

Union
146
119

In the next section, we explain how we deploy a nonparametric learning approach to identify the labels of the rest
of the data to be sent for further expert verification.
VII. N ON -PARAMETRIC L EARNING
We use the Python package scikit-learn [25] for training
semi-supervised learner on the filtered dataset. There are
two label propagation semi-supervised (non-parametric) based
models in this package, namely, LabelPropagation and LabelSpreading [26]. These models rely on the geometry of
the data induced by both labeled and unlabeled instances as
opposed to the supervised models which only use the labeled
data [26]. This geometry is usually represented by a graph
G = (V, E), with the nodes V represent the training data
and edges E represent the similarity between them [26] in the
form of weight matrix W. Given the graph G, a basic approach
for semi-supervised learning is through propagating labels on
the graph [26]. Due to the higher performance achieved, we
chose to use LabelSpreading model. We conducted experiment
with the two built-in kernels radial basis function (RBF) and
K-nearest neighbor (KNN) in label propagation models and
report the results in Table III. Note that we only reported the
precision when 119 negative samples (labeled by either of the
experts) were used in the learning process. We did so because
of the reasonable number of the positive labels assigned by
either of the kernels in presence of these negative instances
(our experts had limited time to validate the labels of the data).
As we see from this table, out of 849 unlabeled data, our
learner with RBF and KNN kernels assigned positive labels
to the 145 and 188 instances, respectively. Next, we pass the
identified positive labels to the experts for further verification.
Our approach with RBF and KNN correctly identified 134

VIII. C ONCLUSION
Readily available online data from escort advertisements
could be leveraged in favor of fighting against the human
trafficking. In this study, having focused on textual information
from available data crawled from Backpage.com, we identified if an escort advertisement can be reflective of human
trafficking activities. More specifically, we first propose an
unsupervised filtering approach to filter out the data which
are more likely involved in trafficking. We then trained a

semi-supervised learner on small portion of such data, handlabeled by human trafficking experts, to identify the labels for
unseen data. The results suggest our non-parametric approach
is successful at identifying the potential human trafficking
related advertisements.
In future work we seek to extract the underlying network of
the data to find interesting patterns such as the most influential
nodes as they might indicate the known pimps and traffickers.
We would also like to replicate the study by integrating
more features, especially those supported by the criminology
literature.
ACKNOWLEDGMENT
This work was funded by the Find Me Group, a 501(c)3
dedicated to bring resolution and closure to families of missing
persons. https://www.findmegroup.org/
R EFERENCES
[1] “Trafficking in Persons Report,” July 2015.
[2] “UNODC on human trafficking and migrant smuggling,” 2011.
[3] C. Desplaces, “Police Run ‘Prostitution’ Sting; 19 Men Arrested,
Charged in Fourth East Dallas Operation.” Nov 1992.
[4] K. Nicholas D., “How Pimps Use the Web to Sell Girls.” Jan 2012.
[5] E. Kennedy, “Predictive patterns of sex trafficking online,” 2012.
[6] “Trafficking Victims Protection Act of 2000,” 2000.
[7] D. M. Hughes et al., “The demand for victims of sex trafficking,”
Womens Studies Program, University of Rhode Island, 2005.
[8] D. M. Hughes, “The Use of New Communications and Information
Technologies for Sexual Exploitation of Women and Children,” Hastings
Women’s Law Journal, vol. 13, no. 1, pp. 129–148, 2002.
[9] M. Latonero, “Human trafficking online: The role of social networking
sites and online classifieds,” Available at SSRN 2045851, 2011.
[10] D. Roe-Sepowitz, J. Gallagher, K. Bracy, L. Cantelme, A. Bayless,
J. Larkin, A. Reese, and L. Allbee, “Exploring the Impact of the Super
Bowl on Sex Trafficking,” Feb. 2015.
[11] K. Miller, E. Kennedy, and A. Dubrawski, “Do Public Events Affect
Sex Trafficking Activity?” ArXiv e-prints, Feb. 2016.
[12] P. A. Szekely, C. A. Knoblock, J. Slepicka, A. Philpot, A. Singh,
C. Yin, D. Kapoor, P. Natarajan, D. Marcu, K. Knight, D. Stallard, S. S.
Karunamoorthy, R. Bojanapalli, S. Minton, B. Amanatullah, T. Hughes,
M. Tamayo, D. Flynt, R. Artiss, S.-F. Chang, T. Chen, G. Hiebel, and
L. Ferreira, “Building and Using a Knowledge Graph to Combat Human
Trafficking.” in International Semantic Web Conference (2), ser. Lecture
Notes in Computer Science, vol. 9367. Springer, 2015, pp. 205–221.
[13] C. Nagpal, K. Miller, B. Boecking, and A. Dubrawski, “An Entity
Resolution approach to isolate instances of Human Trafficking online,”
ArXiv e-prints, Sep. 2015.
[14] A. Dubrawski, K. Miller, M. Barnes, B. Boecking, and E. Kennedy,
“Leveraging publicly available data to discern patterns of humantrafficking activity,” Journal of Human Trafficking, vol. 1, no. 1, pp.
65–85, 2015.
[15] M. Li and P. M. Vitnyi, An Introduction to Kolmogorov Complexity and
Its Applications, 3rd ed. Springer Publishing Company, Incorporated,
2008.
[16] I. Kanaris, K. Kanaris, and E. Stamatatos, “Spam Detection Using
Character N-Grams.” in SETN, ser. Lecture Notes in Computer Science,
vol. 3955. Springer, 2006, pp. 95–104.
[17] K. Hetter, “Fighting sex trafficking in hotels, one room at a time,” March
2012.
[18] R. Lloyd, “An Open Letter to Jim Buckmaster,” April 2012.
[19] J. Dickinson Goodman and M. Holmes, “Can We Use RSS to Catch
Rapists,” 2011.
[20] “Average Height to Weight Chart - Babies to Teenagers.”
[Online]. Available: http://www.disabled-world.com/artman/publish/
height-weight-teens.shtml
[21] C. E. Shannon, “A mathematical theory of communication,” ACM
SIGMOBILE Mobile Computing and Communications Review, vol. 5,
no. 1, pp. 3–55, 2001.

[22] L. van der Maaten and G. Hinton, “Visualizing High-Dimensional Data
Using t-SNE,” 2008.
[23] D. M. Blei, A. Y. Ng, and M. I. Jordan, “Latent dirichlet allocation,”
the Journal of machine Learning research, vol. 3, pp. 993–1022, 2003.
[24] R. Řehůřek and P. Sojka, “Software Framework for Topic Modelling
with Large Corpora,” in Proceedings of the LREC 2010 Workshop on
New Challenges for NLP Frameworks. Valletta, Malta: ELRA, May
2010, pp. 45–50, http://is.muni.cz/publication/884893/en.
[25] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, “Scikit-learn: Machine learning in Python,” Journal of Machine
Learning Research, vol. 12, pp. 2825–2830, 2011.
[26] Y. Bengio, O. Delalleau, and N. Le Roux, In Semi-Supervised Learning.
MIT Press, 2006.

A Non-Parametric Learning Approach to Identify
Online Human Trafficking
Hamidreza Alvari
and Paulo Shakarian

J.E. Kelly Snyder

Arizona State University

Tempe, Arizona

Tempe, Arizona

Email: kelly@findmegroup.org

Find Me Group

Email: {halvari,shak}@asu.edu

Abstract-Human trafficking is among the most challenging
law enforcement problems which demands persistent fight against
from all over the globe. In this study, we leverage readily
available data from the website "Backpage"- used for classified
advertisement- to discern potential patterns of human trafficking
activities which manifest online and identify most likely traffick­
ing related advertisements. Due to the lack of ground truth,
we rely on two human analysts- one human trafficking victim
survivor and one from law enforcement, for hand-labeling the
small portion of the crawled data. We then present a semi­
supervised learning approach that is trained on the available
labeled and unlabeled data and evaluated on unseen data with
further verification of experts.

I. INTRODUCTION

Although, the Internet is being used for many other activities
including attracting the victims, communicating with cos­
tumers and rating the escort services, here we only focus on the
online advertisements. In this study, we use data crawled from
the adult entertainment section of the website Backpage.com
and propose a non-parametric learning approach to identify the
most likely human trafficking related online advertisements out
of the escort advertisements. To the best of our knowledge,
this is the first study that employs both data mining and
semi-supervised machine learning techniques to identify the
potential human trafficking related advertisements given only
a small portion of labeled data. We thus make the following
contributions.
1) We collected real posts from the U.S. cities represented
on Backpage.com. The data was then preprocessed and
cleaned.
2) Based on the literature, we created different groups
of features that capture the characteristics of potential
human trafficking activities. The less likely human traf­
ficking related posts were then filtered out using these
features.
3) Due to the lack of ground truth, we relied on human
analysts for hand-labeling small portion of the filtered
data.
4) We trained a semi-supervised learner on labeled and
unlabeled data and sent back the identified highly hu­
man trafficking related advertisements to the experts for
further verification. We then validated our approach on
unseen data with further verification of experts.

Human trafficking has received increased national and so­
cietal concern over the past decade [1]. According to the
United Nation [2], human trafficking is defined as the modern
slavery or the trade of humans mostly for the purpose of
sexual exploiting and forced labor, via different improper ways
including force, fraud and deception. Human trafficking is
among the challenging problems facing the law enforcement­
it is difficult to identify victims and counter traffickers.
Before the advent of the Internet, pimps were under the risks
of being arrested by law enforcement, while advertising their
victims on the streets [3]. However, the move to the Internet,
has made it easier and less dangerous for both sex buyers and
sellers, especially for the pimps [4] as they no longer needed
to advertise on the streets. There are now plethora of websites
that host and provide sexual services, under categories of
escort, adult entertainment, massage services, etc., which help
pimps, traffickers and sex buyers (a.k.a. "johns"), maintain
their anonymity. Though some services such as Craiglist's
adult section and myredbook.com were shut down recently,
still there are many websites such as Backpage.com that
provide such services and many new are frequently created.
Traffickers even use dating and social networking websites,
including Twitter, Facebook, Instagram and Tinder to reach
out to the johns and their other followers. Although Internet
has presented new trafficking related challenges for law en­
forcement, it has also provided readily and publicly available
rich source of information which could be gleaned from online
sex advertisements for fighting this crime [5].

978-1-5090-3865-7/16/$31.00 ©20 16 IEEE

The rest of the paper is organized as follows. In Section II,
we briefly provide the background of the problem of human
trafficking. Next, we review the prior studies on human traf­
ficking in Section III. Then in Section IV, we explain our data
preparation and feature extraction scheme. Our unsupervised
filtering and expert assisted labeling are explained in Sections
V and VI, respectively. We detail our non-parametric learning
approach in Sections VII. We conclude the paper by providing
future research directions in Section VIII.
II. BACKGROUND
The United States' Trafficking Victim Protection Act of
2000 (TVPA 2000) [6], was the first U.S. legislation passed

133

against human trafficking. According to TVPA 2000, sex
trafficking is a severe form of trafficking, where force, fraud
or corecion are primary ways of inducing commercial sex
act. Human Trafficking is a crime against humanity and is
one of the most atrocious crimes of global magnitude. It is
a $150 billion industry of exploitation of children and young
adults, utilizing humans for forced labor and sex trafficking
worldwide. No country is immune and the problem is rapidly
growing with little to no law enforcement addressing the issue
and approximately 161 countries affected. Human trafficking
is considered to be a form of modern day slavery. Humans
are controlled, exploited, abused, forced into prostitution and
labor of servitude in some form and all under the threat of
punishment if they do not perform their required duties.
The Find Me Group (FMG) was founded by retired DEA
Special Agent Jerry "Kelly" Snyder in 2002 primarily to
locate missing persons. The natural evolution of the group
in locating missing persons was to allocate resources for
locating victims in human trafficking, as well as identifying
the persons responsible and reporting these organizations to
law enforcement. The FMG consists of current and retired
law enforcement agents and officers with a wide-range of
investigative expertise, including but not limited to linguistics,
handwriting analysis, body language, missing persons and
homicide. The search and rescue component of the FMG is
also comprised of current and retired law enforcement officers
and agents with 28 years of field management skills in locating
missing persons. The FMG has an additional advantage by
using trained experts/sources that provide detailed location
information of human trafficking victims.
The ultimate goal of the current project is to identify
missing persons which are connected to human trafficking
organizations. This can be done by identifying their locations,
utilizing logistical methodology with an additional focus on
their financial status and reporting assets to worldwide law
enforcement.
III. RELATED W ORK
Recently, several studies have examined the role of the Inter­
net and related technology in facilitating human trafficking[7],
[8], [9]. For example, the work of [7] studied how closely sex
trafficking is intertwined with new technologies. According
to [8], "The sexual exploitation of women and children is
a global human rights crisis that is being escalated by the
use of new technologies". Researchers have studied the rela­
tionship between new technologies and human trafficking and
advantages of the Internet for sex traffickers. For instance,
according to [9], findings from a group of experts from the
Council of Europe demonstrate that the Internet and sex
industry are closely interlinked and the volume and content
of the material on the Internet promoting human trafficking
are unprecedented.
One of the earliest works which leveraged data mining
techniques for online human trafficking was [9], where the
authors conducted an analysis of data on the adult section
of the website Backpage.com. Their findings confirmed that

the female escort post frequency would increase in Dallas,
Texas, leading up to Super Bowl 2011 event. In a similar
attempt, other studies [10], [11] have investigated the impact
of large public events such as Super Bowl on sex trafficking
by exploring advertisement volume, trends and movement of
advertisements along with the scope and volume of demand
associated with such events. The work of [10], for instance,
concludes that in large events like Super Bowl which attract
significant amount of concentration of people in a relatively
short period of time and in a confined urban area, could be
a desirable location for sex traffickers to bring their victims
for commercial sexual exploitation. Similarly, the data-driven
approach of [11] shows that in some but not all events, one
can see a correlation between the occurrence of the event and
statistically significant evidence of an inftux of sex trafficking
activity. Also, certain studies [12] have tried to build large
distributed systems to store and process the available online
human trafficking data in order to perform entity resolution
and create ontological relations between the entities.
Beyond these works, the work of [13], studied the problem
of isolating sources of human trafficking from online advertise­
ments with a pairwise entity resolution approach. Specifically,
they trained a classifier to predict if two ads are from the
same source, using phone numbers as a strong feature. Then,
this classifier was used to perform entity resolution using a
heuristically learned value for the score of classifier. Another
work of [5] used Backpage.com data and extracted most likely
human trafficking spatio-temporal patterns with the help of law
enforcement. Note that unlike our method, this work did not
employ any machine learning methodologies for automatically
identifying the human trafficking related advertisements. The
work of [14] also used machine learning techniques by training
a supervised learning classifier on labeled data (based on the
phone numbers of known traffickers) provided by a victim
advocacy group, for the ad-classification problem. We note that
while phone numbers can provide very precise set of positive
labeled data, there are clearly many posts with previously
unseen phone numbers. In contrast, we do not solely rely on
the phone numbers for labeling the data. Instead, our experts
analyze the whole post's content to identify whether it is
human trafficking related or not. Indeed, we first filter out
the most likely advertisements using several feature groups
and pass a small sample to the experts for hand-labeling.
Then, we train a semi-supervised learner on both labeled and
unlabeled data which in turn lets us evaluate our approach on
the new coming (unseen) data as well. We note that our semi­
supervised approach can also be used as a complementary
method to procedures such as those described in [14] as we can
significantly expand the training set for use with supervised
learning.
IV. DATA COLLECTION E FFORT
We collected about 20K publicly available listings from
the U.S. posted on Backpage.com in March, 2016. Each post
includes a title, description, time stamp, the poster's age,
poster's ID, location, image, and sometimes video and audio.

134

The description usually
usually lists
lists the
the attributes
attributes of
of the
the individual(s)
individual(s)
and contact phone numbers. In
In this work we only focus on
the textual component of the data. This free-text data required
to aa variety
variety of
of issues
issues common
common to
to
significant cleaning due to
significant
textual analytics (i.e.
of phone
phone numbers,
numbers,
textual
(i.e. misspellings, format of
that the
the information in
in data
data could
could
etc.). We also acknowledge that
as the
the poster's
poster's name,
name, age
age and
and
be intentionally
intentionally inaccurate,
inaccurate, such
such as
be
even physical appearance (i.e. bra cup size, weight). Figure 1
an actual
actual post from Backpage.com. To
To illustrate
illustrate the
the
shows an
shows
of the
the listings,
listings, we
we also
also plot the
the phone
geographic diversity of
to the
the different states
states in
in Figure
Figure 2.
2.
distribution with
with respect to
Note that for brevity, we only show those with a frequency
greater than
than 5.

Fig. 3. An evidence of human trafficking. The boxes and numbers in red,
features and their corresponding group numbers (see also Table I).
indicate the features

New ... "'100%REAL PIC • • • • • • • • • • Japanese

Posted: Saturday, April 23, 2016 1:23 AM

CD
EVERYTHING REQUIRED TO FULFILL YOUR DESIRE

!22% YOUNG !2!l% SEXY !22% REAL PIC ...

2417 OUTCALL ON LY
Never RUSh , Amazing Serv ices

_-=-"-:-::--.

Don't play games, Don't waste a nyo nes' time".
Ca ll us to mee\~ F Un, Natural Super Cute, papanese & Koreanl GirlsOut Ca ll Service.
CA LL : 212.300.
Service Lo cation : Manhatta n •
• •••••••••••••
Poster's age: 21

Fig.
I. A
real
Fig.
from
Fig. 1.
1.
A real
real post
post from
from Backpage.
Backpage.

NEW t:; Upscale Barbie In Town (0 IN & Outcalls

Posted: Thursday, April 28, 20 16 11:10 PM

*-

• Local km: Manhattan.
• Post 1D:_

21

CD
i' -all

Group
I No.
No. I Feature
Feature Group

1m !l!!!percent real
Come let me pamper you as much as you need orwa nte '
1m 5'7 135 POUndS at pure pleasure fj)Q
From the moment we meet you will no im the one you have
IJ)~AIways discreet, clean, and on time.

420 & party

I I I I II I I III I I

TABLE I
DIFFERENT GROUPS
GROUPS OF
OF FEAT
URES USED
US ED IN
IN OUR
OUR WORK.
WORK.
DIFFERENT
FEATURES

Hello Gentlemen .
My name

~~i m

Oul Ca ll Only I

newyo rk

1I
2

beenPiiiv For.

3
4
5
6

So dont bullshit or lowba ll J ~o

friendry.~-.!l

~~NO POLICEIANPI M PS~ ~...

Give me a call o r 832_996 • • • •

Advertisement Language Pattern
Words and Phrases of Interest
Countries of Interest
Multiple Victims
Victim s Advertised
Multiple
Victim Weight
Victim
Massage Therapy
Reference to Website or Spa Massage

Ref.
Ref.

[5], [15]
[15],, [16]
[17], [18], [19]
[I]
[1]
[5]
[6], [20]
[5]

Poster's age: 2 1
• location: Hillsborough co, • • • • • • • • • • • • • • • • • • • •

. Post 10 : _

ampa
t

for multiple
multiple escorts
escorts with
with the
the first
first individual
individual coming
coming from
from Asia
In the
the followings,
followings, we
we discuss
discuss such
such common
common
and very
very young.
young. In
and
of human
human trafficking
trafficking related
related advertisements,
advertisements, in
in more
more
properties of
properties
details.
details.
we define
define and
and extract
extract 66 groups
groups of
of
Inspired from literature,
literature, we
Inspired
features from advertisements,
advertisements, shown
shown in
in Table
Table I,
I, which
which could
could
In
be amongst
amongst the
the strong
strong indicators
indicators of
of the
the human
human trafficking.
trafficking. In
be
what follows, we
we briefly
briefly describe each
each group
group of
of features used
used
what
in our
our work.
work. Each
Each feature
feature listed
listed is
is treated
treated as
as aa binary
binary variable.
variable.
in

Fig. 2.
2. Phone distribution by different states.

1)
Advertisement Language
Language Pattern:
Pattern: The
The first
first group
group con­
con1) Advertisement
sists of
of different
different language
language related
related features.
features. For
For the
the first
first and
and
sists
second features,
features, we
we identify
identify posts
posts which
which has
has third
third person
person
second
to be
be written
written by
by someone
someone other
other than
than the
the
language (more likely
likely to
language
escort) and
and posts
posts which
which contain
contain first
first person
person plural
plural pronouns
pronouns
escort)
as 'we' and
and 'our' (more likely
likely to
to be
be an
an organization)
organization) [5].
such as
such
Next, we explain the
the most
most important
important characteristics
characteristics of
of
potential human
human trafficking
trafficking advertisements
advertisements captured
captured by
by our
our
feature groups.
A.
A. Feature
Feature Engineering
Engineering

Though many advertisements
advertisements on
on Backpage.com are
are posted
posted
by posters selling
selling their
their own
own services without
without coercion and
and
by
intervention
of traffickers,
some do
do exhibit
exhibit many
many common
intervention of
traffickers, some
common
to the
the previous ad­
adtrafficking triggers.
triggers. For
For example, in
in contrast
contrast to
trafficking
an advertisement
advertisement that
that could
could be
be an
an
vertisement, Figure
Figure 3
3 shows
shows an
vertisement,
evidence of
of human
human trafficking.
trafficking. This
This advertisement
advertisement has
has several
several
potential properties of
of human trafficking
trafficking including
including advertising
advertising

To ensure
ensure their
their anonymity,
anonymity, traffickers
traffickers would
would deploy
deploy tech­
techTo
to generate
generate diverse
diverse information
information and
and hence
hence make
make their
their
niques to
niques
posts look
look more
more complicated.
complicated. They
They usually
usually do
do this
this to
to avoid
avoid be­
beposts
by either
either human
human analyst
analyst or
or automated
automated programs.
programs.
ing identified
identified by
ing
to obtain
obtain the
the third
third feature, we
we take
take an
an approach
approach from
from
Thus, to
Thus,
Kolmogorov complexity
which is
is
complexity theory,
theory, namely
namely Kolmogorov
complexity
complexity which
defined as
as the
the length
length of
of the
the shortest program to
to reproduce
reproduce the
the
advertisement content on a universal machine such as Turing
approximate the
the Kolmogorov
Kolmogorov complexity
complexity of
of
Machine [15]. We approximate
Machine
an advertisement's
advertisement's content,
content, by
by simply
simply computing
computing the
the Entropy
Entropy
an
as follows. Let
Let X
X denote
denote the
the content
content and
and
of the
the content
content [15] as
of
Xi be
be aa given
given word
word in
in the
the content.
content. We
We use
use the
the following
following

135
135

evidence of human trafficking- this is described in the next
section.

equation [21] to calculate the Entropy of the content.
n

H(X)

=

-

L P(Xi) log2 P(Xi)

i=l

(1)

We expect higher values of the Entropy correspond to
human trafficking. Finally, we discretize the result by using
the threshold of 4 which was found empirically in our exper­
iments.
Next, we use word-level n-grams to find the common
language patterns of the advertisements, as the character-level
n-grams have already shown to be useful in detecting
unwanted content for Spam detection [16]. We set n
4
and compute the normalized n-grams (using TF-IDF) of the
advertisement's content and use threshold of 0.5 to binarize
their values. This gives us 6 more features to include into
our feature set. Overall, we have 9 features related to the
language of the advertisement.
=

2) Words and Phrases of Interest: Despite the fact that
advertisements on Backpage.com do not directly mention
sex with children, costumers who prefer children, know to
look for words and phrases such as "sweet, candy, fresh,
new in town, new to the game" [17], [18], [19]. We thus
investigate within the posts to see if they contain such words as
they could be highly related with human trafficking in general.

V. UNSUPERV ISED FILTERING
Having detailed our feature set, we now construct feature
vectors for each instance by creating a vector of 15 binary
features that correspond to the important characteristics of
human trafficking related posts.
We obtain 999 instances from our dataset by filtering out
samples that do not posses any of the binary features. We
will refer to this as our filtered dataset. In Figure 4, we
visualize 500 of the 999 samples and an additional 500
samples outside of the filtered dataset (i.e., from the remainder
of the samples) we studied in a 2-D projection (using the t­
SNE transformation [22]). We clustered the visualized samples
into 2 clusters (using K-means) and found the clusters to be
purely either inside or outside of the sampled data (100% of
samples in cluster 1 were from the identified listings and 100%
of samples in cluster 2 were from outside this group).

Fig. 4. Two clusters of a portion of the filtered data set combined with random
samples from the remainder of the samples, in the trasformed feature space.

3) Countries of Interest: We identify if the individual
being escorted is coming from other countries such as those
in Southeast Asia (especially from China, Vietnam, Korea
and Thailand, as we observed in our data) [1].
4) Multiple Victims Advertised: Some advertisements
advertise for multiple women at the same time. We consider
the presence of more than one girl as a potential evidence of
organized human trafficking [5].
5) Victim Weight: We take into account weight of the
individual being escorted as a feature (if it is available).
This information is particularly useful assuming that for
the most part, lower body weights (under 110 lbs) correlate
with smaller and underage girls [6], [20] and thereby human
trafficking.
6) Reference to Website or Spa Massage Therapy: The
presence of a link in the advertisement, either referencing
to an outside website (especially infamous ones) or spa
massage therapy, could be an indicator of more elaborate
organization [5]. In case of spa therapy, we observed many
advertisements interrelated with advertising for young Asian
girls and their erotic massage abilities. Therefore, the last
group has two binary features for the presence of both website
and spa.
In order to extract these features, we first clean the original
data and conduct preprocessing. Then we draw 999 instances
out of our dataset for further analysis, as they might be

We then create a second feature space that is used through
the remainder of the paper. Using Latent Drichlet Allocation
(LDA) [23] topic modeling from Python package gensim [24],
we identify 25 most representative topics out of the filtered
dataset. This allows us to uncover the hidden thematic struc­
ture in the data. Further, we rely on the document-topic
distribution given by the LDA (here each document is seen as
a mixture of topics) to distinguish the normal advertisements
(outliers) from highly human trafficking related ones. More
specifically, we treat each listing in the filtered data as a vector
of 25 probabilistic values provided by LDA's document-topic
distribution- this feature space is used in the next step.
Moreover, since we lack ground truth for our data, we rely
on human analysts (experts) for labeling the listings as either
human trafficking or not. In the next section, we select a
smaller yet finer grain subset of this data to be sent to the
experts. This alleviates the burden of the tedious work of hand­
labeling.

136

VI. EXPERT ASSISTED LABELING
We first
first obtain a sample of 150
150 listings from
from the filtered
dataset. This set of listings was labeled by two human experts:
a previous human trafficking victim and a law enforcement
officer who specialized in this type of crime. From this subset,
a law enforcement professional and human trafficking victim
139 instances (respectively) to be human
identified 38 and 139
31
trafficking related instances. Among them, there were 31
records for which both experts agreed were highly related to
31 confirmed positive
human trafficking. Thus, we now have 31
samples, but still have large amounts of unlabeled examples
(849 instances) in our dataset. We summarize the data statistics
in Table II. Any sample for which at least one expert labeled
as negative, we treated as aa negative sample.

TABLE III
VALIDATED
ATA FO
FOR
V ALIDATE D RESULTS
R ESULT S ON
O N UNLABELED
UNLABELED D
DATA
R BOTH
B OT H KERNELS.
KER NELS .

Name
Name
Kernel
Kernel
REF (Union)
RB F (Intersection)
RBF
KNN (Union)
KNN
KNN (Intersection)
KNN

TABLE II
TABLE

Name
Name

Expert 1I
38
112
112

II

II

II

Positive
(Experts)
134
134

-

Precision
(Positive)
92.41
92.41 %
%

-

-

170
170

90.42%
90.42%

-

-

-

-

RBF.
Fig. 5. Word cloud for the positive instances assigned by RBF.

Value
Value
20,822
999
849
Expert 2 II Intersection
139
2l.
II
II
4
11

Negative
Negative
(Learner)
704
1I
661
0

145 and 188 positive instances and
and 170 labels out of 145
92.41 % and 90.42%,
90.42%, respectively. We
achieved precision of 92.41
further demonstrate the word clouds for the positive instances
REF and KNN, in Figure 5
5 and Figure 6,
6,
assigned by RBF
respectively.

D
E SCR IPT IO N OF
O F THE
T HED
DATAS
ET.
DESCRIPTION
ATASET.

Raw
Filtered
Unlabeled
Labeled
Positive
Negative

Value
Value
Positive
(Learner)
145
145
848
188
188
849

table

new asian ~~~?~~~I

south

II Union

II

mi nd

pm

massage

every proffess ionai treatment come

deep s ta ff best young "

bod y day private building service
dry sun girl signs to uch room

neon

sexy

b ehind stress real more all

ave
rd

sort h r
acupressure friendly full treatments
town today oi l l ei vip busty s.c leI sweet
am/p m li ght pa smi le now he re week go lOp .

146
119
ill

days

http://www. re laxo lgy.com givc ri ght sauna c ~lck
plcuse r~ l axing discreet, cash , re lax girl s tissue
am- l ~p.m ready clean parkm g orlental
a~d luon al rand professional free
o pemng o n ly s~ed ish call hot rooms
manage ment
ex perience www .relaxolgy .com
.

we explain
explain how we deploy a non­
nonIn the next section, we
parametric learning approach to identify the labels of the rest
of the data to be sent for further expert verification.

spa

complex ~~ii~~~lfi~~

shower

open

- PARAMETRIC LEARNING
VII. NON
NON-PARAMETRIC
We use the Python
Python package scikit-learn
training
scikit-learn [25]
[25] for trammg
semi-supervised learner on the filtered dataset. There are
two label propagation semi-supervised (non-parametric) based
models in this package, namely, LabelPropagation and LaLa­
belSpreading [26].
[26]. These models rely on the geometry of
the data induced by both labeled and unlabeled instances as
models which
which only use the labeled
opposed to the supervised models
data [26].
[26]. This geometry is usually represented by a graph
G
G = (V,
(V, E),
E), with the nodes V
V represent the training data
and edges E
E represent the similarity between them [26] in the
form of weight matrix W.
basic approach
W. Given the graph G, a basic
for semi-supervised learning is through propagating labels on
the graph [26].
[26]. Due to the higher performance achieved, we
chose to use LabelSpreading model. We conducted experiment
function (RBF) and
with the two built-in kernels radial basis function
K-nearest neighbor (KNN) in label propagation models and
report the results in Table III. Note that we only reported the
precision when 119
119 negative samples (labeled by either of the
experts) were used in the learning process. We did so because
of the reasonable number of the positive labels assigned by
either of the kernels in presence of these negative instances
(our experts had limited time to validate the labels of the data).
As we see from
from this table, out of 849 unlabeled data, our
learner with RBF
REF and KNN kernels assigned positive labels
145 and 188
188 instances, respectively. Next, we pass the
to the 145
identified positive labels to the experts for further verification.
Our approach with RB
F and KNN correctly identified 134
RBF

Fig. 6. Word cloud for the positive instances assigned by KNN.
KNN.
located relaxation comfortable

please . respectful spa

open

serious ddappottnmenl hour gIve
shower
maine caucasIan
free here
now
welcome
hot day smile every
rea d Y b 'f I
eautl
u
call
best
ooms
r..
v ip ooking
l
fun make
nice ge ntle m a n

aSl" an

Iove gir l mos t

calls/lext treatment

tissue

sexy

.
grand real relax week
green service
sauna ave one youn cr right full come s t lime eyes
friendly
enJ.oy all hr sofi clean
.
mature dee'"p ler
parking
south sIgns
dsweet
today . party days
auburn r
half managemenl staff click touch body
only m .
"
cash
p discreet
private
dish pIay re IaXing
·
stress
always more thick swe
female

=

gIfls

new ex;~~!~ce massage
VIII . CONCL
USION
VIII.
CONCLUSION

Readily available online data from
from escort advertisements
could be leveraged in favor of fighting against the human
In this study, having focused on textual information
trafficking. In
idenfrom available data crawled from Backpage.com, we iden­
tified if an escort advertisement can be reflective of human
trafficking activities. More specifically, we first propose an
unsupervised filtering approach to filter out the data which
are more likely involved in trafficking. We then trained a

137
137

semi-supervised learner on small portion of such data, hand­
labeled by human trafficking experts, to identify the labels for
unseen data. The results suggest our non-parametric approach
is successful at identifying the potential human trafficking
related advertisements.
In future work we seek to extract the underlying network of
the data to find interesting patterns such as the most influential
nodes as they might indicate the known pimps and traffickers.
We would also like to replicate the study by integrating
more features, especially those supported by the criminology
literature.

[22] L. van der Maaten and G. Hinton, "Visualizing High-Dimensional Data
Using t-SNE," 2008.
[23] D. M. Blei, A. Y. Ng, and M. I. Jordan, "Latent dirichlet allocation;'
the Journal of machine Learning research, vol. 3, pp. 993-1022, 2003.
[24] R. Rehurek and P. Sojka, "Software Framework for Topic Modelling
with Large Corpora;' in Proceedings of the LREC 2010 Workshop on
New Challenges for NLP Frameworks.
Valletta, Malta: ELRA, May
2010, pp. 4S-S0, http://is.muni.cz/publication/884893/en.
[2S] F. Pedregosa, G. Varoquaux, A. Gramfort, Y. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, Y. Dubourg, J. Vander­
plas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duch­
esnay, "Scikit-learn: Machine learning in Python," Journal of Machine
Learning Research, vol. 12, pp. 282S-2830, 2011.
[26] Y. Bengio, O. Delalleau, and N. Le Roux, In Semi-Supervised Learning.
MIT Press, 2006.

ACKNOW LEDGMENT

This work was funded by the Find Me Group, a SOI(c)3
dedicated to bring resolution and closure to families of missing
persons. https://www.findmegroup.org/
REFERENCES
[ I ] "Trafficking in Persons Report;' July 201S.
[2] "UNODC on human trafficking and migrant smuggling;' 2011.
[3] c. Desplaces, "Police Run 'Prostitution' Sting; 19 Men Arrested,
Charged in Fourth East Dallas Operation." Nov 1992.
[4] K. Nicholas D., "How Pimps Use the Web to Sell Girls." Jan 2012.
[S] E. Kennedy, "Predictive patterns of sex trafficking online," 2012.
[6] "Trafficking Victims Protection Act of 2000," 2000.
[7] D. M. Hughes et aI., "The demand for victims of sex trafficking,"
Womens Studies Program. University of Rhode Island, 200S.
[8] D. M. Hughes, "The Use of New Communications and Infonnation
Technologies for Sexual Exploitation of Women and Children;' Hastings
Women's Law Journal, vol. 13, no. 1, pp. 129-148, 2002.
[9] M. Latonero, "Human trafficking online: The role of social networking
sites and online classifieds;' Available at SSRN 2045851, 20 I I .
[10] D. Roe-Sepowitz, J. Gallagher, K. Bracy, L. Cantelme, A. Bayless,
J. Larkin, A. Reese, and L. Allbee, "Exploring the Impact of the Super
Bowl on Sex Trafficking;' Feb. 20 I S.
[ I I ] K. Miller, E. Kennedy, and A. Dubrawski, "Do Public Events Affect
Sex Trafficking Activity?" ArXiv e-prints, Feb. 2016.
[12] P. A. Szekely, C. A. Knoblock, J. Slepicka, A. Philpot, A. Singh,
C. Yin, D. Kapoor, P. Natarajan, D. Marcu, K. Knight, D. Stallard, S. S.
Karunamoorthy, R. Bojanapalli, S. Minton, B. Amanatullah, T. Hughes,
M. Tamayo, D. Flynt, R. Artiss, S.-F. Chang, T. Chen, G. Hiebel, and
L. Ferreira, "Building and Using a Knowledge Graph to Combat Human
Trafficking." in International Semantic Web Conference (2), ser. Lecture
Notes in Computer Science, vol. 9367. Springer, 20 IS, pp. 20S-221.
[13] c. Nagpal, K. Miller, B. Boecking, and A. Dubrawski, "An Entity
Resolution approach to isolate instances of Human Trafficking online;'
ArXiv e-prints, Sep. 201S.
[14] A. Dubrawski, K. Miller, M. Barnes, B. Boecking, and E. Kennedy,
"Leveraging publicly available data to discern patterns of human­
trafficking activity," Journal of Human Trafficking, vol. I, no. I, pp.
6S-8S, 201S.
[ I S] M. Li and P. M. Vitnyi, An Introduction to Kolmogorov Complexity and
Its Applications, 3rd ed. Springer Publishing Company, Incorporated,
2008.
[16] I. Kanaris, K. Kanaris, and E. Stamatatos, "Spam Detection Using
Character N-Grams." in SETN, ser. Lecture Notes in Computer Science,
vol. 39SS. Springer, 2006, pp. 9S-104.
[17] K. Hetter, "Fighting sex trafficking in hotels, one room at a time," March
2012.
[18] R. Lloyd, "An Open Letter to Jim Buckmaster;' April 2012.
[19] J. Dickinson Goodman and M. Holmes, "Can We Use RSS to Catch
Rapists," 2011.
[20] "Average Height to Weight Chart - Babies to Teenagers." [On­
line]. Available: http://www.disabled-world.com/artmanlpublishlheight­
weight-teens.shtml
[21] C. E. Shannon, "A mathematical theory of communication," ACM
SIGMOBILE Mobile Computing and Communications Review, vol. S,
no. I, pp. 3-SS, 2001.

138

The Workshops of the Thirtieth AAAI Conference on Artificial Intelligence
Artificial Intelligence for Cyber Security: Technical Report WS-16-03

Socio-Cultural Modeling for Cyber Threat Actors
Paulo Shakarian and Jana Shakarian
Arizona State University
{shak, jshak}@asu.edu

er communities combined with the goal of automating the
collection and analysis of information about the activity of
cyber threat actors produces some very unique challenges.
In this position paper, we describe some unique characteristics of cyber threat socio-cultural environments and several challenging modeling problems for which various artificial intelligence techniques can be used to help solve.

Abstract
In this paper we describe the unique challenges to the important problem of socio-cultural modeling of cyber-threat
actors and why they necessitate further advances in artificial
intelligence – particularly with regard to interdisciplinary
efforts with the social sciences.

Introduction
Cyber security is often referred to as “offense dominant”
referring to the notion that the domain generally favors the
attacker (Lynn, 2010). The reasoning behind this is simple:
a successful defense requires total control over all pathways to a system while a successful attack requires only
one. As a result, any given cyber-defense based on the
hardening of systems will fall prey to a cyber-attack as
perpetrators gain knowledge and resources. Solutions have
ranged from sophisticated adaptive defense strategies to
offensive cyber-operations directed against malicious
hackers. However, these methods have various technical
shortcomings – which range from the technical immaturity
of adaptive defenses to consequences of aggressive cyber
counter-operations which can lead to undesirable effects
such as preemptive and preventative cyber war.
A recent trend in the cybersecurity industry has been a
move toward “threat intelligence” where various sources of
information about potential cyber-attackers are explored
with the goal of pre-empting cyber-attacks before they occur. A key source of cyber-threat intelligence lies in the
digital communities of the malicious hackers – a collection
of sites, markets, chatrooms, and social media channels
where information is shared, hackers are recruited, and the
latest malware and exploits are bought and sold. While
artificial intelligence and machine learning techniques for
analyzing communities on the Internet are long-established
across specialty areas such as data mining, information
retrieval, and web science, we argue that the study of hack-

Characteristics of Cyber Threat
Socio-Cultural Environments
In our group, we have studied hacker communities from a
qualitative standpoint (Shakarian, Shakarian, and Ruef
2015). Throughout this research, we have noted several
unique characteristics in the online socio-cultural environments frequented by malicious hackers that make these
communities distinct from other groups. Some of these
characteristics include the following.
• Bounded anonymity. Individuals participating in the
malicious hacker community online make efforts to
hide their identity. Some however seek to maintain a
consistent online persona to gain social status in the
hacker meritocracy.
• Participation in high-risk behavior. Despite recent arrests for individuals associated with darknet markets
as well as suspicions of law-enforcement infiltration,
many individuals still participate in discussions about
illegal activities in darknet forums, though access controls appear to increase. Likewise, individuals participate in hacktivist operations advertised through social
media. A recent lab-based behavioral study has explored some of the potential factors that would lead an
individual to participate in risky hacktivism activities
(Bodford, 2015).
• High incentives to cheat. The existence of marketplaces where malicious hackers sell software and exploits
to others is an environment where both parties are
highly incentivized to cheat. For instance the sale of a

Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.

193

• Emergence and disintegration of trust-based communities. For darknet marketplaces to thrive, populations of
individuals have to make decisions to trust both those
running the marketplace and many of the vendors. While
there are established models for trust among individuals,
understanding how the propagation of trust is initiated
and spread in anonymous environments – which seem to
discourage trust – remains an open question. By addressing this problem, we can better understand when a given
cyber-exploit/malware marketplace will become well established.
• Modeling deception hypotheses. In order to properly attribute individual activity on the darknet to that seen in
public in cases of cyber-attacks or attributing the author
of a given malware or exploit, cyber-security analysts
consider the “deception hypotheses” – the chance that
some or all of the observed evidence can be planted by
an adversary. Therefore, for models designed for problems relating to cyber-attribution, we must also consider
the deception hypothesis. In some of our ongoing efforts, we are leveraging defeasible logic programming to
explicitly consider the deception hypothesis.

faulty product and violations of exclusive use agreements can be conducted with relative ease.
• Ability to deceive. The anonymous nature of these environments combined with the fact that various aspects of a malicious hacker’s digital persona can be
forged allow for deceptive activities to occur with relative ease.
These characteristics are interesting in several ways.
First, from a sociological and behavioral standpoint, the
freedom at which individuals in these communities discuss
criminal activities as well as share information and code
with individuals likely involved with computer related
crimes (which itself is also a crime) begs the question how
trust is afforded to enable observable social interactions.
Second, the characteristics such as anonymity and deception lead to modeling challenges – perhaps requiring consideration of latent attributes. Third, aspects such as cheating may actually constrain models to a degree – hence
leading to model simplifications.

Modeling Challenges
Conclusion and Ongoing Efforts

In this section, we describe a few major challenges for
modeling socio-cultural cyber threat actor communities.
Overcoming these challenges will provide new insights
into this environment and also aide in higher-level tasks
such as predicting cyber-attacks and understanding the
development of exploits and malware by this community.

In this paper, we have discussed some of the unique
characteristics of the socio-cultural environment for cyber
threat actors and associated modeling problems that are of
interest to the artificial intelligence community. We are
currently exploring these challenges in support of larger
cyber-security goals such as attack prediction and critical
infrastructure defense.

• Establishment of social status in an anonymous environment. In order for a malicious hacking community to
exist, there must be anonymity, yet actors stand to gain
from prestige earned in the hacker meritocracy, such as
access to invite-only forums, trust in social interactions
in general as opposed to undergoing frequent vetting
processes. Modeling the accumulation of this latent
quantity with which proxy measurements are challenging in non-anonymous environments – and the level of
anonymity itself creates even more difficult challenges.
However, in addressing these challenges, we can better
identify significant cyber threat actors and associate a
greater degree of confidence with their actions. Recently, there has been some initial, descriptive work on this
topic (Abbasi et al., 2014).
• Data-driven modeling of risk taking. The adoption of
risky behavior has gained attention in the computational
social science literature using model-based approaches
(Roos, Carr, and Nau, 2010). However, instantiating
models based on data remains largely an open question.
The issue is further complicated by limited data on verified activities – as not all cyber-attacks are reported in
the open. The goals in establishing such models for the
study of cyber-threats in determining when certain risky
behavior will occur is likely to aide in prediction and
preventative cyber defense.

Acknowledgements. This work was supported by Arizona
State University’s Global Security Initiative (GSI) as well
as the U.S. Office of Naval Research (ONR) NEPTUNE
program.

References
Abbasi, A.; Li, W.; V. Benjamin, V.; Hu, S.; Chen, H. (2014)
Descriptive Analytics: Examining Expert Hackers in Web Forums. IEEE Joint International Conference on Intelligence and
Security Informatics.
Bodford, J. (2015) We are Legion: Hacktivism as a Product of
Deindividuation, Power, and Social Injustice, Masters Thesis,
Arizona State University.
Lynn, W. J. 2010. Defending a New Domain: The Pentagon’s
Cyberstrategy. Foreign Affairs, 89(5).
Roos, P.; Carr, R.; Nau, D. 2010. Evolution of state-dependent
risk preferences. ACM Transactions on Intelligent Systems and
Technology 1(1).
Shakarian, J.; Shakarian, P.; Ruef, A. 2015. Cyber Attacks and
Public Embarrassment: A Survey of Some Notable Hacks. Elsevier SciTechConnect.

194

2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)

An Empirical Evaluation Of Social Influence
Metrics
Nikhil Kumar, Ruocheng Guo, Ashkan Aleali and Paulo Shakarian
Arizona State University,
Tempe, AZ
Email: {nikhilkumar, rguosni, aleali, shak}@asu.edu

Abstract—Predicting when an individual will adopt a new
behavior is an important problem in application domains such
as marketing and public health. This paper examines the performance of a wide variety of social network based measurements
proposed in the literature - which have not been previously
compared directly. We study the probability of an individual
becoming influenced based on measurements derived from neighborhood (i.e. number of influencers, personal network exposure),
structural diversity, locality, temporal measures, cascade measures, and metadata. We also examine the ability to predict
influence based on choice of classifier and how the ratio of positive
to negative samples in both training and testing affect prediction
results - further enabling practical use of these concepts for social
influence applications.

I. I NTRODUCTION
Predicting when an individual will adopt a new behavior
is an important problem in application domains such as
marketing [25], the spread of innovation [24], countering
extremism [1], and public health [5]. As a result, a variety of
social network based measurements have been proposed in the
literature and shown to predict how likely an individual will
adopt a new behavior given information about his immediate
social ties. However, when such measures are proposed, they
are often evaluated under different conditions - making it
difficult to understand which of these measurements should
be used in a real-world application. Further complicating the
issue is that the choice of classification algorithm and the
effect of class imbalance in both training and testing are often
not explored in most research. In our lab, we have the goal
of creating and deploying a system for counter-extremism
messaging. Hence, understanding how influence measurements
work in experimental settings that closely resemble real-world
scenarios is an important first step.
In this paper, we study measurements based on neighborhood (i.e. number of influencers [5], personal network
exposure [24]), structural diversity [23], locality [29], temporal
measures [11], cascade measures [12], and metadata [15]. We
examine the probability of an individual becoming influenced
based on these measurements (probability of adoption). We
also examine the the ability to predict influence based on
choice of classifier and the how the ratio of positive to negative
samples in both training and testing affect prediction results.
Specifically, we make the following contributions.

1) We review a variety of measurements used to predict
social influence and we group them in six categories
(Section III).
2) We evaluate how these measurements relate to the probability of a user being influenced using real-world microblog data (Section IV).
3) We evaluate how these measurements perform when used
as features in a machine learning approach and compare
performance across a variety of supervised machine learning approaches (Section V).
4) We evaluate how the ratio of positive to negative samples in both training and testing affect predictive results
(Section VI).
We note that contribution 4 is of particular importance, as
(particularly with microblog data) users are exposed to large
number of messages that they do not retweet (negative samples). Hence, in both training and testing, researchers can
increase the negative samples utilized by large amounts - hence
arbitrarily determining the level of class imbalance. As with
this study as a whole, the experiments on data imbalance were
to better understand these previous research results in tests that
better mimicked real-world scenarios.
Related work. Beyond the work that we shall describe
concerning the various measures for social influence we investigate in Section IV, there has been some general work
in the area of social influence that have taken approaches not
necessarily amenable to comparison. For instance, the seminal
work of Kempe et al. [16] describe two popular models for
information cascades which spawned several techniques to
learn the parameters (which also correspond to edge weights
in the graph). For example, Saito et al. [20] assigned such
probabilities based on an expectation-maximization appproach
while Goyal et al. [11] leveraged a variety of simple models
based on ideas such as a empirically-learned probabilities and
similarity measurements. See [21] for a review of some of
this work. There has also been related work on predicting cascades [8], [27], [12] which are more focused on determining
if a trend in social media exceeds a certain size. That said,
some of the ideas from these approaches, such as structural
diversity [23] are examined here (though this paper is focused
on a different problem). Other work such as Myers et al. [19]
studied the external factors influencing information diffusion,

IEEE/ACM ASONAM 2016, August 18-21, 2016, San Francisco, CA, USA
c
978-1-5090-2846-7/16/$31.00 
2016
IEEE

1329

Liu et al. [18] and Tang et al. [22] focused their studies
on topic influence. Jenders et al. [15] studied a combination
of different features including some of the metadata features
like mentions and hashtags, along with latent features like
sentiments and emotional divergence for predicting the virality
of a tweet - many of which we examine in this study as well.
Hong et al. [14] have also considered a wide spectrum of features including structural, content and temporal information.
However, their study focused more on content-based features
and not the structural features considered here - many of which
were introduced after that work.
II. T ECHNICAL P RELIMINARIES
Here we introduce the necessary notation and describe our
social network data. We represent a social network as a graph
G = (V, E) where V is the set of vertices and E is the set
of directed edges that have sizes |V |, |E| respectively. The
intuition behind edge (v, v 0 ) is that node v can influence v 0 .
This intuition stems from how we create the edges in our
network: (v, v 0 ) is an edge if during a specified time period
there is at least one microblog posted by v that is reposted
by v 0 . For node v ∈ V , the set of in-neighbors is denoted as
ηvin , and the set of out-neighbors as ηvout . We use din
v and
dout
to
denote
the
in-degree
and
out-degree
respectively.
We
v
also assume a partition over nodes that specifies a community
structure. We assume that such a partition is static (based on
the same time period from which the edges were derived) and
the function P (V ) : V → C maps the set of nodes (V ) to the
set of communities (C), where C consists of k communities:
{C1 , C2 , ..., Ck }. We utilize the Louvain algorithm [3] to
identify our communities in this paper due to its ability to
scale.
Cascades. For a given microblog θ, we define t as the number
of time units from the initial post of θ before the microblog
was reposted by one of v’s incoming neighbors - intuitively
the time at which v was exposed to θ. We denote the subset
of nodes who originally posted or reposted θ for time period
t as Vθt . Likewise, the set of reposting relationships within
the same time period will be denoted by Rθt . Taken together,
we have a cascade: Dθt = (Vθt , Rθt ). Any valid original
microblog θ could be treated as a unique identifier for a
cascade. Given a microblog θ, vθ is the originator at instance
t0θ , which is defined as the origin time when the originator
posted the microblog θ. We denote the size of a cascade at
any particular time t as |Vθt |. For v ∈ Vθt , the set of all active
neighbors with respect to θ is defined as Sθv = Vθt ∩ ηvin . We
also define the distance dtθ (v, u) as the shortest path length
between v and u in Dθt .
Sina Weibo Dataset. The dataset we used was provided by the
WISE 2012 Challenge1 . It included a sample of microblogs
posted on Sina Weibo from 2009 to 2012. In this dataset, we
are provided with time and user information for each post and
1 http://www.wise2012.cs.ucy.ac.cy/challenge.html

the last repost in a chain which enabled us to derive a corpus of
cascades. We create the social network G from the retweeting
relationships of microblogs published between May 1, 2011
and July 31, 2011. We use the microblogs published in August
2011 to train and test our approach. Table I lists the statistics
of the dataset we used.
#Users
5,910,608

#Edges
52,472,547

#Reposted tweets
2,238,659

#Reposted Users
394,441

TABLE I: Graph statistics
We found that the network derived from the dataset had
7,668,693 users with 55,381,104 edges between them. For this
network, the number of active users in August (the time period
used to study social influence) is 5,910,608 while 5,664,625 of
them have at least have one out-neighbor. During the month
of August, there were 22,182,703 retweet chains. From this
data, we removed the users who are not present in V ; we
also removed 2,660,421 empty repost chains caused by this
elimination. The dataset does not contain the repost time for
the nodes in the middle of chains. We estimated this time for
each node in the chain based on the original post time and
the final repost time. Table I lists the statistics of this dataset
during the period of study.
Among all the retweeted users we further extract the top
retweeters defined as those who had at least 100 retweets
during the period. This set of high frequency tweeters will be
used as a base for deriving the sample set for our experiments.
For each user in the above mentioned group, an occurrence of
them retweeting a post when they have an active in-neighbor
is considered as a positive instance. If any of their followees
have tweeted and they haven’t retweeted, it is considered as a
negative instance.
III. M EASUREMENTS TO P REDICT S OCIAL I NFLUENCE
In this section, we categorize several approaches for predicting social influence.
1) Neighborhood-based measures
2) Structural diversity measures
3) Influence locality
4) Cascade-based measures
5) Temporal measures
6) Metadata
We examine each of these categories in turn.
Neighborhood-based measures. These are the measures computed using each node and its immediate neighbors. These
measures represents the pair wise influence that the neighboring nodes exert on a given node. Retweeting from followees
is the primary mode of tweet visibility in a microblogging
site, as usually a tweet is visible to a user from its followee
subgraph. Specifcially, we study the following
θ
• Number of active neighbors. (|Sv |) This represents
the count of active neighbors for a node v. In Damon
Centola’s notable empirical study [5], he noted that additional “social signals” – or active neighbors – significantly

1330

•

•

increased the likelihood of an individual adopting a new
behavior.
Personal Network Exposuure (PNE). (|Svθ |/din
v ) Is a
measure adopted from the social science community (i.e.
see [24] ) and has obtained recent interest (i.e. [13]). As
per [24], PNE quantifies the extent to which a person
is exposed to direct and indirect influence. This value is
defined as the ratio of number of active neighbors to total
number of neighbors. It is a measure of the fraction of
influence an active neighbor u has on v. If v has many
in-neighbors aka followees, then u’s influence is diluted
and PNE represents that dilution.
Average in-neighbor count of active neighbors.
θ
(|Σu∈Svθ din
u |/|Sv |) This is calculated by averaging the
number of in-neighbors of each active neighbor of a node.
This defines the dilution of the influence path and is
similar to the measure, number of uninfected neighbors
as described in [27]. Other releated studies include Cha
et al. [6], where they studied the effect of a social
network user’s indegree in depth, and observed that high
indegree is not necessarily correlated to influence in terms
of spawning retweets.

Structural diversity measures. This group of measurements
take into account the structural diversity in the local neighborhood of the node - which refers to the communities present
in the neighborhood.
Ugander et al. [23] introduced structural diversity where
they studied the effect of number of connected components of
a friendship network. Fortunato et al [9] defined communities
as the set of graph vertices which are organized into groups
that seem to live fairly independently of the rest of the graph.
Weng et al. [28] used the community structure to predict the
increase in cascade size. We use the modularity maximisation
method [7] for detecting communities in our dataset. The
Louvian Algorithm [3] which comes under this method is
used to derive the communities in this study due to its ability
to scale. We use two community based measures.
•

•

Active community count. (|P (Svθ )|) This is defined as
the number of adjacent communities of a given user v
with at least one active neighbor of v. The communities
that include active neighbors are more significant in this
context than rest of the adjacent communities. Shakarian
et al. have studied this measure in their book [21]
highlighting the importance of structural diversity.
Active community ratio (|P (Svθ )|/|P (ηvin )|) It is calculated as the ratio of the active community count to the
total number of adjacent communities. This is similar to
the personal network exposure [24] and represents the
dilution of the effect of active community count with
respect to other neighboring communities.

Influence locality. We examine the Influence Locality model
known as LRC-Q, introduced by Zhang et al. [29]. LRC-Q
is defined by the influence locality function Q which is a
combination of peer influence factor (g) and structural factor
(f ). Peer influence factor is obtained as a linear combination

of the geometric mean of random walk probabilities of active
neighbors and structural factor as a linear combination of the
number of circles formed by the active neighbors in the ego
network of the user v. These are defined in their paper by the
following equations.
Q = w × g + (1 − w) × f
s Y
g = |Svθ |
(tvθ − tvθi ) × pvi

(1)
(2)

vi ∈Svθ
θ

f = a log(|Svθ | + 1) + be−µ|C(Sv )|

(3)

In the above equations, pvi is the random walk probability
from the active user vi to the given user v, C(Sv ) is the
collection of circles formed by the active neighbors, tvθ is the
time at which v posted or reposted the microblog θ, µ is the
decay factor and, a, b and w are balance parameters. For our
experiments we set the value of µ as 1 and, a, b and w to be
0.5, as per the parameter settings of [29].
Cascade-based measures.
This group of measurements take into account the various
parameters that are part of a microblog cascade. There has
been many studies in the area of predicting the cascades
including Bakshy et al. [2] , Cheng et al. [8] and more
recently Guo et al. [12]. Unlike our study, there hasn’t been
many attempts to utilize the cascade parameters in predicting
retweet behavior. We study the following measures.
t
• Cascade size. (|Vθ |) Cascade size is computed as the
count of people who have retweeted a particular microblog θ at time t. This number is usually visible to the
microblog user and can have an impact on their retweet
behavior.
t
• Path length. (dθ (v, vθ )) Path length is the length of a
tweet trace path from the original tweeter to a given user
in the cascade. Watts et al. [26] were the first to study
the path length where they found that many social and
technological networks have small path lengths. Kwak et
al. [17] studied the path length in twitter, and Weng et
al. [28] studied a distance measure called Average step
distance which was based on the path length. Our study
focuses on the path length with respect to a particular
cascade Dθt .
Temporal Measure Temporal measures were given prominence in many of the prior studies either by itself, or as a
factor in combination with other measures. Goyal et al. [11]
utilized the temporal factor and attempted to predict the time
by which an influenced user will perform an action. Hong et al.
[14] studied a variety of temporal measures and observed that
they have a stronger effect on messages with low and medium
volume of retweets, compared to highly popular messages. We
study the following temporal measure.
• Retweet Time delay. (t) This is defined as the time
delay between the original tweet and the time when
v is exposed to microblog θ. The time at which a

1331

tweet was made is another piece of information which
people are exposed to while viewing a tweet. This
can affect their decision to retweet it or not. This is
one of the temporal measures studied by Hong et al. [14].
Metadata. These are simple measures derived from the metadata associated with the tweets. We consider the presence
or absence of links, mentions and hashtags as measures for
our study. Jenders et al. [15] did an extensive analysis of a
wide range of tweet and user features regarding their influence
on the spread of tweets. They considered the number of
mentions and number of hashtags among the obvious tweet
features. They observed that tweets containing both hashtags
and mentions are more likely to be retweeted than those with
out, however as the number of hashtags/mentions in a tweet
grows, the expected number of retweets decreases. In this
study we only considers their presence or absence as a measure
and doesn’t go into any deeper analysis.
• Presence of a link (hasLink). This is a binary value
which represents whether the original tweet had a link.
Links are usually shown as part of the tweet content.
Links in tweets is measure similar to mentions and
hashtags, but hasn’t been studied as extensively as either
in the context of social influence.
• Presence of a mention (hasMention). A binary value
which represents whether the original tweet had a mention. Intuitively, a user might be more willing to retweet if
there is a mention of them or someone they know. Similar
to [15], Cha et al. [6] analysed the effect of the number
of mentions and found that mentions can be an important
measure of an individual influence in the social network.
• Presence of a hashtag (hasHashtag). A binary value
which represents whether the original tweet had hashtags.
Hashtags are also a means by which tweets become
visible to users and thus has a lot of significance in
this regard. A deeper analysis of it’s significance like in
[15], is beyond the scope of this work and we only focus
on how the presence or absence of a hashtag affects the
retweeting behavior.
IV. S OCIAL I NFLUENCE M EASUREMENT S TUDY
Here, we examine the distribution of the various
measurements which were defined in the last section.
For each of those measures, the values are put into intervals
of equal sizes and the fraction of positive samples in the
interval is plotted as the probability. The horizontal axis
shows the value intervals of the measure, while the vertical
one shows the number of occurrences for positive instances
with respect to the total in that particular interval. The error
bar shows twice the standard deviation of the sample. These
are shown in Fig. 1 and Fig 2. A detailed analysis of their
distribution is given below.
Neighborhood-based measures. Active neighbor count
intuitively has a positive correlation with the influence

as shown in Figure 1(a). Figure 1(b) shows the active
neighbor count for the lower values which also shows similar
correlation. This is consistent with the empirical study
of [5]. As the number of retweeters among in-neighbors
increases, the probability of a person retweeting the particular
tweet increases. Figure 1(c) shows that PNE also exhibits
positive correlation like active neighbor count. This shows
the significance of PNE measure as demonstrated by other
studies such as [24] and [13]. Average in-neighbor count
of Active Neighbors doesn’t show a clear correlation in it’s
distribution as seen in Figure 1(d).
Structural diversity measures. Number of active
communities shows a good positive correlation with the
retweet behavior. This result is consistent with the related
studies such as [28] and [8]. Active community ratio
also demonstrates a reasonable correlation with the positive
instances as this measure represents the dilution of community
influence based on the total number of adjacent communities.
Cascade-based measures. Intuitively, cascade size is an
important influencer in retweet behavior. If a tweet is
reasonably popular it tends to attract further retweets. The
same is revealed from the distribution in Figure 2(c). This is
consistent with the research of [2] and [8] although they
studied a different problem. The intuition for path length is
that, as the distance from the original tweeter increases a
user is less interested in retweeting the tweet. Our results
show (Figure 2(d)) that this intuition holds between path
length 1 and 2. But, for the remaining intervals, results
doesn’t correlate well. This can be explained by comparing
to the results of [15] where they found similiar pattern
while analyzing mentions and hashtags. Further, the results
of [8] indicate that information cascade depth is related
to popularity. Hence, the microblogs that are far from the
original poster may be inherently popular as the information
cascade has proceeded to a larger depth.
Temporal. Figure 2(e) shows that retweet time delay have
slight inverse correlation with the influence. Intuitively, the
influence of a tweet decays with time, and as people are
exposed to date/time information in the social network they
are less likely to retweet old tweets. This decay factor has
been used in works like [11], [29] etc. and above result
shows the same.
Metadata. Table II shows the conditional probability of
positive instances given the meta measure value of 0 and 1,
respectively. The values from the table shows that presence or
absence of a link doesn’t seem to have much correlation with
the influence. It also shows that, the presence of mentions
seem have slight negative correlation to influence though
there is no actual intuition to base this on. But, this can be
explained by the observation in the paper [15] that as the
number of mentions in a tweet grows, the expected number
of retweets decreases. The presence of hashtag shows an

1332

Probability

0.6
0.4
0.2
1

2

3

4

Active community ratio

(a)

(b)
1.0

1.0

0.8

0.8
0.6
0.4

0.8

0.8

040 399
0
80 -799
0
12 -119
0
16 0-15 9
0 9
20 0-19 9
0 9
24 0-23 9
0 9
28 0-27 9
0 9
32 0-31 9
0 9
36 0-35 9
0 9
40 0-39 9
00 99
-43
99

0.2
0.0

0.2
0.0

0.4

Active neighbor count

0.2
0.0

0 1 2 3 4 5 6 7 8 9

Path length
(d)

1.0
0.8

0 1 2 3 4 5 6 7 8 9

Active neighbor count (lower values)
(b)

0.6
0.4

1.0

0.8

0.8

0.0

0.6

Probability

1.0

010 99
0-1
20 99
0
30 -299
0
40 -399
0
50 -499
0
60 -599
0-6
70 99
0
80 -799
0-8
90 99
0-9
99

(a)

0.4

(c)

0.2
0.0

0-9 10-19 20-29 30-39 40-49 50-59

0.6

Cascade size

0.6

Probability

0.4

0.2
0.0

5

Active community count

1.0

0.6

0.6
0.4

[0.
0-0
[0. .1)
1-0
[0. .2)
2-0
[0. .3)
3-0
[0. .4)
4-0
[0. .5)
5-0
[0. .6)
6-0
[0. .7)
7-0
.8)

0

1.0

Probability

Probability

1.0
0.8

0.0

P (yi = ”pos”|Vi = 1)
0.48
0.45
0.66

~ is a column of the design matrix corresponding
TABLE II: V
to a certain binary feature,”pos” represents positive label and
i is the index of the sample

0.6
0.4
0.2

0.4

Time Delay
(e)

.6)

.5)

[0.

[0.

5-0

.4)

(c)

4-0

.3)

[0.

3-0

.2)

[0.

2-0

.1)

1-0

[0.

0-0
[0.

PNE

10 99
0
20 0-19
00 99
30 -29
0 99
40 0-39
00 99
50 -49
0 99
60 0-59
00 99
70 -69
0 99
80 0-79
0 99
90 0-89
9
10 00-99 9
00 99
0-1
09
99

0.0

0.0

0.2

0.2

0-9

Probability

1.0
0.8

Probability

P (yi = ”pos”|Vi = 0)
0.51
0.51
0.50

Probability

~
V
hasLink
hasMention
hasHashtag

Probability

interesting correlation in Table II. This is consistent with the
study of [15] and illustrates the significance of hashtags in
enhancing the visibility of the tweet and motivating a user to
retweet them.

Fig. 2: Plots of Structural Diversity and Cascade-based measures. Error bars represent two standard deviations.

Avg. in-neighbor count
(d)

Fig. 1: Plots of Neighborhood and temporal measures. Error
bars represent two standard deviations.
V. I NFLUENCE P REDICTION
A. Methods
We derive our graph G from the dataset as described
under Section II. We use the microblogs published in August
2011 to extract the instances to train and test our approach.
Positive and negative instances are extracted as described in
Section II, and the measures described in Section III were
extracted as features for each of them. This set is used to
obtain a random sample with 1:1 negative to positive ratio,
which we will use for the classification experiments.
Classification experiments Here we examine our experiments
for predicting whether a user under given conditions will
retweet or not. As this is a binary classification task we report
the performance measurements (precision, recall and unbiased
F1) for only the positive (retweeting) class. We also examine
the classification performances of various learning algorithms.
For each of the experiments we use a training to test set ratio of

70:30 and used a 10 fold cross validation. We use the following
classification algorithms for our experiment.
Random Forest (RF). Random Forest [4] is a popular
ensemble method used for classification and regression.
Ensemble methods use multiple classifier algorithms to obtain
better accuracy than that could be obtained using any of the
individual classifiers. We use random forest algorithm with
bootstrap aggregating, that fits a number of decision trees
on different sub-samples of the dataset. Each decision tree
provides its own predictions which are then merged obtain a
better accuracy.
AdaBoost Classifier (AB). The AdaBoost algorithm [10]
proposed by Yoav Freund and Robert Schapire is one of the
most important ensemble methods. It is prominent among the
boosting techniques [10] which are used in conjuction with
other learning algorithms. In this method, the weak learners
are combined into a final sum representing the boosted
output. We use the particular algorithm called AdaBoostSAMME [30] and use the decision trees as the base estimator.
Logistic Regression (LR). Logistic regression is a generalized

1333

linear model which uses a logistic function to infer the
relationship between a dependent variable and one or more
independent variables. We utilizes the binomial logistic
regression which predicts the probability that an observation
falls into one of the two categories. Logistic regression has
low varience and is less prone to overfitting.

individual feature groups to improve our ability to predict
retweet behavior in real world datasets.

Naive Bayes Classifier (NB). Naive Bayes is a probabilistic
classifier which is based on applying Bayes’ theorem with
independence assumption between every feature pairs. Naive
Bayes classifiers are highly scalable and less prone to the
curse of dimensionality, making it one of the top machine
learning algorithms. We implement the Gaussian Naive Bayes
algorithm for classification where the likelihood of the features
is assumed to be Gaussian.

0.4

B. Measurement Group Comparison

0.6

Here we compare the classification performance of the
various measurement groups described in Section III. Fig. 3
shows the behavior of different feature groups using multiple
classifier algorithms, which provides a better understanding of
this all-important component in a deployed system. Generally
Random Forest provides the best performance among all
the classifier algorithms. Neighborhood-based (Nbr) measures
performs quite well in Random Forest, AdaBoost and Logistic
regression. This is consistent with what we discussed in
Section IV. Structural diversity measures shows less performance compared to other groups. This can be attributed to the
fact that it is not often used independently in classification,
and usually this group performs well in conjunction with
other measures such as Neighborhood-based. LRC-Q gives
performance measure comparable to the results in [29].
Cascade-based measures are observed to perform reasonably
well in Random Forest, Logistic Regression and AdaBoost.
This once again illustrates the significance of cascade size and
bring into focus the path length measure. Temporal measure
performs well in all classifiers except Naive Bayes. Although
time based measures are frequently used as a decay factor in
conjunction with other measures ([11], [29]), our results show
that it could yield high predictive power by itself. Metadata
measures shows good and consistent performance across all
classifiers. As research by [15] shows, hashtag and mentions
have high predictive power with respect to retweet behaviour
and our results confirms the significance of this measure along
with the hasLinks measure.
With an eye toward a deployed system, we also examine
a “Multi-Measurement model” which is a combination of
Neighborhood, Structural, Cascade, Temporal and Metadata
measures. The Multi-Measurement model shows better performance than individual groups generally among Random Forest, Logistic Regression and AdaBoost classifiers. The other
measures such as neighborhood-based, temporal and LRC-Q
performs reasonably well compared to rest of the individual
future groups. The performance of Multi-Measurement model
shows a real value in combining the various features and

1.0

Precision

Recall

F1

0.8
0.6

0.2
0.0

Nbr

Structural Cascade Temporal

Meta

LRC-Q Multi-Meas

(a)

1.0

Precision

Recall

F1

0.8

0.4
0.2
0.0

Nbr

Structural Cascade Temporal

Meta

LRC-Q Multi-Meas

(b)

1.0

Precision

Recall

F1

0.8
0.6
0.4
0.2
0.0

Nbr

Structural Cascade Temporal

Meta

LRC-Q Multi-Meas

Meta

LRC-Q Multi-Meas

(c)

1.0

Precision

Recall

F1

0.8
0.6
0.4
0.2
0.0

Nbr

Structural Cascade Temporal
(d)

Fig. 3: Performance with different classifier algorithms. a)
Random Forest b) Logistic Regression c) Naive Bayes d)
AdaBoost.
C. Multi-Measurement Model Compared to Influence Locality
We compare our results with the LRC-Q model described in
[29]. We experimented with multiple classification algorithms
for this task and the best results were obtained using Random
Forest classifier. The results obtained using Random Forest
(RF), Logistic Regression (LR), Naive Bayes (NB) and

1334

Precision
0.679
0.95
0.794
0.602
0.764

Recall
0.573
0.947
0.765
0.704
0.285

Precision

1.00
0.95
0.90
0.85
0.80
0.75
0.70
N to 9
8
P tra765
0.65
inin432 1 9 8 7 6 5 4 3 2 1
gs
P test set

et

Precision

1
2

N to

(a)

Recall

0.95
0.90
0.85
0.80
0.75
0.70
0.65
89

6 7 set
1 2
4 5 test
N to3P tr4 5 6
3
P
aining s7 8
2
et 9 1 N to

(c)

(d)

0.90

F10.85
0.80
1 et
0.75
4 3 2 ng s
1 2 3 4 5 6
7 6 5 aini
N to P test set 7 8 9 N9 t8o P tr

(e)

VI. VARYING N EGATIVE TO P OSITIVE RATIO
An important question when deploying the aforementioned
methods in a real-world application is how to best train the
model to cope with data imbalance observed in-practice. As
individuals are exposed to an arbitrarily large number of
microblogs that they do not rebroadcast, this is a difficult and unfortunately relatively unstudied problem. Here, we conducted experiments to analyse how classification performance
varies with different negative to positive ratio in both training
and test set. The surface and linear plots in Figure 4 shows
the precision, recall and F1 values obtained using Random
Forest classifier, when negative to positive ratio is varied from
1:1 to 9:1. The ratio was varied in both training set and test
set to observe the effects on overall performance. Precision
is observed to decrease as we increase the size of negative
samples in test set while keeping the ratio in training set
constant. Recall is observed to remain the same with changing
ratio in test set. Change in negative to positive ratio in training
set on the hand, shows slight increase in precision where as
recall decreases. Results for LRC-Q follows a similar pattern
except for the convergence of recall for increased imbalance in

9

1.00
0.95
0.90
0.85
0.80
0.75
0.70
0.65
0.60
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

N to P for training
1
3
5
7
2
4
6
8

TABLE III: Performance of retweet behavior prediction

9

1.00
0.95
0.90
0.85
0.80
0.75
0.70
0.65
0.60
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(b)

0.95

F1
0.622
0.948
0.784
0.649
0.415

N to P for training
3
5
7
4
6
8

N to P for training
1
3
5
7
2
4
6
8

F1

Model
LRC-Q (LR)
Multi-Meas (RF)
Multi-Meas (AB)
Multi-Meas (LR)
Multi-Meas (NB)

training set. From these results, it can be generally observed
that 1:1 is the ideal ratio of negative to positive samples in
training set for an unknown imbalance in test data.

Recall

AdaBoost (AB) are shown in the Table III . As LRC-Q uses
only a single feature, we only use Logistic Regression for
it’s evaluation. It can be observed that Multi-Measurement
model outperforms the LRC-Q model in all classifiers except
for Naive Bayes. This can be attributed to the fact that
while LRC-Q takes into account pairwise and structural
influence along with time decay, Multi-Measurement model
incorporates more parameters in addition to the above. LRC-Q
has combined the pairwise and structural factor into a single
feature and uses time measure as a decay factor. The MultiMeasurement model on the other hand treat them individually,
along with including different kinds of pairwise influence
(such as active neighbor count, personal network exposure
and average in-neighbors of active neighbors), considering
both direct as well as ratio based measures for structural
diversity, and using temporal measure as an independent
feature. In addition to that, this model also includes cascade
and metadata based features giving it a broader view of
the parameters that can influence an individual’s retweeting
behavior. This demonstrates that in any attempt of retweet
prediction, a broader approach is required, which incorporates
multiple measures that are are closely related (within the
measurement groups) and those that are mutually exclusive
(across groups) to obtain the best prediction in classification.

9

1.00
0.95
0.90
0.85
0.80
0.75
0.70
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(f)

Fig. 4: Plots for classification on imbalanced data for MultiMeasurement model using Random Forest. a) Precision surface plot b) Precision line plot c) Recall surface plot d) Recall
line plot e) F1 surface plot f) F1 line plot.
VII. C ONCLUSION
In this paper, we examines the performance of a wide
variety of social network based measurements and study the
probability of an individual becoming influenced based on
them. In this study, we grouped those measures under various
measurement groups to understand their group wise predictive
power. We designed these experiments so that they would
move beyond standard research-based experiments used to
evaluate an idea - we designed these experiments to understand
how well these ideas can be used in a deployed system. We
look to use these results in a system that we intend to deploy
or license for real-world influence operations such as counterextremism.
ACKNOWLEDGMENTS
Some of the authors are supported through the AFOSR
Young Investigator Program (YIP) grant FA9550-15-1-0159,

1335

Precision

N to 9
P tr8a765
inin432 1 9 8 7 6 5 4 3 2 1
g se
N to P test set
t

Precision

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1

1
2

N to P for training
3
5
7
4
6
8

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(a)

(b)

Recall

0.6
0.5
0.4
0.3
0.2
0.1
0.0
9
8

Recall

N to P for training
1
3
5
7
2
4
6
8

6 7 set
1 2
4 5 test
N to3P tr4 5 6
3
P
aining s7 8
2
et 9 1 N to

9

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(c)

(d)

F1

N to P for training
1
3
5
7
2
4
6
8

0.7
0.6
0.5
F1 0.4
0.3
0.2
0.1
0.0

9

1 et
4 3 2 ng s
1 2 3 4 5 6
7 6 5traini
8
7
8
9
9
P
N to P test set
N to

9

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(e)

(f)

Fig. 5: Plots for classification on imbalanced data for LRCQ using Logistic Regression. a) Precision surface plot b)
Precision line plot c) Recall surface plot d) Recall line plot e)
F1 surface plot f) F1 line plot.

ARO grant W911NF-15-1-0282, the DoD Minerva program
grant N00014-16-1-2015 and the EU RISE program.
R EFERENCES
[1] S. Al-khateeb and N. Agarwal, “Examining botnet behaviors for propaganda dissemination: A case study of isil’s beheading videos-based
propaganda,” in ICDM Workshops. IEEE, 2015, pp. 51–57.
[2] E. Bakshy, J. M. Hofman, W. A. Mason, and D. J. Watts, “Everyone’s
an influencer: quantifying influence on twitter,” in Proceedings of the
fourth ACM international conference on Web search and data mining.
ACM, 2011, pp. 65–74.
[3] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast
unfolding of communities in large networks,” Journal of Statistical
Mechanics: Theory and Experiment, vol. 2008, no. 10, p. P10008, 2008.
[4] L. Breiman, “Random forests,” Machine learning, vol. 45, no. 1, pp.
5–32, 2001.
[5] D. Centola, “The Spread of Behavior in an Online Social Network
Experiment,” Science, vol. 329, no. 5996, pp. 1194–1197, Sep. 2010.
[6] M. Cha, H. Haddadi, F. Benevenuto, and P. K. Gummadi, “Measuring
user influence in twitter: The million follower fallacy.” ICWSM, vol. 10,
no. 10-17, p. 30, 2010.
[7] M. Chen, K. Kuzmin, and B. K. Szymanski, “Community detection
via maximization of modularity and its variants,” Computational Social
Systems, IEEE Transactions on, vol. 1, no. 1, pp. 46–65, 2014.

[8] J. Cheng, L. Adamic, P. A. Dow, J. M. Kleinberg, and J. Leskovec,
“Can cascades be predicted?” in Proceedings of the 23rd international
conference on World wide web. ACM, 2014, pp. 925–936.
[9] S. Fortunato, “Community detection in graphs,” Physics reports, vol.
486, no. 3, pp. 75–174, 2010.
[10] Y. Freund, R. Schapire, and N. Abe, “A short introduction to boosting,”
Journal-Japanese Society For Artificial Intelligence, vol. 14, no. 771780, p. 1612, 1999.
[11] A. Goyal, F. Bonchi, and L. V. Lakshmanan, “Learning influence
probabilities in social networks,” in Proceedings of the third ACM
international conference on Web search and data mining. ACM, 2010,
pp. 241–250.
[12] R. Guo, E. Shaabani, A. Bhatnagar, and P. Shakarian, “Toward order-ofmagnitude cascade prediction,” in Proceedings of the 2015 IEEE/ACM
International Conference on Advances in Social Networks Analysis and
Mining 2015. ACM, 2015, pp. 1610–1613.
[13] A. Halavais, K. H. Kwon, S. Havener, and J. Striker, “Badges of
friendship: Social influence and badge acquisition on stack overflow,”
in 2014 47th Hawaii International Conference on System Sciences, Jan
2014, pp. 1607–1615.
[14] L. Hong, O. Dan, and B. D. Davison, “Predicting popular messages in
twitter,” in Proceedings of the 20th international conference companion
on World wide web. ACM, 2011, pp. 57–58.
[15] M. Jenders, G. Kasneci, and F. Naumann, “Analyzing and predicting
viral tweets,” in Proceedings of the 22nd international conference
on World Wide Web companion.
International World Wide Web
Conferences Steering Committee, 2013, pp. 657–664.
[16] D. Kempe, J. Kleinberg, and É. Tardos, “Maximizing the spread of
influence through a social network,” in Proceedings of the ninth ACM
SIGKDD international conference on Knowledge discovery and data
mining. ACM, 2003, pp. 137–146.
[17] H. Kwak, C. Lee, H. Park, and S. Moon, “What is twitter, a social
network or a news media?” in Proceedings of the 19th international
conference on World wide web. ACM, 2010, pp. 591–600.
[18] L. Liu, J. Tang, J. Han, M. Jiang, and S. Yang, “Mining topic-level
influence in heterogeneous networks,” in Proceedings of the 19th ACM
international conference on Information and knowledge management.
ACM, 2010, pp. 199–208.
[19] S. A. Myers, C. Zhu, and J. Leskovec, “Information diffusion and
external influence in networks,” in Proceedings of the 18th ACM
SIGKDD international conference on Knowledge discovery and data
mining. ACM, 2012, pp. 33–41.
[20] K. Saito, R. Nakano, and M. Kimura, “Prediction of information
diffusion probabilities for independent cascade model,” in Knowledgebased intelligent information and engineering systems. Springer, 2008,
pp. 67–75.
[21] P. Shakarian, A. Bhatnagar, A. Aleali, R. Guo, and E. Shaabani,
Diffusion in Social Networks. Springer, 2015.
[22] J. Tang, J. Sun, C. Wang, and Z. Yang, “Social influence analysis
in large-scale networks,” in Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and data mining.
ACM, 2009, pp. 807–816.
[23] J. Ugander, L. Backstrom, C. Marlow, and J. Kleinberg, “Structural
diversity in social contagion,” Proceedings of the National Academy
of Sciences, vol. 109, no. 16, pp. 5962–5966, 2012.
[24] T. W. Valente, Network models of the diffusion of innovations, ser.
Quantitative methods in communication.
Cresskill, N.J.: Hampton
Press, 1995, thomas W. Valente. Includes bibliographical references (p.
153-163) and indexes.
[25] D. Watts and J. Peretti, “Viral marketing for the real world,” Harvard
Business Review, May 2007.
[26] D. J. Watts and S. H. Strogatz, “Collective dynamics of smallworldnetworks,” nature, vol. 393, no. 6684, pp. 440–442, 1998.
[27] L. Weng, F. Menczer, and Y.-Y. Ahn, “Virality prediction and community
structure in social networks,” Scientific reports, vol. 3, 2013.
[28] ——, “Predicting successful memes using network and community
structure,” in Eighth International AAAI Conference on Weblogs and
Social Media, 2014.
[29] J. Zhang, B. Liu, J. Tang, T. Chen, and J. Li, “Social influence locality
for modeling retweeting behaviors.” in IJCAI, vol. 13, 2013, pp. 2761–
2767.
[30] J. Zhu, H. Zou, S. Rosset, and T. Hastie, “Multi-class adaboost,”
Statistics and its Interface, vol. 2, no. 3, pp. 349–360, 2009.

1336

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

Toward Order-of-Magnitude Cascade Prediction
Ruocheng Guo, Elham Shaabani, Abhinav Bhatnagar and Paulo Shakarian
Arizona State University
Tempe, AZ
Email: {rguosni, shaabani, abhatn, shak}@asu.edu
Abstract—When a piece of information (microblog, photograph, video, link, etc.) starts to spread in a social network, an
important question arises: will it spread to “viral” proportions
– where “viral” is defined as an order-of-magnitude increase.
However, several previous studies have established that cascade
size and frequency are related through a power-law - which leads
to a severe imbalance in this classification problem. In this paper,
we devise a suite of measurements based on “structural diversity”
– the variety of social contexts (communities) in which individuals
partaking in a given cascade engage. We demonstrate these
measures are able to distinguish viral from non-viral cascades,
despite the severe imbalance of the data for this problem. Further,
we leverage these measurements as features in a classification
approach, successfully predicting microblogs that grow from 50
to 500 reposts with precision of 0.69 and recall of 0.52 for the
viral class - despite this class comprising under 2% of samples.
This significantly outperforms our baseline approach as well as
the current state-of-the-art. Our work also demonstrates how we
can tradeoff between precision and recall.

I.

I NTRODUCTION

When a piece of information (microblog, photograph,
video, link, etc.) starts to spread in a social network, an
important question arises: will it spread to “viral” proportions
– where “viral” is defined as an order-of-magnitude increase.
Several previous studies [1], [2] have established that cascade
size and frequency are related through a power-law - which
leads to a severe imbalance in this classification problem.
In this paper, we devise a suite of measurements based on
“structural diversity” that are associated with the growth of a
viral cascade in a social network. Structural diversity refers
to the variety of social contexts in which an individual engages and is typically instantiated (for social networks) as the
number of distinct communities represented in an individual’s
local neighborhood. Previously, Ugander et al. identified a
correlation between structural diversity and influence [3]. We
demonstrate these measures are able to distinguish viral from
non-viral cascades, despite the severe imbalance of the data
for this problem. Further, we leverage these measurements as
features in a classification approach, successfully predicting
microblogs that grow from 50 to 500 reposts with precision
of 0.69 and recall of 0.52 for the viral class (under 2% of the
samples).
We note that our results on the prediction of cascades
rely solely upon the use of our structural diversity based
measures for features and limited temporal features - hence
the prediction is based on network topology alone (no content
information was utilized). We also achieved these results while
maintaining the imbalances of the dataset - which we felt better
mimics reality. This differs from some previous studies which
balance the data before conducting classification. Further,
ASONAM '15, August 25-28, 2015, Paris, France
ACM ISBN 978-1-4503-3854-7/15/08
DOI: http://dx.doi.org/10.1145/2808797.2809358

1610

we note that we obtained prediction of order-of-magnitude
increases in the size of the cascade - which also differs from
other work (i.e. [1]) which focus on identifying cascades that
double in size.
II.

T ECHNICAL P RELIMINARIES

Here we introduce necessary notation and describe our
social network data. We represent a social network as a graph
G = (V, E) where V is the set of vertices and E as set
of directed edges that have sizes |V |, |E| respectively. The
intuition behind edge (v, v 0 ) is that node v can influence v 0 .
This intuition stems from how we create the edges in our
network: (v, v 0 ) is an edge if during a specified time period
there is at least one microblog posted by v that is reposted by
v 0 (we leave other thresholds beyond 1 repost to future work).
We shall also assume a partition over nodes that specifies a
community structure. We shall assume that such a partition is
static (based on the same time period from which the edges
were derived) and that the partition C consists of k communities: {C1 , C2 , ..., Ck }. There are many possible methods to
derive the communities (if user-reported communities are not
available). We utilize the Louvain algorithm to identify our
communities in this paper due to its ability to scale.
Cascades. For a given microblog θ, we denote the subset
of first-m nodes who originally posted or reposted θ as Vθm
and refer to them as adopters (at size m). Likewise, the
set of reposting relationships within the same time period
will be denoted Rθm . Taken together, we have a cascade:
Dθm = (Vθm , Rθm ). Any valid original microblog θ could
be treated as a unique identifier for a cascade. Given a
microblog θ, vθ is the originator at instance t0θ , which is
defined as the origin time when the originator posted the
microblog θ and time t is time since t0θ . The mth repost
of the microblog θ happens at time tm
θ . As m increases, a
cascade accumulates nodes and edges over time. We shall
use Nθ to denote the final size of a cascade while the size
of a cascade at any particular instance is the set of nodes
present at that instance is simply |Vθm |. For a given size m,
we shall refer to the frontiers as the outgoing neighbors of the
adopters in graph G who are not adopters themselves. Formally: Fθm = {v ∈ V /Vθm s.t. ∃vi ∈ Vθm where (vi , v) ∈ E}.
For nodes in G that are outside the adopters, we shall use
the notation texp (v, θ, m) to denote the number of time units
from the initial post of θ before the microblog was reposted
by one of v’s incoming neighbors - intuitively the time at
which v was exposed to θ. For a given natural number λ
(used to specify a time period), we define the λ frontiers
as a subset of the frontiers that have been exposed to θ
no earlier than λ time units previously. Formally this set
is defined as follows: Fθm,λ = {v ∈ Fθm |texp (v, θ, m) ≤ λ}.

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
Finally, the complement of this set are the λ non-adopters:
F̄θm,λ = {v ∈ Fθm |texp (v, θ, m) > λ}.
Sina Weibo Dataset. The dataset we used was provided by
WISE 2012 Challenge1 . It included a sample of microblogs
posted on Sina Weibo from 2009 to 2012. In this dataset, we
are provided with time and user information for each post
and subsequent repost which enabled us to derive a corpus
of cascades. From this data, we derived our social network
G = (V, E) (with 17.9 M vertices and 52.4 M edges) that
was created from reposts that were published during the 3
month period between May 1, 2011 and July 31, 2011. For this
network, the average clustering coefficient is 0.107. There are
4974 connected components in the network. Louvain algorithm
outputs 379,416 communities with average size of 47.5 for
this network. As expected, this network exhibits a power-law
degree distrubtion. For this network, the number of active
nodes in August (the time period we studied for cascade
prediction) is 5,910,608, while 5,664,625 of them at least have
one out-neighbor. During the month of August, there were
9,323,294 reposts with 2,252,368 different original microblogs.
1,920,763 (86.6%) of them were written by authors who at
least published one microblog during May 1, 2011 to July
31, 2011 (the time period we used to create the underlying
network). The average time it took for viral cascades to become
viral is approximately 18 hours. The distribution of final
size of cascades mimics a power-law distribution which can
demonstrate that this dataset is more representative of cascade
behavior observed “in the wild”. This differs significantly
from the previous works which conduct biased sampling to
artificially provide balanced classes. We selected λ as 30
minutes as 90% of all reposts in the initial 3 month period
occurred in under this time.
Number of communities. For V 0 ⊆ V , the associated communities C(V 0 ) are the communities represented by V 0 . Formally:
C(V 0 ) = {Ci ∈ C s.t. V 0 ∩ Ci 6= ∅}. The cardinality of this set
(number of communities) will be denoted K(V 0 ). We measure
the number of communities represented by the above three
populations of nodes: K(Vθm ), K(Fθm,λ ), K(F̄θm,λ ) observed
at either a given cascade size.
0

0

Gini impurity. For V ⊆ V , the gini impurity, IG (V ) is the
probability of a node in V 0 being placed into the incorrect
community if assigned a community based on the distribution
of communities represented in V 0 . Formally: IG (V 0 ) =
P |Ci ∩V 0 |
1 − i ( |V 0 | )2 . We study the gini impurity of the adopters,
λ non-adopters and λ frontiers for either a given cascade size
m: IG (Vθm ), IG (Fθm,λ ), IG (F̄θm,λ ). The intuition is to capture
a notion of how the communities are distributed amongst the
nodes in each of these sets with a single scalar value. We note
that the impurity of the adopter set IG (Vθm ) behaves similar
to the entropy of this set (a measurement introduced in [4]).
However, as we will see in the next two sections, we found
that the impurity of the λ frontiers is a more discriminating
feature.
Overlap. For Va , Vb ⊂ V , the overlap (O(Va , Vb )) is simply
the number of shared communities. Formally: O(Va , Vb ) =
|C(Va ) ∩ C(Vb )|. We study overlap between adopters and λ
frontiers, between adopters and λ non-adopters, and between
1 http://www.wise2012.cs.ucy.ac.cy/challenge.html

1611

λ frontiers and λ non-adopters: O(Vθm , Fθm,λ ), O(Vθm , F̄θm,λ ),
and O(Fθm,λ , F̄θm,λ ) respectively. The intuition with overlap
stems directly from the original structural diversity results
of [3] - for instance a high overlap between adopters and
λ frontiers may indicate that the λ frontiers are linked to
adopters with inner-community connections and high structural
diversity - hence increasing the probability of adoption.
Average time to adoption. The average time to adoption for
the nodes in P
the current set of adopters (once the cascade grows
m
tiθ
to size m): i=1
. We also use average time to adoption as
m
a baseline measure.
III.

R ESULTS

Here we examine the behavior of the various structural diversity measurements as viral and non-viral cascades
progress. We define a cascade as viral if the number of
reposts reaches a threshold (denoted T H) of 500 (in the
next section we will explore other settings for T H when
describing our classification results). We look at snapshots of
the cascades as they progress both in terms of size (denoted
m). For m = {10, 30, 50, 100, 200}, the number of samples
is {98832, 26733, 13285, 4722, 1324} respectively with 208 of
the samples are viral. With each size m we consider the
m
Cascades with m adopters at some time tm
θ , tθ can vary for
different θ. Hence, cascades with final size N < m are ignored
in our analysis task. This leads to a decrease in the number of
non-viral Cascades as m increases.
Average time to adoption. As a baseline measurement, we
study the average time to adoption for each size-based stage
of the cascade process (Fig. 1i, Fig. 1j). As expected, viral
cascades exhibit a faster rate of reposting. While we note that
significant differences are present - especially in the early
stages of the cascade, the whiskers of the non-viral class
indicate a significant proportion of non-viral cascades that
exhibit rapid adoption. We believe this is likely due to the fact
that certain cascades may have very high appeal to specialized
communities.
Number of communities. Fig. 1a, Fig. 1b, Fig. 1c and Fig. 1d
display how the number of communities K(V 0 ) n
increases over
o
m = {10, 30, 50, 100, 200} for the sets V 0 = Vθm , Fθm,λ .
We note that K(Vθm ) (the communities represented in the
set of adopters) was shown to be a useful feature in [4]
for tasks where the target class had fewer reposts than in
this study. Here, we note that while statistically significant
differences exist, the average and median values at each of the
examined stages are generally similar. On the other hand, the
communities represented by the set of λ frontiers (K(Fθm,λ ))
shows viral Cascades have stronger capability than non-viral
ones to keep a diverse set of λ frontiers. We also noted that the
median of K(F̄θm,λ ) (not pictured) shows viral cascades start
with smaller K(Fθm,λ ). However, it increases faster in viral
cascades as nodes in λ frontiers becomes λ non-adopters.
Gini impurity. Cascades in both classes tend to accumulate
diversity in the process of collecting more adopters - and we
have also noted that a related entropy measure (studied in [4])
performed similarly. We also noted (not pictured) that in the
early stages, viral cascades can show more diversity in λ frontiers measured by IG (Fθm,λ ) (m = {10, 30, 50}). But, perhaps

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

Community Features Mentioned in [4] and Cm

Cm

Pm
i
i=1 tθ
m

, m = 50

most striking, that non-viral Cascades gain more uniformly
distributed nodes over communities in λ non-adopters, shown
by IG (F̄θm,λ ) (Fig. 1g, Fig. 1h). We believe that this is due to
non-viral cascades likely have an appeal limited to a relatively
small number of communities - hence those not adopting the
trend may represent a more diverse set of communities.
Overlap. We found that overlap grows with the number
of adopters in the three types of overlap considered. For
O(Vθm , Fθm ), viral cascades start with a larger initial value
and keep leading non-viral ones in the diffusion process of first
200 nodes (Fig. 1e, Fig. 1f). This may hint that viral cascades
also take advantage of the densely linked communities to help
them become viral. However, in the case of O(Vθm , F̄θm ) and
O(Fθm,λ , F̄θm,λ ), viral cascades begin with lower value but
grow much faster than non-viral Cascades.
Classification Experiments. Here we examine our experiments for predicting whether a cascade becomes viral - when
a size threshold (T H) exceeds 500 adopters given that the
cascade has 50 adopters (s = 50). Based on the distribution
of final size of cascades in this dataset, this is a binary
classification task with two heavily imbalanced classes. Hence,
we report performance measurements (precision, recall and
F1 score) for only the minority (viral) class. Throughout the
course of our experiments, we found that varying threshold
(slightly modifying the definition of “viral”) for only the training set allows for a trade-off between precision and recall. We
study the trend of performance measures in two cases: (1.) The
threshold for test set is maintained as T Hts = 500 while the
training threshold is varied T Htr = {300, 400, 500, 600, 700}.
(2.) The two thresholds are kept as the same T H while we
modify this value T H = {300, 400, 500, 600, 700}.
Table I shows the groups of features used in our prediction
tasks. The features introduced in this paper is group Am . As
a baseline method for size-based prediction (feature group
Cm ) we used average time to adoption. We also compare our
features (Group Am ) with the community features extracted
in [4] (Group Bm ). This was the best performing feature set
in that paper for a comparable task.2 Additionally, we study
the average size of recalled and non-recalled viral cascades by
classifiers using features in groups Am . We also investigate
the significance and performance of individual and certain
combinations of features introduced in this paper.
We used ten-fold cross-validation in our experiments to
ensure the results do not take any advantage of randomness in picking training and testing sets. First we carried
2 This was their highest-performing set of features for predicting cascades
that grew from 50 to 367 and 100 to 417 reposts. We also included the
baseline feature in this set as we found it improved the effectiveness of this
approach.

1612

10

30

50

100

Number of Adopters

48.0
47.6

200

(a) Number of communities amongst
adopters (K(Vθm )) for non-viral cascades

1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0

M: 7.0
A: 25.7

10

15.0
39.6

20.0
53.2

30

50

100

Number of Adopters

200

M: 3.0
A: 3.7

9.0
8.7

12.0
12.3

19.0
18.5

1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0

60

50

50

40

40

30
10
0

30

50

100

Number of Adopters

34.0
34.0

46.5
46.5

30

50

100

200

Number of Adopters

M: 21.0
A: 24.3

10

30.0
41.7

30.0
44.4

33.5
78.7

42.5
88.6

30

50

100

200

Number of Adopters

M: 7.0
A: 6.7

13.0
12.7

17.0
16.5

22.5
22.2

31.0
29.5

30

50

100

200

30
20

M: 0.8
A: 0.8

0.9
0.9

0.9
0.9

0.9
0.9

0

200

10

Number of Adopters

(f) Overlap of adopters and λ frontiers (O(Vθm , Fθm,λ )) for viral cascades

0.9
0.9

1.0

0.8

M: 0.0
A: 0.4

0.9
0.8

0.9
0.9

0.9
0.9

0.9
0.9

30

50

100

200

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

0.0

10

30

50

100

Number of Adopters

200

(g) Gini impurity of λ non-adopters
(IG (F̄θm,λ )) for non-viral cascades

1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0

23.0
23.5

10
10

(e) Overlap of adopters and λ frontiers (O(Vθm , Fθm,λ )) for non-viral
cascades

1.0

10

17.0
17.3

(d) Number of communities amongst
λ frontiers (K(Fθm,λ )) for viral cascades

26.0
25.2

20

M: 8.0
A: 8.1

(b) Number of communities amongst
adopters (K(Vθm )) for viral cascades

27.0 33.0
88.5 111.1

(c) Number of communities amongst
λ frontiers (K(Fθm,λ )) for non-viral
cascades

60

70
60
50
40
30
20
10
0

Overlap

, m ∈ {30, 50}

Bm

35.0
34.9

Gini

Pm
i
i=1 tθ
m

25.0
24.0

M: 865.9
A: 780.3

10

853.1 804.5 754.6 765.2
790.1 771.0 753.8 759.9

30

50

100

Number of Adopters

(i) Non-viral cascades

200

10

Number of Adopters

(h) Gini impurity of λ non-adopters
(IG (F̄θm,λ )) for viral cascades

Average Time(103 )

|Fθm,λ |, |F̄θm,λ |,

18.0
17.5

Number of Communities

Number of Communities

O(Vθm , Fθm,λ ),O(Vθm , F̄θm,λ ),O(Fθm,λ , F̄θm,λ ),

Number of Communities(102 )

Am

Overlap

K(Fθm,λ ),K(F̄θm,λ ),IG (Vθm ),IG (Fθm,λ ),IG (F̄θm,λ ),

M: 8.0
A: 7.7

Gini

Feature(s) over size

Average Time(103 )

Group

70
60
50
40
30
20
10
0

Number of Communities(102 )

TABLE I: Features: Cascade Prediction over Time and Size

1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0

M: 15.3
A: 40.9

10

49.7 78.4 168.1 301.1
86.9 129.4 215.8 347.7

30

50

100

Number of Adopters

200

(j) Viral cascades

Fig. 1: Number of communities, gini impurity, overlap and average time since t0θ to adoption for m = {10, 30, 50, 100, 200}

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
Am
Bm

Cm

precision

1.0

recall

f1 score

0.8

Size (103 )

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0 Precision

0.6
0.4
Recall

0.2

F1 Score

Fig. 2: Classification results based on groups of features
(Am ,Bm ,Cm ) extracted when m = 50 for fixed T Htr = 500,
T Hts = 500. Error bars represent one standard deviation.
out the prediction tasks with fixed thresholds T Htr =
500, T Hts = 500. Then we modify the training threshold T Htr = {300, 400, 500, 600, 700} to show how this
achieves a trade-off between precision and recall. The difference in average final size between correctly classified viral
cascades and incorrectly classified ones is also monitored
over T Htr = {300, 400, 500, 600, 700} to show the potential
to predict exact number of adopters by features. Furthermore, we modify threshold of both training and testing sets
T H = {300, 400, 500, 600, 700} to show the robustness of
our features on related classification problems. We used the
oversampling method SMOTE with random forest classifier to
generate synthetic samples for the viral class. Other, lesserperforming classifiers were also examined (including SVM,
MLP, and other ensemble methods) and are not reported here.
All results shown in this section is a sample mean produced by
ten repeated experiments under each combination of variables.
Size-based prediction. We studied cascades of size 50 that
reached 500 for this task. There are 13,285 cascades that can
reach the size m = 50 while 208 out of them reached the size
of 500. Maintaining the threshold T H = 500, Fig. 2 shows
random forest classifier trained with features in group Am can
outperform the other groups. The trade-off between precision
and recall can be achieved by changing the training threshold T Htr while maintaining the testing threshold (Fig. 3a).
We also note that the average final size of viral cascades
recalled by the classifier increases with the training threshold
(Fig. 3b). With threshold T H = {300, 400, 500, 600, 700}
on both training and testing samples, the features of group
Am consistently outperform those previously introduced (Bm )
(Fig. 3c, Fig. 3d).
Feature investigation. Here we investigate the importance of
each feature in Am . With T Htr = 500 and T Hts = 500,
we trained 100 randomized logistic regressions models - each
assigning weights to the features in those sets. We then
categorized the features with weight larger than 0.01 (on
average) into groups such as overlap, gini impurity, etc. Then,
we performed classification on the basis of single feature
categories or combination of such categories. The average
weights assigned are shown in Table II. As shown by these
results, overlaps can make significant contribution to cascade
prediction. Intuitively, communication between two sets of
nodes is more likely to happen in their shared communities which is consistent with the results of [3]. This implies that the
larger overlap value, the more influence of one set on the other.
For example, we can infer that viral cascades tend to have
larger O(Vθm , Fθm,λ ) value for adopters have larger chance to
influence the λ frontiers than non-viral cascades. Moverover,

1613

300

400
500 600
Training Threshold

700

1.4
recalled
not recalled
1.3
1.2
1.1
1.0
0.9
0.8
0.7
0.6 300
400
500
600
Training Threshold

mean

700

(a) Results for features in Am with (b) Average final size of viral cascades
different T Htr .
(recalled, mean and not recalled)
1.0

precision

recall

f1 score

1.0

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0 300

400
500 600 700
Training/Testing Threshold

precision

0.0 300

recall

f1 score

400
500 600 700
Training/Testing Threshold

(c) Results for features in group Am (d) Results for features in group Bm
when T Htr and T Hts change.
when T Htr and T Hts change.

Fig. 3: Prediction results for Am when T Htr and T Hts
change. Error bars represent one standard deviation.

Name
Gini

Baseline

Features

Weights

IG (Fθ50,λ )
IG (F̄θ50,λ )
IG (F̄θ30,λ )
P50
i
i=1 tθ
50

0.02
0.02
0.52

Name

Features

Weights

O(Vθ30 , Fθ30,λ )

0.50

O(Vθ30 , F̄θ30,λ )

0.04

Overlap O(F 30,λ , F̄ 30,λ )
θ
θ

1.00

0.23

O(Vθ50 , Fθ50,λ )

0.50

O(Fθ50,λ , F̄θ50,λ )

0.26

TABLE II: Weights of features assigned by randomized logistic
regression models
the gini impurity of λ non-adopters also shows its importance.
Intuitively, non-viral cascades are easier to be trapped in a
relatively small amount of communities. This means even if
they could show up in people’s timeline with high structural
diversity but can not get them infected.
IV.

ACKNOWLEDGMENT

This work is supported through the AFOSR Young Investigator Program (YIP), grant number FA9550-15-1-0159.
R EFERENCES
[1]

J. Cheng, L. Adamic, P. A. Dow, J. M. Kleinberg, and J. Leskovec,
“Can cascades be predicted?” in Proceedings of the 23rd international
conference on World wide web.
International World Wide Web
Conferences Steering Committee, 2014, pp. 925–936.
[2] P. Shakarian, A. Bhatnagar, A. Aleali, R. Guo, and E. Shaabani,
Diffusion in Social Networks. Springer (in press), 2015. [Online].
Available: http://lab.engineering.asu.edu/cysis/diffusion/
[3] J. Ugander, L. Backstrom, C. Marlow, and J. Kleinberg, “Structural
diversity in social contagion,” Proceedings of the National Academy of
Sciences, vol. 109, no. 16, pp. 5962–5966, 2012.
[4] L. Weng, F. Menczer, and Y.-Y. Ahn, “Predicting successful memes
using network and community structure,” in Eighth International AAAI
Conference on Weblogs and Social Media, 2014.

MANCaLog: A Logic for Multi-Attribute Network Cascades
(Technical Report)
Paulo Shakarian

Gerardo I. Simari

Robert Schroeder

Network Science Center and
Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY 10996

Dept. of Computer Science
University of Oxford
Wolfson Building, Parks Road
Oxford OX1 3QD, UK

CORE Lab
Defense Analysis Dept.
Naval Postgraduate School
Monterey, CA 93943

arXiv:1301.0302v2 [cs.AI] 19 Jan 2013

paulo@shakarian.net

gerardo.simari@cs.ox.ac.uk

ABSTRACT

rcschroe@nps.edu

I.2.4 [Artificial Intelligence]: Knowledge Representation
Formalisms and Methods—Representation Languages

variety of disciplines, including computer science [10], biology [11], sociology [8], economics [12], and physics [15].
Much existing work in this area is based on pre-existing
models in sociology and economics – in particular the work
of [8, 12]. However, recent examinations of social networks
– both analysis of large data sets and experimental – have
indicated that there may be additional factors to consider
that are not taken into account by these models. These
include the attributes of nodes and edges, competing diffusion processes, and time. In this paper, we outline seven
design criteria (Section 1.1) for such a framework and introduce MANCaLog (Section 2), which is to the best of our
knowledge the first logical language for modeling diffusion
in complex networks that meets these criteria. MANCaLog
is a rule-based framework (inspired by logic programming)
that can richly express how agents adopt or fail to adopt
certain behaviors, and how these behaviors cascade through
a network. We also introduce fixed-point based algorithms
that allow for the calculation of the result of the diffusion
process in Section 3. Note that these algorithms are proven
not only to be correct, but also to run in polynomial time.
Hence, our approach can not only better express many aspects of cascades in complex networks, but it can do so in
a reasonable amount of time. We conclude by discussing
applications of MANCaLog in Section 4.

General Terms

Proofs of all results stated in this paper can be found in the
appendix.

Languages, Algorithms

1.1

The modeling of cascade processes in multi-agent systems
in the form of complex networks has in recent years become
an important topic of study due to its many applications:
the adoption of commercial products, spread of disease, the
diffusion of an idea, etc. In this paper, we begin by identifying a desiderata of seven properties that a framework for
modeling such processes should satisfy: the ability to represent attributes of both nodes and edges, an explicit representation of time, the ability to represent non-Markovian
temporal relationships, representation of uncertain information, the ability to represent competing cascades, allowance
of non-monotonic diffusion, and computational tractability.
We then present the MANCaLog language, a formalism based
on logic programming that satisfies all these desiderata, and
focus on algorithms for finding minimal models (from which
the outcome of cascades can be obtained) as well as how
this formalism can be applied in real world scenarios. We
are not aware of any other formalism in the literature that
meets all of the above requirements.

Categories and Subject Descriptors

Keywords
Complex Networks, Cascades, Logic Programming

1.

INTRODUCTION AND RELATED WORK

An epidemic working through a population, cascading electrical power failures, product adoption, and the spread of
a mutant gene are all examples of diffusion processes that
can happen in multi-agent systems structured as complex
networks. These network processes have been studied in a
This is an extended version of MANCaLog: A Logic
for Multi-Attribute Network Cascades, which appears in: Proceedings of the 12th International Conference
on Autonomous Agents and Multiagent Systems (AAMAS
2013), Ito, Jonker, Gini, and Shehory (eds.), May 6–10,
2013, Saint Paul, Minnesota, USA.

Desiderata of Properties

We begin by identifying a set of criteria that we believe a
framework for reasoning about cascades in complex networks
should satisfy.
1. Multiply labeled and weighted nodes and edges.
Many existing frameworks for studying diffusion in complex
networks assume that there is only one type of vertex that
may become “active” [10] or may “mutate” [11, 15] and only
one possible relationship between nodes. In reality, nodes
and edges often have different properties. For instance, labels on edges can be used to differentiate between strong
and weak ties (edge types) – a concept that is well studied [7]. Recently, such attributes of nodes have been shown
to impact influence in a network [1].
2. Explicit Representation of Time. Most work in
the literature assumes static models, with the exception
of the recent developments in [4, 5, 6], which assume the
existence of a timestamped log referring to actions taken

in the network in order to learn how nodes influence each
other. Though [4] tackles the problem of predicting the
time at which a certain node will take an action, the authors make several simplifying assumptions such as monotonicity of probability functions, probabilistic independence,
sub-modularity and, most importantly for this criterion, a
modeling of time solely based on temporal decay of influence. We seek a richer model of temporal relationships between conditions in the network structure, the current state
of the cascades in process, and how influence propagates.
3. Non-Markovian Temporal Relationships. Apart
from time being explicitly represented, the temporal dependencies should be able to span multiple units of time. Hence,
the “memoryless” mode of a standard Markov process, where
only the information of the current state is required, is insufficient. Here, we strive to create a framework where dependencies can be from other earlier time steps. This issue has
been previously studied with respect to more general logic
programming frameworks such as [13], but to our knowledge
has not been applied to social networks.
4. Representation of Uncertainty. As in practice it is
not always possible to judge the attributes of all individuals
in a network, an element of uncertainty must be included.
However, in connection with point 7, this should not be at
the expense of tractability. For instance, the probabilistic
models of [10] are normally addressed with simulation (and
hence do not scale well) as the computation of the expected
number of activated nodes is a #P -hard problem [3].
5. Competing Cascades. Often, in real-world situations
there will be competing cascading processes. For example,
in evolutionary graph theory [11], “mutants” and “residents”
compete for nodes in the network – the success of one hinges
on the failure of the other.
6. Non-Monotonic Cascades. In much existing work on
cascades in complex networks, the number of nodes attaining a certain property at each time step can only increase.
However, if we allow for competing cascades in the same
model, we cannot have such a strong restriction as the success of one cascade may come at the expense of another.
7. Tractability. The social networks of interest in today’s
data mining problems often have millions of nodes. It is
reasonable to expect that soon billion-node networks will be
commonplace. Any framework for dealing with these problems must be solvable in a reasonable amount of time and
offer areas for practical improvement for further scalability.

1.2

Related Work

The above criteria can be summarized as the desire to
design the most expressive language for network cascades
possible while still allowing computation of the outcome of
a diffusion process to be completed in a tractable amount
of time. As a comparison, let us briefly describe some relevant related work. Perhaps the best known general model
for representing diffusion in complex networks is the independent cascade/linear threshold (IC/LT) model of [10].
However, although this framework was shown to be capable of expressing a wide variety of sociological models, it
assumes the Markov property and does not allow for the
representation of multiple attributes on vertices and edges.
A more recent framework, social network optimization problems (SNOPs) [14] uses logic programming to allow for the
representation of attributes, but this framework does not al-

 

1

 

3

 

7

 

8
 

5

 

6

 

 

2

 

4

 
10

 

9

Figure 1: Simple online social network Gsoc . Solid
edges are labeled with strTie, while dashed edges are
labeled with wkTie. White nodes are labeled with
male, while gray nodes are labeled with fem. Arrows
represent the direction of the edge; double-headed
edges represent two edges with the same label.
low for competing processes or non-monotonic cascades. A
related logic programming framework, competitive diffusion
(CD) [2] allows for competitive diffusion and non-monotonic
processes but does not explicitly represent time and also
makes Markovian assumptions. Further, we also note that
the semantics of CD yields a “most probable interpretation”
that is not a unique solution. Hence, a given model in
that framework can lead to multiple and possibly contradictory, outcomes to a cascade (this problem is avoided in
MANCaLog). Another popular class of models is Evolutionary Graph Theory (EGT) [11], which is highly related to
the voter model (VM) [15]. Although this framework allows for competing processes and non-monotonic diffusion,
it also makes Markovian assumptions while not explicitly
representing time. Further, determining the outcome of a
cascade in those models is NP-hard, while determining the
outcome in MANCaLog can be accomplished in polynomial
time. Table 1 lists how these models compare to MANCaLog
when considering our design criteria.

2.
2.1

FRAMEWORK
Syntax and Semantics

In this paper we assume that agents are arranged in a
directed graph (or network) G = (V, E), where the set of
nodes corresponds to the agents, and the edges model the
relationships between them. We also assume a set of labels
L, which is partitioned into two sets: fluent labels Lf (labels
that can change over time) and non-fluent labels Lnf (labels
that do not); labels can be applied to both the nodes and
edges of the network. We will use the notation G = V ∪ E
to be the set of all components (nodes and edges) in the
network. Thus, c ∈ G could be either a node or an edge.
Example 2.1. We will use the sample online social network Gsoc shown in Figure 1 as the running example; Gsoc is
used to denote the set of components of Gsoc . Here we have
Lnf = {male, fem, strTie, wkTie} representing male, female,
strong ties and weak ties, respectively. Additionally, we have
Lf = {visPgA, visPgB} representing visiting webpage A and
visiting webpage B, respectively.

In this paper, we present a logical language where we use
atoms, referring to labels and weights, to describe properties
of the nodes and edges. Though labels themselves could
be modeled as atoms instead of predicates (to model nonground labelings that allow for greater expressibility), for
simplicity of presentation we leave this to future work. The
first piece of the syntax is the network atom.

Table 1: Comparison with other models
Criterion
MANCaLog IC/LT [10] SNOP [14]
1. Labels
Yes
No
Yes
2. Explicit Representation of Time
Yes
No
Yes
3. Non-Markovian Temporal Relationships
Yes
No
No
4. Uncertainty
Yes
Yes
Yes
5. Competing Cascades
Yes
No
No
6. Non-monotonic Cascades
Yes
No
No
7. Tractablity
PTIME
#P-hard
PTIME

Definition 2.1 (Network Atom). Given label L ∈ L
and weight interval bnd ⊆ [0, 1], then hL, bnd i is a network atom. A network atom is fluent (resp., non-fluent) if
L ∈ Lf (resp., L ∈ Lnf ). We use N A to denote the set of
all possible network atoms.
Network atoms describe properties of nodes and edges.
The definition is intuitive: L represents a property of the
vertex or edge, and associated with this property is some
weight that may have associated uncertainty – hence represented as an interval bnd , which can be open or closed. An
invalid bound is represented by ∅, which is equivalent to all
other invalid bounds.
Definition 2.2 (World). A world W is a set of network atoms such that for each L ∈ L there is no more than
one network atom of the form hL, bnd i in W .
A network formula over N A is defined using conjunction, disjunction, and negation in the usual way. If a formula contains only non-fluent (resp., fluent) atoms, it is a
non-fluent (resp., fluent) formula.
Definition 2.3 (Satisfaction of Worlds). Given a
world W and network formula f , satisfaction of W by f
(denoted W |= f ) is defined:
• If f = hL, [0, 1]i then W |= f .
• If f = hL, ∅i then W 6|= f .
• If f = hL, bnd i, with bnd 6= ∅ and bnd 6= [0, 1], then
W |= f iff there exists hL, bnd 0 i ∈ W s.t. bnd 0 ⊆ bnd .
• If f = ¬f 0 then W |= f iff W 6|= f 0 .
• If f = f1 ∧ f2 then W |= f iff W |= f1 and W |= f2 .
• If f = f1 ∨ f2 then W |= f iff W |= f1 or W |= f2 .
For some arbitrary label L ∈ L, we will use the notation Tr = hL, [0, 1]i and F = hL, ∅i to represent a tautology
and contradiction, respectively. For ease of notation (and
without loss of generality), we say that if there does not
exist some bnd s.t. hL, bnd i ∈ W , then this implies that
hL, [0, 1]i ∈ W .
Example 2.2. Following from Example 2.1, the network
atom hf emale, [1, 1]i can be used to identify a node as a
woman. Likewise, the world W =
n
o
hfem, [1, 1]i, hmale, [0, 0]i, hvisPgA, [1, 1]i, hvisPgB, [0, 0]i

CD [2]
Yes
No
No
Yes
Yes
Yes
PTIME

EGT/VM [11]
No
Yes
No
Yes
Yes
Yes
NP-hard

might be used to identify a woman who visits webpage A.
Clearly, we have that W |=
hfem, [1, 1]i ∧ ¬hvisPgA, [0.5, 0.9]i ∧ ¬hvisPgB, [0.1, 0.7]i
Note that the network atoms formed with strTie and wkTie
are not present; this could be due to the fact that such a
world is used to describe a node and not an edge, and hence
there is no information about those two labels. As such is
the case, W |= hstrTie, [0, 1]i ∧ hwkTie, [0, 1]i.

The idea is to use MANCaLog to describe how properties
(specified by labels) of the nodes in the network change over
time. We assume that there is some natural number tmax
that specifies the total amount of time we are considering,
and we use τ = {t | t ∈ [0, tmax ]} to denote the set of all
time points. How well a certain property can be attributed
to a node is based on a weight (to which the bnd bound in
the network atom refers). As time progresses, a weight can
either increase/decrease and/or become more/less certain.
We now introduce the MANCaLog fact, which states that
some network atom is true for a node or edge during certain
times.
Definition 2.4 (MANCaLog Fact). If [t1 , t2 ] ⊆ [0, tmax ],
c ∈ G, and a ∈ N A, then (a, c) : [t1 , t2 ] is a MANCaLog
fact. A fact is fluent (resp., non-fluent) if atom a is fluent
(resp., non-fluent). All non-fluent facts must be of the form
(a, c) : [0, tmax ]. Let F be the set of all facts and Fnf , Ff be
the set of all non-fluent and fluent facts, respectively.
Example 2.3. Following from Example 2.2, the following
facts are based on Figure 1:
F1
F2
F3
F4

=
=
=
=

(hmale, [1, 1]i, 1) : [0, tmax ]
(hfem, [1, 1]i, 1) : [0, tmax ]
(hmale, [1, 1]i, 3) : [0, tmax ]
(hstrTie, [1, 1]i, (1, 2)) : [0, tmax ]

F5
F6
F7
F8

=
=
=
=

(hstrTie, [1, 1]i, (2, 1)) : [0, tmax ]
(hwkTie, [1, 1]i, (2, 3)) : [0, tmax ]
(hvisPgA, [0.8, 1.0]i, 1) : [0, tmax ]
(hvisPgA, [0.5, 1.0]i, 2) : [0, tmax ]

For instance, agent 1 is male, and has a strong tie to agent 2,
who is female.

Next, we introduce integrity constraints (ICs).
Definition 2.5. Given fluent network atom a and conjunction of network atoms b, an integrity constraint is of the
form a ←- b.

Intuitively, integrity constraint hL, bnd i ←- b means that
if at a certain time point a component (vertex or edge) of
the network has a set of properties specified by conjunction
b, then at that same time the component’s weight for label
L must be in interval bnd .
Example 2.4. Following from the previous examples, the
integrity constraint hmale, [0, 0]i ←- hfem, [1, 1]i would require any node designated as a female to not be male.

We now define MANCaLog rules. The idea behind rules is
simple: an agent that meets some criteria is influenced by
the set of its neighbors who possess certain properties. The
amount of influence exerted on an agent by its neighbors is
specified by an influence function, whose precise effects will
be described later on when we discuss the semantics. As a
result, a rule consists of four major parts: (i) an influence
function, (ii) neighbor criteria, (iii) target criteria, and (iv) a
target. Intuitively, (i) specifies how the neighbors influence
the agent in question, (ii) specifies which of the neighbors
can influence the agent, (iii) specifies the criteria that cause
the agent to be influenced, and (iv) is the property of the
agent that changes as a result of the influence.
We will discuss each of these parts in turn, and then define
rules in terms of these elements. First, we define influence
functions and neighbor criteria.
Definition 2.6 (Influence Function). An influence
function is a function ifl : N × N → [0, 1] × [0, 1] that satisfies the following two axioms:
1. ifl can be computed in constant (O(1)) time.
2. For x0 > x we have ifl (x0 , y) ⊆ ifl (x, y).
We use IFL to denote the set of all influence functions.
Intuitively, an influence function takes the number of qualifying influencers and the number of eligible influencers and
returns a bound on the new value for the weight of the property of the target node that changes. In practice, we expect
the time complexity of such a function to be a polynomial
in terms of the two arguments. However, as both arguments
are naturals bounded by the maximum degree of a node in
the network, this value will be much smaller than the size
of the network – we thus treat it as a constant here.
Example 2.5. The well-known “tipping model” originally
introduced in [8, 12] states that an agent adopts a behavior
when a certain fraction of his incoming neighbors do so. A
common tipping function is the majority threshold where
at least half of the agent’s neighbors must previously adopt
the behavior. We can represent this using the following influence function:
(
[1.0, 1.0] if x/y ≥ 0.5
tip(x, y) =
[0.0, 1.0] otherwise
This function says that an agent adopts a certain behavior
if at least half of his incoming neighbors have some property
(strong ties, weak ties, meet some requirement of gender,
income, etc.) and that we have no information otherwise.
In our framework, we can leverage the bounds associated with
the influence function to create a “soft” tipping function:
(
[0.7, 1.0] if x/y ≥ 0.5
sftTp(x, y) =
[0.0, 1.0] otherwise

Intuitively, the above function says that an agent adopts a
behavior with a weight of at least 0.7 if half of the incoming
neighbors that have some attribute and meet some criteria,
and we have no information otherwise. Another possibility
is to have an influence function that may reduce the weight
that an agent adopts a certain behavior:
(
[0.0, 0.2] if x = y
ngTp(x, y) =
[0.0, 1.0] otherwise
The ngTp function says that an agent will adopt a behavior with a weight no greater than 0.2 if all of the incoming
neighbors possessing some property meet some criteria, and
that we have no information otherwise.

Definition 2.7 (Neighbor Criterion). If gedge , gnode
are non-fluent network formulas (formed over edges and nodes,
respectively), h is a conjunction of network atoms, and ifl is
an influence function, then (gedge , gnode , h)ifl is a neighbor
criterion.
Formulas gnode and h in a neighbor criterion specify the
(non-fluent and fluent, respectively) criteria on a given neighbor, while formula gedge specifies the non-fluent criteria on
the directed edge from that neighbor to the node in question.
The next component is the “target criteria”, which are the
criteria that an agent must satisfy in order to be influenced
by its neighbors. Ideas such as “susceptibility” [1] can be
integrated into our framework via this component. We represent these criteria with a formula of non-fluent network
atoms. The final component, the “target”, is simply the label of the target agent that is influenced by its neighbors.
Hence, we now have all the pieces to define a rule.
Definition 2.8 (Rule). Given fluent label L, natural
number ∆t, target criteria f and neighbor criteria
(gedge , gnode , h)ifl , a MANCaLog Rule is of the form:
r=L

∆t

← f, (gedge , gnode , h)ifl

We will use the notation head(r) to denote L.
Note that the target (also referred to as the head) of the rule
is a single label; essentially, the body of the rule characterizes
a set of nodes, and this label is the one that is modified for
each node in this set. More specifically, the rule is essentially
saying that when certain conditions for an agent and its
neighbors are met, the bnd bound for the network atom
formed with label L on that agent changes. Later, in the
semantics, we introduce network interpretations, which map
components (nodes and edges) of the network to worlds at
a given point in time. The rule dictates how this mapping
changes in the next time step.
Definition 2.9 (MANCaLog Program). A program P
is a set of rules, facts, and integrity constraints s.t. each
non-fluent fact F ∈ Fnf appears no more than once in the
program. Let P be the set of all programs.
Example 2.6. Following from the previous examples, we
can have a MANCaLog program that leverage the sftTp and
ngTp influence functions in rules that are more expressive

Table 2: Example network interpretation, N I1 .
Comp.

male

fem

strTie

wkTie

visPgA

visPgB

1
2
3
4
5
(1,2)
(2,1)
(1,3)
(2,3)
(3,4)
(4,3)
(4,5)

[1, 1]
[0, 0]
[1, 1]
[0, 0]
[1, 1]
-

[0, 0]
[1, 1]
[0, 0]
[1, 1]
[0, 0]
-

[1, 1]
[1, 1]
[0, 0]
[0, 0]
[1, 1]
[1, 1]
[1, 1]

[0, 0]
[0, 0]
[1, 1]
[1, 1]
[0, 0]
[0, 0]
[0, 0]

[0.9, 1.0]
[0.0, 0.3]
[0.6, 1.0]
[0.0, 0.2]
[0.0, 0.2]
-

[0.8, 1.0]
[0.0, 0.2]
[0.0, 0.2]
[0.9, 1.0]
[0.7, 1.0]
-

than previous models. Consider the following rules:
2

R1

=

visPgA ←
hfem, [1, 1]i, (hstrTie, [0.9, 1]i, Tr, hvisPgA, [0.9, 1.0]i)sftTp

R2

=

visPgB ←
hmale, [1, 1]i, (Tr, Tr, hvisPgB, [0.8, 1.0]i)sftTp

R3

=

visPgA ←
hmale, [1, 1]i, (Tr, hfem, [1, 1]i, ¬hvisPgA, [0.7, 1.0]i)ngTp

1

3

Rule R1 says that a female agent in the network visits page
A with a weight of at least 0.7 (this is specified in the sftTp
influence function) if at least half of her strong ties (with
weight of at least 0.9) visited the page (with a weight of at
least 0.9) two days ago. The rest of the rules can be read
analogously.

We now introduce our first semantic structure: the network interpretation.
Definition 2.10 (Network Interpretation). A network interpretation is a mapping of network components to
sets of network atoms, N I : G → 2N A . We will use NI to
denote the set of all network interpretations.
We note that not all labels will necessarily apply to all
nodes and edges in the network. For instance, certain labels
may describe a relationship while others may only describe
a property of an individual in the network. If a given label L
does not describe a certain component c of the network, then
in a valid network interpretation N I, hL, [0, 1]i ∈ N I(c).
Example 2.7. Consider G0soc , the induced subgraph of Gsoc
that has only nodes {1, 2, 3, 4, 5}. Table 2 shows the contents
of N I1 , an example network interpretation.


Example 2.8. Consider interpretation I1 , where I1 (0) =
N I1 (from Example 2.7), and MANCaLog facts F7 and F8
from Example 2.3. In this case, I1 |= F7 and I1 6|= F8 .

For non-fluent facts, we introduce the notion of strict satisfaction, which enforces the bound in the interpretation to
be set to exactly what the fact dictates.
Definition 2.13 (Strict Fact Satisfaction). Interpretation I strictly satisfies MANCaLog fact (c, a) : [t1 , t2 ]
iff ∀t ∈ [t1 , t2 ], a ∈ I(t)(c).
Next, we define what it means for an interpretation to
satisfy an integrity constraint.
Definition 2.14 (IC Satisfaction). An interpretation
I satisfies integrity constraint a ←- b iff for all t ∈ τ and
c ∈ G, I(t)(c) |= ¬b ∨ a.
Before we define what it means for an interpretation to
satisfy a rule, we require two auxiliary definitions that are
used to define the bound enforced on a label by a given rule,
and the set of time points that are affected by a rule.
Definition 2.15

(Bound function). For a given rule

∆t

r = L ← f, (gedge , gnode , h)ifl , node v, and network interpretation N I, Bound (r, v, N I) =

 


ifl Qual v, gedge , gnode , h, N I , Elig v, gedge , gnode , N I  ,
where Elig(v, gedge , gnode , N I) =
n
o

v 0 ∈ V | N I(v 0 ) |= gnode ∧(v 0 , v) ∈ E∧N I (v 0 , v) |= gedge
and Qual (v, gedge , gnode , h, N I) =
n
o
v 0 ∈ Elig(v, gedge , gnode , N I) | N I(v 0 ) |= h
Intuitively, the bound returned by the function depends on
the influence function and the number of qualifying and eligible nodes that influence it.
Definition 2.16

(Target Time Set). For interpreta∆t

tion I, node v, and rule r = L ← f, (gedge , gnode , h)ifl , the
target time set of I, v, r is defined as follows:
n
o
TTS (I, v, r) = t ∈ [0, tmax ] | I(t − ∆t)(v) |= f
We also extend this definition to a program P , for a given
c ∈ G and L ∈ L, as follows; TTS (I, c, L, P ) =

We define a MANCaLog interpretation as follows.
[

Definition 2.11 (Interpretation). A MANCaLog interpretation I is a mapping of natural numbers in the interval [0, tmax ] to network interpretations, i.e., I : N → NI.
Let I be the set of all possible interpretations.

2.2

Satisfaction

First, we define what it means for an interpretation to
satisfy a fact and a rule.
Definition 2.12 (Fact Satisfaction). An interpretation I satisfies MANCaLog fact (a, c) : [t1 , t2 ], written I |=
(a, c) : [t1 , t2 ], iff ∀t ∈ [t1 , t2 ], I(t)(c) |= a.


	
TTS (I, c, r)∪ t ∈ [t1 , t2 ] | (hL, bndi, c) : [t1 , t2 ] ∈ P

r∈P,head(r)=L

∪

n

t | hL, bndi ←- b ∈ P ∧ I(t)(c) |= b

o

We can now define satisfaction of a rule by an interpretation.
Definition 2.17. An interpretation I satisfies a rule r =
∆t
L ← f, (gedge , gnode , h)ifl iff for all v ∈ V and t ∈ TTS (I, v, r)
it holds that
D
E
I(t)(v) |= L, Bound r, v, I(t − ∆t) .

Example 2.9. Let I1 be the interpretation from Example 2.8. Suppose that hvisPgB, [0.8, 1.0]i ∈ I(1)(5). In this
case, I1 |= R2 . Let I2 be equivalent to I1 except that we have
hvisPgB, [0.0, 0.5]i ∈ I2 (1)(3). In this case, I2 6|= R2 .

We now define satisfaction of programs, and introduce
canonical interpretations, in which time points that are not
“targets” retain information from the last time step.
Definition 2.18. For interpretation I and program P :
I is a model for P iff it satisfies all rules, integrity constraints, and fluent facts in that program, strictly satisfies
all non-fluent facts in the program, and for all L ∈ L, c ∈ G
and t ∈
/ TTS (I, c, L, P ), hL, [0, 1]i ∈ I(c)(t).
I is a canonical model for P iff it satisfies all rules, integrity constraints, and fluent facts in P , strictly satisfies
all non-fluent facts in P , and for all L ∈ L, c ∈ G, and
t ∈
/ TTS (I, c, L, P ), hL, [0, 1]i ∈ I(c)(t) when t = 0 and
hL, bndi ∈ I(t)(c) where hL, bndi ∈ I(t − 1)(c), otherwise.
Example 2.10. Following from previous examples, if we
consider interpretation I1 and program P = {F7 , R2 }, we
have that hvisPgB, [0.0, 0.2]i must be in I1 (1)(2) in order for
I1 to be canonical.


2.3

Consistency and Entailment

In this section we discuss consistency and entailment in
MANCaLog programs, and explore the use of minimal models towards computing answers to these problems.
Definition 2.19 (Consistency). A MANCaLog program P is (canonically) consistent iff there exists a (canonical) model I of P .
Definition 2.20 (Entailment). A MANCaLog program
P (canonically) entails MANCaLog fact F iff for all (canonical) models I of P , it holds that I |= F .
Now we define an ordering over models and define the concept of minimal model. We then show that if we can find a
minimal model then we can answer consistency, entailment,
and tight entailment queries. To do so, we first define a
pre-order over interpretations.
Definition 2.21 (Preorder over Interpretations).
Given interpretations I, I 0 we say I vpre I 0 if and only if for
all t, v, L if there exists hL, bnd i ∈ I(t)(v) then there must
exist hL, bnd 0 i ∈ I 0 (t)(v) s.t. bnd 0 ⊆ bnd .
Next, we define an equivalence relation for interpretations
denoted with ∼; we will use the notation [I] for the set of
all interpretations equivalent to I w.r.t. ∼. This allows us
to define a partial ordering.
Definition 2.22. Two interpretations I, I 0 are equivalent (written I ∼ I 0 ) iff for all P ∈ P, I |= P iff I 0 |= P .
Definition 2.23 (Partial Ordering). Given classes
of interpretations [I], [I 0 ] that are equivalent w.r.t. ∼, we say
that [I] precedes [I 0 ], written [I] v [I 0 ], iff I vpre I 0 .
The partial ordering is clearly reflexive, antisymmetric,
and transitive. Note that we will often use I v I 0 as shorthand for [I] v [I 0 ]. We define two special interpretations, ⊥
and >, such that ∀t ∈ τ, c ∈ G, ⊥(t)(c) = ∅ and there exists

network atom hL, ∅i ∈ >(t)(c). Clearly, no other interpretation can be below ⊥ as the [`, u] bound on all network atoms
for each time step and each component is [0, 1]; similarly, no
other interpretation is above >, since for any interpretation
I for which there exists hL, bnd i ∈ I(t)(c) where bnd 6= ∅,
we have ∅ ⊆ bnd . We can prove (see the full version of the
paper for details) that with > and ⊥, hI, vi is a complete
lattice. We can now arrive at the notion of minimal model
for a MANCaLog program.
Definition 2.24 (Minimal Model). Given program P ,
the minimal model of P is a (canonical) interpretation I s.t.
I |= P and for all (canonical) interpretation I 0 s.t. I 0 |= P ,
we have that I v I 0 .
Suppose we have some algorithm A that takes as input
a program P and returns an interpretation I (where I does
not necessarily satisfy P ) s.t. for all I 0 where I 0 |= P , I v I 0 .
It is easy to show that if A(P ) |= P then P is consistent.
Likewise, if A(P ) = > then P is inconsistent, as all models must then have a tighter weight bound for the network
atoms than an invalid interpretation (hence, making such an
interpretation invalid as well). Clearly, any such algorithm
A would provide a sound and complete answer to the consistency problem. Likewise, if we consider the entailment problem, it is easy to show that for fact F = (hL, bnd i, c) : [t1 , t2 ],
P (canonically) entails F iff the minimal model of P (canonically) satisfies F . This is because for minimal model A(P )
of P , for any time t ∈ [t1 , t2 ], if A(P )(t)(c) |= hL, bnd i then
there is network atom hL, bnd 0 i ∈ A(P )(t)(c) s.t. bnd 0 ⊆
bnd . We note that for any other interpretation I of P with
hL, bnd 00 i ∈ I(t)(c) we have that bnd 0 ⊇ bnd 00 . Hence, having a minimal model allows us to solve any entailment query.
We can think of a minimal model of a MANCaLog program
as the outcome of a diffusion process in a multi-agent system
modeled as a complex network. Hence, a question such as
“how many agents will adopt the product with a weight of
at least 0.9 in two months?” can be easily answered once
the minimal model is obtained.

3.

FIXED POINT MODEL COMPUTATION

In this section we introduce a fixed-point operator that
produces the non-canonical minimal model of a MANCaLog
program in polynomial time. This is followed by an algorithm to find a canonical minimal model also in polynomial
time. First, we introduce three preliminary definitions.
Definition 3.1. For a given MANCaLog program P , c ∈
G, L ∈ L, and t ∈ τ we define function FBnd (P, c, t, L) =
\
bnd
(hL,bndi,c):[t1 ,t2 ]∈P s.t. t∈[t1 ,t2 ]

Definition 3.2. For a given MANCaLog program P , c ∈
G, L ∈ L, and t ∈ τ we define function IBnd (P, c, t, L) =
\
bnd
hL,bndi←-a∈P s.t. I(t)(c)|=a

Definition 3.3. Given MANCaLog program P , interpretation I, v ∈ V , L ∈ L, and t ∈ τ , we define RBnd (P, I, v, t, L) =
\
Bound (r, v, I(t − ∆t))
r∈P s.t. t∈TTS (I,v,L,P )∩TTS (I,v,r)

We can now introduce the operator.
Definition 3.4 (Γ Operator). For a given MANCaLog
program P , we define the operator ΓP : I → I as follows:
For a given I, for each t ∈ τ , c ∈ G, and L ∈ L, add hL, bnd i
to ΓP (I)(t)(c) where bnd is defined as:
bnd

= bnd prv ∩ FBnd (P, c, t, L) ∩
IBnd (P, I, c, t, L) ∩ RBnd (P, I, c, t, L)

where hL, bnd prv i ∈ I(t)(c).
It is easy to show that Γ can be computed in polynomial
time (the proof is in the full version). Next, we introduce
notation for repeated applications of Γ.
Definition 3.5 (Iterated Applications of Γ). Given
natural number i > 0, interpretation I, and program P , we
define ΓiP (I), the multiple applications of Γ, as follows:
(
ΓP (I)
if i = 1
i
ΓP (I) =
ΓP (Γi−1
(I))
otherwise
P

Algorithm 1 CANON PROC
Require: Program P
Ensure: Interpretation I

1: cur interp = Γ∗P (⊥);
2: Initialize matrix array cur f ree[·][·] where for v ∈ V, and
L ∈ L, cur f ree[v][L] = τ − TTS (cur interp, v, L, P ) − {0};

3: Initialize array vl pr[·] where for each t ∈ [1, tmax ], vl pr[t] =
{(v, L) | t ∈ cur f ree[v][L]};

4: for t = 1, . . . , tmax do
5:
if vl pr[t] 6= ∅ then
6:
for (v, L) ∈ vl pr[t] do
7:
Remove hL, bndi from I(t)(v);
8:
Let a be the atom in I(t − 1)(v) of the form hL, bnd0 i;
9:
10:
11:
12:
13:

Add a to I(t)(v);
end for
Set cur interp = Γ∗P (cur interp);
end if
For v ∈ V , and L ∈ L, cur f ree[v][L] = τ −
TTS (cur interp, v, L, P ) − {0, . . . , t}
14:
For each t ∈ [t + 1, tmax ], vl pr[t] = {(v, L) | t ∈
cur f ree[v][L]}
15: end for
16: return I

We can prove that the iterated Γ operator converges after a
polynomial number of applications:
Theorem 3.1. Given interpretation I and program P ,
(I), and
there exists a natural number k s.t. ΓkP (I) = Γk+1
P


k ∈ O |P | · din
∗ · tmax · |E|
where din
∗ is the maximum in-degree in the network.
Proof (sketch). For a given vertex i ∈ V , we will use
the notation din
i to denote the number of incoming neighbors
(of any edge type). First note that for a given t ∈ τ, i ∈ V,
and L ∈ L, a given rule r can tighten the bound on a network
in
atom formed with L no more than (din
i + 1) · (d∗ + 1) times.
At each application of Γ, at least one
 network atom must

tighten. Hence, as there are only O |P | · din
∗ · tmax · |E|
tightenings possible, this is also the bound on the number
of applications of Γ.
In the following, we will use the notation Γ∗P to denote the
iterated application of Γ after a number of steps sufficient
for convergence; Theorem 3.1 means that we can efficiently
compute Γ∗P . We also note that as a single application of Γ
can be computed in polynomial time, this implies that we
can find a minimal model of a MANCaLog program in polynomial time. We now prove the correctness of the operator.
We do this first by proving a key lemma that, when combined with a claim showing that for consistent program P ,
Γ∗P is a model of P , tells us that Γ∗P is a minimal model for P .
Following directly from this, we have that P is inconsistent
iff Γ∗P = >.
Lemma 3.2. If I |= P and I 0 v I then Γ(I 0 ) v I.
Theorem 3.3. If program P is consistent then Γ∗P is a
minimal model for P .
These results, when taken together, prove that tight entailment and consistency problems for MANCaLog can be solved
in polynomial time, which is precisely what we set out to accomplish as part of our desiderata described in Section 1.1.
Next, we develop an algorithm for the canonical versions

of consistency and tight entailment, and show that we can
bound the running time of the algorithm with a polynomial.
We also note that subsequent runs of the convergence of Γ
will likely complete quicker in practice, as the initial interpretation is the last interpretation calculated (cf. line 11).
We also show that the interpretation produced by the algorithm is a canonical minimal model. Following from that, a
program is inconsistent iff the algorithm returns >.
Proposition 3.1. Algorithm CANON PROC performs no
more than 1+tmax ·min(|L|, |P |)·|V | calculations of the convergence of Γ.
Theorem 3.4. If P is consistent, then CANON PROC(P )
is the minimal canonical model of P .

4.

APPLICATIONS

In this section, we will briefly discuss work in progress on
how MANCaLog can be applied in real world settings.
It is widely acknowledged that modeling influence in multiagent systems (most usefully modeled as complex networks)
is highly desirable for many practical problems as varied
as viral marketing, prevention of drug use, vaccination, and
power plant failure. Though MANCaLog programs are a rich
model to work with, the acquisition of rules is the principal
hurdle to overcome; this is mainly due to this richness of
representation, since for each rule we must provide a set
of conditions on the agents being influenced, conditions on
their neighbors and their ties to their neighbors, and how
capable these neighbors are of influencing them. A domain
expert is likely able to provide important insights into these
components, but the best way to obtain these rules is undoubtedly to leverage the presence of large amounts of data
in domains like Twitter (with about 340M messages sent per
day, available through public APIs), Facebook (over 950M
users with more complex information; not publicly available,
but data can be requested through apps), and blogging and
photo hosting sites such as Blogger and Flickr (which have
millions of users as well).

…
Data Sources

Clustering

Influence &
Susceptibility

Rule
Generation

MANCaLog
Program

Expert
Knowledge

Figure 2: An architecture for obtaining MANCaLog
programs from available data sources.
Concretely, we have begun working towards this goal by
extracting several time-series, multi-attribute network data
sets on which to apply MANCaLog. For instance, to study
the proliferation of research on different topics, we looked
at research on “niacin” indexed by Thomson Reuters Web
of Knowledge (http://wokinfo.com). This topic was chosen due to its interest to a variety of disciplines, such as
medicine, biology, and chemistry; this gives the data more
variety compared with more discipline-specific topics. We
extracted an author-paper bipartite network consisting of
3, 790 papers with 10, 465 authors and 16, 722 edges (cf. Figure 3); from this data we can easily focus on various kinds of
networks (co-author, citation, etc.). We have also collected
attribute and time-series data for this network, as well as
the subjects of the papers; the propagation of these subjects
is a good starting point to test methods for the acquisition
of MANCaLog rules. We are harvesting larger datasets from
various online social networks. Further details can be found
in the full version of the paper.
A proposed learning architecture. We are currently
developing a MANCaLog learning architecture (depicted in
Fig. 2) based on the use of state-of-the-art data analysis,
clustering, and influence learning techniques as building blocks
for the acquisition of MANCaLog rules from data sets. The
key question is not just the identification of the best techniques to adopt, but how to adapt them and combine them
in such a way as to produce meaningful and useful outputs.
Consider the diagram in Fig. 2: the data first flows from
raw data sources to the cluster identification component,
which has the goal of identifying sets of agents behaving
as groups (for instance, teens influencing other teens of the
same sex in the consumption of music, or scientists of a certain field influencing the research topics of others in a related
field) [16, 9]; the main output here is a set of conditions on
nodes and edges that characterize groups of nodes. Once
clusters are identified, the influence recognition component
will make use of both the clusters and the data sources to
recognize what kind of influence is present in the system [1,
5, 6]; the main output of this component is the influence
function to be used in the MANCaLog rules. The rule generation component then takes the output of the cluster identification and influence recognition components, along with
the raw data (e.g., to analyze time stamps) and produces
MANCaLog rules; the output of this component is involved
in a refinement cycle with experts who can provide feedback
on the rules being produced (such as possible combinations
of rules, identification of cases of overfitting, etc.).

Figure 3: (Left) Visualization of a multi-attribute
time-series author-paper network from 1952 to 2012.
(Top-Right) Close-up of the data inside the small box
in the main figure. (Bottom-Right) Close-up showing
node attributes. In all cases, authors are colored
green and papers are colored red. Data extracted
from Thomson Reuters Web of Knowledge.

5.

CONCLUSION

In this paper, we presented the MANCaLog language for
modeling cascades in multi-agent systems organized in the
form of complex networks. We started by establishing seven
criteria in the form of desiderata for such a formalism, and
proved that MANCaLog meets all of them; to the best of our
knowledge, this has not been accomplished by any previous
model in the literature. We also note that MANCaLog is the
first language of its kind to consider network structure in
the semantics, potentially opening the door for algorithms
that leverage features of network topology in more efficiently
answering queries. Our current work involves implementing
the algorithms described in this paper, as well as the realworld applications described in Section 4; though our algorithms have polynomial time complexity, it is likely that
further optimizations will be needed in practice to ensure
scalability for very large data sets.
In the near future, we shall also explore various types
of queries that have been studied in the literature, such
as finding agents of maximum influence, identifying agents
that cause a cascade to spread more quickly, and identifying
agents that can be influenced in order to halt a cascade.

6.

ACKNOWLEDGMENTS

P.S. is supported by the Army Research Office (project
2GDATXR042). G.I.S. is supported under (UK) EPSRC
grant EP/J008346/1 – PrOQAW. The opinions in this paper
are those of the authors and do not necessarily reflect the
opinions of the funders, the U.S. Military Academy, or the
U.S. Army.

7.

REFERENCES

[1] S. Aral and D. Walker. Identifying Influential and
Susceptible Members of Social Networks. Science,
337(6092):337–341, 2012.
[2] M. Broecheler, P. Shakarian, and V. Subrahmanian. A
scalable framework for modeling competitive diffusion
in social networks. In Proc. of SocialCom. IEEE, 2010.
[3] W. Chen, C. Wang, and Y. Wang. Scalable influence
maximization for prevalent viral marketing in
large-scale social networks. In Proc. of KDD ’10,
pages 1029–1038. ACM, 2010.
[4] A. Goyal, F. Bonchi, and L. Lakshmanan. Discovering
leaders from community actions. In Proc. of CIKM,
pages 499–508. ACM, 2008.
[5] A. Goyal, F. Bonchi, and L. Lakshmanan. Learning
influence probabilities in social networks. In Proc. of
WSDM, pages 241–250. ACM, 2010.
[6] A. Goyal, F. Bonchi, and L. Lakshmanan. A
data-based approach to social influence maximization.
Proc. of VLDB, 5(1):73–84, 2011.
[7] M. Granovetter. The Strength of Weak Ties. The
American Journal of Sociology, 78(6):1360–1380, 1973.
[8] M. Granovetter. Threshold models of collective
behavior. The American Journal of Sociology,
83(6):1420–1443, 1978.
[9] A. Jain. Data clustering: 50 years beyond K-means.
Pattern Recognition Letters, 31(8):651–666, 2010.
[10] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing
the spread of influence through a social network. In
Proc. of KDD ’03, pages 137–146. ACM, 2003.
[11] E. Lieberman, C. Hauert, and M. A. Nowak.
Evolutionary dynamics on graphs. Nature,
433(7023):312–316, 2005.
[12] T. C. Schelling. Micromotives and Macrobehavior.
W.W. Norton and Co., 1978.
[13] P. Shakarian, A. Parker, G. I. Simari, and V. S.
Subrahmanian. Annotated probabilstic temporal logic.
ACM Trans. on Comp. Logic, 12(2), 2011.
[14] P. Shakarian, V. Subrahmanian, and M. L. Sapino.
Using Generalized Annotated Programs to Solve
Social Network Optimization Problems. In Proc. of
ICLP (tech. comm.), 2010.
[15] V. Sood, T. Antal, and S. Redner. Voter models on
heterogeneous networks. Physical Review E,
77(4):041121, 2008.
[16] T. Warren Liao. Clustering of time series data–a
survey. Pattern Recognition, 38(11):1857–1874, 2005.

8.
8.1

APPENDIX
Set of interpretations form a complete lattice

With top interpretation > and bottom interpretation ⊥,
hI, vi is a complete lattice.
Proof. Let I 0 be a subset of I. We can create inf (I 0 )
as follows. We build interpretation I 0 . For each t ∈ τ, c ∈
G, L ∈ L, let `1 be the least of the set ∪I∈I 0 {`|hL, [`, u]i ∈
I(t)(c), hL, [`, u)i ∈ I(t)(c)} and `2 be the least of the set
∪I∈I 0 {`|hL, (`, u]i ∈ I(t)(c), hL, (`, u)i ∈ I(t)(c)}. Then, for
each t ∈ τ, c ∈ G, L ∈ L let u1 be the greatest element of the
set ∪I∈I 0 {u|hL, [`, u]i ∈ I(t)(c), hL, (`, u]i ∈ I(t)(c)}
and u2 be the greatest of the set
∪I∈I 0 {u|hL, [`, u)i ∈ I(t)(c), hL, (`, u)i ∈ I(t)(c)}. If there is
any interpretation I in I where there is not some bnd s.t.
hL, bnd i ∈ I(t)(c) then add hL, [0, 1]i to I 0 (t)(c). If `2 ≤ `1
and u1 ≥ u2 then add hL, (`2 , u1 ]i to I 0 (t)(c). If `2 ≤ `1 and
u2 > u1 then add hL, (`2 , u2 )i to I 0 (t)(c). If `2 > `1 and
u2 > u1 then add hL, [`1 , u2 )i to I 0 (t)(c). Finally, if `2 > `1
and u1 ≥ u2 then add hL, [`1 , u1 ]i to I 0 (t)(c). Clearly, I 0 =
inf (I 0 ).
In the next part of the proof, we show we can create
sup(I 0 ) as follows. We build interpretation I 0 . For each
t ∈ τ, c ∈ G, L ∈ L let `1 be the greatest of the set
∪I∈I 0 {`|hL, [`, u]i ∈ I(t)(c), hL, [`, u)i ∈ I(t)(c)} and `2 be
the greatest of the set
∪I∈I 0 {`|hL, (`, u]i ∈ I(t)(c), hL, (`, u)i ∈ I(t)(c)}. Then, for
each t ∈ τ, c ∈ G, L ∈ L let u1 be the least element of the set
∪I∈I 0 {u|hL, [`, u]i ∈ I(t)(c), hL, (`, u]i ∈ I(t)(c)} and u2 be
the least of the set ∪I∈I 0 {u|hL, [`, u)i ∈ I(t)(c), hL, (`, u)i ∈
I(t)(c)}. If max(`1 , `2 ) > min(u1 , u2 ) or (`2 > `1 ) ∧ (u2 <
u1 ) ∧ (`2 = u2 ) then add hL, ∅i to I 0 (t)(c). If `2 > `1 and
u1 ≤ u2 then add hL, (`2 , u1 ]i to I 0 (t)(c). If `2 > `1 and
u2 < u1 then add hL, (`2 , u2 )i to I 0 (t)(c). If `2 ≤ `1 and
u2 < u1 then add hL, [`1 , u2 )i to I 0 (t)(c). Finally, if `2 ≤ `1
and u1 ≤ u2 then add hL, [`1 , u1 ]i to I 0 (t)(c). Clearly,
I 0 = sup(I 0 ).
As both inf (I 0 ) and sup(I 0 ) exist and are clearly in I then
the statement follows.

8.2

A single application of Γ can be computed
in polynomial time

For interpretation I, Γ(I) can be computed by conducting
in
O(|P |·|V |·tmax ·din
∗ ) satisfaction checks where d∗ is the maximum in-degree of a node in the network. (This combined
with the assumption that the influence function is computed
in constant time results in polynomial time computation for
a single application of Γ.)
Proof. We note that a given rule will require the most
satisfaction checks, as a rule will potentially affect a network
atom of a certain label for each vertex-time point pair. By
the definition of RBnd , a given rule clearly causes no more
than O(din
∗ ) satisfaction checks. As the number of rules is
no more than |P |, the statement follows.

8.3

Proof of Theorem 3.1

Given interpretation I and program P , there exists a natural number k s.t. ΓkP (I) = Γk+1
(I), and
P


k ∈ O |P | · din
∗ · tmax · |E|
where din
∗ is the maximum in-degree in the network.
Proof. For a given vertex i ∈ V , we will use the notation
din
to denote the number of incoming neighbors (of any
i
in
edge type) and din
∗ = maxi di . First we show that for a
given t ∈ τ, i ∈ V, and L ∈ L, a given rule r can tighten
the bound on a network atom formed with L no more than
in
(din
i + 1) · (d∗ + 1) times. This is because a given rule
adjusts the bound on a network atom based on the number
of eligible and qualifying neighbors, which are bounded by
in
din
i , d∗ respectively. At each application of Γ, at least
 one
network atom must tighten. Hence, as there are only O |P |·


P in 
din
=O |P | · din
tightenings
∗ · tmax ·
∗ · tmax · |E|
i di
possible, this is also the bound on the number of applications
of Γ.

8.4

Proof of Lemma 3.2

If I |= P and I 0 v I then Γ(I 0 ) v I.
Proof. Suppose, BWOC, that Γ(I 0 ) = I. Then, there
exists some L ∈ L, t ∈ τ and c ∈ G s.t. hL, bnd i ∈ I(t)(c),
hL, bnd 0 i ∈ I 0 (t)(c), and hL, bnd 00 i ∈ Γ(I 0 )(t)(c) s.t. bnd ⊃
bnd 00 and bnd 0 ⊇ bnd 00 . There are four things that affect
bnd 00 : facts, rules, integrity constraints and bnd 0 . Clearly,
we need not consider the effect that either facts or bnd 0
have on bnd 00 , as I satisfies all facts and I 0 v I. We also
note that a given integrity constraint imposed by Definition 3.2 can tighten bnd 00 no more than the associated bound
∆t
in any model. Hence, there must be some rule r = L ←
00
f, (gedge , gnode , h)ifl that causes bnd to become less than
bnd . As bnd 00 6= bnd 0 , we know that t ∈ TTS (Γ(I 0 ), c, r) ∩
TTS (I 0 , c, r). As a result, we have Γ(I 0 )(t − ∆t)(c) |= f and
I 0 (t − ∆t)(c) |= f . Further, as I |= P, I 0 v I, and no rule
can modify a non-fluent atom, we have
|Elig(v, gedge , gnode , Γ(I 0 )(t − ∆t)| =
|Elig(v, gedge , gnode , I 0 (t − ∆t)| =
|Elig(v, gedge , gnode , Γ(I 0 )(t − ∆t)|.
Further, we know that as I 0 v I, it must be the case that
|Qual (v, gedge , gnode , h, I(t − ∆t))| ≥
|Qual (v, gedge , gnode , h, I 0 (t − ∆t))|.
This implies, by Axiom 2 that, Bound (r, v, I(t − ∆t)) ⊆
Bound (r, v, I 0 (t − ∆t)). This then implies that bnd ⊆ bnd 00 ,
which is a contradiction.

8.5

Proof of Theorem 3.3

Γ∗P is a minimal model for P .
Proof. Claim: If program P is consistent then Γ∗P is a
model of P .
Suppose, BWOC, that there is a fact in P that Γ∗P does not
satisfy. However, by the definition of Γ and the definition of
a fact, Γ∗P must satisfy all facts as the bound on the weight
associated with each fact is included in the intersection. Further, we can also see by the definition of Γ that Γ∗P strictly

satisfies all non-fluent facts in P . We also note that the final application of the Γ operator ensures that all integrity
constraints are satisfied by Γ∗P . Now, Suppose, BWOC, that
there is a rule in P that Γ∗P does not satisfy. However, with
each application of Γ, for each rule, we include the bound
on the weight returned by the Bound function for each time
step in the target time step associated with that rule. As Γ
is applied to convergence, and new bounds are intersected
with each application, then we know that all time points in
any associated target time set are considered in the intersection.
Proof of Theorem: The above claim tells us that Γ∗P |= P .
Now consider interpretation I s.t. I |= P . As ⊥ v I, multiple applications of Lemma 3.2 tell us that Γ∗P v I. Hence,
the statement follows.

8.6

Proof of Theorem 3.4

If P is consistent, then CANON PROC(P ) is the minimal
canonical model of P .
Proof. CLAIM 1: If P is consistent, then CANON PROC(P )
is a canonical model of P .
Clearly, I = CANON PROC(P ) satisfies all facts and integrity constraints in P . Hence, we shall consider programs
that only consist of rules in this proof. We say I L-canonically
satisfies P iff I canonically satisfies {r ∈ P | head(r) = L}.
Clearly, I canonically satisfies P if for all L ∈ L, P Lcanonically satisfies by I. We say that I is an (L, c, q)canonically consistent interpretation if for c ∈ G, for the
first t ∈ τ − TTS (I, c, L, P ) − {0}, I(t)(c) |= hL, bndi where
hL, bndi ∈ I(t − 1)(c). Consider some L ∈ L and c ∈ G.
Clearly, I is an (L, c, 0)-model for P . Let us assume, for
some value q, that I is an (L, c, q − 1) model for P . Let time
point t be the q-th element of τ − TTS (I, c, L, P ) − {0}.
Consider the time step before time t is considered in the forloop at line 4 of CANON PROC, which causes the condition
at line 5 to be true. By line 13, τ − TTS (I, c, L, P ) − {0} ⊆
cur f ree[c][L]. This means that t is a member of both.
Hence, when t is considered at line 4, the condition at line 5
is true, causing hL, bndi ∈ I(t)(c) ∩ I(t − 1)(c) and as the
element hL, bndi ∈ I(t − 1)(c) is not changed here, we have
shown the I is an (L, c, q)-model for P . By the for-loop at
line 6, for all L ∈ L and c ∈ G, I is an (L, c, q)-model for P .
Hence, at the for-loop at line 4, we can be assured that for
L ∈ L and c ∈ G that I (L, c, |τ − TTS (I, c, L, P ) − {0}|)
satisfies P – which means that I canonically satisfies P
CLAIM 2: If I is a canonical model for P ,
cur interp v I is an interpretation that also strictly satisfies
all non-fluent facts in P , and cur interp0 is cur interp after being manipulated in lines 6-10 of CANON PROC, then
cur interp0 v I.
We note that by the definition of satisfaction of a nonfluent fact, and the fact that both cur interp and I must
strictly satisfy all non-fluent facts in P , we know that for all
c ∈ G and L ∈ L that:
T T S(I, c, L, P )

= T T S(cur interp, c, L, P )
= T T S(cur interp0 , c, L, P )

Let us assume that lines 6-10 of the algorithm are changing
cur interp when the outer loop is considering time t and
that the condition at line 5 is true. Clearly,
t ∈ τ − T T S(I, v 0 , L0 , P ) − {0}

As a result, for any (v, L) pair considered at this point
by the algorithm, if hL, bnd i ∈ I(t)(v) and hL, bnd 0 i ∈
I(t − 1)(v) then we have bnd = bnd 0 . By the algorithm,
if we have hL, bnd ∗ i ∈ cur interp0 (t)(v) and hL, bnd ∗∗ i ∈
cur interp0 (t − 1)(v) we have that bnd ∗ = bnd ∗∗ . As
hL, bnd ∗∗ i ∈ cur interp(t − 1)(v), we know that bnd 0 ⊆
bnd ∗∗ . As a result, we have cur interp0 v I, completing the
claim.
Proof of theorem: As initially cur interp = Γ∗P and Γ∗P v I
by Theorem 3.3, we note that the algorithm changes
cur interp either by applying Γ or manipulating it in lines 610, which tells us (by claim 2) that for all models I of P that
CANON PROC(P ) v I. Since by claim 1 we know that
CANON PROC(P ) |= P , the statement of the theorem follows.

8.7

Details on the Extracted Dataset

One way in which MANCaLog can be used is looking at
proliferation of research on different topics. We look at
research conducted on niacin, an organic compound commonly used for increasing levels of high density lipoproteins (HDL). Using Thomson Reuters Web of Knowledge
(http://wokinfo.com) we were able to extract information
on 4, 202 articles about niacin. This information was then
processed using the Science of Science (Sci2 ) Tool (http:
//sci2.cns.iu.edu) to extract numerous different networks
such as author by paper networks, citation networks, and paper by subject networks. Each paper has attributes about
when it was published, what journal it was published in, and
what subjects the paper was about. During the first time
period there is a total of 508 papers with 856 different authors and 1, 231 connections based on an author being cited
as an author of a given paper. During the second time period, there is a total of 3, 790 papers with 10, 465 different
authors and 16, 772 connections.

MANCaLog: A Logic for Multi-Attribute Network Cascades
(Extended Abstract)
Paulo Shakarian

Gerardo I. Simari

Robert Schroeder

Network Science Center and
Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY 10996

Dept. of Computer Science
University of Oxford
Wolfson Building, Parks Road
Oxford OX1 3QD, UK

CORE Lab
Defense Analysis Dept.
Naval Postgraduate School
Monterey, CA 93943

paulo@shakarian.net

gerardo.simari@cs.ox.ac.uk

Categories and Subject Descriptors

rcschroe@nps.edu

the cascade in polynomial time. In this extended abstract,
we introduce the MANCaLog language, which meets all of
these properties.1

I.2.4 [Artificial Intelligence]: Knowledge Representation
Formalisms and Methods—Representation Languages

2.

General Terms

FRAMEWORK

Appears in: Proceedings of the 12th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2013), Ito, Jonker, Gini, and Shehory (eds.), May, 6–10, 2013,

We assume that agents are arranged in a directed graph
(or network) G = (V, E), where V is the set of nodes (agents)
and E the set of edges (their relationships). We also assume
a set of labels L, which is partitioned into two sets: fluent
labels Lf (labels that can change over time) and non-fluent
labels Lnf (labels that do not); labels can be applied to both
the nodes and edges of the network. We will use G = V ∪ E
to denote the set of all components (nodes and edges) in the
network.
Our logical language uses atoms, referring to labels and
weights, to describe properties of the nodes and edges. The
first piece of the syntax is the network atom. Given label L ∈ L and weight interval bnd ⊆ [0, 1], then hL, bnd i
is a network atom. An atom is fluent (resp., non-fluent)
if L ∈ Lf (resp., L ∈ Lnf ). N A is the set of all possible network atoms. The definition is intuitive: L represents
a property of the vertex or edge, and associated with this
property is some weight that may have associated uncertainty – hence represented as an interval bnd , which can be
open or closed. An invalid bound is represented by ∅. A set
of these atoms is a world. For a given world W , we impose the requirement that for each L ∈ L there is no more
than one atom of the form hL, bnd i in W (and bnd 6= ∅).
A network formula over N A is defined using conjunction,
disjunction, and negation in the usual way. If a formula contains only non-fluent (resp., fluent) atoms, it is a non-fluent
(resp., fluent) formula. The satisfaction relationship is defined as follows. If f is an atom of the form hL, bnd i then
W |= f iff there exists hL, bnd 0 i ∈ W s.t. bnd 0 ⊆ bnd . The
satisfaction of conjunctions, disjunctions, and negations of
formulas is then defined in the normal inductive manner.
For some arbitrary label L ∈ L, we will use the notation Tr = hL, [0, 1]i and F = hL, ∅i to represent a tautology
and contradiction, respectively. For ease of notation (and
without loss of generality), we say that if there does not
exist some bnd s.t. hL, bnd i ∈ W , then this implies that
hL, [0, 1]i ∈ W . The idea is to use MANCaLog to describe
how properties (specified by labels) of the nodes in the network change over time. We assume that there is some nat-

Saint Paul, Minnesota, USA.
Copyright © 2013, International Foundation for Autonomous Agents and
Multiagent Systems (www.ifaamas.org). All rights reserved.

1
A full version of this abstract can be found at
http://arxiv.org/abs/1301.0302.

Languages, Algorithms

Keywords
Complex Networks, Cascades, Logic Programming

1.

INTRODUCTION

Cascading processes on a network have been studied in
a variety of disciplines, including computer science [3], biology [4], sociology [2], and economics [5]. Much existing work
in this area is based on pre-existing models. However, recent
examinations of social networks – both analysis of large data
sets and experimental – have indicated that there may be
additional factors to consider that are not taken into account
by these models [1]. In this paper we introduce MANCaLog,
a logical framework designed to describe cascades in complex
networks that meets seven desiderata we selected based on a
thorough review of the relevant literature. First, the framework must consider multiply labeled and weighted nodes and
edges. This aspect is due to the fact that cascades in realworld networks do not only seem to depend on topological
properties (i.e., an individual adopts a behavior after a certain number of his friends do) but also due to characteristics
of that individual as well. Second, time should be explicitly
represented, and (third) it should be non-Markovian, meaning that a node may choose to adopt or not adopt a behavior
based on any previous time point (not simply the last one).
Fourth, there must be some representation of uncertainty.
Fifth, we must allow for competing cascades as has been
previously done in the classic work of [4]. Sixth, cascades
should be able to be non-monotonic, meaning that the number of nodes with a given property may increase or decrease
in a given time period. Finally, such a framework should be
tractable and allow for the computation of the outcome of

1175

ural number tmax that specifies the total amount of time we
are considering, and we use τ = {t | t ∈ [0, tmax ]} to denote
the set of all time points. How well a certain property can
be attributed to a node is based on a weight (to which the
bnd bound in the network atom refers). As time progresses,
a weight can either increase or decrease and/or become more
or less certain. Next, MANCaLog facts state that some network atom is true for a node or edge during certain times. If
[t1 , t2 ] ⊆ [0, tmax ], c ∈ G, and a ∈ N A, then (a, c) : [t1 , t2 ] is a
MANCaLog fact. A fact is fluent (resp., non-fluent) if atom
a is fluent (resp., non-fluent). All non-fluent facts must be
of the form (a, c) : [0, tmax ]. Let F be the set of all facts and
Fnf , Ff be the set of all non-fluent and fluent facts, respectively. Likewise, we introduce integrity constraints (ICs) as
follows: given fluent network atom a and conjunction of network atoms b, an integrity constraint is of the form a ←- b.
Intuitively, integrity constraint hL, bnd i ←- b means that if
at a certain time point a component (vertex or edge) of the
network has a set of properties specified by conjunction b,
then at that same time the component’s weight for label L
must be in interval bnd .
We now define MANCaLog rules. The idea behind rules is
simple: an agent that meets some criteria is influenced by
the set of its neighbors who possess certain properties. The
amount of influence exerted on an agent by its neighbors is
specified by an influence function, whose precise effects will
be described later on when we discuss the semantics. As a
result, a rule consists of four major parts: (i) an influence
function, (ii) neighbor criteria, (iii) target criteria, and (iv) a
target. Intuitively, (i) specifies how the neighbors influence
the agent in question, (ii) specifies which of the neighbors
can influence the agent, (iii) specifies the criteria that cause
the agent to be influenced, and (iv) is the property of the
agent that changes as a result of the influence. We will discuss each of these parts in turn, and then define rules in
terms of these elements. First, an influence function, which
is a function ifl : N × N → [0, 1] × [0, 1] that satisfies the
following two axioms: (1) it can be computed in PTIME
and (2) for x0 > x we have ifl (x0 , y) ⊆ ifl (x, y). This function takes the number of qualifying and eligible influencers
and returns a bound on the new value for the weight of the
property of the target node that changes. The next part of
a rule is the neighborhood criterion: (gedge , gnode , h)ifl .
Formulas gnode and h are non-fluent/fluent formulas that
specify the (non-fluent and fluent, respectively) criteria on a
given neighbor, while the non-fluent formula gedge specifies
the non-fluent criteria on the directed edge from that neighbor to the node in question. The next component is the
“target criteria”, which are the criteria that an agent must
satisfy in order to be influenced by its neighbors. Ideas such
as “susceptibility” [1] can be integrated into our framework
via this component. We represent these criteria with a formula of non-fluent network atoms. The final component, the
“target” (denoted with fluent label L), is simply the label of
the target agent that is influenced by its neighbors. Along
with ∆t, which specifies the time until the target is affected,
we now have all the pieces to define a rule:
r=L

∆t

←

that when certain conditions for an agent and its neighbors
are met, the bnd bound for the network atom formed with
label L on that agent changes. Later, in the semantics, we
introduce network interpretations, which map components
(nodes and edges) of the network to worlds at a given point
in time. The rule dictates how this mapping changes in the
next time step. Hence a MANCaLog program, P , is a set
of rules, facts, and integrity constraints s.t. each non-fluent
fact F ∈ Fnf appears no more than once in the program. P
is the set of all programs.
Our first semantic structure: the network interpretation is a mapping of network components to sets of network atoms, N I : G → N A. We will use NI to denote
the set of all network interpretations. We note that not all
labels will necessarily apply to all nodes and edges in the
network. For instance, certain labels may describe a relationship while others may only describe a property of an
individual in the network. If a given label L does not describe a certain component c of the network, then in a valid
network interpretation N I, hL, [0, 1]i ∈ N I(c). Now we can
define a MANCaLog interpretation as a mapping of natural
numbers in the interval [0, tmax ] to network interpretations,
i.e., I : N → NI. Let I be the set of all possible interpretations.
In the full version of the paper, we formally define what
it means for an interpretation I to satisfy a program P .
We then define the problems of consistency and entailment.
Program P is consistent if there exists an interpretation that
satisfies all elements in P . Likewise, P entails fact F iff for
all models I of P , it holds that I |= F . In the full paper,
we define an ordering over models and define the concept of
minimal model – the interpretation that assigns components
of the network the tightest bound possible on the weight. If
we can find the minimal model, the questions of consistency
and entailment can be answered easily. We prove, using a
fixed-point operator (a technique common in logic programming) that the minimal model of a MANCaLog program can
be found in polynomial time. Currently, we are creating an
implementation for this framework and designing methods
to automatically learn these programs from data.

3.

ACKNOWLEDGMENTS

P.S. is supported by ARO project 2GDATXR042, and
G.S. by (UK) EPSRC grant EP/J008346/1 – PrOQAW.

4.

REFERENCES

[1] S. Aral and D. Walker. Identifying Influential and
Susceptible Members of Social Networks. Science,
337(6092):337–341, 2012.
[2] M. Granovetter. Threshold models of collective
behavior. The American Journal of Sociology,
83(6):1420–1443, 1978.
[3] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing
the spread of influence through a social network. In
Proc. of KDD ’03, pages 137–146. ACM, 2003.
[4] E. Lieberman, C. Hauert, and M. A. Nowak.
Evolutionary dynamics on graphs. Nature,
433(7023):312–316, 2005.
[5] T. C. Schelling. Micromotives and Macrobehavior.
W.W. Norton and Co., 1978.

f, (gedge , gnode , h)ifl

Note that the target (also referred to as the head) of the
rule is a single label; essentially, the body of the rule characterizes a set of nodes, and this label is the one that is modified for each node in this set. More specifically, the rule says

1176

2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)

A Comparison of Methods for Cascade Prediction
Ruocheng Guo, Paulo Shakarian
Arizona State University
Tempe, AZ
Email: {rguosni,shak}@asu.edu

Abstract— Information cascades exist in a wide variety of
platforms on Internet. A very important real-world problem is
to identify which information cascades can “go viral”. A system
addressing this problem can be used in a variety of applications
including public health, marketing and counter-terrorism. As a
cascade can be considered as compound of the social network
and the time series. However, in related literature where methods
for solving the cascade prediction problem were proposed, the
experimental settings were often limited to only a single metric
for a specific problem formulation. Moreover, little attention was
paid to the run time of those methods. In this paper, we first
formulate the cascade prediction problem as both classification
and regression. Then we compare three categories of cascade
prediction methods: centrality based, feature based and point
process based. We carry out the comparison through evaluation
of the methods by both accuracy metrics and run time. The
results show that feature based methods can outperform others
in terms of prediction accuracy but suffer from heavy overhead
especially for large datasets. While point process based methods
can also run into issue of long run time when the model can not
well adapt to the data. This paper seeks to address issues in order
to allow developers of systems for social network analysis to select
the most appropriate method for predicting viral information
cascades.

I. I NTRODUCTION
Identifying when a piece of information goes “viral” in social media is an important problem in social network analysis.
This is often referred to as “cascade prediction”. Recently,
the cascade prediction problem attracted considerable attention from researchers from communities of machine learning,
data mining and statistics. Researchers attempted to predict
the final size of information cascades based on approaches
inspired by knowledge in various areas. Pei et al. [1] measured
influence of the root node by k-shell number and related
heuristics. Weng et al. [2] and Guo et al. [3] uitilized features
describing both structural and temporal properties of earlystage cascades. The work described in [4] and [5] modelled
cascades by one-dimensional point process. However, in this
line of research, the experimental settings varied from paper
to paper. Furthermore, as the cascade prediction problem
can be treated as either classification or regression, most of
previous work only dealt with one or the other and using
just a single evaluation metric.With deployment of a counterextremism messaging system (i.e. an enhanced version of [6])
as one of the primary goals in our group, cascade prediction
can play a crucial role in detection of early-stage extremism
message that is potential to go viral on social network sites.

Other applications include the spread of information following
a disaster, promotion of health behaviors and applications
to marketing. Therefore, it is important to understand how
well the existing methods stemming from different research
area could perform in near real-world experimental settings.
An ideal cascade prediction method for counter-extremism
messaging system should provide acceptable accuracy with
ability to make near real-time prediction.
In this paper, we compare performance of a variety of
cascade prediction methods originating from different research
areas as both classification and regression problems with
multiple evaluation metrics. We also measure the run time
of the tasks required by the methods to complete cascade
prediction – another key deployment concern not explored in
most research.
In this paper, the main contribution can be summarized as:
• We compare cascade prediction methods in three categories: centrality based, feature based and point process
based, therefore providing comparison between methods
orginating from different research areas.
• The cascade prediction problem is considered from both
the aspect of regression and classification. we also conduct a comprehensive comparison between methods by
various evaluation metrics.
• We also compare the run time of tasks needed for the
cascade prediction methods are also measured in a task
by task style.
The rest of this paper is organized as the follows: In Section II,
definitions relevant to the methods considered in this paper are
introduced along with a formal problem statement of cascade
prediction. Section III summarizes the mechanism of the three
categories of cascade prediction methods. Section IV and V
presents the setup of experiments and performance of each
method in terms of both accuracy and run time. Section VI
reviews related work. At last, Section VII concludes the paper
and discusses the main issues of these methods.
II. T ECHNICAL P RELIMINARIES
In this section, related concepts for the three categories of
methods are defined. Then we formulate the cascade prediction
problem as regression and classification respectively.
A. Definitions
Network and Cascade: The social network is a directed
graph G = (V, E) where each node v ∈ V represents a

IEEE/ACM ASONAM 2016, August 18-21, 2016, San Francisco, CA, USA
c
978-1-5090-2846-7/16/$31.00 
2016
IEEE

591

user and each edge eij = (vi , vj ) denotes that user vi is
followed by user vj . Identified by the original message or the
corresponding hashtag, a cascade is a time-variant subgraph of
the social network d(t) = (V (t), E(t)). Each node v ∈ V (t)
denotes a user reposted the original message of cascade d(t)
(for the Aminer dataset [7]) or a user posted the hashtag
defining cascade d(t) (for the Twitter dataset [2]) within time
t. The time variable t denotes number of time units since the
microblog including the original message or the hashtag. For
each node v ∈ V (t) we record their adoption time of cascade
d(t) as tv . For v ∈ V (t), tv ≤ t while for v 6∈ V (t) we define
tv = ∞. Thus we can get an ascendingly sorted vector tv (t)
including all tv ≤ t for each cascade, which plays an important
role in both feature based methods and point process based
methods for cascade prediction. The kth element of tv (t) can
be denoted as tv (t)[k]. For convenience, we use tend to denote
the time when the last adoption of a cascade happened.
Besides the cascade d(t) = (V (t), E(t)), the neighborhood
of V (t) also can provide information about the potential of
the cascade. Here we define the out-neighborhood reachable
by any node in V (t) in step i as ith surface Fi (t). To show
how ’fresh’ the cascade is for a node v ∈ Fi (t), we define a
function f∆t : v → ∆t that maps such a node to the number of
time units since v become a member of first surface to current
time t. As time makes a big difference in social influence and
diffusion, we divide the first surface F1 (t) into two sets of
nodes depends on f∆t (v) for all v ∈ F1 (t). With a selected
threshold tλ . The first set named as frontiers includes all
nodes v ∈ F1 (t) such that f∆t (v) ≤ tλ and the other set nonadopters consists the other nodes v ∈ F1 (t) with f∆t (v) > tλ .
In this paper, |x| denotes absolute value of scaler x and |x|
denotes cardinality of set x.
Communities: We can treat a community partition of a social
network as a function fC : V → C which maps a set of
nodes V to a set of communities C. With this function, given
a cascade d(t) = (V (t), E(t)), it enables us to describe the
distribution of nodes over communities by features such as
|fC (V )|, the number of communities among set V .
Point Process: Each adoption in a cascade can be represented
as an event from the aspect of point process as in [4]. Thus,
for cascade prediction, we can use tv (t − ∆t) to describe the
history of a point process strictly before t. The core of a point
process is the conditional density function λ(t). Conditioned
on tv (t − ∆t), the conditional density is the limit of expected
number of adoptions would happen in time interval [t, t + ∆t]
by taking ∆t → 0+ :
λ(t) = lim + E {|V (t + ∆t)| − |V (t)|}
∆t→0

(1)

Given the density function λ(t) and target prediction time
t0 , the predicted cascade size can be computed by:
Z t0
ˆ
0
|V (t )| = |V (t)| +
λ(τ )dτ
(2)
t

B. Problem Statement
In this paper, we focus on comparison of different methods
which can solve the cascade prediction problem. This prob-

lem can be formulated as either a regression problem or a
classification problem:
Regression Problem: Given a early stage cascade d(t) =
(V (t), E(t)) and the corresponding node attribute vector tv (t)
with constraint |V (t)| = n, the target is to predict the final
size of the cascade |V (tend )|.
Classification Problem: A threshold T hres is selected to
label each cascade. For a given cascade if its |V (tend )| ≥
T hres, we define it as a viral sample labeled as 1, otherwise,
we label it as non-viral labeled as 0. Then the problem is to
classify a given early-stage cascade d(t) to the viral class or
the non-viral class.
III. M ETHODS
In this section we introduce several recently published
methods for solving the cascade prediction problem. Diffusion
process in social network includes information of time series,
network structure, sometimes with microblog content and node
attributes, therefore, methods originated from knowledge in
various research area like social network analysis, random
point process and non-linear programming can be applied. The
methods can be categorized into: centrality based methods,
feature based methods and point process based methods.
A. Centrality Based Methods
Previous work [1] discovered that the k-shell value of a node
is highly correlated to the average cascade size it initiates.
In this paper, we also consider eigenvector centrality, outdegree and Pagerank of the root node of cascades to deal with
the cascade prediction problem. We refer to centrality based
approaches as method C in this paper.
B. Feature Based Methods
In this paper, we consider two recently proposed methods
[3] and [2] and call them method A and method B respectively
for convenience. The features computed by the two methods
can be categorized into network features, community based
features and temporal features.
Both of the feature based methods require to take advantage
of community detection algorithms. Given the social network,
community detection algorithms such as [8] and [9] can
be applied to it and assign each node to one or multiple
communities. Based on the communities detected, features can
be computed to numerically describe how the nodes that participate in a cascade are distributed over communities. Thus,
we can quantitatively measure structural diversity from [10]
or influence locality from [7] as features.
Network Features: In method B proposed by [2], the authors
consider several types of network features:
• Neighborhood size, including first surface (|F1 (Vt )|) and
second surface (|F2 (Vt )|).
• Path length, consisting average step distance and coefficient of variation of it, and diameter of the cascade.
Step distance is the length of shortest path between two
consecutive adopters vi and vi+1 .

592

TABLE I: Dataset Statistics

Where coefficient of variation is defined as the ratio of the
standard deviation to the mean.
Community Based Features: In both [3] and [2], community
features are extracted and contribute to the predictive methods.
•
•

•

Property
Directed
Nodes
Edges
Number of communities
Modularity
Average Out-degree
Average Eigenvector Centrality
Average K-shell
Average Pagerank
Cascades (≥ 50 nodes)

Community features for adopters, including the number
of communities (|fC (V (t))|), entropy and gini entropy.
Community features for frontiers and non-adopters, including the number of communities (|fC (F1 (t))|), entropy and gini entropy.
The number of shared communties between any two
groups of adopters, frontiers and non-adopters.

Temporal Features: In [3], the authors computed average of
tv (t) while average step time and its corresponding coefficient
of variation are calculated in [2] as two features.
C. Point Process Based Methods
To discover patterns in the temporal dynamics of cascades,
authors of both [5] and [4] both consider a cascade as an
instance of one-dimensional point process in time space. They
proposed novel density functions to characterize time series
of cascades. The two methods are quite similar, in terms of
the formulation of conditional density function λ(t). In both
cases, λ(t) consists of an element modeling the popularity of
the cascade and another describing the probablity distribution
of an adoption behavior over time.
The Reinforced Poisson Process (RPP) Method: In [5], the
authors consider the density function for a cascade d as a
product of three elements:
λd (t) = αd fd (t; θd ) |V (t)|

(3)

For cascade d, αd denotes the intrinsic attractiveness, fd (t; θd )
is defined as the relaxation function which models how likely
an adoption would happen at time t without considering αd
and |V (t)|. For each cascade d, parameters αd and θd are
learned by maximization of the likelihood of tv (t). Thus, the
predicted cascade size at time t0 > t can be computed by:
Z

0

t0

|V̂ (t )| = |V (t)| +

αd fd (τ ; θd ) |V (τ )| dτ

|V (t)|

X

ni φ(t − tvi )

(5)

i=1

Where tvi ∈ tv (t) is the time when each adoption happens.
Similar to αd in the Reinforced Poisson Process model, pt is
computed by maximization of the likelihood function:
|V (t)|−1
pt

Y

directed
1,787,443
216,511,564
2,802
0.5581
231.3381
0.0186

24.6032
1.6794e−6
14,607

52.3064
5.596e−7
99,257

While the human reaction time distribution φ(s) is formulated
as a piece-wise function consists of a constant piece and a
power-law piece with parameter c and θ:
(
c
s ≤ s0
(7)
φ(s) =
s −(1+θ)
c( s0 )
s > s0
As φ(s)R is a probability distribution function, with the con∞
straint 0 φ(s)ds = 1 and power-law decay factor θ estimated by training data, c can be computed. With the density
function λ(t), the predicted cascade size can be computed by
equation (2).
IV. E XPERIMENTAL S ETUP
For comprehensiveness, we evaluate the performance of
each method by treating cascade prediction problem as both
regression and classification problem. We only consider cascades that end up with at least 50 adopters. Thus we can treat
first 50 nodes of each cascade as its early stage. In this section,
an introduction of the datasets is followed by descriptions
of setup of the classification and regression experiments. All
the experiments are carried out on an Intel(R) Xeon(R) CPU
E5-2620 @ 2.40 GHz machine with 256GB RAM running
Windows 7. All the methods are implemented in Python 2.7.
A. Dataset Description

The SEISMIC Method: In [4], authors model the density
function as a modified Hawkes Process made up of three elements: infectiousness pt , node degree ni and human reaction
time distribution φ(s):

pt = arg max

Weibo Dataset

undirected
595,460
7,170,209
24,513
0.7865
47.94
0.001783

(4)

t

λ(t) = pt

Twitter Dataset

λ(tvi ) exp−

R tvi+1
tvi

λ(τ )dτ

The statistics of the two datasets used in this paper for
evaluation of the cascade prediction methods are shown in
Table I.
Twitter Dataset: Twitter1 is the most well-known microblog
platform throughout the world. The dataset was used in [2].
This dataset includes a friendship network with undirected
edges, cascades identified by hashtags and corresponding
mentions and retweets.
Weibo Dataset: Sina Weibo2 is the largest Chinese microblog
social network. The dataset was used in [7]. It consists of a
directed followership network and retweet cascades.

(6)

i=0

593

1 https://twitter.com
2 https://weibo.com

TABLE II: Thresholds for Classification

B. Regression
For the regression problem, the m × 1 ground truth vector
y is made up of final size of each cascade (|V (tend )|), where
m is the number of cascade. Each regression model is able
to output a m × 1 vector ŷ. Thus each element ŷi ∈ ŷ
is the predicted size of the ith cascade. For point process
models, with different prediction time, the predicted results
can change. Thus, for each early-stage cascade, we set t as
the time when we observed the 50th adoption and prediction
time as {2, 4, 6, 8, 10} × tv (t)[50]. To evaluate a method for
the regression problem, the difference between its prediction
results ŷ and the ground truth y can be described by various
error functions. In addition, ŷtop10% denotes the set of top
10% cascades in prediction result while ytop10% is the set
top of 10% cascades of ground truth. In this paper we choose
following metrics to compare the prediction made by different
methods, as they are widely used in related literatures such as
[11], [5], [12] and [4]:
Pm |yˆi −yi |
1
• APE (average percentage error): m
i=1
yi
• RMSE (root mean square error):
r Pm
2
i=1 (yˆi − yi )
m
• RMLSE (root mean logrithm square error):
r Pm
2
i=1 (log yˆi − log yi )
m


10 
ŷtop10% ∩ ytop10% 
• Top 10% coverage:
m

C. Classification
For classification, we apply three predetermined thresholds
(50th, 75th and 90th percentiles) to final size of cascades to
assign each of them a class label, which provides the m × 1
ground truth vector L = {l0 , ..., lm−1 } one for each threshold.
The cascades with size larger than threshold are labelled as
viral class with li = 1. Table II shows the thresholds and
counts of samples for both classes. Then the methods for
solving the classification problem can output predicted label
vector L̂. Comparing L with L̂ results in standard metrics:
precision, recall and F1 score. To examine the effectivess of
the methods, we focus on reporting the metrics on the minority
class (viral) as it is more difficult to do good predictions for
it than the other.
Specially, for point process based mothods, as they are capable to predict the final cascade size without being trained with
class labels (once parameters are determined and prediction
times are selected), we carry out the evaluation on them in this
way: prediction results (by setting different prediction times)
are treated as features for each sample. As the time when each
cascade stop growing is not easy to determine.
D. Run time
We also take the run time of tasks into account for the cascade prediction methods. To understand how computationally
expensive the methods are in terms of run time, it is necessary to analyze the procedure of them. For centrality based

Percentile

Threshold

Viral samples

Non-viral samples

Twitter Dataset
50%
75%
90%

106
226
587

50%
75%
90%

152
325
688

7,303
3,652
1,461

7,304
10,955
13,146

Weibo Dataset
49,628
24,814
9,925

49,629
74,443
89,332

methods, the prediction can be divided into three steps: computation of centrality, training and prediction. Similarly, for
feature based methods, computation of features, training and
prediction are required to be done. In addition, preprocessing
like community detection, computation of shortest path length
are needed, which can be computationally expensive. While
point process based methods require little preprocessing. For
each cascade, parameters are computed independently through
MLE of the observed time vector tv (t) and properties of the
adopters V (t). Then prediction is made by integral of density
functions. Thus, we consider the following processes one by
one and then combine them to estimate the run time of a
certain method.
Proprecessing: There are three types of proprecessing considered: loading the graph, computation of centralities and
community detection.
Computation of Features: For feature based methods, we
measure the run time of computation of the features , which
takes the product of preprocessing as input.
Training and Prediction: For centrality and feature based
methods, the run time of training and prediction is measured
for ten-folds. For point process based methods, we measure
the run time of parameter estimation and prediction for the
whole batch of data.
V. E XPERIMENTAL R ESULTS
In this section we show the experimental results including
both accuracy of cascade prediction and the run time for each
method. For convenience, we call method of [3], [2] and the
centrality based method as method A, B and C respectively.
For method A, B and C, 10-fold cross-validation is applied.
For results where we compare these three methods, we report
only the best-performing centrality measure amongst outdegree, Pagerank, Shell number and eigenvector centrality as
the method C for each dataset. As shown in Fig. 1, eigenvector
centrality outperforms others in the classification task when
the two classes are imbalanced. Thus we take eigenvector
centrality as the method C. The results for regression is not
shown here for limited space as the difference between results
produced by different centralities is trivial. For the Reinforced
Poisson Process (RPP) method [5], as the parameter estimation
task for each cascade is independent of others, the crossvalidation is skipped and predictions are made by parameters
learned from first 50 nodes of each cascade. For the SEISMIC

594

Out-degree
Pagerank
Shell Number
Eigenvector

1.0
0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

Precision

Recall

F1 Score

(a) Twitter Dataset: 50th percentile
Out-degree
Pagerank
Shell Number
Eigenvector

1.0
0.8

0.0

0.4

0.2

0.2

0.0

0.0

(c) Twitter Dataset: 90th percentile
Out-degree
Pagerank
Shell Number
Eigenvector

1.0
0.8

50.0%
Precision

Recall

0.0%

F1 Score

(a) Twitter Dataset: APE

Out-degree
Pagerank
Shell Number
Eigenvector

2.0
1.5

Precision

Recall

(d) Weibo Dataset: 50th percentile
0.8

200.0%

0.6
0.4

100.0%

0.2

0.2
F1 Score

(e) Weibo Dataset: 75th percentile

0.0

Precision

Recall

F1 Score

SEISMIC
RPP

(b) Twitter Dataset: RMSE

0.30

0.25
0.20

A(SVR)
B(SVR)
C(DTR)

SEISMIC
RPP

0.10
0.05
0.00

(c) Twitter Dataset: RMSLE

Out-degree
Pagerank
Shell Number
Eigenvector

1.0

A(SVR)
B(SVR)
C(DTR)

0.15

0.0

F1 Score

0.4

Recall

SEISMIC
RPP

0.5

0.6

Precision

A(SVR)
B(SVR)
C(DTR)

1.0

150.0%

0.0

3000
2500
2000
1500
1000
500
0

A(SVR)
B(SVR)
C(DTR)
SEISMIC
RPP

100.0%

0.8

0.4

F1 Score

200.0%
150.0%

1.0

0.6

Recall

250.0%

(b) Twitter Dataset: 75th percentile

0.6

Precision

300.0%

Out-degree
Pagerank
Shell Number
Eigenvector

1.0

A(SVR)
B(SVR)
C(DTR)
SEISMIC
RPP

(d) Twitter Dataset: Top 10% Coverage
2000

A(SVR)
B(SVR)
C(DTR)

SEISMIC
RPP

1500
1000

50.0%

500

0.0%

0

(f) Weibo Dataset: 90th percentile
(e) Weibo Dataset: APE

Fig. 1: Classification results of centrality based methods: error
bar stands for one standard deviation.

2.0
1.5

A(SVR)
B(SVR)
C(DTR)

SEISMIC
RPP

1.0

method [4], we also skip the 10-fold cross-validation. We set
the cutoff time s0 = 30000(s) for the Twitter dataset and
s0 = 300(s) for the Weibo dataset then fit the parameters
(θ, c) for the human reaction time distribution function φ(s)
with all samples in the dataset. While in the original paper [4],
the authors set θ and c just by 15 tweets they manually
picked. The power-law fitting is done as per [13], which
returns (θ, c) = (0.440, 1.018e−5 ) and (0.282, 7.332e−4 ) for
the Twitter dataset and Weibo dataset respectively.
A. Regression
For centrality based methods, we apply linear regression
with least squared error. We carry out the training and prediction with random forest regressor, SVR and linear regression
model provided by [14] for feature based methods. We only
show the results produced by SVR as it outperformes others.
For the point process based mothods, we only report the best
result among prediction time out of {2, 4, 6, 8, 10}×tv (t)[50].
For the Twitter dataset, Fig. 2a, 2b, 2c and 2d show the
experimental results for the regression problem. Feature based
methods and SEISMIC outperform RPP and method C w.r.t.
APE. Concerning RMSE, method A shows more predictive
power than others. As to RMSLE, feature based methods result
in less error than the other two categories. From the aspect of
Top 10% coverage, RPP, method A are more likely to track
the trending cascades than others.
Fig. 2e, 2f, 2g and 2h show the regression result for the
Weibo dataset, Regarding APE, SEISMIC, method A and B
have comparable performance and outperform others. In terms
of RMSE, method A, B are measured to be more predictive

0.5
0.0

(g) Weibo Dataset: RMSLE

(f) Weibo Dataset: RMSE

0.35
0.30
0.25
0.20
0.15
0.10
0.05
0.00

A(SVR)
B(SVR)
C(DTR)

SEISMIC
RPP

(h) Weibo Dataset: Top 10% Coverage

Fig. 2: Regression results

than the rest. Feature based methods also make predictions
with least RMSLE. For top 10% coverage, RPP is more likely
to detect popular cascades than others.
An interesting observation is that the prediction accuracy
measured by different error metrics can be contrary to each
other. For example, in Fig. 2a, compared to SEISMIC, prediction made by method C results in more error measured by
APE, however, comparable error w.r.t. RMSE and less error
regarding RMSLE (See Fig. 2b and 2c). This implies that it
is better for researchers to show more than one type of error
for evaluation of regression results.
B. Classification
We show the precision, recall and F1 score for the viral
class with all the three percentile thresholds. For each dataset,
we choose the 50th, 75th and 90th percentile of the final size
of all cascades as the thresholds for assigning the cascades
into viral or non-viral class. The number of samples in
each class is shown in Table II. Thus we can evaluate the
cascade prediction methods with balanced and imbalanced
classes. For each method, we only show the best result among
those produced by different classifiers or various training
methods. As a result, for feature based methods, random forest

595

1.0

A(RF)
B(RF)

C(DT)
SEISMIC

RPP

1.0

0.8

0.8

0.6

0.6

0.4

0.4

0.2
0.0

Recall

F1 Score

A(RF)
B(RF)

C(DT)
SEISMIC

RPP

0.0

1.0
0.8

0.6

0.6

0.4

0.4

0.2

0.2
Precision

Recall

F1 Score

(c) Twitter Dataset: 90th percentile
1.0

A(RF)
B(RF)

C(DT)
SEISMIC

RPP

0.0

1.0
0.8

0.6

0.6

0.4

0.4

0.2

Precision

Recall

F1 Score

A(RF)
B(RF)

Precision

C(DT)
SEISMIC

Recall

RPP

F1 Score

(d) Weibo Dataset: 50th percentile

0.8

0.0

RPP

(b) Twitter Dataset: 75th percentile

0.8

0.0

C(DT)
SEISMIC

0.2
Precision

(a) Twitter Dataset: 50th percentile
1.0

A(RF)
B(RF)

A(RF)
B(RF)

C(DT)
SEISMIC

RPP

0.2
Precision

Recall

F1 Score

(e) Weibo Dataset: 75th percentile

0.0

Precision

Recall

F1 Score

(f) Weibo Dataset: 90th percentile

Fig. 3: Classification results: error bar stands for one standard
deviation.

outperforms others. While for point process based methods
we treat cascade size predicted by setting prediction time as
{2, 4, 6, 8, 10}×tv (t)[50] as features. Here we show the results
produced by classifiers trained by these features.
Fig. 3a, 3b and 3c show the classification results for
the Twitter dataset. With all three thresholds, feature based
methods A and B outperform others. In addition, they also
show more robustness than others to imbalance of two classes
in dataset. In terms of point process based methods, SEISMIC
outperforms RPP especially when the two class are imbalanced. RPP suffers from relatively large standard deviation,
as the Newton’s method is not always able to achieve convergence. Thus the parameters learned through the MLE approach
can vary as a result from random initialization. Method C
(eigenvector centrality) shows little predictive power with any
of the three thresholds for the Twitter dataset, even if it
outperforms other centrality based methods.
For the Weibo dataset, as shown in Fig. 3d, 3e and 3f,
feature based methods outperform others again with all three
thresholds. Regarding point process based methods, contrary
to the results for Twitter dataset, RPP achieves better F1 score
than SEISMIC when threshold value becomes large. Method
C (eigenvector centrality) performs comparably to RPP.
C. Run time
In this subsection, we show the run time of tasks for the
cascade prediction methods considered in this paper. On one
hand, preprocessing, computation of centralities and features
suffer from high overhead as immense amount of data needs
to be loaded. The run time of these tasks are listed in Table III.

On the other hand, training and prediction tasks barely have
the overhead issue.
Preprocessing: We carry out the community detection task by
the java implementation of Louvain algorithm [15] with 10
random start and 10 iterations for each start. For computation
of centralities, we load edgelist of the social networks as a
graph object in igraph-python [16]. As shown in Table III,
community detection, computation of Pagerank and loading
graph are the tasks suffer the most when the size of dataset
increases. Community detection, computation of Pagerank and
loading graph for the Weibo dataset take 80.32, 66.855 and
19.80 times the run time of those for the Twitter dataset
respectively.
Computation of Features: As shown in Table III, for the
feature computation task, it takes method B 12.37 and 8 times
the run time method of A for the Twitter Dataset and the
Weibo Dataset respectively. To explain this observation, an
analysis of what computation is carried out in each iteration for
method A and B. For method A, computation of the features
can be done without loading the graph (a heavy overhead).
Moreover, for each cascade, method B also requires expensive
computation of shortest path length for each pair of nodes in
cascade subgraphs and size of 2-hop neighborhood.
Training and Prediction: The run time of training and prediction is not directly related to the size of the social network.
On one hand, it is correlated to the number of cascades for
training and prediction. On the other hand, it is decided by the
complexity of the method: for example, number of parameters
to be learned, the complexity for learning each paramter and
the comsumption to work out the prediction. Here we only
measure the run time for solving the classification problem.
We run each method with single process, overhead run time
such as graph loading is ignored. For feature based methods
the training and prediction time are also correlated to the
number of features. For centrality based methods, we only
show the run time for k-shell (method C) as all methods in this
category are trained and tested with one feature: the centrality
measure of the root node. Compared to RPP, SEISMIC is a
deterministic method with closed form solution. The run time
for each sample can be distributed with little variance. For the
RPP method, as the log-likelihood function is non-convex, it is
not guaranteed that global maximum can be reached in limited
number of iterations. Therefore, the run time for a sample
running out of the maximum number of iterations can be
thousands times that of another, which reaches the convergence
condition in the first iteration. As the log-likelihood function of
RPP is twice-differentiable, Newton’s method can be applied.
In our experiments, with the maximum number of iterations
setted as 100, the convergence is more likely to be achieved by
Newton’s method than gradient descent. Thus we only show
the run time of RPP with Newton’s method.
Fig. 4 shows the run time for each method to complete
training and prediction tasks for all cascades in the two
datasets. For feature based methods, it shows the run time
needed for random forest (RF), SVM and logistic regression
(LR). For method C, it shows that of decision tree (DT), SVM

596

TABLE III: Run time: Preprocessing & Feature Computation
Type

Task

Twitter Dataset
Louvain
275
Loading Graph
60.033
Degree
0.016
K-shell
2.757
Eigenvector
20.444
Pagerank
26.298
A
267.144
B
3252.7562
Weibo Dataset
Louvain
22087
Loading Graph
1188.486
Degree
0.045
K-shell
139.128
Eigenvector
391.140
Pagerank
1758.164
A
11181.453
B
87651.213

Feature
Computation

Preprocessing

Feature
Computation

Run time (seconds)

10 2

A(RF)
A(LR)
A(SVM)
B(RF)

B(LR)
B(SVM)
C(DT)
C(LR)

C(SVM)
SEISMIC
RPP

10 6
10 5

Run time (seconds)

Preprocessing

10 3

Total time (s)

A(RF)
A(LR)
A(SVM)
B(RF)

Time
per
sample (s)
–
–
–
–
–
–
0.018
0.2227
–
–
–
–
–
–
0.110
0.883
B(LR)
B(SVM)
C(DT)
C(LR)

C(SVM)
SEISMIC
RPP

10 4
10 3

10 1

10 2

10 0

10 1
10 0

10 -1

(a) Twitter Dataset

(b) Weibo Dataset

Fig. 4: Run Time of Trainig and Prediction

and logistic regression (LR).
Concerning the Twitter dataset (See Fig. 4a), taking advantage of decent implementation of classifiers, feature based
methods comparable run time to point process based methods
w.r.t. the training and prediction task with random forest and
SVM (rbf kernel).
For the Weibo dataset, as shown in Fig. 4b, the run time
feature based methods comsume is comparable to SEISMIC
with random forest. But the SVM with rbf kernel suffers from
the order-of-magnitude increase of the number of training and
testing samples. Thus leads to the observation that the run time
becomes approximately 10 times that of random forest.
Comparing Fig. 4b with Fig. 4a, the run time of RPP method
increases the most. This means it is much more difficult for
the Newton’s method to converge for samples in the Weibo
datasets. There are two possible reasons to explain this: 1).
the uniform distribution used in random initialization can not
produce good initial values that are closed to local optimal
points; 2). the choice of log-norm distribution as function
fd (t; θd ) can not provide fairly good description of cascades
in this dataset.
VI. R ELATED W ORK
Influence Maximization Since the proposal of Influence maximization problem by Kempe et al. [17], related work emerged,

focusing on estimation of influence for a selected set of nodes
that can be measured by expected number of infectees under
a certain influence model, such as [18] and [19]. Recently,
a scalable randomized algorithm designed by Du et al. [20]
estimates influence initiated by selected source nodes and thus
select seed set with maximum expected influence.
Cascade Prediction Although in [1], k-shell and heuristics
of k-shell were shown to be effective indicator of long-term
influence of nodes, in [21], experimental results showed that
the shell number of the root node is not effectively predictive in
the cascade by cascade scenario. Feature based methods from
Jenders et al. [22] Chen et al. [23] were designed to solve the
cascade prediction problem formulated as binary classification
on balanced dataset, however, these methods are more or less
dependent on content features from specific social media sites.
Ma et al. [24] focused on applying content features to classify
hashtag cascades by how much their size increases. Regarding
to point process based methods, model designed with the
intuition of mutual exciting nature of social influence, Zhou
et al [25] applied multi-dimensional Hawkes process to rank
cascades (memes) by their popularity. Recently, the model
introducted by Yu et al. [11] combined feature engineering and
human reaction time distribution function widely used in point
process based methods to aggregate adoptions in subcascades
for cascade prediction. Besides feature based methods and
point process based methods, knowledge from related research
fields could also be applied to cascade prediction. Goyal et
al. [26] proposed the credit distribution model to learn pairwise influence based on IC model proposed by Kempe et
al. [17]. Wang et al. [27] proposed a model to decouple
the influence measured in a pair-wise way into two latent
vectors representing influence and susceptibility of a node.
This work differs from all the past efforts in that it is the most
thorough comparison of methods general enough to be applied
to different datasets without relying on features specific to a
certain social media site.
VII. D ISCUSSION AND C ONCLUSION
In this paper, we evaluate three categories of recently
proposed methods with both the classification and regression
formulaton of cascade prediction. Feature based methods
generally provide better prediction accuracy for the cascade
prediction problem, no matter it is considered as classification
or regression. However, they suffer from heavy overhead
such as community detection and computation of features.
Random point process based methods enable us to achieve the
prediction with little preprocessing but are shown to be less
accurate than feature based methods. The run time of methods
in this category can also suffer from the situation when the
data can not be well modelled by the proposed density function
λ(t).
In regression experiments, we find the inconsitancy between
evaluation with different error metrics. A method that performs
well w.r.t. one metric could result in large error measured by
another. A predictive method should be able to perform fairly
well measured by various error metrics.

597

How to deal with changes in the social network and progress
of cascades to update features is the biggest issue that both
centrality based and feature based methods encounter. The
heavy overhead introduced by preprocessing and computation
of features limits these methods from near real-time prediction.
Point process based methods require little preprocessing
and the training and prediction process are parallelable as
they consider each cascade is indenpendent of others. This
advantage in terms of run time over feature based methods
can also be amplified as the size of the social network and the
number of cascades. Moreover, point process based methods
encounter little cold start problem. These two characteristics of
point process based methods make them more suitable for realtime cascade prediction task. But how to secure the accuracy
of prediction is the biggest issue for them. The point process
based models are faced with two more problems: sensitivity
to scale of time unit and requirement of prediction time as an
input variable. In real-world application, given a early stage
cascade, estimation of when it will stop progressing is a nontrivial problem.
On balance, this paper explored various methods in the
academic literature of predicting viral information cascades
in a more comprehensive manner. Our aim is to provide important insights into which methods based on graph topology
or temporal dynamics performed best - as these results can
generalize to a variety of application domains. In our ongoing
work on developing a deplyable system for identifying viral
extremist messages, this represents an important consideration.
Our next step is to consider microblog content as well - which
tends to be more domain specific.
ACKNOWLEDGMENTS
Some of the authors are supported through the AFOSR
Young Investigator Program (YIP) grant FA9550-15-1-0159,
ARO grant W911NF-15-1-0282, the DoD Minerva program
N00014-16-1-2015 and the EU RISE program.
R EFERENCES
[1] S. Pei, L. Muchnik, J. S. Andrade Jr, Z. Zheng, and H. A. Makse,
“Searching for superspreaders of information in real-world social media,” Scientific reports, vol. 4, 2014.
[2] L. Weng, F. Menczer, and Y.-Y. Ahn, “Predicting successful memes
using network and community structure,” in Eighth International AAAI
Conference on Weblogs and Social Media, 2014.
[3] R. Guo, E. Shaabani, A. Bhatnagar, and P. Shakarian, “Toward order-ofmagnitude cascade prediction,” in Proceedings of the 2015 IEEE/ACM
International Conference on Advances in Social Networks Analysis and
Mining 2015. ACM, 2015, pp. 1610–1613.
[4] Q. Zhao, M. A. Erdogdu, H. Y. He, A. Rajaraman, and J. Leskovec,
“Seismic: A self-exciting point process model for predicting tweet
popularity,” in Proceedings of the 21th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining. ACM, 2015,
pp. 1513–1522.
[5] H. Shen, D. Wang, C. Song, and A.-L. Barabási, “Modeling and
predicting popularity dynamics via reinforced poisson processes,” in
Twenty-Eighth AAAI Conference on Artificial Intelligence, 2014.
[6] N. Kim, S. Gokalp, H. Davulcu, and M. Woodward, “Lookingglass: A
visual intelligence platform for tracking online social movements,” in
Advances in Social Networks Analysis and Mining (ASONAM), 2013
IEEE/ACM International Conference on. IEEE, 2013, pp. 1020–1027.

[7] J. Zhang, B. Liu, J. Tang, T. Chen, and J. Li, “Social influence locality
for modeling retweeting behaviors.” in IJCAI, vol. 13, 2013, pp. 2761–
2767.
[8] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast
unfolding of communities in large networks,” Journal of statistical
mechanics: theory and experiment, vol. 2008, no. 10, p. P10008, 2008.
[9] M. Rosvall and C. T. Bergstrom, “Maps of random walks on complex
networks reveal community structure,” Proceedings of the National
Academy of Sciences, vol. 105, no. 4, pp. 1118–1123, 2008.
[10] J. Ugander, L. Backstrom, C. Marlow, and J. Kleinberg, “Structural
diversity in social contagion,” Proceedings of the National Academy
of Sciences, vol. 109, no. 16, pp. 5962–5966, 2012.
[11] L. Yu, P. Cui, F. Wang, C. Song, and S. Yang, “From micro to
macro: Uncovering and predicting information cascading process with
behavioral dynamics,” arXiv preprint arXiv:1505.07193, 2015.
[12] S. Gao, J. Ma, and Z. Chen, “Modeling and predicting retweeting
dynamics on microblogging platforms,” in Proceedings of the Eighth
ACM International Conference on Web Search and Data Mining. ACM,
2015, pp. 107–116.
[13] J. Alstott, E. Bullmore, and D. Plenz, “powerlaw: a python package for
analysis of heavy-tailed distributions,” PloS one, vol. 9, no. 1, p. e85777,
2014.
[14] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, “Scikit-learn: Machine learning in Python,” Journal of Machine
Learning Research, vol. 12, pp. 2825–2830, 2011.
[15] L. Waltman and N. J. van Eck, “A smart local moving algorithm
for large-scale modularity-based community detection,” The European
Physical Journal B, vol. 86, no. 11, pp. 1–14, 2013.
[16] G. Csardi and T. Nepusz, “The igraph software package for complex
network research,” InterJournal, vol. Complex Systems, p. 1695, 2006.
[Online]. Available: http://igraph.org
[17] D. Kempe, J. Kleinberg, and É. Tardos, “Maximizing the spread of
influence through a social network,” in Proceedings of the ninth ACM
SIGKDD international conference on Knowledge discovery and data
mining. ACM, 2003, pp. 137–146.
[18] W. Chen, Y. Wang, and S. Yang, “Efficient influence maximization in
social networks,” in Proceedings of the 15th ACM SIGKDD international
conference on Knowledge discovery and data mining. ACM, 2009, pp.
199–208.
[19] A. Goyal, W. Lu, and L. V. Lakshmanan, “Celf++: optimizing the greedy
algorithm for influence maximization in social networks,” in Proceedings
of the 20th international conference companion on World wide web.
ACM, 2011, pp. 47–48.
[20] N. Du, L. Song, M. Gomez-Rodriguez, and H. Zha, “Scalable influence
estimation in continuous-time diffusion networks,” in Advances in neural
information processing systems, 2013, pp. 3147–3155.
[21] P. Shakarian, A. Bhatnagar, A. Aleali, E. Shaabani, and R. Guo,
Diffusion in Social Networks. Springer, 2015.
[22] M. Jenders, G. Kasneci, and F. Naumann, “Analyzing and predicting
viral tweets,” in Proceedings of the 22nd international conference
on World Wide Web companion.
International World Wide Web
Conferences Steering Committee, 2013, pp. 657–664.
[23] J. Cheng, L. Adamic, P. A. Dow, J. M. Kleinberg, and J. Leskovec,
“Can cascades be predicted?” in Proceedings of the 23rd international
conference on World wide web. ACM, 2014, pp. 925–936.
[24] Z. Ma, A. Sun, and G. Cong, “On predicting the popularity of newly
emerging hashtags in twitter,” Journal of the American Society for
Information Science and Technology, vol. 64, no. 7, pp. 1399–1410,
2013.
[25] K. Zhou, H. Zha, and L. Song, “Learning social infectivity in sparse lowrank networks using multi-dimensional hawkes processes,” in Proceedings of the Sixteenth International Conference on Artificial Intelligence
and Statistics, 2013, pp. 641–649.
[26] A. Goyal, F. Bonchi, and L. V. Lakshmanan, “A data-based approach to
social influence maximization,” Proceedings of the VLDB Endowment,
vol. 5, no. 1, pp. 73–84, 2011.
[27] Y. Wang, H. Shen, S. Liu, and X. Cheng, “Learning user-specific latent
influence and susceptibility from information cascades,” in Twenty-Ninth
AAAI Conference on Artificial Intelligence, 2015.

598

Power Grid Defense Against Malicious Cascading Failure
Paulo Shakarian

Hansheng Lei

Roy Lindelauf

Dept. EECS and
Network Science Center
U.S. Military Academy
West Point, NY, 10996

Dept. EECS and
Network Science Center
U.S. Military Academy
West Point, NY, 10996

Netherlands Defence
Academy
Faculty of Military Science
Military Operational Art and
Science

paulo[at]shakarian.net hansheng.lei[at]usma.edu

rha.lindelauf.01[at]nlda.nl

ABSTRACT

1.

An adversary looking to disrupt a power grid may look
to target certain substations and sources of power generation to initiate a cascading failure that maximizes the number of customers without electricity. This is particularly
an important concern when the enemy has the capability
to launch cyber-attacks as practical concerns (i.e. avoiding disruption of service, presence of legacy systems, etc.)
may hinder security. Hence, a defender can harden the security posture at certain power stations but may lack the
time and resources to do this for the entire power grid. We
model a power grid as a graph and introduce the cascading failure game in which both the defender and attacker
choose a subset of power stations such as to minimize (maximize) the number of consumers having access to producers
of power. We formalize problems for identifying both mixed
and deterministic strategies for both players, prove complexity results under a variety of different scenarios, identify tractable cases, and develop algorithms for these problems. We also perform an experimental evaluation of the
model and game on a real-world power grid network. Empirically, we noted that the game favors the attacker as he
benefits more from increased resources than the defender.
Further, the minimax defense produces roughly the same
expected payoff as an easy-to-compute deterministic load
based (DLB) defense when played against a minimax attack
strategy. However, DLB performs more poorly than minimax defense when faced with the attacker’s best response to
DLB. This is likely due to the presence of low-load yet highpayoff nodes, which we also found in our empirical analysis.

Rapid cascading failure in a power grid caused by a succession of overloading lines can lead to very large outages,
as observed in the United States in 2003 [1]. Studies on cascading failure [7, 8, 16] have illustrated that such a failure
can be initiated with only a small number of initial node failures. Further, power grid infrastructure is often particularly
vulnerable with respect to cyber-security due to a variety of
issues, including the use of legacy and proprietary computer
hardware and software [26].
In this paper, we extend the work on cascading failure
models to a two-player game where an attacker attempts to
create a cascade that maximizes the number of customers
without power while the defender defends key nodes to avoid
a major outage. In Section 2, we introduce an extension to
the failure model of [8] to not only consider the attacker and
defender, but also the different types of nodes in the power
grid (i.e. power generation vs. power consumers). In Section 3, we explore the computational complexity of finding
deterministic best-response strategies for the attacker and
defender under several different scenarios depending on the
relative number of resources each player has and whether
the opponent has a deterministic or mixed strategy. Here we
found that, in general, these problems are NP-hard, though
we do identify some tractable cases. In Section 4, we explore heuristic algorithms for finding determinsitic “best responses” as well as minimax mixed strategies. We introduce
a “high-load” strategy for defense (based on the observations of [8]), greedy heuristics for deterministic strategies,
and a double-oracle approach based on [15] for finding a
mixed strategy. In Section 5 we perform experiments on a
real-world dataset of a power grid [20] and find that this
game seems to favor the attacker as he benefits more from
increased resources than the defender. Further, our experiments revealed that the minimax defense produces roughly
the same expected payoff as an easy-to-compute deterministic load based (DLB) defense when played against a minimax attack strategy, though the load based defense does
more poorly than minimax when faced with the attacker’s
best response to DLB. This is likely due to the presence
of low-load yet high-payoff nodes, which we also found in
our empirical analysis of the model. Finally, related work is
discussed in Section 6.

Categories and Subject Descriptors
I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence

General Terms
Algorithms Security

Keywords
power grid defense, game theory, complex networks
Appears in: Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2014), Lomuscio, Scerri, Bazzan, Huhns (eds.), May,
5–9, 2014, Paris, France.
c 2014, International Foundation for Autonomous Agents and
Copyright 
Multiagent Systems (www.ifaamas.org). All rights reserved.

813

INTRODUCTION

2.

TECHNICAL PRELIMINARIES

attacker is unable to destroy them - though these nodes can
be taken offline as a result of the cascading failure1 . The attacker can destroy ka nodes while the defender can harden
kd nodes. Thus the strategy space of both the attacker and
defender consists of all subsets Va , Vd ⊆ V of size |Va | ≤ ka
(|Vd | ≤ kd respectively). We denote these strategy spaces
by AT K (DEF respectively), i.e., if we allow the attacker
to consider all strategies of size ka or less we have:

Consider a power-grid network modeled as an undirected
graph G = (V, E). Let Vsrc , Vld ⊆ V be source (producers of
power) and load (consumers of power) on the network. We
shall use the notation discVld ,Vsrc (G) to denote the number
of nodes in Vld which are not connected to any node in Vsrc
in graph G. Let G be the set of all subgraphs of G. For
a given node i, let NG (i) be the set of nodes in Vsrc − {i}
that are closest to that node (based on path length in G).
From this, we define edge load (similar to the idea of edge
betweenness [25]).

AT K = {S ∈ 2V : |S| ≤ ka }
We now have all of the components to define the payoff
function.

Definition 2.1 (Edge Load). Given edge ij ∈ E, the
edge load, loadG (ij) is defined as follows:
X X
σG (s, t|ij)
,
loadG (ij) =
|N
G (t)| σG (s, t)
t∈V
ld

Definition 2.3 (Payoff Function). Given initial network G = (V, E) with edge capacities cij (G), attack (defend)
strategy Va (Vd ), the payoff function is defined by

s∈NG (t)

pG (Va , Vd ) = discVld ,Vsrc (F∗ ((V − (Va − Vd ), E)).

where σG (s, t) is the number of shortest paths between s, t ∈
V and σG (s, t|ij) is the subset of these paths that pass through
edge ij ∈ E.

Now, in reality, the defender will have real-world limitations on the number of nodes (i.e. substations) he may
harden. For instance, with regard to smart grid defense, applying the most up-to-date patches on all systems may not
be realistic as it could potentially require system down-time affecting customer service. Further, it would also likely not
make sense for the defender to only harden certain nodes
and ignore others. Hence, it is reasonable to consider a situation where the defender can only harden certain nodes
against attack (and may do so probabilistically - i.e. applying hardware or software updates according to a schedule). Therefore, we study mixed strategies. Such strategies will be specified by probability distributions Pra , Prd
for the attacker and defender respectively. We shall denote
the number of strategies assigned a non-zero probability as
|Pra |, |Prd |. We can define expected payoff as follows.

Starting from initial network G0 = (V0 , E0 ) we use cij to
denote the capacity edge ij ∈ E0 . In a real-world setting,
we would expect to have this information. However, in this
paper, we use the following proxy (similar to [8]).
cij (G0 ) = (1 + α)loadG0 (ij)
where α is a non-negative real that specifies the excess capacity available on that line. We shall refer to α as the
capacity margin. We assume that an edge ij ∈ E fails in
G = (V, E), with E ⊂ E0 , if loadG (ij) > cij (G0 ). Once
nodes (and adjacent edges) in V0 are removed from G0 , this
results in a change of shortest paths between sources and
loads, hence more edges will potentially fail. This cascading
power failure is modeled by a “failure” operator denoted with
F (based on the failure model of [8] - though we note that
our model is a new contribution due to the consideration of
source and load nodes) that maps networks to networks. We
define it as follows.
Definition 2.2 (Failure Operator). The failure operator, F : G → G, is defined as follows:
F((V, E)) = (V, {ij ∈ E|load(V,E) (ij) ≤ cij (G0 )})

Va ∈2V

Intuitively, one application of the failure operator removes
all edges that have exceeded their maximum capacity. We
can define multiple applications of this operator as follows:
(
Fi (G) =

G
F(Fi−1 (G))

Definition 2.4 (Expected Payoff). Let Pra , Prd be
probability distributions over all subsets of V of sizes ka
(resp. kd ) or less. These probability distributions correspond
to a mixed strategy for the attacker and defender respectively.
Hence, given such probability distributions, the expected payoff can be computed as follows:
X
X
ExP(Pra , Prd ) =
Pra (Va )
Prd (Vd )pG (Va , Vd )
Vd ∈2V

In this work our goal is to find the minimax strategy for
the defender - that is the mixed strategy for the defender
that minimizes the attacker’s maximum expected payoff as well as deterministic “best responses” for both players
given the other’s strategy.

if i = 0
otherwise

Clearly, there must exist a fixed point that is reached in
no more than |E| + 1 applications of F. Hence, we shall use
the following notation:

3.

COMPUTATIONAL COMPLEXITY

In this section, we analyze the computational complexity
of determining the best response for each of the agents to
a strategy of its opponent. First, we shall discuss the case
for finding a deterministic strategy for the defender and attacker. Then we shall explore the computational complexity
of finding a mixed strategy. We summarize our complexity
results in Table 3.

F∗ (G) = Fi (G) s.t. Fi (G) = Fi+1 (G)
We now consider two agents: an attacker and a defender.
The attacker’s strategy is to destroy nodes (and their adjacent edges) in an effort to cause a cascading failure that
maximizes the number of load nodes (Vld ) that are disconnected from all source nodes (Vsrc ). Meanwhile, the defender’s strategy is to harden certain nodes such that the

1

Note that this would likely be the case where the attack
and defense occurs in cyber-space, while the cascade occurs
in the physical world.

814

Opponent Strategy
Mixed w. 1 resource
Det. w. fewer resources
Det. w. greater resources
Mixed w. fewer resources
Mixed w. greater resources

Attacker
NP-Compl.
Thm. 3
NP-Compl.
Thm. 3
NP-Compl.
Thm. 3
NP-Compl.
Thm. 3
NP-Compl.
Thm. 3

Defender
PTIME
Prop. 3.2
PTIME
Prop. 3.1
NP-Compl.
Thm. 1
NP-Compl.
Thm. 2
NP-Compl.
Thm. 1

Table 1: Complexity Results for Finding a Deterministic Best Response
We frame the formal combinatorial problem of finding the
best-response for the defender as follows:
Grid-Defend Deterministic Best Response (GD-DBR)
INPUT: Network G = (V, E), attacker mixed strategy Pra
(where each option is of size no greater than ka ), natural
number kd , real numbers X, α
OUTPUT:
“Yes” if there exists a set Vd ⊆ V s.t. |Vd | ≤ kd
P
and Va ∈AT K Pra (Va )pG (Va , Vd ) ≤ X and “no” otherwise.
We shall study this case under several conditions. The
first, and easiest case is when Pra = 1 (the attacker uses a
deterministic strategy) and ka ≤ kd .

instance of GD-DBR. Suppose the defender utilizes this as
a strategy. The attacker then effectively attacks the set V −
Vld −V 0 . Note that as the graph is bi-bipartite, this does not
cause any cascading failure. By the construction, each load
node must be connected to a source node, hence the number
of offline load nodes is X. This gives us a contradiction.
Suppose, BWOC, that there is a “yes” answer to GD-DBR
but a “no” answer to the corresponding instance of Set Cover.
Let V 0 be the certificate for GD-DBR. We note that any element of Vld ∩ V 0 in V 0 can be replaced by a neighboring
node from Vsrc without changing the size of this set and that
such a set would still allow for all load nodes to remain online, let V 00 be this new set. Consider the set {h|vh ∈ V 00 }.
By the contra-positive of the claim, this cannot be a cover
of all elements of S. However, this would also imply that
there is some element vs ∈ Vld that is not connected to V 00
meaning that it fails (as the attacker successfully destroys
all its neighbors). This means that the adversary has a payoff greater than 0 (which is what X was set to) – hence a
contradiction.
Hence, the presence of a more advantageous attacker is
a source of complexity. The next question would be if the
attacker’s behavior, i.e. deterministic vs. non-deterministic,
also affects the complexity of the problem, even if the defender has the advantage. First, let us examine the case
where the attacker has a mixed strategy with ka = 1.
Proposition 3.2. When ka = 1 then GD-DBR is solvable in polynomial time (w.r.t. |Pra |), even when |Pra | ≥ 0.

Proposition 3.1. When ka ≤ kd and |Pra | = 1 then
GD-DBR is solvable in polynomial time.
Proof. As the attacker plays only one strategy and the
defender can defend at least as many nodes as are being
attacked, the defender simply defends all the nodes in the
attacker’s strategy.
However, even with |Pra | = 1, the problem becomes NPhard in the case where ka > kd .
Theorem 1. When ka > kd then GD-DBR is NP-complete,
even when |Pra | = 1 and X is an integer.

Proof. In this case, we can re-write the payoff function
as pG ({v}, Vd ) = 0 if v ∈ Vd and pG ({v}, Vd ) = pG ({v}, ∅)
otherwise. Let V 0 = ∪{Va ∈ AT K|Pra (Va ) > 0}. Note
that each element of V 0 is also a strategy the attacker plays
with a non-zero probability (as the attacker only plays singletons).
Hence, the expected payoff can be re-written as
P
0
v∈V −Vd Pra ({v})pG ({v}, ∅). Therefore, the best a defender can do is defend the top kd nodes in V 0 where
Pra ({v})pG ({v}, ∅) is the greatest - which can be easily computed in polynomial time and allows us to determine the
answer to GD-DBR.
However, if the defender is playing a mixed strategy with
ka > 1, then the problem again becomes NP-complete.

Proof. Clearly, checking if a given deterministic defender
strategy Vd meets the requirements of the “output” of GDDBR can be completed in polynomial-time, providing membership in the class NP.

Theorem 2. When |Pra | > 1 and ka > 1, GD-DBR is
NP-complete, even when kd > ka and X is an integer.
Proof. NP-completeness mirrors that of Theorem 1. For
NP-hardness, we again consider a reduction from set-cover
(defined in the proof of Theorem 1. The embedding can
again be performed in polynomial time as follows: set ka =
maxs∈S |{h|s ∈ h}|, set kd = k, X = 0, α = |H| + |S|,
create G = (V, E), Vsrc , and Vld as per the construction in
Theorem 1. We then set up the mixed strategy as follows:
for each s ∈ S, let Vas = {h|s ∈ h} and Pra (Vas ) = 1/|S|.
Suppose, BWOC, that there is a “yes” answer to set cover
and a “no” answer to the instance of GD-DBR. Consider
set cover solution H ∗ and set Vd = {vh |h ∈ H ∗ }. Note
that Vd meets the cardinality requirement. Note that by
the construction, a source node becomes disconnected only
if all of the load nodes connected to it are attacked, hence
there is some node in the set Vld that is totally disconnected
under at least one attacker strategy - let vs be this node.

For NP-hardness consider the known NP-hard “set cover”
problem [11] that takes as input a natural number k, set
of elements S = {s1 , . . . , sn }, family of subsets of S, H =
{h1 , . . . , hm } and returns “yes” if there is a k-sized (or smaller)
subset of H s.t. their union is equal to S. We can embed
Set Cover into an instance of GD-DBR in polynomial time
with the following embedding: set ka = |H|, kd = k, X = 0,
α = |H| + |S|, create G = (V, E) as follows:
• For each h ∈ H create a node vh and for each s ∈ S create
node vs
• If s ∈ h, create edge (vh , vs ), for each ij ∈ E
• Set Vsrc = {vh |h ∈ H}, Vld = {vs |s ∈ S}, Va = V − Vld

Suppose, by way of contradiction (BWOC), that there is
a “yes” answer to Set Cover but a “no” answer to GD-DBR.
Consider set H 0 a subset of H that is the certificate for Set
Cover and the corresponding set V 0 = {vh |h ∈ H 0 } in the

815

However, as set H ∗ covers S, then regardless of the attacker
strategy, there is always some node vh that is connected and
never attacked (giving the attacker a payoff of zero) - hence
a contradiction.
Suppose, BWOC, that there is a “yes” answer to GD-DBR
and a “no” answer to the instance of set cover. Consider GDDBR solution V 0 . We note that any element of Vld ∩ V 0 in
V 0 can be replaced by a neighboring node from Vsrc without
changing the size of this set and that such a set would still
allow for all load nodes to remain online, let V 00 be this
new set. Consider the set H ∗ = {h|vh ∈ V 00 }. Note that
|H ∗ | ≤ k. By the contra-positive, there must be at least
one element of S not covered by H ∗ . Let node vs be a node
associated with uncovered element s. As GD-DBR returned
“yes” then there is no attacker strategy where vs becomes
disconnected from some node in Vsrc . As attack strategy
Vas includes all nodes that are connected to vs , then at least
one of these nodes must be included in V 00 . Therefore, for
every node vs ∈ Vld there is some node vh ∈ Vld ∩ V 00 that is
connected to it, which means, by the construction, that H ∗
must cover all elements of S - a contradiction.

Suppose, BWOC, the above problem instance provides a
“yes” answer to GA-DBR but a “no” answer to the vertex
cover problem. Let Va be the set of nodes the attacker attacks in GA-DBR. As α = |E| and as Vsrc = V , nodes only
fail in a cascade if they are either targeted by the attacker
or become totally disconnected. Further, as X = |V |, all
nodes in G are either in Va or disconnected - meaning that
Va must be a vertex cover of size ka or less. As ka = k we
have a contradiction.
Due to the use of covering problems for the complexity
results in Theorems 1, 2, and 3, it may seem reasonable to
frame the problem as a sub- or super- modularity optimization where the objective function is monotonic. However,
here we show (unfortunately) that these properties do not
hold for either player. First, we shall make statements regarding the monotonicity of the payoff function.
Proposition 3.3. Iff ∀Vd∗ , Va ⊆ Va0 : pG (Va , Vd∗ ) ≤ pG (Va0 , Vd∗ )
then ∀Va∗ , Vd ⊆ Vd0 : pG (Va∗ , Vd ) ≥ pG (Va∗ , Vd0 ).
The idea of submodularity can be thought of as “diminishing returns.” Given a set of elements S and a function
f : 2S → <+ , we say a f is submodular if for any sets
S1 ⊆ S2 and element s ∈
/ S2 , we have the following relationship:

We now frame the formal problem for finding a deterministic best-response for the attacker below.
Grid-Attack Deterministic Best Response (GA-DBR)
INPUT: Network G = (V, E), defender mixed strategy Prd
(where each option is of size no greater than kd ), natural
number ka , real numbers X, α
OUTPUT:
“Yes” if there exists a set Va ⊆ V s.t. |Va | ≤ ka
P
and Vd ∈DEF Prd (Vd )pG (Va , Vd ) ≥ X and “no” otherwise.

f (S1 ∪ {s}) − F (S1 ) ≥ f (S2 ∪ {s}) − F (S2 )
A complementary idea of supermodularity is also often
studied - in this case the inequality is reversed. Unfortunately, when we fix the strategy for the defender, the attacker strategy is neither submodular nor supermodular making the dynamics of this model significantly different
from others (i.e. [24]). Let consider strategies Va , Vd where
Va causes some load node v ∈
/ (Va ∪ Vd ) ∩ Vld to disconnect
and any node the strategy {v} causes to disconnect will also
become disconnected with strategy Va (such a case is easy to
contrive, particularly with a bi-partite network). Therefore,
we get the following relationship:

In the case of ka = 1, this problem is solvable in polynomial time:
P simply consider each v ∈ V . The attacker
computes Vd ∈DEF Prd (Vd )pG ({v}, Vd ) until one is found
that causes the payoff to exceed or be equal to X. However,
for strategies of larger size, the problem becomes NP-hard,
regardless of the size of the defender strategy.
Fact 3.1. When ka = 1, GA-DBR is solvable in polynomial time (w.r.t. |Prd |).

pG (Va ∪ {v}, Vd ) − pG (Va , Vd ) < pG ({v}, Vd ) − pG (∅, Vd )
This arises from the fact that the left-hand side of the above
equation becomes zero and the right hand side of the equation is equal to pG ({v}, Vd ) which must be at least one. Now
consider another example. Suppose we have a simple Vshaped network of three nodes. The angle of the V is a load
node, while the other two nodes are source nodes. With
α = 1, the load node receives power if at least one of the
source nodes is connected to it. However, it does not require
both. Let Va be a strategy consisting of one source node and
v be the other source node, and Vd consist of the load node.
From this, we have the following relationship:

Theorem 3. GA-DBR is NP-complete.
Proof. Clearly, a certificate consisting of a set Va ⊆ V
can be verified in polynomial time, giving us membership in
NP. For NP-hardness consider the known NP-hard “vertex
cover” problem [11] that takes as input a graph G0 = (V 0 , E 0 )
(with no self-loops) and natural number k and returns “yes”
iff there is a set of k or fewer vertices that are adjacent
to each edge in E. We can embed vertex cover into an
instance of GD-DBR in polynomial time with the following
embedding: set ka = k, kd = 0, Vd = ∅, X = |V 0 |, α = |E|,
G = G0 , and Vsrc = Vld = V 0 .
Suppose, BWOC, the above problem instance provides a
“yes” answer to the vertex cover problem but a “no” answer
to GA-DBR. Let V 00 be a vertex cover of size k or less for G0 .
Consider the corresponding set of vertices in G (we shall call
this V ∗ ). Note that |V ∗ | ≤ ka . As an attacker attacking V ∗
disconnects those nodes from the network, all edges adjacent
to V ∗ fail. As V ∗ is a vertex cover for G, this means that
there are no edges in the graph once V ∗ is removed. Hence,
no load node is connected to any source node - giving the
attacker a payoff of at least X – hence a contradiction.

pG (Va ∪ {v}, Vd ) − pG (Va , Vd ) > pG ({v}, Vd ) − pG (∅, Vd )
In this case, the right-hand side becomes zero while the left
hand side becomes one. This leads us to the following fact:
Fact 3.2. When Vd is fixed, pG is neither submodular nor
supermodular.
Now let us consider when we fix the attacker’s strategy.
If the payoff is submodular when the attacker’s strategy is
fixed, then we have the following for Vd ⊆ Vd0 and v ∈
/ Vd0 if

816

the payoff subtracted from the number of nodes is submodular:
pG (Va , Vd0 ∪ {v}) − pG (Va , Vd0 ) ≥ pG (Va , Vd ∪ {v}) − pG (Va , Vd )
This is equivalent to the following:
pG (Va − (Vd0 ∪ {v}), ∅) − pG (Va − Vd0 , ∅) ≥
pG (Va − (Vd ∪ {v}), ∅) − pG (Va − Vd , ∅)
Now let Va0 = Va − (Vd0 ∪ {v}) and Va00 = Va0
Clearly Va00 ⊇ Va0 and v ∈
/ Va00 . Now we get the

∪ (Vd0 − Vd ).
following:

pG (Va0 , ∅) − pG (Va0 ∪ {v}, ∅)

≥

pG (Va00 , ∅) − pG (Va00 ∪ {v}, ∅)

pG (Va0 ∪ {v}, ∅) − pG (Va0 , ∅)

≤

pG (Va00 ∪ {v}, ∅) − pG (Va00 , ∅)

Hence, submodualrity of the payoff function when the attacker’s strategy is fixed would give us supermodualrity of
the payoff function when the defender’s strategy is fixed at
the empty set. However, this clearly violates Fact 3.2 and
gives rise to the following:

Algorithm 1 GREEDY DEFENDER RESP
Require: Mixed strategy Pra , Natural number kd
Ensure: Set of nodes Vd

1:
2:
3:
4:
5:
6:

Fact 3.3. When Va is fixed, pG is neither submodular
nor supermodular.

4.

ALGORITHMS

In this section, we present heuristic algorithms for finding
the deterministic best response of each player as the results
of the previous section generally preclude a polynomial time
algorithm for an exact solution. We first introduce a version
of a “high load” strategy for the defender based on the ideas
of [8]. Then we introduce a greedy heuristic for each player.
This is followed by our approach for finding mixed strategies
based on the double-oracle algorithm of [15].

7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:

Hi-Load Node Approach. In [8], the authors study “high
load” nodes: nodes through which the greatest number of
shortest paths pass. They show that attacks on these nodes
tend to initiate cascading failures – suggesting that they
should be a priority for defense. We formalize the definition
of nodal load in our framework (essentially an extended definition of node betweenness [25]) by extending our function
loadG for nodes as follows.

Vd = ∅
Let AT K be the set of strategies associated with Pra
Set f lag = True, p∗ = −∞
while |VdP
| ≤ kd and f lag and p∗ < 0 do
p∗ = − Va ∈AT K Prd (Va )pG (Va , Vd )
curBest = null, curBestScore = 0, haveV alidScore =
False
for i ∈ V − Vd do P
curScore = p∗ − Va ∈AT K Prd (Va )pG (Va , Vd ∪ {i})
if curScore ≥ curBestScore then
curBest = i
curBestScore = curScore
haveV alidScore = True
end if
end for
if haveV alidScore = False then
f lag = False
else
Vd = Vd ∪ {curBest}
end if
end while
return Vd .

Finding Mixed Strategies. If the attacker uses a mixed
strategy that consists of uniformly attacking elements of
{S ⊂ Vld : |S| = ka } then the best any pure defender strategy can do is defending Vd ⊂ Vld . The attacker’s strategy ima
.
plies that any node in Vld is attacked with probability |Vkld
|
Each of the |Vld | − ka remaining nodes in Vld is then discona
d
nected with probability |Vkld
, i.e., x ≥ ka (1 − |Vkld
). Clearly
|
|
due to the cascading the value of the game will probably
be higher, illustrating the disadvantage the defender has in
this game. To determine both player’s optimal strategies
and the value of the game we resort to an algorithmic approach. We find the defender’s optimal strategy with the
following linear program. We can find minimax strategy for
the defender with the following linear program. It simply
assigns a probability to each of the defenders strategies in a
manner that minimizes the maximum payoff for the adversary. As a consequence, the solution to the following linear
program, DEF LP can provide the mixed minimax strategy
for the defender. An analogous linear program, ATK LP (not
shown), which mirrors DEF LP, will provide that result for
the attacker.

Definition 4.1 (Nodal Load). For a given node, the
nodal load is defined as the sum of the fraction of shortest
paths for each pair that pass through that node. Formally:
X
σG (s, t|i)
,
loadG (i) =
σG (s, t)
s∈V
,t∈V
src

analogous heuristic for the attacker is not shown due to space
constraints, but we shall refer to it as
GREEDY ATTACKER RESP. We note that while we do not
make general approximation guarantees (due to the results
in Section 3), we note that by Proposition 3.3, that nodes
added in step 18 will always cause an increase in payoff to the
defender (and in the analogous greedy approach for the attacker, this holds true as well). Further, by Proposition 3.2,
when ka = 1, we can be sure that GREEDY DEFENDER RESP
returns an exact solution, even when the attacker has a
mixed strategy. Unfortunately, by Theorem 3, the same cannot be said if the greedy heuristic is used for the attacker’s
best response.

ld

where σG (s, t|i) is the number of shortest paths between s, t ∈
V that pass through node i.
Hence, we shall refer to the Deterministic Load-Based or
DLB strategy for the defender as one in which he deterministically protects the kd nodes with the greatest load. We
note that this is not necessarily a “best response” but the intuition is that defense will occur at nodes that are perceived
to be critical to the adversary. This intuition is similar to
that of the “most vital arc” idea seen in other failure model
games [2, 21].
Greedy Heuristics for Finding Deterministic Strategies. Here we present a simple greedy heuristic to find the
defender’s best-response (GREEDY DEFENDER RESP). The

817

min p∗
subj.to

p∗ ≥

P

Vd ∈DEF

1=

P

(1)

XVd pG (Va , Vd )

Vd ∈DEF

∀Va ∈ AT K (2)

XV d

XVd ∈ [0, 1]

(3)
∀Vd ∈ DEF (4)

50

100

45

90

Payoff (Disconnected Nodes)

(DEF LP).

Payoff (Disconnected Nodes)

Definition 4.2

40
35
30

25
20
15

10
5
0

ka=3

40

ka=2

30
20

ka=1

10

2

4

6

8

10

12

1

2

3

4

5

6

Capacity Margin

Only one core was used for experiments. All algorithms
were coded using Python 2.7 and leveraged the NetworkX
library2 as well as the PuLP library for linear programming3 .
All statistics presented in this section were calculated using
the R statistics software.
In our experiments, we utilized a dataset of an Italian 380
kV power transmission grid [20]. This power grid network
consisted of 310 nodes of which 113 were source, 96 were
load, and the remainder were transmission nodes. The nodes
were connected with 361 edges representing the power lines.
In our initial experiments, we examined the properties
of the model when no defense is employed. In Figure 1
(left) we show results concerning nodal load vs. the payoff
achieved by the adversary if that node is attacked (and no
others). Interestingly, we noticed a significant number of
nodes with low nodal load yet high-payoff if attacked (see
nodes in dashed box). This may suggest that the DLB strategy may be insufficient in some cases. Later we see how DLB
fails to provide adequate in a defense against the attacker
best response to DLB. This is likely due to these hi-payoff,
low-load nodes. In Figure 1 (right) we examine α (capacity
margin) vs. attacker payoff for various settings of ka (using
the GREEDY ATTACKER RESP heuristic). Here we found
that, in general, payoff decreases linearly with capacity margin (R2 ≥ 0.84 for each trial).
Next, we examined the relative performance of the minimax (mixed) defense strategy and the DLB strategy under different resource constraints and against the minimax
(mixed) attack strategy as well as the attacker’s (deterministic) greedy response to the DLB defense. In these experiments, we considered the case where both players have equal
resources, the attacker has one resource (which by Proposition 3.2 and Fact 3.1 we are guaranteed an optimal solution), and the defender has one resource. These results are
displayed in Figure 2. In these trials we set the capacity
margin α = 0.5, meaning that all edges had an excess capacity of 50%. We did not use the maxIters parameter of
the DOUBLE ORACLE algorithm, but instead allowed it to
run until convergence.
With regard to the comparison between DLB and minimax defense, both performed comparably against the minimax attack strategy. In fact, an analysis of variance (ANOVA)
indicated little variance between the two when faced with the
minimax attacker (p ≥ 0.74 for these trials). Yet, a defender
known to be playing a single strategy would likely not face
an attacker who plays the minimax strategy, but rather the

1: Initialize numIters = 0, f lag = True
2: Initialize the sets of strategies AT K, DEF to both be {∅}
3: while f lag and numIters ≤ maxIters do
4:
Create Pra , Prd based on the solutions to ATK LP and
DEF LP respectively.
IF numIters < maxIters THEN let Va be the attacker’s
best response to Prd and Vd be the defender’s best response to Pra
IF Va ∈ AT K and Vd ∈ DEF THEN f lag = False ELSE
AT K = AT K ∪ {Va }, DEF = DEF ∪ {Vd }
numIters+ = 1
end while
return Pra .

The intuition behind the above algorithm is that it iteratively creates mixed strategies for both the attacker and defender based on a solution to a linear program over the sets
of current possible strategies for both players (AT K, DEF ).
This is followed by finding (for each player) the best deterministic response to it’s opponent’s strategy. If these new
strategies are both already in the set of possible strategies
for the respective players, the algorithm terminates. Otherwise, they are added to AT K, DEF respectively. We note
that by Theorem 1 of [15] that the above algorithm will guarantee an exact solution if maxIters is set to the number of
possible strategies. In practice, [15] demonstrates that the
algorithm converges much faster.
In DOUBLE ORACLE, the finding the solutions to DEF LP,
ATK LP will be tractable provided that the algorithm converges in a polynomial number of steps (either through convergence or after the specified maxIters). However, as we
have shown, computing the best responses is usually computationally difficult. Although, we note in the case where
ka = 1, that by Proposition 3.2 and Fact 3.1, the double oracle algorithm will return an optimal solution, even if greedy
approximations are used for the oracles (provided it runs
until convergence).

5.

ka=4

50

Figure 1: Left: Nodal load vs. payoff (note hi-payoff,
low-load nodes in the dashed box), Right: Capacity
margin (α) vs. payoff

Require: Network G = (V, E), natural number maxIters
Ensure: Mixed defender strategy Prd

7:
8:
9:

ka=5

60

Nodal Load

Algorithm 2 DOUBLE ORACLE

6:

ka=6

70

0
0

Note that the above linear program requires one variable
for each of the defender’s strategies and one constraint for
each of the attacker’s strategies. However, as there are a
combinatorial number of strategies, even writing down such
a linear program is not practical except for very small problem instances. To address this issue of intractability, we
employ the double-oracle framework for zero-sum games introduced in [15] and has been applied in more recent work
as well [5, 12]. We present the algorithm DOUBLE ORACLE
as follows:

5:

80

EXPERIMENTAL EVALUATION

All experiments were run on a computer equipped with
an Intel X5677 Xeon Processor operating at 3.46 GHz with
a 12 MB Cache and 288 GB of physical memory. The machine was running Red Hat Enterprise Linux version 6.1.

2
3

818

http://networkx.lanl.gov/
http://pythonhosted.org/PuLP/

Greedy Attacker Response to DLB
90

Minimax
Defense

60
50

40

DLB Defense

30
20
10

80
70

60
50

40
30

20

2

3

4

5

6

Equal resources

ka=kd
200
150

Advantageous
defender

kd=1

100

1

2

Resources (ka=kd)

3

4

5

ka=1
1

6

2

3

4

5

6

Advantageous
Attacker

max(ka,kd)

Resources (ka=kd)

10

ka=kd=5
ka=kd=4

8
6
4
2

0

0
1

250

50

10

0

ka=kd=6

12

300

Run-time (hours)

70

14

350

Run-time (hours)

100

80

Expected Payoff
(Disconnected Nodes)

Expected Payoff
(Disconnected Nodes)

Minimax Attack Strategy
90

0

ka=kd=3
ka=kd=2
ka=kd=1
1 4 7 10 13 16 19 22 25 28 31 34 37 40 43 46

Iteration Number

50

30

Minimax
Defense

20
15

DLB Defense

10
5

Expected Payoff
(Disconnected Nodes)

Expected Payoff
(Disconnected Nodes)

45

25

40

Figure 3: Strategy size vs. run-time in hours (left)
and the run-time of each iteration for the experiments where ka = kd

35
30
25
20
15
10
5

0

0
1

3

4

5

6

1

2

Resources (kd)
100

4

5

6

5

6

each iteration, not a cumulative time). This increase is
likely the combined result of the growing linear program
and the growing size of the mixed strategies considered by
the greedy approximation sub-routines. We are currently
exploring reliable methods to limit the number of iterations
while maintaining defender payoff.

100

90

90

80

Minimax
Defense

70

60
50
40

DLB Defense

30
20
10

Expected Payoff
(Disconnected Nodes)

Expected Payoff
(Disconnected Nodes)

3

Resources (kd)

80
70
60
50
40
30

20
10

0

0
1

2

3

4

Resources (ka)

5

6

1

2

3

4

6.

Resources (ka)

RELATED WORK

Network security has received much attention from the
research community in the past two decades. Recent incidents have shown that due to their internet connectedness
such networks can come under cyber attack, causing severe
problems4 . See [26] for a discussion of cyber-security issues
relevant to smart grid grids.
The utilization of game theory in designing defense solutions seems ubiquitous. For instance [13] model the interaction between a DDoS attacker and the network administrator while [14] considers a game theoretic formulation for intrusion detection. Other formulations consist include stochastic games [17], signaling games [19], allocation
games [4] and repeated games [3]. Game theory is also being used in monitoring and decision making in smart grids,
see for instance [9] or the survey by Fadlullah et al. [10].
However to date no game theoretic approach has been given
for the specific problem where the attacker explicitly sets of
a cascading power failure to maximize the damage to the
defender.
Cascading failure models applied to power grid infrastructure have been studied in the past [7, 8, 16]. The model of
[8] introduces the idea of edge failure based on excessive
loads. The goal of the research presented in these papers
was to illustrate properties of the cascade, rather than explore strategies for attack and defense as this work does.
There has been work on attack and defense of a power-grid
network under the DC power-flow mode [2, 21, 20, 6]. However, the DC power flow model is not designed to model the
more rapid cascading failures (i.e. the 2003 cascading failure
in the eastern United States [1]).
The application of game theory to security situations was
made popular by [18] where it used for airport security patrol scheduling. Since then, other applications have emerged
including port protection [23], finding weapons caches [22],
and security checkpoint placement [12]. One that bears similarity to this work is [24] - studying games for controlling
contagions on a network. However, as previously discussed,
that model operates under very different dynamics.

Figure 2: Minimax and DLB defense strategies vs.
minimax attack strategy (left) and the attacker’s
greedy best response to DLB (right). Examined are
the cases where ka = kd (top), ka = 1, kd varies (middle) and kd = 1, ka varies (bottom).

best response to the DLB. In this case, DLB play resulted
in significantly greater payoff to the attacker than the defender (p ≤ 0.29 for these trials, the DLB defense results in
15.6 more disconnected nodes on average). This failure of
the DLB strategy to perform well against a deterministic attacker best response is likely due to the presence of low-load
yet high-payoff nodes as shown in Figure 1.
We also noticed that an increase in resources seems to favor the attacker more than the defender. When both players played their respective minimax strategy, the expected
payoff for the attacker increased monotonically with the cardinality of the strategies. Further, when kd = 1 and ka was
greater, the attacker’s payoff tripled when his resources increased from 1 to 6. However, when ka = 1 and kd was
greater, the defender’s payoff only increased by a factor of
1.7. Hence, the attacker can cause more damage than the
defender can mitigate with the same amount of extra resources. We suspect that this is likely because a defended
node can still fail during a cascade - which would likely be
the case if the attack and defense operations are restricted to
cyber-space, where physical system failure may still be possible as the result of a cascade initiated by virtual means.
We also examined the run-time of our approach, as displayed in Figure 3 (left). Though run-time did seem to scale
linearly with strategy size (R2 = 0.90 ± 0.2 for each experiment), it appears that run-time will in general prohibit the
study of larger strategies or networks (our longest experiment ran for 12 days). In examining the iterations of the
DOUBLE ORACLE algorithm, Figure 3 (left), we find that
run-time of an iteration of the algorithm progressively increases (note that this figure is showing the run-time for

4

819

http://www.wired.com/threatlevel/2009/10/smartgrid/

7.

CONCLUSION

In this paper, we explored complexity, algorithmic, and
implementation issues in a two-player security game where
the attacker/defender look to create/mitigate cascading failure on a power grid. Future work includes an examination
of scalability issues (larger networks and strategies), adding
uncertainty to the model, and the consideration of more realworld information about the power grid network (i.e. actual
line capacities, etc.) in order to create a richer model.

[12]

[13]

[14]

8.

ACKNOWLEDGMENTS

We would like to thank D. Alderson for his input on related work and V. Rosato for providing us the power grid
dataset. Some of the authors are supported by ARO project
2GDATXR042. The opinions in this paper are those of the
authors and do not necessarily reflect the opinions of the
funders, the U.S. Military Academy, or the U.S. Army.

[15]

9.

[16]

REFERENCES

[1] Final Report on the August 14, 2003 Blackout in the
United States and Canada: Causes and
Recommendations. U.S.-Canada Power System
Outage Task Force, April 2004.
[2] D. L. Alderson, G. G. Brown, M. W. Carlyle, and
L. Anthony Cox. Sometimes there is no ”most-vital”
arc: Assessing and improving the operational
resilience of systems. Military Operations Research,
18(1):21–37, 2013-03-01T00:00:00.
[3] T. Alpcan and T. Basar. A game theoretic analysis of
intrusion detection in access control systems. In
Decision and Control, 2004. CDC. 43rd IEEE
Conference on, volume 2, pages 1568–1573 Vol.2, 2004.
[4] M. Bloem, T. Alpcan, and T. Başar. Intrusion
Response as a Resource Allocation Problem. Decision
and Control, 2006 45th IEEE Conference on, pages
6283–6288, Dec. 2006.
[5] B. Bosanský, C. Kiekintveld, V. Lisý, J. Cermak, and
M. Pechoucek. Double-oracle algorithm for computing
an exact nash equilibrium in zero-sum extensive-form
games. In AAMAS, pages 335–342, 2013.
[6] G. Brown, M. Carlyle, J. Salmeron, and K. Wood.
Defending critical infrastructure. Interfaces,
36(6):530–544, Nov. 2006.
[7] S. V. Buldyrev, R. Parshani, G. Paul, H. E. Stanley,
and S. Havlin. Catastrophic cascade of failures in
interdependent networks. Nature,
464(7291):1025–1028, Apr. 2010.
[8] P. Crucitti, V. Latora, and M. Marchiori. Model for
cascading failures in complex networks. Phys. Rev. E,
69(4):45104, 2004.
[9] M. Esmalifalak, G. Shi, Z. Han, and L. Song. Bad
data injection attack and defense in electricity market
using game theory study. IEEE Trans. Smart Grid,
4(1):160–169, 2013.
[10] Z. Fadlullah, Y. Nozaki, A. Takeuchi, and N. Kato. A
survey of game theoretic approaches in smart grid. In
Wireless Communications and Signal Processing
(WCSP), 2011 International Conference on, pages
1–4, 2011.
[11] M. R. Garey and D. S. Johnson. Computers and
Intractability; A Guide to the Theory of

[17]

[18]

[19]

[20]

[21]

[22]

[23]

[24]

[25]

[26]

820

NP-Completeness. W. H. Freeman & Co., New York,
NY, USA, 1979.
M. Jain, V. Conitzer, and M. Tambe. Security
scheduling for real-world networks. In International
Conference on Autonomous Agents and Multiagent
Systems (AAMAS), 2013.
P. Liu, W. Zang, and M. Yu. Incentive-based modeling
and inference of attacker intent, objectives, and
strategies. ACM Trans. Inf. Syst. Secur., 8(1):78–118,
Feb. 2005.
Y. Liu, C. Comaniciu, and H. Man. A bayesian game
approach for intrusion detection in wireless ad hoc
networks. In Proceeding from the 2006 workshop on
Game theory for communications and networks,
GameNets ’06, New York, NY, USA, 2006. ACM.
H. B. McMahan, G. J. Gordon, and A. Blum.
Planning in the presence of cost functions controlled
by an adversary. In T. Fawcett and N. Mishra, editors,
ICML, pages 536–543. AAAI Press, 2003.
A. E. Motter and Y. C. Lai. Cascade-based attacks on
complex networks. Phys. Rev. E, 66(6), Dec. 2002.
K. C. Nguyen, T. Alpcan, and T. Basar. Security
games with incomplete information. In ICC, pages
1–6. IEEE, 2009.
P. Paruchuri, J. P. Pearce, J. Marecki, M. Tambe,
F. Ordonez, and S. Kraus. Playing games for security:
an efficient exact algorithm for solving bayesian
stackelberg games. In AAMAS, pages 895–902,
Richland, SC, 2008.
A. Patcha and J.-M. Park. A game theoretic approach
to modeling intrusion detection in mobile ad hoc
networks. In Information Assurance Workshop, 2004.
Proc. from the Fifth Annual IEEE SMC, pages
280–284, 2004.
V. Rosato, L. Issacharoff, F. Tiriticco, S. Meloni, S. D.
Porcellinis, and R. Setola. Modelling interdependent
infrastructures using interacting dynamical models.
IJCIS, 4(1/2):63–79, 2008.
J. Salmeron, K. Wood, and R. Baldick. Analysis of
electric grid security under terrorist threat. Power
Systems, IEEE Transactions on, 19(2):905–912, May
2004.
P. Shakarian, J. P. Dickerson, and V. S.
Subrahmanian. Adversarial geospatial abduction
problems. ACM Trans. Intell. Syst. Technol.,
3(2):34:1–34:35, Feb. 2012.
E. Shieh, B. An, R. Yang, M. Tambe, C. Baldwin,
J. DiRenzo, B. Maule, and G. Meyer. Protect: a
deployed game theoretic system to protect the ports of
the united states. In AAMAS, pages 13–20, Richland,
SC, 2012.
J. Tsai, T. H. Nguyen, and M. Tambe. Security games
for controlling contagion. In J. Hoffmann and
B. Selman, editors, AAAI. AAAI Press, 2012.
S. Wasserman and K. Faust. Social Network Analysis:
Methods and Applications. Number 8 in Structural
analysis in the social sciences. Cambridge University
Press, 1 edition, 1994.
D. Wei, Y. Lu, M. Jafari, P. Skare, and K. Rohde.
Protecting smart grid automation systems against
cyberattacks. Smart Grid, IEEE Transactions on,
2(4):782–795, 2011.

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

Malware Task Identification: A Data Driven
Approach
Eric Nunes, Casey Buto, Paulo Shakarian
School of Computing, Informatics and
Decision Systems Engineering
Arizona State University
Tempe, AZ 85281, USA
Email: {enunes1, cbuto, shak} @asu.edu

Christian Lebiere,
Stefano Bennati,
Robert Thomson
Carnegie Mellon University
Pittsburgh, PA 15218
Email: {cl@cmu.edu ,
{sbennati, thomsonr} @andrew.cmu.edu}

Abstract—Identifying the tasks a given piece of malware was
designed to perform (e.g. logging keystrokes, recording video,
establishing remote access, etc.) is a difficult and time-consuming
operation that is largely human-driven in practice. In this paper,
we present an automated method to identify malware tasks.
Using two different malware collections, we explore various
circumstances for each - including cases where the training
data differs significantly from test; where the malware being
evaluated employs packing to thwart analytical techniques; and
conditions with sparse training data. We find that this approach
consistently out-performs the current state-of-the art software for
malware task identification as well as standard machine learning
approaches - often achieving an unbiased F1 score of over 0.9.
In the near future, we look to deploy our approach for use by
analysts in an operational cyber-security environment.

I.

Earlier work has sought to classify malware by similar
“families” which has been explored as a supervised classification problem [2], [15], [16]. However, differences over “ground
truth” for malware families (e.g. Symantec and McAfee cluster
malware into families differently) and the tendency for automated approaches to primarily succeed at “easy to classify”
samples [19], [23] are two primary drawbacks of malware
family classification. More recently, there has been work on
directly inferring the tasks a malware was designed to perform [12]. This approach leverages static malware analysis (i.e.
analysis of the malware sample conducted without execution,
such as decompilation) and a comparison with a crowd-source
database of code snippets using a proprietary machine leaning
U.S. Provisional Patent 62/182,006. Contact shak@asu.edu for licensing
information.

ASONAM '15, August 25-28, 2015, Paris, France
© 2015 ACM. ISBN 978-1-4503-3854-7/15/08 $15.00
DOI: http://dx.doi.org/10.1145/2808797.2808894

978

Sentar Inc.
Huntsville, AL 35805
Email: holger.jaenisch@sentar.com

approach. However, a key shortcoming of the static method is
that it is of limited value when the malware authors encrypt
part of their code – as we saw with the infamous Gauss
malware [14]. This work builds upon recent developments
in the application of cognitive models to intelligence analysis tasks [18] and our own preliminary studies on applying
cognitive models to identify the tasks a piece of malware was
designed to perform [17], [27]. Specifically, the contributions
of this paper include,
•

I NTRODUCTION

Identifying the tasks a given piece of malware was designed
to perform (e.g. logging keystrokes, recording video, establishing remote access, etc.) is a difficult and time consuming task
that is largely human-driven in practice [24]. The complexity
of this task increases substantially when you consider that
malware is constantly evolving, and that how each malware
instance is classified may be different based on each cybersecurity expert’s own particular background. However, automated solutions are highly attractive for this problem as it can
significantly reduce the time it takes to conduct remediation
in the aftermath of a cyber-attack.

Holger Jaenisch

•

•

•

Experimental results illustrating consistent and significant performance improvements (in terms of precision, recall, and F1) of the instance-based cognitive
model approach when compared with various standard
machine learning approaches (including SVM, logistic regression and random forests) for two different
sandboxes and for two different datasets.
Experimental results showing a consistent and significant performance improvement of the instance-based
cognitive model and several other machine learning
approaches when compared to the current state-of-theart commercial technology (which is based on static
analysis).
Experiments where we study cases where the malware
samples are mutated, encrypted, and use different
carriers - providing key insights into how our approach
will cope with operational difficulties.
Experimental results illustrating that a cognitivelyinspired intermediate step of inferring malware families provides improved performance in the machine
learning and rule-based cognitive model (though no
significant change to the instance-based cognitive
model).

This paper is organized as follows. In Section II we state
the technical preliminaries used in the paper. In Section III
we introduce our cognitive-based approaches, describing the
algorithms and explaining our selection of parameter settings.
This is followed by a description of the baseline approaches
that we studied in our evaluation in Section IV-A and a
description of the two different dynamic malware sandbox
environments we used in Section IV-B. In Section V we present
our suite of experimental results which include experiments
involving samples discovered by Mandiant, Inc. in their APT1
report [21] and samples created using the GVDG [11] tool. Fi-

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
nally, related work and conclusion are discussed in Section VI
and Section VII respectively.
II.

T ECHNICAL P RELIMINARIES

Throughout this paper, we shall assume that we have a set
of malware samples that comprise a historical corpus (which
we shall denote M) and each sample i ∈ M is associated with
a set of tasks (denoted tasks(i)) and a set of attributes (denoted
attribs(i)). Attributes are essentially binary features associated
with a piece of malware that we can observe using dynamic
and/or static analysis while the tasks - which tell us the higherlevel purpose of the malware - must be determined by a human
reviewing the results of such analysis. As M comprises our
historical knowledge, we assume that for each i ∈ M both
tasks(i) and attribs(i) are known. For a new piece of malware,
we assume that we only know the attributes. We also note that
throughout the paper, we will use the notation | · | to denote
the size of a given set. Tables 1 and 2 provide an example of
the attributes and tasks based on the malware samples from
the Mandiant APT1 dataset (created from samples available
at [22], see also [21]). A full description of this dataset is
presented in Section V.
TABLE 1: Attributes extracted through automated malware
analysis

review some of the major concepts of the ACT-R framework
that are relevant to these models and provide a description of
both approaches.
We leveraged features of the declarative memory and
production system of the ACT-R architecture to complete
malware task identification. These systems store and retrieve
information that correspond to declarative and procedural
knowledge, respectively. Declarative information is the knowledge that a person can attend to, reflect upon, and usually
articulate in some way (e.g., by declaring it verbally or by
gesture). Conversely, procedural knowledge consists of the
skills we display in our behavior, generally without conscious
awareness.
Declarative Knowledge. Declarative knowledge is represented
formally in terms of chunks. Chunks have an explicit type, and
consist of an ordered list of slot-value pairs of information.
Chunks are retrieved from declarative memory by an activation
process, and chunks are each associated with an activation
strength which in turn is used to compute an activation
probability. In this paper, chunks will typically correspond to
a malware family. In the version of ACTR-IB where we do
not leverage families, the chunks correspond with samples in
the training data.
For a given chunk i, the activation strength Ai is computed

Attribute

Intuition

usesDLL(X)

Malware uses a library X

regAct(K)

Malware conducts an activity in the registry, modifying key K.

fileAct(X)

Malware conducts an activity on certain file X

proAct

Malware initiates or terminates a process

as,
Ai = Bi + Si + Pi

TABLE 2: Sample of malware tasks
Task

Intuition

beacon

Beacons back to the adversary’s system

enumFiles

Designed to enumerate files on the target

serviceManip

Manipulates services running on the target

takeScreenShots

Takes screen shots

upload

Designed to upload files from the target

Throughout the paper, we will also often consider malware
families, using the symbol F to denote the set of all families.
Each malware sample will belong to exactly one malware
family, and all malware samples belonging to a given family
will have the same set of tasks. Hence, we shall also treat each
element of F as a subset of M.
III.

ACT-R BASED A PPROACHES

We propose two models built using the mechanisms of
the ACT-R (Adaptive Control of Thought-Rational) cognitive
architecture [1]. These models leverage the work on applying
this architecture to intelligence analysis problems [18]. In particular, we look to leverage our recently-introduced instancebased (ACTR-IB) and rule-based (ACTR-R) models [17], [27].
Previous research has argued the ability of instance-based
learning in complex dynamic situations making it appropriate
for sensemaking [10]. On the other hand the rule-based learning is a more compact representation of associating samples
in memory with their respective families. In this section, we

979

(1)

where, Bi is the base-level activation, Si is the spreading
activation, and Pi is the partial matching score. We describe
each of these in more detail as follows.
Base-Level Activation (Bi ): The base-level activation for
chunk i reflects the frequency of samples belonging to a
particular family in memory . More important, base-level is
set to the log of the prior probability (i.e., the fraction of
samples associated with the chunk) in ACTR-R; for instancebased (ACTR-IB), we set it to a base level constant βi .
Spreading Activation (Si ): The spreading activation for chunk
i is based on a strength of association between chunk i and
the current test malware sample being considered. The strength
of association is computed differently in both approaches and,
in some cognitive model implementations, is weighted (as is
done in ACTR-R of this paper).
Partial Matching (Pi ): A partial matching mechanism computes the similarity between two samples. In this work, it
is only relevant to the instance-based approach. Given a test
sample j, its similarity with a sample i in memory is computed
as a product of the mismatch penalty (mp, a parameter of the
system) and the degree of mismatch Mji . We define the value
of Mji to be between 0 and −1; 0 indicates complete match
while −1 complete mismatch.
As common with models based on the ACT-R framework,
we shall discard chunks whose activation strength is below a
certain threshold (denoted τ ). All the chunks with activation
greater than τ are denoted as Aj . Once the activation strength,
Ai , is computed for a given chunk, we can then calculate
the activation probability, Pri . This is the probability that
the cognitive model will recall that chunk and is computed
using the Boltzmann(softmax) equation [25], which we provide

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
below.

B. ACT-R Rule-Based Model
Ai
s

(e )
P ri = P Aj
s )
j (e

(2)

Here, e is the base of the natural logarithm and s is momentary
noise inducing stochasticity by simulating background neural
activation (this is also a parameter of the system).

A. ACT-R Instance-Based Model
The instance based model is an iterative learning method
that reflects the cognitive process of accumulating experiences
(in this case the knowledge base of training samples) and
using them to predict the tasks for unseen test samples. Each
malware instance is associated with a set of attributes. When
a new malware sample is encountered, the activation strength
of that sample with each sample in memory is computed
using Equation 1. The spreading activation is a measure of
the uniqueness of the attributes between a test sample i and
a sample j in memory. To compute the spreading activation
we compute the f an for each attribute a (f an(a) finds all
instances in memory with the attribute a) of the test sample
i. The Partial matching is computed as explained above. The
degree of mismatch is computed as the intersection between
the attribute vector of the given malware and each sample
in memory normalized using the Euclidean distance between
the two vectors. The retrieval probability of each sample j
in memory with respect to the test sample i is then computed
using Equation 2. This generates a probability distribution over
families. The tasks are then determined by summing up the
probability of the families associated with that task with an
appropriately set threshold (we set that threshold at 0.5, based
on rationality).
Algorithm 1 ACT-R Instance-based Learning
INPUT: New malware sample i, historical malware corpus
M.
OUTPUT: Set of tasks associated with sample i.
for query malware sample i do
for all j in M do
Bj = βj
Pj = mp × √|attribs(i)∩attribs(j)|

In this version of ACT-R model we classify samples based
on simple rules computed during the training phase. Given a
malware training sample with its set of attributes a, along with
the ground truth value family, we compute pair of conditional
probabilities p(a|f ) and p(a|¬f ) for an attribute in a piece
of malware belonging (or not belonging) to family f . These
probabilistic rules (conditional probabilities) are used to set
the strength of association of the attribute with a family
(sa,f ). We use empirically determined Bayesian priors p(f )
to set the base-level of each family as opposed to using a
constant base-level for instance based. Only two components
of the activation function in Equation 1 are used, namely
base-level and spreading activation. Given the attributes for
current malware , we calculate the probability of the sample
belonging to each family according to Equation 2, generating
a probability distribution over families. The task are then
determined in a similar way to that of instance-based model.
Algorithm 2 ACT-R Rule-based Learning
INPUT: New malware sample i, historical malware corpus
M.
OUTPUT: Set of tasks associated with new sample i.
TRAINING:
S
Let X = j∈M attrib(j)
for all a in X do
Compute the set of rules p(a|f ) and p(a|¬f )
(where p(a|f ) = |{i∈M∩f s.t.|f |a∈attrib(i)}|
s.t. a∈attrib(i)}|
and p(a|¬f ) = |{i∈M−f |M|−|f
)
|
end for
TESTING:
for all f ∈ F do
|f |
Bf = log(p(f )) (where p(f ) = |M|
)
Sf = 0.0
for all a ∈ attrib(i) do
w×sa,f
p(a|f )
sa,f = log( p(a|¬f
) ); Sf += |attribs(i)|
end for
Af = Bf + Sf
end for
Calculate Prf as per Equation 2
tp = {t ∈ T |pf ≥ 0.5}

|attribs(i)|×|attribs(j)|

sij = 0.0
for a ∈ attribs(i) do
if a ∈ attribs(j) then
sij += log( |f|M|
an(a) |)
else
1
sij += log( |M|
)
end if
end for
P
sij
Sj = j |attribs(i)|
Calculate Aj as per Equation 1
end for
Calculate
P Prj as per Equation 2
Prf = j∈f s.t. Aj ≥τ Prj
tp = {t ∈ T | Prf ≥ 0.5}
end for

C. Model Parameter Settings
The two proposed models leverage separate components of
the activation function. Table 3 provides a list of parameters
used for both the ACT-R models - we use standard ACT-R
parameters that have been estimated from a wide range of
previous ACT-R modeling studies from other domains [28] and
which are also suggested in the ACT-R reference manual [3].
The intuition behind these parameters is as follows. The
parameter s injects stochastic noise in the model. It is used to
compute the variance of the noise distribution and to compute
the retrieval probability of each sample in memory. The
mismatch penalty parameter mp is an architectural parameter
that is constant across samples, but it multiplies the similarity
between the test sample and the samples in knowledge base.
Thus, with a large value it penalizes the mismatch samples

980

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
more. It typically trades off against the value of the noise s
in a signal-to-noise ratio manner: larger values of mp lead
to more consistent retrieval of the closest matching sample
whereas larger values of s leads to more common retrieval of
poorer matching samples.The activation threshold τ determines
which samples will be retrieved from memory to make task
prediction decisions. The base level constant β is used to avoid
retrieval failures which might be caused due to high activation
threshold. The source activation w is assigned to each retrieval
to avoid retrieval failures for rule-based models.
TABLE 3: Parameters for the Cognitive models
Model

Parameters

Instance Based Learning

β = 20 (base-level constant)
s = 0.1 (stochastic noise parameter)
τ = -10 (activation threshold)
mp = 20(mismatch penalty)

Rule Based learning

s = 0.1 (stochastic noise parameter)
w = 16 (source activation)

IV.

predictors used in combination to classify new unseen samples.
We use a random forest which combines bagging for each
tree with random feature selection at each node to split the
data thus generating multiple decision tree classifiers [4]. Each
decision tree gives its own opinion on test sample classification
which are then merged to generate a probability distribution
over families.
Support Vector Machine (SVM). Support vector machines
(SVM) was proposed by Vapnik [7]. SVM’s work by finding
a separating margin that maximizes the geometric distance
between classes. The separating margin is termed as hyperplane. We use the popular LibSVM implementation [5] which
is publicly available.
Logistic Regression (LOG-REG). Logistic regression classifies samples by computing the odds ratio. The odds ratio
gives the strength of association between the attributes and
the family like simple rules used in the ACT-R rule based
learning. We implement the multinomial logistic regression
which handles multi-class classification.

E XPERIMENTAL S ETUP

A. Baseline Approaches

B. Dynamic Malware Analysis

We compare the proposed cognitive models against a
variety of baseline approaches - one commercial package and
five standard machine learning techniques. For the machine
learning techniques, we generate a probability distribution
over families and return the set of tasks associated with a
probability of 0.5 or greater while the commercial software
was used as intended by the manufacturer. Parameters for all
baseline approaches were set in a manner to provide the best
performance.
Commercial Offering: Invencia Cynomix. Cynomix is a malware analysis tool made available to researchers by Invencia
industries [12] originally developed under DARPA’s Cyber
Genome project. It represents the current state-of-the-art in
the field of malware capability detection. Cynomix conducts
static analysis of the malware sample and uses a proprietary
algorithm to compare it to crowd-sourced identified malware
components where the functionality is known.
Decision Tree (DT). Decision tree is a hierarchical recursive
partitioning algorithm. We build the decision tree by finding
the best split attribute i.e. the attribute that maximizes the
information gain at each split of a node. In order to avoid
over-fitting, the terminating criteria is set to less than 5% of
total samples. Malware samples are tested by the presence and
absence of the best split attribute at each level in the tree till
it reaches the leaf node.
Naive Bayes Classifier (NB). Naive Bayes is a probabilistic
classifier which uses Bayes theorem with independent attribute
assumption. During training we compute the conditional probabilities of a given attribute belonging to a particular family.
We also compute the prior probabilities for each family i.e.
fraction of the training data belonging to each family. Naive
Bayes assumes that the attributes are statistically independent
hence the likelihood for a sample S represented with a
set of attributes a associated
with a family f is given as,
Qd
Pr(f |S) = P (f ) × i=1 Pr(ai |f ), where d is the number
of attributes in a.
Random Forest (RF). Ensemble methods are popular classification tools. It is based on the idea of generating multiple

Dynamic analysis studies a malicious program as it executes on the host machine. It uses tools like debuggers,
function call tracers, machine emulators, logic analyzers, and
network sniffers to capture the behavior of the program. We
use two publicly available malware analysis tools to generate
attributes for each malware sample. These tools make use of
a sandbox which is a controlled environment to run malicious
software.
Anubis Sandbox. Anubis [13] is an online sandbox which
generates an XML formated report for a malware execution in
a remote environment. It generates detailed static analysis of
the malware but provides less details regarding the behavior of
the malware on the host machine. Since it is hosted remotely
we cannot modify its settings.
Cuckoo Sandbox. Cuckoo [6] is a standalone sandbox implemented using a dedicated virtual machine and more importantly can be customized to suit our needs. It generates
detailed reports for both static as well as behavior analysis by
watching and logging the malware while its running on the
virtual machine. These behavior analysis prove to be unique
indicators for a given malware for the experiments.

981

C. Performance Evaluation
In our tests, we evaluate performance based primarily
on four metrics: precision, recall, unbiased F1, and family
prediction accuracy. For a given malware sample being tested,
precision is the fraction of tasks the algorithm associated with
the malware that were actual tasks in the ground truth. Recall,
for a piece of malware, is the fraction of ground truth tasks
identified by the algorithm. The unbiased F1 is the harmonic
mean of precision and recall. In our results, we report the
averages for precision, recall, and unbiased F1 for the number
of trials performed. Our measure of family accuracy - the
fraction of trials where the most probable family was the
ground truth family of the malware in question - is meant
to give some insight into how the algorithm performs in the
intermediate steps.

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
R ESULTS

All experiments were run on Intel core-i7 operating at 3.2 GHz
with 16 GB RAM. Only one core was used for experiments.
All experimental results presented in this section are new and
have not been previously introduced.
A. Mandiant Dataset
Our first set of experiments uses a dataset based on the
the T1 cyber espionage group as identified in the popular
report by Mandiant Inc [21]. This dataset consisted of 132
real malware samples associated with the Mandiant report
that were obtained from the Contagio security professional
website [22]. Each malware sample belonged to one of 15
families including BISCUIT, NEWSREELS, GREENCAT and
COOKIEBAG. Based on the malware family description [21],
we associated a set of tasks with each malware family (that
each malware in that family was designed to perform). In
total, 30 malware tasks were identified for the given malware
samples (see Table 2). On average, each family performed 9
tasks.
We compared the four machine learning approaches with
the rule based and instance-based ACT-R models (ACTR-R
and ACTR-IB respectively). We also submitted the samples
to the Cynomix tool for automatic detection of capabilities.
These detected capabilities were then manually mapped to
the tasks from the Mandiant report. Precision and recall
values were computed for the inferred adversarial tasks. On
average the machine learning approaches predicted 9 tasks per
sample, ACTR-R predicted 9 tasks per sample and ACTR-IB
predicted 10 tasks. On the other hand Cynomix was able to
detect on average only 4 tasks.

Average

Leave one out Cross-Validation(LOOCV)
In leave one out cross validation, for n malware samples,
we train on n − 1 samples and test on the remaining one.
This procedure was repeated for all samples and the results
were averaged. We performed this experiment using both
sandboxes and compared the results (see Fig. 1).
1

1

0.9
0.8
0.7
0.6
0.5
Precision

LOG-REG

SVM

Recall

RF

ACTR-R

F1

ACTR-IB

Family
Prediction
INVINCEA

Fig. 2: Average Precision, Recall, F1 and Family prediction
comparisons for LOG-REG, RF, SVM, ACTR-R, ACTR-IB
and INVINCEA.
Fig. 2 compares the performance of the five best performing methods from Fig. 1 and compares it with the Cynomix
tool of Invincea industries. ACTR-IB outperformed LOGREG, SVM, RF and ACTR-R; average F1 = 0.97 vs 0.85 (t
(132) = 7.85, p < .001), 0.9 (t (132) = 4.7, p < .001), 0.89
(t (132) = 5.45, p < .001) and 0.88 (t (132) = 5.2, p < .001)
respectively. Both the proposed cognitive models and machine
learning techniques significantly outperformed the Cynomix
tool in detecting the capabilities (tasks).
These three approaches (LOG-REG, SVM, RF) were
also evaluated with respect to predicting the correct family
(before the tasks were determined). ACTR-IB outperformed
LOG-REG, SVM, RF and ACTR-R; average family prediction
= 0.93 vs 0.84 (t (132) = 3.22, p < .001), 0.86 (t (132) =
3.13, p < .001), 0.86 (t (132) = 3.13, p < .001) and 0.89 (t
(132) = 2.13, p = .03) respectively.

0.6

Task Prediction without inferring families:
In the proposed models we infer the malware family first and
then predict the tasks associated with that family. However,
differences over “ground truth” for malware families in the
cyber-security community calls for a direct inference of tasks
without dependence on family prediction. In this section we
adapt the models to predict tasks directly without inferring
the family.

0.2
F1

Family Prediction

Anubis Sandbox
Average

RF (t (132) = 0.56, p = 0.57), SVM (t (132) = 1.95, p = 0.05),
LOG-REG (t (132) = 1.82, p = 0.07), NB (t (132) = 1.79, p
= 0.08) and DT (t (132) = 0.83, p = 0.4). But the significant
improvement was in the family prediction values with ACTRIB improving by 0.12 from 0.81 to 0.93 (t (132) = 3.86, p
< .001) and ACTR-R by 0.15 from 0.72 to 0.87 (t (132) =
3.78, p < .001) outperforming all other methods. Since having
behavior analysis helps in better task prediction as seen from
the comparison experiment, we use cuckoo sandbox for rest
of our experiments.

Average

V.

1
0.6
0.2
F1

Family Prediction

Cuckoo Sandbox
DT

NB

LOG-REG

SVM

RF

ACTR-R

ACTR-IB

Fig. 1: Average F1 and Family prediction comparisons for DT,
NB, LOG-REG, SVM, RF, ACTR-IB and ACTR-R for Anubis
(top) and Cuckoo (bottom).
The average F1 increases by 0.03 when we use the attributes generated by the Cuckoo sandbox instead of Anubis.
The statistical significance results are as follows: for ACTR-IB
(t (132) = 1.94, p = 0.05), ACTR-R (t (132) = 1.39, p = 0.16),

982

Fig. 3 shows the performance of the cognitive and machine
learning models without inferring the families. There is no
difference in the performance of ACTR-IB and ACTR-R
approaches as compared to Fig. 2 where we use families. On
the other hand direct task prediction reduces the F1 measure
of machine learning techniques on average by almost 0.1. This
is due to the fact, now instead of having a single classifier
for each family we have multiple classifiers for each task
that a malware sample is designed to perform. This not only
degrades the performance but also adds to the training time

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

Average

1

0.9

0.8

0.7
Precision
LOG-REG

SVM

Recall
RF
ACTR-R

F1
ACTR-IB

Fig. 3: Average Precision, Recall, and F1 comparisons for
LOG-REG, RF, SVM, ACTR-R and ACTR-IB without inferring families.

200

Training time (sec)

Training time (sec)

for these methods. We compare the training time with increase
in training data for task prediction with/without inferring
families. Inferring families first reduces the training time
(see Fig. 4 (a)). On the other hand predicting tasks directly
significantly increases the training time for the machine
learning methods along for the rule-based ACT-R approach
(Fig. 4 (b)). Due to the issues with respect to performance
and training time, we consider inferring families first for rest
of the experiments. An important point to note is this has no
effect on the Instance-based model for both performance and
computation time.
150
100
50

0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
LOG-REG SVM RF ACTR-R

(a) (a)

200
150
100
50

0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
LOG-REG SVM RF ACTR-R

(b) (b)

Fig. 4: Training time for LOG-REG, SVM, RF and ACTR-R
with(a) / without(b) inferring families.

Fig. 5 shows the GVDG user interface used for the
generation of malware samples. We can select the carrier
type and the tasks that we want the malware sample to
perform on the host machine. The tasks are represented as
payloads, while carrier is a functional template of specific
behavior which are the operational framework supporting and
enabling the task activity. In generating datasets with GVDG,
we specify families based on sets of malware with the same
tasks. Whether or not a family consists of malware with the
same carrier depends on the experiment. Further, GVDG also
has an option to increase “mutation” or variance among the
samples. We perform experiments analyzing the performance
of the proposed methods when the generated samples belong
to different carrier and same carrier types, as well as when
the samples are encrypted and mutated making task prediction
difficult. In all the experiments we consider 60% of the data
for training and 40% for testing. The results are averaged
across 10 trials. The Cynomix tool from Invencia was unable
to detect any tasks for the GVDG dataset, primarily due to
to its inability to find public source documents referencing
GVDG samples and also unable to generalize from similar
samples.
Different Carriers:
In this experiment, we generated 1000 samples for each
carrier type with low mutation. On average each carrier type
performs 7 tasks(payloads). Hence each carrier represents one
family for this experiment. Both random forest and ACTR-IB
model were able to predict the tasks and family with F1
measure of 1.0 outperforming LOG-REG 1 vs 0.91 , SVM
1 vs 0.95 and ACTR-R 1 vs 0.95. All results are statistical
significant with (t (1998) ≥ 8.93, p < .001)(Fig. 6). Also for
family prediction ACTR-IB and RF outperformed LOG-REG
1 vs 0.92, SVM 1 vs 0.92 and ACTR-R 1 vs 0.95 (t (1998)
≥ 8.93, < .001). These results are not surprising given that
different carrier(family) types have high dissimilarity between
them. Also, samples belonging to the same carrier have on
average 60% of similar attributes.
1

Average

B. GVDG Dataset

0.9

0.8
Precision

LOG-REG

Recall

SVM

RF

F1

ACTR-R

Family
Prediction
ACTR-IB

Fig. 6: Average Precision, Recall, F1 and Family prediction
comparisons for LOG-REG,SVM, RF, ACTR-R and ACTRIB for different carrier samples.
Fig. 5: GVDG User Interface
GVDG is a malware generation tool designed for the study
of computer threats [11]. It is capable of generating following
malware threats,
•
•
•
•
•

File-virus
Key-Logger
Trojan-Extortionist
USB-Worm
Web Money-Trojan

983

Different Carriers-Mutation:
For this case, we generate the same samples as in the previous
experiment but with maximum mutation between samples
belonging to the same carrier. We generated 1000 samples for
each carrier with maximum mutation. In this case ACTR-IB
had an average F1 of 1 outperforming LOG-REG 1 vs 0.83,
SVM 1 vs 0.88 , RF 1 vs 0.96 and ACTR-R 1 vs 0.92 (t (1998)
≥ 7, p < .001)(Fig. 7). Also for family prediction ACTR-IB
outperformed LOG-REG 1 vs 0.85, SVM 1 vs 0.88 , RF 1 vs

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
1

0.95 and ACTR-R 1 vs 0.92 (t (1998) ≥ 7, p < .001).

Average

Average

1

0.9

0.9

0.8

0.8

Precision
0.7

LOG-REG
Precision

LOG-REG

Recall

SVM

F1

RF

Family
Prediction
ACTR-IB

ACTR-R

Fig. 7: Average Precision, Recall, F1 and Family prediction
comparisons for LOG-REG,SVM, RF, ACTR-R and ACTRIB.
High mutation induces high variance between samples
associated with the same carrier making the classification task
difficult. High mutation samples belonging to same carrier have
only 20% of common attributes as compared to 60% for low
mutation.

RF

ACTR-R

Family
Prediction
ACTR-IB

outperforming LOG-REG 0.95 vs 0.84, SVM 0.95 vs 0.87, RF
0.95 vs 0.90 and ACTR-R 0.95 vs 0.92 (t (678) ≥ 1.52 , p ≤
0.13). Since each family performs exactly one task the family
prediction is similar to F1. Using the same carrier for each
payload makes the task difficult as they have high similarity
between them.
Same Carrier-Encryption:
The GVDG tool provides the option for encrypting the
malware samples for the File-virus carrier type. We use
this option to generate 100 encrypted malware samples
for each task(payload) and use them as test data with the
unencrypted versions from the same carrier experiment as
training samples. From Fig. 10 ACTR-IB had an average F1
of 0.9 outperforming LOG-REG 0.9 vs 0.8, SVM 0.9 vs 0.8,
RF 0.9 vs 0.74 and ACTR-R 0.9 vs 0.88 (t (1698) ≥ 2.36
, p ≤ 0.02). Encrypting malware samples morphs the task
during execution making it difficult to detect during analysis.
Hence the drop in performance as compared to non-encrypted
samples. We note that SVM performs better than RF likely
because it looks to maximize generalization.

0.5
0.4
0.3
0.2
0.1

1

0.9

File-virus

Key-logger

Trojan-E

USB-worm

Web-T

0.5
Average

SVM

F1

Fig. 9: Average Precision, Recall, F1 and Family prediction
comparisons for LOG-REG,SVM, RF, ACTR-R and ACTRIB.

Average

F1

Leave one carrier out cross-validation:
To see how the models generalize to unseen malware family(carrier), we performed a leave-one-carrier-out comparison
(using high mutation samples), where we test the models
against one previously unseen malware carrier. ACTR-IB performs better or on par with all other baseline approaches for
all the carriers. It clearly outperforms all the approaches in
recalling most of the actual tasks (40%) (see Figure 8). ACTRIB has shown to generalize for unseen malware families [17].
This case is difficult given the fact that the test family is
not represented during training, hence task prediction depends
on associating the test family with the training families that
perform similar tasks.

Recall

0.4

0.8
0.7

0.3
0.6

0.2

Precision

0.1
Precision

LOG-REG

Recall

SVM

RF

ACTR-R

F1

LOG-REG

ACTR-IB

Fig. 8: Average F1 values for 5 malware carriers (above) and
the average precision, recall and F1 across all carriers (below)
for LOG-REG, SVM, RF, ACTR-R and ACTR-IB..
Same Carrier:
As seen in the previous experiments, different carrier types
makes the task easier because of less similarity between them.
We now test the performance, on same carrier type performing
exactly one task. Since there are 17 tasks in the GVDG tool,
we generate 100 samples for each task for carrier type Filevirus. In this experiment each task represents one family.
Thus in total we have 1700 samples. We do the 60-40 split
experiment. From Fig. 9 ACTR-IB had an average F1 of 0.95

984

Recall

SVM

RF

F1

ACTR-R

Family
Prediction
ACTR-IB

Fig. 10: Average Precision, Recall, F1 and Family prediction
comparisons for LOG-REG,SVM, RF, ACTR-R and ACTRIB.
VI. R ELATED W ORK
Identification of malicious software. The identification of
whether or not binary is malicious [8], [26] is important and
can be regarded as a “first step” in the analysis of suspicious
binaries in the aftermath of a cyber-attack. However, we note
that as many pieces of malware are designed to perform
multiple tasks, that successful identification of a binary as
malicious does not mean that the identification of its associated
tasks will be a byproduct of the result - and hence this is
normally the case, which has led to some of the other related
work described in this section.
Malware family classification. There is a wealth of existing

2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
work on malware family identification [2], [15], [16]. The
intuition here is that by identifying the family of a given piece
of malware, an analyst can then more easily determine what it
was designed to do based on previously studied samples from
the same family. However, malware family classification has
suffered from two primary draw-backs: (1) disagreement about
malware family ground truth as different analysts (e.g. Symantec and McAfee) cluster malware into families differently; and
(2) previous work has shown that some of these approaches
mainly succeed in “easy to classify” samples [19], [23], where
“easy to classify” is a family that is agreed upon by multiple
malware firms. In this paper, we infer the specific tasks a piece
of malware was designed to carry out. While we do assign
malware to a family as a component of our approach, to avoid
the two aforementioned issues as the family partition is done
so probabilistically and the result ground truth is the focus of
our comparison (though we show family prediction results as
a side-result). Further, we also describe and evaluate a variant
of our instance-based method that does not consider families
and yields a comparable performance to our instance-based
method that does consider families.
Malware task identification. With regard to direct inference
of malware tasks, the major related work include the software
created by the firm Invincea [12] for which we have included
a performance comparison. Additionally, some of the ideas
in this paper were first introduced in [17], [27]. However, that
work primarily focused on describing the intuitions behind the
cognitive modeling techniques and only included experimental
evaluation on one dataset (the Mandiant APT1 dataset) and
one sandbox environment (Anubis) with a comparison amongst
only the instance based approach, the rule-based cognitive
model, the standard decision tree, and the naive Bayes reasoner. The experimental evaluation in this paper was designed
to be much more thorough to pave the way toward deployment
of the approach for use by cyber-security analysts.
VII.

[2]
[3]
[4]
[5]

[6]
[7]
[8]

[9]
[10]
[11]
[12]

[13]
[14]
[15]
[16]

[17]

[18]

C ONCLUSION

In this paper, we introduced an automated method that
combines dynamic malware analysis with cognitive modeling
to identify malware tasks. This method obtains excellent precision and recall - often achieving an unbiased F1 score of over
0.9 - in a wide variety of conditions over two different malware
sample collections and two different sandbox environments outperforming a variety of baseline methods. Currently, our
future work has three directions. First, we are looking to
create a deployed version of our approach to aid cyber-security
analysts in the field. Second, we look to enhance our malware
analysis to also include network traffic resulting from the
sample by extending the capabilities of the sandbox. Finally,
we also look to address cases of highly-sophisticated malware
that in addition to using encryption and packing to limit static
analysis, also employ methods to “shut down” when run in a
sandbox environment [20]. We are exploring multiple methods
to address this such as the recently introduced technique of
“spatial analysis” [9] that involves direct analysis of a malware
binary.

[19]
[20]

[21]
[22]
[23]
[24]

[25]
[26]

[27]

R EFERENCES
[1]

J. R. Anderson, D. Bothell, M. D. Byrne, S. Douglass, C. Lebiere, and
Y. Qin. An integrated theory of mind. PSYCHOLOGICAL REVIEW,
111:1036–1060, 2004.

985

[28]

U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kruegel, and E. Kirda.
Scalable, behavior-based malware clustering, 2009.
D. Bothell. Act-r 6.0 reference manual. http:// act-r.psy.cmu.edu/ actr6/
reference-manual.pdf , 2004.
L. Breiman. Random forests. Machine Learning, 45(1):5–32, 2001.
C.-C. Chang and C.-J. Lin. Libsvm: A library for support vector
machines. ACM Trans. Intell. Syst. Technol., 2(3):27:1–27:27, May
2011.
J. B. M. S. Claudio Guarnieri, Alessandro Tanasi. Cuckoo sandbox.
http:// www.cuckoosandbox.org/ , 2012.
C. Cortes and V. Vapnik. Support-vector networks. pages 273–297,
1995.
I. Firdausi, C. lim, A. Erwin, and A. S. Nugroho. Analysis of machine
learning techniques used in behavior-based malware detection. In
Proceedings of the 2010 Second International Conference on ACT, ACT
’10, pages 201–203, Washington, DC, USA, 2010. IEEE Computer
Society.
D. Giametta and A. Potter. Shmoomcon 2014:there and back again:a
critical analysis of spatial analysis, 2014.
C. Gonzalez, J. F. Lerch, and C. Lebiere. Instance-based learning in
dynamic decision making. Cognitive Science, 27(4):591 – 635, 2003.
GVDG. Generator malware gvdg. 2011.
Invencia. Crowdsource: Crowd trained machine learning model for
malware capability detection. http:// www.invincea.com/ tag/ cynomix/ ,
2013.
ISEC-Lab. Anubis: Analyzing unknown binaries. http:// anubis.iseclab.
org/ , 2007.
Kaspersky. Gauss: Abnormal distribution, 2012.
J. Kinable and O. Kostakis. Malware classification based on call graph
clustering. J. Comput. Virol., 7(4):233–245, Nov. 2011.
D. Kong and G. Yan. Discriminant malware distance learning on structural information for automated malware classification. In Proceedings
of the 19th ACM SIGKDD, KDD ’13, pages 1357–1365, New York,
NY, USA, 2013. ACM.
C. Lebiere, S. Bennati, R. Thomson, P. Shakarian, and E. Nunes.
Functional cognitive models of malware identification. In Proceedings
of ICCM, ICCM 2015, Groningen, The Netherlands, April 9-11, 2015,
2015.
C. Lebiere, P. Pirolli, R. Thomson, J. Paik, M. Rutledge-Taylor,
J. Staszewski, and J. R. Anderson. A functional model of sensemaking
in a neurocognitive architecture. Intell. Neuroscience, 2013:5:5–5:5,
Jan. 2013.
P. Li, L. Liu, and M. K. Reiter. On challenges in evaluating malware
clustering, 2007.
M. Lindorfer, C. Kolbitsch, and P. Milani Comparetti. Detecting
environment-sensitive malware. In Proceedings of the 14th International Conference on RAID, RAID’11, pages 338–357, Berlin, Heidelberg, 2011. Springer-Verlag.
Mandiant. Apt1:exposing one of china’s cyber espionage units. http:
// intelreport.mandiant.com/ , 2013.
Mandiant. Mandiant APT1 samples categorized by malware families.
Contagio Malware Dump, 2013.
R. Perdisci and ManChon. Vamo: towards a fully automated malware
clustering validity analysis. In ACSAC, pages 329–338. ACM, 2012.
M. Sikorski and A. Honig. Practical Malware Analysis: The Hands-On
Guide to Dissecting Malicious Software. No Starch Press, 1 edition,
2012.
R. S. Sutton and A. G. Barto. Introduction to Reinforcement Learning.
MIT Press, Cambridge, MA, USA, 1st edition, 1998.
A. Tamersoy, K. Roundy, and D. H. Chau. Guilt by association: Large
scale malware detection by mining file-relation graphs. In Proceedings
of the 20th ACM SIGKDD, KDD ’14, pages 1524–1533. ACM, 2014.
R. Thomson, C. Lebiere, S. Bennati, P. Shakarian, and E. Nunes. Malware identification using cognitively-inspired inference. In Proceedings
of BRIMS, BRIMS 2015, Washington DC, March 31-April 3, 2015, 2015.
T. J. Wong, E. T. Cokely, and L. J. Schooler. An online database of
act-r parameters: Towards a transparent community-based approach to
model development. 2010.

Proceedings of the Twenty-Eighth AAAI Conference on Innovative Applications (IAAI-16)

Data Driven Game Theoretic Cyber Threat Mitigation
John Robertson, Vivin Paliath, Jana Shakarian, Amanda Thart, Paulo Shakarian∗
Arizona State University

The widespread availability of zero-day exploits represents a
potential game changer for penetration testers – speciﬁcally
posing the following questions:

Abstract
Penetration testing is regarded as the gold-standard for
understanding how well an organization can withstand
sophisticated cyber-attacks. However, the recent prevalence of markets specializing in zero-day exploits on
the darknet make exploits widely available to potential
attackers. The cost associated with these sophisticated
kits generally precludes penetration testers from simply obtaining such exploits – so an alternative approach
is needed to understand what exploits an attacker will
most likely purchase and how to defend against them.
In this paper, we introduce a data-driven security game
framework to model an attacker and provide policy recommendations to the defender. In addition to providing
a formal framework and algorithms to develop strategies, we present experimental results from applying our
framework, for various system conﬁgurations, on realworld exploit market data actively mined from the darknet.

1

• What exploits will an attacker likely purchase if he targets
my organization?
• What software used in the organization pose the biggest
risk to new threats?
However, the high cost of a variety of exploits available on
the darknet may preclude a penetration tester from simply
obtaining them. In this paper, we introduce a novel, datadriven security game framework to directly address these
challenging questions. Given a system conﬁguration (or a
distribution of system conﬁgurations within an organization)
we model an attacker who, given a budget, will purchase
exploits to maximize his level of access to the target system. Likewise, a defender will look to adjust system conﬁgurations in an effort to minimize the effectiveness of an
attacker while ensuring that necessary software dependencies are satisﬁed. Not only have we introduced a rigorous
and thoroughly analyzed framework for these problems, but
we have also implemented and evaluated a system that is fed
with real-world exploit market data, mined from the darknet.
We are currently moving our system toward real-time scraping of market information to provide game-theoretic assessment of the exploit market – while considering speciﬁc system information. We provide a schematic diagram of our
system in Figure 1. The speciﬁc contributions of this paper
include a new security game framework designed to model
an attacker with access to exploit markets and a defender of
information technology infrastructure (Section 2); theoretical analysis of the framework leading to the development
of algorithms to ﬁnd near-optimal strategies for both players (Section 3); and an implementation of the system and
the results of a thorough suite of experiments on real-world
data (Section 4). Before discussing these contributions, we
review some domain-speciﬁc background and related literature in the security games.
Exploit markets on the darknet. While criminal activity on
the darknet has been extensively studied over the past decade
for issues such as drug trade (Soska and Christin 2015) and
terrorism (Chen 2011) the markets of exploits existing on
the darknet are much less well-understood. There has been
related work on malicious hacker forums (Zhao et al. 2012;

Introduction

Many corporations rely on extensive penetration testing to
assess the security of their computer networks. In a penetration test, a red team is hired to expose major ﬂaws in the
ﬁrms security infrastructure. Recently, however, the market
for exploit kits has continued to evolve and what was once a
rather hard-to-penetrate and exclusive market – whose buyers were primarily western governments (Shakarian, Shakarian, and Ruef 2013), has now become more accessible to a
much wider population. Speciﬁcally, the darknet portions
of the Internet accessible through anonymization protocols
such as Tor and i2p – have become populated with a variety of markets specializing in such products (Shakarian and
Shakarian 2015; Ablon, Libicki, and Golay 2014). In particular, 2015 saw the introduction of darknet markets specializing in zero-day exploit kits – exploits designed to leverage previously undiscovered vulnerabilities. These exploit
kits are difﬁcult and time-consuming to develop – and often are sold at premium prices. We have surveyed 8 marketplaces and show the price ranges of exploit kits for common software in Table 1 – these range from 0.0126-8.4 Bitcoin (2.88-1919.06 U.S. dollars at the time of this writing).
∗

shak@asu.edu
c 2016, Association for the Advancement of Artiﬁcial
Copyright 
Intelligence (www.aaai.org). All rights reserved.

4041

exploit market and the defender is tasked with host-based
defense of either a single or group of systems. We use the notation V to represent the entire set of vulnerabilities within
a given computer system. Though there may be vulnerabilities not yet detected by the system administrator, we can
mine for information on new vulnerabilities through an examination of darknet hacking markets. In a real-world organization, system administrators are not able to patch all
vulnerabilities for a variety of reasons. Software dependencies, use of legacy systems, and non-availability of patches
are some examples. To model this, we deﬁne a “constraint
set” (denoted C) as a subset of V . The vulnerabilities in a
constraint set represent the vulnerabilities required for some
system functionality. When each vulnerability in a constraint
set C is in the presented attack surface (i.e. externally accessible), C is then said to be satisﬁed and the system supports
the functionality modeled by C. Let C represent the set of
all possible constraint sets. We extend this idea with an “application constraint set” which, for an arbitrary application,
i, denoted Ci , is a set of constraint sets (i.e. Ci ⊆ C). Each
constraint set in Ci represents a set of vulnerabilities that together will provide complete functionality of application i.
Ci is said to be satisﬁed if any single constraint set in Ci
is satisﬁed. If Ci is satisﬁed by a system conﬁguration, and
hence at least one constraint set in Ci is satisﬁed, application i will properly operate on the system. C is the set of all
application constraint sets for a given system conﬁguration
and represents all of the applications to be run on the system.
So, in this framework, for a given system, a system administrator must select which vulnerabilities must be present in
order to allow each application i to function. This begs the
question as to how to make this selection – so we now start
to deﬁne some concepts relevant to the adversary.
We will use ex to denote a particular exploit - a technique used to take advantage of a given vulnerability. Let
Ex denote the set of all possible exploits and Ex denote
the set of all possible exploit sets (i.e. Ex = 2Ex ). For
each ex ∈ Ex, cex is the associated cost of exploit ex and this is speciﬁed directly on a darknet market (normally
in Bitcoin). Associated with the set of exploits is the Exploit Function, ExF , which takes a set of exploits as input
and returns a set of vulnerabilities (i.e. ExF : Ex → 2V ).
The set of vulnerabilities produced by ExF (A), for a given
set of exploits A, represents the vulnerabilities that are exploited by the exploits in A. While many possible variations
of an exploit function are possible, in this paper, we will use
a straightforward deﬁnition that extends the exploit function from singletons (whose associated vulnerabilities can
be taken directly fromthe online marketplaces) to sets of
exploits: ExF (A) = a∈A ExF ({a}). For use in proving
complexity results, we shall denote the special case where
Ex = V , ExF (A) = A, and ∀ex ∈ Ex, cex = 1 as the
“Identity Exploit Model”.
Player Strategies and Payoff. An attacker will use a set of
exploits to attempt to gain access to a system, and must do so
within a budget. Likewise, the defender must identify a set
of vulnerabilities that he is willing to expose (often referred
to as the “presented attack surface”). We deﬁne strategies for
the two players formally as follows.

Darknet exploit markets
Threat intelligence
concerning highthreat exploit kits

Crawler

Parsers

Adversarial
model

Defender
model

Strategies to mitigate
cyber-attacks

Organizational
system information

Figure 1: Schematic of real-time exploit analysis system.
Product
GovRAT (Source Code + 1 Code Signing
Certiﬁcate Included)
0day Wordpress MU Remote Shell
A5/1 Encryption Rainbow Tables
Unlimited Code Signing Certiﬁcate
Ready-made Linux botnet 600 SERVERS
FUD version of Adobe Flash <=16.0.0.287
(CVE 2015-0311)

Price in BTC
2.000

Price in $*
$456.92

1.500
1.500
1.200
1.200
1414.68

$342.69
$342.69
$274.16
$274.16
$600.00

*Price in U.S. Dollar as of Sep. 1, 2015 [1 BTC = $228.46]

Table 1: Example of Products offered on Darknet Markets
Li and Chen 2014), which did not focus on the purchase and
sale of speciﬁc items. Markets of malicious products relevant to cyber security have been previously studied (Ablon,
Libicki, and Golay 2014; Shakarian and Shakarian 2015),
but none of these works gathered data on speciﬁc exploits
(or other products) from either the darkweb or open Internet; nor did they examine the markets through the lens of
security games. To our knowledge, this is the ﬁrst work that
describes the collection of price data on speciﬁc exploits for
sale on the deep web and then analyzes them in a security
game framework that yields policy recommendations for cyber defenders that are tailored to speciﬁc system conﬁgurations.
Related work in security games. In recent years, “security games” where attacker-defender models are used to inform the actions of defenders in military, law-enforcement,
and homeland security applications have gained much traction (see (Tambe 2011) for an overview). With regard to
cyber-security, there have been many contributions including intrusion detection (Nguyen, Alpcan, and Başar 2009);
attack graph based games (Lye and Wing 2005) and honeypot placement (Kiekintveld, Lisý, and Pı́bil 2015). However,
to the best of our knowledge, the work of this paper represents the ﬁrst game theoretic approach to host-based defense
where the activities of the attacker are informed from an “unconventional” source (information not directly related to the
defender’s system) - speciﬁcally information from darknet
markets in this case. Further, the very recent emergence of
darknet markets specializing in zero-day exploits allow for
the integration of information that was unavailable in previous work.

2

Security Game Framework

Here we formalize our concept of our security game where
the attacker is a malicious hacker with access to a darknet

4042

Deﬁnition 2.1. (Attack Strategy). Given budget katk ∈
+
R
 , an Attack Strategy, denoted A is a subset of Ex s.t.
a∈A ca ≤ katk .

Best Response Problems. We now have the components
to deﬁne a pair of decision problems dealing with the best
response for the players. These problems are the deterministic host attacker problem (DHAP) and deterministic host
defender problem (DHDP), respectively, and are deﬁned as
follows:

Deﬁnition 2.2. (Defense Strategy). Given a family of application constraint sets C = {C0 , C1 , . . . , Cn }, a Defense
Strategy, denoted D is a subset of V s.t. for each Ci ∈ C,
there exists C ∈ Ci where C ⊆ D.

DHAP.
INPUT: katk ∈ R+ , x ∈ R+ , mixed defense strategy P rD ,
and payoff function p.

OUTPUT:
“Yes” if ∃A ∈ A s.t. a∈A ca ≤ katk ,

and D∈D P rD (D)p(A, D) ≥ x, “No” otherwise.
DHDP.
INPUT: x ∈ R+ , application constraints C, mixed attack
strategy P rA , and payoff functionp.
OUTPUT: “Yes” if ∃D ∈ D s.t. A∈A P rA (A)p(A, D) ≤
x and D satisﬁes C. and “No” otherwise.
The natural optimization variants for these two problems
will deal with maximizing the payoff in DHAP and minimizing the payoff in DHDP.

Note that when a defense strategy D meets the requirements of C, as per Deﬁnition 2.2, we say D satisﬁes C. We
will use the notation A, D to denote the set of all attack
and defense strategies, respectively, and refer to an attackerdefender pair of strategies as a “strategy proﬁle.” We will
also deﬁne a mixed strategy for both players in the normal
manner. For the attacker (resp. defender) a mixed strategy
is a probability distribution over A (resp. D). We shall normally denote mixed strategies as P rA , P rD for each player
and use the notation |P rA | (resp. |P rD |) to denote the number of strategies in A (resp. D) that are assigned a nonzero
probability by the mixed strategy. We now turn our attention
to the payoff function, which we deﬁne formally as follows:
Deﬁnition 2.3. (Payoff Function). A payoff function, p, is
any function that takes a strategy proﬁle as an argument and
returns a positive real. Formally, p : A × D → R+
Unless noted otherwise, we will treat the payoff function
as being computable in polynomial time. Also, the payoff
function is underspeciﬁed - which is designed to allow ﬂexibility in the framework. However, in the context of the results of this paper, we shall consider the following “payoff
function axioms”:
∀D ∈ D, ∀A ∈ A s.t. ExF (A) ∩ D = ∅, p(A, D) = 0




∀D ∈ D, ∀D ⊆ D , ∀A ∈ A, p(A, D ) ≤ p(A, D)




∀D ∈ D, ∀A ∈ A, ∀A ⊆ A, p(A , D) ≤ p(A, D)






∀A ∈ A, D, D ∈ D, p(A, D) + p(A, D ) ≥ p(A, D ∪ D )






∀D ∈ D, A, A ∈ A, p(A, D) + p(A , D) ≥ p(A ∪ A , D)

3

Analysis and Algorithms

In this section we analyze the complexity and limits of approximation for both DHAP and DHDP. We use the ”Identity Exploit Model” for the complexity results. Unfortunately, both problems are NP-Complete in the general case.
Theorem 1. DHAP is NP-Complete, even when |P rD | = 1
and the payoff function adheres to the submodularity and
monotonicity axioms.
Proof Sketch. Membership in NP is trivial if the payoff is
PTIME computable. The hardness result relies on an embedding of the well-known budgeted set cover (Feige 1998).
Here, the defender’s strategy is treated as a set of elements
to cover and the exploits are treated as subsets of D (by
virtue of the exploit function). Exploit costs are set as 1 and
the attacker’s budget is the value budget from the embedded problem. So, the attacker must pick exploits to meet the
budget and cover the determined number of the defender’s
vulnerabilities.
Theorem 2. When |C| > 1 and |P rA | = 1, DHDP is NPComplete.
Proof Sketch. Again, membership in NP is trivial if the payoff is PTIME computable. Hardness is shown by embedding
the hitting set problem. In this reduction, the attacker plays
all exploits and each exploit corresponds with precisely one
vulnerability. This has the effect of imposing a unit cost on
each vulnerability. Here, each Ci must be covered by a vulnerability. Hence, the defender must pick a set of all vulnerabilities to meet the cost requirement of DHDP while covering each Ci .
We also were able to analyze the hardness of approximation
for the optimization variants of DHAP and DHDP. Due to
the fact that the above embeddings used set cover and hitting
set, we can draw upon the results of (Feige 1998) to obtain
the following corollaries:
Corollary 3. DHAP can not be approximated where the
payoff is within a factor of (1 − 1e ) unless P = N P

(1)
(2)
(3)
(4)
(5)

Axiom 1 states that if the vulnerabilities generated by an
attack strategy’s exploits and the vulnerabilities in a defense
strategy are disjoint sets, the payoff function must return 0.
A consequence of axiom 1 is that if either the attack strategy
or the defense strategy is the empty set, the payoff function
will return 0. Axioms 2 and 3 require the payoff function
to be monotonic in the size of the attack and defense strategies. Axioms 4 and 5 require the payoff function to be submodular with respect to the attack and defense strategies.
In this paper, we shall (in general) focus on the “overlap payoff function” which we shall deﬁne as follows:
p(A, D) = |ExF (A) ∩ D|. Intuitively, this is simply the
number of vulnerabilities exploited by the attacker. Further,
when dealing with mixed strategies, we shall discuss payoff in terms of expectation. Expected payoff can be formally
deﬁned as follows:
 
P rA (A)P rD (D)p(A, D)
Exp(P rA , P rD ) =
D∈D A∈A

Using the overlap function, the expected payoff can be interpreted as the “expected number of exploited vulnerabilities.”

4043

Corollary 4. DHDP can not be approximated where the
payoff is within a factor of (1 − o(1))ln(n) unless P = N P

approximation algorithm is transformed into a uniform cost
lazy approximation algorithm.
Multiplicative Update Approach. An improved approximation ratio, when compared with the 12 (1 − 1/e) ratio for the
greedy algorithms, can be obtained by adapting Algorithm 1
from (Azar and Gamzu 2012) for DHAP. This is shown as
Algorithm 2 in this paper. For some value  (a parameter),
this algorithm provides a (1 − )(1 − 1/e) approximation
of the optimal solution (Theorem 1.2 in (Azar and Gamzu
2012)), which, by providing an exceedingly small  value,
can get arbitrarily close to the (1 − 1/e) optimal approximation limit we discussed earlier.

With the limits of approximation in mind, we can now introduce several algorithms to solve the optimization variants
of DHAP and DHDP. The optimization variant of DHAP
under the overlap payoff function is a special case of submodular maximization with the distinction that we are not
simply picking k discrete objects, but instead picking items
that each have a unique cost associated with them. Understanding this, we examine several different approaches to
this problem based on the literature on submodular maximization. DHDP, on the other hand, can be readily approximated using the traditional set-cover algorithm (under some
realistic assumptions), as cost does not affect DHDP.

Algorithm 2 Multiplicative Update
Input: katk ,  ∈ R+ s.t. 0 <  ≤ 1, P rD , and payoff function p.

Output: A ⊆ Ex s.t. a∈A ca ≤ katk
1: Ex
 ← {ex ∈ Ex : cex ≤ katk }
2: A ← ∅
2
3: W ← minexi ∈|Ex | katk
/cexi
W/4
4: w ← 1/katk ; λ ← e
5: while katk w ≤ λ and Ex
 = ∅ do
cex
6:
exj ← argminexj ∈Ex \A katkj w/Δp,P rD (exj |A)
7:
A ← A ∪ {exj }
2
8:
w ← wλcexj /katk




9:
Ex ← Ex \{exj }
10: end
while
11: if Ai ∈A cAi ≤ katk then
12:
return
A
13: else if D∈P rD P rD (D)p(A\{exj }, D) ≥

D∈P rD P rD (D)p({exj }, D) then
14:
return A\{exj }
15: else
16:
return {exj }
17: end if

Algorithm 1 Lazy Greedy Algorithm (Cost-Beneﬁt Variant)
Input: katk ∈ R+ , P r
D , and payoff function p.
Output: A ⊆ Ex s.t. a∈A ca ≤ katk
1: A ← ∅; cost ← 0; priority queue Q ← ∅; iter ← 1
2: for e ∈ Ex do
Δ
(e|∅)
3:
e.key ← p,P rcDe
; e.i ← 1
4:
insert e into Q with “key” as the key
5: end for
6: while {a ∈ Ex\A : ca + cost ≤ katk } = ∅ do
7:
extract top (max) element e of Q
8:
if e.i = iter and ce + cost ≤ katk then
9:
A ← A ∪ {e}; iter ← iter + 1
10:
cost ← cost + ce
11:
else if ce + cost ≤ katk then
Δ
(e|A)
12:
e.i ← iter; e.key ← p,P rcDe
;
13:
re-insert e into Q
14:
end if
15: end while
16: return A
Algorithms for DHAP.
Greedy Approaches. As mentioned earlier, the non-unit
cost of exploits mean that DHAP can be considered as
a submodular maximization problem subject to knapsack
constraints. Two versions of the traditional greedy algorithm (Nemhauser, Wolsey, and Fisher 1978) can be applied: a cost-beneﬁt variant and uniform-cost variant, both
of which will also use the lazy-greedy optimization (Minoux 1978) to further enhance performance while maintaining the approximation guarantee. We note that independently, the uniform-cost and the cost-beneﬁt algorithms can
perform arbitrarily badly. However, by extending a result
from (Leskovec et al. 2007), either the cost-beneﬁt or the
uniform-cost algorithm will provide a solution within a factor of 12 (1 − 1/e) for a given set of input parameters. By
applying both algorithms to a given problem instance and returning the attack strategy which produces the larger payoff,
the 12 (1 − 1/e) approximation factor is achieved for DHAP.
A cost-beneﬁt lazy approximation algorithm is shown in Algorithm 1. By removing “ce ” from the denominator in the
e.key assignment in lines 3 and 12, the cost beneﬁt lazy

Algorithm for DHDP. When using the overlap payoff function, DHDP can be modeled as a weighted set cover problem. Because the overlap payoff function is a modular function, the associated cost of a given vulnerability v, is simply
the payoff produced by the singleton
set {v} with a mixed

attack strategy P rA (i.e. cv = A∈P rA P rA (A)p(A, {v}).
In the common case where each constraint set is a singleton
set (i.e. ∀Ci ∈ C, ∀C ∈ Ci , |C| = 1), if the overlap payoff function is used, an adaptation on the standard greedy
weighted set cover algorithm can be used for DHDP (Algorithm 3), providing a ln(n) + 1 approximation (Feige 1998).

4

Evaluation and Discussion

Darknet Market Data. We scraped and parsed eight marketplaces located on the Tor network during the month of
May 2015. Each of these markets host vendors offering
“hacking tools”, including malware, botnets, exploits and
other means serving to breach, steal and otherwise manipulate virtual targets. The product list is comprised of 235 such
hacking tools, 167 of which were distinct. We found several

4044

Algorithm 3 Weighted Greedy DHDP Algorithm for Singleton Constraint Set and Overlap Payoff Function Case
Input: Vulnerabilities V , P rA , and application constraints
C.
Output: D ⊆ V s.t. the application constraints C are satisﬁed.
1: D ← ∅
2: S ← set s.t. Si = {j : Vi ∈ Cj where Vi is ith vulnerability in
V }
3: cSi ← A∈P rA P rA (A)|ExF (A) ∩ {Vi }|
4: C 
 ← [|C|]
5: while C 
 = ∅ do

|
6:
Si ← argmaxSi ∈S |Sci ∩C
Si
7:
C 
 ← C 
 \Si
8:
D ← D ∪ {Vi }
9: end while
10: return D
Mac OS X Client

POS iOS Device

Android
Linux
Client

Figure 3: DHAP Payoff vs Budget - Left: Windows Server;
Right: Linux Server.
ated (and conducted experiments with) models for Android,
Point-of-Sale, and Apple systems – though qualitatively the
results differed little from the Windows and Linux Server
experiments.
DHAP Results. We implemented both the greedy and multiplicative update approaches to the DHAP problem. For the
greedy algorithm, we studied three variants of greedy (costbeneﬁt, uniform cost, and combination of the the two) while
we varied the parameter  for the multiplicative update approach. We examined attacker payoff as a function of budget
(in Bitcoin). Figure 3 displays this result. Though the costbeneﬁt greedy algorithm has the potential to perform poorly,
it was, in general, the best performing approach - despite the
multiplicative update approach achieving the better approximation guarantee. Further, the multiplicative update algorithm (Algorithm 2) was consistently the slowest in terms
of runtime, taking much longer than the lazy greedy algorithms, particularly for high values of katk . Despite the multiplicative update algorithm having a better theoretical approximation ratio when compared to the tandem of greedy
algorithms, namely (1−)(1−1/e) compared to 12 (1−1/e),
we see in Figure 3 that the greedy algorithms performed as
well as or better than the multiplicative update very consistently. In all algorithms, as expected, runtime grew with budget (not pictured) - though the relationship was not strict, as
an increase in budget does not necessarily mean that more
exploits will be selected. In our experiments (on a commodity computer equipped with a 3.49 GHz i7 CPU and 16 GB
of memory), our runtimes never exceeded ten minutes.
DHDP Results. Figure 4 demonstrate a defender’s best
response to an attack strategy against a Windows Server
and Linux Server, respectively, for varying values of katk .
Though we see similar trends in Figure 3 as we do in Figure
4, we see that the payoff is generally lower, meaning that the
defender can lower the expected payoff by enacting a best
response strategy to an attack strategy produced by DHAP
- which in our framework translates to fewer exploited vulnerabilities.
Exploit Payoff Analysis. Instead of altering the software
that appears on the host system in an attempt to avoid
exploits, such as in the best response approach, in exploit payoff analysis, the defender will identify which speciﬁc exploits are increasing the payoff the most, with a
hope that the defender can reverse-engineer the exploit,
or patch the vulnerability himself. To identify which exploits should be reverse-engineered, the defender ﬁrst runs

Windows
Server

Windows
Client
Linux
Server

Figure 2: Distribution of Exploits with respect to platform.
identical products being sold on more than one market usually by the same seller (using an identical online handle).
The products targeted 21 speciﬁc platforms, such as different versions of Adobe Flash, Linux, MSWindows and OS
X as well as online presences such as Facebook, Wordpress
and others. Hardware-related software such as those associated with Point-of-Sale machines, routers, and servers are
also reﬂected in this number. Figure 2 illustrates the variety
of products in the markets and Table 2 illustrates exemplar
exploits.
Prod.

Vuln.

Target

USD

Kernel Panic
IE <= 11
RemoteShell
0day RCE
WindowsLPE
MS15-034 RCE
FUD Flash Exp.

X-display system
memory corr.
wpconﬁg.php
WebView memory corr.
win32k elev. of priv.
http.sys
unspec.

Linux <= 3.13.0-48
IE on Windows <= 7
Wordpress MU
Android 4.1, 4.2
Windows <= 8.1
Windows <= 8.1
FlashPlayer <=16.0.0.287

$471.56
$35.00
$1, 500
$36.50
$12-48
$311.97
$600.00

Table 2: Examples of Exploits from Darknet Markets
System Conﬁgurations. As noted in Figure 2, a variety
of platforms were represented in our darknet market data.
In this paper, we describe results when using application
constraints based on common conﬁgurations for Windows
and Linux servers - as these were the most prominent targets of exploits found on the darknet. In our experiments,
we mapped software such as media players, databases, and
FTP server software to application constraint sets to model
the functional requirements of a system. We have also cre-

4045

References
Ablon, L.; Libicki, M. C.; and Golay, A. A. 2014. Markets for
Cybercrime Tools and Stolen Data: Hackers’ Bazaar. Rand Corporation.
Azar, Y., and Gamzu, I. 2012. Efﬁcient submodular function maximization under linear packing constraints. ICALP 1:38–50.
Chen, H. 2011. Dark web: Exploring and data mining the dark
side of the web, volume 30. Springer Science & Business Media.
Feige, U. 1998. A threshold of ln n for approximating set cover. J.
ACM 45(4):634–652.
Kiekintveld, C.; Lisý, V.; and Pı́bil, R. 2015. Game-theoretic foundations for the strategic use of honeypots in network security. In
Cyber Warfare - Building the Scientiﬁc Foundation. 81–101.
Leskovec, J.; Krause, A.; Guestrin, C.; Faloutsos, C.; VanBriesen,
J.; and Glance, N. 2007. Cost-effective outbreak detection in networks. In Proceedings of the 13th ACM SIGKDD international
conference on Knowledge discovery and data mining, 420–429.
ACM.
Li, W., and Chen, H. 2014. Identifying top sellers in underground
economy using deep learning-based sentiment analysis. In Intelligence and Security Informatics Conference (JISIC), 2014 IEEE
Joint, 64–67.
Lye, K.-w., and Wing, J. M. 2005. Game strategies in network
security. International Journal of Information Security 4(1):71–86.
Minoux, M. 1978. Accelerated greedy algorithms for maximizing submodular set functions. In Stoer, J., ed., Optimization Techniques, volume 7 of Lecture Notes in Control and Information Sciences. Springer Berlin Heidelberg. 234–243.
Nemhauser, G.; Wolsey, L.; and Fisher, M. 1978. An analysis of
approximations for maximizing submodular set functions. Mathematical Programming 14(1):265–294.
Nguyen, K. C.; Alpcan, T.; and Başar, T. 2009. Stochastic games
for security in networks with interdependent nodes. In Game Theory for Networks, 2009. GameNets’ 09. International Conference
on, 697–703. IEEE.
Shakarian, P., and Shakarian, J. 2015. Considerations for the development of threat prediction in the cyber domain. submitted.
Shakarian, P.; Shakarian, J.; and Ruef, A. 2013. Introduction to
cyber-warfare: A multidisciplinary approach. Elsevier.
Soska, K., and Christin, N. 2015. Measuring the longitudinal evolution of the online anonymous marketplace ecosystem. In 24th
USENIX Security Symposium (USENIX Security 15), 33–48. Washington, D.C.: USENIX Association.
Tambe, M. 2011. Security and Game Theory: Algorithms, Deployed Systems, Lessons Learned. New York, NY, USA: Cambridge University Press, 1st edition.
Zhao, Z.; Ahn, G.-J.; Hu, H.; and Mahi, D. 2012. Socialimpact:
Systematic analysis of underground social dynamics. In Foresti,
S.; Yung, M.; and Martinelli, F., eds., ESORICS, volume 7459 of
Lecture Notes in Computer Science, 877–894. Springer.

Figure 4: Defender Best Response, Payoff vs katk - Left:
Windows Server; Right: Linux Server.

DHAP against his host system to identify what payoff an
attacker could expect to produce. Then, for each exploit
ex, the defender runs DHAP against the host with the set
of exploits Ex\{ex}. The exploit ex that, when removed
from the universe of exploits Ex, produces the largest
drop in payoff for the attacker is the exploit that the defender should attempt to reverse-engineer. More formally,
let A be the attack strategy produced by DHAP when using Ex as the universe of exploits and let Aex be the attack strategy that is produced when DHAP is run against
the host when using Ex\{ex} as the universe of exploits.
The defender will attempt to reverse-engineer the exploit
ex = argmaxex∈Ex p(A, D) − p(Aex , D), where D is the
defense strategy representing the host. To account for exploits that, though they greatly reduce payoff when removed
from Ex, may be too expensive for the defender to purchase, we also consider a cost-beneﬁt analysis, where the
decrease in payoff is normalized by the cost of the exploit
ex ,D)
(i.e. ex = argmaxex∈Ex p(A,D)−p(A
). The top exploits
cex
to reverse-engineer to defend a Windows Server host when
considering an attacker budget of katk = 5, are shown in
Table 3 with columns for both maximum payoff reduction
and maximum cost-beneﬁt analysis.
Exploit

Payoff Reduction

Max. Cost-Beneﬁt

Exploit Cost (BTC)

SMTP Mail Cracker
SUPEE-5433
Hack ICQ
Plasma
Wordpress Exploiter
CVE-2014-0160

1
1
1
0.6677
0.6677
0.6677

4.757
1.190
79.089
1.582
2.6467
3.178

0.2102
0.8404
0.01264
0.2563
0.2102
0.2101

Table 3: Defender Exploit Analysis for katk = 5
Discussion. In future work, we plan to extend the gametheoretic framework to include non-deterministic problem
formulations and construct algorithms to generate mixed
strategies for the attacker and defender. By extending the exploit function in the framework, we plan to support blended
threats, where the number of vulnerabilities affected by a
cyber-attack is a superset of the union of the vulnerabilities affected by each individual exploit (i.e. ExF (A) ⊇

a∈A ExF ({a})).
Acknowledgements This work was supported by ASU GSI
and the ONR Neptune program.

4046

BioSystems 107 (2012) 66–80

Contents lists available at SciVerse ScienceDirect

BioSystems
journal homepage: www.elsevier.com/locate/biosystems

Review article

A review of evolutionary graph theory with applications to game theory
Paulo Shakarian a,∗ , Patrick Roos b , Anthony Johnson c
a

Network Science Center and Dept. of Electrical Engineering and Computer Science, United States Military Academy, West Point, NY 10996, United States
Dept. of Computer Science, University of Maryland, College Park, MD 20740, United States
c
Network Science Center and Dept. of Mathematical Sciences, United States Military Academy, West Point, NY 10996, United States
b

a r t i c l e

i n f o

Article history:
Received 15 September 2011
Accepted 26 September 2011
Keywords:
Evolutionary dynamics
Structured populations
Game theory
Fixation probability
Time to ﬁxation

a b s t r a c t
Evolutionary graph theory (EGT), studies the ability of a mutant gene to overtake a ﬁnite structured
population. In this review, we describe the original framework for EGT and the major work that has
followed it. This review looks at the calculation of the “ﬁxation probability” – the probability of a mutant
taking over a population and focuses on game-theoretic applications. We look at varying topics such as
alternate evolutionary dynamics, time to ﬁxation, special topological cases, and game theoretic results.
Throughout the review, we examine several interesting open problems that warrant further research.
Published by Elsevier Ireland Ltd.

Contents
1.
2.

3.

4.

5.

6.

7.

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
The model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.
Properties of ﬁxation probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.
The complexity of computing ﬁxation probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.
Game theoretic extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Determining ﬁxation probability for ﬁxed ﬁtness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.
Fixation probability calculations for certain topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.
Undirected evolutionary graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.
Calculating ﬁxation probability using dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Time to ﬁxation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1.
Time to ﬁxation for ﬁxed ﬁtness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2.
Time to ﬁxation for games on graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Alternate update rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.
Comparing update rules in undirected EGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2.
Comparing update rules in directed EGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Further game theoretic extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.1.
Evolutionary stability on graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.2.
Regular graphs and the replicator equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.3.
Evolution of cooperation and social viscosity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.4.
Graph heterogeneity and evolution of cooperation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.5.
Direct reciprocity on regular graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.6.
Separate interaction and replacement graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.7.
Further work for game theoretic extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Other extensions to the model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.1.
Bi-level evolutionary graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.2.
Multiple mutants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.3.
EGs that change over time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

∗ Corresponding author. Tel.: +1 5205089319.
E-mail address: paulo@shakarian.net (P. Shakarian).
0303-2647/$ – see front matter. Published by Elsevier Ireland Ltd.
doi:10.1016/j.biosystems.2011.09.006

67
67
67
68
69
69
69
70
70
72
72
73
73
74
74
75
75
75
75
76
76
76
76
77
77
78
78

P. Shakarian et al. / BioSystems 107 (2012) 66–80

8.

7.4.
Further extensions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1. Introduction
Evolutionary graph theory (EGT), introduced by Lieberman et al.
(2005), studies the ability of a mutant gene to overtake a ﬁnite
structured population. The reproduction of the individuals in the
population is modeled as a stochastic process. The structure of the
population is represented as a directed, weighted graph called an
evolutionary graph (EG). Since its introduction, numerous results
on EGT, both analytical and experimental, have been produced.
Additionally, several extensions to the model have been proposed,
including game-theoretic ones. The application of EGT to game theory has provided researchers new insight about the evolution of
cooperation and other game-theoretic concepts in structured populations. In this review, we present the original model of Lieberman
et al. (2005) and various extensions. We also summarize major
results in EGT (both analytical and experimental), including those
relating to game theory. Throughout this review, we pose several
open questions in EGT that would be relevant for future research.
This review is organized as follows. In Section 2, we introduce
the original model, discuss computation of ﬁxation probability,
and describe the standard game theoretic extensions. This is followed by a presentation of results concerning the computation of
the ﬁxation probability in Section 3 for graphs of certain topologies – including the large class of undirected EGs. We then turn
to the related problem of mean time to ﬁxation in Section 4. Then
we describe how some of the results relating to ﬁxation probability change under alternative model dynamics in Section 5. We
then survey more advanced game theoretic extensions in Section
6. Finally, in Section 7, we present other major extensions to EGT
including the study of bi-level EGs and EGs whose topology change
over time.

1 − 1/r
1 − 1/r N

Theorem 1 (Isothermal Theorem (Lieberman et al., 2005)). An EG
is isothermal iff the ﬁxation probability of a randomly placed mutant
is 1 .
Hence, for EGs that are not isothermal, the ﬁxation probability
of the evolutionary process is not only dependent on the ﬁtness of
the mutant (as in the Moran Process), but also on the structure of
the graph.
2.1. Properties of ﬁxation probability
Many researchers (such as Broom and Rychtář, 2008; Masuda
and Ohtsuki, 2009) have studied the problem of computing the
probability of ﬁxation given that a certain subset of vertices are
mutants. If the mutants inhabit set C ⊆ V, then this probability is
written PC . As the calculation of the ﬁxation probability () for an
EG is determined based on a uniformly picked vertex, we have the
following relationship between  and P:



P{vi }

(2)

i

Consider a population of N individuals where there is no speciﬁed graph-structure relating them to each other (this is known as
a well-mixed population). The Moran Process of Moran (1958) is a
stochastic process used to model evolution in such a population. It
is deﬁned as follows. At each time-step a randomly selected individual is chosen to reproduce. Then, a second individual is chosen
at random to die – replaced by a duplicate of the ﬁrst individual.
If all of the members of the population are identical (termed residents with ﬁtness 1), and a mutant is introduced at random in the
population (with ﬁtness r, where r = 1 is the special case of neutral
drift), the probability that the mutant will eventually overtake the
population is known as the ﬁxation probability (the opposite event –
that all mutants die out – is called extinction and a population with
a lower ﬁxation probability is deemed more evolutionarily stable as
it is resistant to invasion by a mutant). This probability, 1 , arising from this N original Moran Process, is often termed the Moran
probability and can be solved for exactly (see Eq. (1)).
1 =

78
79
79
79

graph. The edges of the graph are speciﬁed by the adjacency matrix
W = [wij ], where for vertices vi , vj , the quantity wij speciﬁes the
weight of the directed edge from vi to vj . As this is an evolutionary
graph (EG), wij corresponds to the probability that, if vi is selected to
reproduce then
it replaces vj (note that for all vi , wii = 0). Hence, for
any given vi ,
w = 1. The earlier work of Slatkin (1981) proved
j ij
that, in such a structure if ∀vi , vj ∈ V we have wij = wji , then the
ﬁxation probability for a randomly placed mutant is 1 . A similar result was proved by Maruyama (1974). In Lieberman et al.
(2005), this

 result is extended for a wider variety of EGs where ∀vi ,
w =
w . This type of EG is known as isothermal. Consider
j ij
j ji
the following theorem.

N · =

2. The model

67

(1)

In the original work that introduced EGT, Lieberman et al. (2005)
generalize the model of the Moran Process by specifying relationships between the N individuals of the population in the form of a
directed, weighted graph. We shall use the symbol V to denote the
set of individuals. We can think of these individuals as vertices in a

Note that although these two problems are closely related, they
have rather different intuitions. The ﬁxation probability  provides
insight into a graph of a certain topology. For example, researchers
often refer to graphs with a low value for  as being “evolutionary stable” as the toplogy of the graph seems to be resistant to a
mutant invasion. The ﬁxation probability PC on the other hand tells
us something about a set of vertices C. For example, identifying a
certain subset C of a graph that has a higher ﬁxation probability
may cause a user to take a certain action regarding those vertices
(dependent on the domain).
If the graph is not isothermal, but if we are under neutral drift,
ﬁxation probability PC is additive. This was proven for the special case of undirected graphs by Broom et al. (2010) and proved
for general, weighted, directed graphs by Shakarian and Roos (in
press).
Theorem 2 (Additive Under Neutral Drift (Shakarian and Roos, in
press)). When r = 1 for disjoint sets C, D ⊆ V, PC + PD = PC∪D .
This additive result says that, under neutral drift, determining
a subset of individuals in the population that maximize ﬁxation
probability is not (polynomially) harder than determining the ﬁxation probability. Further, when we ﬁx the topology of the graph, we
ﬁnd that for some subset of vertices C, that the ﬁxation probability under neutral drift is a lower bound for the ﬁxation probability
when r > 1.

68

P. Shakarian et al. / BioSystems 107 (2012) 66–80

Theorem 3 (Neutral Drift as a Lower Bound (Shakarian and Roos, in
(1)
press)). For a given set C, let PC be the ﬁxation probability under neu-

Open Problem 2.1. What is the computational complexity of
determining  in an arbitrary evolutionary graph?

(r)

tral drift and PC be the ﬁxation probability calculated using a mutant
(1)

(r)

ﬁtness r > 1. Then, PC ≤ PC .
By Theorem 2 and Eq. (2), we observe that under neutral drift
 = 1/N regardless of the topology of the graph – even with directed
and weighted edges. Hence, Theorem 3 tells us that for r > 1 we
have  ≥ 1/N. This particular observation is independently noted by
Houchmandzadeh and Vallade (2011). Masuda (2009) observed in
their experiments that ﬁxation probability monotonically increases
with r. Based on these observations and Theorem 3, we have the
following conjecture.
Conjecture 2.1.

Fixation probability is monotonic in r.

This conjecture seems natural and is supported by experimental
results. However, a formal proof is currently lacking.
2.2. The complexity of computing ﬁxation probability
As we can appeal to the Moran probability only in the case of an
isothermal graph, we must resort to other calculations to determine
 or P. Using the following set of constraints, we can solve directly
for any PC (hence,  as well by Eq. (2)).



PC =

vi ∈C



v ∈/C (r · wij · PC∪{vj } + wji · PC−{vi } )

j

vi ∈C



vj ∈/C (r · wij + wji )

.

(3)

These constraints originally appeared in Rychtář and Stadler (2008)
for the case of an undirected EG, but applies to the general case as it
follows directly from the rules of dynamics. However, the number
of constraints and variables is equal to the number of mutantresident formations in the graphs, which is intractable for large N.
In fact, Lieberman et al. (2005) present a decision problem related
to computing the ﬁxation probability that is claimed to be as hard as
any problem in the complexity class NP (the class of nondeterministic polynomial time computable problems). Broom and Rychtář
(2008) and Broom et al. (2010) attempted to reduce the number
of constraints by ﬁnding automorphisms in the graph. Based on
automorphism, the authors are able to calculate the exact number
of possible mutant-resident formations (MRFs). Since this number
gives the size of the system of linear equations for the ﬁxation
probability and in general increases with the difﬁculty of solving
this system, the measure may be a useful indicator in deciding
whether to undertake an analytical approach to solving for the ﬁxation probability on a given graph. The authors then show that even
in the special case of undirected EGs, if the graph contains a vertex of degree of at least 3, that there is a non-zero probability that
the dynamics will evolve to any of the MRFs (except in the trivial
cases where C = V or C =).1 We note that for the general case, this
still leads to an intractable number of constraints. Further, ﬁnding
graph automorphisms is also a non-trivial problem in the general
case (see Torán, 2004, for the latest complexity results on graph
automorphism).
We note that the problem proven to be NP-hard by Lieberman
et al. (2005) is actually more general than a standard computation
or  using their model. As for an upper bound on complexity, Eq. (3)
only tells us that this problem can be solved in exponential time.
Hence, the issue of ﬁnding a tight bound on the complexity for
computing ﬁxation probability is still an open problem.

1
There is the exception of an alternating state where every edge connects a
mutant-resident pair. This state cannot be reached if it exists. We would like to
thank an anonymous reviewer for pointing this out.

Open Problem 2.1 is important to the study of evolutionary
graph theory as virtually all current works in this area is performed
with simulation. Often, it has been found that this approach does
not scale well for large graphs. Properly identifying the complexity class of this problem may provide insight into the development
of a more efﬁcient and scalable approach, perhaps broadening the
appeal of this paradigm.
What about the computational complexity of ﬁnding PC – the
set C ⊆ V are mutants and the rest are
ﬁxation probability given 
P
v ∈V {vi }

i
residents? Clearly, as  =
, solving N instances of PC can
N
give us . However, a reduction going in the opposite direction
seems less likely, so it is possible that determining PC may be more
difﬁcult than ﬁnding .
Despite the computational difﬁculty of determining the ﬁxation
probability in the general case, there are several special classes of
EGs where we have analytical solutions (or at least good approximations). We review many of these special cases in the next section.
To address the issue of computation of the ﬁxation probability in
the general case (i.e. to conﬁrm analytical approximations), most
work we review resorts to simulation methods via Markov Chain
Monte Carlo (MCMC). These simulations generally rely on a direct
application of the model we have already described (see Rychtář
and Stadler, 2008, for a pseudocode algorithm). However, as the
size of the graph increases, even such simulations may become
impractical. Barbosa et al. (2010) addressed the issue of increasing
the speed of such simulations. Their main technique for the general case is to stop the simulation early if the number of mutants
in the population exceed a certain threshold (hence that particular simulation would be considered to have reached ﬁxation).
They determine this threshold by ﬁnding the conditional probability that mutants spread to M vertices in the graph given that
extinction eventually occurs. The authors plot the probability distribution density of this function compared to M and determine for
several types of networks (including E-R graphs) of size 103 , that if
M > 102 then this probability drops to 10−5 – which is lower than the
estimated standard error of a MCMC simulation by several orders of
magnitude (the authors showed that the estimated standard error
for populations of 104 –106 have associated standard errors of at
least 10−4 ). Hence, the outcome of any simulation where the number of mutants exceeds 100 is considered equivalent to ﬁxation.
The authors showed that for networks with 103 and 104 vertices,
and showed it provided a signiﬁcant speed-up of up to 100 times,
depending on the size of the network.
More recently, the authors of this review developed a novel
approach that can quickly compute the ﬁxation probability in an
evolutionary graph (with weights and directions) under neutral
drift. We rely on the idea of a vertex probability – the probability
of a given vertex being a mutant. In the limit of time, these probabilities converge to the ﬁxation probability (for strongly connected
graphs). We have shown that this convergence occurs quickly in
practice, providing an improvement over MCMC by several orders
of magnitude. While this result is for the case of neutral drift,
Theorem 3 suggests it may provide good insight for r > 1. Further,
the quick convergence of our algorithm in practice may also suggest
that having a value of r =
/ 1 may be a source of complexity.
Another recent development is the work of Houchmandzadeh
and Vallade who use dynamics to quickly approximate ﬁxation
probability in a certain bi-level graph that generalizes the model
of Maruyama (1974). While this particular model can also generalize the standard evolutionary graphs of Lieberman et al. (2005).
However, it is unclear if their approximation is still appropriate for
arbitrary graphs. In Section 3.3 we show how this approach can be

P. Shakarian et al. / BioSystems 107 (2012) 66–80

69

used to derive the Moran probability (1 ). In Section 7.1 we discuss
bi-level graphs and discuss their approach further.
2.3. Game theoretic extensions
One of the most popular applications of EGT is to game theory.
In the game theoretic context, vertices of a graph represent agents
and edges represent potential for interaction between them. Interactions between agents are games played that can be described
using a normal game theoretic payoff matrix. EGT thus provides
a structural component for interactions in populations of agents.
Evolutionary game theory, which is concerned with the populationdependent success of game theoretic strategies, has initially mostly
focused on well-mixed populations in which interactions between
all agents are equally likely. Incorporating EGT to evolutionary
game theory can take into account the effect of population structure, which has the capacity to crucially impact evolutionary
trajectories, outcomes, and strategy success. Thus EGT is a welcome
tool to explore how many of the results for well-mixed populations
are affected by population structure.
In game-theoretic applications of EGT, the evolutionary ﬁtness
(fi ) of individual vi is often related to their game theoretic payoff
(P) (based on game-play with neighbors) with something akin to
the following equation:
fi = 1 − w + w · P

Open Problem 2.2. Given a two-player game and w, what is the
computational complexity of determining  with respect to an arbitrary evolutionary graph?
Evolutionary game dynamics of ﬁnite populations on graphs
for a general two-player game between mutants and residents are
often considered using the following payoff matrix:

mutant
a
c

In Section 4 we look at Broom et al. (2010a) who also study twoplayer games on graphs, but are mainly concerned time to ﬁxation
for a given game. In Section 6 we will review important other works
considering various aspects of game theoretic applications of EGT.
3. Determining ﬁxation probability for ﬁxed ﬁtness
We now turn to the problem of determining ﬁxation probability
for some special cases of graphs when the value of r is ﬁxed (i.e.
most non-game theoretic work). First we look at computing ﬁxation
probabilities for graphs of certain topologies. Then, we look at a very
large special case – that of undirected graphs.
3.1. Fixation probability calculations for certain topologies

(4)

The parameter w relates the payoff acquired from games played
to ﬁtness. If w = 1, the payoff acquired is equal to the ﬁtness. If
w = 0, the game is irrelevant and we are at neutral drift. An often
explored special case is weak selection, where w 	 1, which reﬂects
the assumption that the game of interest plays only a partial role in
the overall ﬁtness of individuals. Using this paradigm, researchers
have reached a variety of important conclusions on the effects of
population structure on game-theoretic concepts. The inclusion of
a game adds a layer of computational complexity to our already
difﬁcult problem of determining ﬁxation probability. As with ﬁxation probability computation under ﬁxed ﬁtness, much of the game
theoretic work on EGT is done using simulation. Hence, we have the
following open problems.

mutant
resident

Fig. 1. Left: Super-star EG, K = 3, L = 2, M = 4. Center: Star EG, K = 2, L = 8, M = 1. Right:
Funnel EG, K = 3.

resident
b
d

(5)

Tarnita et al. (2009) consider evolutionary dynamics (under
weak selection) on graphs for the general game given by (5) and
present a theorem stating that a strategy A (mutant) is favored
over strategy B (resident) iff a + b > c + d, depending on the single
parameter . “A is favored over B” means that it is more abundant
in the stationary distribution of the mutation selection process. The
authors show  to depend on the population structure, update rule
(see Section 5), and mutation rate. Thus the single parameter can
be used to quantify the ability of a population structure to promote the evolution of cooperation or to choose efﬁcient equilibria
in coordination games. In general, if the combination of update
rule and population structure leads to a  > 1 (which can but does
not necessarily occur for different combinations), individuals of the
same strategy type are more likely to interact due to a clustering of
strategies (Nowak and May, 1992; Nowak et al., 2010).

Lieberman et al. (2005) examine the ﬁxation probability for a
few special cases of EGs to illustrate how ﬁxation can be ampliﬁed
or suppressed based on the structure of the graph. For example,
they deﬁne a one-rooted graph as a graph with a unique global
source without incoming edges (i.e. a directed tree, with edges
directed toward the leaves, would be such a graph – the unique
global source being the root in this case). Hence, for any value of r,
if an EG is one-rooted its ﬁxation probability is 1/N.
Another special case is the EG referred to as a super-star (see
K
Fig. 1). Such a structure, denoted SL,M
consists of a central vertex,
vcenter surrounded by L leaves. A leaf , contains M reservoir vertices,
r,m and K − 2 ordered chain vertices c,1 , . . ., c,K−2 . All directed
edges are of the form (r,m , c,1 ), (c,w , c,w+1 ), (c,K−2 , vcenter ), and
K as (S K ),
(vcenter , r,m ). Denoting the ﬁxation probability of EG SL,M
L,M
the following result is given in Lieberman et al. (2005).
K
lim (SL,M
)=

L,M→∞

1 − 1r K
1 − 1/r K · N

(6)

Because of the role it plays in enhancing ﬁxation, the K parameter
is often referred to as the ampliﬁcation factor. If K = 2, this is simply
referred to as a star EG (see Fig. 1). Another special case, related
to the super-star, is the funnel (see Fig. 1). A generalization of the
funnel, known as a layered network was studied by Barbosa et al.
(2009, 2010). In this type of EG, V can be partitioned into K subsets V1 , . . ., VK such that for all v ∈ Vi there are only outgoing edges
to vertices in set Vi+1modK . Barbosa et al. (2010) also present a way
to increase the speed of MCMC simulations speciﬁc to layered networks. Their technique involves skipping evolutionary steps where
none of the vertices in the graph changes a label. This is done by
calculation the probability of a change occurring somewhere in the
graph. The tradeoff with this speed-up is the price of calculating
this probability compared to the savings. The authors show for layered networks, that this probability can be efﬁciently computed
and yield a 2–3 times speed-up in simulations for K-funnels and
random layered networks.
These special cases represent important building blocks for
other results. For instance, Broom et al. (2010a) leverages some
of these intuitions to study ﬁxation probability for games on star
graphs while the work on bi-level EGs we review in Section 7.1
leverages some of these ideas as well. More recently, this style

70

P. Shakarian et al. / BioSystems 107 (2012) 66–80

of analytical calculation of ﬁxation probabilities has been applied
to economics by Zhou (2011) where the authors determined the
evolutionary stability of various forms of business, which are modeled as star and bi-level graphs (we discuss this work further in
Section 7.1 as well). Analytically ﬁnding the value of  for certain
graph topologies will most likely continue to be an active area of
research in EGT, particularly as certain structures are identiﬁed in
nature or other domains. Perhaps an interesting direction would
be to use work on the subgraph isomorphism problem (Garey and
Johnson, 1979) to identify structures such as stars and funnels in
larger graphs. The presence of such structures may allow us to make
statements on the evolutionary stability of the larger graph and/or
compare the probability PC for certain vertices in the larger graph
(i.e. PC may be higher for a set of nodes located in a star substructure
of a larger graph).

(2011) that as the relative ﬁtness of the mutant increases, the ﬁxation probabilities increase more rapidly for mutants placed into
vertices with higher degree. Some of these results were experimentally veriﬁed by Broom et al. (2009). In Section 5, we examine
the correlation of the initial mutant’s degree to the ﬁxation probability when the dynamics of the evolutionary process is changed
via different update rules.
It is also interesting to note that Broom and Rychtář (2008)
were able to analytically solve for the ﬁxation probabilities for
the special case of undirected star graphs (K = 2) of L leaf vertices
(hence N = L + 1). Let Pi0 (Pi ) denote the ﬁxation of probability given
i mutants on the leaves and a the center being a mutant (resp. the
center being a resident). Broom and Rychtář (2008) derived the
following.
P10 =

3.2. Undirected evolutionary graphs
Several works explore a large special case: undirected EGs. In
this case, we shall use the symbol E to denote the set of edges.
However, it is important to note that the precise deﬁnition of this
graph is somewhat different than the standard concept of an undirected graph. Speciﬁcally, the weights in both directions are not the
same. This is deﬁned by Broom and Rychtář (2008) as



wij =

di−1
0

iff (vi , vj ) ∈ E or (vj , vi ) ∈ E
otherwise

Theorem 4 (Undirected Isothermal Theorem (Broom and Rychtář,
2008)). An undirected EG is isothermal iff it is regular.
Interestingly, for the undirected case, when r = 1 (neutral drift),
there is a tractable solution to the constraints speciﬁed by Eq. (3)
that is presented by Broom et al. (2010).
PC =



−1

vi ∈C (di

)

−1
vj ∈V (dj )

(8)

Hence, for an undirected graph with r = 1, we have  = 1/N. For
the case where a mutant is very advantageous, r > > 1, Broom et al.
(2011) provide us with an approximation for PC when C is a singleton set (the approximation is based on the assumption that once
|C| ≥ 2, then ﬁxation occurs).
P{vi } ≈

r+



r

vj ∈V −{vi } wji

(9)

Broom et al. (2011) conducted an exhaustive study of undirected graphs with 8 vertices and concluded that a low degree
of a vertex corresponded with a more advantageous mutant and
this
 advantage seemed to increase monotonically for vertex vi with
d
vj ∈V j

− di . This aligns well with Eqs. (8) and (9). Further, they also
provide the following analytical approximation for relative mutant
advantage.
N

P{vi }
P{vj }

 2

≈

dj

di

1+

L−1 

r
P0,
r+L 1

(10)

The inverse relationship between ﬁxation and the degree of the
initial mutant vertex shown by Broom et al. (2011) is in strong
agreement with the previous work of Antal et al. (2006). It is interesting to note that experimentally, it was observed by Broom et al.

j=1



(11)

j
L+r
r(L · r+1)

P0 =

r ·L
P0
r ·L + 1 1

(12)

From this, they derive the following for ﬁxation probability
(undir-star ).
undir-star =

	

lim undir-star =

L→∞

L·

(L + 1) 1 +

(7)

where di is the degree of vi . The intuition behind this asymmetric assignment of weights is that if vi is chosen to reproduce, it
replaces one of its neighbors with a uniform probability. Broom and
Rychtář (2008) determined a necessary and sufﬁcient condition for
an isothermal undirected graph.



P00 =

1

L
L+r

r ·L
r · L+1
L
L+r

+

r
r+L

L−1 
j=1




j
L+r
r(L · r+1)

1 − 12
r
1 − 12L
r

(13)

(14)

3.3. Calculating ﬁxation probability using dynamics
Another novel approach to determining ﬁxation probabilities is
through the use of dynamics which involves a carefully constructed
variation of the Kimura diffusion equation. This approach was introduced by Houchmandzadeh and Vallade (2010) for well-mixed
populations and extended to a graphical case (that generalizes
the model of Maruyama (1974)) in Houchmandzadeh and Vallade
(2011). Here we illustrate this approach by using it to derive the
Moran probability, 1 . This particular approach is rooted in the
master equation governing a continuous time birth–death stochastic process in a community of ﬁxed size N, when the probability of
observing k events in an inﬁnitesimal time interval dt is proportional to Poissonian events dtk . The transition rates , derived from
the probability density for the system to change its size from n
to m individuals during the inﬁnitesimal period of time as dt → 0,
become the weights of the master equation summarized by
(n → n + 1) = + (n),
−

(15)

(n → n − 1) =  (n),

(16)

(n → n + k) = 0,

(17)

if |k| > 1.

The master equation governing the probability, P(n, t), of observing
n individuals at time t and incorporating the transition weight for
each observance is given by

∂P(n, t)
= + (n − 1)P(n − 1) − + (n)P(n) + − (n + 1)P(n − 1)
∂t
− − (n)P(n).

(18)

We can generalize problems using the master equation to
continuous time Moran Processes for haploid populations
(Houchmandzadeh and Vallade, 2011). As usual, we have a population of N individuals that are either mutants or residents.
Individuals in this population die randomly at a rate  and are
immediately replaced with a duplicate of another individual. Also
as normal, residents have a ﬁtness of 1 and mutants have a ﬁtness

P. Shakarian et al. / BioSystems 107 (2012) 66–80

of r. We shall use the symbol s for the value (r − 1) – the difference in ﬁtness between the two. This quantity s will be factored
into the duplication probability to decrease or increase the population of individuals carrying the mutant gene by one unit within
time step dt. Designating n to be the number of individuals carrying the mutant gene and (N − n) the number of all those who
do not, the transition probabilities become (Houchmandzadeh and
Vallade, 2010)
− (n) = n

(N − n)
N

(19)

+ (n) = n

(N − n)
(1 + r)
N

(20)

(N − n)
(n, s) = n
(1 + r)
N

(21)

and

∂P(n, t)
= ˛(n, r)P(n − 1) − ˇ(n, r)P(n).
∂t

(22)

where ˛(n, r) = (n − 1, r) + (n − 1, 0) and ˇ(n, r) = (n, r) − (n, 0).
To transform the discrete master Eq. (22) into a continuous differential equation for large N, we must set x = n/N, dx = 1/N, p(x, t)dx = P(n,
t), and (x, r) = (n, r). Developing Eq. (22) by transforming each
term into powers of dx yields
2

∂p(x, t)
1 ∂[˛(x, r)p(x, t)]
1 ∂ [ˇ(x, r)p(x, t)]
3
+ O(dx ),
=−
+
N
2N 2
∂t
∂x
∂x2
(23)
and can be approximated by the Kimura diffusion equation, such
that
2

∂p(x, t)
∂[x(1 − x)p(x, t)] ∂ [x(1 − x)p(x, t)]
.
= −Nr
+
∂t
∂x
∂x2

(24)

The neat thing about developing the equation this way is that we
do not have to use it as it is an approximation. By deriving Kimura’s
diffusion equation using the applied transition rates we validate
that the method is sound. So instead of resorting to the approximation, we can take a more direct route and extract exact quantities
such as the probability generating function (PGF) by letting
(z, t) =

z n P(n, t),

(25)

n

where z is an auxiliary continuous variable. Notice that PGF (z,
t) constitutes the most complete information we can have on the
given stochastic process. The system will have two absorbing states
at n = 0 and n = N. This will have the added effect of ensuring that
(z, t) is a polynomial of degree N for n < 0 and n > N. Substituting
(z, t) into the master Eq. (22) yields

∂
= 
(z n+1 − z n )(n, r) + 
(z n−1 − z n )(n, 0)
∂t

(26)

We now turn to the transition rates, (n, r), for the Moran Process. Recall that we measure time as /N = 1 and therefore
(n, r) = k(r)n(N − n)

where k(r) = 1 + r. Eq. (26) becomes

∂
= 
(z n+1 − z n )k(r)n(N − n) + 
(z n−1 − z n )k(0)n(N − n)
∂t

(27)

(28)

We can now make use of the identity (Houchmandzadeh and
Vallade, 2010)




z n+˛ k(r)n(N − n) = k(r)z ˛ z

∂
∂
N − z
∂z
∂z



which when used to evaluate Eq. (28) yields



where n and (N − n) represent the probability per unit of time
that either one A individual dies and is replaced by a non-A individual or vice versa, respectively. The factor (1 + r) designates the
differing ﬁtness levels of the mutants. Time will be measured in
N/ units so that /N = 1.
Because N and  are ﬁxed, Eqs. (19) and (20) can be combined
as a function of two parameters allowing a slightly simpler version
of Eq. (18). Thus,



71

∂
∂
∂
N − z
= (k(r)z 2 − k(r)z + k(0) − k(0)z)
∂t
∂z
∂z



= (1 − z)(k(0) − k(r)z)

∂
∂
N − z
∂z
∂z



∂
∂
= (1 − z)(k(0) − k(r)z)
N − z
∂z
∂z
1
∂
= (1 − z)( − z)

∂z



∂
N − z
∂z

(29)


(30)



(31)


(32)



(33)

where  is the inverse of the ﬁtness such that
 = k(0)/k(r) = 1/k(r) = 1/(1 + r). This partial differential equation
is well-deﬁned and has the exact same formal structure as the
diffusion equation. Notice that it is ﬁrst order in time t and second
order in z. The initial and boundary conditions are speciﬁed as
well. For the initial condition examine time t = 0. There are n0
individuals with the mutant gene. That means there is a 100%
probability of observing n0 individuals have the mutant gene or
P(n0 , 0) = 1 and Eq. (25) becomes
(z, 0) = z n0 .

(34)

Further, because P(n, t) is stochastic we have a boundary in that
(1, t) = 1.

(35)

If s = 0, then k(0) = k(r), 
n(t)  = n0 , and



∂ 

= n0 ,
∂z 
=1

if r = 0.

(36)

/ 0, z =  is a ﬁxed point because
If r =



∂ 

= 0,
∂t 
z=

if r =
/ 0

(37)

which means that
(, t) = (, 0) =  n0 .

(38)

Houchmandzadeh and Vallade (2011) demonstrate that Eq. (33)
along with initial condition Eq. (34) and the boundary conditions
Eq. (35) with either Eq. (36) or (38) constitute a well-posed problem.
Fortunately, (z, t) of Eq. (33) converges to stationary solution
s (z). This stationary solution is found by solving the ﬁrst order
differential equation
Ns (z) − zs (z) = K

(39)

where K is a constant. The solution of (39) is
s (z) = c1 z N + c0

(40)

If we now use the boundary conditions (35) and (36) when r = 0, we
can solve for c1 and c0 . They become
c1 =

n0
,
N

c0 =

N − n0
.
N

(41)

72

P. Shakarian et al. / BioSystems 107 (2012) 66–80

Of course when r =
/ 0, boundary condition (36) is replaced with
(38) and
c1 =

1 −  n0
,
1 − N

c0 =

(42)

1 − 1/r
1 − 1/r N

(43)

4.1. Time to ﬁxation for ﬁxed ﬁtness
Here, we examine research on time to ﬁxation when the ﬁtness
of the mutant and resident is ﬁxed at r and 1 respectively (i.e. not
determined by the outcome of a game). In the undirected case, this
was explored experimentally by Whigham and Dick (2008), Broom
et al. (2011), and Paley et al. (2007). Generally, these studies ﬁnd
that certain graph structures which promote ﬁxation (i.e. stars and
funnels) also increase time to ﬁxation. Whigham and Dick (2008)
found that stars increase the time to ﬁxation over regular graphs by
two orders of magnitude. Paley et al. (2007) examine domination
times for lattices. Domination in that work refers to a mutant or
resident occupying a large fraction of vertices (approaching N) –
hence the term ‘dominate’ is used to describe the results of Paley
et al. (2007) rather than ﬁxation. They found experimentally that
time t* for mutants to dominate lattices decreases as the dimension
of the lattice increases (i.e. a fully connected graph has a faster time
to domination than a square lattice) for several different values
of r.
There has also been some work to explore this problem analytically. Antal and Scheuring (2006) provided a method for
determining mean time to ﬁxation (and mean time to extinction) in
well-mixed populations. This formal method was later adopted by
Nie and Zhang (2010) for ﬁxed ﬁtness and Broom et al. (2010a) for
ﬁtness resulting from a two player game (described in the next section). We brieﬂy highlight the most relevant parts of this method
as follows. Given a well-mixed population of N individuals, let 0,
. . ., i, . . ., N denote N + 1 possible states identiﬁed by the number of
mutants in each state (analogous to the different conﬁgurations in
an evolutionary graph). We will use the notation Pi , Pi to denote ﬁxation and extinction probabilities given initial state i. Let i be the
transition probability from state i to state i − 1 and 	i be the transition probability from state i to i + 1. Antal and Scheuring (2006)
showed the following:
s0,i−1
s0,N−1

(44)

m

q
k=n k

1
(t)
t · Pi
Pi

ti =

and qi =

(45)

Additionally, the following recursions hold.
(t)

Pi

i

j
.
j=1 	j

(t)

(t)

Now we deﬁne Pi , Pi

be

the probabilities of entering ﬁxation/extinction at time t. Let ti (resp.
ti ) be the mean times to ﬁxation (resp. extinction) given state i at
time 0. We are concerned with ﬁnding t1 – the probability of ﬁxation

(t−1)

= i Pi−1

(t−1)

+ (1 − i − 	i )Pi

(t−1)

+ 	i Pi+1

Pi ti = i Pi−1 (ti−1 + 1)+(1 − i −	i )Pi (ti + 1)+	i Pi+1 (ti+1 + 1)

(46)
(47)

Through a series of further manipulations and by expression (44),
Antal and Scheuring (2006) determined the mean time to ﬁxation
as follows.
t1 =

In this section we explore an area of EGT that has recently seen
some interesting activity: determining the mean time it takes to
reach ﬁxation. First we examine this for ﬁxed values of r and then
for the case where r depends on the payoff of a two-player game.

where sn,m =

and we can

t=0

4. Time to ﬁxation

Pi =

(t)

∞

 n0 −  N
.
1 − N

It is interestingly to note that as r → 0, Eq. (42) converges to Eq. (41).
Note that for relatively small ﬁtness, r, c1 of Eq. (42) contains the
well-known result for ﬁxation probability for haploid populations,
namely the Moran ﬁxation probability result, Eq. (1) of the previous
section.
1 =

∞

P
given a single mutant invader. Clearly, Pi =
t=0 i
obtain the following for the mean time to ﬁxation.

N−1

s0,n−1 sn,N−1
n=1

	n qn s0,N−1

(48)

Note that Antal and Scheuring (2006) rely on determining mean
time to ﬁxation based on the transition probabilities (for example,
Antal and Scheuring, 2006, look at when these ﬁxation probabilities
are dependent upon game-play, the problem becomes more complex, even for well mixed populations). Further, in a well-mixed
population there are N + 1 states, signiﬁcantly less than the 2N
possible states for an arbitrary evolutionary graph. Therefore, evolutionary graph theorists focus on reducing the state space (usually
by assuming a certain graph topology) and calculating the transition probabilities ( and 	). If a certain graph topology allows for a
tractable number of states, analytical results become apparent.
This method was applied successfully for ﬁxed ﬁneness by Nie
and Zhang (2010). Using the aforementioned described method,
they obtain the following result for isothermal evolutionary graphs.
Here the notation t1 refers to the mean time to ﬁxation given a
single mutant picked with a uniform probability over the set V.
Theorem 5 (Isothermal Mean Time to Fixation (Nie and Zhang,
2010)). For large N in an isothermal structure, the mean time to
ﬁxation is:
t1 =

N−1

(r n − 1)(r N−n − 1)(1 + r)
n=1

(r N − 1)(r − 1)

(49)

Then show an analogous result for K-star structures.
Theorem 6 (K-Star Mean Time to Fixation (Nie and Zhang, 2010)).
For large N in a k-star structure, the mean time to ﬁxation is:
t1 =

N−1

(r nK − 1)(r (N−n)K − 1)(1 + r K )
n=1

(r NK − 1)(r K − 1)

(50)

Though we have analytical results for these special cases, there
are still many open questions dealing with mean time to ﬁxation
(and extinction). For example, identifying the complexity of calculating the mean time to ﬁxation in the general case has not been
addressed. A good complexity analysis may lend some insight into
this particular problem. To provide some insight into this general
case, we will derive a set of constraints similar to expression (3)
earlier in the paper. For a given conﬁguration C of mutant vertices
(the remainder of the population being residents), let C,i be the
transition probability from C to C − {vi }, 	C,i be the transition probability from C to C ∪ {vi }, and 
 C be the probability that C transitions
to itself. Hence, we have the following:
C,i =


vj ∈/C

wji
N + r|C| − |C|

(51)

P. Shakarian et al. / BioSystems 107 (2012) 66–80

	C,i =



wji r

(52)

vj ∈C

N + r|C| − |C|

⎛




C = 1 − ⎝

C,i +

vi ∈C



⎞
	C,i ⎠

(53)

vi ∈/C

We can now create an analogous recursion mirroring that of (46)
(t)
for well-mixed populations where PC is the probability of entering
an all-mutant state at time t given initial set C.

⎛
(t)

PC =



⎝

C,i PC−{v } ⎠ + 
C PC
(t−1)
i

vi ∈C

⎛
PC tC =

⎞



⎝

+

⎝

⎞

+⎝

	C,i PC∪{v } ⎠



⎞



Table 1
Different families of update rules.
Update rule

Intuition

Birth–death (BD) (a.k.a.
invasion process (IP))

(1) Vertex vi selected
(2) Neighbor of vi , vertex vj selected
(3) Offspring of vi replaces vj

Death–birth (DB) (a.k.a.
voter model (VM))

(1) Vertex vi selected
(2) Neighbor of vi , vertex vj selected
(3) Offspring of vj replaces vi
(1) Edge (vi , vj ) selected
(2) The offspring of one vertex in the edge
replaces the other vertex

Link dynamics (LD)

(t−1)
i

vi ∈/C

C,i PC−{vi } (tC−{vi } + 1)⎠ + 
C PC (tC + 1)

vi ∈C

⎛

(t−1)

⎛

73

⎞
	C,i PC∪{vi } (tC∪{vi } + 1)⎠

vi ∈/C

Clearly, as we are dealing with a intractable number of states there
are an intractable number of constraints and variables the above
expression, making it impractical. Hence, a more practical algorithm is in order if we are to avoid simulation for this problem.
Another option would be to explore mean time to ﬁxation for
special cases, such as undirected evolutionary graphs or the case of
neutral drift. Another area that is largely unexplored (in the general
case) is time-to-ﬁxation under alternate update rules, such as the
voter model (although for games on star graphs, we review the
work of Hadjichrysanthou et al., 2011, in the next section).

analyzed quantities, but not that these results can be signiﬁcantly
different for a Hawk–Dove game with an alternative payoff matrix.
In general, this work illuminates the fact that discovering and
describing (to the extent that they exist) general and consistent patterns in the effects of game payoffs, graph types, and combinations
thereof on ﬁxation probability and time to ﬁxation is a challenging but important area for future work. Hadjichrysanthou et al.
(2011) made a step of progress in this direction by providing general formulae for ﬁxation probability and mean time to absorption
for star graphs speciﬁcally. The authors provide detailed analysis of
these quantities for the ﬁxed ﬁtness case and the Hawk–Dove, Prisoner’s Dilemma and coordination games. They ﬁnd that the time to
absorption on star graphs depend crucially on the update process
used: while in general birth–death processes yield higher ﬁxation
probabilities for advantageous mutants, birth–death processes take
much longer to reach ﬁxation/absorption than death–birth processes (see Section 5 for details on these update processes). There
is still much room for this type of work on more general graphs:
Open Problem 4.3. Discover and describe patterns of the effects
of a larger variety of graph structures, game payoffs, and their combinations on ﬁxation probability and time to ﬁxation.

4.2. Time to ﬁxation for games on graphs
5. Alternate update rules
Broom et al. (2010a) studied evolutionary dynamics for general
games on several special graph structures: the star, the circle, and
the complete graph under a birth–death update process (speciﬁcally the invasion process, see Section 5) while placing an emphasis
on the speed of the evolutionary process in their analysis. At each
time step, the ﬁtness of an individual is assumed to be the average of
the payoffs of games against all its neighbors. The authors analyze
and derive exact solutions for the ﬁxation probability of mutants,
the mean time to absorption and the ﬁxation time of mutants on the
three graph structures considered. The authors ﬁnd these quantities to differ for the different graph structures and in general depend
on population size and graph heterogeneity.
The authors conﬁrm earlier ﬁndings that ﬁxation probability
usually increases with graph heterogeneity. The time to ﬁxation
for mutants was found to be shortest for the complete graph and
longest for the star, conﬁrming the results from the previous section that ﬁxation time generally is longer for graph structures that
promote ﬁxation. Fixation times for all graphs explored were also
shown to be longest in neutral drift. More interestingly however,
using a Hawk–Dove game as an example, the authors show that
the variation of the payoff values in the payoff matrix of a game
played on graphs plays a crucial role in the behavior of the analyzed
quantities. Not only is the ﬁxation probability no longer the same
for all regular graphs with N vertices, but also which of the three
considered graph types gives the highest mutant ﬁxation probability and the fastest time to ﬁxation/absorption depends on the
values of the game’s payoff matrix. The authors give several interesting features of the Hawk–Dove game considered regarding the

Let us momentarily return to the original model of Lieberman
et al. (2005). At each time-step, some vertex vi is selected with
probability

 fi

f
vj ∈V j

, where fi is the ﬁtness of vi and equal to either

1 or r. This is the vertex chosen to reproduce, hence a ‘birth’ event.
The next vertex selected is one of the neighbors of vi – lets call it
vj and it is selected with probability wij . This is a ‘death’ event as vj
is replaced with a duplicate of vi . Notice that the ﬁtness of vj is not
considered when it is selected. Hence, the ﬁtness bias is on the birth
event. This method of selecting vertices vi and vj is referred to as an
update rule. The update rule described by Lieberman et al. (2005)
is termed ‘birth–death with birth bias’ or BD-B updating. Several
works address different update rules including: Antal et al. (2006),
Ohtsuki and Nowak (2006), Sood et al. (2008), Masuda and Ohtsuki
(2009), and Masuda (2009). Overall, we have identiﬁed three major
families of update rules – birth–death (a.k.a. the invasion process)
where the vertex to reproduce is chosen ﬁrst, death–birth (a.k.a.
the voter model) where the vertex to die is chosen ﬁrst, and link
dynamics, where an edge is chosen. We summarize these in Table 1.
Note that the three categories of Table 1 are very broad as
they do not consider ﬁtness-based bias in vertex selection (i.e.
the BD-B updating of Lieberman et al. (2005) places the bias on
the birth event as the ﬁrst vertex is chosen with a probability
proportional to its ﬁtness). If there is a birth-bias, the individual
reproducing is chosen with a probability proportional to its ﬁtness. If there is a death-bias, the individual dying is chosen with a
probability inversely proportional to its ﬁtness. We summarize how

74

P. Shakarian et al. / BioSystems 107 (2012) 66–80

Table 2
Variations of EGT. vi and vj are vertices in a graph that are neighbors, vi is always
chosen ﬁrst. fi and fj are the associated ﬁtness values which both equal 1 in the case
of neutral drift.
Update rule

Birth–death (BD)

Special case

Intuition

Unbiased, undirected
Directed

Offspring of vi replace vj
Considers vi ’s outgoing
edges
vi chosen w. prob.
proportional to fi
vj chosen w. prob.
proportional to fj−1

Biased-birth (BD-B)
Biased-death (BD-D)

Death–birth (DB)

Unbiased, undirected
Directed
Biased-birth (DB-B)
Biased-death (DB-D)
Unbiased, undirected

Link dyn. (LD)

Imitation (IM)

Pairwise compar. (PC)
Directed, unbiased
Directed, birth biased
Directed, death biased

Offspring of vj replace vi
Considers vi ’s incoming
edges
vj chosen w. prob.
proportional to fj
vi chosen w. prob.
proportional to fi−1
One vertex reproduces to
replace the other
Least ﬁt vertex dies,
replaced by offspring of
other vertex
vj replaces vi iff fj > fx , o/w
no change
Edge from vi to vj , vi
replaces vj
Edge selected w. prob.
proportional to fi
Edge selected w. prob.
proportional to fj−1

directionality and bias affect the update rules in Table 2. Note that
imitation (IM) is also known as biased link dynamics.
5.1. Comparing update rules in undirected EGs
For the case on undirected graphs, there are many results based
on the initial placement of the mutant have been discovered for
several update rules (as we have described for BD-B in the previous
section). Antal et al. (2006) and Sood et al. (2008) studied moments
of degree distribution, density, and degree-weighted moments and
show that the ﬁxation probability is proportional to the average
degree-weighted moment for death–birth updating (a.k.a. voter
model), the inverse for birth–death (a.k.a. invasion process), and
equal to the density (the percentage of the number of vertices in
the graph labeled as mutants) for link dynamics, thus independent
of the underlying graph in that case. Note that their results for BD-B
are in agreement with the ﬁnding of Broom et al. (2011) described
earlier.
As shown in Theorem 4, under BD-B, an undirected EG is isothermal iff it is regular. In Antal et al. (2006), this is extended to other
update rules as follows.
Theorem 7 (Antal et al., 2006). Evolutionary dynamics under BD-B,
DB-D, and LD are equivalent for undirected regular EGs.
Although there is currently an excellent suit of results for studying evolutionary graphs under various different update rules in
the directed case, there has been no work (to the knowledge of
the authors) that compares any of these update rules to the synchronous update model described by Santos et al. (2006).2 At each
time-step, all individuals in the population update their labels (i.e.

2
Note that the original work of Santos et. al. is a model with a game theoretic
extension. Here we describe the natural, ﬁxed ﬁtness counterpart for the purpose of
examining the update rule. We review this work with respect to its game theoretic
results in Section 6.

Table 3
Summary of experimental results for directed case with r = 1 by Masuda and Ohtsuki
(2009) illustrating whether experimentally determined ﬁxation probability results
that aligned with the mean-ﬁeld approximation. din and dout are the in and out
degrees of the initial mutant vertex.
Mean-ﬁeld approximation

BD: 1/din

DB: dout

LD: dout /din

Asymmetric random
Asymmetric scale-free
E-mail
Asymmetric Small World

1/din
No relation
No relation
No relation

dout
dout
No relation
No relation

dout /din
dout /din
No relation
No relation

mutant or resident, or strategy if game-play is involved) simultaneously. For each vertex vi , one of its neighbors (vertex vj ) is selected at
1
. Then, if and only if fj > fi , vi ’s label is replaced with vj ’s label with a
d
i

probability proportional to fj − fi (i.e.

fj −fi
max(di ,dj ) · r

for example). There

are several interesting aspects about this model. First, is that the ﬁtness of vertices does not play a role in selecting which vertex is born
and/or dies. Rather, the ﬁtness determines if a vertex is replaced by
a neighbor and the probability at which this happens. Second, the
model presented by Santos et al. (2006) clearly has a death–birth
ﬂavor to it. One could easily adjust it for other types of dynamics.
Third, as all vertices are updated simultaneously, we might conjecture that the evolutionary process occurs faster than in the other
update rules. These topics may warrant some further consideration in that synchronous updates may represent some real-world
processes more accurately or possibly be used as a proxy for the
standard update rules we have already described. Further, the synchronous update model can also easily be extended to the directed
case, which we cover for the other update rules in the next section.
5.2. Comparing update rules in directed EGs
Not only does the original model of Lieberman et al. (2005) utilize a directed graph, but also many real-world networks can be
more accurately modeled as directed graphs than undirected ones.
This is the motivation of the work (Masuda and Ohtsuki, 2009;
Masuda, 2009). There are two main conclusions to their work: (1)
degree correlation to ﬁxation probability (i.e. using the exact methods of Broom et al. (2010) or the mean-ﬁeld approximation) for
undirected graphs does not necessarily hold in the direct case and
(2) directed graphs generally suppress ﬁxation more than undirected ones.
Masuda and Ohtsuki (2009) studied directed graphs under LD,
BD, and DB for r = 1. For all three update rules, under r = 1, they
derive sets of linear constraints using the mean-ﬁeld approximation (degrees of connected vertices in the EG are uncorrelated).
They compare these analytical approximations with experiments
and ﬁnd that, in general, the ﬁxation probability is not only dependent on the degree of the initial vertex but also the global structure
of the graph. In fact, often there is no observed relation between
degree and ﬁxation. See Table 3 for a summary of experimental results compared with the analytical approximations. While
Masuda and Ohtsuki (2009) mainly considered the case of neutral drift (r = 1), they also run some tests with r = 4 and claim that
ﬁxation increases monotonically with r.
Masuda (2009) performed an in-depth comparison on directed
and undirected networks for several variants of these rules
(Table 4). He exactly computes ﬁxation probabilities on an exhaustive set of small graphs (with six vertices) and uses Monte-Carlo
approximation for randomly generated larger graphs. He found
that directed networks tended to suppress more than undirected,
regardless of update rule. Based on these experiments for small
networks, the order of ampliﬁcation for rules is as follows: BD-B >
LD > DB-D > BD-D > DB-B (BD-B was least suppressive and DB-B
was the most suppressive). The value of r was set to 4 in these

P. Shakarian et al. / BioSystems 107 (2012) 66–80
Table 4
Relationship between ﬁxation and degree of initial vertex (undirected graphs).
Update rule

Fixation probability proportional to

BD-B
DB-D
LD

Inverse of degree of initial vertex
Degree of initial vertex
Density of mutant vertices

trials. For large graphs (also with r = 4), the simulations provided
the following ordering: BD-B > BD-D, LD > DB-D > DB-B.
The authors are currently looking at adopting the algorithm of
Shakarian and Roos (in press) for alternate update rules on directed
EGs, which would allow us to obtain more exact and deterministic
results on larger graphs(as we would not resort to simulation). This
would provide a complement to the work of Masuda (2009).
6. Further game theoretic extensions
Now that we have described alternate update rules, we shall
re-visit our game-theoretic extensions and review some results
regarding topics such as cooperation, reciprocity, and evolutionary
stability w.r.t. a game on the graph under various update rules.
6.1. Evolutionary stability on graphs
Evolutionary stability, describing the ability of a player type
comprising a population to be resistant against invasion by another
type, is an important concept in evolutionary game theory that has
been well studied for well-mixed populations. Ohtsukia and Nowak
(2008) analyzed evolutionary stability on regular graphs of degree
k > 2 for the BD, DB, and IM updating rules through pairwise approximation and simulation. Evolutionary stability on graphs means
that a small fraction of rare mutants cannot spread, i.e. a resident
strategy evolutionarily stable if it has a selective advantage over an
invading strategy (invading at an  fraction of the total population).
Ohtsuki et al. provide evolutionary stability conditions for this definition on regular graphs for the different update rules considered,
and (on top of the game payoff matrix values) all these conditions
depend on the graph degree k. The results are validated through
simulations on speciﬁc game examples. The important point to consider from these results is that population structure can have crucial
impact on the evolutionary stability of strategies, i.e. in the words
of “traditional criterion for evolutionarily stable strategies in wellmixed populations is neither necessary nor sufﬁcient to guarantee
evolutionary stability in structured populations”.

75

Prisoner’s Dillema coincide with those of Ohtsuki et al. (2006),
showing identical conditions necessary for cooperators to be
favored over defectors. Results for the snow drift game qualitatively agree with those of Hauert and Doebeli (2004), who
observe that spatial structure inhibits cooperation in the snow drift
game.
6.3. Evolution of cooperation and social viscosity
Ohtsuki et al. (2006) explored the problem of cooperation on a
variety of graphs through numerical simulations. The graph types
explored are cycles, spatial lattices, random regular graphs, random
graphs and scale free networks. Every player plays a game with
all its neighbor, where the game between two players is given by
the payoff matrix (54). This game represents a Prisoner’s Dilemma
game between two players, and gives a kind of Public Goods Game
when each player plays the game with all its neighbors. In this
game b is called the beneﬁt of the altruistic act and c is the cost
of the altruistic cooperation act. A Cooperator that is connected to
n Cooperators and m Defectors for receives a payoff of b n − c (n + m).

cooperate
defect

cooperate defect
b-c
-c
b
0

(54)

Ohtsuki and Nowak (2006) studied evolutionary games on regular graphs of degree k considering the BD, DB, IM, PC update rules.3
The authors use pair approximation (Matsuda et al., 1987, 1992;
Keeling, 1999; Haraguchi and Sasaki, 2000; Van Baalen, 2000) to
derive a system of ordinary differential equations describing the
change in expected frequency of strategies in a game on a graph
over time. In the limit of weak selection (w 	 1), the authors show
that under the update rules BD, DB, and IM this differential equation
is the well-known replicator equation with a transformed payoff
matrix. The payoff matrix is the original payoff matrix summed
with a payoff matrix describing the local competition of strategies, different for BD, DB, and IM. PC is shown to be equivalent
to BD in the model used. This result is applied to the Prisoner’s
Dillema and the Snow Drift Game on regular graphs. Results for the

Ohtsuki et al.’s results suggest that under the DB update rule, a
necessary condition for cooperation to arise in the types of graphs
explores is that b/c > k, where k is the average number of neighbors.
This result is derived under the conditions of weak selection and
that the number of vertices in the graph is much larger than the
average degree. The authors note the close and interesting relation
of this result to Hamilton’s rule (Hamilton, 1964), which states that
kin selection can favor cooperation provided that b/c > 1/r, where
r is the coefﬁcient of genetic relatedness between individuals. The
condition for cooperation ﬁts less well for non-regular graphs, as
one would expect due to the larger variance in vertex degrees, but
is a good approximation unless the variance in degree distributions
of the graph gets too large. Other dynamics explored are IM, 4 for
which cooperation is favored when b/c > k + 2, and BD, for which
cooperation is never favored by selection.
Other authors have veriﬁed the condition introduced by Ohtsuki
et al. (2006) to hold in a different model with network dynamics. Yang et al. (2009) used pair approximation and numerical
simulations to deduce cooperation frequencies for social dilemma
games (including the Prisoner’s Dilemma and Snow-Drift games)
on graphs whose structure changes as part of the update rule
throughout evolution. The graphs originally are randomly connected with average degree k. The update rule used is a type of DB
process which also involves addition and deletion of vertices and
edges in the graph: “An individual is selected for reproduction with
a probability proportional to his ﬁtness. The offspring is introduced
with the same strategy of his parent and connects to his parent
always and other k − 1 individuals randomly. The offspring replaces
a random individual except for his parent. The randomly selected
individual with all its links are removed.” More recently, the preliminary work of Zhong et al. (2011) also conﬁrmed Ohtsuki’s rule
on a continuous version of the model.
Voelkl and Kasper (2009) used evolutionary graph theory to
understand the emergence of cooperation in primates. Using social
interaction networks derived from empirically observed social
interactions, they looked at a two player game with payoff matrix
as (54). The authors use selection intensity Eq. (4) with w = 0.01 to

3
We use the shorter BD and DB notation for the update rules with birth bias BD-B
and DB-B. See Table 2.

4
Ohtsuki et al. (2006) also noted that mathematically, “IM updating can be
obtained from DB updating by adding loops to every vertex”.

6.2. Regular graphs and the replicator equation

76

P. Shakarian et al. / BioSystems 107 (2012) 66–80

determine ﬁtness. The authors discovered that the structured populations of the primates were more likely to reach ﬁxation than
populations of well-mixed individuals.
Voelkl and Kasper (2009) also looked at the community structure of the primate interaction networks. For this they leveraged
the idea of modularity introduced by Newman and Girvan (2004).
Given a partition of vertices in a graph, modularity measures the
quality of these partitions – often referred to as “communities”.
Intuitively, the modularity of a partition increases with the density of edges within communities and decreases with the density
of edges outside of communities. Often in work dealing with modularity (such as Newman, 2004; Blondel et al., 2008) researchers
attempt to ﬁnd an optimal partition. Hence, the modularity of the
optimal partition can also be viewed as a property of graph topology. Voelkl and Kasper (2009) compared optimal modularity values
to ﬁxation probability (, determined by simulation) using linear
regression. This led them to the conclusion that 60% of the variance
in ﬁxation probability can be accounted for by the modularity of the
graph. An interesting direction for future work would be a more
detailed examination on the relationship between  and optimal
modularity based on a wider variety of graphs.
6.4. Graph heterogeneity and evolution of cooperation
Santos et al. (2006) investigated the effects of single-scale
and scale-free networks on cooperation in the Prisoner’s Dillema,
Snow-Drift, and Stag-Hunt games through simulations. The update
rule used is a type of imitation dynamic in which all vertices update
simultaneously in each generation, as follows: for each vertex a random neighbor is chosen, and if that neighbor has achieved a higher
payoff, the vertex adopts the strategy of this neighbor with a probability proportional to the payoff difference. The authors ﬁnd that
in degree-heterogeneous graphs cooperation is easier to sustain
than in well-mixed populations and thus identify heterogeneity as
a “powerful mechanism for the emergence of cooperation.” Additionally, the authors ﬁnd that the sustainability of cooperation also
depends on “detailed and intricate ties” between agents. As evidence of this, scale free networks which exhibit properties like
those that emerge from models of growth from preferential attachment (Albert–Barbarasi topology) are shown to produce higher
cooperation than random scale-free networks.
Fu et al. (2009) devised a framework for the general study of
games on arbitrary graphs under weak selection, formulating the
game dynamics as a discrete Markov process. Using DB updating
and the game of the Prisoner’s Dilemma, they employ their method
on random regular graphs and scale-free networks to demonstrate
the utility of their framework compared to pair-approximation and
simulated data. The authors ﬁnd a stronger correlation between
their approach and the simulated results. They also reach some conclusions on the evolution of cooperation, most notably that under
DB updating and weak selection, degree heterogeneous graphs
(e.g. scale-free networks) generally impose higher invasion barriers than regular graphs. This extends a result of Antal et al. (2006)
who reported that a heterogeneous graph is an inhospitable environment for a mutant to evolve in the case of constant selection.
Fu et al. show this to be true for weak selection as well. This result
seems to be in disagreement with the conclusion of Santos et al.
(2006), which concludes that graph heterogeneity aids the emergence of cooperation. Fu et al. point out that this conclusion by
Santos et al. (2006) hinges on the simultaneous appearance of a
number of cooperators to overcome the invasion barrier.
6.5. Direct reciprocity on regular graphs
Ohtsuki and Nowak (2007) studied reciprocity in the iterated
Prisoner’s Dilemma (exhibited by strategies such as Tit-for-Tat)

on large, regular graphs through pair approximation for the four
update rules BD, DB, IM, and PC under weak selection. The game
concerned is again that of payoff matrix (54), but translating the
payoffs in the matrix to a repeated game with q probability of playing another iteration and assuming a game between reciprocators
playing Tit-for-Tat and Defectors All-D gives the following payoffs:

cooperate
cooperate (b − c)/(1 − q)
b
defect

defect
-c
0

(55)

The authors are particularly concerned with evolutionary stability and “advantageousness” of reciprocators and ﬁnd that different
update rules have a critical effect on these measures. A strategy is
termed “advantageous” if a single mutant following the strategy
starting in a random position on the graph has a ﬁxation probability greater than the inverse of the population size, meaning that
selection favors it over residents. The authors ﬁnd that the ratio b/c
necessary for a cooperator to be advantageous depends only on the
probability to play another round in the repeated game (q) and the
number of neighbors per individual (k). BD and PC produce identical results, showing evolutionary stability to be harder to achieve
for cooperators on graphs compared to well-mixed populations, but
it is easier for cooperation to be advantageous. In contrast, DB and
IM updating make it easier for cooperation to be both evolutionarily
stable and advantageous. In particular, for DB and IM either small k
or large q are sufﬁcient for the evolution of cooperation.
6.6. Separate interaction and replacement graphs
Ohtsuki et al. (2007) examined the evolution of cooperation in
games on regular graphs – again with payoff matrix (54). However,
unlike other work, the graph for the interactions between players in
the game (interaction graph H), and the graph among the relationships of who can replace whom (replacement graph G) are separate.
The authors consider the case of weak selection, where w 	 1. The
authors use BD, DB, and IM updating. The authors consider regular graphs and again use pair approximation for their analysis of
ﬁxation probabilities. For DB updating, the authors ﬁnd the following result, which is veriﬁed through experiments: if c and b are
the cost and beneﬁt associated with the game,  is the degree of
overlap between G and H, and g and h are the degrees of G and H,
then the following inequality holds under death–birth updating:
b/c> hg/. Hence, the authors conclude that, for ﬁxed cost and beneﬁt values, cooperation is less likely to evolve if there is a greater
disparity between the interaction and replacement graph, cooperation is maximized when G and H coincide. IM updating leads to
b/c> h(g + 2)/, while BD, as has been shown before, never gives an
evolutionary advantage to cooperators.
6.7. Further work for game theoretic extensions
A main area for future work is the extension of any of the results
as described in this section to games with more than two competing
strategies on graphs, as well as for multi-player (>2) games:
Open Problem 6.4. Extend results on evolutionary games on
graphs to populations with more than two competing strategies
and multi-player games.
However, there are still a signiﬁcant amount of issues to explored
in two-player games. As noted in Nowak et al. (2010) the beneﬁtcost payoff matrix (54) used in a number of works described is only
a simpliﬁed version of the general Prisoner’s Dilemma game that
has been so important in the study of the evolution of cooperation.
Extending results to the general game seems to be of considerable
importance to the study of the evolution of cooperation on graphs:

P. Shakarian et al. / BioSystems 107 (2012) 66–80

77

Open Problem 6.5. Extend results that used the beneﬁt-cost payoff matrix (54) version of the Prisoner’s Dilemma to the general
Prisoner’s Dilemma game payoff matrix.
In reviewing work on games in EGT, we have noted and important difference in ﬁtness assignment used by different researchers,
the effects of which are unclear: While some works have used the
average payoff of games on graphs in their ﬁtness computation and
resulting analysis (e.g. Broom et al., 2010a) others use the total
accumulated payoff of games (e.g. Ohtsuki et al., 2006; Santos et al.,
2006). There is an important distinction between these on heterogeneous graphs: the former excludes the effect of playing a different
amount of games due to different amounts of neighbors, while the
latter does not. It is important to be aware of this difference and
it is of high interest to the community to explore to what extent
analytical and experimental results are affected by this difference.
Open Problem 6.6. Explore and understand the effects of using
the average vs. accumulated payoff from games played with neighbors for ﬁtness in evolutionary games on graphs.
On the analysis of reciprocity, while Ohtsuki and Nowak (2007)
have considered direct reciprocity in their analyses for regular
graphs, as noted by Nowak et al. (2010), much more work is
needed to work direct and indirect reciprocity into the mathematical frameworks presented by different authors (or a general one)
encompassing various update rules and more complex population
structures:
Open Problem 6.7. Incorporate direct and indirect reciprocity
into a general mathematical framework for evolutionary games on
graphs.
Concerning punishment and reputation, past work on spatial
evolutionary games (e.g. Brandt et al., 2003), where the population
is structured on a simple grid, has explored the effects of punishment and reputation on the evolution of cooperation. However, the
exploration of these mechanisms on general and complex population structures has not yet been explored:
Open Problem 6.8. Using EGT to explore the effects of punishment and reputation on the evolution of cooperation under the
constraints of general, more complex, population structures.
Generally, we feel there exists a need to incorporate EGT
into more evolutionary game theory applications: many existing applications of evolutionary game theory, particularly those
in anthropology, economics, and social modeling and prediction
could possibly greatly from EGT by using it to account for effects of
population structure.
Open Problem 6.9. Incorporate known or estimated population
structures into more existing evolutionary game theoretic applications.
7. Other extensions to the model
There are several other notable extensions to the original model
of Lieberman et al. (2005) worth noting. These include scenarios with bi-level graphs, multiple mutants, EGs whose topology
changes over time, and other modiﬁcations.
7.1. Bi-level evolutionary graphs
Nie (2008) introduced bi-level EGs. In general, a bi-level EG is
deﬁned as follows: ﬁrst, there is an EG representing relationships
between communities – with the vertices in this graph representing communities. The work on bi-level EGs often denote the
community-level EG as graph B. Each of the m vertices of B is itself
an EG of individuals – vertex vi on graph B is EG Ai . This type of EG

Fig. 2. A bi-level EG where the leaders (set A) form an isothermal EG. When they
are collapsed into a single vertex, we have a one-rooted EG.

has been shown to help describe several biological phenomena. In
the bi-level EGs of Nie (2008) and Zhang et al. (2007), one of the
vertices in graph B is an isothermal EG consisting of n individuals
(‘leaders’). The remaining m − 1 vertices in graph B represent single
individuals (‘followers’). Hence, for the entire graph, N = n + m − 1.
As only one vertex in graph B represents an EG, these works use A
to refer to the EG consisting of the n leaders. As the structure of A
and B are independent, we have the following relationship:
(AB) = (A) · (B)

(56)

where (AB) is the ﬁxation probability of the entire bi-level EG, and
(A), (B) are the ﬁxation probabilities of EGs A and B respectively.
In Nie (2008), graph B is a star formation (K = 2, M = 1), with the central vertex being equivalent to EG A. The author shows that for r =
/ 1
this bi-level graph suppresses ﬁxation more than an isothermal
graph, thus helping to explain the evolutionary stability of bi-level
structures found in nature. Zhang et al. (2007) studied a bi-level EG
where B is one-rooted and A is equivalent to the root-vertex of B
(see Fig. 2). The one-rooted case reﬂects hierarchical population
structures. The authors show that when the number of followers is identical, that a bi-level EG has a lower ﬁxation probability
than a one-rooted EG. They also show that the ﬁxation probability
increases when the number of leaders increase (making a bi-level
EG of this type with 2 leaders the most stable bi-level EG). They also
show that an increase in number of followers decreases ﬁxation
probability and that ﬁxation probability for a bi-level EG is closely
tied to ﬁtness. The authors apply these theoretical results to biology
to help explain why structure occurs in some animal populations.
Examples of this include symbiosis (such as the growth of Lichens)
and commensalism (i.e. the relationship between clownﬁsh and sea
anemone).
The work on bi-level EGs is extended by Zhang et al. (2010)
where the authors considered bi-level EGs where the mutant has
a different ﬁtness depending on the level of the graph. The model
is described as follows. In this work, each vertex of B is associated
with an EG. Hence, vertices v1 , . . . , vi , . . . , vm in EG B are associated
with EGs A1 , . . ., Ai , . . ., Am . Each of these groups has ni individuals
and adjacency matrix Wi (B has adjacency matrix W0 ). The ﬁxation probability of a mutant with ﬁtness r taking over one of these
groups is (Wi , ni , r). For graph B, the ﬁtness of the mutant is r0 and
the ﬁxation probability for B is written (W0 , m, r0 ). The authors
study the case where the levels of the graph and r, r0 are independent. For the overall bi-level EG, the authors obtain the following
ﬁxation probability (denoted (W, n, m, r, r0 ) where W = {W0 , . . .,
Wm }).

m

(W, n, m, r, r0 ) =

n
i=1 i

· (Wi , ni , r)

m

n
i=1 i

· (W0 , m, r0 )

(57)

What if the ﬁtness of one level of the population is dependent
on the other? Regretfully, this has not been address with the current work on bi-level evolutionary graphs and provides us with the
following open problem.

78

P. Shakarian et al. / BioSystems 107 (2012) 66–80

Open Problem 7.10. Computing the ﬁxation probability for a bilevel EG when r, r0 are not independent (Zhang et al., 2010, assumes
independence).
Further, we also note that the stochastic evolutionary process on
a bi-level graph takes place on the entire graph (i.e. graphs A and B
at the same time scale). Essentially, a bi-level EG is a special case of
an evolutionary graph as deﬁned by Lieberman et al. (2005). What
happens when the two levels of the graph evolve at different time
scales? To study this, we would most likely view the stochastic
process on the two graph structures – A and B separately. Such
an addition would seem to add another layer of complexity to the
problem. Additionally, game theoretic extensions to bi-level graphs
have also not yet been considered. This would also likely go handin-hand with studying the ﬁxation probability of bi-level graphs
under different model dynamics.
It turns out that the earlier model of Maruyama (1974) is also an
evolutionary graph. In that model, there are m islands whose relationship is speciﬁed in graph B. This speciﬁes the migration pattern
between islands. Each island has n individuals in a well mixed population (i.e. n = n1 = n2 = · · · = nm and each Ai is a complete, undirected
graph). Maruyama (1974) used birth–death updating and assumed
that progeny in an island descend only from local individuals. The
recent work of Houchmandzadeh and Vallade (2011) explores this
model without this assumption and under both birth–death and
death–birth dynamics. It is interesting to note that their model is
both a generalization and a special case of the original model of
Lieberman et al. (2005). As this model speciﬁes a particular bilevel graph, it is a special case. However, by setting n = 1 we can
encode an arbitrary evolutionary graph. Adopting the technique
of Houchmandzadeh and Vallade (2010) for well-mixed populations, (see Section 3.3) the authors develop an approximation
technique for ﬁxation probability under this model. For r > 1, they
show that the approximation is valid when n · m · (r − 1) is approximately greater than 1. However, it is unclear how this approach
can scale, particularly as m increases – all of the experiments in
Houchmandzadeh and Vallade (2011) had m ≤ 5 (the experiments
where the approximation performed the best had n = 50). Not only
is the scalability of this approach an area for future work, but also
the issue of the topology of the Ai graphs as well. Can the same
approach be used for an arbitrary bi-level graph?
Zhang et al. (2010) described several anecdotal applications of
bi-level EGs. or example, describe several species whose populations resemble a non-hierarchical bi-level EG where both upper
and lower level structures are isothermal including the budgerigar of Oceania and the aptenodytes fosteri (emperor penguins) of
Antarctica. However, Zhou (2011) took a step further toward a realworld application by using bi-level EGs and star EGs to examine
the stability of various types of business forms. Speciﬁcally, they
look at corporations with individual decisions (CIDs), multi-person
decision corporations (MDCs), and stock corporations (SCs). They
model CIDs as 1-level star graphs and MDCs and SCs are modeled
as bi-level graphs. They ﬁnd that, under reasonable conditions,
MDCs have a higher ﬁxation probability than CIDs, which have a
higher ﬁxation probability than SCs. Hence, by through the lens
of EGT, SCs represent the most stable organizational structure for
business.
7.2. Multiple mutants
Paley et al. (2010) discussed the issue of clonal interference where
two different lineages in a population compete with each other. In
such a case, multiple mutations exist in a population. Hence, the
authors of this work extend the model of Lieberman et al. (2005) to
allow for this case. These mutants are referred to as type-1 and type2 mutants. The authors are primarily concerned with determining

the ﬁxation probability of the type-2 mutants. The authors view the
population of individuals as two disjoint sets. The ﬁrst set deﬁned
by the authors is the set of type-1 mutants which is referred to as
the resident mutant population (RMP). The authors use m1 to denote
the cardinality of this set. The second set is the set of residents in
the population which are referred to as the wild type population
(WTP). There are N − m1 individuals in this set. To obtain the ﬁxation probability of the type-2 mutant ((2) ), the authors consider the
ﬁxation probability of the type-2 mutants within the WTP and RMP
populations. As the probability that a type-2 mutant occurs in the
WTP and RMP populations are (N − m1 )/N, m1 /N respectively, the
authors derive the following equation for the ﬁxation probability
of the type-2 mutant:
(2)

(2) =

(N − m1 ) · WTP
N

(2)

+

m1 · RMP

(58)

N

(2)

where WTP is the ﬁxation probability of a type-2 mutant in the
(2)

WTP and RMP is the ﬁxation probability of the type-2 mutant in
the RMP. The authors come up with analytical approximations of
ﬁxation probabilities for the type-2 mutants in the cases of lines
and fully connected graphs. These approximations work well in
the cases where m1 > > 1 and r is high. For a lines, they obtain

m1 · (1−1/r)
(N−m1 )2
+
· (1 − 1/r) and for a fully connected graph they
N
2 · N2
N−m1
m
N+(r−1)m1
1
obtain N · m +1 + N1 · 1 −
. The authors perform
Nr 2
1

	




simulation experiments that aligned well with these analytical
results. Hence, they were able to demonstrate that topology and the
population of the type-1 mutants ﬁgures signiﬁcantly into ﬁxation
probability calculations in real populations.
7.3. EGs that change over time
Barbosa et al. (2009) modiﬁed the original formulation of
Lieberman et al. (2005) by examining a simple class of graphs
that change over time (Barbosa et al., 2009). Speciﬁcally, they look
at layered networks. They ﬁnd, through experimental simulation,
that their growth structure also substantially increases the ﬁxation
probability. In future work, the authors intend to explore a more
general framework for dynamic graphs.
Broom et al. (2011) conjectured results for undirected graphs
that change over time for BD-B. They conjecture that existing BD-B
results still hold if the graph changes more slowly than it evolves.
They also suspect that even if the graph does not change slowly,
that existing BD-B results will still provide ‘good’ estimates.
Overall, studying ﬁxation probability on a graph whose topology
changes over time is an area ripe for new research. For example, preferential attachment has been observed in graph-structured
with evolving topologies and essentially states that vertices of
high degree are more likely to increase their connections as time
progresses (Jeong et al., 2003). Now consider birth–death updating, where the results described in the previous sections show
that ﬁxation probability is inversely proportional to its degree.
So, under preferential attachment with birth–death updating, do
new mutant vertices whose degree increases end up suppressing evolution as they connect to more residents? How do the
time scales of the topology evolution with the evolution of the
mutant trait affect each other? Further, would alternate methods of graph evolution, such as the biologically inspired models
of Southwell and Cannings (2010) affect ﬁxation (i.e. as compared
to preferential attachment)?
7.4. Further extensions
Paley et al. (2007) examined the model of Lieberman et al. (2005)
under birth–death updating on graphs where vertex connectivity

P. Shakarian et al. / BioSystems 107 (2012) 66–80

is ﬁxed – speciﬁcally lines, square lattices, cubic lattices, and fully
connected graphs. They then extend the model to allow offspring
to not be perfect clones of their parents. Further, in their model,
the offspring of a parent subject to a mutation with a probability of
 and increase the ﬁtness with a probability p, or decrease it with
probability 1 − p. The calculation of the new ﬁtness for the offspring
is based on a previously studied model. They examined their asexual model experimentally on graphs with 250, 000 vertices and the
results showed that the equilibrium ﬁtness of the population was
correlated with the dimensionality of the lattice – speciﬁcally that
more connected graphs had a higher level of equilibrium ﬁtness. No
saturation was observed for the fully connected graph in this case.
The authors also examined a modiﬁcation to the model allowing
for sexual reproduction with multiple genes per vertex. For sexual
reproduction, the equilibrium ﬁtness increased not only with the
dimension of the lattice, but also with the population.
Zhang and Nie (2009) studied EGT in the case where the ﬁtness
of the mutant changes with its frequency. For example, the ﬁtness
of cancer cells changes with frequency which often causes a failure
in therapy. Given a population of size N, they assume N different
values of r – each associated with a different number of mutants
in the population. They assume r1 ≤ r2 ≤ · · · ≤ rN and obtain analytical approximation for the ﬁxation probabilities of super-stars and
isothermal EGs.
Whigham and Dick (2008) considered a ‘local’ version of the
Moran Process where the update rules are dependent upon a deme.
In this work, a deme (indexed the same way as the vertices in v)
corresponds to the neighborhood of a given vertex. In this case,
Whigham and Dick (2008) adds the requirement that for each vertex vi , wii > 0 (note that this type of self-loop is not permitted in
the original mode of Lieberman et al., 2005). At each step, a row
Wi of the matrix is chosen with a probability 1/N. Next, a vertex vj
is selected s proportional to the ﬁtness of all vertices in the deme.
Finally, the vertex to be replaced is selected based on the outgoing
edge weights of vj . The authors experiment with this process on star
and Kawachi-style small world networks to ﬁnd that this process
achieves the Moran probability for ﬁxation.
8. Conclusion
In this paper we have described evolutionary graph theory, which
was ﬁrst introduced by Lieberman et al. (2005) and generalizes the
classic Moran Process of Moran (1958). We have described the original model, the major results and extensions, and applications to
game theory. While this is still a relatively new tool for ﬁelds such
as biology, physics, game theory, and computer science, the number of publications on the topic seems to be steadily increasing each
year – hence resulting in this review. Our view is that there is great
potential with EGT for a variety of applications, and that represents
the next wave of research in this area. Applied work such as Zhou
(2011) for economics and Voelkl and Kasper (2009) in biology most
likely represent just the beginning of a new trend. However as EGT
becomes more operational, many new questions arise. First, how
can the model be adjusted for certain applications? Second, can we
learn the model and/or mutant ﬁtness from historical data? Third,
many real-world applications utilize large data sets, for example,
a data set LiveJournal social network data set consists of over 4
million vertices and over 6 million edges.5 Can procedures for calculating ﬁxation probability and time to ﬁxation be scaled for these
large data-sets? There are multiple directions in which EGT can be
taken. We are very excited about the possibilities due to the large
problem-space.

5

http://snap.stanford.edu/data/index.html.

79

Acknowledgements
We would all like to thank the anonymous reviewers for their
comments that helped improve the paper.
P.S. and A.J. are supported by ARO grant 611102B74F as well as
the Ofﬁce of the Secretary of Defense (OSD).
P.R. is supported by AFOSR grant FA95500610405 and NAVAIR
contract N6133906C0149. The opinions in this paper are those of
the authors and do not necessarily reﬂect the opinions of the funders.
P.S. would like to thank Prof. Jan Rychtář from the University of
North Carolina at Greensboro for his personal correspondence in
response to questions about his work.

References
Antal, T., Redner, S., Sood, V., 2006. Evolutionary dynamics on degreeheterogeneous graphs. Physical Review Letters 96 (18), 188104,
http://link.aps.org/abstract/PRL/v96/e188104.
Antal, T., Scheuring, I., 2006. Fixation of strategies for an evolutionary game
in ﬁnite populations. Bulletin of Mathematical Biology 68, 1923–1944,
doi:10.1007/s11538-006-9061-4.
Barbosa, V.C., Donangelo, R., Souza, S.R., 2009. Network growth for enhanced natural
selection. Physical Review E (Statistical, Nonlinear, and Soft Matter Physics) 80
(2), 026115, http://link.aps.org/abstract/PRE/v80/e026115.
Barbosa, V.C., Donangelo, R., Souza, S.R., 2010. Early appraisal of the ﬁxation probability in directed networks. Physical Review E 82 (October (4)), 046114.
Blondel, V., Guillaume, J., Lambiotte, R., Lefebvre, E., 2008. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment
2008, P10008.
Brandt, H., Hauert, C., Sigmund, K., 2003. Punishment and reputation in spatial public
goods games. Proceedings of the Royal Society of London, Series B: Biological
Sciences 270 (1519), 1099.
Broom, M., Hadjichrysanthou, C., Rychtar, J., 2010a. Evolutionary games on graphs
and the speed of the evolutionary process. Proceedings of the Royal Society A
466, 1327–1346.
Broom, M., Hadjichrysanthou, C., Rychtar, J., Stadler, B.T., 2010. Two results on evolutionary processes on general non-directed graphs. Proceedings of the Royal
Society A: Mathematical, Physical and Engineering Sciences 466 (April (2121)),
2795–2798, http://rspa.royalsocietypublishing.org.
Broom, M., Rychtář, J., 2008. An analysis of the ﬁxation probability of a mutant on
special classes of non-directed graphs. Proceedings of the Royal Society A 464
(May), 2609–2627.
Broom, M., Rychtaı̌r, J., Stadler, B., 2011. Evolutionary dynamics on graphs - the
effect of graph structure and initial placement on mutant spread. The Journal of
Statistical Theory and Practice 5 (3), 369–381.
Broom, M., Rychtář, J., Stadler, B., 2009. Evolutionary dynamics on small-order
graphs. Journal of Interdisciplinary Mathematics 12 (2), 129–140.
Fu, F., Wang, L., Nowak, M.A., Hauert, C., 2009. Evolutionary dynamics on graphs:
efﬁcient method for weak selection. Physical Review E 79 (April (4)).
Garey, M.R., Johnson, D.S., 1979. Computers and Intractability; A Guide to the Theory
of NP-Completeness. W.H. Freeman & Co., New York, NY, USA.
Hadjichrysanthou, C., Broom, M., Rychtar, J., 2011. Evolutionary games on star graphs
under various updating rules. Dynamic Games and Applications, 1–22.
Hamilton, W., 1964. The genetical evolution of social behaviour. II. Journal of Theoretical Biology 7 (1), 17–52.
Haraguchi, Y., Sasaki, A., 2000. The evolution of parasite virulence and transmission
rate in a spatially structured population. Journal of Theoretical Biology 203 (2),
85–96.
Hauert, C., Doebeli, M., 2004. Spatial structure often inhibits the evolution of
cooperation in the snowdrift game. Nature 428 (April (6983)), 643–646,
http://dx.doi.org/10.1038/nature02360.
Houchmandzadeh, B., Vallade, M., 2010. Alternative to the diffusion equation in population genetics. Physical Review E 82 (November), 051913,
http://link.aps.org/doi/10.1103/PhysRevE.82.051913.
Houchmandzadeh, B., Vallade, M., 2011. The ﬁxation probability of a beneﬁcial mutation in a geographically structured population. New Journal of Physics 13 (July
(7)), 073020, http://stacks.iop.org/1367-2630/13/i=7/a=073020.
Jeong, H., Neda, Z., Barabasi, A.L., 2003. Measuring preferential attachment in evolving networks. EPL (Europhysics Letters) 61 (4), 567, http://stacks.iop.org/02955075/61/i=4/a=567.
Keeling, M., 1999. The effects of local spatial structure on epidemiological invasions.
Proceedings of the Royal Society of London Series B: Biological Sciences 266
(1421), 859–867.
Lieberman, E., Hauert, C., Nowak, M.A., 2005. Evolutionary dynamics on graphs.
Nature 433 (7023), 312–316, http://dx.doi.org/10.1038/nature03204.
Maruyama, T., 1974. A simple proof that certain quantities are independent of the geographical structure of population. Theoretical Population
Biology 5 (2), 148–154, http://www.sciencedirect.com/science/article/pii/
0040580974900379.

80

P. Shakarian et al. / BioSystems 107 (2012) 66–80

Masuda, N., 2009. Directionality of contact networks suppresses selection pressure
in evolutionary dynamics. Journal of Theoretical Biology 258 (2), 323–334.
Masuda, N., Ohtsuki, H., 2009. Evolutionary dynamics and ﬁxation probabilities in
directed networks. New Journal of Physics 11, 033012.
Matsuda, H., Ogita, N., Sasaki, A., Sato, K., 1992. Statistical mechanics of population.
Progress of Theoretical Physics 88 (6), 1035–1049.
Matsuda, H., Tamachi, N., Sasaki, A., Ogita, N., 1987. A lattice model for population biology. In: Teramot, E., Yamaguti, M. (Eds.), Mathematical Topics in
Biology, Morphogenesis and Neuro-sciences. Vol. 71 of Springer Lecture Notes
in Biomathematics. , pp. 154–161.
Moran, P., 1958. Random processes in genetics. Mathematical Proceedings of the
Cambridge Philosophical Society 54 (01), 60–71.
Newman, M.E.J., 2004. Fast algorithm for detecting community structure in networks. Physical Review E 69 (June (6)), 066133.
Newman, M.E.J., Girvan, M., 2004. Finding and evaluating community structure in
networks. Physical Review E 69 (February (2)), 026113.
Nie, P.Y., 2008. Evolutionary graphs on two levels. Ars Combinatoria 86.
Nie, P.-Y., Zhang, P.-A., 2010. Fixation time for evolutionary graphs. International
Journal of Modern Physics B 24, 5285–5293.
Nowak, M., May, R., 1992. Evolutionary games and spatial chaos. Nature 359 (6398),
826–829.
Nowak, M., Tarnita, C., Antal, T., 2010. Evolutionary dynamics in structured populations. Philosophical Transactions of the Royal Society B: Biological Sciences 365
(1537), 19.
Ohtsuki, H., Hauert, C., Lieberman, E., Nowak, M.A., 2006. A simple rule for the evolution of cooperation on graphs and social networks. Nature 441 (May (7092)),
502–505, http://dx.doi.org/10.1038/nature04605.
Ohtsuki, H., Nowak, M., 2007. Direct reciprocity on graphs. Journal of Theoretical
Biology 247, 462–470.
Ohtsuki, H., Nowak, M.A., 2006. The replicator equation on graphs. Journal of Theoretical Biology 243 (November (7)), 86–97, http://dx.doi.org/
10.1016/j.jtbi.2006.06.004.
Ohtsuki, H., Pacheco, J., Nowak, M., 2007. Evolutionary graph theory: breaking the
symmetry between interaction and replacement. Journal of Theoretical Biology
246, 681–694.
Ohtsukia, H., Nowak, M., 2008. Evolutionary stability on graphs. Journal of Theoretical Biology 251, 698–707.
Paley, C., Taraskin, S., Elliott, S., 2010. The two-mutant problem: clonal interference in evolutionary graph theory. Journal of Chemical Biology 3, 189–194,
doi:10.1007/s12154-010-0042-6.
Paley, C.J., Taraskin, S.N., Elliott, S.R., 2007. Temporal and dimensional
effects in evolutionary graph theory. Physical Review Letters 98, 098103,
doi:10.1103/PhysRevLett.98.098103.

Rychtář, J., Stadler, B., 2008. Evolutionary dynamics on small-world networks. International Journal of Computational and Mathematical Sciences 2 (Winter (1)).
Santos, F.C., Pacheco, J.M., Lenaerts, T., 2006. Evolutionary dynamics of social
dilemmas in structured heterogeneous populations. PNAS 103 (February (9)),
3490–3494, http://dx.doi.org/10.1073/pnas.0508201103.
Shakarian, P., Roos, P. Fast and deterministic computation of ﬁxation probability in
evolutionary graphs. In: CIB’11: The Sixth IASTED Conference on Computational
Intelligence and Bioinformatics. IASTED, in press.
Slatkin, M., 1981. Fixation probabilities and ﬁxation times in a subdivided population. Evolution 35 (May (3)), 477–488.
Sood, V., Antal, T., Redner, S., 2008. Voter models on heterogeneous networks. Physical Review E (Statistical, Nonlinear, and Soft Matter Physics) 77 (4), 041121,
http://link.aps.org/abstract/PRE/v77/e041121.
Southwell, R., Cannings, C., 2010. Some models of reproducing graphs. I. Pure reproduction. Applied Mathematics 1 (3), 137–145.
Tarnita, C., Ohtsuki, H., Antal, T., Fu, F., Nowak, M., 2009. Strategy selection in structured populations. Journal of Theoretical Biology 259, 570–581.
Torán, J., 2004. On the hardness of graph isomorphism. SIAM Journal on Computing
May (33), 1093–1108.
Van Baalen, M., 2000. Pair approximation for different spatial geometries.
In: Dieckmann, U., Law, R., Metz, J.A.J. (Eds.), The Geometry of Ecological Interactions: Simplifying Spatial Complexity. Cambridge University Press,
pp. 359–387.
Voelkl, B., Kasper, C., 2009. Social structure of primate interaction networks facilitates the emergence of cooperation. Biology Letters 5, 462–464.
Whigham, P.A., Dick, G., 2008. Evolutionary dynamics for the spatial Moran Process.
Genetic Programming and Evolvable Machines 9 (2), 157–170.
Yang, Dong-Ping, Lin, Hai, Wu, Chen-Xu, Shuai, Jian-Wei, 2009. Modelling Moran
Process with network dynamics for the evolution of cooperation. Chinese
Physics Letters 26 (6).
Zhang, P., Nie, P., 2009. Evolutionary graphs with frequency dependent ﬁtness. International Journal of Modern Physics B 23 (4), 537–543.
Zhang, P.A., Nie, P.Y., Hu, D.Q., Zou, F.Y., 2007. The analysis of bi-level evolutionary
graphs. Biosystems 90 (3), 897–902.
Zhang, P., Nie, P., Hu, D., 2010. Bi-level evolutionary graphs with multi-ﬁtness. Systems Biology, IET 4 (1), 33–38.
Zhong, W., Zhang, Y., Liu, J., 2011. Evolutionary dynamics of continuous strategy
games on social networks under weak selection: a preliminary study. In: IEEE
Congress on Evolutionary Computation (CEC), June, pp. 2514–2518.
Zhou, A.-n., 2011. Stability analysis for various business forms. In: Zhou, Q.
(Ed.), Applied Economics, Business and Development. Vol. 208 of Communications in Computer and Information Science. Springer, Berlin, Heidelberg,
pp. 1–7.

Adversarial Geospatial Abduction Problems
PAULO SHAKARIAN, United States Military Academy
JOHN P. DICKERSON and V. S. SUBRAHMANIAN, University of Maryland

Geospatial Abduction Problems (GAPs) involve the inference of a set of locations that “best explain” a given
set of locations of observations. For example, the observations might include locations where a serial killer
committed murders or where insurgents carried out Improvised Explosive Device (IED) attacks. In both
these cases, we would like to infer a set of locations that explain the observations, for example, the set of locations where the serial killer lives/works, and the set of locations where insurgents locate weapons caches.
However, unlike all past work on abduction, there is a strong adversarial component to this; an adversary
actively attempts to prevent us from discovering such locations. We formalize such abduction problems as
a two-player game where both players (an “agent” and an “adversary”) use a probabilistic model of their
opponent (i.e., a mixed strategy). There is asymmetry as the adversary can choose both the locations of the
observations and the locations of the explanation, while the agent (i.e., us) tries to discover these. In this article, we study the problem from the point of view of both players. We define reward functions axiomatically
to capture the similarity between two sets of explanations (one corresponding to the locations chosen by the
adversary, one guessed by the agent). Many different reward functions can satisfy our axioms. We then formalize the Optimal Adversary Strategy (OAS) problem and the Maximal Counter-Adversary strategy (MCA)
and show that both are NP-hard, that their associated counting complexity problems are #P-hard, and that
MCA has no fully polynomial approximation scheme unless P=NP. We show that approximation guarantees
are possible for MCA when the reward function satisfies two simple properties (zero-starting and monotonicity) which many natural reward functions satisfy. We develop a mixed integer linear programming
algorithm to solve OAS and two algorithms to (approximately) compute MCA; the algorithms yield different
approximation guarantees and one algorithm assumes a monotonic reward function. Our experiments use
real data about IED attacks over a 21-month period in Baghdad. We are able to show that both the MCA
algorithms work well in practice; while MCA-GREEDY-MONO is both highly accurate and slightly faster
than MCA-LS, MCA-LS (to our surprise) always completely and correctly maximized the expected benefit to
the agent while running in an acceptable time period.
Categories and Subject Descriptors: I.2.3 [Artificial Intelligence]: Deduction and Theorem Proving—
Nonmonotonic reasoning and belief revision; I.2.3 [Artificial Intelligence]: Problem Solving, Control
Methods, and Search—Heuristic methods; I.2.1 [Artificial Intelligence]: Applications and Expert
Systems—Cartography
General Terms: Algorithms, Experimentation, Theory
Additional Key Words and Phrases: Abduction, spatial reasoning

Some of the authors of this article were funded in part by AFOSR grant FA95500610405 and ARO grants
W911NF0910206 and W911NF0910525.
Authors’ addresses: P. Shakarian (corresponding author), United States Military Academy, West Point,
NY 10996; email: Paulo@shakarian.net; J. P. Dickerson and V. S. Subrahmanian, University of Maryland,
College Park, MD 20742.
c
2012
Association for Computing Machinery. ACM acknowledges that this contribution was authored or
co-authored by a contractor or affiliate of the [U.S.] Government. As such, the Government retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for Government
purposes only.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for profit or commercial advantage and that
copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights
for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of
this work in other works requires prior specific permission and/or a fee. Permissions may be requested from
the Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, USA, fax +1 (212)
869-0481, or permissions@acm.org.
c 2012 ACM 2157-6904/2012/02-ART34 $10.00

DOI 10.1145/2089094.2089110 http://doi.acm.org/10.1145/2089094.2089110

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34

34:2

P. Shakarian et al.

ACM Reference Format:
Shakarian, P., Dickerson, J. P., and Subrahmanian, V. S. 2012. Adversarial geospatial abduction problems.
ACM Trans. Intell. Syst. Technol. 3, 2, Article 34 (February 2012), 35 pages.
DOI = 10.1145/2089094.2089110 http://doi.acm.org/10.1145/2089094.2089110

1. INTRODUCTION

Geospatial Abduction Problems (GAPs) were introduced by Shakarian et al. [2010] to
find a set of locations that “best explain” a given set of locations of observations. We
call these inferred sets of locations “explanations.” There are many such applications
in a wide variety of domains.
— In criminology, serial killers carry out murders at various locations; these correspond to the observations we make. The goal of the police is to identify a set of
locations that best “explain” the observations. Thus, the police look for the killer’s
home and office locations. The killer, of course, goes to considerable effort usually to
ensure that he cannot be easily found by the police.
— In military applications, insurgents (such as those in Iraq and Afghanistan) carry
out Improvised Explosive Device (IED) attacks at various locations; these corresponding to our observations. Multinational forces operating in these countries
would like to identify many locations associated with these attack locations; one
such class of locations corresponds to the locations of weapons caches that provide
logistics support for the attacks and enable the attackers to carry them out. As in
the case of the serial killer, the insurgents reason carefully about their choice of
weapons cache locations to minimize the probability of being detected.
— In a wildlife application, a rare animal or bird might be spotted at several locations
(observations). We would like to infer the location of the creature’s nest or den.
Many animals take considerable care to keep their den/nest hidden as these often
hold young ones or eggs and, in some cases, food.
Shakarian et al. [2010] defined Geospatial Abduction Problems (GAPs) and studied
a version of the problem where the adversary (the “bad guy” or the entity that wishes
to evade detection) does not reason about the agent (the “good guy” or the entity that
wants to detect the adversary). Despite this significant omission, they were able to accurately predict the locations of weapons caches in real-world data about IED attacks
in Baghdad. In this article, we introduce adversarial geospatial abduction problems
where both the agent and the adversary reason about each other. Specifically, our
contributions are as follows.
(1) We axiomatically define reward functions to be any functions that satisfy certain
basic axioms about the similarity between an explanation chosen by the adversary
(e.g., where the serial killer lives and works or where the insurgents put their IED
caches) and define notions of expected detriment (to the adversary) and expected
benefit (to the agent).
(2) We formally define the Optimal Adversary Strategy (OAS) that minimizes chances
of detection of the adversary’s chosen explanation and the Maximal CounterAdversary strategy (MCA) that maximizes the probability that the agent will detect
the adversary’s chosen explanation.
(3) We provide a detailed set of results on the computational complexity of these problems, the counting complexity of these problems, and the possibility of approximation algorithms with approximation guarantees for both OAS and MCA.
(4) We develop Mixed Integer Linear Programming algorithms (MILPs) for OAS and
two algorithms, MCA-LS and MCA-GREEDY-MONO, to solve MCA with certain
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:3

approximation guarantees. MCA-LS has no assumptions, while MCA-GREEDYMONO assumes monotonicity.
(5) We develop a prototype of our MILP algorithms to solve the OAS problem, using
our techniques for variable reduction on top of an integer linear program solver.
We demonstrate the ability to achieve near-optimal solutions as well as a correct
reduction of variables by 99.6% using a real-world dataset.
(6) We develop a prototype implementation that shows that both MCA-LS and MCAGREEDY-MONO are highly accurate and have very reasonable time frames.
Though MCA-GREEDY-MONO is slightly faster than MCA-LS, we found that on
every single run, MCA-LS found the exact optimal benefit even though its theoretical lower-bound approximation ratio is only 1/3. As MCA-LS does not require any
additional assumptions and as its running time is only slightly slower than that of
MCA-GREEDY-MONO, we believe this algorithm has a slight advantage.
The organization of the article is as follows. Section 2 first reviews the GAP
framework of Shakarian et al. [2010]. Section 3 extends GAPs to the adversarial
case using an axiomatically-defined reward function (Section 2). Section 4 presents
complexity results and several exact algorithms using MILPs for the OAS problem.
Section 5 provides complexity results and develops exact and approximate methods
MCA, including an approximation technique that provides the best possible guarantee
unless P = NP. We then briefly describe our prototype implementation and describe a
detailed experimental analysis of our algorithms. Finally, related work is described in
Section 7.
2. OVERVIEW OF GAPS

In this section, we briefly describe the theory of GAPs introduced by Shakarian
et al. [2010]. With the exception of the counting complexity results (Lemma 2.1 and
Theorem 2.1), everything in Section 2 appeared in Shakarian et al. [2010]. Throughout this article, we assume the existence of integers M, N > 0 that jointly define a
2-dimensional gridded space. We use N, R, R+ to respectively denote the sets of natural numbers, all real numbers, and nonnegative reals.
Definition 2.1 (Space). Suppose M, N ∈ N. The space S is the set {1, . . . , M} ×
{1, . . . , N}.
Throughout this article, we assume that M, N, S are arbitrary, but fixed. This representation of the space S as a set of integer coordinates is common in most Geospatial
Information Systems (GIS). We use 2S to denote the power set of S. We assume that S
has an associated distance function d which assigns a nonnegative distance to any two
points and satisfies the usual distance axioms.1
Definition 2.2 (Observation Set). An observation set O is any finite subset of S.
For instance, in our IED application, an observation set is simply the set of locations
where attacks occurred. In the serial killer example, the observation set is the set of
locations where the killings occurred.
Definition 2.3 (Feasibility Predicate). A feasibility predicate is any function feas :
S → {TRUE, FALSE}.
Feasibility predicates encode domain knowledge. For instance, a feasibility predicate
in the IED application might rule out the caches being on U.S. bases or in bodies of
1

d(x, y) ≥ 0; d(x, x) = 0; d(x, y) = d(y, x); d(x, y) + d(y, z) ≥ d(x, z).
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:4

P. Shakarian et al.

water or (in the case of Baghdad where our dataset contains Shiite attacks) Sunni
neighborhoods. Throughout this article, we assume an arbitrary, but fixed function
feas that assigns either true or false to every point in S. In our complexity results, we
assume feas is computable in constant time.
Definition 2.4 ((α, β)-explanation). Given a finite set of observations O and real
numbers α ≥ 0, β > 0, a finite set of points E ⊆ S is an (α, β)-explanation of O iff:
(1) (∀ p ∈ E) feas( p) = TRUE;
(2) (∀o ∈ O)(∃ p ∈ E) α ≤ d( p, o) ≤ β.
Intuitively, E is an (α, β )-explanation of O if every point in E is feasible and every observation in O is neither too close nor too far from a point in E. For a given observation,
o, we will refer to point p as a partner iff feas( p) and d(o, p) ∈ [α, β].
α and β are parameters that can be easily learned from historical data (as was done
in Shakarian et al. [2010]). Both criminologists Rossmo and Rombouts [2008] and
military experts U.S. Army [1994] have noted that partner locations are not too close
to an observation location nor are they too far.2 Note that having α, β actually increases
the generality of our approach as√users can always opt not to use them by setting α = 0
and β to any number exceeding M2 + N2 . Given an integer k > 0, a k-explanation is
an (α, β)-explanation of cardinality k or less. Often we will fix k; in this situation we
will use the terms “k-explanation” and “explanation” interchangeably. Alternatively,
another requirement that can be imposed on an explanation is irredundancy.
Definition 2.5. An explanation E is irredundant iff no strict subset of E is an
explanation.
Intuitively, if we can remove any element from an explanation, and this action causes
it to cease to be a valid explanation, we say the explanation is irredundant.
Example 2.1. Figure 1 shows a map of a drug plantation depicted in a 18 ×
14 grid. The distance between grid squares is 100 meters. Observation set O =
{o 1 , o 2 , o 3 , o 4 , o 5 } represents the center of mass of the poppy fields. Based on an informant or from historical data, drug enforcement officials know that there is a drug
laboratory located 150−320 meters from the center mass of each field (i.e., in a geospatial abduction problem, we can set [α, β] = [150, 320]). Further, based on the terrain,
the drug enforcement officials are able to discount certain areas (shown in black on
Figure 1, a feasibility predicate can easily be set up accordingly). Based on Figure 1,
the set { p40 , p46 } is an explanation. The sets { p42 , p45 , p48 } and { p40 , p45 } are also explanations.
We now formally recall the definition of a GAP from Shakarian et al. [2010].
The k Spatial (α, β) Explanation Problem (k-SEP).
INPUT: Space S, a set O of observations, a feasibility predicate feas, reals numbers
α ≥ 0, β > 0, and natural number k.
OUTPUT: “Yes” if there exists an (α, β) explanation for O of size k, “no” otherwise.
Shakarian et al. [2010] shows this problem to be NP-complete based on a reduction
from the known NP-complete problem Geometric Covering by Discs (GCD) seen in
2 In

the case of IED attacks, this is because the location around an IED attack is usually cordoned off and
searched and the insurgents do not want their weapons caches to be found, thus leading to α. In contrast, the
insurgents do not want their caches to be too far away as they then run the risk of detection at checkpoints
and random search points while transporting munitions, leading to β.

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:5

Fig. 1. Map of poppy fields for Example 2.1. For each labeled point pi, the “ p” is omitted for readability.

Johnson [1982], also known as the Euclidean m-center on points in Masuyama and
Ibaraki [1981]. The problem is defined as follows.
Geometric Covering by Discs (GCD).
INPUT: A set P of integer-coordinate points in a Euclidean plane, positive integers
b > 0 and K < |P|.
OUTPUT: “Yes” if there exists k discs of diameter b centered on points in P such that
there is a disc covering each point in P, “no” otherwise.
As with most decision problems, we define the associated counting problem, #GCD,
as the number of “yes” answers to the GCD decision problem. The result that follows,
which is new, shows that #GCD is #P-complete and, moreover, that there is no fully
polynomial random approximation scheme for #GCD unless NP equals the complexity
class RP.3
L EMMA 2.1. #GCD is #P-complete and has no FPRAS unless NP=RP.
We can leverage the preceding result to derive a complexity result for the counting
version of k-SEP.
T HEOREM 2.1. The counting version of k-SEP is #P-complete and has no FPRAS
unless NP=RP.
3. GEOSPATIAL ABDUCTION AS A TWO-PLAYER GAME

Throughout this article, we view geospatial abduction as a two-player game where
an agent attempts to find an “explanation” for a set of observations caused by the
adversary who wants to hide the explanation from the agent.
Each agent chooses a strategy which is merely a subset of S. Though “strategy” and
“observation” are defined identically, we use separate terms to indicate our intended
use. In the IED example, the adversary’s strategy is a set of points where to place his
3 RP

is the class of decision problems for which there is a randomized polynomial algorithm that, for any
instance of the problem, returns “false” with probability 1 when the correct answer to the problem instance
is false, and returns “true” with probability (1 − ) for a small  > 0 when the correct answer to the problem
instance is “true.”

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:6

P. Shakarian et al.

cache, while the agent’s strategy is a set of points that he thinks hold the weapons
caches. Throughout this article, we use A (respectively B) to denote the strategy of the
adversary (respectively agent).
Given a pair (A, B) of adversary-agent strategies, a reward function measures how
similar the two sets are. The more similar, the better it is for the agent. As reward
functions can be defined in many ways, we choose an axiomatic approach so that our
framework applies to many different reward functions including ones that people may
invent in the future.
Definition 3.1 (Reward Function). A reward function is any function rf : 2S × 2S →
[0, 1] that for any k-explanation A 
≡ ∅ and set B ⊆ S, the function satisfies:
(1) If B = A, then rf(A, B) = 1.
(2) For B, B 
 then
rf(A, B ∪ B 
) ≤ rf(A, B) + rf(A, B 
 ) − rf(A, B ∩ B 
 ).
We now define the payoffs for the agent and adversary.
O BSERVATION 3.1. Given adversary strategy A, agent strategy B, and reward function rf, the payoff for the agent is rf(A, B) and the payoff for the adversary is −rf(A, B).
It is easy to see that for any reward function and pair (A, B), the corresponding game is
a zero-sum game [Leyton-Brown and Shoham 2008]. Our complexity analysis assumes
all reward functions are polynomially computable. All the specific reward functions we
propose in this article satisfy this condition.
The basic intuition behind the reward function is that the more the strategy of the
agent resembles that of the adversary, the closer the reward is to 1. Axiom 1 says that
if the agent’s strategy is the same set as adversary’s, then the reward is 1. Axiom 2
says that adding a point to B cannot increase the reward to the agent if that point is
already in B, that is, double-counting of rewards is forbidden.
The following theorem tells us that every reward function is submodular, that is,
the marginal benefit of adding additional points to the agent’s strategy decreases as
the cardinality of the strategy increases.
P ROPOSITION 3.1 (S UBMODULARITY OF R EWARD F UNCTIONS ). Every
reward
/ B and p ∈
/ B
,
function is submodular, that is, if B ⊆ B 
 , and point p ∈ S such that p ∈


then rf(A, B ∪ { p}) − rf(A, B) ≥ rf(A, B ∪ { p}) − rf(A, B ).
Some readers may wonder why rf(A, ∅) = 0 is not an axiom. While this is true of
many reward functions, there are reward functions where we may wish to penalize the
agent for “bad” predictions. Consider the following reward function.
Definition 3.2 (Penalizing Reward Function). Given a distance dist, we define the
penalizing reward function, prf dist (A, B), as follows.
1 |{ p ∈ A|∃ p
 ∈ B s.t. d( p, p
 ) ≤ dist}| |{ p ∈ B| 
 ∃ p
 ∈ A s.t. d( p, p
 ) ≤ dist}|
+
−
2
2 · |A|
2 · |S|
P ROPOSITION 3.2. prf is a valid reward function.
Example 3.1. Consider Example 2.1 and the explanation A ≡ { p40 , p46 } (resembling
actual locations of the drug labs), the set B ≡ { p38 , p41 , p44 , p56 } (representing areas
that the drug enforcement officials wish to search), distance dist = 100 meters. There is
only one point in A that is within 100 meters of a point in B (point p40 ) and 3 points in
B more than 100 meters from any point in A (points p38 , p44 , p56 ). These relationships
are shown visually in Figure 2. Hence, prf dist (A, B) = 0.5 + 0.25 − 0.011 = 0.739.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:7

Fig. 2. Dashed circles encompass all feasible points within 100 meters from explanation { p40 , p45 }.

prf penalizes the agent if he poorly selects points in S. The agent starts with a
reward of 0.5. The reward increases if he finds points close to elements of A; otherwise,
it decreases.
A reward function is zero-starting if rf(A, ∅) = 0, that is, the agent gets no reward if
he infers nothing.
Definition 3.3. A reward function, rf, is monotonic if (i) it is zero-starting and (ii) if
B ⊆ B 
 then rf(A, B) ≤ rf(A, B 
 ).
We now define several example monotonic reward functions.
The intuition behind the cutoff reward function crf is simple: For a given distance
dist (the “cut-off ” distance), if for every p ∈ A, there exists p
 ∈ B such that d( p, p
 ) ≤
dist, then p
 is considered “close to” p.
Definition 3.4 (Cutoff Reward Function). Reward function based on a cut-off distance, dist.
crf dist (A, B) :=

card({ p ∈ A|∃ p
 ∈ B s.t. d( p, p
 ) ≤ dist})
card(A)

The following proposition shows that the cutoff reward function is a valid, monotonic
reward function.
P ROPOSITION 3.3. crf is a valid, monotonic reward function.
Example 3.2. Consider Example 3.1. Here, crf dist (A, B) returns 0.5 as one element
of A is within 100 meters of an element in B.
By allowing a more general notion of “closeness” between points p ∈ A and p
 ∈ E,
we are able to define another reward function, the falloff reward function, frf. This
function provides the most reward if p = p
 but, unlike the somewhat binary crf,
gently lowers this reward to a minimal zero as distances d( p, p
 ) grow.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:8

P. Shakarian et al.

Definition 3.5 (Falloff Reward Function). Reward function with value based on
minimal distances between points.

0
if B = ∅
frf(A, B) := 
1
p∈A |A|+min p
 ∈B (d( p, p
 )2 ) otherwise

with d( p, p
 ) := ( px − p
x )2 + ( py − p
y )2 . In this case, the agent’s reward is inversely
proportional to the square of the distance between points, as the search area required
grows proportionally to the square of this distance.
P ROPOSITION 3.4. frf is a valid, monotonic reward function.
In practice, an agent may assign different weights to points in S based on the perceived importance of their partner observations in O. The “weighted reward function”
wrf gives greater reward for being “closer” to points in A that have high weight than
those with lower weights.
Definition 3.6 (Weighted Reward Function). Given weight function W : S → R+ ,
and a cut-off distance dist we define the weighted reward function to be:

{ p∈A|∃ p
 ∈B s.t. d( p, p
 )≤dist} W( p)
(W,dist)

wrf
.
(A, B) :=

p
 ∈A W( p )
P ROPOSITION 3.5. wrf is a valid, monotonic reward function.
It is easy to see that the weighted reward function is a generalization of the cutoff
reward function where all weights are 1.
It is important to note that we have introduced reward functions axiomatically.
There are numerous other reward functions that satisfy the axioms given in Definition 3.1 that can be defined in an application. There is no guarantee that the few specific instances of a reward function we have defined are the only good ones; application
developers are welcome to use their own.
3.1. Incorporating Mixed Strategies

In this section, we introduce pdfs over strategies (or “mixed strategies” [Leyton-Brown
and Shoham 2008]) and introduce the notion of “expected reward.” We first present
explanation/strategy functions which return an explanation (respectively strategy) of
a certain size for a given set of observations.
Definition 3.7 (Explanation/Strategy Function). An explanation (respectively strategy) function is any function ef : 2S × N → 2S (respectively sf : 2S × N → 2S ) that,
given a set O ⊆ S and k ∈ N, returns a set E ⊆ S such that E is a k-sized explanation of O (respectively E is a k-sized subset of S). Let EF be the set of all explanation
functions.
Example 3.3. Following from Example 2.1, we shall define two functions ef1 , ef2 ,
which for set O (defined in Example 2.1) and k ≤ 3, give the following sets.
ef1 (O, 3) = { p42 , p45 , p48 }
ef2 (O, 3) = { p40 , p46 }
These sets may correspond to explanations from various sources. Perhaps they correspond to the answer of an algorithm that drug-enforcement officials use to solve GAPs.
Conversely, they could also be the result of a planning session by the drug cartel to
determine optimal locations for the drug labs.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:9

In theory, the set of all explanation functions can be infinitely large; however, it
makes no sense to look for explanations containing more points than S, so we assume
explanation functions are only invoked with k ≤ M × N.
A strategy function is appropriate for an agent who wants to select points resembling what the adversary selected, but is not required to produce an explanation. Our
results typically do not depend on whether an explanation or strategy function is used
(when they do, we point it out). Therefore, for simplicity, we use “explanation function”
throughout the article. In our complexity results, we assume that explanation/strategy
functions are computable in constant time.
Both the agent and the adversary do not know the explanation function (where
is the adversary going to put his weapons caches? Where will US forces search for
them?) in advance. Thus, they use a pdf over explanation functions to estimate their
opponent’s behavior, yielding a “mixed” strategy.
Definition 3.8 (Explanation Function Distribution). Given a space S, real numbers
α, β, feasibility predicate feas, and an associated set of explanation functions EF, an
explanation
function distribution is a finitary4 probability distribution efd : EF → [0, 1]

with ef∈EF efd(ef) = 1. Let EFD be a set of explanation function distributions.
We use |efd| to denote the cardinality of the set EF associated with efd.
Example 3.4. Following from Example 3.3, we shall define the explanation function
distribution efddrug that assigns a uniform probability to explanation functions in the
set ef1 , ef2 (i.e., efddrug (ef1 ) = 0.5).
We now define an “expected reward” that takes into account these mixed strategies
specified by explanation function distributions.
Definition 3.9 (Expected Reward). Given a reward function rf, and explanation
function distributions efdadv , efdag , the expected reward is the function EXRrf : EFD ×
EFD → [0, 1] defined as follows. 



EXRrf (efdadv , efdag ) = efadv ∈EFadv efdadv (efadv ) · efag∈EFag efdag (efag) · rf(efadv , efag )
However, in this article, we will generally not deal with expected reward directly,
but two special cases (expected adversarial detriment and expected agent benefit) in
which the adversary’s and agent’s strategies are not mixed respectively. We explore
these two special cases in the next two sections.
4. SELECTING A STRATEGY FOR THE ADVERSARY

In this section, we study how an adversary would select points (set A) in the space he
would use to cause observations O. For instance, in the IED example, the adversary
needs to select A and O so that A is an explanation for O. We assume the adversary
has a probabilistic model of the agent’s behavior (an explanation function distribution)
and that he wants to eventually find an explanation (e.g., where to put his weapons
caches). Hence, though he can use expected reward to measure how close the agent will
be to his explanation, only the agent’s strategy is mixed. The adversary’s actions are
concrete. Hence, we introduce a special case of expected reward: expected adversarial
detriment.
4

That is, efd assigns nonzero probabilities to only finitely many explanation functions.

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:10

P. Shakarian et al.

Definition 4.1 (Expected Adversarial Detriment). Given any reward function rf and
explanation function distribution efd, the expected adversarial detriment is the function EXDrf : EFD × 2S → [0, 1] defined as follows.

EXDrf (efd, A) =
rf(A, ef(O, k)) · efd(ef)
ef∈EF
Intuitively, the expected adversarial detriment is the expected number of partner locations the agent may uncover if efd is correct. Consider the following example.
Example 4.1. Following from the previous examples, suppose the drug cartel is
planning three drug labs. Suppose they have information that drug-enforcement
agents will look for drug labs using efddrug (Example 3.4). One suggestion the adversary may consider is to put the labs at locations p41 , p52 (see Figure 1). Note that this
explanation is optimal with respect to cardinality. With dist = 100 meters, they wish
to compute EXDcrf (efddrug , { p41 , p52 }). We first need to find the reward associated with
each explanation function (see Example 3.3).
crf dist ({ p41 , p52 }, ef1 (O, 3)) = 1
crf dist ({ p41 , p52 }, ef2 (O, 3)) = 0.5
Thus, EXDcrf (efddrug , { p41 , p52 }) = 0.5 · 1 + 0.5 · 0.5 = 0.75. Hence, this is probably not
the best location for the cartel to position the labs with respect to crf and efd, because
the expected adversarial detriment of the drug-enforcement agents is large.
The expected adversarial detriment is a quantity that the adversary would seek to
minimize. This is now defined as an optimal adversarial strategy next.
Definition 4.2 (Optimal Adversarial Strategy). Given a set of observations O, natural number k, reward function rf, and explanation function distribution efd, an optimal adversarial strategy is a k-sized explanation A for O such that EXDrf (efd, A) is
minimized.
4.1. The Complexity of Finding an Optimal Adversarial Strategy

In this section, we formally define the Optimal Adversary Strategy (OAS) problem
and study its complexity.
OAS Problem.
INPUT: Space S, feasibility predicate feas, real numbers α, β, set of observations O,
natural number k, reward function rf, and explanation function distribution efd.
OUTPUT: Optimal adversarial strategy A.

We show that the known NP-hard problem Geometric Covering by Discs (see
Section 2) is polynomially reducible to OAS, which establishes NP-hardness.
T HEOREM 4.1. OAS is NP-hard.
The proof of the previous theorem yields two insights. First, OAS is NP-hard even
if the reward function is monotonic (or antimonotonic). Second, OAS remains NP-hard
even if the cardinality of EF is small; in the construction we only have one explanation
function. Thus, we cannot simply pick an “optimal” function from EF. To show an
upper bound, we define OAS-DEC to be the decision problem associated with OAS. If
the reward function is computable in polynomial time, OAS-DEC is in NP.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:11

OAS-DEC .
INPUT: Space S, feasibility predicate feas, real numbers α, β, set of observations O,
natural number k, reward function rf, explanation function distribution efd, and number R ∈ [0, 1].
OUTPUT: “Yes” if there exists an adversarial strategy A such that EXDrf (efd, A) ≤ R,
“no” otherwise.

T HEOREM 4.2. If the reward function is computable in PTIME, then OAS-DEC is
NP-complete.
Suppose we have an NP oracle that can return an optimal adversarial strategy;
let’s call it A. Quite obviously, this is the best response of the adversary to the mixed
strategy of the agent. Now, how does the agent respond to such a strategy? If we were
to assume that such a solution were unique, then the agent would simply have to find
an strategy B such that rf(A, B) is maximized. This would be a special case of the
problem we discuss in Section 5. However, this is not necessarily the case. A natural
way to address this problem is to create a uniform probability distribution over all
optimal adversarial strategies and optimize the expected reward, again a special case
of what is to be discussed in Section 5. However, obtaining the set of explanations is not
an easy task. Even if we had an easy way to exactly compute an optimal adversarial
strategy, finding all such strategies is an even more challenging problem. In fact, it is
at least as hard as the counting version of GCD, which we already have shown #P-hard
and difficult to approximate. This is shown in the following theorem.
T HEOREM 4.3. Finding the set of all adversarial optimal strategies that provide a
“yes” answer to OAS-DEC is #P-hard.
4.2. Preprocessing and Naive Approach

In this section, we present several algorithms to solve OAS. We first present a simple
routine for preprocessing followed by a naive enumeration-based algorithm.
We use  to denote the maximum number of partners per observation and f
to denote the maximum number of observations supported by a single partner. In
general,  is bounded by π(β 2 − α 2 ), but may be lower depending on the feasible points
in S. Likewise, f is bounded by min(|O|, ) but may be much smaller depending on
the sparseness of the observations.
Preprocessing Procedure. Given a space S, a feasibility predicate feas, real numbers
α ≥ 0, β > 0, and a set O of observations, we create two lists (similar to a standard
inverted index) as follows.

— Matrix M. M is an array of size S. For each feasible point p ∈ S, M[ p] is a list
of pointers to observations. M[ p] contains pointers to each observation o such that
feas( p) is true and such that d(o, p) ∈ [α, β].
— List L. List L contains a pointer to position M[ p] in the array M iff there exists an
observation o ∈ O such that feas( p) is true and such that d(o, p) ∈ [α, β].
It is easy to see that we can compute M and L in O(|O| · ) time. The next example
shows how M, L apply to our running drug example.
Example 4.2. Consider our running example concerning the location of drug laboratories that started with Example 2.1. The set L consists of { p1 , . . . , p67 }. The matrix
M returns lists of observations that can be associated with each feasible point. For
example, M( p40 ) = {o 3 , o 4 , o 5 } and M( p46 ) = {o 1 , o 2 }.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:12

P. Shakarian et al.

Fig. 3. Set L of all possible partners for our drug laboratory location example.

Naive Approach. After preprocessing, a straightforward exact solution to OAS would
be to enumerate all subsets of L that have a cardinality less than or equal to k. Let us
call this set L ∗ . Next, we eliminate all elements of L ∗ that are not valid explanations.
Finally, for each element of L ∗ , we compute the expected adversarial detriment and
return the element of L ∗ for which this value is the least. Clearly, this approach is
impractical as the cardinality of L ∗ can be very large. Further, this approach does not
take advantage of the specific reward functions. We now present Mixed Integer Linear
Programs (MILPs) for wrf and frf and later look at ways to reduce the complexity of
solving these MILPs.
4.3. Mixed Integer Linear Programs for OAS under wrf, crf, frf

We present Mixed Integer Linear Programs (MILPs) to solve OAS exactly for some
specific reward functions. First, we present a mixed integer linear program for the
reward function wrf. Later, in Section 4.4, we show how to improve efficiency (while
maintaining optimality) by reducing the number of variables in the MILP. Note that
these constraints can also be used for crf as wrf generalizes crf. We also define a
MILP for the frf reward function.
While these mixed integer programs may appear nonlinear, Proposition 4.4 gives a
simple transformation to standard linear form. For readability, we define the MILPs
before discussing this transformation.
Definition 4.3 (wrf MILP). Given real number dist > 0 and weight function W, associate a constant wi with the weight W( pi) of each point pi ∈ L. Next, for each pi ∈ L
and ef j ∈ EF, let constant ci, j = 1 iff ∃ p
 ∈ ef(O, k) such that d( p
 , pi) ≤ dist and 0 otherwise. Finally, associate an integer-valued variable X i with each pi ∈ L.
Minimize:
⎛


⎞


wi · ci, j
⎠
⎝efd(ef j) ·
Xi · 
wi · X i
p
∈L
i
p
∈L
i
ef j∈EF
subject to:
(1) X i ∈ {0, 1}; 
(2) Constraint pi∈L X i ≤ k;
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:13

(3) 
For each o j ∈ O, add constraint
pi ∈L d(o , p )∈[α,β] X i ≥ 1.
j

i

Example 4.3. Continuing from Examples 4.1 and 4.2, suppose the drug cartel wishes to produce an adversarial strategy A using wrf. Consider the case
where we use crf, k ≤ 3, and dist = 100 meters as before (see Example 4.1).
Clearly, there are 67 variables in these constraints, as this is the cardinality
of set L (as per Example 4.2). The constants ci,1 are 1 for elements in the set
{ p35 , p40 , p41 , p42 , p43 , p44 , p45 , p46 , p49 , p49 , p50 , p52 , p56 } (and 0 for all others). The
constants ci,2 are 1 for elements in the set { p33 , p37 , p40 , p41 , p45 , p46 , p47 , p48 } (and 0
for all others).
We can create a MILP for frf as follows.
Definition 4.4 (frf MILP). For each pi ∈ L and ef j ∈ EF, let constant ci, j =
min p
 ∈ef(O,k) (d( pi, p
 )2 ). Associate an integer-valued variable X i with each pi ∈ L.
Minimize:
⎛


⎞


1
⎠
⎝efd(ef j) ·

Xi ·
ci, j + pi∈L X i
p
∈L
i
ef j∈EF
subject to:
(1)
(2)
(3)

X i ∈ {0, 1}; 
Constraint pi∈L X i ≤ k;
For each o j ∈ O, add constraint

pi ∈L d(o , p )∈[α,β] X i ≥ 1.
j

i

The following theorem tells us that solving the preceding MILPs correctly yields a
solution for the OAS problem under both wrf or frf.
P ROPOSITION 4.1. Suppose S is a space, O is an observation set, real numbers α ≥
0, β > 0, and suppose the wrf and frf MILPs are defined as earlier.
(1) Suppose A ≡ { p1 , . . . , pn} is a solution to OAS with wrf(respectively frf). Consider
the assignment that assigns 1 to each X 1 , . . . , X n corresponding to the pi’s and 0
otherwise. This assignment is an optimal solution to the MILP.
(2) Given the solution to the constraints, if for every X i = 1, we add point pi to set A,
then A is a solution to OAS with wrf(respectively frf).
Setting up either set of constraints can be performed in polynomial time, where
computing the ci, j constants is the dominant operation.
P ROPOSITION 4.2. Setting up the wrf/frf constraints can be accomplished in
O(|EF| · k · |O| · ) time (provided the weight function W can be computed in constant
time).
The number of variables for either set of constraints is related to the size of L, which
depends on the number of observations, spacing of S, and α, β.
P ROPOSITION 4.3. The wrf/frf constraints have O(|O| · ) variables and 1 + |O|
constraints.
The MILPs for wrf and frf appear nonlinear as the objective function is fractional.
However, as the denominator is nonzero and strictly positive, the Charnes-Cooper
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:14

P. Shakarian et al.

transformation [Charnes and Cooper 1962] allows us to quickly (in the order of number
of constraints multiplied by the number of variables) transform the constraints into a
purely integer linear form. Many linear and integer linear program solvers include
this transformation in their implementation.
P ROPOSITION 4.4. The wrf/frf constraints can be transformed into a purely linear
integer form in O(|O|2 · ) time.
We note that a linear relaxation of any of the aforesaid three constraints can yield
a lower bound on the objective function in O(|L|3.5 ) time.
P ROPOSITION 4.5. Given the constraints of Definition 4.3 or Definition 4.4, if we
consider the linear program formed by setting all X i variables to be in [0, 1], then the
value returned by the objective function will be a lower bound on the value returned
by the objective function for the mixed integer linear constraints, and this value can be
obtained in O(|O|3.5 · 3.5 ) time.
Likewise, if we solve the mixed integer linear program with a reduced number of
variables, we are guaranteed that the solution will cause the objective function to be
an upper bound for the original set of constraints.
P ROPOSITION 4.6. Consider the MILPs in Definition 4.3 and Definition 4.4. Suppose L 
 ⊂ L and every variable X i associated with some pi ∈ L 
 is set to 0. The resulting
solution is an upper bound on the objective function for the constraints solved on the
full set of variables.
4.4. Correctly Reducing the Number of Variables for crf

As the complexity of solving MILPs is closely related to the number of variables in
the MILP, the goal of this section is to reduce the number of variables in the MILP
associated before with the crf reward function. We note that all results in this section
apply only for the crf reward function. In this section, we show that if we can find
a certain type of explanation called a δ-core optimal explanation, then we can “buildup” an optimal adversarial strategy in polynomial time. It also turns out that finding
these special explanations can be accomplished using an MILP which will often have
significantly fewer variables than the MILPs of the last section. First, we consider the
wrf constraints applied to crf which is a special case of wrf. The objective function for
this case is
⎛


⎞


ci, j
⎠,
⎝efd(ef j) ·
Xi · 
pi ∈L X i
p
∈L
i
ef j∈EF
where for each pi ∈ L and ef j ∈ EF, ci, j = 1 iff ∃ p
 ∈ ef j(O, k) such that d( p
 , pi) ≤ dist
and 0 otherwise. If we rearrange the objective function, we see that with each X i
variable associated with point pi ∈ L, there is an associated constant consti.

consti =
efd(ef j) · ci, j
ef j∈EF
This lets us rewrite the objective function as

pi ∈L X i · consti

.
pi ∈L X i
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:15

Example 4.4. Continuing from Example 4.3, consti = 0.5 for the following elements: { p33 , p35 , p37 , p42 , p43 , p44 , p47 , p49 , p50 , p52 , p56 }; consti = 1 for these elements:
{ p40 , p41 , p45 , p46 , p48 }, and 0 for all others.
In many covering problems where we wish to find a cover of minimal cardinality,
we could reduce the number of variables in the integer program by considering equivalent covers as duplicate variables. However, for OAS, this technique cannot be easily
applied. The reason for this is because an optimal adversarial explanation is not necessarily irredundant (see Definition 2.5). Consider the following. Suppose we wish to find
an optimal adversarial strategy of size k. Let P be an irredundant cover of size k – 1.
Suppose there is some element p
 ∈ P that covers only one observation o 
 . Hence, there
cover. Suppose there
is no p ∈ P−{ p
 } that covers o 
 by the definition of an irredundant

/ P that also covers o 
 . Now, let m = pi∈P− p
 consti. In our construcis also some p

 ∈
tion of an example solution to OAS that is not irredundant, we let const
 be the value
m
. Suppose by
associated with both p
 and p

 . Consider the scenario where const
 < k−2
way of contradiction that the optimal irredundant cover is also the optimal adversarial
strategy. Then, by the definition of an optimal adversarial strategy we know that the


set P is more optimal than P ∪ { p

 }. This would mean that m+const
< m+2·const
. This
k−1
k
m


leads us to infer that m < const · (k – 2), which clearly contradicts const < k−2 . It is
clear that a solution to OAS need not be irredundant.
Even though an OAS is not necessarily irredundant, we are able to reduce the size
of the set L by looking at certain aspects of an OAS. Our intuition is that each OAS
contains a core explanation which has fewer redundant elements than the OAS and
low values of const for each element in that set. Once this type of explanation is found,
we can build an optimal adversarial strategy in polynomial time. First, we define a
core explanation.
Definition 4.5 (Core Explanation). Given an observation set O and set L of possible
partners, an explanation Ecore is a core explanation iff for any pi ∈ Ecore , there does not
exist p j ∈ L such that:
(1) ∀o ∈ O if o, pi are partners, then o, p j are also partners.
(2) const j < consti.
We now show that any optimal adversarial strategy contains a subset that is a core
explanation.
T HEOREM 4.4. If A is an optimal adversarial strategy, there exists a core explanation Ecore ⊆ A.
Example 4.5. Continuing from Example 4.4, consider the set A ≡ { p34 , p38 , p57 }
(which would correspond to drug lab locations as planned by the cartel). Later, we
show that this is an optimal adversarial strategy (the expected adversarial detriment
associated with A is 0). Consider the subset p34 , p38 . As p34 explains observations
o 3 , o 4 , o 5 , and p38 explains observations o 1 , o 2 , this set is also an explanation. Obviously, it is of minimal cardinality. Hence, the set { p34 , p38 } is a core explanation
of A.
Suppose we have an oracle that, for a given k, O, and efd returns a core explanation
Ecore that is guaranteed to be a subset of the optimal adversarial strategy associated
with k, O, and efd. The following theorem says we can find the optimal adversarial
strategy in polynomial time. The key intuition is that we need not concern ourselves
with covering the observations as Ecore is an explanation. The algorithm BUILD-STRAT
follows from this theorem.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:16

P. Shakarian et al.

ALGORITHM 1: BUILD-STRAT
INPUT: Partner list L, core explanation Ecore , natural number k, explanation function distribution efd
OUTPUT: Optimal adversarial strategy A
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)

If |Ecore | = k, return Ecore
Set A = Ecore . Let k
 = |Ecore |
Sort the set L − Ecore by consti. Let L 
 = { p1 , . . . , pk−k
 } be the k − k
 elements of this set with
the lowest values for consti, in ascending order
Pi be the set { p1 , . . . , pi}
For each pi ∈ L 
 let 
For each Pi let Si = j≤i const j
rf
k
 ·EXD (efd,Ecore )+Si

 ({
Let ans = min
})
pi ∈L

k
 +i

Let Pans be the Pi associated with ans
If ans ≥ EXDrf (efd, Ecore ), return Ecore , else return Ecore ∪ Pans

T HEOREM 4.5. If there is an oracle that for any given k, O, and efd returns a core
explanation Ecore that is guaranteed to be a subset of the optimal adversarial strategy
associated with k, O, and efd, then we can find an optimal adversarial strategy in
O( · |O| · log( · |O|) + (k − |Ecore |)2 ) time.
We now introduce the notion of δ-core optimal. Intuitively, this is a core explanation of cardinality exactly δ that is optimal with respect to the expected adversarial
detriment compared to all other core explanations of that cardinality.
Definition 4.6. Given an integer δ > 0, an explanation distribution function efd,
and a reward function rf, a core explanation Ecore is δ-core optimal iff:
— |Ecore | = δ.

of cardinality exactly δ such that
— There does not exist another core explanation Ecore
rf
rf

EXD (efd, Ecore ) < EXD (efd, Ecore ).
We now define some subsets of the set L that are guaranteed to contain core explanations and δ-core optimal explanations as well. In practice, these sets will be much
smaller than L and will be used to create an MILP of reduced size.
Definition 4.7 (Reduced Partner Set). Given observations O and set of possible partners L, we define the reduced partner set L ∗∗ as follows.
L ∗∗ ≡ { pi ∈ L| 
 ∃ p j ∈ L such that (const j < consti) ∧ (∀o ∈ O such that o, pi are partners,
o, p j are also partners)}
We define L ∗ as follows.
L ∗ ≡ { pi ∈ L ∗∗ | 
 ∃ p j ∈ L ∗∗ such that (const j = consti) ∧ (∀o ∈ O such that o, pi are partners,
o, p j are also partners)}
L EMMA 4.6. (1) If explanation E is a core explanation, then E ⊆ L ∗∗ .
(2) If explanation E is δ-core optimal, then E ⊆ L ∗∗ .
(3) If for some natural number δ, there exists an explanation of size δ, then there exists
a δ-core optimal explanation E such that E ⊆ L ∗ .
The reduced partner set can be computed in polynomial time. We also note that under
the assumption that |O| << |L|, which we have found true in practice, determining
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:17

Table I. The Set L Partitioned by consti and Supported Observations
Supported Observations

consti = 0

consti = 0.5

o1

p4 − p6 , p12 − p16 , p22 − p23 , p30 − p31

p44

o1, o2

p38

p37 , p52

o2

p64 , p67

p47

o2, o3

p57

o3

p17 − p19 , p24 − p26 , p32 , p39 , p58 − p59

o3, o4

p27 − p28

p33

o4

p1 − p3 , p7 − p11 , p20 − p21 , p29 , p51

p50

o3, o4, o5

p34 , p53 − p54

p49

o5

p36 , p60 − p66

p35

o4, o5
o3, o5

consti = 1
p45 , p46

p40 − p41

p42 − p43
p55

p56

p48

the set L ∗∗ or L ∗ can be accomplished faster (in terms of time complexity) than solving
even a relaxation of the original MILP.
P ROPOSITION 4.7. Given set L, set L ∗ and L ∗∗ can be found in O(|L|2 · |O|2 ) time.
Example 4.6. Let us continue from Example 4.5. Based on preprocessing and the
computation of consti, we can easily produce the data of Table I in polynomial time.
Based on this, we obtain a reduced partner set L ∗ ≡ { p34 , p38 , p57 }.
Next, the following lemma tells us that an OAS must contain a core explanation
that is δ-core optimal.
L EMMA 4.6. Given an optimal adversarial strategy A, there exists some δ ≤ |A| such
that there is a δ-core optimal explanation that is a subset of A (using the crf reward
function).
Thus, if we can find the δ-core optimal explanation that is contained in an OAS, we
can then find the OAS. If we know δ, such an explanation can be found using an MILP.
We now present a set of integer linear constraints to find a δ-core optimal explanation.
Of course we can easily adopt the constraints of the previous section, but this would
offer us no improvement in performance. We therefore create an MILP that should
have a significantly smaller number of variables in most cases.
To create this MILP, we take a given set of possible partners L and calculate the
set L ∗ (the reduced partner set), which often will have a cardinality much smaller
than L. Next, we use L ∗ to form a new set of constraints to find a δ-core optimal
explanation. We now present these δ-core constraints. Notice that the cardinality
requirement in these constraints is “=” and not “≤”. This is because Lemma 4.6
ensures a core explanation that is δ-core optimal, meaning that the core explanation must have cardinality exactly δ. This also allows us to eliminate variables
from the denominator of the objective function, as the denominator must equal δ as
well.
Definition 4.8 (δ-core MILP). Given parameter δ and reduced partner set L ∗ , we
define the δ-core constraints by first associating a variable X i with each point pi ∈ L ∗ ,
then solving:
Minimize:
1 
X i · consti
δ p ∈L ∗
i

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:18

P. Shakarian et al.

subject to:
(1)
(2)
(3)

X i ∈ {0, 1}. 
Constraint pi∈L X i = δ.
For each o j ∈ O, add constraint

pi ∈L ∗ d(o , p )∈[α,β] X i ≥ 1.
j

i

Example 4.7. Using set L ∗ from Example 4.6, we can create δ-core constraints as
follows:
Minimize:
1
( X 34 · const34 + X 38 · const38 + X 57 · const57 )
δ
subject to:
(1)
(2)
(3)
(4)
(5)
(6)

X 34 , X 38 , X 57 ∈ {0, 1}
X 34 + X 38 + X 57 = δ
X 38 ≥ 1 (for observation o 1 )
X 38 + X 57 ≥ 1 (for observation o 2 )
X 34 + X 57 ≥ 1 (for observation o 3 )
X 34 ≥ 1 (for observations o 4 , o 5 )

In the worst case, the set L ∗ ≡ L. Hence, we can assert the following:
P ROPOSITION 4.8. The δ-core constraints require O( · |O|) variables and 1 + |O|
constraints.
P ROPOSITION 4.9. Given δ-core constraints:
(1) Given set δ-core optimal explanation Ecore ≡ { p1 , . . . , pn}, if variables
X 1 , . . . , X n—corresponding with elements in A—are set to 1 and the rest of the variables are set to 0, the objective function of the constraints will be minimized.
(2) Given the solution to the constraints, if for every X i = 1, we add point pi to set Ecore ,
then Ecore is a δ-core optimal solution.
We now have all the pieces required to leverage core explanations and reduced partner sets to find an optimal adversarial strategy. By Theorem 4.5, we know that any
optimal adversarial strategy must have a core explanation. Further, by Lemma 4.6,
such a core explanation is δ-core optimal. Using a (usually) much smaller mixed integer linear program, we can find such an explanation. We can then find the optimal
adversarial strategy in polynomial time using BUILD STRAT. Though we do not know
what δ is, we know it must be in the range [1, k]. Further, using a relaxation of the
OPT-KSEP-IPC constraints for solving geospatial abduction problems (as presented in
Shakarian et al. [2010]), we can easily obtain a lower bound tighter than 1 on δ. Hence,
if we solve k such (most likely small) mixed integer linear programs, we are guaranteed that at least one of them must be a core explanation for an optimal adversarial
strategy. We note that these k MILPs can be solved in parallel (and the following k
instances of BUILD-STRAT can also be run in parallel as well). An easy comparison of
the results of the parallel processes would be accomplished at the end. As L ∗ is likely
to be significantly smaller than L, this could yield a significant reduction in complexity. Furthermore, various relaxations of this technique can be used (e.g., only using
one value of δ).
Example 4.8. Continuing from Example 4.7, where the cartel members are attempting to find an OAS to best position drug laboratories, suppose they used the
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:19

relaxation of OPT-KSEP-IPC (from Shakarian et al. [2010]) to obtain a lower bound on
the cardinality of an explanation and found it to be 2. With k = 3, they would solve
two MILPs of the form of Example 4.7: one with δ = 2 and one with δ = 3. The solution
to the first MILP would set X 34 and X 38 both to 1 while the second MILP would set
X 34 , X 38 , and X 57 all to 1. As the expected adversarial detriment for both solutions is
0, they are both optimal and running BUILD-STRAT is not necessary. Either { p34 , p38 }
or { p34 , p38 , p57 } can be returned as an OAS.
5. FINDING A COUNTER-ADVERSARY STRATEGY

Now that we have examined ways in which the adversary can create a strategy based
on probabilistic knowledge of the agent, we consider how the agent can devise an “optimal” strategy to counter the adversary. As before, we use a special case of expected
reward (Definition 3.1 from Section 3.9).
Definition 5.1 (Expected Agent Benefit). Given a reward function rf and explanation function distribution efd, the expected agent benefit is the function EXBrf :
2S × EFD → [0, 1] defined as follows.

EXBrf (B, efd) =
rf(ef(O, k), B) · efd(ef)
ef∈EF
Example 5.1. Following from Examples 2.1 and 3.4, suppose drug-enforcement
agents have information that the cartel is placing drug labs according to efddrug . (Such
information could come from multiple runs of the GREEDY-KSEP-OPT2 algorithm
of Shakarian et al. [2010]). The drug-enforcement agents wish to consider the set
B ≡ { p41 , p52 }. First, they must calculate the reward associated with each explanation
function (note that k = 3, dist = 100, and rf = crf).
crf dist (ef1 (O, 3), { p41 , p52 }) = 0.67
crf dist (ef2 (O, 3), { p41 , p52 }) = 0.5
(As an aside, we would like to point out the asymmetry in crf; compare these computations with the results of Example 4.1). Hence, EXBcrf ({ p41 , p52 }, efddrug ) = 0.634.
We now define a maximal counter-adversary strategy.
Definition 5.2 (Maximal Counter-Adversary Strategy (MCA)). Given a reward function rf and explanation function distribution efd, a maximal counter-adversary strategy, B, is a subset of S such that EXBrf (B, efd) is maximized.
Note that MCA does not include a cardinality constraint. This is because we do
not require reward functions to be monotonic. In the monotonic case, we can trivially return all feasible points in S and be assured of a solution that maximizes the
expected agent benefit. Therefore, for the monotonic case, we include an extra parameter B ∈ {1, . . . , |S|} (for “budget”) which will serve as a cardinality requirement for B.
This cardinality requirement for B is necessarily the same as for A as the agent and
adversary may have different sets of resources. Also, we do not require that B be an
explanation. We discuss the special case where the solution to the MCA problem is
required to be an explanation in the Appendix.
5.1. The Complexity of Finding a Maximal Counter-Adversary Strategy

We now formally define the problem of finding a maximal counter-adversary strategy.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:20

P. Shakarian et al.

MCA Problem.

INPUT: Space S, feasibility predicate feas, real numbers α, β, set of observations O,
natural numbers k, B, reward function rf, and explanation function distribution efd.
OUTPUT: Maximal counter-adversary strategy B.
MCA is NP-hard via a reduction of the GCD problem.
T HEOREM 5.1. MCA is NP-hard.
The proof of the preceding result shows that MCA is NP-hard even if the reward
function is monotonic. Later, in Section 5.3, we also show that MCA can encode the
NP-hard MAX-K-COVER problem [Feige 1998] as well (which provides an alternate
proof for NP-hardness of MCA). We now present the decision problem associated with
MCA and show that it is NP-complete under reasonable conditions.
MCA-DEC.

INPUT: Space S, feasibility predicate feas, real numbers α, β, set of observations O,
natural numbers k, B, reward function rf, explanation function distribution efd, and
number R ∈ [0, 1].
OUTPUT: Counter-adversary strategy B such that EXBrf (B, efd) ≥ R.
T HEOREM 5.2. MCA-DEC is NP-complete, provided the reward function can be
evaluated in PTIME.
Not only is MCA-DEC NP-hard, under the same assumptions as earlier, the counting
version of the problem is #P-complete and moreover, it has no fully polynomial random
approximation scheme.
T HEOREM 5.3. Counting the number of strategies that provide a “yes” answer to
MCA-DEC is #P-complete and has no FPRAS unless NP=RP.
Theorem 5.3 tells us that MCA may not have a unique solution. Therefore, setting
up a mixed strategy of all MCAs to determine the “best response” to the MCA of an
agent by an adversary would be an intractable problem. This mirrors our result of the
previous section (Theorem 4.3).
5.2. MCA in the General Case: Exact and Approximate Algorithms

We now describe exact and approximate algorithms for finding a maximal counteradversary strategy in the general case. Note that throughout this section (as well
as in Section 5.3), we assume that the same preprocessing for OAS is used (refer to
Section 4.2). We will use the symbol L to refer to the set of all possible partners.
An Exact Algorithm For MCA. A naive, exact, and straightforward approach to the MCA
problem would simply consider all subsets of L and pick the one which
the

maximizes
|S| |L|
and
is
expected agent benefit. Obviously, this approach has a complexity O
i=0 i
not practical. This is unsurprising as we showed this to be an NP-complete problem.
Approximation in the General Case. Despite the impractical time complexity associated
with an exact approach, it is possible to approximate MCA with guarantees, even in
the general case. This is due to the fact that when efd is fixed, the expected agent
benefit is submodular.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:21

ALGORITHM 2 : (MCA-LS)
INPUT: Reward function rf, set O of observations, explanation function distribution efd, possible
partner set L, real number  > 0
OUTPUT: Set B ⊂ S
(1)
(2)
(3)
(4)

Set B∗ = L, for each pi ∈ B∗ let inci = EXBrf ({ p}, efd) − EXBrf (∅, efd).
Sort the pi’s in B∗ from greatest to least by inci (i.e., p1 is the element with the greatest
inci).
B = { p1 }, B∗ = B∗ − { p1 }, cur val = inc1 + EXBrf (∅, efd), f lag1 = true, i = 2
While f lag1
(a) new val = cur val + inci
(b) If new val > (1 + |L| 2 ) · cur val then
i.If EXBrf (B ∪ { pi}, efd) > (1 +


)
|L|2

· EXBrf (B, efd) then:

B = B ∪ { pi}, B∗ = B∗ − { pi}, cur val = EXBrf (B ∪ { pi}, efd)
(c) If new val ≤ (1 + |L| 2 ) · cur val or if pi is the last element then
i. j = 1, f lag2 = true, number each p j ∈ B
ii. While f lag2
A. If EXBrf (B − { p j}, efd) > (1 + |L| 2 ) · EXBrf (B, efd) then:

(5)
(6)

B = B − { p j}, cur val = EXBrf (B − { p j}, efd)
For each pi ∈ B∗ let inci = EXBrf (B ∪ { pi}, efd) − EXBrf (B, efd).
Sort the pi ’s in B∗ from greatest to least by inci
i = 0, f lag2 = false
B. Else,
If p j was the last element of B then set f lag1, f lag2 = false
Otherwise, j + +
(d) i + +
If EXBrf (L − B, efd) > EXBrf (B, efd) then set B = L − B
Return B

T HEOREM 5.4. For a fixed O, k, efd, the expected agent benefit, EXBrf (B, efd) has the
following properties:
(1) EXBrf (B, efd) ∈ [0, 1].
/ B 
 , the following is true:
(2) For B ⊆ B 
 and some point p ∈ S where p ∈
EXBrf (B ∪ { p}, efd) − EXBrf (B, efd) ≥ EXBrf (B 
 ∪ { p}, efd) − EXBrf (B 
, efd)
(i.e., expected agent benefit is submodular for MCA).
It follows immediately that MCA reduces to the maximization of a submodular function. We now present the MCA-LS algorithm that leverages this submodularity.
The following two propositions leverage Theorem 5.4 and Theorem 3.4 of Feige et al.
[2007].
P ROPOSITION 5.1. MCA-LS has time complexity of O( 1 · |L|3 · F(efd) · lg(|L|) where
F(efd) is the time complexity to compute EXBrf (B, efd) for some set B ⊆ L.
P ROPOSITION 5.2. MCA-LS is an ( 13 −


|L| )-approximation

algorithm for MCA.

Example 5.2. Let us consider our running example where drug-enforcement agents
are attempting to locate illegal drug laboratories in the area depicted in Figure 1.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:22

P. Shakarian et al.

The agents have information that there are k or fewer drug laboratories that support the poppy fields (set of observations O) and that they are positioned according
to efddrug (see Example 3.4). The agents wish to find a maximal counter-adversarial
strategy using the prf reward function. They decide to use MCA-LS to find such a
strategy with  = 0.1. Initially (at line 2), the algorithm selects point p48 (renumbering as p1 , note that in this example we shall use pi and inci numbering based
on Example 2.1 rather than what the algorithm uses). Hence, inc40 = 0.208 and
cur val = 0.708. As the elements are sorted, the next point to be considered in the
loop at line 2 is p40 which has an incremental increase of 0, so it is not picked. It
then proceeds to point p41 , which gives an incremental increase of 0.084 and is added
to B so cur val = 0.792. Point p45 is considered next, which gives an incremental increase of 0.208 and is picked, so now cur val = 1.0. The algorithm then considers
point p46 , which does not afford any incremental increase. After considering points
p33 , p35 , p37 , p42 , p43 , p44 , p47 , p49 , p50 , p52 , p56 , and finding they all give a negative incremental increase (and thus, are not picked), the algorithm finds that the old incremental increase of the next element, p1 , would cause the “if ” statement at line 4c to
be true, thus proceeding to the inner loop inside that “if ” statement (line 4(c)iiA). This
loop considers if the removal of any of the picked elements p48 , p41 , p45 causes the
expected agent benefit to increase. However, in this example, if any of the elements
are removed, the expected agent benefit decreases. Hence, the boolean f lag1 is set
to false and the algorithm exits the outer loop. The algorithm then returns the set
B ≡ { p48 , p41 , p45 } which is optimal.
5.3. Finding a Maximal Counter-Adversary Strategy, the Monotonic Case

In the previous section we showed a 13 approximate solution to MCA can be found in
polynomial time even without any monotonicity restriction. In this section, we show
that under the additional assumptions of monotonicity of reward functions, we can
obtain a better 63% approximation ratio with a faster algorithm. Here, we also have
the additional cardinality requirement of B for the set B (as described in Section 5).
We first show that expected agent benefit is monotonic when the reward function is.
C OROLLARY 5.1. For a fixed O, k, efd, if the reward function is monotonic, then the
expected agent benefit, EXBrf (B, efd) is also monotonic.
Thus, when we have a monotonic reward function, the MCA problem reduces to
the maximization of a monotonic, normalized5 submodular function with respect to
a uniform matroid6 ; this is a direct consequence of Theorem 5.4 and Corollary 5.1.
Therefore, we can leverage the result of Nemhauser et al. [1978], to develop the MCAGREEDY-MONO algorithm that follows. We improve performance by including “lazy
evaluation” using the intuition that the incremental increase caused by some point p
at iteration i of the algorithm is greater than or equal to the increase caused by that
point at a later iteration. As with MCA-LS, we also sort elements by the incremental
increase, which may allow the algorithm to exit the inner loop earlier. In most nontrivial instances of MCA, this additional sorting operation will not affect the complexity
of the algorithm (i.e., under the assumption that the time to compute EXBrf is greater
than lg(|L|), we make this same assumption in MCA-LS as well).

5 As
6

we include zero-starting in our definition of monotonic.
In our case, the uniform matroid consists of all subsets of L of size B or less.

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:23

ALGORITHM 3 : (MCA-GREEDY-MONO)
INPUT: Monotonic reward function rf, set O of observations, real number B > 0, explanation
function distribution efd, possible partner set L, real number  > 0
OUTPUT: Set B ⊂ S
(1)
(2)
(3)
(4)

(5)

Initialize B = ∅ and B∗ = L
For each pi ∈ B∗ , set inci = 0
Set last val = EXBrf (B, efd)
While |B| ≤ B
(a) pb est = null, cur inc = 0
(b) For each pi ∈ B∗ , do the following
i. If inci < cur inc, break loop and goto line 3.
ii. Let inci = EXBrf (B ∪ { p}, efd) − last val
iii. If inci ≥ cur inc then cur inc = inci and pb est = p
(c) B = B ∪ { pb est}, B∗ = B∗ − { pb est }
(d) Sort B∗ in descending order by inci.
(e) Set last val = EXBrf (B, efd)
Return B

P ROPOSITION 5.3. The complexity of MCA-GREEDY-MONO is O(B · |L| · F(efd))
where F(efd) is the time complexity to compute EXBrf (B, efd) for some set B ⊆ L of
size B. In the first iteration of the algorithm, we have the next corollary.
e
C OROLLARY 5.2. MCA-GREEDY-MONO is an ( e−1
)-approximation algorithm for
MCA (when the reward function is monotonic).
e
)-approximation algoIn addition to the fact that MCA-GREEDY-MONO is an ( e−1
rithm for MCA, it also provides the best possible approximation ratio unless P = NP.
This is done by a reduction of MAX-K-COVER [Feige 1998].

T HEOREM 5.5. MCA-GREEDY-MONO provides the best approximation ratio for
MCA (when the reward function is monotonic) unless P = NP.
The following example illustrates how MCA-GREEDY-MONO works.
Example 5.3. Consider the situation from Example 5.2, where the drugenforcement agents are attempting to locate illegal drug labs. Suppose they want to
locate the labs, but use the crf reward function, which is monotonic and zero-starting.
They use the cardinality requirement B = 3 in MCA-GREEDY-MONO. After the first
iteration of the loop at line 3, the algorithm selects point p48 as it affords an incremental increase of 0.417. On the second iteration, it selects point p46 , as it also affords
an incremental increase of 0.417, so last val = 0.834. Once p46 is considered, the next
point considered is p33 , which had a previous incremental increase (calculated in the
first iteration) of 0.25, so the algorithm can correctly exit the loop to select the final
element. On the last iteration of the outer loop, the algorithm selects point p35 , which
gives an incremental increase of 0.166. Now the algorithm has a set of cardinality
3, so it exits the outer loop and returns the set B = { p48 , p46 , p35 }, which provides an
expected agent benefit of 1, which is optimal. Note that this would not be an optimal
solution for the scenario in Example 5.2 which uses prf as p35 would incur a penalty
(which it does not when using crf as in this example).
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:24

P. Shakarian et al.

6. IMPLEMENTATION AND EXPERIMENTS

In this section, we describe prototype implementations and experiments for solving
the OAS and MCA problems. For OAS, we create an MILP for the crf case and reduce
the number of variables with the techniques we presented in Section 4. For MCA, we
implement both the MCA-LS and MCA-GREEDY-MONO.
We carried out all experiments for MCA on an Intel Core2 Q6600 processor running
at 2.4 GHz with 8GB of memory available, using code written in Java 1.6; all runs
were performed in Windows 7 Ultimate 64-bit using a 64-bit JVM, and made use of a
single core. We also used functionality from the previously implemented SCARE software [Shakarian et al. 2009] to calculate, for example, the set of all possible partners
L and to perform preprocessing (see the discussion in Section 4.2).
Our experiments are based on 21 months of real-world Improvised Explosive Device
(IED) attacks in Baghdad7 [Shakarian et al. 2009]. The IED attacks in this 25 × 27
km region constitute our observations. The data also includes locations of caches associated with those attacks discovered by U.S. forces. These constitute partner locations.
We used data from the International Medical Corps to define feasibility predicates
based on ethnic makeup, location of U.S. bases, and geographic features. We overlaid
a grid of 100m × 100m cells, about the size of a standard U.S. city block. We split
the data into two parts; the first 7 months of data were used as a “training” set to
learn the [α, β] parameters and the next 14 months of data were used for the observations. We created an explanation function distribution based on multiple runs of the
GREEDY-KSEP-OPT2 algorithm described in Shakarian et al. [2010].
6.1. OAS Implementation

We now present experimental results for the version of OAS, with the crf reward function, based on the constraints in Definition 4.3 and variable reduction techniques of
Section 4.4. First, we discuss promising real-world results for the calculation of the
reduced partner set L ∗ , described in Definition 4.5. Then, we show that an optimal
adversarial strategy can be computed quite tractably using the methods discussed in
Section 4.4. Finally, we compare our results to a set of real-world data, showing a
significant decrease in the adversary’s expected detriment across various parameter
settings. Our implementation was written on top of the QSopt8 MILP solver and used
900 lines of Java code.
Reduced Partner Set. As discussed in Section 4.2, producing an optimal adversarial
strategy for any reward function relies heavily on efficiently solving a (provably worstcase intractable) integer linear program. The number of integer variables in these
programs is based solely on the size of the partner set L; as such, the ability to experimentally solve OAS relies heavily on the size of this set.
Our real-world data created a partner set L with cardinality 22,692. We then applied the method from Definition 4.5 to reduce this original set L to a smaller subset of
possible partners L ∗ , while retaining the optimality of the final solution. This simple
procedure, while dependent on the explanation function distribution efd as well as the
cutoff distance for crf, always returned a reduced partner set L ∗ with cardinality between 64 and 81. This represents around a 99.6% decrease in the number of variables
required in the subsequent integer linear programs!
Figure 4 provides more detailed accuracy and timing results for this reduction. Most
importantly, regardless of parameters chosen, our real-world data is reduced by orders
7 Attack
8

and cache location data provided by the Institute for the Study of War.
http://www2.isye.gatech.edu/˜wcook/qsopt/index.html

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:25

Fig. 4. The size of the reduced partner set L ∗ (left) and the time required to compute this reduction (right).
Regardless of parameters chosen, we see a 99.6% decrease in possible partners (as well as integer variables
in our linear program) in under 3 minutes.

of magnitude across the board. Of note, we see a slight increase in the size of the reduced set L ∗ as the size of the explanation function distribution efd increases. This
can be traced back to the strict inequality in Definition 4.7. As we increase the number of nontrivial explanation functions in efd, the number of nonzero constants consti
increases. This results in a higher number of candidates for the intermediary set L ∗∗ .
We see a similar result as we increase the penalizing cutoff distance. Again, this is a
factor of the strict inequality in Definition 4.7 in conjunction with a higher fraction of
nonzero consti constants.
Interestingly, Figure 4 shows a slight decrease in the runtime of the reduction as
we increase the penalizing cutoff distance. Initially, this seems counterintuitive; with
more nontrivial constants consti , the construction of the intermediary set L ∗∗ requires
more work. However, this extra work pays off during the computation of the final reduced set L ∗ . In our experiments, the reduction from L to L ∗∗ took less time than the
final reduction from L ∗∗ to L ∗ . This is due to frequent short circuiting in the computation of the right-hand side of the conjunction during L ∗∗ creation. As we increase the
penalizing cutoff distance, the size of L ∗∗ actually decreases, resulting in a decrease in
the longer computation of L ∗ . As seen before, this decrease in L ∗∗ did not correspond
to a decrease in the size of L ∗ .
Optimal Adversarial Strategy. Using the set L ∗ , we now present results to find an optimal adversarial strategy using δ-core optimal explanations. This is done by minimizing the MILP of Section 4.4, then feeding this solution into BUILD-STRAT. Since we do
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:26

P. Shakarian et al.

Fig. 5. Expected detriment of the optimal adversarial strategy (left, lower is better) and the runtime of the
integer linear program required to produce this strategy in milliseconds (right). Note the smooth decrease
toward zero detriment as k increases, corresponding with a near-linear increase in total runtime.

not know the value of δ in advance, we must perform this combined operation multiple
times, choosing the best (lowest expected detriment) adversarial strategy as optimal.
A note on the lower bound for δ: As shown by Shakarian et al. [2009], finding a
minimum-cardinality explanation is NP-hard. Because of this, it is computationally
difficult to find a tight lower bound for δ. However, this lower bound can be estimated
empirically. For instance, for our set of real-world data from Baghdad, an explanation
of cardinality below 14 has never been returned, even across tens of thousands of runs
of GREEDY-KSEP-OPT2. Building on this strong empirical evidence, the minimum δ
used in our experiments is 14.
Figure 5 shows both timing and expected detriment results as the size of the explanation function |efd| and maximum strategy cardinality k are varied. Note that a lower
expected detriment is better for the adversary, with zero representing no probability
of partner discovery by the reasoning agent. As the adversary is allowed larger and
larger strategies, its expected detriment smoothly decreases toward zero. Intuitively,
as the number of nontrivially-weighted explanation functions in efd increases, the expected detriment increases as well. This is a side-effect of a larger |efd| allowing the
reasoning agent to cover a larger swath of partner locations.
Recall that, as the maximum k increases, we must solve linear programs for each
δ ∈ {klow , k}. This is mirrored in the timing results in Figure 5, which assumes
klow = 14. As k increases, we see a near-linear increase in the total runtime of the
set of integer programs. Due to the reduced set L ∗ , we are able to solve dozens of
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:27

Fig. 6. Expected number of caches found when the adversary uses our strategy instead of the current
state-of-the-art (left, lower is better). Relative improvement of the OAS strategy versus the current stateof-the-art (right, higher is better). We assume the reasoning agent is using the Spatial Cultural Abductive
Reasoning Engine (SCARE) to provide information on cache locations.

integer programs in less than 800ms; were we to use the unreduced partner set L,
this would be intractable. Note that the runtime graph includes that of BUILD-STRAT
which always ran in under sixteen milliseconds.
OAS Performance with respect to Real-World Adversarial Strategy. Figure 6 compares the
expected number of caches found under the current, state-of-the-art—IED cache locations based on 21 months of real-world data from Baghdad, Iraq—against the OAS
strategy proposed in this article. We hold the cardinality of the adversary’s solution
(i.e., the number of possible caches) to 14 to match the real-world data. We assume
the reasoning agent uses the Spatial Cultural Abductive Reasoning Engine (SCARE)
introduced in Shakarian et al. [2009] to provide partner locations to these attacks.
SCARE is the state-of-the-art method for finding IED caches.
When tested against real-world adversaries based on real-world Baghdad data, OAS
significantly outperforms what adversaries have done so far in the real world (fortunately this is balanced by later experiment results showing that MCA-LS and MCAGREEDY-MONO significantly outperform SCARE). The expected number of caches
found by SCARE against an opponent using OAS is significantly lower than against
present-day insurgents in Iraq. For instance, while SCARE (using a cutoff distance
of 100 meters) detects 1.6 of the 14 possible caches against a real-world adversary, it
is expected to detect only 0.11 of the caches against an adversary using OAS. This
roughly order of magnitude improvement is seen across all five cutoff distances, from
a minimum of approximately 7x at a cutoff distance of 200m to a maximum of over 31x
at a distance of 500m. Thus, OAS significantly improves the adversary’s performance.
6.2. MCA Implementation

First, we briefly discuss an implementation of the naive MCA algorithm discussed in
Section 5.2. Next, we provide promising results for the MCA-LS algorithm using the
prf reward function. Finally, we give results for the MCA-GREEDY-MONO using the
monotonic crf reward function, and qualitatively compare and contrast the results
from both algorithms.
MCA-Naive. The naive, exact solution to MCA (considering all subsets of L with
agent bencardinality kB or more and picking the one which maximizes the expected
 
efit) is inherently intractable. This approach has a complexity O( |L|
),
and
is made
kB
worse by the large magnitude of the set L. In our experimental setup, we typically
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:28

P. Shakarian et al.

Fig. 7. The average size of the strategy recommended by MCA-LS decreases as the distance cutoff increases.
For these experiments, the minimum cardinality for a given explanation E considered is efd was 14, which
gives us a natural lower bound on the expected size of a strategy. Note the convergence to this bound at
cutoff distances at and above 300 meters.

saw |L| > 20,000; as such, for even the trivially small kB = 3, we must enumerate
and rank over a trillion subsets. For any realistic value of kB , this approach is simply
unusable. Luckily, we will see that both MCA-LS and MCA-GREEDY-MONO provide
highly tractable and accurate alternatives.
MCA-LS. In sharp contrast to the naive algorithm described previously, the MCALS algorithm provides (lower-)bounded approximate results in a tractable manner.
Interestingly, even though MCA-LS is an approximation algorithm, in our experiments
on real-world data from Baghdad using the prf reward function, the algorithm returned strategies with an expected benefit of 1.0 on every run. Put simply, on our
practical test data, MCA-LS always completely maximized the expected benefit. This
significantly outperforms the lower-bound approximation ratio of 1/3. We would also
like to point out that this is the first implementation (to the best of our knowledge) of
the nonmonotonic submodular maximization approximation algorithm of Feige et al.
[2007].
Since the expected benefit was maximal for every strategy B returned, we move to
analyzing the particular structure of these strategies. Figure 7 shows a relationship
between the size |B|, the cutoff distance dist, and the cardinality of the expectation
function distribution |efd|. Recall that prf penalizes any strategy that does not completely cover its input set of observations; as such, intuitively, we see that MCA-LS
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:29

Fig. 8. The runtime of MCA-LS decreases as the penalizing cutoff distance is relaxed. Note the relation to
Figure 7; intuitively, larger recommended strategies tend to take longer to compute.

returns larger strategies as the penalizing cutoff distance decreases. If the algorithm
can cover all possible partners across all expectation functions, it will not receive any
penalty. Still, even when dist is 100m, the algorithm returns B only roughly twice
the size as minimum-sized explanation found by GREEDY-KSEP-OPT2 (which, based
on the analysis of Shakarian et al. [2010], is very close to the minimum possible explanation). As the cutoff dist increases, the algorithm returns strategies with sizes
converging, generally, to a baseline: the smallest-sized explanation found by the algorithm of Shakarian et al. [2010], |E|. This is an intuitive soft lower bound; given
enough leeway from a large distance dist, a single point will cover all expected partners. This is not a strict lower bound in that, given two extremely close observations
with similar expected partners, a single point may sufficiently cover both.
In Figure 8, we see results comparing overall computation time to both the distance
dist and the cardinality of efd. For more strict (i.e., smaller) values of dist, the algorithm (which, under prf, is penalized for all uncovered observations across efd) must
spend more time forming a strategy B that minimizes penalization. Similarly, as the
distance constraint is loosened, the algorithm completes more quickly. Finally, an increase in |efd| results in higher computational cost; as explained in Proposition 5.1,
this is due to an increase in F(efd), the time complexity of computing EXBrf (B, efd).
Comparing these results to Figure 7, we see that the runtime of MCA-LS is correlated
to the size of the returned strategy B.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:30

P. Shakarian et al.

Fig. 9. Expected benefit of the strategy returned by MCA-GREEDY-MONO as the budget increases, with
|efd| = 10 (left) and |efd| = 100 (right). Note the decrease in expected benefit due to the increase in |efd|.
Similarly, note the increase in expected benefit given a larger cutoff distance.

MCA-GREEDY-MONO. As discussed in Section 5.3, MCA-GREEDY-MONO provides
tighter approximation bounds than MCA-LS at the cost of a more restrictive (monotonic) reward function. For these experiments, we used the monotonic rf = crf. Recall
that a trivial solution to MCA given a monotonic reward function is B = L; as such,
MCA-GREEDY-MONO uses a budget B to limit the maximum size |B|  |L|. We varied
this parameter B ∈ {1, . . . , 28}.
Figure 9 shows the expected benefit EXBrf (B, efd) increases as the maximum allowed |B| increases. In general, the expected benefit of B increases as the distance
constraint dist is relaxed. However, note the points with B ∈ {3, . . . , 9}; we see that
dist ≤ 100 performs better than dist > 100. We believe this is an artifact of our realworld data. Finally, as |efd| increases, the expected benefit of B converges more slowly
to 1.0. This is intuitive, as a wider spread of possible partner positions will, in general,
require a larger |B| to provide coverage.
Figure 10 shows that the runtime of MCA-GREEDY-MONO increases as predicted by
Proposition 5.1. In detail, as we linearly increase budget B, we also linearly increase
the runtime of our F(efd) = EXBrf (B, efd). In turn, the overall runtime O(B·|L|· F(efd))
increases quadratically in B, for our specific reward function. Finally, note the increase
in runtime as we increase |efd| = 10 to |efd| = 100. Theoretically, this increases F(efd)
linearly; in fact, we see almost exactly a ten-fold increase in runtime given a tenfold
increase in |efd|.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:31

Fig. 10. Runtime of MCA-GREEDY-MONO as the budget increases, with |efd| = 10 (left) and |efd| = 100
(right). Note the increase in runtime due to the extra determinism of a larger efd.

MCA Algorithms and SCARE. We now compare the efficacy of the two MCA algorithms
proposed in this article to SCARE [Shakarian et al. 2009] which represents the current state-of-the-art as far as IED cache detection is concerned. Again, our experiments are based on real-world data from Baghdad, Iraq. For these experiments, we
average results across 100 runs of SCARE; as such, we hold |efd| = 100 static for the
MCA-based algorithms. Figure 11 plots the average number of predicted points within
500 meters of an actual cache for both MCA-LS and MCA-GREEDY-MONO. SCARE,
plotted as a horizontal line, predicts an average of 7.87 points within 500 meters of
caches. MCA-LS finds over twice as many points at low penalizing cutoff distances,
and steadily converges to SCARE’s baseline as the penalizing distance increases (as
expected). As shown earlier in Figure 7, MCA-LS tends to find larger strategies given
a smaller penalizing cutoff distance; in turn, these larger strategies yield more close
points to actual caches. MCA-GREEDY-MONO shows similar behavior; as we increase
the allowable budget (i.e., maximum strategy size), more points are within 500 meters
of a real-world cache location. Thus, MCA-LS and MCA-GREEDY-MONO both outperform SCARE, enabling more caches to be discovered.
We note that while the number of points in the strategy close to a real-world
cache location is higher in the MCA-based algorithms than SCARE, the fraction
of close points stays consistently close. SCARE returns a solution of size 14, with
approximately half (7.87/14 ≈ 56%) of these points within 500 meters of cache.
Compare this to, for instance, MCA-LS with a penalizing cutoff distance of 300 meters;
for these settings, the algorithm returns an average strategy size of 18, with 11 points
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:32

P. Shakarian et al.

Fig. 11. Expected number of points within 500 meters of an actual cache returned by MCA-LS (left) and
MCA-GREEDY-MONO (right) compared against an agent using SCARE (higher is better). Note that the
SCARE software always returns an explanation of size 14, while both MCA algorithms benefit from the
ability to adjust this explanation size.

(approximately 60%) within 500 meters of a cache location. This behavior is a product
of the strategy size flexibility built into the MCA-based algorithms, and is beneficial
to the reasoning agent. For example, assume the minimal solution to a problem is
of size 2 and the reasoning agent has a budget of size 4. Now assume SCARE finds
1/2 = 50% of the points near caches, while MCA-GREEDY-MONO finds 2/4 = 50% of its
points near caches. Both algorithms returned the same fraction of points near caches;
however, the reasoning agent will spend its budget of 4 resources more effectively
under MCA-GREEDY-MONO, instead of wasting two of its resources under the strategy
provided by SCARE.
7. RELATED WORK

Geospatial abduction was introduced in Shakarian et al. [2010] and used to infer a
set of partner locations from a set of observations, given a feasibility predicate and
an interval [α, β] ⊆ [0, 1]. The authors developed exact and approximate algorithms
for GAPs. In particular, no adversary was assumed to exist there. In this article,
we study the case of geospatial abduction where there is an explicit adversary who is
interested in ensuring that the agent does not detect the partner locations. This is
the case with real-world serial killers and insurgents who launch IED attacks. In this
article, we develop a game-theoretic framework for reasoning about the best strategy
that an adversary might adopt (based on minimizing the adversary’s detriment) and
the best strategy that the agent could adopt to counter the adversary’s strategy. All
this is uncharted territory and represents a novel contribution of this article. In fact,
everything from Section 3 onwards in this article is new.
Although abduction [Peirce 1955] has been studied in a variety of different
contexts—medicine [Peng 1986; Peng and Reggia 1990], fault diagnosis [Console et al.
1991], belief revision [Pagnucco 1996], database updates [Console et al. 1995; Kakas
and Mancarella 1990], and AI planning [do Lago Pereira and de Barros 2004]—we
are not aware of any work in abduction where an adversary selects a ground-truth
explanation with respect to a probability distribution over explanation functions that
an agent would consider. Additionally, we are not aware of any related work dealing
with the problem of an agent finding elements of an adversarially selected explanation
(with respect to a probability distribution). However, we do believe that many of the
techniques introduced here for adversarial geospatial abduction may be generalized to
other forms of abduction as well.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:33

In the field of operations research, the facility location problem [Stollsteimer 1963]
is a well-studied problem dealing with optimal placement of facilities in a plane, network, or multidimensional space. The facilities must be positioned to optimize some
sort of distance to the “demand points”, most likely resembling consumers of the items
being produced at the facility. In Shakarian et al. [2010], the authors outline numerous
differences between facility location and geospatial abduction (difference in optimality
criteria, use of feasibility predicate, nonconvexitivity of covers, etc.), even when no adversaries are present. However, facility location with adversaries has not really been
studied, and that is the focus of this article.
Similar motivation exists in the field of (multi-)agent security, where the central
idea is to protect a set of targets from adversaries. These games are typically modeled
on top of graphs, with agents and adversaries competing to protect or penetrate a set of
targets. Paruchuri et al. [2006] represent the adversary’s behavior through a probability distribution over states, indicating the probability of that state being targeted; no
real graph structure is considered, much less a geospatial model. Agmon et al. [2008,
2009] consider an environment with more hidden information, and attempt to detect
adversarial penetrations across the routes (represented as paths on a graph) of patrolling agents. Pita et al. [2009] solve Stackelberg (leader-follower) games under the
assumption of bounded reasoning rationality, again on a graph network. Dickerson
et al. [2010] explores protecting dynamic targets from rational adversaries on realworld road networks.
8. CONCLUSION

Geospatial abduction was introduced in Shakarian et al. [2010] and used to infer a set
of partner locations from a set of observations, given a feasibility predicate and reals
α ≥ 0, β > 0. Shakarian et al. [2010] developed exact and approximate algorithms for
GAPs. In particular, no adversary was assumed to exist there. In this article, we study
the case of geospatial abduction where there is an explicit adversary who is interested
in ensuring that the agent does not detect the partner locations. This is the case with
real-world serial killers and insurgents who launch IED attacks. We develop a gametheoretic framework for reasoning about the best strategy that an adversary might
adopt (based on minimizing the adversary’s detriment) and the best strategy that the
agent could adopt to counter the adversary’s strategy.
We consider the adversarial geospatial abduction problem to be a two-player game:
an agent (“good” guy) and an adversary (“bad” guy). The adversary is attempting to
cause certain observable events to occur (e.g., murders or IED attacks) but make it
hard to detect the associated set of partner locations (e.g., location of the serial killer’s
home/office, or the locations of weapons caches supporting the IED attacks). We use
an axiomatically-defined “reward function” to determine how similar two explanations
are to each other. We study the problems of finding the best response for an agent and
adversary to a mixed strategy (based on a probability distribution over explanations)
of the opponent. We formalize these problems as the Optimal Adversarial Strategy
(OAS) and Maximal Counter-Adversary strategy (MCA) problem. We show both OAS
and MCA to be NP-hard and provide exact and approximate methods for solving them.
When reasoning about the best possible strategy for the adversary, we present a
mixed-integer-programming-based algorithm and show that the MILP in question can
be greatly reduced through the elimination of many variables using the concept of a
δ-core explanation. Our experiments are carried out on real-world data about IED
attacks over a period of 21 months in Baghdad.
When reasoning about the best possible strategy for the adversary, we present two
algorithms. The MCA-LS algorithm is very general and leverages submodularity of reward functions. The MCA-GREEDY-MONO algorithm assumes the reward function is
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

34:34

P. Shakarian et al.

monotonic. Both MCA-LS and MCA-GREEDY-MONO are highly accurate and have very
reasonable time frames. Though MCA-GREEDY-MONO is slightly faster than MCALS, we found that on every single run, MCA-LS found the exact optimal benefit even
though its theoretical lower-bound approximation ratio is only 1/3, a truly remarkable performance. As MCA-LS does not require any additional assumptions and as its
running time is only slightly slower than that of MCA-GREEDY-MONO, we believe this
algorithm has a slight advantage.
ELECTRONIC APPENDIX

The electronic appendix for this article can be accessed in the ACM Digital Library.
ACKNOWLEDGMENTS
We thank the reviewers for their many excellent comments that have significantly improved the article.

REFERENCES
A GMON, N., K RAUS, S., AND K AMINKA , G. 2008. Multi-robot perimeter patrol in adversarial settings. In
Proceedings of the IEEE International Conference on Robotics and Automation (ICRA’08). 2339–2345.
A GMON, N., K RAUS, S., K AMINKA , G., AND S ADOV, V. 2009. Adversarial uncertainty in multi-robot patrol. In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI’09).
1811–1817.
C HARNES, A. AND C OOPER , W. 1962. Programming with linear fractional functionals. Naval Res. Logistics
Quart. 9, 3, 163–297.
C ONSOLE , L., P ORTINALE , L., AND D UPR É , D. T. 1991. Focusing abductive diagnosis. AI Comm. 4, 2–3,
88–97.
C ONSOLE , L., S APINO, M. L., AND D UPR É , D. T. 1995. The role of abduction in database view updating.
J. Intell. Info. Syst. 4, 3, 261–280.
D ICKERSON, J., S IMARI , G., S UBRAHMANIAN, V., AND K RAUS, S. 2010. A graph-theoretic approach to
protect static and moving targets from adversaries. In Proceedings of the 9th International Conference
on Autonomous Agents and Multiagent Systems (AAMAS’10). 299–306.
DO L AGO P EREIRA , S. AND DE B ARROS, L. N. 2004. Planning with abduction: A logical framework to explore extensions to classical planning. Advances in Artificial Intelligence: In Proceedings of the Brazilian
Symposium on Artificial Intelligence (SBIA). 106–118.
D YER , M., G OLDBERG, L. A., G REENHILL , C., AND J ERRUM , M. 2000. On the relative complexity of
approximate counting problems. Tech. rep., Coventry, UK.
F EIGE , U. 1998. A threshold of ln n for approximating set cover. J. ACM 45, 4, 634–652.
F EIGE , U., M IRROKNI , V. S., AND V ONDRAK , J. 2007. Maximizing non-monotone submodular functions.
In Proceedings of the 48th Annual IEEE Symposium on Foundations of Computer Science (FOCS’07).
IEEE Computer Society. 461–471.
H UNT III, H. B., M ARATHE , M. V., R ADHAKRISHNAN, V., AND S TEARNS, R. E. 1998. The complexity of
planar counting problems. SIAM J. Comput. 27, 4, 1142–1167.
J OHNSON, D. 1982. The NP-completeness column: An ongoing guide. J. Algorithms 3, 2, 182–195.
K AKAS, A. C. AND M ANCARELLA , P. 1990. Database updates through abduction. In Proceedings of the
International Conference on Very Large Databases (VLDB).
K ARMARKAR , N. 1984. A new polynomial-time algorithm for linear programming. Combinatorica 4, 4,
373–395.
L EYTON -B ROWN, K. AND S HOHAM , Y. 2008. Essentials of Game Theory: A Concise, Multidisciplinary
Introduction. Morgan and Claypool Publishers.
M ASUYAMA , S. T. AND I BARAKI , T. H. 1981. The computational complexity of the m-center problems on the
plane. Trans. IECE Japan E84, 57–64.
N EMHAUSER , G., W OLSEY, L., AND F ISHER , M. 1978. An analysis of the approximations for maximizing
submodular set functions. Math. Program. 14, 265–294.
PAGNUCCO, M. 1996. The role of abductive reasoning within the process of belief revision. Ph.D. thesis,
Basser Department of Computer Science, University of Sydney, Australia.

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Adversarial Geospatial Abduction Problems

34:35

PARUCHURI , P., T AMBE , M., O RD Ó ÑEZ , F., AND K RAUS, S. 2006. Security in multiagent systems by policy
randomization. In Proceedings of the 5th International Conference on Autonomous Agents and Multiagent Systems (AAMAS’06).
P EIRCE , C. S. 1955. Philosophical Writings of Peirce, Selected and Edited with an Introduction by Justus
Buchler. Dover Publications, New York.
P ENG, Y. AND R EGGIA , J. A. 1990. Abductive Inference Models for Diagnostic Problem-Solving. Springer,
New York.
P ITA , J., J AIN, M., O RD Ó ÑEZ , F., T AMBE , M., K RAUS, S., AND M AGORI -C OHEN, R. 2009. Effective solutions
for real-world stackelberg games: When agents must deal with human uncertainties. In Proceedings of
the 8th International Conference on Autonomous Agents and Multiagent Systems (AAMAS’09). 369–376.
R OSSMO, D. K. AND R OMBOUTS, S. 2008. Geographic profiling. In Enviromental Criminology and Crime
Analysis, R. Wortley and L. Mazerolle Eds., 136–149.
S HAKARIAN, P., S UBRAHMANIAN, V., AND S APINO, M. L. 2009. SCARE: A case study with Baghdad. In
Proceedings of the 3rd International Conference on Computational Cultural Dynamics. AAAI.
S HAKARIAN, P., S UBRAHMANIAN, V., AND S APINO, M. L. 2010. GAPs: Geospatial Abduction Problems.
ACM Trans. Intell. Syst. Technol. http://www.di.unito.it/ mlsapino/Conferma-I-fascia/TIST.pdf.
S TOLLSTEIMER , J. F. 1963. A working model for plant numbers and locations. J. Farm Econ. 45, 3, 631–645.
U.S. A RMY. 1994. Intelligence Preparation of the Battlefiled (US Army Field Manual) (FM 34-130 Ed).
P ENG, Y. J. R. 1986. Plausibility of diagnostic hypotheses. In Proceedings of the 5th National Conference on
Artificial Intelligence (AAAI’86). 140–145.
Received January 2011; revised July 2011; accepted August 2011

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 2, Article 34, Publication date: February 2012.

Power Grid Defense Against Malicious Cascading Failure
Paulo Shakarian

Hansheng Lei

Roy Lindelauf

Dept. EECS and
Network Science Center
U.S. Military Academy
West Point, NY, 10996

Dept. EECS and
Network Science Center
U.S. Military Academy
West Point, NY, 10996

Netherlands Defence
Academy
Faculty of Military Science
Military Operational Art and
Science

arXiv:1401.1086v1 [cs.CR] 6 Jan 2014

paulo[at]shakarian.net hansheng.lei[at]usma.edu

rha.lindelauf.01[at]nlda.nl

ABSTRACT

1.

An adversary looking to disrupt a power grid may look
to target certain substations and sources of power generation to initiate a cascading failure that maximizes the number of customers without electricity. This is particularly
an important concern when the enemy has the capability
to launch cyber-attacks as practical concerns (i.e. avoiding disruption of service, presence of legacy systems, etc.)
may hinder security. Hence, a defender can harden the security posture at certain power stations but may lack the
time and resources to do this for the entire power grid. We
model a power grid as a graph and introduce the cascading failure game in which both the defender and attacker
choose a subset of power stations such as to minimize (maximize) the number of consumers having access to producers
of power. We formalize problems for identifying both mixed
and deterministic strategies for both players, prove complexity results under a variety of different scenarios, identify tractable cases, and develop algorithms for these problems. We also perform an experimental evaluation of the
model and game on a real-world power grid network. Empirically, we noted that the game favors the attacker as he
benefits more from increased resources than the defender.
Further, the minimax defense produces roughly the same
expected payoff as an easy-to-compute deterministic load
based (DLB) defense when played against a minimax attack
strategy. However, DLB performs more poorly than minimax defense when faced with the attacker’s best response to
DLB. This is likely due to the presence of low-load yet highpayoff nodes, which we also found in our empirical analysis.

Rapid cascading failure in a power grid caused by a succession of overloading lines can lead to very large outages,
as observed in the United States in 2003 [1]. Studies on cascading failure [7, 8, 16] have illustrated that such a failure
can be initiated with only a small number of initial node failures. Further, power grid infrastructure is often particularly
vulnerable with respect to cyber-security due to a variety of
issues, including the use of legacy and proprietary computer
hardware and software [26].
In this paper, we extend the work on cascading failure
models to a two-player game where an attacker attempts to
create a cascade that maximizes the number of customers
without power while the defender defends key nodes to avoid
a major outage. In Section 2, we introduce an extension to
the failure model of [8] to not only consider the attacker and
defender, but also the different types of nodes in the power
grid (i.e. power generation vs. power consumers). In Section 3, we explore the computational complexity of finding
deterministic best-response strategies for the attacker and
defender under several different scenarios depending on the
relative number of resources each player has and whether
the opponent has a deterministic or mixed strategy. Here we
found that, in general, these problems are NP-hard, though
we do identify some tractable cases. In Section 4, we explore heuristic algorithms for finding determinsitic “best responses” as well as minimax mixed strategies. We introduce
a “high-load” strategy for defense (based on the observations of [8]), greedy heuristics for deterministic strategies,
and a double-oracle approach based on [15] for finding a
mixed strategy. In Section 5 we perform experiments on a
real-world dataset of a power grid [20] and find that this
game seems to favor the attacker as he benefits more from
increased resources than the defender. Further, our experiments revealed that the minimax defense produces roughly
the same expected payoff as an easy-to-compute deterministic load based (DLB) defense when played against a minimax attack strategy, though the load based defense does
more poorly than minimax when faced with the attacker’s
best response to DLB. This is likely due to the presence
of low-load yet high-payoff nodes, which we also found in
our empirical analysis of the model. Finally, related work is
discussed in Section 6.

Categories and Subject Descriptors
I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence

General Terms
Algorithms Security

Keywords
power grid defense, game theory, complex networks

INTRODUCTION

2.

TECHNICAL PRELIMINARIES

Consider a power-grid network modeled as an undirected
graph G = (V, E). Let Vsrc , Vld ⊆ V be source (producers of
power) and load (consumers of power) on the network. We
shall use the notation discVld ,Vsrc (G) to denote the number
of nodes in Vld which are not connected to any node in Vsrc
in graph G. Let G be the set of all subgraphs of G. For
a given node i, let NG (i) be the set of nodes in Vsrc − {i}
that are closest to that node (based on path length in G).
From this, we define edge load (similar to the idea of edge
betweenness [25]).
Definition 2.1 (Edge Load). Given edge ij ∈ E, the
edge load, loadG (ij) is defined as follows:
X X
σG (s, t|ij)
,
loadG (ij) =
|N
G (t)| σG (s, t)
t∈V
ld

AT K = {S ∈ 2V : |S| ≤ ka }
We now have all of the components to define the payoff
function.
Definition 2.3 (Payoff Function). Given initial network G = (V, E) with edge capacities cij (G), attack (defend)
strategy Va (Vd ), the payoff function is defined by

s∈NG (t)

where σG (s, t) is the number of shortest paths between s, t ∈
V and σG (s, t|ij) is the subset of these paths that pass through
edge ij ∈ E.
Starting from initial network G0 = (V0 , E0 ) we use cij to
denote the capacity edge ij ∈ E0 . In a real-world setting,
we would expect to have this information. However, in this
paper, we use the following proxy (similar to [8]).
cij (G0 ) = (1 + α)loadG0 (ij)
where α is a non-negative real that specifies the excess capacity available on that line. We shall refer to α as the
capacity margin. We assume that an edge ij ∈ E fails in
G = (V, E), with E ⊂ E0 , if loadG (ij) > cij (G0 ). Once
nodes (and adjacent edges) in V0 are removed from G0 , this
results in a change of shortest paths between sources and
loads, hence more edges will potentially fail. This cascading
power failure is modeled by a “failure” operator denoted with
F (based on the failure model of [8] - though we note that
our model is a new contribution due to the consideration of
source and load nodes) that maps networks to networks. We
define it as follows.
Definition 2.2 (Failure Operator). The failure operator, F : G → G, is defined as follows:
F((V, E)) = (V, {ij ∈ E|load(V,E) (ij) ≤ cij (G0 )})
Intuitively, one application of the failure operator removes
all edges that have exceeded their maximum capacity. We
can define multiple applications of this operator as follows:
Fi (G) =

attacker is unable to destroy them - though these nodes can
be taken offline as a result of the cascading failure1 . The attacker can destroy ka nodes while the defender can harden
kd nodes. Thus the strategy space of both the attacker and
defender consists of all subsets Va , Vd ⊆ V of size |Va | ≤ ka
(|Vd | ≤ kd respectively). We denote these strategy spaces
by AT K (DEF respectively), i.e., if we allow the attacker
to consider all strategies of size ka or less we have:

(
G
F(Fi−1 (G))

if i = 0
otherwise

Clearly, there must exist a fixed point that is reached in
no more than |E| + 1 applications of F. Hence, we shall use
the following notation:
F∗ (G) = Fi (G) s.t. Fi (G) = Fi+1 (G)
We now consider two agents: an attacker and a defender.
The attacker’s strategy is to destroy nodes (and their adjacent edges) in an effort to cause a cascading failure that
maximizes the number of load nodes (Vld ) that are disconnected from all source nodes (Vsrc ). Meanwhile, the defender’s strategy is to harden certain nodes such that the

pG (Va , Vd ) = discVld ,Vsrc (F∗ ((V − (Va − Vd ), E)).
Now, in reality, the defender will have real-world limitations on the number of nodes (i.e. substations) he may
harden. For instance, with regard to smart grid defense, applying the most up-to-date patches on all systems may not
be realistic as it could potentially require system down-time affecting customer service. Further, it would also likely not
make sense for the defender to only harden certain nodes
and ignore others. Hence, it is reasonable to consider a situation where the defender can only harden certain nodes
against attack (and may do so probabilistically - i.e. applying hardware or software updates according to a schedule). Therefore, we study mixed strategies. Such strategies will be specified by probability distributions Pra , Prd
for the attacker and defender respectively. We shall denote
the number of strategies assigned a non-zero probability as
|Pra |, |Prd |. We can define expected payoff as follows.
Definition 2.4 (Expected Payoff). Let Pra , Prd be
probability distributions over all subsets of V of sizes ka
(resp. kd ) or less. These probability distributions correspond
to a mixed strategy for the attacker and defender respectively.
Hence, given such probability distributions, the expected payoff can be computed as follows:
X
X
ExP(Pra , Prd ) =
Pra (Va )
Prd (Vd )pG (Va , Vd )
Va ∈2V

Vd ∈2V

In this work our goal is to find the minimax strategy for
the defender - that is the mixed strategy for the defender
that minimizes the attacker’s maximum expected payoff as well as deterministic “best responses” for both players
given the other’s strategy.

3.

COMPUTATIONAL COMPLEXITY

In this section, we analyze the computational complexity
of determining the best response for each of the agents to
a strategy of its opponent. First, we shall discuss the case
for finding a deterministic strategy for the defender and attacker. Then we shall explore the computational complexity
of finding a mixed strategy. We summarize our complexity
results in Table 3.
1

Note that this would likely be the case where the attack
and defense occurs in cyber-space, while the cascade occurs
in the physical world.

Opponent Strategy
Mixed w. 1 resource
Det. w. fewer resources
Det. w. greater resources
Mixed w. fewer resources
Mixed w. greater resources

Attacker
NP-Compl.
Thm. 3
NP-Compl.
Thm. 3
NP-Compl.
Thm. 3
NP-Compl.
Thm. 3
NP-Compl.
Thm. 3

Defender
PTIME
Prop. 3.2
PTIME
Prop. 3.1
NP-Compl.
Thm. 1
NP-Compl.
Thm. 2
NP-Compl.
Thm. 1

Table 1: Complexity Results for Finding a Deterministic Best Response
We frame the formal combinatorial problem of finding the
best-response for the defender as follows:
Grid-Defend Deterministic Best Response (GD-DBR)
INPUT: Network G = (V, E), attacker mixed strategy Pra
(where each option is of size no greater than ka ), natural
number kd , real numbers X, α
OUTPUT:
“Yes” if there exists a set Vd ⊆ V s.t. |Vd | ≤ kd
P
and Va ∈AT K Pra (Va )pG (Va , Vd ) ≤ X and “no” otherwise.
We shall study this case under several conditions. The
first, and easiest case is when Pra = 1 (the attacker uses a
deterministic strategy) and ka ≤ kd .
Proposition 3.1. When ka ≤ kd and |Pra | = 1 then
GD-DBR is solvable in polynomial time.
Proof. As the attacker plays only one strategy and the
defender can defend at least as many nodes as are being
attacked, the defender simply defends all the nodes in the
attacker’s strategy.
However, even with |Pra | = 1, the problem becomes NPhard in the case where ka > kd .
Theorem 1. When ka > kd then GD-DBR is NP-complete,
even when |Pra | = 1 and X is an integer.
Proof. Clearly, checking if a given deterministic defender
strategy Vd meets the requirements of the “output” of GDDBR can be completed in polynomial-time, providing membership in the class NP.
For NP-hardness consider the known NP-hard “set cover”
problem [11] that takes as input a natural number k, set
of elements S = {s1 , . . . , sn }, family of subsets of S, H =
{h1 , . . . , hm } and returns “yes” if there is a k-sized (or smaller)
subset of H s.t. their union is equal to S. We can embed
Set Cover into an instance of GD-DBR in polynomial time
with the following embedding: set ka = |H|, kd = k, X = 0,
α = |H| + |S|, create G = (V, E) as follows:
• For each h ∈ H create a node vh and for each s ∈ S create
node vs
• If s ∈ h, create edge (vh , vs ), for each ij ∈ E
• Set Vsrc = {vh |h ∈ H}, Vld = {vs |s ∈ S}, Va = V − Vld

Suppose, by way of contradiction (BWOC), that there is
a “yes” answer to Set Cover but a “no” answer to GD-DBR.
Consider set H 0 a subset of H that is the certificate for Set
Cover and the corresponding set V 0 = {vh |h ∈ H 0 } in the

instance of GD-DBR. Suppose the defender utilizes this as
a strategy. The attacker then effectively attacks the set V −
Vld −V 0 . Note that as the graph is bi-bipartite, this does not
cause any cascading failure. By the construction, each load
node must be connected to a source node, hence the number
of offline load nodes is X. This gives us a contradiction.
Suppose, BWOC, that there is a “yes” answer to GD-DBR
but a “no” answer to the corresponding instance of Set Cover.
Let V 0 be the certificate for GD-DBR. We note that any element of Vld ∩ V 0 in V 0 can be replaced by a neighboring
node from Vsrc without changing the size of this set and that
such a set would still allow for all load nodes to remain online, let V 00 be this new set. Consider the set {h|vh ∈ V 00 }.
By the contra-positive of the claim, this cannot be a cover
of all elements of S. However, this would also imply that
there is some element vs ∈ Vld that is not connected to V 00
meaning that it fails (as the attacker successfully destroys
all its neighbors). This means that the adversary has a payoff greater than 0 (which is what X was set to) – hence a
contradiction.
Hence, the presence of a more advantageous attacker is
a source of complexity. The next question would be if the
attacker’s behavior, i.e. deterministic vs. non-deterministic,
also affects the complexity of the problem, even if the defender has the advantage. First, let us examine the case
where the attacker has a mixed strategy with ka = 1.
Proposition 3.2. When ka = 1 then GD-DBR is solvable in polynomial time (w.r.t. |Pra |), even when |Pra | ≥ 0.
Proof. In this case, we can re-write the payoff function
as pG ({v}, Vd ) = 0 if v ∈ Vd and pG ({v}, Vd ) = pG ({v}, ∅)
otherwise. Let V 0 = ∪{Va ∈ AT K|Pra (Va ) > 0}. Note
that each element of V 0 is also a strategy the attacker plays
with a non-zero probability (as the attacker only plays singletons).
Hence, the expected payoff can be re-written as
P
0
v∈V −Vd Pra ({v})pG ({v}, ∅). Therefore, the best a defender can do is defend the top kd nodes in V 0 where
Pra ({v})pG ({v}, ∅) is the greatest - which can be easily computed in polynomial time and allows us to determine the
answer to GD-DBR.
However, if the defender is playing a mixed strategy with
ka > 1, then the problem again becomes NP-complete.
Theorem 2. When |Pra | > 1 and ka > 1, GD-DBR is
NP-complete, even when kd > ka and X is an integer.
Proof. NP-completeness mirrors that of Theorem 1. For
NP-hardness, we again consider a reduction from set-cover
(defined in the proof of Theorem 1. The embedding can
again be performed in polynomial time as follows: set ka =
maxs∈S |{h|s ∈ h}|, set kd = k, X = 0, α = |H| + |S|,
create G = (V, E), Vsrc , and Vld as per the construction in
Theorem 1. We then set up the mixed strategy as follows:
for each s ∈ S, let Vas = {h|s ∈ h} and Pra (Vas ) = 1/|S|.
Suppose, BWOC, that there is a “yes” answer to set cover
and a “no” answer to the instance of GD-DBR. Consider
set cover solution H ∗ and set Vd = {vh |h ∈ H ∗ }. Note
that Vd meets the cardinality requirement. Note that by
the construction, a source node becomes disconnected only
if all of the load nodes connected to it are attacked, hence
there is some node in the set Vld that is totally disconnected
under at least one attacker strategy - let vs be this node.

However, as set H ∗ covers S, then regardless of the attacker
strategy, there is always some node vh that is connected and
never attacked (giving the attacker a payoff of zero) - hence
a contradiction.
Suppose, BWOC, that there is a “yes” answer to GD-DBR
and a “no” answer to the instance of set cover. Consider GDDBR solution V 0 . We note that any element of Vld ∩ V 0 in
V 0 can be replaced by a neighboring node from Vsrc without
changing the size of this set and that such a set would still
allow for all load nodes to remain online, let V 00 be this
new set. Consider the set H ∗ = {h|vh ∈ V 00 }. Note that
|H ∗ | ≤ k. By the contra-positive, there must be at least
one element of S not covered by H ∗ . Let node vs be a node
associated with uncovered element s. As GD-DBR returned
“yes” then there is no attacker strategy where vs becomes
disconnected from some node in Vsrc . As attack strategy
Vas includes all nodes that are connected to vs , then at least
one of these nodes must be included in V 00 . Therefore, for
every node vs ∈ Vld there is some node vh ∈ Vld ∩ V 00 that is
connected to it, which means, by the construction, that H ∗
must cover all elements of S - a contradiction.
We now frame the formal problem for finding a deterministic best-response for the attacker below.
Grid-Attack Deterministic Best Response (GA-DBR)
INPUT: Network G = (V, E), defender mixed strategy Prd
(where each option is of size no greater than kd ), natural
number ka , real numbers X, α
OUTPUT:
“Yes” if there exists a set Va ⊆ V s.t. |Va | ≤ ka
P
and Vd ∈DEF Prd (Vd )pG (Va , Vd ) ≥ X and “no” otherwise.
In the case of ka = 1, this problem is solvable in polynomial time:
P simply consider each v ∈ V . The attacker
computes Vd ∈DEF Prd (Vd )pG ({v}, Vd ) until one is found
that causes the payoff to exceed or be equal to X. However,
for strategies of larger size, the problem becomes NP-hard,
regardless of the size of the defender strategy.
Fact 3.1. When ka = 1, GA-DBR is solvable in polynomial time (w.r.t. |Prd |).
Theorem 3. GA-DBR is NP-complete.
Proof. Clearly, a certificate consisting of a set Va ⊆ V
can be verified in polynomial time, giving us membership in
NP. For NP-hardness consider the known NP-hard “vertex
cover” problem [11] that takes as input a graph G0 = (V 0 , E 0 )
(with no self-loops) and natural number k and returns “yes”
iff there is a set of k or fewer vertices that are adjacent
to each edge in E. We can embed vertex cover into an
instance of GD-DBR in polynomial time with the following
embedding: set ka = k, kd = 0, Vd = ∅, X = |V 0 |, α = |E|,
G = G0 , and Vsrc = Vld = V 0 .
Suppose, BWOC, the above problem instance provides a
“yes” answer to the vertex cover problem but a “no” answer
to GA-DBR. Let V 00 be a vertex cover of size k or less for G0 .
Consider the corresponding set of vertices in G (we shall call
this V ∗ ). Note that |V ∗ | ≤ ka . As an attacker attacking V ∗
disconnects those nodes from the network, all edges adjacent
to V ∗ fail. As V ∗ is a vertex cover for G, this means that
there are no edges in the graph once V ∗ is removed. Hence,
no load node is connected to any source node - giving the
attacker a payoff of at least X – hence a contradiction.

Suppose, BWOC, the above problem instance provides a
“yes” answer to GA-DBR but a “no” answer to the vertex
cover problem. Let Va be the set of nodes the attacker attacks in GA-DBR. As α = |E| and as Vsrc = V , nodes only
fail in a cascade if they are either targeted by the attacker
or become totally disconnected. Further, as X = |V |, all
nodes in G are either in Va or disconnected - meaning that
Va must be a vertex cover of size ka or less. As ka = k we
have a contradiction.
Due to the use of covering problems for the complexity
results in Theorems 1, 2, and 3, it may seem reasonable to
frame the problem as a sub- or super- modularity optimization where the objective function is monotonic. However,
here we show (unfortunately) that these properties do not
hold for either player. First, we shall make statements regarding the monotonicity of the payoff function.
Proposition 3.3. Iff ∀Vd∗ , Va ⊆ Va0 : pG (Va , Vd∗ ) ≤ pG (Va0 , Vd∗ )
then ∀Va∗ , Vd ⊆ Vd0 : pG (Va∗ , Vd ) ≥ pG (Va∗ , Vd0 ).
The idea of submodularity can be thought of as “diminishing returns.” Given a set of elements S and a function
f : 2S → <+ , we say a f is submodular if for any sets
S1 ⊆ S2 and element s ∈
/ S2 , we have the following relationship:
f (S1 ∪ {s}) − F (S1 ) ≥ f (S2 ∪ {s}) − F (S2 )
A complementary idea of supermodularity is also often
studied - in this case the inequality is reversed. Unfortunately, when we fix the strategy for the defender, the attacker strategy is neither submodular nor supermodular making the dynamics of this model significantly different
from others (i.e. [24]). Let consider strategies Va , Vd where
Va causes some load node v ∈
/ (Va ∪ Vd ) ∩ Vld to disconnect
and any node the strategy {v} causes to disconnect will also
become disconnected with strategy Va (such a case is easy to
contrive, particularly with a bi-partite network). Therefore,
we get the following relationship:
pG (Va ∪ {v}, Vd ) − pG (Va , Vd ) < pG ({v}, Vd ) − pG (∅, Vd )
This arises from the fact that the left-hand side of the above
equation becomes zero and the right hand side of the equation is equal to pG ({v}, Vd ) which must be at least one. Now
consider another example. Suppose we have a simple Vshaped network of three nodes. The angle of the V is a load
node, while the other two nodes are source nodes. With
α = 1, the load node receives power if at least one of the
source nodes is connected to it. However, it does not require
both. Let Va be a strategy consisting of one source node and
v be the other source node, and Vd consist of the load node.
From this, we have the following relationship:
pG (Va ∪ {v}, Vd ) − pG (Va , Vd ) > pG ({v}, Vd ) − pG (∅, Vd )
In this case, the right-hand side becomes zero while the left
hand side becomes one. This leads us to the following fact:
Fact 3.2. When Vd is fixed, pG is neither submodular nor
supermodular.
Now let us consider when we fix the attacker’s strategy.
If the payoff is submodular when the attacker’s strategy is
fixed, then we have the following for Vd ⊆ Vd0 and v ∈
/ Vd0 if

the payoff subtracted from the number of nodes is submodular:
pG (Va , Vd0 ∪ {v}) − pG (Va , Vd0 ) ≥ pG (Va , Vd ∪ {v}) − pG (Va , Vd )
This is equivalent to the following:
pG (Va − (Vd0 ∪ {v}), ∅) − pG (Va − Vd0 , ∅) ≥
pG (Va − (Vd ∪ {v}), ∅) − pG (Va − Vd , ∅)
Now let Va0 = Va − (Vd0 ∪ {v}) and Va00 = Va0
Clearly Va00 ⊇ Va0 and v ∈
/ Va00 . Now we get the

∪ (Vd0 − Vd ).
following:

pG (Va0 , ∅) − pG (Va0 ∪ {v}, ∅) ≥ pG (Va00 , ∅) − pG (Va00 ∪ {v}, ∅)
pG (Va0 ∪ {v}, ∅) − pG (Va0 , ∅) ≤ pG (Va00 ∪ {v}, ∅) − pG (Va00 , ∅)
Hence, submodualrity of the payoff function when the attacker’s strategy is fixed would give us supermodualrity of
the payoff function when the defender’s strategy is fixed at
the empty set. However, this clearly violates Fact 3.2 and
gives rise to the following:
Fact 3.3. When Va is fixed, pG is neither submodular
nor supermodular.

4.

ALGORITHMS

In this section, we present heuristic algorithms for finding
the deterministic best response of each player as the results
of the previous section generally preclude a polynomial time
algorithm for an exact solution. We first introduce a version
of a “high load” strategy for the defender based on the ideas
of [8]. Then we introduce a greedy heuristic for each player.
This is followed by our approach for finding mixed strategies
based on the double-oracle algorithm of [15].
Hi-Load Node Approach. In [8], the authors study “high
load” nodes: nodes through which the greatest number of
shortest paths pass. They show that attacks on these nodes
tend to initiate cascading failures – suggesting that they
should be a priority for defense. We formalize the definition
of nodal load in our framework (essentially an extended definition of node betweenness [25]) by extending our function
loadG for nodes as follows.
Definition 4.1 (Nodal Load). For a given node, the
nodal load is defined as the sum of the fraction of shortest
paths for each pair that pass through that node. Formally:
X
σG (s, t|i)
,
loadG (i) =
σG (s, t)
s∈V
,t∈V
src

ld

where σG (s, t|i) is the number of shortest paths between s, t ∈
V that pass through node i.
Hence, we shall refer to the Deterministic Load-Based or
DLB strategy for the defender as one in which he deterministically protects the kd nodes with the greatest load. We
note that this is not necessarily a “best response” but the intuition is that defense will occur at nodes that are perceived
to be critical to the adversary. This intuition is similar to
that of the “most vital arc” idea seen in other failure model
games [2, 21].
Greedy Heuristics for Finding Deterministic Strategies. Here we present a simple greedy heuristic to find the
defender’s best-response (GREEDY DEFENDER RESP). The

analogous heuristic for the attacker is not shown due to space
constraints, but we shall refer to it as
GREEDY ATTACKER RESP. We note that while we do not
make general approximation guarantees (due to the results
in Section 3), we note that by Proposition 3.3, that nodes
added in step 18 will always cause an increase in payoff to the
defender (and in the analogous greedy approach for the attacker, this holds true as well). Further, by Proposition 3.2,
when ka = 1, we can be sure that GREEDY DEFENDER RESP
returns an exact solution, even when the attacker has a
mixed strategy. Unfortunately, by Theorem 3, the same cannot be said if the greedy heuristic is used for the attacker’s
best response.

Algorithm 1 GREEDY DEFENDER RESP
Require: Mixed strategy Pra , Natural number kd
Ensure: Set of nodes Vd

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:

Vd = ∅
Let AT K be the set of strategies associated with Pra
Set f lag = True, p∗ = −∞
while |VdP
| ≤ kd and f lag and p∗ < 0 do
p∗ = − Va ∈AT K Prd (Va )pG (Va , Vd )
curBest = null, curBestScore = 0, haveV alidScore =
False
for i ∈ V − Vd do P
curScore = p∗ − Va ∈AT K Prd (Va )pG (Va , Vd ∪ {i})
if curScore ≥ curBestScore then
curBest = i
curBestScore = curScore
haveV alidScore = True
end if
end for
if haveV alidScore = False then
f lag = False
else
Vd = Vd ∪ {curBest}
end if
end while
return Vd .

Finding Mixed Strategies. If the attacker uses a mixed
strategy that consists of uniformly attacking elements of
{S ⊂ Vld : |S| = ka } then the best any pure defender strategy can do is defending Vd ⊂ Vld . The attacker’s strategy ima
.
plies that any node in Vld is attacked with probability |Vkld
|
Each of the |Vld | − ka remaining nodes in Vld is then discona
d
nected with probability |Vkld
, i.e., x ≥ ka (1 − |Vkld
). Clearly
|
|
due to the cascading the value of the game will probably
be higher, illustrating the disadvantage the defender has in
this game. To determine both player’s optimal strategies
and the value of the game we resort to an algorithmic approach. We find the defender’s optimal strategy with the
following linear program. We can find minimax strategy for
the defender with the following linear program. It simply
assigns a probability to each of the defenders strategies in a
manner that minimizes the maximum payoff for the adversary. As a consequence, the solution to the following linear
program, DEF LP can provide the mixed minimax strategy
for the defender. An analogous linear program, ATK LP (not
shown), which mirrors DEF LP, will provide that result for
the attacker.

min p∗
subj.to

p∗ ≥

P

Vd ∈DEF

1=

P

XVd pG (Va , Vd )

Vd ∈DEF

(1)
∀Va ∈ AT K (2)

XVd

XVd ∈ [0, 1]

(3)
∀Vd ∈ DEF (4)

50

100

45

90

Payoff (Disconnected Nodes)

(DEF LP).

Payoff (Disconnected Nodes)

Definition 4.2

40
35
30

25
20
15

10
5
0

Algorithm 2 DOUBLE ORACLE
Require: Network G = (V, E), natural number maxIters
Ensure: Mixed defender strategy Prd

1: Initialize numIters = 0, f lag = True
2: Initialize the sets of strategies AT K, DEF to both be {∅}
3: while f lag and numIters ≤ maxIters do
4:
Create Pra , Prd based on the solutions to ATK LP and
5:
6:
7:
8:
9:

DEF LP respectively.
IF numIters < maxIters THEN let Va be the attacker’s
best response to Prd and Vd be the defender’s best response to Pra
IF Va ∈ AT K and Vd ∈ DEF THEN f lag = False ELSE
AT K = AT K ∪ {Va }, DEF = DEF ∪ {Vd }
numIters+ = 1
end while
return Pra .

The intuition behind the above algorithm is that it iteratively creates mixed strategies for both the attacker and defender based on a solution to a linear program over the sets
of current possible strategies for both players (AT K, DEF ).
This is followed by finding (for each player) the best deterministic response to it’s opponent’s strategy. If these new
strategies are both already in the set of possible strategies
for the respective players, the algorithm terminates. Otherwise, they are added to AT K, DEF respectively. We note
that by Theorem 1 of [15] that the above algorithm will guarantee an exact solution if maxIters is set to the number of
possible strategies. In practice, [15] demonstrates that the
algorithm converges much faster.
In DOUBLE ORACLE, the finding the solutions to DEF LP,
ATK LP will be tractable provided that the algorithm converges in a polynomial number of steps (either through convergence or after the specified maxIters). However, as we
have shown, computing the best responses is usually computationally difficult. Although, we note in the case where
ka = 1, that by Proposition 3.2 and Fact 3.1, the double oracle algorithm will return an optimal solution, even if greedy
approximations are used for the oracles (provided it runs
until convergence).

5.

EXPERIMENTAL EVALUATION

All experiments were run on a computer equipped with
an Intel X5677 Xeon Processor operating at 3.46 GHz with
a 12 MB Cache and 288 GB of physical memory. The machine was running Red Hat Enterprise Linux version 6.1.

ka=6

70

ka=5

60

ka=4

50

ka=3

40

ka=2

30
20

ka=1

10
0

0

Note that the above linear program requires one variable
for each of the defender’s strategies and one constraint for
each of the attacker’s strategies. However, as there are a
combinatorial number of strategies, even writing down such
a linear program is not practical except for very small problem instances. To address this issue of intractability, we
employ the double-oracle framework for zero-sum games introduced in [15] and has been applied in more recent work
as well [5, 12]. We present the algorithm DOUBLE ORACLE
as follows:

80

2

4

6

8

10

12

Nodal Load

1

2

3

4

5

6

Capacity Margin

Figure 1: Left: Nodal load vs. payoff (note hi-payoff,
low-load nodes in the dashed box), Right: Capacity
margin (α) vs. payoff

Only one core was used for experiments. All algorithms
were coded using Python 2.7 and leveraged the NetworkX
library2 as well as the PuLP library for linear programming3 .
All statistics presented in this section were calculated using
the R statistics software.
In our experiments, we utilized a dataset of an Italian 380
kV power transmission grid [20]. This power grid network
consisted of 310 nodes of which 113 were source, 96 were
load, and the remainder were transmission nodes. The nodes
were connected with 361 edges representing the power lines.
In our initial experiments, we examined the properties
of the model when no defense is employed. In Figure 1
(left) we show results concerning nodal load vs. the payoff
achieved by the adversary if that node is attacked (and no
others). Interestingly, we noticed a significant number of
nodes with low nodal load yet high-payoff if attacked (see
nodes in dashed box). This may suggest that the DLB strategy may be insufficient in some cases. Later we see how DLB
fails to provide adequate in a defense against the attacker
best response to DLB. This is likely due to these hi-payoff,
low-load nodes. In Figure 1 (right) we examine α (capacity
margin) vs. attacker payoff for various settings of ka (using
the GREEDY ATTACKER RESP heuristic). Here we found
that, in general, payoff decreases linearly with capacity margin (R2 ≥ 0.84 for each trial).
Next, we examined the relative performance of the minimax (mixed) defense strategy and the DLB strategy under different resource constraints and against the minimax
(mixed) attack strategy as well as the attacker’s (deterministic) greedy response to the DLB defense. In these experiments, we considered the case where both players have equal
resources, the attacker has one resource (which by Proposition 3.2 and Fact 3.1 we are guaranteed an optimal solution), and the defender has one resource. These results are
displayed in Figure 2. In these trials we set the capacity
margin α = 0.5, meaning that all edges had an excess capacity of 50%. We did not use the maxIters parameter of
the DOUBLE ORACLE algorithm, but instead allowed it to
run until convergence.
With regard to the comparison between DLB and minimax defense, both performed comparably against the minimax attack strategy. In fact, an analysis of variance (ANOVA)
indicated little variance between the two when faced with the
minimax attacker (p ≥ 0.74 for these trials). Yet, a defender
known to be playing a single strategy would likely not face
an attacker who plays the minimax strategy, but rather the
2
3

http://networkx.lanl.gov/
http://pythonhosted.org/PuLP/

Greedy Attacker Response to DLB
90

Minimax
Defense

60
50

40

DLB Defense

30
20
10

80
70

60
50

40
30

20

2

3

4

5

6

Equal resources

ka=kd
200
150

Advantageous
defender

kd=1

100

1

2

Resources (ka=kd)

3

4

5

ka=1
1

6

2

3

4

5

6

Advantageous
Attacker

max(ka,kd)

Resources (ka=kd)

10

ka=kd=5
ka=kd=4

8
6
4
2

0

0
1

250

50

10

0

ka=kd=6

12

300

Run-time (hours)

70

14

350

Run-time (hours)

100

80

Expected Payoff
(Disconnected Nodes)

Expected Payoff
(Disconnected Nodes)

Minimax Attack Strategy
90

0

ka=kd=3
ka=kd=2
ka=kd=1
1 4 7 10 13 16 19 22 25 28 31 34 37 40 43 46

Iteration Number

50

30

Minimax
Defense

20
15

DLB Defense

10
5

Expected Payoff
(Disconnected Nodes)

Expected Payoff
(Disconnected Nodes)

45

25

40

Figure 3: Strategy size vs. run-time in hours (left)
and the run-time of each iteration for the experiments where ka = kd

35
30
25
20
15
10
5

0

0
1

3

4

5

6

1

2

Resources (kd)
100

4

5

6

each iteration, not a cumulative time). This increase is
likely the combined result of the growing linear program
and the growing size of the mixed strategies considered by
the greedy approximation sub-routines. We are currently
exploring reliable methods to limit the number of iterations
while maintaining defender payoff.

100

90

90

80

Minimax
Defense

70

60
50
40

DLB Defense

30
20
10

Expected Payoff
(Disconnected Nodes)

Expected Payoff
(Disconnected Nodes)

3

Resources (kd)

80
70
60
50
40
30

20
10

0

0
1

2

3

4

Resources (ka)

5

6

1

2

3

4

5

6

Resources (ka)

Figure 2: Minimax and DLB defense strategies vs.
minimax attack strategy (left) and the attacker’s
greedy best response to DLB (right). Examined are
the cases where ka = kd (top), ka = 1, kd varies (middle) and kd = 1, ka varies (bottom).

best response to the DLB. In this case, DLB play resulted
in significantly greater payoff to the attacker than the defender (p ≤ 0.29 for these trials, the DLB defense results in
15.6 more disconnected nodes on average). This failure of
the DLB strategy to perform well against a deterministic attacker best response is likely due to the presence of low-load
yet high-payoff nodes as shown in Figure 1.
We also noticed that an increase in resources seems to favor the attacker more than the defender. When both players played their respective minimax strategy, the expected
payoff for the attacker increased monotonically with the cardinality of the strategies. Further, when kd = 1 and ka was
greater, the attacker’s payoff tripled when his resources increased from 1 to 6. However, when ka = 1 and kd was
greater, the defender’s payoff only increased by a factor of
1.7. Hence, the attacker can cause more damage than the
defender can mitigate with the same amount of extra resources. We suspect that this is likely because a defended
node can still fail during a cascade - which would likely be
the case if the attack and defense operations are restricted to
cyber-space, where physical system failure may still be possible as the result of a cascade initiated by virtual means.
We also examined the run-time of our approach, as displayed in Figure 3 (left). Though run-time did seem to scale
linearly with strategy size (R2 = 0.90 ± 0.2 for each experiment), it appears that run-time will in general prohibit the
study of larger strategies or networks (our longest experiment ran for 12 days). In examining the iterations of the
DOUBLE ORACLE algorithm, Figure 3 (left), we find that
run-time of an iteration of the algorithm progressively increases (note that this figure is showing the run-time for

6.

RELATED WORK

Network security has received much attention from the research community in the past two decades. Recent incidents
have shown that due to their internet connectedness such
networks can come under cyber attack, causing severe problems4 . See [26] for a discussion of cyber-security issues relevant to smart grid grids. The utilization of game theory in
designing defense solutions seems ubiquitous. For instance
[13] model the interaction between a DDoS attacker and
the network administrator while [14] considers a game theoretic formulation for intrusion detection. Other formulations
consist include stochastic games [17], signaling games [19],
allocation games [4] and repeated games [3]. Game theory is also being used in monitoring and decision making
in smart grids, see for instance [9] or the survey by Fadlullah et al. [10]. However to date no game theoretic approach
has been given for the specific problem where the attacker
explicitly sets of a cascading power failure to maximize the
damage to the defender.
Cascading failure models applied to power grid infrastructure have been studied in the past [7, 8, 16]. The model of
[8] introduces the idea of edge failure based on excessive
loads. The goal of the research presented in these papers
was to illustrate properties of the cascade, rather than explore strategies for attack and defense as this work does.
There has been work on attack and defense of a power-grid
network under the DC power-flow mode [2, 21, 20, 6]. However, the DC power flow model is not designed to model the
more rapid cascading failures (i.e. the 2003 cascading failure
in the eastern United States [1]).
The application of game theory to security situations was
made popular by [18] where it used for airport security patrol scheduling. Since then, other applications have emerged
including port protection [23], finding weapons caches [22],
and security checkpoint placement [12]. One that bears similarity to this work is [24] - studying games for controlling
contagions on a network. However, as previously discussed,
that model operates under very different dynamics.
4

http://www.wired.com/threatlevel/2009/10/smartgrid/

7.

CONCLUSION

In this paper, we explored complexity, algorithmic, and
implementation issues in a two-player security game where
the attacker/defender look to create/mitigate cascading failure on a power grid. Future work includes an examination
of scalability issues (larger networks and strategies), adding
uncertainty to the model, and the consideration of more realworld information about the power grid network (i.e. actual
line capacities, etc.) in order to create a richer model.

[12]

[13]

[14]

8.

ACKNOWLEDGMENTS

We would like to thank D. Alderson for his input on related work and V. Rosato for providing us the power grid
dataset. Some of the authors are supported by ARO project
2GDATXR042. The opinions in this paper are those of the
authors and do not necessarily reflect the opinions of the
funders, the U.S. Military Academy, or the U.S. Army.

[15]

9.

[16]

REFERENCES

[1] Final Report on the August 14, 2003 Blackout in the
United States and Canada: Causes and
Recommendations. U.S.-Canada Power System
Outage Task Force, April 2004.
[2] D. L. Alderson, G. G. Brown, M. W. Carlyle, and
L. Anthony Cox. Sometimes there is no ”most-vital”
arc: Assessing and improving the operational
resilience of systems. Military Operations Research,
18(1):21–37, 2013-03-01T00:00:00.
[3] T. Alpcan and T. Basar. A game theoretic analysis of
intrusion detection in access control systems. In
Decision and Control, 2004. CDC. 43rd IEEE
Conference on, volume 2, pages 1568–1573 Vol.2, 2004.
[4] M. Bloem, T. Alpcan, and T. Başar. Intrusion
Response as a Resource Allocation Problem. Decision
and Control, 2006 45th IEEE Conference on, pages
6283–6288, Dec. 2006.
[5] B. Bosanský, C. Kiekintveld, V. Lisý, J. Cermak, and
M. Pechoucek. Double-oracle algorithm for computing
an exact nash equilibrium in zero-sum extensive-form
games. In AAMAS, pages 335–342, 2013.
[6] G. Brown, M. Carlyle, J. Salmeron, and K. Wood.
Defending critical infrastructure. Interfaces,
36(6):530–544, Nov. 2006.
[7] S. V. Buldyrev, R. Parshani, G. Paul, H. E. Stanley,
and S. Havlin. Catastrophic cascade of failures in
interdependent networks. Nature,
464(7291):1025–1028, Apr. 2010.
[8] P. Crucitti, V. Latora, and M. Marchiori. Model for
cascading failures in complex networks. Phys. Rev. E,
69(4):45104, 2004.
[9] M. Esmalifalak, G. Shi, Z. Han, and L. Song. Bad
data injection attack and defense in electricity market
using game theory study. IEEE Trans. Smart Grid,
4(1):160–169, 2013.
[10] Z. Fadlullah, Y. Nozaki, A. Takeuchi, and N. Kato. A
survey of game theoretic approaches in smart grid. In
Wireless Communications and Signal Processing
(WCSP), 2011 International Conference on, pages
1–4, 2011.
[11] M. R. Garey and D. S. Johnson. Computers and
Intractability; A Guide to the Theory of

[17]

[18]

[19]

[20]

[21]

[22]

[23]

[24]

[25]

[26]

NP-Completeness. W. H. Freeman & Co., New York,
NY, USA, 1979.
M. Jain, V. Conitzer, and M. Tambe. Security
scheduling for real-world networks. In International
Conference on Autonomous Agents and Multiagent
Systems (AAMAS), 2013.
P. Liu, W. Zang, and M. Yu. Incentive-based modeling
and inference of attacker intent, objectives, and
strategies. ACM Trans. Inf. Syst. Secur., 8(1):78–118,
Feb. 2005.
Y. Liu, C. Comaniciu, and H. Man. A bayesian game
approach for intrusion detection in wireless ad hoc
networks. In Proceeding from the 2006 workshop on
Game theory for communications and networks,
GameNets ’06, New York, NY, USA, 2006. ACM.
H. B. McMahan, G. J. Gordon, and A. Blum.
Planning in the presence of cost functions controlled
by an adversary. In T. Fawcett and N. Mishra, editors,
ICML, pages 536–543. AAAI Press, 2003.
A. E. Motter and Y. C. Lai. Cascade-based attacks on
complex networks. Phys. Rev. E, 66(6), Dec. 2002.
K. C. Nguyen, T. Alpcan, and T. Basar. Security
games with incomplete information. In ICC, pages
1–6. IEEE, 2009.
P. Paruchuri, J. P. Pearce, J. Marecki, M. Tambe,
F. Ordonez, and S. Kraus. Playing games for security:
an efficient exact algorithm for solving bayesian
stackelberg games. In AAMAS, pages 895–902,
Richland, SC, 2008.
A. Patcha and J.-M. Park. A game theoretic approach
to modeling intrusion detection in mobile ad hoc
networks. In Information Assurance Workshop, 2004.
Proc. from the Fifth Annual IEEE SMC, pages
280–284, 2004.
V. Rosato, L. Issacharoff, F. Tiriticco, S. Meloni, S. D.
Porcellinis, and R. Setola. Modelling interdependent
infrastructures using interacting dynamical models.
IJCIS, 4(1/2):63–79, 2008.
J. Salmeron, K. Wood, and R. Baldick. Analysis of
electric grid security under terrorist threat. Power
Systems, IEEE Transactions on, 19(2):905–912, May
2004.
P. Shakarian, J. P. Dickerson, and V. S.
Subrahmanian. Adversarial geospatial abduction
problems. ACM Trans. Intell. Syst. Technol.,
3(2):34:1–34:35, Feb. 2012.
E. Shieh, B. An, R. Yang, M. Tambe, C. Baldwin,
J. DiRenzo, B. Maule, and G. Meyer. Protect: a
deployed game theoretic system to protect the ports of
the united states. In AAMAS, pages 13–20, Richland,
SC, 2012.
J. Tsai, T. H. Nguyen, and M. Tambe. Security games
for controlling contagion. In J. Hoffmann and
B. Selman, editors, AAAI. AAAI Press, 2012.
S. Wasserman and K. Faust. Social Network Analysis:
Methods and Applications. Number 8 in Structural
analysis in the social sciences. Cambridge University
Press, 1 edition, 1994.
D. Wei, Y. Lu, M. Jafari, P. Skare, and K. Rohde.
Protecting smart grid automation systems against
cyberattacks. Smart Grid, IEEE Transactions on,
2(4):782–795, 2011.

arXiv:1507.01922v1 [cs.CR] 7 Jul 2015

Cyber-Deception and Attribution
in Capture-the-Flag Exercises
Eric Nunes, Nimish Kulkarni, Paulo Shakarian

Andrew Ruef, Jay Little

School of Computing, Informatics and
Decision Systems Engineering
Arizona State University
Tempe, AZ 85281, USA
Email: {enunes1, nimish.kulkarni, shak} @asu.edu

Trail of Bits, Inc.
New York, NY 10003, USA
Email: {andrew, jay} @trailofbits.com

Abstract—Attributing the culprit of a cyber-attack is widely
considered one of the major technical and policy challenges
of cyber-security. The lack of ground truth for an individual
responsible for a given attack has limited previous studies. Here,
we overcome this limitation by leveraging DEFCON capture-theflag (CTF) exercise data where the actual ground-truth is known.
In this work, we use various classification techniques to identify
the culprit in a cyberattack and find that deceptive activities
account for the majority of misclassified samples. We also explore
several heuristics to alleviate some of the misclassification caused
by deception.

I.

I NTRODUCTION

Attributing the culprit of a cyber-attack is widely considered one of the major technical and policy challenges of
cyber-security. The lack of ground truth for an individual
responsible for a given attack has limited previous studies. In
this study, we take an important first step toward developing
computational techniques toward attributing the actual culprit
(here hacking group) responsible for a given cyber-attack. We
leverage DEFCON capture-the-flag (CTF) exercise data which
we have processed to be amenable to various machine learning
approaches. Here, we use various classification techniques to
identify the culprit in a cyber-attack and find that deceptive
activities account for the majority of misclassified samples. We
also explore several heuristics to alleviate some of the misclassification caused by deception. Our specific contributions are
as follows:
•

We assemble a dataset of cyber-attacks with ground
truth derived from the traffic of the CTF held at
DEFCON 21 in 2013.

•

We analyze this dataset to identify cyber-attacks where
deception occurred.

•

We frame cyber-attribution as a multi-label classification problem and leverage several machine learning
approaches. We find that deceptive incidents account
for the vast majority of misclassified samples.

explore the deception hypothesis in a cyber-warfare scenario.
When compared to other domains of warfare, there is a much
greater potential for evidence found in the aftermath of cyberattack to be planted by the adversary for purposes of deception.
The policy implications of cyber-attribution have also been
discussed in [9] where the authors point out that anonymity,
ability to launch multi-stage attacks, and attack speed pose
significant challenges to cyber attribution.
In an early survey on cyber-attribution [1], the authors point
out that technical attribution will generally identify machines,
as opposed to a given hacker and his/her affiliations. While
we will use technical information in our approach, we have
ground truth data on the group involved by the nature of
the capture-the-flag data. This will allow our approach to
profile the tactics, techniques, and procedures of a given group
as we have ground-truth information on a hacking group as
opposed to machines. An example of such an approach is the
WOMBAT attribution method [3] which attributes behavior
to IP sources that are potentially linked to some root cause
determined through a clustering technique. Similarly, other
work [8] combines cluster analysis with a component for multicriteria decision analysis and studied an implementation of this
approach using honeypot data – again, this approach lacks any
ground truth of the actual hacker or hacking group.
Concurrently, we have devised a formal logical framework
for reasoning about cyber-attribution [5], [7]. However, we
have not studied how this framework can be instantiated on
a real world dataset and, to date, we have not reported on an
implementation or experiments in the literature. We note that
none of the previous work on cyber-attribution leverages a
data set with ground truth information of actual hacker groups
– which is the main novelty of this paper.
II.

DATASET

We introduce several pruning techniques and show
that they can reduce the effect of deception as well as
provide insight into the conditions in which deception
was employed by the participants of the CTF.

Our dataset consists of events recorded from a Capturethe-flag (CTF) tournament held at DEFCON 21 in 2013.
Briefly, CTF competitions act as educational exercise that
exposes real world attack scenarios to participants. Network
sniffing, analysis of protocols, programming and system level
knowledge, cryptanalysis are some of the instrumental skills
acquired by contestants.

In our text on cyber-warfare [6], we discuss the difficulties
of cyber-attribution and how an intelligence analyst must also

Our data represents attack/defense style, where each team
owns a small network of machines to defend. Teams are judged

•

Robot Mafia

svc

02345

payload hash

2cc03b4e0053cde24400bbd80890446c

time

2013-08-03T23:45:17

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

T-10

T-8

T-7

T-6

T-5

T-4

T-3

T-2

T-1

T-20
T-20

men in black hats

to team

T-19

from team

0

T-18

cmp:12 , svcmi:2, subs:8, movtmi:60 ......

T-17

0×43:245, 0×69:8, 0×3a:9, 0×5d:1, .....

inst hist

T-16

byte hist

200000

T-15

Value

400000

T-14

Field

600000

T-13

TABLE 2: Example event from the dataset

800000

T-12

From this pre-processing of the network data (packets) we
have around 10 million network attacks. There are 20 teams
in the CTF competition. In order to attribute an attack to a
particular team, apart from analyzing the payloads used by the
team, we also need to analyze the behavior of the attacking
team towards his adversary. For this purpose we separate the
network attacks according to the team being targeted. Thus
we have 20 such subsets. We represent the 20 subsets (teams)
as T-i, where i = 1, 2, 3...20. An example of an event in the
dataset is shown in Table 2.

T-11

indicates the date and time of the attack

T-10

indicates the payload used in the attack (md5)

time

T-9

the service that the payload is running

payload hash

T-8

the team being attacked by the payload

svc

Duplicate attacks: A duplicate attack occurs when the same
team uses the same payload to attack a team at different time
instances. Duplicate attacks can be attributed to two reasons.
First when a team is trying to compromise other systems, it
just does not launch a single attack but a wave of attacks with
very little time difference between consecutive attacks. Second,
once a successful payload is created which can penetrate the
defense of other systems, it is used more by the original
attacker as well as the deceptive one as compared to other
payloads. We group duplicates as being non-deceptive and
deceptive. Non-deceptive duplicate are the duplicates of the
team that first initiated the use of a particular payload. On the
other hand deceptive duplicates are all the attacks from the
teams that are being deceptive. Deceptive duplicates form a
large portion of the dataset as seen in Fig. 2.

T-7

the team where the payload originates (attacking team)

to team

Deceptive Attacks

Fig. 1: Unique deceptive attacks directed towards each team.

T-6

histogram of instructions used in the payload

from team

Teams

Unique Attacks

T-5

histogram of byte sequences in the payload

inst hist

0

T-4

Intuition

byte hist

100000

T-3

Field

200000

T-2

TABLE 1: Fields in an instance of network attack

300000

T-1

For each file, we computed an md5 checksum, a byte
histogram, and an ARM instruction histogram. This data was
recorded as a list of tuples (time-stamp, hash, byte-histogram,
instruction-histogram) in a JSON document. These individual
fields of the tuple are listed in Table 1.

400000

Unique Attacks

DEFCON CTF organizers recorded network traffic that
includes network packets generating to and from all participating teams and is available on Internet [4]. Recordings are
stored as archive files of PCAP (packet capture) for each team
(destination as that team) separately. PCAP file contains packet
headers (TCP, SSL, UDP etc.) and respective data as source,
destination, sequence numbers etc. with timestamp having
millisecond precision. Using open source tool tcpflow1 , we
interpreted collection of PCAPs as cumulative data streams.
Tcpflow reconstructs actual data streams from the packets
that proved helpful in protocol analysis and debugging. This
tool produces a file containing the contents of each stream,
representing the data sent between two points in the CTF
system.

attack to a team difficult.
Deception: In the context of this paper we define an attack to
be deceptive when multiple adversaries get mapped to a single
attack pattern. In the current setting we define deception as the
scenario when the same payload is used by multiple teams to
target the same team. Fig. 1 shows the distribution of unique
deception attacks with respect to the total unique attacks in
the dataset based on the target team. These unique deceptive
attacks amount to just under 35% of the total unique attacks.

Total Attacks

based on scores given to attack machines of other teams as well
as defending their own network. Initially, all virtual machines
are configured with specific set of services. These services
are vulnerable to state-of-art hacking techniques. Files can be
considered as form of flag to be captured from other teams or
to be planted to other teams by exploiting those vulnerabilities.

Teams

Non-Deceptive

Deceptive

Total Attacks

Fig. 2: Total attacks and duplicate attacks(Deceptive and
Non-deceptive) directed towards each team

A. Dataset Analysis
We now discuss two important observations from the
dataset, that makes the task of attributing an observed network
1 https://github.com/simsong/tcpflow

III.

BASELINE A PPROACHES

From the dataset, we have the ground truth available for
all the samples. Hence we use supervised machine learning

0.26

Logistic regression (LOG-REG)

0.31

Support vector machine (SVM)

0.30

Random Forest (RF)

0.37

•

Non-deceptive duplicate attacks attributed to one of
the deceptive teams.

•

Deceptive duplicates attributed to some other deceptive team.

•

Payloads that were not encountered during the training
phase.

The first two sources of error make up the majority of
misclassifications, since a given attack can be attributed to any
of the 19 teams.
1.0

0.8

0.6

0.4

0.2

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

T-10

T-8

T-7

T-6

T-5

T-4

0.0

T-3

For our baseline experiments, we separate the attacks based
on the team being targeted. Thus we have 20 subsets. We then
sort the attack according to time. We reserve the first 90% of
the attacks for training and the rest 10% for testing. Attacker
prediction accuracy is used as the performance measure for
the experiment. Accuracy is defined as the fraction of correctly
classified test samples. Fig. 3 shows the accuracy for predicting
the attacker for each target team. Machine learning techniques
significantly outperform random guessing which would have
an average accuracy of choosing 1 out of 19 teams attacking
yielding an accuracy of 0.053. For this experiment random
forest classifier performs better than logistic regression, support vector machine and decision tree for all the target teams.
Table 3 below summarizes the average performance for each
method.

Average Performance

Decision tree (DT)

T-2

A. Experimental Results

Method

T-1

Decision Tree (DT). For baseline comparisons we first implemented a decision tree classifier. We built the decision tree
by finding the attribute that maximizes the information gain at
each split. In order to avoid over-fitting, the terminating criteria
is set to less than 0.1% of total samples.
Random Forest (RF). We use a random forest which combines bagging for each tree with random feature selection at
each node to split the data thus generating multiple decision
tree classifiers.
Support Vector Machine (SVM). Support vector machines
is a popular supervised classification technique that works
by finding a separating margin that maximizes the geometric
distance between classes. We use the popular LibSVM implementation [2] which is publicly available.
Logistic Regression (LOG-REG). Logistic regression classifies samples by computing the odds ratio. The odds ratio
gives the strength of association between the features and the
class. We implement the multinomial logistic regression which
handles multi-class classification.

TABLE 3: Summary of Prediction results averaged across all
Teams

Fraction of Misclassified Samples

approaches to predict the attacking team. The ground truth
corresponds to a team competing in the competition.

Teams

Non-Deceptive Duplicates

Deceptive Duplicates

Unseen payloads

Fig. 4: Sources of error in the misclassified samples.
Fig. 4 shows the distribution of the above mentioned
sources of misclassification for each team. Deceptive duplicates form the majority of misclassifications. This is not
surprising given the fact that deceptive duplicates make up
almost 90% of the total attacks (see Fig. 2).

0.6

IV.

0.5

We explore different pruning techniques to address
misclassification issues with respect to deceptive and nondeceptive duplicates. The pruning techniques are only applied
to the training data, while the test data is maintained at 10%
as mentioned in Section III-A. We use the random forest
classifier for all the pruning techniques.

0.4

Accuracy

P RUNING

0.3
0.2

0.1

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

T-10

T-8

T-7

T-6

T-5

T-4

T-3

T-2

T-1

0

Teams

LOG-REG

RF

SVM

DT

Fig. 3: Team prediction accuracy for LOG-REG, RF, SVM
and DT.

B. Misclassified Samples
Misclassification can be attributed to the following sources,

All-but-majority (P-1): In this pruning technique, for each
payload, we only retain duplicates of the most frequent attacking team and prune the duplicates of all other teams. This
pruned set is then used to train the random forest classifier.
Table 4 shows the classifier performance in comparison with
the baseline method. All-but-majority pruning technique has
better performance on the test set than the baseline approach
for 11 out of 20 teams. Using this pruning technique does
benefit majority of the teams as the prediction accuracy improves for them, but for some teams the performance drops.

The reason for the drop in performance for some teams is
due to the fact that training set gets dominated by a single
team which does not have majority in testing set. Since the
majority team gets represented in most of the leaves of the
random forest classifier, it gets predicted more often leading
to high misclassifications.
All-but-K-majority (P-2): In order to address the issue of
one team dominating in the training set, we use the all-but-Kmajority where we consider the K most frequent teams for a
payload under consideration. After trying out different values
of K we select K = 3, which gives the best performance.
For higher values of K, the pruning behaves like the baseline
approach and for lower values it behaves like All-but-majority.
On average each team gains about 40K samples in the training
set as compared to all-but-majority pruning. Table 4 shows
the classifier performance. In this case also pruning performs
better than baseline in 11 out of 20 teams, but as compared to
all-but-majority the performance for most teams is better.
All-but-earliest (P-3): For this pruning we only retain the
duplicates of the team that initiated the attack using a particular
payload. This pruning technique retains all the non-deceptive
duplicates while getting rid of the deceptive ones. Table 4
shows the classifier performance. This pruning technique performs better than the baseline approach for 8 out of 20 teams.
Comparing this result to all-but-majority (including all-butK-majority) pruning indicates that deceptive duplicates are
informative in attributing an attack to a team and should not
be ignored completely.
All-but-most-recent (P-4): In this pruning we repeat a similar
procedure like All-but-earliest but instead of retaining the
duplicates of the team that initiated an attack, we retain the
duplicates of the team that used the payload last in the training
set. Since the data is sorted according to time, the last attacker
becomes the most recent attacker for the test set. Table 4 shows
the classifier performance.
TABLE 4: Pruning technique performance comparison.
Teams

RF

P-1(RF)

P-2(RF)

P-3(RF)

P-4(RF)

T-1

0.45

0.16

0.46

0.15

0.15

T-2

0.22

0.28

0.30

0.15

0.14

T-3

0.30

0.53

0.29

0.57

0.57

T-4

0.26

0.33

0.27

0.31

0.32

T-5

0.26

0.38

0.45

0.40

0.42

T-6

0.50

0.27

0.24

0.31

0.26

T-7

0.45

0.59

0.58

0.19

0.49

T-8

0.42

0.52

0.52

0.51

0.55

T-9

0.41

0.65

0.68

0.52

0.53

T-10

0.30

0.54

0.34

0.55

0.57

T-11

0.37

0.27

0.35

0.27

0.29

T-12

0.24

0.37

0.37

0.25

0.22

T-13

0.35

0.27

0.37

0.29

0.27

T-14

0.42

0.27

0.40

0.30

0.30

T-15

0.30

0.20

0.27

0.21

0.20

T-16

0.42

0.28

0.22

0.32

0.31

T-17

0.43

0.45

0.35

0.43

0.40

T-18

0.48

0.39

0.43

0.41

0.40

T-19

0.41

0.65

0.58

0.54

0.60

T-20

0.48

0.16

0.16

0.16

0.17

Table 5 gives the summary of the prediction results for
all the pruning techniques in comparison with the random
forest baseline approach. In the pruning techniques All-butK-majority works best with an average accuracy of 0.42.

TABLE 5: Summary of Prediction results averaged across all
Teams
Method

Average Performance

Baseline Approach (RF)

0.37

All-but-majority Pruning (RF)

0.40

All-but-K-majority Pruning (RF)

0.42

All-but-earliest Pruning (RF)

0.34

All-but-most-recent Pruning (RF)

0.36

V.

C ONCLUSION

In this paper, we study cyber-attribution by examining
DEFCON CTF data - which provides us with ground-truth
on the culprit responsible for each attack. We frame cyberattribution as a classification problem and examine it using
several machine learning approaches. We find that deceptive
incidents account for the vast majority of misclassified samples
and introduce heuristic pruning techniques that alleviate this
problem somewhat. Moving forward, we look to employ a
more principled approach to counter deception based on our
previously established theoretical framework for reasoning
about cyber-attribution [5], [7]. In particular we wish to employ
temporal reasoning to tackle the problem of deceptive attacks.
This opens up interesting research questions in particular identifying hacking group from a series of attacks over a period of
time, differentiating between deceptive hacking groups in time
series data. This is a knowledge engineering challenge which
calls for development of efficient and scalable algorithms.
VI.

ACKNOWLEDGMENT

Some of this work was supported by the U.S. Office of
Naval Research and ASU Global Security Initiative (GSI).
R EFERENCES
[1]
[2]

[3]

[4]
[5]

[6]
[7]

[8]

[9]

W. E. Boebert. A survey of challenges in attribution. In Proceedings of
a workshop on Deterring CyberAttacks, pages 41–54, 2010.
C.-C. Chang and C.-J. Lin. Libsvm: A library for support vector
machines. ACM Transactions on Intelligent Systems and Technology
(TIST), 2(3):27, 2011.
M. Dacier, V.-H. Pham, and O. Thonnard. The wombat attack attribution
method: some results. In Information Systems Security, pages 19–37.
Springer, 2009.
DEFCON. Defcon: Capture the flag. 2013.
S. Jajodia, P. Shakarian, V. S. Subrahmanian, V. Swarup, and C. Wang.
Cyber Warfare: Building the Scientific Foundation. Springer Publishing
Company, Incorporated, 2015.
P. Shakarian, J. Shakarian, and A. Ruef. Introduction to cyber-warfare:
A multidisciplinary approach. Newnes, 2013.
P. Shakarian, G. I. Simari, and M. A. Falappa. Belief revision in
structured probabilistic argumentation. In Foundations of Information
and Knowledge Systems, pages 324–343. Springer, 2014.
O. Thonnard, W. Mees, and M. Dacier. On a multicriteria clustering
approach for attack attribution. ACM SIGKDD Explorations Newsletter,
12(1):11–20, 2010.
N. Tsagourias. Nicolas politis initiatives to outlaw war and define
aggression, and the narrative of progress in international law. European
Journal of International Law, 23(1):255–266, 2012.

2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)

Argumentation Models for Cyber Attribution
Eric Nunes, Paulo Shakarian

Gerardo I. Simari

Andrew Ruef

Arizona State University
Tempe, AZ 85281, USA
Email: {enunes1, shak} @asu.edu

Inst. for CS and Eng. (CONICET–UNS)
DCIC, UNS, Bahia Blanca, Argentina
Email: gis@cs.uns.edu.ar

Trail of Bits, Inc.
New York, NY 10003, USA
Email: andrew@trailofbits.com

Abstract—A major challenge in cyber-threat analysis is combining information from different sources to find the person or
the group responsible for the cyber-attack. It is one of the most
important technical and policy challenges in cyber-security. The
lack of ground truth for an individual responsible for an attack
has limited previous studies. In this paper, we take a first step
towards overcoming this limitation by building a dataset from
the capture-the-flag event held at DEFCON, and propose an
argumentation model based on a formal reasoning framework
called DeLP (Defeasible Logic Programming) designed to aid an
analyst in attributing a cyber-attack. We build models from latent
variables to reduce the search space of culprits (attackers), and
show that this reduction significantly improves the performance of
classification-based approaches from 37% to 62% in identifying
the attacker.

I.

I NTRODUCTION

A major challenge in cyber-threat analysis is to find the
person or the group responsible for a cyber-attack. This is
known as cyber-attribution [17] and it is one of the central
technical and policy challenges in cyber-security. Oftentimes,
the evidence collected from multiple sources provides a contradictory viewpoint. This gets worse in cases of deception
where either an attacker plants false evidence or the evidence
points to multiple actors, leading to uncertainty. In the text
on cyber-warfare [17] the authors discuss the difficulties that
an intelligence analyst faces in attributing an attack to a
perpetrator given that deception might have occurred, and how
the analyst needs to explore deception hypotheses under the
given attack scenario.
However, one of the major drawbacks of the study and
evaluation of cyber-attribution models is the lack of datasets
with the ground truth available regarding the individual party
responsible for the attack—this has limited previous studies.
To overcome this, we built and leveraged a dataset from the
capture-the-flag event held at DEFCON. In previous work,
this dataset was used to study cyber-attribution, framing it
as a multi-label classification problem to predict the attacker [13]. Machine learning approaches struggle in situations
of deception, where similar attributes point towards multiple
attackers—we propose to address this issue using a formal
logical framework.
Specific contributions of this paper include:
•
•

description of how a model for cyber-attribution can
be designed and implemented in the DeLP structured
argumentation framework;
experiments demonstrating that using argumentationbased tools can significantly reduce the number of

IEEE/ACM ASONAM 2016, August 18-21, 2016, San Francisco, CA, USA
c 2016 IEEE
978-1-5090-2846-7/16/$31.00 

837

•

potential culprits that need to be considered in the
analysis of a cyber-attack; and
experiments showing that the reduced set of culprits,
used in conjunction with classification, leads to improved cyber-attribution decisions.

Related work: Adversarial machine learning is an emerging
field of study. It uses effective machine learning techniques to
identify or defend against an adversary’s opponents. Understanding the limits of adversary’s knowledge and capabilities
is crucial for coming up with countermeasures, as discussed
in [9]. Here the authors propose models to study these limitations to come up with evasion techniques. On the contrary,
Lowd and Meek [12] explore the problem from an adversarial
point of view. They propose strategies that an adversary can
use to reverse engineer a classifier so that his attacks are
undetected by the classifier. They use a real world application
in spam filtering to demonstrate their method, which they call
adversarial classifier evasion. In a spam filtering setting an
example of such a technique is replacing feature words that
raise a red flag with their synonyms to evade detection. This
feature cross substitution technique is discussed in [10]. Here
the authors offer a simple heuristic method based on mixedinteger linear programming with constraint generation to make
the classifier robust to cross substitution techniques. There is
research that looks at modeling the interaction between the
learner (adversary) and the classifier in terms of a competition
using Stackelberg games [4], [3]. Most adversarial machine
learning applications deal with modeling classifiers to be
robust against evasive techniques in real world applications like
malware detection and spam filtering. Cyber-attribution falls in
the domain of adversarial learning, but looks at analyzing the
evidence in the aftermath of an attack to discover the attacker.
Currently, cyber-attribution is limited to identifying machines [2] as opposed to the hacker or their affiliation to a
group or a state. An example of such a technical attribution
approach is WOMBAT [5], where a clustering technique is
used to group attacks to common IP sources. A method that
combines information from different sources was proposed by
Walls [22], who considered forensic information from diverse
sources but did not account for inconsistency or uncertainty
due to deception. A less rigorous mathematical model, known
as the Q model [15], was proposed recently; the model answers
queries from an analyst, and by combining these answers the
analyst attributes an attack to a party. Unfortunately, there
are no experimental evaluations of its effectiveness. Argumentation has been used for cyber reasoning [1] by leveraging
arguments to deal with incomplete and contradictory data,
allowing to derive big-picture conclusions to keep systems
secure and online in case of an attack. This is a different

application than the one we are addressing.
In [20], a tool was presented to support human decisions,
focusing on how user trust in the evidence influences the process; a user study demonstrating the hypotheses was presented
in [16]. Concurrently, a formal logical framework for reasoning
about cyber-attribution has been devised [18], [19]; it explores
multiple competing hypotheses based on the evidence for and
against a particular attacker to help analysts decide on an
attribution, providing a map of the reasoning that led to the
decision.
The rest of the paper is organized as follows. We present
a description of our DEFCON capture-the-flag dataset and an
analysis on the occurrence of deception within this data in
Section II. This is followed by the argumentative model based
on [8] in Section III. We then summarize results from [13] and
discuss how we built our baseline argumentation model along
with two other extended baseline models for cyber-attribution
with DeLP in Section V and Section VI, with a discussion of
the experimental results obtained with each of these models.
Conclusions are discussed in Section VII.
II.

DEFCON CTF DATASET

stopping the services, the white team (a third team, played
by the organizers) conducts periodic availability tests of the
services running on each team’s server. A team’s score is the
sum of the value of the flags they have captured, minus the sum
of the flags that have been captured from that team, multiplied
by an availability score determined by how often the white
team was able to test that team’s services. This scoring model
incentivizes teams to keep their server online, identify the
vulnerabilities in services and patch them quickly, and exploit
other teams services to capture their flags. It disincentivizes
teams’ from performing host-level blocking and shutting down
services, as this massively impacts their final score.
This game environment can be viewed as a microcosm of
the global Internet and the careful game of cat and mouse
between hacking groups and companies. Teams are free to use
different technical means to discover vulnerabilities. They may
use fuzzing and reverse engineering on their own programs,
or, they may monitor the network data sent to their services
and dynamically study the effects that network data has on
unpatched services. If a team discovers a vulnerability and uses
it against another team, the first team may discover that their
exploit is re-purposed and used against them within minutes.

The DEFCON security conference sponsors and hosts a
capture the flag (CTF) competition every year, held on site with
the conference in Las Vegas, Nevada. DEFCON CTF is one of
the oldest and best-known competitions. The ctftime.org site
provides a ranking for CTF teams and CTF competitions, and
in this system DEFCON CTF has the highest average weight
of all other CTF competitions.

The organizers of DEFCON CTF capture all of the network
traffic sent and received by each team, and publish this traffic
at the end of the competition [6]. This includes IP addresses
for source and destination, as well as the full data sent and
received and the time the data was sent or received. This data
is not available to contestants; depending on the organizers’
choice from year to year, the contestants either have a real
time feed but with the IP address obscured, or a full feed
delivered on a time delay of minutes to hours.

CTF competitions can be categorized by what role the
competitors play in the competition: either red team, blue
team, or a combination. In a blue team focused CTF the
competitors harden their systems against a red team played
by the organizers of the CTF. In a combined red/blue team
CTF every team plays both blue and red team simultaneously.
The NCCDC and CDX competitions are examples of a blue
team CTF, while DEFCON CTF is a combined red/blue team.
Each team is simultaneously responsible for hardening and
defending their systems as well as identifying vulnerabilities
and exploiting them in other teams’ systems.

Analysis: We use the data from the CTF tournament held at
DEFCON 21 in 2013. The CTF data set is very large, about
170 GB in compressed format. We used multiple systems with
distributed and coordinated processing to analyze the entire
dataset—fortunately, analyzing individual streams is easy to
parallelize. To analyze this data, we identified the TCP ports
associated with each vulnerable service. From this information,
we used the open source tool tcpflow to process the network
captures into a set of files, with each file representing data sent
or received on a particular connection.

The game environment is created primarily by the DEFCON CTF organizers. The game focuses around programs
(known in the game as services) written by the organizers.
These services are engineered to contain specific vulnerabilities. The binary image of the service is made available to
each team at the start of the game, but no other information
about the service is released. Part of the challenge of the
game is identifying the purpose of each service as well as
the vulnerabilities present in the service. Identification of
vulnerabilities serves both a defensive and offensive goal. Once
a vulnerability has been identified, a team may patch this
vulnerability in the binary program. Additionally, the teams
may create exploits for that vulnerability and use them to
attack other teams and capture digital flags from those teams’
systems.
Each team is also provided with a server running the
services, which contains the digital flags to be defended. To
deter defensive actions such as powering off the server or

838

With these data files identified, we analyzed some of them
by hand using the Interactive Disassembler (IDA) to determine
if the data contained shell-code, which in fact was the case.
We used an automated tool to produce a summary of each data
file as a JSON encoded element. Included in this summary
was a hash of the contents of the file and a histogram of the
processor instructions contained in the file. These JSON files
were the final output of the low-level analysis, transforming
hundreds of gigabytes of network traffic into a manageable set
of facts about exploit traffic in the data. Each JSON file is a list
of tuples (time-stamp, byte-histogram, instruction-histogram,
attack team and target team). The individual fields of the tuple
are listed in Table 1.
The pre-processing can be summarized in the following
steps:
•

Un-tarring the archives available from the organizers.
The archives produce a large number of pcap-ng
formatted files that contain the traffic captures.

of a particular payload; on the other hand, deceptive duplicates
are all the attacks from the teams that did not initiate the use.

TABLE 1: Fields in an instance of network attack
Field

Intuition

Value

byte hist

Histogram of byte sequences
in the payload

0×43:245, 0×69:8,
0×3a:9, .....

inst hist

Histogram of instructions
used in the payload

cmp:12,
subs:8,
movtmi:60 ......

from team

The team where the payload
originates (attacking team)

Blue Lotus

to team

The team being attacked by
the exploit

Robot Mafia

time

Indicates the date and time of
the attack

2013-08-03T23:45:17

•
•

•

III.

A RGUMENTATION M ODEL

Our approach relies on a model of the world where we can
analyze competing hypotheses in a cyber-operation scenario.
Such a model should allow for contradictory information so it
can handle inconsistency in cases of deception.

Conversion of the pcap-ng files to tcpdump format
capture using the editcap utility. This is to allow
tcpflow to process the data.
Use of xargs and GNU parallel to run tcpflow on
each pcap. This is a time-consuming process, and
produced a directory structure with files for data
sent and received on host-port socket pairs. This step
of processing allows file-based tools to process the
network data.
A tool to process each file containing data sent
or received by network ports associated with CTF
challenges. These tools produced summary statistics
for each data stream, to include a byte histogram,
overall size, a hash, and an ARM instruction histogram
(we ran a linear sweep with the Capstone instruction
decoder to produce this). This data was saved via
JSON.

After this pre-processing of the network data packets, we
have around 10 million network attacks consisting of around
1 million unique exploits built and used by 20 teams in the
competition. In order to attribute an attack to a particular
team, apart from analyzing the payloads used by the team,
we also need to analyze the behavior of the attacking team
towards their adversary. For this purpose, we divide the attacks
according to the team being targeted. Thus, we have 20 such
subsets, which we represent as T-i, where i ∈ {1, 2, 3, ..., 20}.
The processed dataset is publicly available 1 .
We now discuss two important observations from the
dataset, which make the task of attributing an observed network attack to a team difficult.

Before describing the argumentation model in detail, we
introduce some necessary notation. Variables and constant
symbols represent items such as the exploits/payloads used for
the attack, and the actors conducting the cyber-attack (in this
case, the teams in the CTF competition). We denote the set of
all variable symbols with V and the set of all constants with
C. For our model we require two subsets of C: Cact , denoting
the actors capable of conducting the cyber-operation, and Cexp ,
denoting the set of unique exploits used. We use symbols in
all capital letters to denote variables. In the running example,
we use a subset of our DEFCON CTF dataset.
Example 1. Actors and cyber-operations from the CTF
data: Cact = {bluelotus, robotmafia, apt8}, Cexp =
{exploit1 , exploit2 , ..., exploitn }.
The language also contains a set of predicate symbols that
have constants or variables as arguments, and denote events
that can be either true or false. We denote the set of predicates
with P; examples of predicates are shown in Table 2. For
instance, culprit(exploit1 , apt8) will either be true or false, and
denotes the event where apt8 used exploit1 to conduct a cyberoperation.
TABLE 2: Example predicates and explanation
Predicate

Explanation

attack(exploit1 , bluelotus)

exploit1 was targeted towards the
team Blue Lotus.

replay attack(E, Y)

Exploit E was replayed by team Y.

deception(exploit1 , apt8)

Team apt8 used exploit1 for deception.

time diff(I, Y)

Team Y was deceptive within the
given time interval I.

culprit(exploit1 , apt8)

Team apt8 is the likely culprit for
the attack (using exploit1 on the
target team).

Deception: In the context of this paper we define an attack to
be deceptive when multiple adversaries get mapped to a single
attack pattern; deception is thus a scenario in which the same
exploit is used by multiple teams to target the same team. The
number of unique deceptive attacks amount to just under 35%
of the total unique attacks in our dataset—clearly, deception
is a heavily-used technique in this domain.

A ground atom is composed by a predicate symbol and
a tuple of constants, one for each argument. The set of all
ground atoms is denoted as G. A ground literal L is a ground
atom or a negated ground atom; hence, ground literals have
no variables. An example of a ground atom for our running
example is attack(exploit1 , bluelotus). We denote a subset of
G with G0 .

Duplicate attacks: A duplicate attack occurs when the same
team uses the same payload to attack the same team at different
points in time. We group duplicates as either being nondeceptive or deceptive. Non-deceptive duplicates are the copies
of the attacks launched by the team that first initiated the use

We choose a structured argumentation framework [14] for
our model; our approach works by creating arguments (in
the form of a set of rules and facts) that compete with each
other to attribute an attack to a given perpetuator. In this case,
arguments are defeated based on contradicting information in
other arguments. This procedure is known as a dialectical
process, where the arguments that are undefeated prevail.

1 http://lab.engineering.asu.edu/cysis/cyber-attribution/

839

An important result is the set of all the arguments that are
warranted (not defeated) by any other argument, which give
a clear map supporting the conclusion. Such transparency
lets a security analyst not only add new arguments based
on new evidence discovered in the system, but also get rid
of incorrect information and fine-tune the model for better
performance. Since the argumentation model can deal with
inconsistent information, it draws a natural analogy to the way
humans settle disputes when there is contradictory information
available. Having a clear explanation of why one argument is
chosen over others is a desirable characteristic for both the
analyst and for organizations to make decisions and policy
changes. We now briefly discuss some preliminaries on DeLP.
Defeasible Logic Programming: DeLP is a formalism that
combines logic programming with defeasible argumentation;
full details are discussed in [8]. The formalism is made up
of several constructs, namely facts, strict rules, and defeasible
rules. Facts represent statements obtained from evidence, and
are always true; similarly, strict rules are logical combinations
of elements (facts or other inferences) that can always be
performed. On the contrary, defeasible rules can be thought
of as strict rules that may be true in some situations, but
could be false if contradictory evidence is present. These three
constructs are used to build arguments, and DeLP programs are
sets of facts, strict rules and defeasible rules. We use the usual
notation for DeLP programs, denoting the knowledge base with
Π = (Θ, Ω, ∆), where Θ is the set of facts, Ω is the set of
strict rules, and ∆ is the set of defeasible rules. Examples of
the three constructs are provided with respect to the dataset in
Fig. 1. We now describe the constructs in detail.
Facts (Θ) are ground literals that represent atomic information
or its (strong) negation (¬).

Θ:

θ1
θ2
θ3
θ4
θ5

=
=
=
=
=

Ω:

ω1 =
ω2 =

∆:

δ1 =
δ2 =
δ3 =
δ4 =

attack(exploit1 , bluelotus)
first attack(exploit1 , robotmafia)
last attack(exploit1 , apt8))
time diff(interval, robotmafia)
most frequent(exploit1 , pwnies)
culprit(exploit1 , pwnies) ←
most frequent(exploit1 , pwnies),
replay attack(exploit1 )
¬ culprit(exploit1 , robotMafia) ←
last attack(exploit1 , apt8),
replay attack(exploit1 )
replay attack(exploit1 ) -≺
attack(exploit1 , bluelotus),
last attack(exploit1 , apt8)
deception(exploit1 , apt8) -≺
replay attack(exploit1 ),
first attack(exploit1 , robotmafia)
culprit(exploit1 , apt8) -≺
deception(exploit1 , apt8),
replay attack(exploit1 )
¬culprit(exploit1 , apt8) -≺
time diff(interval, robotmafia)

Fig. 1: A ground argumentation framework.
hA1 ,
hA2 ,
hA3 ,
hA4 ,

replay attack(exploit1 ) i
deception(exploit1 , apt8) i
culprit(exploit1 , apt8)i
¬culprit(exploit1 , apt8)i

A1
A2
A3
A4

= {δ1 , θ1 , θ3 }
= {δ1 , δ2 , θ2 }
= {δ1 , δ2 , δ3 }
= {δ1 , δ4 , θ3 }

Fig. 2: Example ground arguments from Figure 1.

Strict Rules (Ω) represent cause and effect information; they
are of the form L0 ← L1 , ...Ln , where L0 is a literal and
{Li }i>0 is a set of literals.

meeting the requirements: (1) L is defeasibly derived from A2 ,
(2) Θ ∪ Ω ∪ ∆ is not contradictory, and (3) A is a minimal
subset of ∆ satisfying 1 and 2, denoted hA, Li.

Defeasible Rules (∆) are weaker versions of strict rules, and
are of the form L0 -≺ L1 , ...., Ln , where L0 , is the literal and
{Li }i>0 is a set of literals.

Literal L is called the conclusion supported by the argument, and A is the support. An argument hB, Li is a
subargument of hA, L0 i iff B ⊆ A. The following examples
show arguments for our scenario.

When a cyber-attack occurs, the model can be used to
derive arguments as to who could have conducted the attack.
Derivation follows the same mechanism as logic programming [11]. DeLP incorporates defeasible argumentation, which
decides which arguments are warranted and it blocks arguments that are in conflict and a winner cannot be determined.
Fig. 1 shows a ground argumentation framework demonstrating constructs derived from the CTF data. For instance, θ1
indicates the fact that exploit1 was used to target the team
Blue Lotus, and θ5 indicates that team pwnies is the most
frequent user of exploit1 . For the strict rules, ω1 says that
for a given exploit1 the attacker is pwnies if it was the
most frequent attacker and the attack exploit1 was replayed.
Defeasible rules can be read similarly; δ2 indicates that exploit1
was used in a deceptive attack by APT8 if it was replayed and
the first attacker was not APT8. By replacing the constants
with variables in the predicates we can derive a non-ground
argumentation framework.
Definition 1. (Argument) An argument for a literal L is a
pair hA, Li, where A ⊆ Π provides a minimal proof for L

840

Example 2. Fig. 2 shows

 example arguments based on the
KB from Fig. 1;
 here, A1 , replay attack(exploit
 1 ) 
is a
subargument of A2, deception(exploit1 , apt8) and A3 ,
culprit(exploit1 , apt8) .
For a given argument there may be counter-arguments that
contradict it. For instance, referring to Fig. 2, we can see that
A4 attacks A3 . A proper defeater of an argument hA, Li is
a counter-argument that—by some criterion—is considered to
be better than hA, Li; if the two are incomparable according
to this criterion, the counterargument is said to be a blocking
defeater. The default criterion used in DeLP for argument
comparison is generalized specificity [21].
A sequence of arguments is called an argumentation line.
There can be more than one defeater argument, which leads to
a tree structure that is built from the set of all argumentation
2 This means that there exists a derivation consisting of a sequence of rules
that ends in L—that possibly includes defeasible rules.

lines rooted in the initial argument. In this dialectical tree,
every child can defeat its parent (except for the root), and the
leaves represent unchallenged arguments; this creates a map
of all possible argumentation lines that decide if an argument
is defeated or not. Arguments that either have no attackers or
all attackers have been defeated are said to be warranted.



Given a literal L and an argument A, L , in order to
decide whether or not a literal L is warranted, every node
in the dialectical tree T (hA, Li) is recursively marked as “D”
(defeated) or “U” (undefeated), obtaining a marked dialectical
tree T ∗ (hA, Li) where:
•

All leaves in T ∗ (hA, Li) are marked as “U”s, and

•

Let hB, qi be an inner node of T ∗ (hA, Li). Then,
hB, qi will be marked as “U” iff every child of hB, qi
is marked as “D”. Node hB, qi will be marked as “D”
iff it has at least one child marked as “U”.

Given argument hA, Li over Π, if the root of T ∗ (hA, Li)
is marked “U”, then T ∗ (hA, hi) warrants L and that L is
warranted from Π. (Warranted arguments correspond to those
in the grounded extension of a Dung argumentation system
[7].)
In practice, an implementation of DeLP accepts as input
sets of facts, strict rules, and defeasible rules. Note that while
the set of facts and strict rules is consistent (non-contrdictory),
the set of defeasible rules can be inconsistent. We engineer
our cyber-attribution framework as a set of defeasible and
strict rules whose structure was created manually, but are
dependent on values learned from a historical corpus of data.
Then, for a given incident, we instantiate a set of facts for
that situation. This information is then provided as input into
a DeLP implementation that uses heuristics to generate all
arguments for and against every possible culprit for the cyber
attack. Dialectical trees based on these arguments are analyzed,
and a decision is made regarding which culprits are warranted.
This results in a reduced set of potential culprits, which we
then use as input into a classifier to obtain an attribution
decision.
IV.

BASELINE A RGUMENTATION M ODEL (BM)

In [13] machine learning techniques were leveraged on the
CTF data to identify the attacker. We will now provide a summary of the results obtained. The experiment was performed
as follows. The dataset was divided according to the target
team, building 20 subsets, and all the attacks were then sorted
according to time. The first 90% of the attacks were reserved
for training and the remaining 10% for testing. The byte and
instruction histograms were used as features to train and test
the model. Models constructed using a random forest classifier
performed the best, with an average accuracy of 0.37. Most of
the misclassified samples tend to be deceptive attacks and their
duplicates.
When using machine learning approaches it is difficult
to map the reasons why a particular attacker was predicted,
especially in cases of deception where multiple attackers were
associated with the same attack. Knowing the arguments that
supported a particular decision would greatly aid the analyst in
making better decisions dealing with uncertainty. To address
this issue we now describe how we can form arguments/rules

841

ω1 =

culprit(E, Y) ← last attack(E, Y), replay attack(E).

δ1 =

replay attack(E) -≺ attack(E, X), last attack(E, Y).

Fig. 3: Defeasible and strict rule for non-deceptive attack.
θ1 = decep (E, X), θ2 = frequent (E, F )
ω1 =
ω2 =

¬culprit(E, Y) ← first attack(E, Y), decep(E, X)
culprit(E, F ) ← frequent(E, F ), deception (E, Di )

δ1 =
δ2 =

replay attack(E) -≺ attack(E, X), last attack(E, Y)
deception(E, Di ) -≺ replay attack(E),
first attack(E, Y)
culprit(E, Di ) -≺ deception(E, Di ), first attack(E, Y)

δ3 =

Fig. 4: Facts and rules for deceptive attacks.

based on the latent variables computed from the training data,
given an attack for attribution.
We use the following notation: let E be the test attack
under consideration aimed at target team X, Y represent all
the possible attacking teams, and D be the set of all deceptive
teams (those using the same payload to target the same team)
if the given attack is deceptive in the training set. For nondeceptive attacks, D will be empty. We note that facts cannot
have variables, only constants (however, to compress the
program for presentation purposes, we use meta-variables in
facts). To begin, we define the facts: θ1 = attack (E, X), θ2 =
first attack (E, Y), θ3 = last attack (E, Y); θ1 states that
attack E was used to target team X, θ2 states that team Y
was the first team to use the attack E in the training data, and
similarly θ3 states that team Y was the last team to use the
attack E in the training data. The first and last attacking team
may or may not be the same. We study the following three
cases:
Case 1: Non-deceptive attacks. In non-deceptive attacks, only
one team uses the payload to target other teams in the training
data. It is easy to predict the attacker for these cases, since the
search space only has one team. To model this situation, we
define a set of defeasible and strict rules.
In Fig. 3, defeasible rule δ1 checks whether the attack was
replayed in the training data. Since it is a non-deceptive attack,
it can only be replayed by the same team. The strict rule ω1
then puts forth an argument for the attacker (culprit) if the
defeasible rule holds and there is no contradiction for it.
Case 2: Deceptive attacks. These attacks form the majority
of the misclassified samples in [13]. The set D is not empty
for this case; let Di denote the deceptive teams in D. We
also compute the most frequent attacker from the training
data given a deceptive attack. Let the most frequent deceptive
attacker be denoted as F . The DeLP components that model
this case are shown in Figure 4; fact θ1 indicates if the attack
E was deceptive towards the team X and θ2 indicates the most
frequent attacker team F from the training set. The strict rule
ω1 indicates that in case of deception the first team to attack
(Y) is not the attacker, ω2 states that the attacker should be
F if the attack is deceptive and F was the most frequent

Average time (sec) - Log Scale

10000

Θ:

θ1 =

timedifference (E, X)

1000

∆:

δ1 =

For Y ∈
/ interval:
¬culprit(E, Y) -≺ timedifference (E, X).

Fig. 6: Time facts and rules. Interval indicates a small portion
of the entire deceptive time (for instance < 2000 sec, > 8000
sec and so on).

100

10

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

Deceptive

T-10

T-8

T-7

T-6

T-5

T-4

T-3

T-2

T-1

1

teams not belonging to the interval to not be the culprits, as
shown in Fig. 6.

Replay

Fig. 5: Average time for team to perform a deceptive attack
and replay its own attack (Log-scale).

deceptive attacker. For the defeasible rules, δ1 deals with the
case in which the attack E was replayed, δ2 deals with the case
of deceptive teams from the set D, δ3 indicates that all the
deceptive teams are likely to be the attackers in the absence of
any contradictory information. and δ4 states that the attacker
should be F if the attack is deceptive and F was the most
frequent attacker.
Case 3: Previously Unseen Attacks. The most difficult attacks
to attribute in the dataset are the unseen ones, i.e. attacks first
encountered in the test set and thus did not occur in the training
set. To build constructs for this kind of attack we first compute
the k nearest neighbors from the training set according to a
simple Euclidean distance between the byte and instruction
histograms of the two attacks. In this case we choose k =
3. For each of the matching attacks from the training data
we check if the attack is deceptive or non-deceptive. If nondeceptive, we follow the procedure for Case 1, otherwise we
follow the procedure for Case 2. Since we replace one unseen
attack with three seen attacks, the search space for the attacker
increases for unseen attacks.
Attacker Time Analysis: The CTF data provides us with time
stamps for the attacks in the competition. We can use this
information to come up with rules for/against an argument for
a team being the attacker. We compute the average time for a
team to replay its own attack given that it was the first one to
deploy the attack (see Fig. 5). It can be observed that teams
like more smoked leet chicken (T-13) and Wowhacker-bios (T8) are very quick to replay their own attacks as compared to
other teams. Fig. 5 also shows the average time for a team
to perform a deceptive attack. Teams like The European (T-7)
and Blue lotus (T-10) are quick to commit deception, while
others take more time.
We use this time information to narrow down our search
space for possible attackers. In particular, for a deceptive
test sample, we compute the time difference between the test
sample and the training sample that last used the same payload.
We denote this time difference as 4t, and include it as a
fact θ1 . We then divide the deceptive times from Fig. 5 into
appropriate intervals; each team is assigned to one of those
time intervals. We then check which time interval 4t belongs
to and define a defeasible rule δ1 that makes a case for all

842

We now provide a summary of the experimental results—
the setup is similar to [13]: the dataset is sorted by time for
each target team, the first 90% of the data is used for training
and the remaining 10% for testing. The constructs for all test
samples based on the cases discussed in the previous section
are computed, and these arguments are used as input to the
DeLP implementation. For each test sample the DeLP system
is queried to find all possible attackers (culprits) based on
the arguments provided. If there is no way to decide between
contradicting arguments, these are blocked and thus return no
answers. Initially, the search space for each test sample is 19
teams (all except the one being attacked).
After running the queries to return the set of possible
culprits, the average search space across all target teams is
5.85 teams. This is a significant reduction in search space
across all target teams; to gauge how much the reduced search
space can aid an analyst in predicting the actual culprit, a
metric is computed that checks if the reduced search space
contains the ground truth (actual culprit). For all the target
teams, the ground truth is present on average in almost 66%
of the samples with reduced search space. For some teams
like more smoked leet chicken (T-13) and raon ASRT (whois)
(T-17) the average reduced search space is as low as 1.82 and
2.9 teams, with high ground truth fraction of 0.69 and 0.63,
respectively.
Predictive analysis is then performed on the reduced search
space. The experimental setup is similar to the one described
earlier; the only difference this time is instead of having a 19
team search space as in [13], the machine learning approach
is allowed to make a prediction from the reduced search space
only; a random forest is used for learning, which has been
shown to have the best performance for CTF data [13].
We report the following average accuracies across 20
target teams; the accuracy achieved after running Random
forest without applying the argumentation-based techniques,
as reported in [13], is 0.37. This was the best performing
approach using standard machine learning techniques. The
baseline model achieves an average accuracy of 0.5, which is
significantly better than the average accuracy of 0.37 in [13].
V.

E XTENDED BASELINE M ODEL I (EB1)

Previously Unseen attacks make up almost 20% of the test
samples for each target team. On analyzing the misclassification from the baseline argumentation model, we observe that
the majority of the previously unseen attacks get misclassified
(>80%). The misclassifications can be attributed to two reasons: (i) the reduced search space is not able to capture the

Θ:

θ1 =
θ2 =

∆:

δ1 =
δ2 =

For (ni ∈ N and sim < T ):
threshold(E, T )
For ui in U:
unique(E, ui )
culprit(E, ui ) -≺ threshold(E, T )
For ui ∈ U:
culprit(E, ui ) -≺ unique(E, ui )

Θ:

θ1 =

timedifference (E, X)

∆:

δ1 =

For Y ∈ interval:
culprit(E, Y) -≺ timedifference (E, X).

Fig. 8: Time facts and rules. Interval indicates a small portion
of the entire deceptive time (for instance < 2000 sec, > 8000
sec and so on).

Fig. 7: Rules for unseen attacks.

ground truth for unseen attacks, leading the learning model to
a wrong prediction; and (ii) we represent each unseen attack
by the 3 most similar attacks in the training data; this leads
to an increase in the search space and many choices for the
learning model.
We address these issues by proposing two sets of defeasible
rules. First, for each target team we compute from the training
set the top 3 teams that come up with the most unique exploits,
as these teams are more likely to launch an unseen attack in
the test set. The intuition behind this rule is the fact that not
all teams write their own exploits, most teams just capture a
successful exploit launched by other teams and repackage it
and use it as their own (deception). The second set of rules
is proposed to avoid addition of less similar teams to the
reduced search space. In the baseline model we use 3-nearest
neighbors to represent an unseen attack. In this extended
version we consider only the nearest neighbors that are less
than a particular threshold value T , which is decided for each
target team separately. So, each attack will be represented by
k ≤ 3 teams depending upon the threshold requirement. In
addition to the baseline model rules, we propose the following
rules for deceptive attacks. Let U denote the set of teams with
the three highest numbers of unique attacks in the training
data. Also, let N denote the set of three most similar culprits
for the given unseen attack.
The extended model is shown in Fig. 7; the fact θ1 indicates
the teams present in N and whose similarity is less than a
particular threshold T , and θ2 indicates if the team ui was
one of most unique attackers from set U. For the defeasible
rules, δ1 makes use of the fact θ1 stating that the teams in N
that satisfy the threshold condition are likely to be the culprits,
and δ2 indicates that if ui is a unique attacker then it can be
the culprit unless contradictory information is available. U is
independent of the test samples and will be the same for all
unseen attacks given a target team.
On the contrary, for each of the similar payloads (three or
fewer) computed from the training data we check if the attack
is deceptive or non-deceptive. If non-deceptive, we follow the
procedure for Case 1, otherwise we follow the procedure for
Case 2 stated in the baseline argumentation model.
Experiment: We evaluate EB1 using an experimental setup
similar to the one for the baseline argumentation model. We report the average reduced search space and prediction accuracy
for both EB1 and baseline model to provide a comparison. EB1
performs better than the baseline with an average accuracy of
0.53 vs. 0.50, and significantly better than the machine learning
model without argumentation that has an average accuracy of
0.37. The improvement in performance is due to the larger

843

fraction of reduced search spaces with ground truth present
in them. Also, the search space reduced from on average 6.07
teams to 5.025 (less teams to consider). The results are reported
in Table 3 along with a comparison to the second extended
baseline argumentation model (EB2).
VI.

E XTENDED BASELINE M ODEL II (EB2)

Another source of misclassification in the baseline argumentation model is the presence of unseen deceptive teams
and their duplicates. These refer to teams that did not use the
exploit in the training set but started using it in the test set. It
is difficult for a machine learning approach to predict such a
team as being the culprit if it has not encountered it using the
exploit in the training set. In our dataset these attacks comprise
15% of the total, and up to 20% for some teams.
In order to address this issue we propose an extension
of EB1, where we group together teams that have similar
deceptive behavior based on the time information available to
us from the training set; for instance teams that are deceptive
within a certain interval of time (e.g., less than 2,000 secs.)
after the first attack has been played are grouped together. For
a given test attack we compute the time difference between
the test attack and the last time the attack was used in the
training set. We then assign this time difference to a specific
group based on which interval the time difference falls in.
In order to fine tune the time intervals, instead of using the
average deceptive times averaged across all target teams (as
used in the baseline model), we compute and use deceptive
times for each target team separately. We model the time rules
as stated in Fig. 8; fact θ1 states the time difference between
the test sample and the last training sample to use that attack,
defeasible rule δ1 on the other hand states that teams belonging
to that interval (in which the time difference lies) are likely to
be the culprits unless a contradiction is present. It is clear that
this rule will increase the search space for the test sample,
as additional teams are now being added as likely culprits.
We observe that for EB2 the search space is increased by an
average of almost 2.5 teams per test sample from EB1; at the
same time the presence of ground truth in the reduced search
space increased to 0.78, which is a significant improvement
over 0.68.
Experiment: We evaluate EB2 using an experimental setup
similar to the one discussed in the baseline argumentation
model. We report the prediction accuracies for each of the
proposed baseline argumentation models for each of the target
teams and compare it with the previous accuracy reported
in [13], denoted as ML. In Table 3 the second extended
baseline model (EB2) performs the best with an average
prediction accuracy of 62% as compared to other proposed
methods. The additions of teams based on time rules not only

benefits detection of unseen deceptive teams but it also helps
in predicting attackers for unseen attacks. The major reason
for the jump in performance is that for most unseen deceptive
team samples, the time rules proposed in the baseline model
block all deceptive teams from being the culprit, leading to
an empty set of culprits. The new set of rules proposed in
EB2 adds similar-behaving teams to this set based on time
information; the learning algorithm can then predict the right
one from this set.

R EFERENCES
[1]

[2]
[3]

[4]

TABLE 3: Results Summary
Team

ML [13]

BM

EB1

EB2

T-1

0.45

0.51

0.52

0.60

T-2

0.22

0.45

0.38

0.43

T-3

0.30

0.40

0.47

0.66

T-4

0.26

0.44

0.42

0.44

T-5

0.26

0.45

0.45

0.56

T-6

0.5

0.49

0.55

0.7

T-7

0.45

0.53

0.56

0.66

T-8

0.42

0.61

0.58

0.74

T-9

0.41

0.50

0.53

0.76

T-10

0.30

0.42

0.41

0.41

T-11

0.37

0.44

0.5

0.73

T-12

0.24

0.43

0.36

0.52

T-13

0.35

0.63

0.64

0.75

T-14

0.42

0.52

0.53

0.67

T-15

0.30

0.38

0.55

0.64

T-16

0.43

0.48

0.55

0.65

T-17

0.42

0.58

0.58

0.68

T-18

0.48

0.50

0.52

0.65

T-19

0.41

0.51

0.56

0.68

T-20

0.48

0.51

0.64

0.71

[5]

[6]
[7]

[8]

[9]

[10]

[11]
[12]

[13]

[14]

VII.

[15]

C ONCLUSION

In this paper we demonstrated how an argumentationbased framework (DeLP) can be leveraged to improve cyberattribution decisions by building DeLP programs based on
CTF data; this affords a reduction of the set of potential
culprits and thus greater accuracy when using a classifier for
cyber attribution. We are currently looking at implementing a
probabilistic variant of DeLP [19], as well as designing our
own CTF event in order to better mimic real-world scenarios.
Our new CTF will encourage deceptive behavior among the
participants, and we are also enhancing our instrumentation of
the CTF, allowing for additional data collection (host data is
of particular interest).
VIII.

ACKNOWLEDGMENTS

[16]

[17]
[18]

[19]

[20]

[21]

Authors of this work were supported by the U.S. Department of the Navy, Office of Naval Research, grant N00014-151-2742 as well as the Arizona State University Global Security
Initiative (GSI) and by CONICET and Universidad Nacional
del Sur, Argentina.

844

[22]

A. Applebaum, K. Levitt, Z. Li, S. Parsons, J. Rowe, and E. Sklar.
Cyber reasoning with argumentation: Abstracting from incomplete and
contradictory evidence. In Proc. of MILCOM, 2015.
W. E. Boebert. A survey of challenges in attribution. In Proc. of a
workshop on Deterring CyberAttacks, pages 41–54, 2010.
M. Brückner, C. Kanzow, and T. Scheffer. Static prediction games
for adversarial learning problems. The Journal of Machine Learning
Research, 13(1):2617–2654, 2012.
M. Brückner and T. Scheffer. Stackelberg games for adversarial prediction problems. In Proceedings of the 17th ACM SIGKDD international
conference on Knowledge discovery and data mining, pages 547–555.
ACM, 2011.
M. Dacier, V.-H. Pham, and O. Thonnard. The wombat attack attribution
method: some results. In Information Systems Security, pages 19–37.
Springer, 2009.
DEFCON. DEFCON: Capture the flag. https://media.defcon.org/, 2013.
[Online; accessed January-2015].
P. M. Dung. On the acceptability of arguments and its fundamental role
in nonmonotonic reasoning, logic programming and n-person games.
Artificial intelligence, 77(2):321–357, 1995.
A. J. Garcı́a and G. R. Simari. Defeasible logic programming: An
argumentative approach. Theory and practice of logic programming,
4(1+ 2):95–138, 2004.
L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. Tygar.
Adversarial machine learning. In Proceedings of the 4th ACM workshop
on Security and artificial intelligence, pages 43–58. ACM, 2011.
B. Li and Y. Vorobeychik. Feature cross-substitution in adversarial
classification. In Z. Ghahramani, M. Welling, C. Cortes, N. D.
Lawrence, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 27, pages 2087–2095. Curran Associates,
Inc., 2014.
J. W. Lloyd. Foundations of logic programming. Springer Science &
Business Media, 2012.
D. Lowd and C. Meek. Adversarial learning. In Proceedings of
the eleventh ACM SIGKDD international conference on Knowledge
discovery in data mining, pages 641–647. ACM, 2005.
E. Nunes, N. Kulkarni, P. Shakarian, A. Ruef, and J. Little. Cyberdeception and attribution in capture-the-flag exercises. In Proceedings
of the 2015 IEEE/ACM International Conference on Advances in Social
Networks Analysis and Mining, ASONAM 2015, Paris, France, August
25 - 28, 2015, pages 962–965, 2015.
I. Rahwan, G. R. Simari, and J. van Benthem. Argumentation in
artificial intelligence, volume 47. Springer, 2009.
T. Rid and B. Buchanan. Attributing cyber attacks. Journal of Strategic
Studies, 38(1-2):4–37, 2015.
J. Salvit, Z. Li, S. Perumal, H. Wall, J. Mangels, S. Parsons, and E. I.
Sklar. Employing argumentation to support human decision making:
A user study. In AAMAS Workshop on Argumentation in Multiagent
Systems, 2014.
P. Shakarian, J. Shakarian, and A. Ruef. Introduction to cyber-warfare:
A multidisciplinary approach. Elsevier, 2013.
P. Shakarian, G. I. Simari, G. Moores, and S. Parsons. Cyber attribution:
An argumentation-based approach. In Cyber Warfare: Building the
Scientific Foundation, pages 151–171. Springer, 2015.
P. Shakarian, G. I. Simari, G. Moores, D. Paulo, S. Parsons, M. Falappa,
and A. Aleali. Belief revision in structured probabilistic argumentation.
Annals of Mathematics and Artificial Intelligence, pages 1–43, 2015.
E. I. Sklar, S. Parsons, Z. Li, J. Salvit, S. Perumal, H. Wall, and
J. Mangels. Evaluation of a trust-modulated argumentation-based
interactive decision-making tool. Autonomous Agents and Multi-Agent
Systems, pages 1–38, 2015.
F. Stolzenburg, A. J. Garcı́a, C. I. Chesnevar, and G. R. Simari.
Computing generalized specificity. Journal of Applied Non-Classical
Logics, 13(1):87–113, 2003.
R. J. Walls. Inference-based Forensics for Extracting Information from
Diverse Sources. PhD thesis, University of Massachusetts Amherst,
2014.

Mining for Causal Relationships: A Data-Driven Study of
the Islamic State
Andrew Stanton, Amanda Thart, Ashish Jain, Priyank Vyas, Arpan Chatterjee, Paulo Shakarian∗
Arizona State University
Tempe, AZ 85287

arXiv:1508.01192v1 [cs.CY] 5 Aug 2015

{dstanto2, althart, ashish.jain.1, pvyas1, achatt14, shak} @asu.edu
ABSTRACT
The Islamic State of Iraq and al-Sham (ISIS) is a dominant
insurgent group operating in Iraq and Syria that rose to
prominence when it took over Mosul in June, 2014. In this
paper, we present a data-driven approach to analyzing this
group using a dataset consisting of 2200 incidents of military activity surrounding ISIS and the forces that oppose
it (including Iraqi, Syrian, and the American-led coalition).
We combine ideas from logic programming and causal reasoning to mine for association rules for which we present
evidence of causality. We present relationships that link
ISIS vehicle-bourne improvised explosive device (VBIED)
activity in Syria with military operations in Iraq, coalition
air strikes, and ISIS IED activity, as well as rules that may
serve as indicators of spikes in indirect fire, suicide attacks,
and arrests.

1.

INTRODUCTION

Since its rise to prominence in Iraq and Syria in June,
2014, The Islamic State of Iraq and al-Sham (ISIS) – also
known as The Islamic State of Iraq and the Levant (ISIL)
or simply the Islamic State, has controlled numerous cities
in Sunni-dominated parts of Iraq and Syria. ISIS has displayed a high level of sophistication and discipline in its military operations in comparison to similar insurgent groups,
which perhaps may be the source of its success. We have
meticulously encoded and recorded 2200 incidents of military activity conducted by ISIS and forces that oppose it
(including Iraqi, Syrian, and the American-led coalition) in
a relational database. Our goal was to achieve a better understanding of how this group operates - which can lead to
new strategies for mitigating ISIS’s operations. Specifically,
we sought to analyze the behavior of ISIS using concepts
from logic programming (in particular APT logic [14, 15])
and causal reasoning [10, 18]. By combining ideas from these
fields, we have been able to conduct a thorough search for
∗

Paulo Shakarian is also affiliated with ASU Center on the
Future of War.

rules whose precondition consists of multiple atomic propositions, and we provide evidence of causality by comparing
rules with the same consequence. So, in addition to considering the probability of a rule (p), we also study a measure
of its causality denoted avg (previously introduced in [10]) –
which, informally, can be thought of as the average increase
in probability a rule’s precondition provides when considered
with each of the comparable rules. Using this approach, we
have found interesting relationships - consider the following:
• Weeks where ISIS conducts infantry operations in Iraq
that are accompanied by indirect fire are indicative of
vehicle-bourne improvised explosive device (VBIED)
operations in Syria in the following week (p = 1.0,
avg = 0.92).
• Weeks in which ISIS conducts operations in Tikrit
and conducts a significant number of executions are
followed by a large spike in improvised explosive device (IED) usage in Iraq and Syria combined (p =
1.0, avg = 0.97)
• Air strikes by the Syrian government are followed by
mass arrests by ISIS in the following week (avg =
0.91, p = 0.67), and such massive arrests were always
proceeded by Syrian air strikes in our dataset.
• In the week after coalition air strikes are conducted
against Mosul while ISIS is conducting operations in
Al-Anbar province, ISIS greatly increases its IED activity in Iraq (p = 0.67, avg = 0.97). However, if
there are also significant ISIS operations occurring in
Syria, the increase in IED usage experienced there is
(p = 0.67, avg = 0.79).
Our findings have also led us to several interesting theories
about ISIS behavior that we have developed as a result of
this data mining effort. These include the following:
• ISIS may employ suicide VBIED operations in Baghdad prior to significant infantry operations in other locations to prevent the deployment of Iraqi army/police
reinforcements.
• ISIS tends to leverage indirect fire (IDF) as a precursor
to infantry operations - more in keeping with a traditional military force as opposed to a primary use of
IDF for harassment purposes (as was typically seen by
insurgent groups during Operation Iraqi Freedom).

.

• As we found relationships between coalition air operations and an increase in ISIS usage of IEDs - and

not other, larger weapons systems (i.e. VBIEDs), this
may indicate that ISIS resorts to more distributed,
insurgent-style tactics in the aftermath of such operations.
To our knowledge, this study represents both the first publiclyavailable, data-driven study of ISIS as well as the first combination of APT logic with the causality ideas of [10]. The
rest of the paper is organized as follows. In Section 2, we describe our approach and recall key concepts from APT logic
and causal reasoning. This is followed by a description of
our corpus of military events surrounding the actions of ISIS
from June-December, 2014 in Section 3. In Section 4, we describe our implementation and discuss our results. Finally,
related work is reviewed in Section 5.

2.

TECHNICAL APPROACH

2.1

APT Logic

We now present a subset of our previously-introduced
APT logic [14, 15]. Our focus here is on the syntax of the
language utilized with an alternate semantics that is based
on the rule-learning approach described in [14]. This is due
to the fact that we are only concerned with learning the
rules in this paper and determining their level of causality
– we leave problems relating to deduction (i.e. the entailment problem studied in [15]) to future work. APT logic
considers a two-part semantic structure: threads (sequences
of events) and interpretations (probability distributions over
such sequences). Initially, we focus on a semantics restricted
to threads.
We assume the existence of a set of ground atoms, A which
in this case correspond with events over time and use the
symbol n to denote the size of this set. We shall partition
the ground atoms into two subsets: action atoms Aact and
environmental atoms Aenv . Action atoms describe actions
of certain actors, and environmental atoms describe aspects
of the environment. We will use nact , nenv to denote the
quantity of ground atoms in Aact , Aenv , respectively. We
can connect atoms using ¬, ∧, ∨ to create formulas in the
normal way. A world is a subset of atoms that are considered
to be true. A thread is a series of worlds, each corresponding
to a discrete time-point, which are represented by simple
natural numbers in the range 1, . . . , tmax . We shall use Th[t]
to refer to the world specified by Th at time t. A thread
(Th) at time t satisfies a formula f (denoted Th[t] |= f ) by
the following recursive definition:
• For some a ∈ A, Th[t] |= a iff a ∈ Th[t]
• For f = ¬f 0 , Th[t] |= f iff Th[t] |= f 0 is false
• For f = f 0 ∧f 00 , Th[t] |= f iff Th[t] |= f 0 and Th[t] |= f 00

Note that we use the notation | · | for the cardinality of a set.
Our goal in this section is for some event g to identify previously occurring event c such that the conditional probability
of g occurring given c is greater than pg . In this paper, we
shall only look at finding APT rules where c occurs in the
time period right before g. The case where multiple time periods elapse between c and g is left to future work. Hence, we
introduce an APT rule of the following form: c ;p g, which
intuitively means that “c is followed by g in one time-step
with probability p.” We shall refer to c as the precondition
and g as the consequence. We say thread Th |= c ;p g iff:
p=

|{t s.t. Th[t] |= c and Th[t + 1] |= g}|
|{t s.t. Th[t] |= c}|

(2)

This alternate definition of semantics is not new: it is a variant of rule satisfaction with the existential frequency function of [14] and also of “trace semantics” used for a PCTL
variant in [9]. In this paper, we are focused on learning rules
where c is a conjunction of positive atoms and g is a single
positive atom. The number of atoms in the conjunction c is
referred to as the “dimension” of the rule c ;p g. We will
also be concerned with two other measures of a given rule:
the “negative probability” (used to describe the probabilistic
rules of [17]) and the notion of support (a standard concept
in association rule learning). First, we define “negative probability” – denoted p∗ – for a given rule of the aforementioned
format.
p∗ =

|{t s.t. Th[t] |= g and Th[t − 1] 6|= c}|
|{t s.t. Th[t] |= g}|

(3)

Simply put, p∗ is the number of times that the consequence
of a rule occurs without the head occurring prior. We can
think of p as a measure of precision of a given rule while p∗
is more akin to a measure of recall. Next, we formally define
the notion of support (s) as follows.
s = |{t s.t. Th[t] |= c}|

(4)
pr , p∗r , sr ,

For a given rule r, we shall use the notation
respectively. We will also use the notation ρr to denote the
prior probability of the consequence. When it is obvious
from context which rule we are referring to (as in the experimental results section), we will drop the subscript.

2.2

Determining Causality

Next, we describe how for a given action, g, we identify
potential causes based on a set of rules for which g is the
consequence. In considering possible causes, we must first
identify a set of prima facie causes for g [10, 18]. We present
the definition in terms of APT logic below.
Definition 2.1 (Prima Facie Cause [10, 18]). Given
APT logic formulas c, g and thread Th, we say c is a prima
facie cause for g w.r.t. Th if:

• For f = f 0 ∨ f 00 , Th[t] |= f iff Th[t] |= f 0 or Th[t] |= f 00

1. There exists time t such that Th[t] |= g (g occurs with
a probability greater than zero)

We also note that based on how often a given formula occurs within a thread, we can obtain a prior probability for
that formula. For instance, consider formula g. We can compute its prior probability (w.r.t. thread Th) as the fraction
of time points where g is satisfied:

2. There exists t, t0 where t < t0 such that Th[t] |= c and
Th[t0 ] |= g (c occurs before g)

ρ=

|{t|Th[t] |= g}|
tmax

(1)

3. For r ≡ c ;p g where Th |= r, we have p > ρr (the
probability of the consequence occurring after the precondition is greater than the prior probability of the
consequence)

As we will assume the existence of a single thread, Th
(which is our historical corpus of data), we will often use the
language “prima facie causal rule” or “PF-rule” to describe
a rule c ;p g where c is a prima facie cause for g w.r.t. Th.
Next, we adopt the method of [10] to determine if an APT
rule is causal. First, in determining if a given PF-rule is
causal, we must consider other, related PF-rules. Intuitively,
a given rule r ≡ c ;p g explains why some instances of g
occur within a thread. Another rule r0 ≡ c0 ;p0 g is related
if it also explains why some of those same instances occur.
Formally, we say r and r0 are related if there exists t such
that Th[t] |= c ∧ c0 and Th[t + 1] |= g. Hence, we will define
related PF-rules (for a given rule r ≡ c ;p g) as follows.
R(r) = {r0 s.t. r0 6≡ r and r, r0 are related}
Next, we will look at how to compare two related rules.
The key purpose from [10] behind doing so is to study how
the probability of the rule changes in cases where both preconditions co-occur in comparison to the probability where
exactly one of the preconditions occurs. So, given rules r, r0
as defined above, we have the following notation: pr,r0 and
p¬r,r0 , which are defined as the point probabilities that will
cause the following two rules to be satisfied by Th.
c ∧ c0 ;pr,r0 g
¬c ∧ c0 ;p¬r,r0 g
So, pr,r0 is the probability that g occurs given both preconditions, and p¬r,r0 is the probability that g occurs given just
the precondition of the second rule and not of the first. The
idea is that if pr,r0 − p¬r,r0 > 0, then there is something
about the precondition of r that causes g to occur that is
not present in r0 . Following directly from [10], we measure
the average of this quantity to determine how causal a given
rule is as follows:
P
0
0
r 0 ∈R(r) pr,r − p¬r,r
avg =
|R(r)|
Intuitively, avg (r) measures the degree of causality exhibited by rule r. Additionally, using this same intuition, we
find it useful to include a few other related measures when
examining causality. First, we define min , defined below:
min

=

min (pr,r0 − p¬r,r0 )

r 0 ∈R(r)

This tells us the “least causal” comparison of r with all related rules. Another measure we will use is f rac , defined as
follows:
f rac (r)

=

|{r0 s.t. (pr,r0 − p¬r,r0 ) ≥ 0}|
|R(r)|

This provides a fraction of the related rules whose probability remains the same or decreases if the precondition of
r is not present. Hence, a number closer to 1 likely indicates that r is more causal. By using multiple causality
measurements, we can have a better determination of more
significant causality relationships.

2.3

Algorithms

Next, given a thread, we provide a variant of the APTExtract algorithm [14] that we call PF-Rule-Extract. Essentially, this algorithm generates all possible Aenv up to a
certain size (specified by the argument M axDim) and then

searches for correlation. It returns rules whose precondition occurs a specified number of times (a lower bound on
support for a rule) - specified with the argument SuppLB.
We make several modifications specific to our application to
support reasoning.
• We reduce the run-time of the algorithm considerably
over APT-Extract. As APT-Extract explores all possible combinations ofatoms up to size M axDim, it runs
env
in time O( M naxDim
). However, PF-Rule-Extract only
examines combinations of atoms that occur in a given

maxt (nt )
time period – hence, reducing run-time to O( M
)
axDim
where nt is the number of atoms in Aenv true at time
t. We find in practice that maxt (nt ) << nenv .
• We further reduce the run-time by not considering elements of Aenv that occur less than the lower bound
on support - as they would never appear in a rule.
• We guarantee that all rules returned by PF-Rule-Extract
are PF-rules.
Algorithm 1 PF-Rule-Extract
Require: Thread Th, sets of atoms Aact , Aenv , positive natural numbers M axDim, SuppLB, real number
minP rob
Ensure: Set of rules R
1: Set R = ∅
2: for g ∈ {a ∈ Aact s.t. ∃t where Th[t] |= a} do
3:
preCond(g) = ∅
4:
for t ∈ {1, . . . , tmax s.t. Th[t + 1] |= g} do
5:
Let X be the set of all combinations of size
M axDim (or less) of elements in Th[t] ∩ Aenv that
occur at least SuppLB times.
6:
preCond(g) = preCond(g) ∪ X
7:
end for
8:
for c ∈ preCond(g) do
9:
Compute ρ, p, s, as per Equations 1,2, and 4
10:
if (s ≥ SuppLB) ∧ (p > ρ) ∧ (p ≥ minP rob) then
11:
R = R ∪ {r}
12:
end if
13:
end for
14: end for
15: return Set R
Note that APT-Extract allows for multiple time periods
between preconditions and consequences – PF-Rule-Extract
can also be easily modified to find rules of this sort through a
simple modification of line 4. Next, we provide some formal
results to show that PF-Rule-Extract finds rules that meet
the requirements of Definition 2.1 and show that it explores
all possible combinations up to size M axDim that are supported by the data that meet the requirement for minimum
support even with our efficiency improvements.
Proposition 2.1. Given thread Th as input, PF-RuleExtract produces a set of rules R such that each r ∈ R is a
prima facie causal rule.
Proof. The first requirement for a prima facie cause is
met by line 2 of PF-Rule-Extract, as the algorithm only considers consequences that have occurred at least once in Th –
hence, they have a prior probability greater than zero. The

second requirement is met by line 4, as we only consider
atoms that occurred immediately before the consequence
when constructing the precondition. Finally, the third condition is met by the if statement at line 10 which will only
select rules whose probability is greater than the prior probability of the consequence.
Proposition 2.2. PF-Rule-Extract finds all PF-rules whose
precondition is a conjunction of size M axDim or a size containing fewer atoms and where both the precondition occurs
at least SuppLB times in Th and the probability is greater
than minP rob.
Proof. By Proposition 2.1, every consequence that could
be used in a PF-rule is considered, so we need only to consider the precondition. Suppose that there is a PF-rule
whose precondition occurs at least SuppLB times that has a
size of M axDim or smaller. Hence, the precondition is comprised of m ≤ M axDim atoms: a1 , . . . , am . Clearly, as this
precondition occurs at least SuppLB times in Th, each of
a1 , . . . , am must also occur SuppLB times by line 5 - so that
the precondition must be considered at that point. The only
condition that would prevent the rule from being returned
is line 10, but again, clearly these are met by the statement
of the proposition. Hence, we have a contradiction.
Once we have identified the PF-rules using PF-Rule-Extract,
we must then compare related rules with each other. The algorithm PF-Rule-Compare returns the top k rules for each
consequence. Again, here we take advantage of our specific application to reduce the run-time of this comparison.
In particular, for a given rule, we need not compare it to
all the rules returned by PF-Rule-Extract; we only need to
compare it to those that share the consequence. By sorting
the rules by consequence - a linear time operation (line 3),
we are able to reduce the cost of the quadratic operation
for the rule comparisons (a brute-force method would take
O(|R|2 ) while this method requires O((maxg |Rg |)2 + |R|) –
and we have observed that maxg |Rg | << |R|).
Algorithm 2 PF-Rule-Compare
Require: Set of rules R, natural number k
Ensure: Set of rules R0
1: Set R0 = ∅.
2: for g ∈ Aact do
3:
Set Rg = {c ;p g ∈ R}
4:
for r ∈ Rg do
5:
Calculate avg for rule r (Equation 5 by comparing
it to all related rules in Rg \ {r})
6:
end for
7:
From the set Rg , add the top k rules by avg to the
set R0
8: end for
9: return Set R0

3.

ISIS DATASET

We collected data on 2200 military events that occurred
from June 8th through December 31st, 2014 that involved
ISIS and forces opposing ISIS. Events were classified into one
of 159 event types - and these events were used as predicates
for APT logic atoms. We list a sampling of the predicates
we used in Table 1. Many predicates are unary because

they correspond with ISIS actions (i.e. armedAtk) while
those dealing with operations by other actors (i.e. airOp)
and predicates denoting spikes in activity (i.e. VBIEDSpike)
accept more than one argument. Nearly every predicate has
one argument that corresponds to the location in which the
associated event took place. See Figure 1 for a sampling of
locations in the ISIS dataset.
We obtained our data primarily from reports published by
the Institute for the Study of War (ISW) [5], and we augmented it with other reputable sources including MapAction
[4, 6], Google Maps [3], and Humanitarian Response [2]. We
devised a code-book as well as coding standards for events,
and one of our team members functioned as a quality-control
to reduce errors in human coding.
Figure 1: Map illustrating cities associated with events in
the ISIS dataset.

4.
4.1

RESULTS AND DISCUSSION
Experimental Setup

We implemented our PF-Rule-Extract and PF-Rule-Compare
in Python 2.8x and ran it on a commodity machine equipped
with an Intel Core i5 CPU (2.7 GHz) with 16 GB of RAM
running Windows 7. The time periods we utilized were
weeks - hence, we had 30 time periods in our thread. We had
980 distinct environmental atoms (Aenv ). Our action atoms
(Aact ) corresponded to weeks where the number of incidents
for certain activity rose to or past one or two moving standard deviations (denoted 1 × σ, 2 × σ respectively, computed
based on the previous 4 weeks) above the four-week moving
average (computed based on the previous 4 weeks). We refer to these atoms as “spikes” and show some sample atoms
denoting such spikes in Table 1. The spikes are designated
for three locations: Iraq, Syria, or both theaters combined.
We also included these spikes in the set of environmental
atoms as well (Aact ⊂ Aenv ).
We set the parameters of PF-Rule-Extract as follows:
M axDim = 3, SuppLB = 3, minP rob = 0.5. For PF-RuleCompare, we did not set a particular k value. Instead, we
used avg to rank the rules by causality for a given consequence. In this paper, we report the top causal rules (in
terms of avg ) for some of the consequences. We also note
that the number of related rules provides insight into that
rule’s significance - we discuss this quantity in our analysis. We examine some of the top rules in terms of avg and

Table 1: A sampling of predicate symbols used to describe
events in the ISIS Dataset
Predicate
Intuition
airOp(X, Y )

Actor X (typically “Coalition,”
“Syrian Government,” or “U.S.”)
conducts an air campaign against
ISIS in the vicinity of city Y .

armedAtk(X)

ISIS conducts an armed attack
(a.k.a. infantry operation) in city
X.

IED(X)

ISIS conducts an attack using an
improvised explosive device (IED)
in city X.

indirectFire(X)

ISIS conducts an indirect fire operation (i.e. mortars) near city X.

VBIED(X)

ISIS conducts an attack using a
vehicle-bourne improvised explosive device (VBIED or car-bomb) in
city X.

armedAtkSpike(X, Y )

There is a spike in ISIS armed
attacks in country X that is Y
amount over the 4-month moving
average (Y is expressed in terms of
moving standard deviations).

VBIEDSpike(X, Y )

There is a spike in ISIS VBIEDs in
country X that is Y amount over
the 4-month moving average (Y is
expressed in terms of moving standard deviations).

describe the military insights that they provide. Our team
includes a former military officer with over a decade of experience in military operations that includes two combat tours
in Operation Iraqi Freedom. In addition to avg , we also examined the rule’s probability (p) - the fraction of times the
consequence follows the precondition, the negative probability (p∗ ) - the fraction of times the consequence is not
proceeded by the precondition, the prior probability of the
consequence (ρ), and the additional causal measures introduced in this paper - min , f rac . The relationship specified
in the rule can be considered more significant if p >> ρ, p∗
is closer to 0, min ≥ 0, and avg , f rac are close to 1. These
measures are discussed in more detail in Section 2.

4.2

Algorithm Efficiency

In Section 2, we described some performance improvements that we utilized in PF-Rule-Extract (which is based
on APT-Extract [14]) that are specific to this application.
The first performance improvement was the reduction in the
number of atoms used to generate the preconditions (which
were conjunctions of atoms of up to size 3 in our experiments). First, we limited the number of atoms to be used
in such combinations based on the weeks in which they occurred. Even though we had 980 environmental atoms, no
more than 93 occurred during any given week (this is the
value maxt (nt ) from Section 2). Further, by eliminating
atoms that occurred less than the SuppLB from consider-

ation, this lowered it further to 49 atoms per week at the
most. This directly leads to fewer combinations of atoms
generated for the precondition. A comparison is shown in
Table 2. Note that the values for APT-Extract are exact,
while the remaining are upper bounds. Again, this substantial, multiple-order-of-magnitude savings in the number
of rules explored is a result of the relative sparseness of our
dataset and the fact that our preconditions consisted of conjunctions of positive atoms. This efficiency is primarily what
enabled us to find and compare rules in a matter of minutes
on a commodity system.
Table 2: Improvement in Algorithm Efficiency
Technique
Atoms Combinations
Explored
APT-Extract [14]
980
182, 122, 025
maxt (nt )
93
8, 853, 042
maxt (nt ) and consider
49
1, 296, 834
only atoms that occur more
than SuppLB times

4.3

ISIS Military Tactics

In this section, we investigate rules that provide insight
into ISIS’s military tactics – in particular, we found interesting and potentially casual relationships that provide insight into their infantry operations, use of terror tactics (i.e.
VBIEDs), and decisions to employ roadside bombs and to
launch suicide operations.
Table 3: Causal Rules for Spikes in Armed Attacks (Iraq
and Syria Combined)
No.

Precondition

avg

p

p∗

1.

indirectFire(Baiji)∧

0.81

0.67

0.50

0.81

0.67

0.50

armedAtk(Balad)
2.

indirectFire(Baiji)∧
armedAtk(Balad)∧
VBIED(Baghdad)

Armed Attacks. The prior probability of large spikes
(2 × σ) (see figure 2) for ISIS armed attacks for Iraq and
Syria was 0.154. However, for our two most causal rules
for this spike (Table 3), we derived this probability as 0.67.
Such spikes likely indicate major infantry operations by the
Islamic State. Rule 1 states that indirect fire at Baiji (attributed to ISIS) along with an armed attack in Balad leads
to a spike in armed attacks by the group in the next week
while rule 2 mirrors rule 1 but adds VBIED activity in Baghdad as part of the precondition. We note the relatively high
p∗ (0.5 in this case), which indicates that each spike in armed
attacks of this type are not necessarily proceeded by this precondition, despite the relatively high value for avg , hinting
at causality (each of these rules was compared with 265 related rules and had f rac = 1 and min = 0 – showing little
indication of a related rule being more causal). We believe
that the strong causality and the high value for p∗ indicate
that these rules may well be “token causes” – causes for a
specific event - in this case, we think it is likely ISIS offensive

security forces away from other parts of the operational theater. It is interesting to note that the negative probability
is only 0.25 - which means that most of the VBIED spikes
we observed were related to operations in Balad and Baiji.
This highlights the strategic importance of these two cities
to ISIS: Baiji is home to a major oil refinery while Balad is
near a major Iraqi air base. We also found solid evidence of
causality for this rule - based on 209 related rules, we found
min = 0.5 which means adding a second precondition to
this rule increases the probability of the second rule by at
least 0.5
Figure 3: Spikes in ISIS VBIED Activity in Iraq and
Syria per Week
18

VBIEDs
Moving Average + 2σ

16

Number of Events

operations in Baiji. This makes sense, as a common military
tactic is to prepare the battlefield with indirect fire (which it
seems ISIS did in the prior week). It is unclear if the VBIED
incidents in Baghdad are related due to the co-occurrence.
That said, it is notable that VBIED operations are often
used as “terror” tactics as opposed to part of a sustained
operation. If so, this may have been part of a preparatory
phase (that included indirect fire in Baiji), and the purpose
of the VBIED events in Baghdad was to prevent additional
Iraqi Security Force deployment from Baghdad to Baiji. We
note in one case supporting this rule (on July 25th, 2014)
that ISIS also conducted IED attacks on power-lines that
support Baghdad - which may have also been designed to
hinder deployment of reinforcements. Here, it is also important to note the ongoing Infantry operations in Balad
(specified in the precondition) - which would consume ISIS
resources and perhaps make it more difficult to respond to
further deployment of government security forces. Though
this is likely a token cause, this may be indicative of ISIS
tactics when preparing to concentrate force on certain objectives (in this case Baiji) while maintaining ongoing operations (Balad), as a spike in armed attacks likely indicates a surge of light infantry-style soldiers into the area (a
manpower-intensive operation).

14
12
10

8
6
4
2
0
1

Figure 2: ISIS Spikes in Armed Attacks in Iraq and
Syria per Week

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

Spikes in VBIED Incidents. VBIED incidents have been
a common terror tactic used by religious Sunni extremist
insurgent groups in Iraq in the past – including Al Qaeda
in Iraq, Ansar al Sunnah, Ansar al Islam, and now ISIS.
We found two relationships that are potentially causal for
spikes in VBIED activity in Iraq and Syria combined, shown
in Table 4.

Spikes in IED Incidents. Improvised explosive device
(IED) incidents have been a common tactic used by Iraqi insurgents throughout the U.S.-led Operation Iraqi Freedom.
Though the IED comprises a smaller weapons system normally employed by local insurgent cells, spikes in such activity could be meaningful. For instance, it may indicate
action ordered by a strategic-level command that is being
carried out on the city level, or it may indicate improved
logistic support to provide local cells the necessary munitions to carry out such operations in larger numbers. Such
spikes only occur with a prior probability of 0.19. In Table 5,
we show a rather strong precondition for such attacks that
consist of infantry operations in Tikrit and a spike in executions. In this Table, rule 4 states that infantry operations
in Tikrit, when accompanied by a spike in executions, lead
to a spike (1 × σ) (see figure 4) in Iraq and Syria combined
- with a probability of 1.0 - much higher than the prior of
the consequence. With avg of 0.97 (based on a comparison with 1180 other rules), this relationship appears highly
causal (f rac = 1.0, min = 0.0) although 40% of 1 × σ IED
spikes were not accounted for by this precondition.

Table 4: Causal Rules for Spikes in VBIED Incidents in
Iraq and Syria Combined

Table 5: Causal Rules for Spikes in IED Incidents in Iraq
and Syria Combined

35

Armed Attacks
Moving Average + 2σ

Number of Events

30
25

20
15
10
5
0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

No.

Precondition

avg

p

p∗

No.

Precondition

avg

p

p∗

3.

armedAtk(Balad)∧

0.95

1.00

0.25

4.

armedAtk(T ikrit)∧

0.97

1.00

0.40

indirectFire(Baiji)
Rule 3 states that if infantry operations in Balad accompanied by indirect fire operations in Baiji occur, we should
expect a major (2 × σ) spike in VBIED activity (see figure 3) by ISIS (Iraq and Syria combined). We believe this
rule provides further evidence of the use of VBIEDs to pull

executionSpike(T otal, 2σ)

4.4

Relationships between Iraqi and Syrian Theaters

ISIS has clearly leveraged itself as a force operating in
both Iraq and Syria, and the identification of relationships

Figure 4: Spikes in ISIS IEDs in Iraq and Syria per
Week
10

7

Moving Average + σ

IEDs

9

Armed Attacks

VBIEDs

6

Number of Events

8

Number of Events

Figure 6: Comparison of ISIS Armed Attacks and
VBIEDs in Syria per Week

7
6
5
4
3
2

5
4

3
2
1

1
0

0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

1

29

3

5

7

9

11

13

Week

between incidents in relation to the two theaters may indicate some sophisticated operational coordination on their
part. We have found some evidence of these cross-theater
relationships with regard to suicide operations in Iraq (potentially affected by other events in Syria) and VBIED operations in Syria (potentially affected by other operations in
Iraq).
VBIED Spikes in Syria. Table 6 shows our most causal
rules whose consequence is a 1×σ spike (over the four-month
moving average) (see figures 5, 6) in ISIS VBIED events in
Syria. Rule 5 provides a precondition of a spike in armed
attacks in Iraq that includes a major spike in indirect fire
activity while rule 6 has the same precondition but includes
an additional VBIED event in Baghdad. We believe that
the spike in armed attacks indicates major ISIS operations
in Iraq and the inclusion of indirect fire events also indicates
that ISIS soldiers specializing in weapon systems such as
mortars may also be concentrated in Iraqi operations. Taken
together, this may indicate a shift in ISIS resources toward
Iraq - which may mean that operations have shifted away
from Syria. Hence, VBIED attacks, which once prepared,
are less manpower-intensive, nevertheless provide a showof-force in the secondary theater. We also note that the
probability of these rules (1.00) is significantly higher than
the prior of these spikes (0.19) and that the causality value is
also high for each of the 983 related rules, as the probability
either remains the same or increases when considering one
of these preconditions (in other words, f rac = 1 and min =
0).

Figure 5: Spikes in ISIS VBIEDs in Syria per Week

Number of Events

19

21

23

25

27

29

No.

Precondition

avg

p

p∗

5.

armedAtkSpike(Iraq, σ)∧

0.92

1.00

0.20

0.92

1.00

0.20

indirFireSpike(Iraq, 2σ)
6.

armedAtkSpike(Iraq, σ)∧
indirFireSpike(Iraq, 2σ)∧
VBIED(Baghdad)

Operations Shifting to Syria. In rules 5 and 6 of Table 6, we saw how increased operations in Iraq led to the
use of VBIEDs in Syria – perhaps due to a focus on more
manpower-heavy operations in Iraq. Interestingly, rule 7
shown in Table 7 indicates that less manpower-intensive
operations in Iraq that have a terror component seem to
have a causal relationship (based on avg = 0.97, f rac =
1.0, min = 0.5 found by comparing to 95 related rules) with
significant indirect fire operations in Syria (that occur with a
prior probability of 0.08). As discussed earlier, indirect fire is
normally used to “prepare the battlefield” for infantry operations, so this rule may be indicative of a shift in manpower
toward Syria - and the use of a VBIED tactic in Baghdad
(less manpower-intensive but very sensational) seems to always proceed a major (2 × σ over the moving average) spike
in indirect fire activity in Syria in our data (hence, a negative
probability of 0.0).

Table 7: Causal Rules for Spikes in Indirect Fire Operations in Syria

VBIEDs
Moving Average + σ

3.5

17

Table 6: Causal Rules for Spikes in VBIED Operations in
Syria

4.5
4

15

Week

3

No.

Precondition

avg

p

p∗

7.

IED(Baghdad)∧

0.97

0.67

0.00

VBIED(Ramadi)

2.5
2

1.5

4.5

1
0.5

0
1

3

5

7

9

11

13

15

Week

17

19

21

23

25

27

29

ISIS Activities Related to Opposition Air
Strikes

Reaction to Syrian Government Air Strikes. Rule 8,
shown in Table 8, tells us that a 2 × σ spike in arrests (see
figure 7) was always (p∗ = 0.0) proceeded by an air strike
conducted by the Syrian government. The prior probability

No.

Precondition

avg

p

p∗

8.

airStrike(SyrianGov, Damascus)

0.91

0.67

0.00

for such a spike in arrests is 0.08. Further, we found evidence
of causality - the actions of the Syrian government raised the
probability of each of 33 related rules by at least 0.5. One
potential reason to explain why arrests follow Syrian air operations is that unlike western nations, Syria generally lacks
advanced technical intelligence-gathering capabilities to determine targets, and Syria likely relies on extensive human
intelligence networks - especially within Iraq and Syria. Successful targeting from the air by the Syrian government may
then indicate that ISIS’s counter-intelligence efforts (activities designed to locate spies within its ranks) may have failed
and so the organization perhaps then decides to conduct
massive arrests.

Figure 7: Spikes in ISIS Arrests in Iraq and Syria
per Week
4

Arrests

Number of Events

3.5

personnel) - hence, it may seek a more economical attack
(in terms of both manpower and equipment) that still has
a significant terror component - and it would appear that a
suicide attack provides a viable option to respond to such
air strikes.
Figure 8: Spikes in ISIS Suicide Operations in Iraq
per Week
4.5

Suicide Attacks

4

Number of Events

Table 8: Causal Rules for Spikes in Arrests (Iraq and Syria
Combined)

Moving Average + 2σ

3.5
3

2.5
2
1.5
1
0.5
0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

Table 10: Causal Rules for Major Spikes in IED Operations
in Iraq
No.

Precondition

avg

p

p∗

10.

airStrike(Coalition, M osul)∧

0.97

0.67

0.33

Moving Average + 2σ

3
2.5

armedAtk(F allujah)

2
1.5
1

Table 11: Causal Rules for Major Spikes in IED Operations
in Syria

0.5

0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

No.

Precondition

avg

p

p∗

11.

airStrike(Coalition, M osul)∧

0.79

0.67

0.33

Week

armedAtk(Ramadi)∧
Table 9: Causal Rules for Major Spikes in Suicide Operations in Iraq
No.

Precondition

avg

p

p∗

9.

airStrike(IraqGovt, Baiji)∧

0.71

0.67

0.60

armedAtk(Balad)∧
VBIED(Baghdad)
Reaction to Iraqi Government Air Strikes. In Table 9,
rule 9 tells us that a 2 × σ spike (see figure 8) in suicide operations in Iraq is related to a precondition involving Iraqi
aerial operations in Baiji, ISIS infantry operations in Balad,
and a VBIED in Baghdad. The rule shows that these spikes
in suicide operations are 3.5 times more likely with this precondition. Though avg is lower than some of the other rules
presented thus far, it has a value for min of 0.3 - the minimum increase in probability afforded to any of the 82 related
rules to which we add the precondition of rule 9. The precondition indicates that ISIS may have recently expended a
VBIED (expensive in terms of equipment) while it has ongoing infantry operations in Balad (expensive in terms of

armedAtkSpike(Syria, σ)
Reaction to Air Strikes by the U.S.-led coalition.
Rules 10 (f rac = 1.0, min = 0.5, 562 related rules) and
11 (f rac = 1.0, min = 0.38, 81 related rules) - shown in
Tables 10 and 11 - illustrate two different outcomes from
coalition air operations in Mosul. In both cases, ISIS has
active operations in the Al-Anbar province – both Ramadi
and Fallujah have similar demographics. Hence, the major
difference is that the precondition of rule 11 also includes
significant infantry operations in Syria. So, even though
both rules result in an increase in IED activity (2 × σ above
average, a spike that in both cases occurs with a prior probability of 0.12) (see figures 9, 10) - the increase occurs in Iraq
for rule 10 and Syria for rule 11. It may be the case that
ISIS is increasing IED activity in response to coalition air
strikes in the location of their main effort. Further, the relatively low negative probability (0.33) along with relatively
high values for min may indicate that coalition air strikes
in Mosul are likely viewed as important factors contributing
to ISIS decisions to increase IED activity. We may also note
that the use of IED activity in the aftermath of coalition

air strikes could also be due to the size of the weapon. An
IED can be fairly small, easily disassembled and stored in
an innocuous location - hence, it is weapon system that the
coalition cannot sense and target from the air.
Figure 9: Spikes in ISIS IEDs in Iraq per Week
12

IEDs

Moving Average + 2σ

Number of Events

10
8
6
4
2
0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

Figure 10: Spikes in ISIS IEDs in Syria per Week
3

IEDs
Moving Average + 2σ

Number of Events

2.5
2
1.5
1
0.5
0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

Week

5.

RELATED WORK

To the best of our knowledge, this paper represents the
first purely data-driven study of ISIS, and it is also the first
to combine the causality framework of [10] with APT-Logic.
However, there has been a wealth of research conducted
where rule-based systems have been applied to terrorist and
insurgent groups, as well as other work on modeling insurgent actions. Here, we review this related work and also
discuss other approaches to causal reasoning.
Rule-based systems. Previously, there has been a variety of research on modeling the actions of terrorist and insurgent groups. Perhaps most well-known is the Stochastic
Opponent Modeling Agents (SOMA) [11, 12], which was developed with the goal of better understanding different cultural groups along with their behaviors. This is also based on
a rule-based framework known as action-probabilistic (AP)
rules [8], which is a predecessor of APT-logic used in this
paper [14, 15]. The SOMA system produces a probabilistic
logic representation for understanding group behaviors and
reasoning about the types of actions a group may take. In recent years, this system has been used to better understand
terror groups like Hamas [12] and Hezbollah [11] through
probabilistic rules. However, it can also be used with cultural, religious, and political groups - as it has been demon-

strated with other groups in the Minorities at Risk Organizational Behavior (MAROB) dataset [1]. The work on
SOMA was followed by an adoption of APT-Logic [14, 15],
which extended AP-rules with a temporal component. APT
logic was also applied to the groups of the MAROB dataset
as well as Shi’ite Iraqi insurgent groups circa 2007 (present
during the American-led Operation Iraqi Freedom) [15] 1 .
Perhaps most significantly, APT-Logic was applied to another dataset for the study of the terror groups Lashkar-eTaiba (LeT) and Indian Mujahideen (IM) in two comprehensive volumes that discuss the policy implications of the
behavioral rules learned in these cases [17, 16]. The main
similarity between the previous work leveraging SOMA, APrules, and/or APT-logic and this paper is that both leverage
probabilistic rule learning. However, all of the aforementioned rule-learning approaches only discover correlations,
while this work is focused on rules that are not only of high
probability, but also have a likely casual relationship. We
also note that none of this previous work studies ISIS but
rather other terrorist and insurgent groups.
Analysis of insurgent military tactics. We also note
that the previous rule-learning approaches to understanding
terrorist and insurgent behavior have primarily focused on
analyzing political events and how they affect the actions of
groups such as LeT and IM. However, with the exception
of some of the work on APT-Logic which studies Shi’ite
Iraqi insurgents [14], the aforementioned work is generally
not focused on tactical military operations - unlike this paper. However, there have been other techniques introduced
in the literature that have been designed to better account
for ground action. Previously, a statistical-based approach
leveraged leaked classified data [19] 2 to predict trends of violent activity during the American-led Operation Enduring
Freedom in Afghanistan. However, this work was primarily
focused on prediction and not identifying causal relationships of interest to analysis as in this work. We also note
that this work does not rely on the use of leaked classified
data, but rather on open-source information. Another interesting approach is the model-based approach of [7], in which
subject matter experts create models of insurgent behavior
using a combination of fuzzy cognitive maps and complex
networks to run simulations and study “what-if” scenarios.
However, unlike this paper, the work of [7] is not as datadriven an approach.
Causal reasoning. The comparison of rules by avg as a
measure of causality was first introduced in [10] and further
studied in [9]. It draws on the philosophical ideas of [18].
However, this work has primarily looked at preconditions as
single atomic propositions. Further, it did not explore the
issue of efficiency. As we look to identify rules whose precondition consists of more than one atomic proposition, we
introduce a rule-learning approach. Further, moving beyond
previous rule-learning approaches such as that introduced in
[8] and [14], we show practical techniques to improve efficiencies of such algorithms. Further, we also improve upon the
efficiency of computing avg - a practical issue not discussed
in [10, 9]. We note that neither this previous work on causal1
ISIS is a Sunni group and did not exist in its present form
in 2007.
2
Resulting from WikiLeaks in 2010.

ity nor APT-logic makes independence assumptions. This
differs substantially from earlier work on causality such as
[13], which relies on graphical models that make relatively
strong independence assumptions. Our goal was to avoid
such structures in order to provide a more purely data-driven
approach. A key aspect of this work as opposed to previous studies on causality is that we leverage the intuitions
of APT logic and AP rules, in which the rule-learning algorithm searches for combinations of atomic propositions that
are related to a given consequence.

6.

CONCLUSION

In this paper, we conducted a data-driven study on the insurgent group ISIS using a combination of APT-logic, rule
learning, and causal reasoning to identify cause-and-effect
behavior rules concerning the group’s actions. We believe
our approach is of significant utility for both military decision making and the creation of policy. In the future, we
look to extend this work in several ways: first, we look to
create non-ground rules that generalize some of the preconditions further. This would allow us to understand the circumstances in which ISIS conducts general operations (as
opposed to operations specific to a given city or to a geographic area). We also look to study more complex temporal
relationships – possibly using a more fine-grain resolution for
time and studying rules where the cause is followed by the
effect in more than one unit of time. We also look to leverage
additional variables about the environment, including data
about weather, information (including social media operations), and the political situation to find more interesting
relationships.

7.

REFERENCES

[1] V. Asal, C. Johnson, and J. Wilkenfeld. Ethnopolitical
violence and terrorism in the middle east. In J. J.
Hewitt, J. Wilkenfeld, and T. R. Gurr, editors, Peace
and Conflict 2008. Paradigm Publishers, 2007.
[2] Districts of iraq. United Nations Office for the
Coordination of Humanitarian Affairs, 2014.
http://www.humanitarianresponse.info/operations/
iraq/search?search=governorate+district.
[3] Google maps. Google Inc., 2014.
https://www.google.com/maps/.
[4] Iraq - district reference maps. MapAction, 2014.
http://www.mapaction.org/component/search/
?searchword=iraq+map&ordering=
newest&searchphrase=all&limit=100&areas[0]=maps.
[5] Situation reports. Institute for the Study of War,
2014. http://understandingwar.org/.
[6] Syria: Governorate and district reference maps.
MapAction, 2014. http://www.mapaction.org/
district-reference-maps-of-syria.html.
[7] P. Giabbanelli. Modelling the spatial and social
dynamics of insurgency. Security Informatics, 3:2,
2014.

[8] S. Khuller, M. V. Martinez, D. Nau, A. Sliva, G. I.
Simari, and V. S. Subrahmanian. Computing most
probable worlds of action probabilistic logic programs:
scalable estimation for 1030,000 worlds. Annals of
Mathematics and Artificial Intelligence,
51(2-4):295–331, 2007.
[9] S. Kleinberg. A logic for causal inference in time series
with discrete and continuous variables. In IJCAI 2011,
Proceedings of the 22nd International Joint Conference
on Artificial Intelligence, Barcelona, Catalonia, Spain,
July 16-22, 2011, pages 943–950, 2011.
[10] S. Kleinberg and B. Mishra. The temporal logic of
causal structures. In UAI 2009, Proceedings of the
Twenty-Fifth Conference on Uncertainty in Artificial
Intelligence, Montreal, QC, Canada, June 18-21,
2009, pages 303–312, 2009.
[11] A. Mannes, M. Michael, A. Pate, A. Sliva, V. S.
Subrahmanian, and J. Wilkenfeld. Stochastic
opponent modeling agents: A case study with
Hezbollah. First International Workshop on Social
Computing, Behavioral Modeling, and Prediction,
April 2008.
[12] A. Mannes, A. Sliva, V. S. Subrahmanian, and
J. Wilkenfeld. Stochastic opponent modeling agents:
A case study with Hamas. Proceedings of the Second
International Conference on Computational Cultural
Dynamics (ICCCD), September 2008.
[13] J. Pearl. Causality: Models, Reasoning, and Inference.
Cambridge University Press, 2000.
[14] P. Shakarian, A. Parker, G. I. Simari, and V. S.
Subrahmanian. Annotated probabilistic temporal
logic. ACM Transactions on Computational Logic,
2011.
[15] P. Shakarian, G. I. Simari, and V. S. Subrahmanian.
Annotated probabilistic temporal logic: Approximate
fixpoint implementation. ACM Transactions on
Computational Logic, 2012.
[16] V. S. Subrahmanian, A. Mannes, A. Roul, and R. K.
Raghavan. Indian Mujahideen - Computational
Analysis and Public Policy, volume 1 of Terrorism,
Security, and Computation. Springer, 2013.
[17] V. S. Subrahmanian, A. Mannes, A. Sliva,
J. Shakarian, and J. P. Dickerson. Computational
Analysis of Terrorist Groups: Lashkar-e-Taiba.
Springer, 2013.
[18] P. Suppes. A probabilistic theory of causality.
North-Holland Pub. Co., 1970.
[19] A. Zammit-Mangion, M. Dewar, V. Kadirkamanathan,
and G. Sanguinetti. Point process modelling of the
afghan war diary. Proceedings of the National
Academy of Sciences, 109(31):12414–12419, 2012.

Geospatial Optimization Problems
V.S. Subrahmanian
Dept. of Computer Science
University of Maryland, College Park MD
vs[at]cs.umd.edu

Abstract—There are numerous applications which require the
ability to take certain actions (e.g. distribute money, medicines,
people etc.) over a geographic region in order to optimize
an objective (e.g. minimize expected number of people with
a disease). We introduce “geospatial optimization problems”
(GOPs) where an agent has limited resources and budget to take
actions in a geographic area. The actions result in one or more
properties changing for one or more locations. There are also
certain constraints on the combinations of actions that can be
taken. We study two types of GOPs - goal-based and benefitmaximizing (GBGOP and BMGOP respectively). A GBGOP
ensures that certain properties must be true at specified locations
after the actions are taken while a BMGOP optimizes a linear
benefit function. We present several approaches to these problems
using various integer programs as well as a multiplicative update
based approximation.

12

14

16

Paulo Shakarian
Network Science Center
U.S. Military Academy, West Point, NY 10996
paulo[at]shakarian.net

I. I NTRODUCTION

Fig. 1.

As geo-located social network data becomes more common
with sites such as FourSquare1 and programs such as RealityMining2 , it becomes desirable to reason about such data.
There are numerous applications which require the ability to
take certain actions (e.g. distribute money, medicines, people
etc.) over a geographic region. For instance, a disaster relief
organization must allocate people and supplies in a region
after a disaster. A public health organization needs to allocate
limited vaccine stocks to people across the region. A government needs to allocate funds for education or unemployment
training across a region. However, allocating any resource will
cause certain effects - some desirable, some not - based on
the network connections among geographic locations. In this
paper we present a formal framework that allows reasoning
about such geo-located data in order to answer certain queries
where we have some desired goal to achieve as the result of
our geographically-based resource allocation - all the while
considering the complex interactions among locations.
Figure 1 shows a 2-dimensional map of a region. A political
candidate can only make so many campaign stops and public
appeals. We assume that a map M is discrete (this is a
common assumption in most GIS systems) and has coordinates
drawn from [0, . . . , M ] × [0, . . . N ] where the bottom left
corner of the map is the point (0, 0). The candidate wants to
identify the best places to campaign or make public appeals
to maximize his exposure. Additionally, the map shows unpopulated areas, areas where campaigning costs are high, and
1 https://foursquare.com/
2 http://realitycommons.media.mit.edu/

978-1-4799-0203-3/13/$31.00 ©2013 IEEE

Group 1 (grp1)
Group 2 (grp2)

1 Influential center for group 1 (hq1)
2 Influential center for group 2 (hq2)

8

10

High-cost area (hi_cost)
Non-populated area (non_pop)

4

6

2

0

2

1

0

2

4

6

8

10

12

14

16

Locations in a district - contingency groups and unpopulated areas.

areas dominated by one of two constituent groups. All of these
factors may affect the set of locations the candidate selects to
optimize his exposure.
In this paper, we introduce geographic optimization problems or GOPs that capture and solve problems such as
those mentioned above. This framework allows one to more
prudently position resources in a manner to achieve a goal
while considering the complex interactions between locations
(that may be modeled as a network). The organization and
contribution of the paper is as follows. Section II formally defines GOPs - specifically we introduce goal-based and benefitmaximizing GOPs (GBGOP and BMGOP respectively) and
provides results on the complexity of these problems (both
are NP-hard). Section III presents integer programs to solve
both GBGOP and BMGOP using an IP solver like CPLEX.
We then show how to correctly reduce the number of variables
in the integer constraints for GBGOP. This is followed by a description of the BMGOP-Compute algorithm that can quickly
approximate a BMGOP in polynomial time and provides an
approximation guarantee.
II. GOP S F ORMALIZED AND C OMPLEXITY R ESULTS
Throughout this paper, we assume that M = [0, . . . , M ] ×
[0, . . . , N ] is an arbitrary, but fixed “map”. We define a logical
language L whose constant symbols are members of M and
that has an infinite set Lvar of variable symbols disjoint from
M. L has a set G = {g1 , . . . , gn } of unary predicate symbols.
As usual, a term is either a constant symbol or variable symbol.

118

If t is a term, then gi (t) is an atom. If t is a constant, then
gi (t) is ground. Intuitively, if p ∈ M, then gi (p) says that
point p has property gi . We use BL to denote the set of all
ground atoms. Well-formed formulas (wffs) are defined in the
usual way. (i) Every atom is a wff. (ii) If F, G are wffs, then
so are F ∧ G, F ∨ G, ¬F are all wffs.
Example 2.1: Consider the map Mcpgn in Figure 1 with
predicates G = {hi cost, non pop, grp1 , grp2 , hq1 , hq2 }.
The predicate exposure not depicted in the figure corresponds to a candidate receiving exposure in a certain area. hi cost((1, 9)), hq1 ((4, 3)), non pop((8, 1)), and
grp2 ((5, 8)) are all examples of ground atoms.
A state is any subset of BL . We use S to denote the set of
all states. Satisfaction of formulas is defined in the obvious
way. State s satisfies a ground atom A, denoted s |= A, iff
A ∈ s. s |= F ∨ G iff s |= F or s |= G. s |= F ∧ G iff
s |= F and s |= G. s |= ¬F iff s does not satisfy F .
Example 2.2: The shading shown in Figure 1 defines
a state. For example, hi cost((1, 9)) ∈ scpgn while
exposure((1, 9)) ∈
/ scpgn .
An action maps points to sets of ground atoms.
Definition 2.1 (Action): An action is a mapping a : M →
2BL . We use A to denote the set of actions. An action-point
pair is any member of A × M.
An action-point pair (a, p) is executed if action a takes place
at point p. Thus, one can think of (a, p) as saying that action
a occurs at point p. The result of executing a set SOL of
action-point pairs in state s0 is denoted appl(SOL, s0 ) and
is the set (s0 ∪ {a(p) | (a, p) ∈ SOL}).
Example 2.3: Continuing with example 2.6, our candidate
has actions Acpgn = {nor, appeal1 , appeal2 } where nor
refers to a normal campaign stop and appeal1 , appeal2 refer
to public appeals to constituent groups 1 and 2 respectively.
The actions map to ground atoms as follows.
nor(p) =
appeali (p) =

{exposure(p0 )|
{exposure(p0 )|

¬non pop(p0 ) ∧ d(p, p0 ) ≤ 1}
hqi (p) ∧ grpi (p0 )}

The first action says that when a normal campign stop is made
at point p and p0 is a populated place one distance unit or less
from p, then the candidate has exposure at place p0 as well.
The second action says that if the candidate makes an appeal
(action) at point p and p is the headquarters of interest group
grpi , then the candidate has obtained exposure in all places
associated with interest group grpi .
Definition 2.2 (Cost Function): A cost function, C : A ×
M → [0, 1].
Throughout this paper, we assume the cost function is arbitrary
but fixed and can be computed in constant time. We also
assume that if A × M = {(a1 , p1 ), . . . , (am , pm )}, then ci
is used to denote C(ai , pi ).
Example 2.4: The cost function for our example is C(s)
cpgn
and is defined (based on some state s) as follows:
C(s)
cpgn (a, p) = 1 if hi cost(p) ∈ s and 0.5 otherwise.
We also assume the existence of a set of integrity constraints
IC that specify that certain actions cannot be jointly taken if
some conditions hold w.r.t. the state — such constraints were
defined before by [1].

Definition 2.3 (Integrity Constraint): If Φ is a set of actionpoint pairs and χ is a wff, then Φ ←- χ is an integrity
constraint.
When Φ ←- χ is ground, this says that if χ is true, then only
one action-point pair in Φ may be executed. Formally, suppose
s is a state and Φ0 is a set of action-point pairs and Φ ←- χ is
ground. (s, Φ0 ) |= Φ ←- χ iff either s 6|= χ or s |= χ and |Φ ∩
Φ0 | ≤ 1. (s, Φ0 ) satisfies an integrity constraint iff it satisfies
all ground instances of it. (s, Φ0 ) |= IC where IC is a set
of integrity constraints iff (s, Φ0 ) satisfies every constraint in
that set. Given a state s and set IC of integrity constraints, we
use ICs to denote the set of all ground instances of integrity
constraints in IC where the associated wff χ is satisfied by
s3 .
Example 2.5: Continuing Example 2.4, let ICcpgn be
{{appeal1 ((4, 3)), appeal2 ((10, 7))} ←- TRUE}. This constraint says that an appeal can be made to either group 1
or group 2 at their center of influence, but not both — for
instance, these two groups may have opposing views.
We now introduce the goal-based geospatial optimization
problem (GBGOP). This problem takes as input a map M,
initial state s0 , set of actions A, cost function C, integrity
constraints IC, positive real number c, and disjoint sets
Θin , Θout ⊆ BL . Intuitively, c restricts the total cost and
Θin (resp. Θout ) is a set of atoms that must be true (resp.
false) after the actions are applied. Our optimality criteria for
a GBGOP is to minimize the cardinality of the action-point
pairs. A GBGOP can be viewed as an abductive inference
problem (i.e. find a set of actions that lead to the current
state) - where minimal cardinality is a common parsimony
requirement.
Definition 2.4 (GBGOP Solution, Optimal Solution): A
solution to a GBGOP (M, s0 , A, C, IC, c, Θin , Θout ) is a
set SOL ⊆ A × M such that: (i) Σ(ai ,pi )∈SOL ci ≤ c,
(ii)
V (s0 , SOL)V |= IC, and (iii) appl(s0 , SOL) |=
Ai ∈Θin Ai ∧
Aj ∈Θout ¬Aj .
A solution SOL is optimal iff there is no other solution
SOL0 such that |SOL0 | ≤ |SOL|.
Our next type of problem is a benefit-maximizing geospatial
optimization problem (BMGOP) that also considers a benefit
function, defined as follows.
Definition 2.5 (Benefit Function): The benefit function,
B : BL → <+ maps atoms to positive real numbers.
Example 2.6: In our running example, we use the benefit
function Bcpgn where Bcpgn (A) = 1 if A has the form
exposure() and 0 otherwise.
As with cost, we assume the benefit function to be arbitrary
but fixed and computable in constant time. We also assume that
if BL = {A1 , . . . , An }, then B(Ai ) is denoted bi . A BMGOP
takes as input, M, s0 , A, C, IC, and c - all defined the same
as for a GBGOP. Additionally it takes benefit function B and
natural number k. Here k is a bound on the number of actions
the agent can take as we attempt to maximize benefit as an
optimality criteria.

119

3 Formally,

ICs = {(Φ ←- χ) ∈ IC|s |= χ}

Definition 2.6 (BMGOP Solution, Optimal Solution):
A solution to a BMGOP (M, s0 , B, A, C, IC, k, c) is a
set SOL ⊆ A × M such that: (i) |SOL| ≤ k and (ii)
Σ(ai ,pi )∈SOL ci ≤ c, and (iii) (s0 , SOL) |= IC.
A solution SOL
P is optimal iff therePis no other solution
SOL0 such that Ai ∈appl(SOL,s0 ) bi < Ai ∈appl(SOL0 ,s0 ) bi .
Here, we provide complexity results for GBGOPs and BMGOPs. First, we establish both as being at least NP-hard. The
following can be shown by embedding the Set-Cover and Maxk-cover problems (see [2] for definitions) into our framework.
This also allows for results on the limits of approximation for
these problems.
Theorem 1: Given GBGOP (M, s0 , A, C, IC, c, Θin ,
Θout ), finding an optimal solution SOL ⊆ A×M is NP-hard.
This result holds even if for each a ∈ A, p ∈ M, it is the case
that ∀g 0 (p0 ) ∈ a(p), p0 = p - i.e. each action only affects the
point is is applied to.
Theorem 2: Given BMGOP (M, s0 , B, A, C, IC, k, c),
finding an optimal solution SOL ⊆ A is NP-hard. This result
holds even if for each a ∈ A, p ∈ M, it is the case that
∀g 0 (p0 ) ∈ a(p), p0 = p - i.e. each action only affects the point
is is applied to).
Theorem 3: If for some  > 0, there is a PTIME algorithm
to approximate GBGOP within (1 − ) · ln(|A × M|), then
N P ⊂ T IM E(|A × M|O(lg lg |A×M|) ) (NP has a slightly
super-polynomial algorithm).
Theorem 4: Finding an optimal solution to BMGOP cannot
be approximated in PTIME within a ratio of e−1
e +  (approx.
0.63) for some  > 0 (where e is the inverse of the natural
log) unless P=NP, even when IC = ∅.
III. A LGORITHMS S OLVING GOP S
In this section, we present an integer programming (IP)
algorithms for both GBGOP and BMGOP which provide exact
solutions. Given a GBGOP, the IP associates an integer-valued
variable Xi with each action-point pair (ai , pi ) ∈ A × M
where ai (pi ) ∩ Θout = ∅. Intuitively, Xi = 1 denotes that
action ai is performed at point pi .
Definition 3.1 (GBGOP-IP): Let set R = {(ai , pi ) ∈ A ×
M|ai (pi )∩Θout = ∅}. For each action-point pair (ai , pi ) ∈ R,
create variable Xi ∈ {0, 1}.
min

|R|
X

Xi

(1)

i=1

s.t.

X

Xj ≥ 1

∀Ai ∈ Θin − s0

(2)

aj (pj )|Ai ∈aj (pj )

X

ci · Xi ≤ c

(3)

(ai ,pi )∈R

X

Xi ≤ 1

∀(Φ ←- χ) ∈ ICs0

(4)

(ai ,pi )∈Φ

The objective function minimizes the total number of actionpoint pairs. Constraint (2) ensures that every ground atom in
Θin (that does not appear in the initial state) is caused by
at least one of the selected action-point pairs. Constraint (3)
enforces the constraint on cost. Constraint (4) ensures that the
integrity constraints are satisfied. Next we present our integer

constraints for a BMGOP where the IP associates an integervalued variable Xi with each action-point pair (ai , pi ) ∈ A ×
M, and an integer-valued variable Yj with each ground atom
Aj ∈ BL − s0 . The intuition for the Xi variables is the same
as in GBGOP-IP.
Definition 3.2 (BMGOP-IP): For each action-point pair
(ai , pi ) ∈ A × M, create variable Xi ∈ {0, 1}. For each
Ai ∈ BL − s0 create variable Yi ∈ {0, 1}.
|BL |−|s0 |

X

max

bi +

X

Ai ∈s0

s.t.

bi · Yi

(5)

i=1

X

Xj ≥ Yi

∀Ai ∈ BL − s0

(6)

aj (pj )|Ai ∈aj (pj )

X

Xi ≤ k

(7)

ci · Xi ≤ c

(8)

(ai ,pi )∈A×M

X
(ai ,pi )∈A×M

X

Xi ≤ 1

∀(Φ ←- χ) ∈ ICso

(9)

(ai ,pi )∈Φ

In the above IP, the objective function looks at each ground
atom and sums the associated benefit if the associated Yi
variable is 1 - meaning that atom Ai is true after the actions
are applied. Constraint (6) effectively sets a Yi variable to 1
if an action that causes Ai to be true occurs. Constraint (7)
enforces the cardinality requirement. Constraints 8-9 mirror
constraints 3-4 of GBGOP-IP. The result below shows that a
solution σ to the above IPs when restricted to the Xi variables,
provides an immediate solution to the GOP.
As integer programming is NP-complete, any algorithm to
solve a GOP using GBGOP-IP or BMGOP-IP using an IP
solver will take exponential time. We note that for GBGOPIP, the number of variables is fairly large – O(|{(ai , pi ) ∈
A × M|ai (pi ) ∩ Θout = ∅}|) variables and O(|Θin − s0 | +
|ICs0 | + 1) constraints. BMGOP-IP has even more variables (though not exponential) - O(|M| · (|A| + |G|)) variables and
O(|M| · |G| + |ICs0 | + 2) constraints.
We now show how to correctly reduce the number of
variables by considering only a subset of R. Our intuition
is that an optimal solution SOL is an irredundant cover
of Θin meaning there is no subset SOL0 ⊂ SOL that
is also a solution. Hence, we can discard certain elements
of R that cannot possibly be in an optimal solution. For
a given GBGOP Γ = (M, s0 , A, C, IC, c, Θin , Θout ), we
introduce QΓ(a,p) = {Φ|(Φ ←- χ) ∈ ICs0 ∧ (a, p) ∈ Φ}
and the set of ground atoms each action-point pair affects
AffΓ(a,p) = ai (pi ) ∩ (Θin − (Θin ∩ s0 )). We can now define a
reduced action-point set.
Definition 3.3 (Reduced Action-Point Set): Given GBGOP
Γ = (M, s0 , A, C, IC, c, Θin , Θout ) and set R = {(ai , pi ) ∈
A × M|ai (pi ) ∩ Θout = ∅}, we define reduced action-point
set R∗ = {(ai , pi ) ∈ R| 6 ∃(aj , pj ) ∈ R s.t.
(cj ≤ ci ) ∧ (QΓ(aj ,pj ) ⊆ QΓ(ai ,pi ) ) ∧ (AffΓ(ai ,pi ) ⊆ AffΓ(aj ,pj ) )}
Set R∗ can be found in quadratic time with a naive
algorithm - an operation that is likely dominated by solving or
approximating GBGOP-IP. Hence, it is easy to show that for

120

any optimal solution SOL ⊆ R, there is an optimal solution
SOL0 ⊆ R∗ .
While BMGOP-IP can solve a BMGOP exactly, doing so is computationally intractable. Here, we leverage
some known methods [3] to solve such problems and develop a fast, deterministic algorithm to approximate BMGOP with an approximation bounds. Given BMGOP Γ =
(M, s0 , B, A, C, IC, k, c), consider the objective function in
BMGOP-IP. We can write that function as a mapping from
action-point pairs to reals. We denote this function (specific
for BMGOP Γ) as fΓ : 2A×M → <+ , where fΓ (S) =
P
Ai ∈appl(S,s0 ) bi , which has certain properties.
We now show that this function fΓ is submodular and has
some other nice properties as well.
Prop. 3.1: For BMGOP Γ, function fΓ is: (i) submodular,
(ii) monotonic, i.e. Z1 ⊆ Z2 → fΓ (Z1 ) ≤ fΓ (Z2 ) and (iii)
under the condition ∀Ai ∈ BL , bi = 0, we have fΓ (∅) = 0.
As our objective function is submodular, and constraints 79 are linear packing constraints, any instance of a BMGOP
can be viewed as maximization of a submodular function
wrt linear packing constraints and hence, methods to solve
such problems can be used here. The BMGOP-Compute
algorithm leverages this idea and illustrated in Example 3.1.
This algorithm takes O(k · |M| · |A| · |ICs0 |) time to complete
and by the previous Proposition along with Theorem 1.1 of [3],
under the assumption that k, c ≥ 2 − δ, BMGOP-Compute
provides a solution within a factor of (2+|ICs 1|)1/(2−δ) (where
0
δ is an infinitesimal) of optimal.

loop at line 3, it finds the action-point pair that minimizes
the quantity at line 3 is (appeal1 , (4, 3)) - which has the
associated value 0.073. Note, other action-point pairs with low
values are (appeal2 , (10, 7)) with 0.083 and (nor, (15, 6))
also with 0.083. It then adds (appeal1 , (4, 3)) to SOL and
updates w0 = 0.93, w00 = 1.09, and w1 = 2.35. On the next
iteration, the BMGOP-Compute picks (nor, (15, 6)), which
now has a value of 0.164. During this iteration, the value of
(appeal2 , (10, 7)) has increased substantially - to 0.294, so
it is not selected. At the end of the iteration, w0 is updated
to 2.611 and w00 is updated to 2.364. As (nor, (15, 6)) does
not impact the lone integrity constraint, the value w1 remains
at 2.354. In the third iteration, BMGOP-Compute selects
(nor, (15, 9)) which has a value of 0.421. Again, the value of
(appeal2 , (10, 7)) has increased - but this time only to 0.472.
BMGOP-Compute re-calculates w0 = 7.331, w00 = 5.128
and w1 remains at 2.354. On the last iteration, BMGOPCompute picks (appeal2 , (10, 7)) as it has the lowest value
– 0.942. After this fourth iteration, it updates w0 = 20.589,
w00 = 11.124, and w1 = 11.0861 - which now total to 42.799
– exceeding λ (22.14) – causing BMGOP-Compute to exit
the outer loop. Now SOL has 4 elements, exceeding the
cardinality constraint (as well as the integrity constraint). The
checks done in line 4 remove (appeal2 , (10, 7)) from SOL
- making the result feasible. BMGOP-Compute returns
{(appeal1 , (4, 3)), (nor, (15, 6), (nor, (15, 9))} which causes
the benefit to be 45.

BMGOP-Compute
INPUT: BMGOP (M, s0 , B, A, C, IC, k, c)
OUTPUT: SOL ⊆ A × M

In this paper, we introduced “geopspatial optimization problems” or GOPs that aide the user in taking certain actions over
a geographic region. We showed these problems to be NP-hard
and provided integer constraints. For the goal-based variant,
we correctly reduce the number of variables. For the benefitmaximizing variant, we provide an approximation algorithm.

1) Set SOL = ∅, δ to be an infinitesimal,
and set λ = e2−δ · (2 + |ICs0 |).
2) Set w0 = 1/k and w00 = 1/c. For each (Φi ←- χi ) ∈ ICs0 ,
set wi = 1/(2 − δ).
P
3) While k ·w0 +c·w00 +(2−δ)· i wi ≤ λ and SOL 6= A×M
a) Let (aj , pj ) ∈ A × M −PSOL have minimal
0

00

w +w ·cj + i|(a ,p )∈Φ wi
j jP i
P
( A ∈appl(SOL∪{(a ,p )},s ) bi )−( A ∈appl(SOL,s ) bi )
0
0
j j
i
i

b) SOL = SOL ∪ {(aj , pj )}
c) Set w0 = w0 · λ1/k , w00 = w00 · λcj /c and for each
integrity constraint i s.t. (aj , pj ) ∈ Φi , set
wi = wi · λ1/(2−δ)
4) If SOL is not a valid solution then
P
a) If Ai ∈appl(SOL−{(aj ,pj )},s0 ) bi ≥
P
Ai ∈appl({(aj ,pj )},s0 ) bi ,
then SOL = SOL − {(aj , pj )}
b) Else SOL = {(aj , pj )}
5) Return SOL

Example 3.1: Following
Example
2.5.
Suppose
the
candidate
wants
to
optimize
BMGOP:
(scpgn )
(Mcpgn , scpgn , Bcpgn , Acpgn , Ccpgn
, ICcpgn , 3, 2).
In
this case, we will set δ = 0.001. He wishes to find a set
of 3 action-point pairs to optimize his exposure. BMGOPCompute sets λ = 22.14, w0 = 0.33, w00 = 0.50, and
w1 = 0.50 in lines 1 and 2. In the first iteration of the

IV. C ONCLUSION

ACKNOWLEDGMENTS
Some of the authors are supported under by the Army
Research Office (project 2GDATXR042). The opinions in this
paper are those of the authors and do not necessarily reflect
the opinions of the funders, the U.S. Military Academy, or the
U.S. Army.
R EFERENCES
[1] T. Eiter, V. Subrahmanian, and G. Pick, “Heterogeneous Active Agents, I:
Semantics,” Artificial Intelligence Journal, vol. 108, no. 1-2, pp. 179–255,
1999.
[2] U. Feige, “A threshold of ln n for approximating set cover,” J. ACM,
vol. 45, no. 4, pp. 634–652, 1998.
[3] Y.
Azar
and
I.
Gamzu,
“Efficient
submodular
function
maximization
under
linear
packing
constraints,”
(http://www.cs.tau.ac.il/ iftgam/papers/SubmodularPacking.pdf), 2010.

121

Keeping Intruders at Large
A Graph-theoretic Approach to Reducing the Probability of Successful Network
Intrusions∗
Paulo Shakarian1 , Damon Paulo2 , Massimiliano Albanese3 and Sushil Jajodia3,4
1 Arizona

State University, Tempe, AZ, U.S.A.
Military Academy, West Point, NY, U.S.A.
3 George Mason University, Fairfax, VA, U.S.A.
4 The MITRE Corporation, McLean, VA, U.S.A.

2 U.S.

Keywords:

Moving Target Defense, Adversarial Modeling, Graph Theory.

Abstract:

It is well known that not all intrusions can be prevented and additional lines of defense are needed to deal with
intruders. However, most current approaches use honeynets relying on the assumption that simply attracting
intruders into honeypots would thwart the attack. In this paper, we propose a different and more realistic
approach, which aims at delaying intrusions, so as to control the probability that an intruder will reach a
certain goal within a specified amount of time. Our method relies on analyzing a graphical representation
of the computer network’s logical layout and an associated probabilistic model of the adversary’s behavior.
We then artificially modify this representation by adding “distraction clusters” – collections of interconnected
virtual machines – at key points of the network in order to increase complexity for the intruders and delay the
intrusion. We study this problem formally, showing it to be NP-hard and then provide an approximation algorithm that exhibits several useful properties. Finally, we present experimental results obtained on a prototypal
implementation of the proposed framework.

1

INTRODUCTION

Despite significant progress in the area of intrusion
prevention, it is well known that not all intrusions
can be prevented, and additional lines of defense are
needed in order to cope with attackers capable of
circumventing existing intrusion prevention systems.
However, most current approaches are based on the
use of honeypots, honeynets, and honey tokens to
lure the attacker into subsystems containing only fake
data and bogus applications. Unfortunately, these
approaches rely on the unrealistic assumption that
simply attracting an intruder into a honeypot would
thwart the attack. In this paper, we propose a totally
different and more realistic approach, which aims at
delaying an intrusion, rather than trying to stop it, so
as to control the probability that an intruder will reach
∗ This

work was partially supported by the Army Research Office under award number W911NF-13-1-0421.
Paulo Shakarian and Damon Paulo were supported by the
Army Research Office project 2GDATXR042. The work of
Sushil Jajodia was also supported by the MITRE Sponsored
Research Program.

a certain goal within a specified amount of time and
keep such probability below a given threshold.
Our approach is aligned with recent trends in cyber defense research, which has seen a growing interest in techniques aimed at continuously changing a
system’s attack surface in order to prevent or thwart
attacks. This approach to cyber defense is generally
referred to as Moving Target Defense (MTD) (Jajodia
et al., 2013) and encompasses techniques designed to
change one or more properties of a system in order
to present attackers with a varying attack surface2 , so
that, by the time the attacker gains enough information about the system for planning an attack, its attack
surface will be different enough to disrupt it.
In order to achieve our goal, our method relies on
analyzing a graphical representation of the computer
network’s logical layout and an associated probabilistic model of the adversary’s behavior. In our model,
an adversary can penetrate a system by sequentially
gaining privileges on multiple system resources. We
2 Generally,

the attack surface refers to system resources
that can be potentially used for an attack.

Shakarian P., Paulo D., Albanese M. and Jajodia S..
Keeping Intruders at Large - A Graph-theoretic Approach to Reducing the Probability of Successful Network Intrusions.
DOI: 10.5220/0005013800190030
In Proceedings of the 11th International Conference on Security and Cryptography (SECRYPT-2014), pages 19-30
ISBN: 978-989-758-045-1
c 2014 SCITEPRESS (Science and Technology Publications, Lda.)
Copyright 

19

SECRYPT2014-InternationalConferenceonSecurityandCryptography

model the adversary as having a particular target (e.g.,
an intellectual property repository) and show how to
calculate the probability of him reaching the target in
a certain amount of time (we also discuss how our
framework can be easily generalized for multiple targets). We then modify our graphical representation
by adding “distraction clusters” – collections of interconnected virtual machines – at key points of the network in order to reduce the probability of an intruder
reaching the target. We study this problem formally,
showing it to be NP-hard and then provide an approximation algorithm that possesses several useful properties. We also describe a prototypal implementation
and present our experimental results.
Related Work. Moving Target Defense (MTD) (Jajodia et al., 2013; Jajodia et al., 2011; Evans et al.,
2011) is motivated by the asymmetric costs borne by
cyber defenders. Unlike prior efforts in cyber security, MTD does not attempt to build flawless systems.
Instead, it defines mechanisms and strategies to increase complexity and costs for attackers. The recent
trend of high-profile cyber-incidents resulting in significant intellectual property theft (Shakarian et al.,
2013) indicates that current practical approaches may
be insufficient.
MTD differs from current practical approaches
which primarily rely on three aspects: (a) attempting
to remove vulnerabilities from software at the source,
(b) patching software as rapidly as possible, and (c)
identifying attack code and infections. The first approach is necessary but insufficient because of the
complexity of software. The second approach is standard practice in large enterprises, but has proven difficult to keep ahead of the threat, nor does it provide
protection against zero-day attacks. The last approach
is predicated on having a signature of malicious attacks, which is not always possible.
MTD approaches aiming at selectively altering a
system’s attack surface (Manadhata and Wing, 2011)
are relatively new. In Chapter 8 of (Jajodia et al.,
2011), Huang and Ghosh present an approach based
on diverse virtual servers, each configured with a
unique software mix, producing diversified attack surfaces. In Chapter 9, Al-Shaer investigates an approach to enables end-hosts and network devices to
change their configuration (e.g., IP addresses). In
Chapter 6, Rinard describes mechanisms to change a
system’s functionality in ways that eliminate security
vulnerabilities while leaving the system able to provide acceptable functionality. A game-theoretic approach to increase complexity for the attacker is presented in (Sweeney and Cybenko, 2012).
The efforts that are more closely related to our
work are those based on the use of honeypots. How-

20

ever, such approaches significantly differ from our
work in that they aim at either capturing the attacker and stopping the attack (Abbasi et al., 2012)
or collecting information about the attacker for forensic purposes (Chen et al., 2013). There is also a
relatively new corpus of work on attacker-defender
models for cyber-security using game-theoretic techniques: an overview is provided in (Alpcan and Baar,
2010). Work in this area related to this paper include
(Williamson et al., 2012) and (Pı́bil et al., 2012). The
work presented in (Williamson et al., 2012) is similar
to our work in that it models the adversary as moving
through a graphical structure. However, that work differs in that the defender is trying to learn about the attacker’s actions for forensic analysis purposes. In this
work, we do not assume a forensic environment and
rather than trying to understand the adversary, we are
looking to delay him from obtaining access to certain
machines (e.g., intellectual property repositories). In
(Pı́bil et al., 2012), the authors use game theoretic
techniques to create honeypots that are more likely
to deceive (and hence attract) an adversary. We view
their approach as complementary to ours, specifically
with regard to the creation of distraction clusters.

2 TECHNICAL PRELIMINARIES
In this section, we first introduce the notion of intruder’s penetration network, and then provide a formal statement of the problem we address in the paper. Note that we model a complex system as a set
S = {s1 , . . . , sn } of computer systems. Each system
in S is associated with a level of access obtained by
the intruder denoted by a natural number in the range
L = {0, . . . , ℓmax }. The level of access to a given system changes over time, which is treated as discrete
intervals in the range 0, . . . ,tmax .
For a given system s and level ℓ, we shall use a
system-level pair (s, ℓ) to denote that the intruder currently has level of access ℓ on system s. We shall use
S to denote the set of all system-level pairs.
Definition 1 (Intruder’s penetration network (IPN)).
Given a system S = {s1 , . . . , sn }, the intruder’s penetration network for S is a directed graph IPN =
(S, R, π, f), where S is the set of nodes representing
individual computer systems, R ⊆ S × S is a set of directed edges representing relationships among those
systems. For a given si ∈ S, ηi = {(si , s′ ) ∈ R}. We
define the conditional success probability function
π : S × S → [0, 1] as a function that, given two systemlevel pairs (s, ℓ), (s′ , ℓ′ ) returns the probability that an
intruder with access level ℓ on s will gain access level
ℓ′ on s′ in the next time step (provided that the attacker

KeepingIntrudersatLarge-AGraph-theoreticApproachtoReducingtheProbabilityofSuccessfulNetworkIntrusions

Attack Source

Inside Router

Inside Switch

Oracle: DBSRV2

IA Switch #1

Figure 1: Sample network based on a real-world case: an
attacker targeting the Oracle server penetrates the network
exploiting a vulnerability in the Router.

selects s′ as the next target). This function must have
the following properties:
(∀(s,s′ )∈R)(∀ℓ>0)(π((s,0),(s′ ,ℓ))=0)
′ >0)(π((s,ℓ),(s′ ,ℓ′ ))=0)
(∀(s,s′ )∈R)(∀ℓ,ℓ
/

(∀ℓk ∈L )(ℓi ≤ℓ j ⇒π((s,ℓi ),(s′ ,ℓk ))≤π((s,ℓ j ),(s′ ,ℓk )))

(1)
(2)
(3)

We define f : S × S → ℜ as a function that provides
the “fitness” of a relationship. The intuition behind
the fitness f((si , ℓi ), (s j , ℓ j )) is that it is associated with
the desirability for the attacker (who is currently on
system si with level ℓi ) to achieve level of access ℓ j on
system s j . If (si , s j ) ∈
/ R then f((si , ℓi ), (s j , ℓ j )) = 0.
We note that, there are mature pieces of software
for generating the graphical structure of the IPN along
with the success probability and fitness function such
as Cauldron and Lincoln Labs’ NetSpa. Additionally,
there are vulnerability databases that can aide in the
creation of an IPN as well. For instance, in NIST’s
NVD database3 , impact and attack difficulty can map
to fitness and the inverse of the probability of success. While we are currently working with Cauldron
to generate the IPN, we do not focus on the creation of
the structure in this paper, but rather on reducing the
overall probability of success of the intruder.
We assume that if a user has no access (i.e., level 0
access) to a system s then the probability of successfully infiltrating another system s′ from that system
is 0, which is why property 1 in Definition 1 above
is valid and necessary. Similarly, property 2 articulates the fact that if no edge exists between s and s′
then the likelihood of a successful attack on s′ originating from s is also 0. Finally, property 3 defines the
intuitive assumption that if an attacker can complete
an attack with a certain probability of success then
if he conducts the same attack with a higher level of
permissions on the original system his probability of
success must be at least the same as it was in the original attack.
Example 2.1. Consider the simple network displayed
in Fig. 1 which represents a subset of a real world
3 http://nvd.nist.gov/

network we examined. In this network a user can
have one of two levels of access on each system; he
can have guest privileges (ℓ1 = 1) or root privileges
(ℓ2 = 2). The attacker begins with root privileges
on his personal device (s1 , 2). The network is displayed in full in Fig. 2 where nodes represent systemlevel pairs and edges represent logical connections
between them. All transitions between system-level
pairs will either involve transitioning to a new system
or to a higher level on the current system. Edges representing gaining higher access on the current system are red and bold in Fig. 2. Given two systemlevel pairs ((si , ℓi ), (s j , ℓ j )), the fitness of the relationship4 between them (f((si , ℓi ), (s j , ℓ j ))) is shown on
the edge between them as f, and the conditional success probability function (π((si , ℓi ), (s j , ℓ j ))) is shown
as π. For example, in the sample network, when the
attacker begins with root access on his personal computer (s1 , 2) he can gain guest privileges on the inside
router (s2 , 1) with a fitness of 1 and a probability of
success of 0.8. For ease of reading, for all systemlevel pairs where f((si , ℓi ), (s j , ℓ j )) = 0 the edge is not
displayed. The probability of a successful attack occurring is the product of the probability that the attack succeeds and the probability that the attack is
selected by the intruder. In our sample network, then,
when the intruder has guest privileges on the inside
router (s2 , 1) his probability of successfully gaining
root access on that router (s2 , 2) in the next time step
1
is 1+1
× 0.6 = 0.3.
Penetration Sequence.
A penetration sequence is simply a sequence of system-level
pairs ⟨(s0 , ℓ0 ), . . . , (sn , ℓn )⟩ such that for each
a = (si , ℓi ), b = (si+1 , ℓi+1 ) in the sequence we have
r = (si , si+1 ) ∈ R, π(a, b), f (a, b) > 0. For a sequence
σ we shall denote the number of system-level
pairs with the notation |σ|. For a given sequence
σ, let σm be the sub-sequence of σ consisting of
the first m − 1 system-level pairs in σ. For a sequence σ = ⟨(s0 , ℓ0 ), . . . , (sn , ℓn )⟩, curSys(σ) = sn ,
curLvl(σ) = ℓn and cur(σ) = (sn , ℓn ). We use the
notation next(σ) to denote the set of system-level
pairs that could occur next in the sequence. Formally:

next(σ)={(s,ℓ)∈S | ℓ>0∧(curSys(σ),s)∈R∧
̸∃ℓ′ ≥ℓ s.t. (s,ℓ′ )∈σ}

(4)

4 We

note that in this particular example we have set the
fitness values to all be one. Note that this is just one way
to specify a fitness function - perhaps in the case with no
information about desirability of a system (i.e. akin to using
uniform priors). All of our results and algorithms are much
more general and allow for arbitrary fitness values.

21

SECRYPT2014-InternationalConferenceonSecurityandCryptography

S2,1

f = 1, π = 0.7

Inside
Router

S3,1

f = 1, π = 0.8

Inside
Switch

S3,2
Inside
Switch

f =1, π = 0.8

S4,2

f = 1, π = 0.7

S2,2
Inside
Router

S5,1
Oracle:
DBSRV2

f = 1, π = 0.8

f = 1, π = 0.3

f = 1, π = 0.6

S1,2
Attack
Origin

S4,1
IA Switch
#1

f = 1, π = 0.7

IA Switch
#1

S5,2
* Oracle:
DBSRV2

Figure 2: The sample network. Nodes are system-level pairs.

Example 2.2. Fig. 3 depicts all five possible penetration sequences by which the attacker can gain root
access to the Oracle: DBSRV2 (s5 , 2) in our sample
network in five time steps or fewer. The penetration
sequences are labeled as σ1 through σ5 .
Model of the Intruder’s Actions. Now, we shall describe our model. Consider an attacker who has infiltrated through a sequence of systems specified by σ.
If the penetration is to continue, the intruder must select a system-level pair from next(σ). The intruder
selects exactly one system-level pair (s, ℓ) with the
following probability:
f(cur(σ), (s, ℓ))
∑(s′ ,ℓ′ )∈next(σ) f(cur(σ), (s′ , ℓ′ ))

(5)

Hence, the probability of selection is proportional
to the relative fitness of (s, ℓ) compared to the other
options for the attacker. This aligns with our idea of
fitness: an intruder will attempt to gain access to systems that are more “fit” with respect to his expertise,
available tools, desirability of the next system, etc.
Note that this probability of selection is not tied to
the intruder’s probability of success. In fact, we consider the two as independent. Hence, the probability
that an intruder selects and successfully reaches (s, ℓ)
can be expressed as follows:
f(cur(σ), (s, ℓ))π(cur(σ), (s, ℓ))
∑(s′ ,ℓ′ )∈next(σ) f(cur(σ), (s′ , ℓ′ ))

(6)

Hence, given that the attacker starts at a certain
(s, ℓ), we can compute the sequence probability or
probability of taking sequence σ (provided that σ
starts at (s, ℓ) – this probability would be zero otherwise).
|σ|−2

∏
i=0

f(cur(σi ), cur(σi+1 ))π(cur(σi ), cur(σi+1 ))
(7)
∑(s,ℓ)∈next(σi ) f(cur(σi ), (s, ℓ))

Hence, for a given initial (s, ℓ) and ending (s′ , ℓ′ ),
and length t + 1, we can compute the probability of
starting at (s, ℓ) and ending at (s′ , ℓ′ ) in t time-steps or
less by taking the sum of the sequence probabilities

22

for all valid sequences that meet that criterion. Formally, we shall refer to this as the penetration probability and for a given IPN,t, (s, ℓ), (s′ , ℓ′ ) we shall denote this probability as PentIPN ((s,ℓ),(s′ ,ℓ′ )). Intuitively,
Pent
((s,ℓ),(s′ ,ℓ′ )) is the probability that an attacker at
IPN
system s with level of access ℓ reaches system s′ with
level of access ℓ′ or greater in t time steps or less.
Example 2.3. The probability of the attacker successfully gaining access to (s5 , 2) in five time steps
or fewer is the sum of the probabilities of each of
the five possible penetration sequences depicted in
Fig. 3. For each penetration sequence σn the probability of the attacker successfully gaining access to
(s5 , 2) through that particular sequence is pn . For the
sample network: p1 = 0.023, p2 = 0.021, p3 = 0.021,
p4 = 0.004, p5 = 0.016. Thus, the total probability of
a successful attack occurring on system 5 at level 2 in
three time steps or fewer is PentIPN (s1 , 2) = 0.085.

3 DISTRACTION CHAINS AND
CLUSTERS
We now introduce the idea of a distraction chain. A
distraction chain is simply a sequence of decoy systems that we wish to entice an adversary to explore to
distract him from the real systems of the network. In
order to entice the adversary to explore a distraction
chain, we propose adding one-way distraction clusters to S. Hence, the adversary enters such a distraction cluster and is delayed from returning to the actual network for a number of time steps proportional
to the size of the cluster. Ideally, a distraction cluster would be large enough to delay the attacker for
a long time; however, larger distraction clusters will
obviously require more resources to construct. Distraction clusters differ from honeypots because they
do not prevent intruders from reaching other portions
of the network, thus minimizing the risk of the intruder realizing that he is trapped. Again, the goal
of a honeypot is to prevent an attacker from completing his attack by trapping him under the assumption

KeepingIntrudersatLarge-AGraph-theoreticApproachtoReducingtheProbabilityofSuccessfulNetworkIntrusions

σ1

σ2

σ3

σ4

σ5

S1,2

0.8

Attack
Origin

S1,2

0.8

Attack
Origin

S1,2

0.8

S1,2

S2,1

S2,1

0.8

S2,1

0.35

S2,1
Inside
Router

0.233

S3,1

0.35

S3,1

0.233

S3,1

0.267

S2,2

S4,2

S4,1

0.1

S3,2

0.45

0.8

S3,1
Inside
Switch

p1 = 0.023

S5,1

0.7

Oracle:
DBSRV2

0.8

S4,2

0.4

S4,2

0.35

S4,2
IA Switch
#1

S5,2
Oracle:
DBSRV2

0.35

IA Switch
#1

0.233

S5,2
Oracle:
DBSRV2

IA Switch
#1

Inside
Switch

Inside
Router

S5,2
Oracle:
DBSRV2

IA Switch
#1

Inside
Switch

0.3

0.35

IA Switch
#1

Inside
Switch

0.35

S4,2
IA Switch
#1

Inside
Switch

Inside
Router

0.8

S3,1
Inside
Switch

Inside
Router

Attack
Origin

Attack
Origin

0.35

Inside
Router

Attack
Origin

S1,2

S2,1
Inside
Router

S5,2
Oracle:
DBSRV2

0.35

S5,2
Oracle:
DBSRV2

p2 = 0.021

p3 = 0.021

p4 = 0.004

p5 = 0.016

Figure 3: All possible penetration sequences with five time steps or fewer.

that once he is trapped he will not leave it, while the
goal of a distraction cluster is – more realistically –
to delay the attacker in order to reduce the probability that he will successfully complete his attack in a
given amount of time.
Clearly, a valid distraction cluster would be connected to the rest of the system through a one-way
connection and the cluster must be created in a manner where there is at least one (preferably many) distraction chain of the necessary length (based on an expected limit of time we expect the intruder to remain
in the network before discovery).
For now we shall leave the creation of distraction
clusters to future work (e.g., the work of (Pı́bil et al.,
2012) may provide some initial insight into this problem) and instead focus on the problem of adding distraction clusters to a system. The configuration of the
first system of a distraction cluster will be a key element in setting up a distraction chain. In particular,
the open ports, patch level, installed software, operating system version, and other vulnerabilities present
on that lead system, as well as any references of that
system found elsewhere on the network will dictate
how “fit” an attacker will determine such a system
to be and the probability of success he will have in
entering into the distraction chain. Note that the fitness of this first system cannot be arbitrarily high and
should be considered based on a realistic assessment
of why the attacker would select such a system. Further, the probability of an adversary obtaining privileges on such a system should be set in such a way
where it is not overly simple for the intruder to gain
access - or he might suspect it is a decoy. Additionally, the last system in the distraction cluster must be
configured in a way to reconnect it to the actual network.
Throughout the paper, we will consider a set of
configurations available to the defender denoted CFG.

For instance, CFG may consist of a predetermined set
of virtual machine images available to the security
team. In addition we will consider a set of potential
distraction clusters denoted CL. For each cl ∈ CL
there exists value tcl ∈ N, a natural number equal to
the minimum number of time steps elapsed before
an attacker is able to leave the cluster and return
to the network. For each cfg ∈ CFG, for the lead
and last systems in the distraction cluster (resp.
sdc1 , sdc2 ) there are associated conditional probabilities (resp.
πcfg,cl : S × {(sdc1 , ℓ)} → [0, 1],
πcfg,cl : {(sdc2 , ℓ)} × S → [0, 1]) and fitness
function (resp.
fcfg,cl : S × {(sdc1 , ℓ)} → ℜ,
fcfg,cl : {(sdc2 , ℓ)} × S → ℜ).
These functions
are based on the software installed on and the vulnerabilities present in that particular configuration.
Hence, once a distraction cluster is added it contains
a lead system configured with configuration cfg.
The resulting IPN formed with the addition of
distraction cluster includes conditional probability
and fitness functions that are the concatenation of
π, πcfg,cl and f, fcfg,cl respectively. Additionally, for
each s ∈ S we add (s, sdc1 ) to R where there exists
s, ℓ where ℓ > 0 s.t. πcfg,cl ((s, ℓ), (sdc1 , 1)) > 0
and fcfg,cl ((s, ℓ), (sdc1 , 1)) > 0 and we add
(sdc2 , s) to R where there exists s, ℓ where
ℓ > 0 s.t.
πcfg,cl ((sdc2 , 1), (s, ℓ)) > 0 and
fcfg,cl ((sdc2 , 1), (s, ℓ)) > 0.
In other words, a
logical connection is formed from all systems in
S for which, if connected to sdc1 or sdc2 there is a
non-zero probability that the intruder can gain a level
of access greater than ℓ = 0. We can easily restrict
which relationship are added by modifying the fcfg,cl
functions. For a given IPN, set of distraction clusters,
and set of configuration-cluster pairs PCP ⊆ CFG × CL,
we will use the notation IPN ∪ PCP to denote the
concatenation of the intrusion penetration network
and the set of configuration-cluster pairs.

23

SECRYPT2014-InternationalConferenceonSecurityandCryptography

Adding Distraction Clusters. We now have the
pieces we need to introduce the formal definition of
our problem.
Definition 2 (Cluster Addition Problem). Given IPN
(S, R, π, f), systems s, s′ ∈ S, access levels ℓs , ℓs′ ∈ L ,
set of potential distraction clusters CL, set of configurations CFG, natural number k, real number x ∈ [0, 1],
and time-limit t, find PCP ⊆ CFG × CL s.t. |PCP| ≤ k and
((s,ℓ),(s′ ,ℓ′ )) − PentIPN∪PCP ((s,ℓ),(s′ ,ℓ′ )) > x.
Pent
IPN
Example 3.1. Following along with our sample network, the set of configurations, CFG, displayed in
Fig. 4, and with k = 2, t = 5, x = 0.05, and CL = {cl}
(with tcl = 6) we find that PCP = {(cfg1 , cl), (cfg3 , cl)}
is a solution to the Chain Addition Problem because
PentIPN (s1 , 2) − PentIPN∪PCP (s1 , 2) = 0.063 > 0.05 = x
The modified IPN is displayed in Fig. 5.
Unfortunately, this problem is difficult to solve exactly by the following result (the proof is provided in
the appendix).
Theorem 1. The Cluster Addition Problem is NPhard and the associated decision problem is NPComplete when the number of sequences from (s, ℓ)
to (s′ , ℓ′ ) is a polynomial in the number of nodes in
the intruder penetration network.
For a given instance of the Cluster Addition
Problem, for a given PCP ⊆ CFG × CL let orc(PCP) =
Pent
((s,ℓ),(s′ ,ℓ′ )) − PentIPN∪PCP ((s,ℓ),(s′ ,ℓ′ )). In the optiIPN
mization version of this problem, this is the quantity we attempt to optimize. Unfortunately, as a byproduct of Theorem 1 and the results of (Feige, 1998)
(Theorem 5.3), there are limits to the approximation
we can be guaranteed to find in polynomial time.
Theorem 2. With a cardinality constraint, finding set
PCP s.t. orc(PCP) cannot be approximated in PTIME
within a ratio of e−1
e + ε for some ε > 0 (where e is
the base of the natural log) unless P=NP.
However, orc does have some useful properties.
Lemma 1 (Monotonicity). For PCP′ ⊆ PCP ⊆ CFG × CL,
′
orc(PCP ) ≤ orc(PCP).
Lemma 2 (Submodularity). For PCP′ ⊆ PCP ⊆ CFG ×
CL and pc = (cfg, cl) ∈
/ PCP we have:
′

orc(PCP ∪{pc})− orc(PCP) ≤ orc(PCP

4

∪{pc})− orc(PCP′ )

ALGORITHMS

Greedy Approach. Now we introduce our greedy
heuristic for the Chain Addition Problem.

24

Algorithm 1: GREEDY CLUSTER.
Require: Systems s, s′ , access levels ℓs , ℓs′ , set of distraction chains CL, set of protocols CFG, natural number k
and time limit t
Ensure: Subset PCP ⊆ CFG × CL
1: PCP = 0/
2: while |PCP| ≤ k do
3:
curBest = null, curBestScore = 0
4:
for (cfg, cl) ∈ (CFG × CL) − PCP do
5:
curScore = orc(PCP ∪ {(cfg, cl)}) − orc(PCP)
if curScore ≥ curBestScore then
6:
7:
curBest = (cfg, cl)
8:
curBestScore = curScore
9:
end if
10:
end for
11:
PCP = PCP ∪ {curBest}
12: end while
13: return PCP.

Example 4.1. When run on our sample network, GREEDY CLUSTER selects (cfg1 , cl) in the
first iteration of the loop at line 4, lowering
PentIPN∪PCP (s1 , 2) from 0.085 to 0.037. In the next
iteration GREEDY CLUSTER selects (cfg3 , cl), lowering PentIPN∪PCP (s1 , 2) from 0.037 to 0.022. At this
point, since |PCP| = 2 = k, GREEDY CLUSTER returns PCP = {(cfg1 , cl), (cfg3 , cl)}, a solution to the
Chain Addition Problem under our given constraints.
Though simple, GREEDY CLUSTER, can provide
the best approximation guarantee unless P=NP under
the condition that orc can be solved in PTIME. Consider the following theorem.
Theorem 3. GREEDY CLUSTER provides the best
PTIME approximation of orc unless P=NP if orc can
be solved in PTIME.
However, the condition on solving orc in PTIME
may be difficult to obtain in the case of a very general IPN. Though we leave the exact computation of
this function as an open problem, we note that the
straight-forward approach for computation would imply the need to enumerate all sequences from (s, ℓ)
to (s′ , ℓ′ ) - which can equal the number of t-sized (or
smaller) permutations of the elements of S - a quantity that is not polynomial in the size of IPN. Hence,
a method to approximate orc is required in practice.
Our intuition is that the expensive computation of the
penetration probability can be approximated by summing up the sequence probabilities of the most probable sequences from (s, ℓ) to (s′ , ℓ′ ). The intuition of
approximating the probability of a path between two
nodes in a network (given a diffusion model) based on
high-probability path computation was introduced in
(Chen et al., 2010) where it was applied to the maximum influence problem. However, our approach differs in that (Chen et al., 2010) only considered the

KeepingIntrudersatLarge-AGraph-theoreticApproachtoReducingtheProbabilityofSuccessfulNetworkIntrusions

Figure 4: The set CFG of possible configurations available to the defender.
cfg3

S2,1

f = 1, π = 0.7

Inside
Router

S3,1

f = 1, π = 0.8

Inside
Switch

S3,2
Inside
Switch

f =1, π = 0.8

S4,2

f = 1, π = 0.7

S2,2
Inside
Router

S5,1
Oracle:
DBSRV2

f = 1, π = 0.8

f = 1, π = 0.3

f = 1, π = 0.6

S1,2
Attack
Origin

S4,1
IA Switch
#1

f = 1, π = 0.7

IA Switch
#1

S5,2
* Oracle:
DBSRV2

cfg1

Figure 5: The updated network with PCP added.

most probable path, as we consider a set of most probable paths. Our intuition in doing so stems from the
fact that alternate paths can contribute significantly to
the probability specified by PentIPN ((s,ℓ),(s′ ,ℓ′ )).
Computing orc.
Next, we introduce a simple
sampling-based method that randomly generates sequences from (s, ℓ) to (s′ , ℓ′ ) of the required length.
These sequences are generated with a probability
proportional to their sequence probability, hence the
computation of orc based on these samples is biased
toward the set of most-probable sequences from (s, ℓ)
to (s′ , ℓ′ ), which we believe will provide a close
approximation to orc. Our pre-processing method,
ORC SAM below generates a set of sequences that
the attacker could potentially take. Using the sequences from SEQ, we can then calculate the penetration probability (PentIPN ((s,ℓ),(s′ ,ℓ′ ))) by summing over
the probabilities over the sequences in SEQ as opposed to summing over all sequences (a potentially
exponential number).
Extensions. Our approach is easily generalizable for
studying other problems related to Cluster-Addition.
For instance, suppose an intruder initiates his infiltration from one of a set of systems chosen based on a

Algorithm 2: ORC SAM.
Require: Systems s, s′ , access levels ℓs , ℓs′ , natural numbers t, maxIters
Ensure: Set of sequences SEQ
1: curIters = 0, SEQ = 0/
2: while curIters < maxIters do
3:
(si , ℓi ) = (s, ℓs ), curSeq = ⟨(s, ℓs )⟩, curLth = 0
4:
while curLth < t and (si , ℓi ) ̸= (s′ , ℓs′ ) do
Select (s′ , ℓ′ ) from the set (ηi × L ) − curSeq with
5:
f((s ,ℓ ),(s′ ,ℓ′ ))π((si ,ℓi ),(s′ ,ℓ′ ))
a probability of ∑ i i
f((s ,ℓ ),(s ,ℓ ))
(s j ,ℓ j )∈(ηi ×L )−curSeq

i

i

j

j

6:
curSeq = curSeq ∪ {(s′ , ℓ′ )}
7:
end while
If (s′ , ℓ′ ) = (s′ , ℓs′ ) then SEQ = SEQ ∪ {curSeq}
8:
9:
curIters+ = 1
10: end while
11: Return SEQ

probability distribution. We can encode this problem
in Chain-Addition by adding a dummy system to the
penetration network and establishing relationships to
each of the potential initial systems in the set. The
fitness and conditional probability functions can then
be set up in a manner to reflect the probability distribution over the set of potential initial systems. Note

25

SECRYPT2014-InternationalConferenceonSecurityandCryptography

that this problem would still maintain the same mathematical properties and guarantees of our already described method to solve the Cluster-Addition problem. Another related problem that can be solved using our methods (again with only minor modification)
is to minimize the expected number of compromised
systems in a set of potential targets. As the expected
number of systems would simply be the sum of the
penetration probability for each of those machines, a
simple modification to Line 5 of GREEDY CLUSTER
would allow us to represent this problem, in this case
instead of examining orc we would examine the sum
of the value for orc returned for paths going to each of
the potential targets. Note that by the fact that positive linear combinations of submodular functions are
also submodular, we are able to retain our theoretical
guarantees here as well.

5

EXPERIMENTAL RESULTS

We conducted several experiments in order to test the
effectiveness of our algorithm under several circumstances. As explained in the preceding running example we tested our algorithm on a small network
derived from a real network. As shown, by adding
two distraction clusters to that network we were able
to reduce the probability of a successful attack from
8.5% to 2.2%, an almost 75% reduction. While this
result shows relevance to a real-world network and
displays the algorithm on an easily understood scale,
we also wanted to test the scalability of our algorithm
by experimenting on larger networks. Due to the difficulty of obtaining large datasets for conducting research in cyber security we generated random graphs
that resembled the network topology of the types of
penetration networks we wish to examine, allowing
us to test the scalability of our algorithm. To do this
we generated networks which were divided into layers, meaning that each system is only connected to
other systems in its own layer or to systems in the
next layer. This is important because it means that in
a network with n layers, the shortest path between the
source of the attack and the target is n − 1. We did
this because it mimics the topology of the real-world
networks we wished to replicate in our experiments.
It provides structure to our networks so that the simulated attackers will have to gain access to systems
across a series of layers before gaining access to a
system from which they can access their target. For
all of our experiments we assumed that π = 1. We
did this because it makes it easier to see and understand the relationship between the lower and upper
bounds of the penetration probability. This does not

26

compromise the value of our results because adding
distraction clusters to a network only effects the relative fitness of an attack, so the probability of success
for any one attack does not influence our results.
The first test we ran sought to measure the effectiveness of the ORC SAM sampling algorithm by testing against the value of t—the maximum length of
a penetration sequence—and the number of iterations
conducted in the sampling algorithm (ORC SAM). We
found—as would be expected—that the number of iterations required for the most accurate possible result
increases as t increases and as the number of systemlevel pairs (nodes) in the network increases. We ran
our tests on randomly generated networks with 50 and
100 systems each with 2 levels per system. Figs. 6, 7,
and 8 display the results of this test. Fig. 6 shows that,
as t increases, the number of iterations of ORC SAM
required to get an accurate prediction of the penetration probability increases. For high values of t, with
a relatively small number of iterations, the difference
between the upper and lower bounds of the test is very
large. This effect is displayed more clearly in Fig. 7
in which this difference is graphed for each value of
t against the number of iterations. Finally, Fig. 8 displays the time in seconds that each individual test took
to run.
One important factor when implementing distraction clusters is determining the location in the network in which to place them. The initial instinct may
be that the goal should be to distract the attacker early
in his pursuit and thus the clusters should be placed
close to the source of the attack; however, this has
little effect on the resulting decrease in penetration
probability. We conducted experiments on the same
two networks from the previous test in which we randomly generated a cluster and connected it to 10 systems in a given layer for each layer in the system
(other than the first and last layers which only have
one system each—the source and the target, respectively). We then measured the changes in penetration
probability that occurred as a result. For each network
we conducted 10 trials. Our results showed little evidence that the proximity to the source of the attack
matters and instead suggest that the size of the layer
is the more influential variable. Clusters with configurations that connected them to systems in a layer
with a relatively small number of systems showed a
larger decrease in the penetration probability. In addition to being suggested by our evidence, this also
makes intuitive sense because providing the attacker
a distraction in a layer with fewer systems means that
more of his options will lead into the distraction cluster rather than allowing him to progress forward with
his attack.

t=6
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
5

t=7

t=8

t=9

t = 10

t = 11

t=7

t = 12
Penetration Probability Bounds

Penetration Probability Bounds

KeepingIntrudersatLarge-AGraph-theoreticApproachtoReducingtheProbabilityofSuccessfulNetworkIntrusions

15

25
35
Iterations (thousands)

t=8

t=9

t = 10

t = 11

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

45

10

30

(a) Network with 50 systems.

50
70
Iterations (thousands)

90

(b) Network with 100 systems.

Figure 6: Upper and lower bounds of the predicted penetration probability vs. number of iterations of ORC SAM, for different
values of t.
t=7

t=8

t=9

t = 10

t = 11

t = 12

t=7
Penetration Probability Range

Penetration Probability Range

t=6
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
5

15

25
35
Iterations (thousands)

t=8

t=9

t = 10

t = 11

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

45

10

30

(a) Network with 50 systems.

50
70
Iterations (thousands)

90

(b) Network with 100 systems.

Figure 7: Difference between upper and lower bounds of the predicted penetration probability vs. number of iterations of
ORC SAM, for different values of t.
t=7

t=8

t=9

t = 10

t = 11

t = 12

t=7
350

35

300
Execution Time (s)

Execution Time (s)

t=6
40
30

25
20
15
10

t=8

t=9

t = 10

t = 11

250
200
150
100
50

5

0

0
0

10

20
30
Iterations (thousands)

40

0

50

20

40

60

80

100

Iterations

(a) Network with 50 systems.

(b) Network with 100 systems.

Figure 8: Execution time vs. number of iterations of ORC SAM, for different values of t.
Lower Bound

Linear (Lower Bound)

Lower Bound

0.22

Penetration Probability

Penetration Probability

Upper Bound

Linear (Lower Bound)

Linear (Upper Bound)

0.030

0.24

0.2
R² = 0.9437

0.18

0.16
0.14
0.12

0.027
R² = 0.8286

0.024
0.021
R² = 0.9206
0.018
0.015

0.1
5

7

9
11
Number of Systems in Layer

(a) Network with 50 systems.

13

15

0

5

10
15
Number of Systems in Layer

20

25

(b) Network with 100 systems.

Figure 9: Correlation between the number of systems in a layer and the penetration probability when the distraction cluster
was configured to systems in that layers (note that for the network with 50 systems, the bounds nearly matched and only the
lower is displayed).

27

SECRYPT2014-InternationalConferenceonSecurityandCryptography

Without DC

With DC

Without DC

Without DC

0.2
0.15
0.1
0.05

Penetration Probability

0.25

0

0.5

0.4
0.3
0.2
0.1
0

5

15
25
35
Iterations (thousands)

45

5

(a) Network with 50 systems, t = 7.
Without DC

15

25
35
Iterations (thousands)

Without DC

45

5

0.03
0.02
0.01
0

0.5

0.4
0.3
0.2
0.1
0

10

30
50
70
Iterations (thousands)

90

(d) Network with 100 systems, t = 7.

10

30

50
70
Iterations (thousands)

25
35
Iterations (thousands)

Without DC
Penetration Probability

Penetration Probability

0.04

15

90

(e) Network with 100 systems, t = 8.

45

(c) Network with 50 systems, t = 9.

With DC

0.6

0.05

With DC

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

(b) Network with 50 systems, t = 8.

With DC

0.06
Penetration Probability

With DC

0.6
Penetration Probability

Penetration Probability

0.3

With DC

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
10

30

50
70
Iterations (thousands)

90

(f) Network with 100 systems, t = 9.

Figure 10: Penetration probabilities before and after adding the cluster chosen by GREEDY CLUSTER.

Fig. 9 shows the results from the tests. The y-axis
represents the average penetration probability with
the configuration added to the layer while the x-axis
represents the number of systems in the layer. The
dotted line shows the result of the linear regression
which shows a linear relationship between the two
variables. While we show a linear regression the relationship is not exactly linear as the effect is lessened
as the layers become larger. Note that the average
percent decrease in penetration probability when clusters were added to the network with 50 systems was
20.7% while the average when they were added to the
larger network was only 6.4%. We hope to do further
testing in the future to identify other variables that affect the outcome. In addition to investigating the ideal
location for placing a cluster we also examined the
effects of the number of iterations of ORC SAM that
are run on the results of the test. These results are
shown in Fig. 10. As explained earlier, ORC SAM is
a heuristic that generates a random sample of possible paths between the source and target. To test this
we ran GREEDY CLUSTER with varying numbers of
iterations run on ORC SAM. We generated ten possible configurations for GREEDY CLUSTER to choose
from and assigned it to choose the optimal configuration. We ran the test on both networks with iterations of ORC SAM ranging from 5,000 to 50,000 in
increments of 5,000 on the smaller network and from
10,000 to 100,000 in increments of 10,000 on the
larger one. We ran this test with the values of t—the

28

maximum length of a penetration sequence—set to 7,
8, and 9 for three different tests on both networks.
We found that regardless of the number of iterations
run or the value of t, GREEDY CLUSTER selected the
same configuration and there was a small difference
between the percent decrease in penetration probabilities after the clusters were added to the network. This
suggests that accurate predictions about the effects of
a cluster on a network can be made without sampling
all possible paths from the source to the target. Additionally, as stated earlier, it suggests that seeking to
reduce the probability of the attack being reached in
the shortest number of steps will also help reduce the
probability of paths of greater lengths.

6 CONCLUSIONS
Despite significant progress in the area of intrusion
prevention, it is well known that not all intrusions
can be prevented, and additional lines of defense are
needed in order to cope with attackers capable of circumventing existing intrusion prevention systems.
In this paper, we proposed a novel approach to intrusion prevention that aims at delaying an intrusion,
rather than trying to stop it, so as to control the probability that an intruder will reach a certain goal within
a specified amount of time. In the future, we plan to
do more experiments to better understand the factors
that influence the ideal location of distraction clus-

KeepingIntrudersatLarge-AGraph-theoreticApproachtoReducingtheProbabilityofSuccessfulNetworkIntrusions

ters and to determine the relationship between penetration probability, iterations of ORC SAM, and the
selection of configurations for adding distraction clusters as well as investigate the impact of the length of
distraction clusters on the network and the location of
the point at which the distraction clusters reconnect to
the network.

REFERENCES
Abbasi, F., Harris, R., Moretti, G., Haider, A., and Anwar, N. (2012). Classification of malicious network
streams using honeynets. In Global Communications
Conference (GLOBECOM), pages 891–897.
Alpcan, T. and Baar, T. (2010). Network Security: A Decision and Game-Theoretic Approach. Cambridge University Press, New York, NY, USA, 1st edition.
Chen, C.-M., Cheng, S.-T., and Zeng, R.-Y. (2013). A
proactive approach to intrusion detection and malware
collection. Security and Communication Networks,
6(7):844–853.
Chen, W., Wang, C., and Wang, Y. (2010). Scalable influence maximization for prevalent viral marketing in
large-scale social networks. In Proceedings of the 16th
ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1029–1038.
Evans, D., Nguyen-Tuong, A., and Knight, J. C. (2011).
Moving Target Defense: Creating Asymmetric Uncertainty for Cyber Threats, chapter Effectiveness of
Moving Target Defenses, pages 29–48. Springer.
Feige, U. (1998). A threshold of ln n for approximating set
cover. J. ACM, 45(4):634–652.
Jajodia, S., Ghosh, A. K., Subrahmanian, V. S., Swarup, V.,
Wang, C., and Wang, X. S., editors (2013). Moving
Target Defense II: Application of Game Theory and
Adversarial Modeling, volume 100 of Advances in Information Security. Springer, 1st edition.
Jajodia, S., Ghosh, A. K., Swarup, V., Wang, C., and Wang,
X. S., editors (2011). Moving Target Defense: Creating Asymmetric Uncertainty for Cyber Threats, volume 54 of Advances in Information Security. Springer.
Manadhata, P. K. and Wing, J. M. (2011). An attack surface
metric. IEEE Transactions on Software Engineering,
37(3):371–386.
Nemhauser, G. L., Wolsey, L. A., and Fisher, M. (1978).
An analysis of approximations for maximizing submodular set functionsi. Mathematical Programming,
14(1):265–294.
Pı́bil, R., Lisý, V., Kiekintveld, C., Bosanský, B., and Pechoucek, M. (2012). Game theoretic model of strategic honeypot selection in computer networks. In
GameSec, pages 201–220.
Shakarian, P., Shakarian, J., and Ruef, A. (2013). Introduction to Cyber-Warfare: A Multidisciplinary Approach.
Syngress.
Sweeney, P. and Cybenko, G. (2012). An analytic approach
to cyber adversarial dynamics. In SPIE Defense, Security, and Sensing, pages 835906–835906. International Society for Optics and Photonics.

Williamson, S. A., Varakantham, P., Hui, O. C., and Gao,
D. (2012). Active malware analysis using stochastic
games. In Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems - Volume 1, AAMAS ’12, pages 29–36, Richland, SC. International Foundation for Autonomous
Agents and Multiagent Systems.

APPENDIX
Proof of Theorem 1. The Cluster Addition Problem is NPhard and the associated decision problem is NP-Complete
when the number of sequences from (s, ℓ) to (s′ , ℓ′ ) is a polynomial in the number of nodes in the intruder penetration
network.
Proof. Membership in NP (if the number of sequences from
(s, ℓ) to (s′ , ℓ′ ) is polynomial can be shown when the certificate is the set of configuration-cluster pairs.
For NP-hardness, consider the set cover problem (Feige,
1998) where the input consists of as set of elements S,
a family of subsets of S denoted as H, and natural numbers K, X. The output of this problem is a subset of H
of size K or less such that their union covers X or more
elements of S. This problem is NP-hard and can be embedded into an instance of the cluster addition problem
as follows: L = {0, 1}, S = {s,t} ∪ {vw |w ∈ S}, R =
{(s, vw ), (vw ,t)|w ∈ S}, ∀w ∈ S, set π((s, 1), (vw , 1)) = 1 and
π((vw , 1), (t, 1)) = 1 (otherwise set π by definition), ∀w ∈ S,
set f((s, 1), (vw , 1)) = 1 and f((vw , 1), (t, 1)) = 1 (otherwise
set f by definition), ℓs , ℓs′ = 1, CL = {cl}, CFG = {cfgh |h ∈
H}, for each cfgh ∈ CFG and cl set πcfgh ,cl (vw ) = 1 if s ∈ h
and 0 otherwise, for each cfgh ∈ CFG and cl set fcfgh ,cl (vw ) =
|S|−X

X
|S| if s ∈ h and 0 otherwise, x = 1− |S| − |S|(|S|+1)
, k = K,
and t = 2. Clearly this construction can be completed in
polynomial time.
Next, we show that a solution to set cover will provide
a solution to the constructed cluster-addition problem. If
H ′ is a solution to set cover, select the set {cfgh |h ∈ H ′ }.
Clearly this meets the cardinality constraint. Note that in
the construction, all sequences from (s, 1) to (t, 1) are of the
form ⟨(s, 1), (vw , 1), (t, 1)⟩ where w ∈ S. Note that as every
system vw ∈ S − {s,t} is now connected to a cluster. Hence,
each cluster now has had its probability reduced from 1/|S|
to at most 1/(|S|(|S| + 1). Hence, PentIPN∪PCP ((s,ℓ),(s′ ,ℓ′ )) <
|S|−X
|S|

X
+ |S|(|S|+1)
which completes this claim of the proof.
Going the other way, we show that a solution to the
constructed cluster-addition problem will provide a solution to set cover. Given cluster-addition solution PCP, consider H ′ = {h|(cfgh , cl) ∈ PCP}. Note that, by the construction, all elements of PCP are of the form (cfgh , cl) where
h ∈ H ′ . Clearly, the cardinality constraint is met by the
construction. Suppose, BWOC, H ′ is not a valid solution
to set cover. We note that this must imply that there are
some vs that are not attached to a distraction cluster. Let
us assume there are δ number of these systems. Hence,
|S|−X+δ
X−δ
((s,ℓ),(s′ ,ℓ′ )) >
Pent
+ |S|(k|S|+1)
. Let us now
IPN∪PCP
|S|
assume, by way of contradiction, that this quantity is less
|S|−X
X
than or equal to |S| + |S|(|S|+1)
, which is the upper bound
t
′ ′
on PenIPN∪PCP ((s,ℓ),(s ,ℓ )) is at least X of the vs systems have

29

SECRYPT2014-InternationalConferenceonSecurityandCryptography

a distraction cluster:
|S| − X + δ
X −δ
+
|S|
|S|(k|S| + 1)
δ(k|S| + 1) + X − δ
|S|(k|S| + 1)
(δk|S| + X)(|S| + 1)

≤
≤
≤

|S| − X
X
+
(8)
|S|
|S|(|S| + 1)
X
(9)
|S|(|S| + 1)
X(k|S| + 1)
(10)

Fi +Bi
Fi +Bi
greater than 1 − ∏i Fi +B
. Here, the term ∏i Fi +B
i +Di
i +Ei
decreases as each of the Ei ’s increase and that this value is
no more than 1. Hence, the following must be true (under
the assumption that the original statement is false).

Fi + Bi + Ei

Fi + Bi

∏ Fi + Bi + Di + Ei < ∏ Fi + Bi + Di
i

i

However, as δk|S| +X > k|S| +1 and as |S| + 1 > X, this
give us a contradiction, completing the proof. 

For the above statement to be true, there must exist
at least one i such that (Fi + Bi + Ei )(Fi + Bi + Di ) <
(Fi + Bi )(Fi + Bi + Di + Ei ) which implies Di , Ei ≥ 0, thus
leading us to a contradiction and completing the proof. 

Proof of Theorem 2. With a cardinality constraint, finding set PCP s.t. orc(PCP) cannot be approximated in PTIME
within a ratio of e−1
e + ε for some ε > 0 (where e is the base
of the natural log) unless P=NP.
Proof. Follows directly from the construction of Theorem
1 and Theorem 5.3 of (Feige, 1998). — Slightly longer
version below: Note that Theorem 1 shows that we can
find an exact solution to set-cover in polynomial time using
an instance of the Cluster Addition problem. A optimization variant of this problem, the MAX-K-COVER problem (Feige, 1998) takes the same input and returns a subset
of H size K whose union covers the maximum number of
elements in S. This variant of the problem cannot be approximated within a ratio of α = e−1
e + ε for some ε > 0 by
Theorem 5.3 of (Feige, 1998). 

Proof of Theorem 3. GREEDY CLUSTER provides the
best PTIME approximation of orc unless P=NP if orc can be
solved in PTIME.
Proof. If orc can be solved in PTIME, it is easy to then
show that GREEDY CLUSTER runs in PTIME. The results
of (Nemhauser et al., 1978) show a greedy algorithm proe
vides a e−1
approximation for the maximization of a nondecreasing submodular function that returns zero on the
/ = 0 and we showed that it is nonempty set. Clearly, orc(0)
decreasing and submodular in Lemmas 1 and 2 respectively
e
- which means that GREEDY CLUSTER provides a e−1
approximation to the maximization of orc. This matches the
theoretical bound proved in Theorem 2 which holds unless
P=NP. 

Proof of Lemma 1. For PCP′ ⊆ PCP ⊆ CFG × CL, orc(PCP′ ) ≤
orc(PCP).
Proof. Given an instance of the cluster addition problem,
consider a single sequence from s to s′ . Clearly the probability associated with that sequence will either remain the
same with the addition of any configuration-cluster pair to
the penetration network as the denominator of the probability of transitioning between system-level pairs will only
increase (due to the additive nature of fitness in the denominator). Likewise, subsequent configuration-cluster pair additions will lead to further decrease. Hence, the penetration probability monotonically decreases with the addition
of configuration-cluster pairs as it is simply the sum of the
sequence probabilities form s to s′ of length t which makes
orc monotonically increasing, as per the statement. 
Proof of Lemma 2. For PCP′ ⊆ PCP ⊆ CFG × CL and pc =
(cfg, cl) ∈
/ PCP we have:
orc(PCP ∪ {pc}) − orc(PCP)

≤ orc(PCP′ ∪ {pc}) − orc(PCP′ )

Proof. It is well known that a positive, linear combination
of submodular functions is also submodular. Hence,
without loss of generality, we can prove the statement by
only considering a single sequence. Let lth be the length
(number of transitions) of the sequence. For the ith (s, ℓ) in
the sequence, let Fi+1 = ∑(s′ ,ℓ′ )∈ηi ×L f((s, ℓ), (s′ , ℓ′ )),
Bi+1 = ∑(s′ ,ℓ′ )∈PCP′ ×L f((s, ℓ), (s′ , ℓ′ )),
Di+1 =
∑(s′ ,ℓ′ )∈PCP×L f((s, ℓ), (s′ , ℓ′ )) − Bi+1 , Ei+1 = f((s, ℓ), pc).
Using this notation, we can apply the definition of orc and some easy algebra, we obtain that
1
is less than or equal to
∏i Fi +B1i +Di − ∏i Fi +Bi +D
i +Ei
1
1
−
.
Suppose,
BWOC, the statement is
∏i Fi +Bi ∏i Fi +Bi +Ei
(
)
Fi +Bi
Fi +Bi +Ei
false, this implies that ∏i Fi +Bi +Ei 1 − ∏i Fi +B
is
i +Di +Ei

30

Ann Math Artif Intell (2016) 78:259–301
DOI 10.1007/s10472-015-9483-5

Belief revision in structured probabilistic argumentation
Model and application to cyber security
Paulo Shakarian1 · Gerardo I. Simari2 ·
Geoffrey Moores3 · Damon Paulo3 · Simon Parsons4 ·
Marcelo A. Falappa2 · Ashkan Aleali1

Published online: 25 September 2015
© Springer International Publishing Switzerland 2015

Abstract In real-world applications, knowledge bases consisting of all the available information for a specific domain, along with the current state of affairs, will typically contain
contradictory data, coming from different sources, as well as data with varying degrees of
uncertainty attached. An important aspect of the effort associated with maintaining such
knowledge bases is deciding what information is no longer useful; pieces of information
may be outdated; may come from sources that have recently been discovered to be of low

 Paulo Shakarian

shak@asu.edu
Gerardo I. Simari
gis@cs.uns.edu.ar
Geoffrey Moores
geoffrey.moores@usma.edu
Damon Paulo
damon.paulo@usma.edu
Simon Parsons
s.d.parsons@liverpool.ac.uk
Marcelo A. Falappa
mfalappa@cs.uns.edu.ar
Ashkan Aleali
aleali@asu.edu
1

Arizona State University, Tempe, AZ, USA

2

Department of Computer Science and Engineering, Universidad Nacional del Sur (UNS)
and Institute for Computer Science and Engineering (CONICET-UNS), Bahı́a Blanca, Argentina

3

Department of Electrical Engineering and Computer Science, U.S. Military Academy,
West Point, NY, USA

4

Department of Computer Science, University of Liverpool, Liverpool, UK

260

P. Shakarian et al.

quality; or abundant evidence may be available that contradicts them. In this paper, we
propose a probabilistic structured argumentation framework that arises from the extension
of Presumptive Defeasible Logic Programming (PreDeLP) with probabilistic models, and
argue that this formalism is capable of addressing these basic issues. The formalism is
capable of handling contradictory and uncertain data, and we study non-prioritized belief
revision over probabilistic PreDeLP programs that can help with knowledge-base maintenance. For belief revision, we propose a set of rationality postulates — based on well-known
ones developed for classical knowledge bases — that characterize how these belief revision
operations should behave, and study classes of operators along with theoretical relationships
with the proposed postulates, including representation theorems stating the equivalence
between classes of operators and their associated postulates. We then demonstrate how our
framework can be used to address the attribution problem in cyber security/cyber warfare.
Keywords Argumentation · Belief revision · Probabilistic reasoning · Cyber security
Mathematics Subject Classification (2010) 68T30 · 68T27 · 68T37

1 Introduction
We begin by motivating our work, describing the most related work from the literature,
introducing the cyber-attribution problem, and clarifying the contribution of the paper.

1.1 Motivation
In many real-world applications, knowledge bases consisting of all the information that is
available about a specific domain, along with all the available information about the current state of affairs, will typically contain contradictory data. That is because the knowledge
base will have been constructed using data from different sources that disagree. This data
will also, typically, contain some measure of uncertainty. Thus, key problems that need to
be addressed by formalisms for knowledge representation are the ability to handle contradictory information and to perform inference in the presence of uncertainty. In addition, in
many cases it is necessary to update the knowledge in the knowledge base: for instance,
pieces of information may be outdated, may come from sources which have recently been
discovered to be of low quality, or there may be abundant evidence available that contradicts these pieces of information. In such cases, the knowledge base needs to be updated
accordingly. A good example of how all of these requirements come together is provided
by the scenario of determining the culprit of a cyber attack, an example that we will use
in some detail to illustrate the ideas we develop in this paper. Here we provide a quick,
motivating, sketch. The basic information in the scenario comes from a variety of different
sources that only have a partial view of the domain, and since these sources disagree, having
contradictory information in the knowledge base is unavoidable. In a cyber attack, it is not
uncommon for the attacker to leave some false pieces of evidence with the goal of misleading the investigation, adding further contradictory information. None of the evidence that is
gathered after an attack is conclusive, so there is uncertainty in the information that must be
handled. Finally, since in responding to an attack new information is added to information
that was gathered after previous attacks, it is necessary to update the knowledge base. In

Belief revision in structured probabilistic argumentation

261

particular, if new information contradicts old information, it may be necessary to perform
belief revision to recover consistency of some parts of the knowledge-base.1
From this discussion we distill the requirements on any knowledge representation formalism that will be used in real-world applications. Such a formalism must be able to:
1. represent contradictory and uncertain information;
2. answer queries on a knowledge base; and
3. handle revisions to the knowledge base.
This paper presents a formalism called DeLP3E that meets all these requirements. A
DeLP3E model consists of two parts, an environmental model (EM) and an analytical model
(AM), which represent different aspects of a scenario. The idea is that the analytical model
contains all the background information that is available for the analysis of the scenario. We
envisage that this information is a combination of ontological information about the world,
for example (to take the old example), “Tweety is a penguin”, “penguins are birds” and
“penguins do not fly”, and commonsense information that is relevant, for example “birds
generally fly”. As can be seen from this small example, the AM can be inconsistent, and
so we will choose a formal model for the AM that can cope with inconsistency. The environmental model is intended to contain evidence that has been collected about a specific
situation (an instance of the more general model in the AM) about which queries will be
answered. In the classic example, “Tweety is a penguin” would be an element of the EM, but
the EM can also be more subtle than this, allowing for the representation of uncertain information. If we did not know for sure that Tweety was a penguin, but just had some suggestive
evidence that this is so, we could, for example include in the EM the fact that “Tweety is a
penguin” has a probability of 0.8 of being true. The EM is not limited to facts — we could
also choose to model our evidence about Tweety with “Tweety is a bird” and “Tweety is
black and white” and the rule that “Black and white birds have a probability of 0.8 of being
penguins”. A more complex pair of EM and AM, which relates to our motivating cyber
security example, is given in Table 1.
The languages used in the AM and the EM are related through an annotation function
(AF), which pairs formulae in the EM and the AM. Reasoning then consists of answering a
query in the AM — when the AM is inconsistent, this will involve establishing the relevant
consistent subset to answer the query computing the probability of the elements of the EM,
and, through the annotation function, establishing the probabilities that correspond to the
answer to the initial query. Thus, in the Tweety example, to answer a query about whether
Tweety can fly, the AM would reason about this truth or falsity of the proposition “Tweety
flies”, the AF would identify which elements of the EM relate to this query, and the EM
would provide a probability for these elements. The probability of the answer to the query,
in this case either “Tweety flies” or “Tweety does not fly”, could then be computed. The
inference of this probability is what we call entailment.
In our vision, DeLP3E is less a specific formalism and more a family of formalisms where
different formal models for handling uncertainty can be used for the EM, and different logical reasoning models can be used for the AM. In this paper, to make the discussion concrete,
we make some specific choices. In particular, the EM is based on Nilsson’s Probabilistic

1 Below

we discuss why we might want to carry out belief revision in a formalism that has the ability to
handle some forms of inconsistency

262

P. Shakarian et al.

Table 1 Examples of the kind of information that could be represented in the environmental and analytical
models in a cyber-security application domain
Environmental model (EM)

Analytical model (AM)

Malware X was compiled on a system

Malware X was compiled on a system in

using the English language.

English-speaking country Y.

Country Y and country Z are

Country Y has a motive to launch a

currently at war.

cyber-attack against country Z

Malware W and malware X were created

Malware W and malware X are related.

in a similar coding style.
Country Y has a significant

Country Y has the capability to

investment in math-science-engineering

conduct a cyber-attack.

(MSE) education.

Logic [32], and the AM is based on the PreDeLP argumentation model from [30]. At the
heart of PreDeLP is the notion of presumptions, elements of the knowledge base that can be
presumed (assumed) to be true. This makes for a very natural connection to the EM, where
the presumptions are the elements of the AM that connect (through the annotation function)
to elements of the EM (as do the other elements of the AM). Thus, the presumptions will
have a probability associated with them, and this is then used to establish the probability of
the answer to the initial query.
This discussion has covered the requirement for DeLP3E to deal with inconsistency and
uncertainty, and identified the need for inference. The final requirement is for the ability to
revise the knowledge base, in particular the ability to perform belief revision in the sense
of [1, 16, 17]. Given that belief revision is concerned with maintaining the consistency of
a set of beliefs and that DeLP3E is built around an argumentation system that can handle
inconsistency, at first glance it might not be obvious why belief revision will be required
if these become inconsistent. However, on more reflection, it is clear that all three parts
of a DeLP3E model — the environmental model, the analytical model, and the annotation
function — may require revision, at least in the instantiation of DeLP3E that we consider
here. The EM is underpinned by probability theory, and this places the constraint that the
set of propositions used in the EM be consistent (a constraint that would not necessarily
exist if we were to use a different uncertainty handling mechanism). The AM is built using
PreDeLP, and though there can be inconsistency in some elements of a PreDeLP model,
the strict rules and facts used to answer a specific query must be consistent, and so belief
revision is required (if we built the AM using an argumentation system that only included
defeasible knowledge, as in [36], belief revision would not be required). Finally, though
there is never a strict requirement for belief revision of the AF, as we will discuss later,
providing the ability to revise the annotation function can help us to avoid revising other
aspects of the model, and this can be helpful.

1.2 Related work
The work that is closest to that reported here has been carried out in the intersection of belief
revision and argumentation, and the work carried out in the combination of structured argumentation approaches with formalisms for probabilistic reasoning. We now discuss these

Belief revision in structured probabilistic argumentation

263

two points of contact with the existing literature; since, to the best of our knowledge, the
combination we tackle in our work is completely novel, it is important to note that this
discussion is necessarily short.
Belief revision studies changes to knowledge bases as a response to epistemic inputs.
Traditionally, such knowledge bases can be either belief sets (sets of formulas closed under
consequence) [1, 16, 17] or belief bases [20, 21] (which are not closed); since our end
goal is to apply the results we obtain to real-world domains, here we focus on belief
bases. In particular, our knowledge bases consist of logical formulas over which we apply
argumentation-based reasoning and to which we couple a probabilistic model. The connection between belief revision and argumentation was first studied in [6]; see [12] and
the further developments in [9]. Since then, the work that is most closely related to our
approach is the development of the explanation-based operators of [11]. The main difference between that line of work and the one developed here arises from the interaction in our
model between classical and probabilistic formalisms; to the best of our knowledge, this has
not been tackled in the literature on combining argumentation and belief revision.
The study of argumentation systems together with probabilistic reasoning has recently
received a lot attention, though a significant part of this recent work has concentrated on
the combination of probability and abstract argumentation [14, 23, 28, 46]. There have,
however, been several approaches that combine structured argumentation with models for
reasoning under uncertainty; the first such approach to be proposed was [19]2 and several
others followed, such as the possibilistic approach of [4], and the probabilistic logic-based
approach of [24]. Similar to the difference between our approach and others on argumentation and belief revision, the main difference between these works and our own is that
here we separate knowledge into the environmental model and the analytical model, where
one part captures the probabilistic knowledge, and the other part the models knowledge
that is not inherently probabilistic. This allows for a clear separation of interests between
the two kinds of models. This approach is based on the similar approach developed for
ontological languages in the Semantic Web (see [18], and references therein). The basic
differences with that work is that the non-probabilistic part of the knowledge base corresponds to a classical ontology that is not inconsistency-tolerant, and that belief revision has
not (again, to the best of our knowledge) been investigated in that formalism or others of its
kind.

1.3 Application to the cyber-attribution problem
Cyber-attribution — the problem of determining who was responsible for a given cyberoperation, be it an incident of attack, reconnaissance, or information theft [39] — is an
important issue. The difficulty of this problem stems not only from the amount of effort
required to find forensic clues, but also the ease with which an attacker can plant false
clues to mislead security personnel. Further, while techniques such as forensics and reverseengineering [2], source tracking [47], honeypots [44], and sinkholing [37] are commonly
employed to find evidence that can lead to attribution, it is unclear how this evidence is
to be combined and reasoned about. In some cases, such evidence is augmented with normal intelligence collection, such as human intelligence (HUMINT), signals intelligence

2 Krause et al. [26], which pre-dates [19], dealt with combining structured argumentation with abstract
uncertainty measures and did not explicitly handle probability.

264

P. Shakarian et al.

(SIGINT) and other means — this adds additional complications to the task of attributing a
given operation.
In essence, cyber-attribution is a highly-technical intelligence analysis problem where
an analyst must consider a variety of sources, each with its associated level of confidence,
to provide a decision maker (e.g., a system administrator or Chief Information Officer)
with insight into who conducted a given operation. Indeed, while previous cyber-attribution
approaches only consider a single source of information, our approach takes into account
multiple sources of information due to its ability to deal with inconsistency. As it is wellknown that people’s ability to conduct intelligence analysis is limited [22], and due to the
highly technical nature of many cyber evidence-gathering techniques, an automated reasoning system would be best suited for the task. Such a system must be able to accomplish
several goals:
–
–
–
–
–

Reason about evidence in a formal, principled manner, i.e., relying on strong computational and mathematical foundations.
Consider evidence for cyber attribution associated with some level of uncertainty
(expressed via probabilities).
Consider logical rules that allow for the system to draw conclusions based on certain
pieces of evidence and iteratively apply such rules.
Consider pieces of information that may not be compatible with each other, decide
which information is most relevant, and express why.
Attribute a given cyber-operation based on the above-described features and provide
the analyst with the ability to understand how the system arrived at that conclusion.

The fit between these requirements and the abilities of DeLP3E led us to develop an
extended example based around cyber-attribution3 as a way of showcasing the functionality
of DeLP3E. This example is given in Section 5.

1.4 Contribution of the paper
The main contribution of this paper is to present the DeLP3E framework, which combines structured argumentation and probability, and to discuss in detail how to perform
belief revision in the context of this model. To our knowledge, this is the first paper
to address the combination of structured probabilistic argumentation and belief revision. The paper brings together and extends the results of two papers that discussed
structured probabilistic argumentation in respect to its application in cyber security —
[40], which introduced the DeLP3E formalism (referred to there as P-PreDeLP) and
annotation-function based belief revision, and [41], which studied a special case of the
entailment query and showed how the framework can be applied to a cyber-attribution
problem. Neither of these works include the more general entailment queries covered
here in Section 3.3, the discussion of determining consistency from Section 4.1, or
the AM-based belief revision introduced in Section 4.3. Further, this work includes
complete proofs for all major theoretical results, as well as enhanced and expanded
examples.

3 The

causality is a little more complicated than this sentence suggests. Indeed the cyber-attribution problem
was the original motivation for the development of DeLP3E, and elements of the example evolved along with
the formalism.

Belief revision in structured probabilistic argumentation

265

1.5 Structure of the paper
The structure of the paper broadly follows the three requirements identified above. First,
in Section 2 we introduce the environmental and analytical model described above, where
the environmental model makes use of Nilsson’s probabilistic logic [32] and the analytical
model builds upon PreDeLP [30]. The resulting framework is a general-purpose probabilistic argumentation language DeLP3E, which stands for Defeasible Logic Programming with
Presumptions and Probabilistic Environment. This is formally laid out in Section 3. That
section also studies the entailment problem for DeLP3E. Section 4 then provides the meat of
the paper, discussing belief revision for the environmental model, the analytical model and
the annotation function focusing on the study of non-prioritized belief revision operations.
The paper suggests two sets of rationality postulates characterizing how such operations
should behave, one for the analytical model and one for the annotation function (as we
show, revising the environmental model is not sufficient to restore consistency). These postulates are based on the well-known approach proposed in [20] for non-prioritized belief
revision in classical knowledge bases — and studies two classes of operators and their theoretical relationships with the proposed postulates, concluding with representation theorems
for each class. Section 5 then walks through an extended example of the use of DeLP3E in
the context of cyber-attribution. Section 6 concludes.

2 Preliminaries
This section presents the main componenets of the DeLP3E framework, the environmental
model and the analytical model.

2.1 Basic language
We assume sets of variables and constants, denoted with V and C, respectively. In the rest
of this paper, we will follow the convention from the logic programming literature and
use capital letters to represent variables (e.g., X, Y, Z) and lowercase letters to represent
constants.
The next component of the language is a set of predicate symbols. Each predicate symbol
has an arity bounded by a constant value; the EM and AM use separate sets of predicate symbols, denoted with PEM , PAM , respectively — the two models can, however, share variables
and constants.
As usual, a term is composed of either a variable or a constant. Given terms t1 , ..., tn and
n-ary predicate symbol p, p(t1 , ..., tn ) is called an atom; if t1 , ..., tn are constants, then the
atom is said to be ground. The sets of all ground atoms for the EM and AM are denoted
with GEM and GAM , respectively.
Given a set of ground atoms, a world is any subset of atoms — those that belong to the
set are said to be true in the world, while those that do not are false. Therefore, there are
2|GEM | possible worlds in the EM and 2|GAM | worlds in the AM; these sets are denoted with
WEM and WAM , respectively. In order to avoid worlds that do not model possible situations
given a particular domain, we include integrity constraints of the form oneOf(A ), where
A is a subset of ground atoms. Intuitively, such a constraint states that any world where
more than one of the atoms from set A appears is invalid. We use ICEM and ICAM to denote
the sets of integrity constraints for the EM and AM, respectively, and the sets of worlds that
conform to these constraints is denoted with WEM (ICEM ) and WAM (ICAM ), respectively.

266

P. Shakarian et al.

Finally, logical formulas arise from the combination of atoms using the traditional connectives (∧, ∨, and ¬). As usual, we say that a world w satisfies formula f , written w |= f ,
iff: (i) If f is an atom, then w |= f iff f ∈ w; (ii) if f = ¬f  then w |= f iff w  |= f  ;
(iii) if f = f  ∧ θ  then w |= f iff w |= f  and w |= θ  ; and (iv) if f = f  ∨ θ  then
w |= f iff w |= f  or w |= θ  . We use the notation formEM , formAM to denote the set of
all possible (ground) formulas in the EM and AM, respectively.
Example 1 Thus, the following are terms
a b c d e f
g h i j k
and the following are formulae using those terms:

p(X)
p(a)

a d ∧e
k
b f ∧g∧h
c i ∨ ¬j

2.2 Environmental model
The EM is used to describe the probabilistic knowledge that we have about the domain. In
general, the EM contains knowledge such as evidence, uncertain facts, or knowledge about
agents and systems. Here we base the EM on the probabilistic logic of [32], which we now
briefly review.
Definition 1 Let f be a formula over PEM , V, and C, p ∈ [0, 1], and  ∈ [0, min(p, 1−p)].
A probabilistic formula is of the form f : p ± . A set KEM of probabilistic formulas is
called a probabilistic knowledge base.
In the above definition, the number  is referred to as an error tolerance. Intuitively, the
probabilistic formula f : p ±  is interpreted as “formula f is true with probability between
p − and p +”. Note that there are no further constraints over this interval apart from those
imposed by other probabilistic formulas in the knowledge base. The uncertainty regarding
the probability values stems from the fact that certain assumptions (such as probabilistic
independence between all formulae) may not hold in the environment being modeled.
Example 2 Consider the following set KEM :
f1 = a : 0.8 ± 0.1
f2 = b : 0.2 ± 0.1
f3 = c : 0.8 ± 0.1

f4 = d ∧ e
: 0.7 ± 0.2
f5 = f ∧ g ∧ h : 0.6 ± 0.1
f6 = i ∨ ¬j
: 0.9 ± 0.1

f7 = k : 1 ± 0
f8 = a ∧ b : 0.4 ± 0.1


= {f1 , f2 , f3 }
Throughout the paper, we also use KEM

A set of probabilistic formulas describes a set of possible probability distributions Pr over
the set WEM (ICEM ). We say that probability distribution Pr satisfies probabilistic formula
f : p ±  iff:

Pr (w) ≤ p + .
p− ≤
w∈WEM (ICEM ),w|=f

A probability distribution over WEM (ICEM ) satisfies KEM iff it satisfies all probabilistic
formulas in KEM .

Belief revision in structured probabilistic argumentation

267

Given a probabilistic knowledge base and a (non-probabilistic) formula q, the maximum
entailment problem seeks to identify real numbers p,  such that all valid probability distributions Pr that satisfy KEM also satisfy q : p ± , and there does not exist p  ,   s.t.
[p − , p + ] ⊃ [p −   , p  +   ], where all probability distributions Pr that satisfy KEM
also satisfy q : p  ±   . In order to solve this problem we must solve the linear program
defined below.
Definition 2 Given a knowledge base KEM and a formula q, we have a variable xi for each
wi ∈ WEM (ICEM ). Each variable xi corresponds with the probability of wi occurring.
–
–
–

For each fj : p
j ± j ∈ KEM , there is a constraint of the form:
pj − j ≤ wi ∈WEM (ICEM ) s.t. wi |=fj xi ≤ pj + j .

We also have the constraint: wi ∈WEM (ICEM
) xi = 1.
The objective is to minimize the function: wi ∈WEM (ICEM ) s.t. wi |=q xi .

We use the notation EP-LP-MIN(KEM , q) to refer to the value of the objective function in
the solution to the EM-LP-MIN constraints.
The next step is to solve the linear program a second time, but this time maximizing the
objective function (we shall refer to this as EM-LP-MAX) — let  and u be the results of
these operations, respectively. In [32], it is shown that:
u−
and p =  + 
2
is the solution to the maximum entailment problem. We note that although the above linear
program has an exponential number of variables in the worst case (i.e., no integrity constraints), the presence of constraints has the potential to greatly reduce this space. Further,
there are also good heuristics (cf. [25, 42]) that have been shown to provide highly accurate
approximations with a reduced-size linear program.
=


from Example 2 and a set of ground atoms restricted to those
Example 3 Consider KB KEM
that appear in that program; we have the following worlds:

w1 = {a, b, c} w2 = {a, b} w3 = {a, c} w4 = {b, c}
w6 = {a}
w7 = {c}
w8 = ∅
w5 = {b}
and suppose we wish to compute the probability for formula q = a ∨ c.
For each formula in KEM we have a constraint, and for each world above we have
a variable. An objective function is created based on the worlds that satisfy the query
 , q) and
formula (in this case, worlds w1 , w2 , w3 , w4 , w6 , w7 ). Solving EP-LP-MAX(KEM


EP-LP-MIN(KEM , q), we obtain the solution 0.9 ± 0.1. Hence, EP-LP-MAX(KEM , q) can be
written as follows:
max

x 1 + x2 + x3 + x4 + x6 + x7

w.r.t. :

0.7 ≤

x1 + x2 + x3 + x6

≤ 0.9

0.1 ≤

x1 + x2 + x4 + x5

≤ 0.3

0.8 ≤

x1 + x3 + x4 + x7

≤1

x1 + x 2 + x 3 + x 4 + x 5 + x 6 + x 7 + x 8 = 1
 , q) and, after an easy modification, EP-LPFrom this, we can solve EP-LP-MAX(KEM

MIN (KEM , q), and obtain the solution 0.9 ± 0.1.

268

P. Shakarian et al.

2.3 Analytical model
The analytical model contains information that a user may conclude based on the information in the environmental model. While the EM contains information that can have
probabilities associated with it, statements in the AM can be either true or false depending
on a certain combination (or several possible combinations) of statements from the EM.
For the AM, we choose to represent information using a structured argumentation framework [34] since this kind of formalism meets the representational requirements discussed in
the introduction. Unlike the EM, which describes probabilistic information about the state
of the real world, the AM must allow for competing ideas. Therefore, it must be able to represent contradictory information. The algorithmic approach we shall later describe allows
for the creation of arguments based on the AM that may “compete” with each other to
answer a given query. In this competition — known as a dialectical process — one argument may defeat another based on a comparison criterion that determines the prevailing
argument. Resulting from this process, certain arguments are warranted (those that are not
defeated by other arguments), thereby providing a suitable explanation for the answer to a
given query.
The transparency provided by the system can allow knowledge engineers and users of
the system to identify potentially incorrect input information and fine-tune the models or,
alternatively, collect more information. In short, argumentation-based reasoning has been
studied as a natural way to manage a set of inconsistent information — it is the way humans
settle disputes. As we will see, another desirable characteristic of (structured) argumentation
frameworks is that, once a conclusion is reached, we are left with an explanation of how we
arrived at it and information about why a given argument is warranted; this is very important
information for users to have.
The formal model that we use for the AM is Defeasible Logic Programming with Presumptions (PreDeLP) [30], a formalism combining logic programming with defeasible
argumentation. Here, we briefly recall the basics of PreDeLP— we refer the reader to [15,
30] for the complete presentation. Formally, we use the notation
AM = (Θ, Ω, Φ, Δ)
to denote a PreDeLP program, where Ω is a set of strict rules, Θ is a set of facts, Δ is a set
of defeasible rules, and Φ is a set of presumptions. We now define these constructs formally.

Facts (Θ) are ground literals representing atomic information or its negation, using strong
negation “¬”. Note that all of the literals in our framework must be formed with a predicate
from the set PAM . Note that information in the form of facts cannot be contradicted. We will
use the notation [Θ] to denote the set of all possible facts.

Strict rules (Ω) represent non-defeasible cause-and-effect information that resembles an
implication (though the semantics is different since the contrapositive does not hold) and are
of the form L0 ← L1 , . . . , Ln , where L0 is a ground literal and {Li }i>0 is a set of ground
literals. We will use the notation [Ω] to denote the set of all possible strict rules.

Presumptions (Φ) are ground literals of the same form as facts, except that they are not
taken as being true but rather are defeasible, which means that they can be contradicted.
Presumptions are denoted in the same manner as facts, except that the symbol –≺ is added.
We note that the presumptions cannot be treated as special cases of the defeasible rules. The

Belief revision in structured probabilistic argumentation

269

intuition of the presumption is that outside of other criteria, arguments with more presumptions should be defeated by arguments with less presumption which is not necessarily the
case if the presumption is expressed as a defeasible rule. As shown in [30] the treatment of
presumptions in this manner also necessitates an extension to generalized specificity. See
[30] for further details.

Defeasible rules (Δ) represent tentative knowledge that can be used if nothing can be
posed against it. Just as presumptions are the defeasible counterpart of facts, defeasible rules
are the defeasible counterpart of strict rules. They are of the form L0 –≺ L1 , . . . , Ln , where
L0 is a ground literal and {Li }i>0 is a set of ground literals. In both strict and defeasible
rules, strong negation is allowed in the head of rules, and hence may be used to represent
contradictory knowledge.
Even though the above constructs are ground, we allow for schematic versions with
variables that are used to represent sets of ground rules. In Fig. 1, we provide an example
AM of a ground knowledge base. (Fig. 7 on Page 42 gives an example of a non-ground
knowledge base.)

Arguments Given a query in the form of a ground atom, the goal is to derive arguments
for and against its validity — derivation follows the mechanism of logic programming [29].
Since rule heads can contain strong negation, it is possible to defeasibly derive contradictory
literals from a program. For the treatment of contradictory knowledge, PreDeLP incorporates a defeasible argumentation formalism that allows the identification of the pieces of
knowledge that are in conflict and, through the previously mentioned dialectical process,
decides which information prevails as warranted. This dialectical process involves the construction and evaluation of arguments, building a dialectical tree in the process. Arguments
are formally defined next.
Definition 3 An argument A, L
 for a literal L is a pair of the literal and a (possibly
empty) set of the AM (A ⊆ AM ) that provides a minimal proof for L meeting the following
requirements: (i) L is defeasibly derived from A; (ii) Ω ∪ Θ ∪ A is not contradictory; and
(iii) A is a minimal subset of Δ ∪ Φ.
Literal L is called the conclusion supported by the argument, and A is the support of the
argument. An argument B , L
 is a subargument of A, L 
 iff B ⊆ A. An argument A, L
is presumptive iff A ∩ Φ is not empty. We will also use Ω(A) = A ∩ Ω, Θ(A) = A ∩ Θ,

Fig. 1 A ground argumentation framework

270

P. Shakarian et al.

Δ(A) = A ∩Δ, and Φ(A) = A ∩Φ. For convenience, we may sometimes call an argument
by its support. (e.g. argument A instead of argument A, L
.
Our definition differs slightly from that of [43], where DeLP is introduced, as we include
strict rules and facts as part of arguments — this is due to the fact that in our framework, the
components of an argument can only be used in certain environmental conditions. Hence, a
fact may be true in one EM world and not another, and so different sets of strict rules and
facts may be applicable to different arguments. This is in contrast to DeLP when the same
set of strict rules and facts can be applied to any argument and so do not have to be explicitly
listed.. We discuss this further in Section 3 (page 16).
Definition 4 A literal is derived from an argument if it appears as a fact or a presumption in
the argument or appears in the head of a strict rule or a defeasible rule where all the literals
in the body of that strict rule or defeasible rule are derived from that argument.
Example 4 Figure 2 shows example arguments based on the knowledge base from Fig. 1.
Note that A5 , u
 is a sub-argument of A2 , s
 and A3 , s
.
Given an argument A1 , L1 
, counter-arguments are arguments that contradict it. Argument A2 , L2 
 is said to counterargue or attack A1 , L1 
 at a literal L iff there exists a
subargument A, L 
 of A1 , L1 
 such that the set Ω(A1 ) ∪ Ω(A2 ) ∪ Θ(A1 ) ∪ Θ(A2 ) is
inconsistent.
Example 5 Consider the arguments from Example 4. The following are some of the attack
relationships between them: A1 , A2 , A3 , and A4 all attack A6 ; A5 attacks A7 ; and A7
attacks A2 .
A proper defeater of an argument A, L
 is a counter-argument that — by some criterion
— is considered to be better than A, L
; if the two are incomparable according to this criterion, the counterargument is said to be a blocking defeater. An important characteristic of
PreDeLP is that the argument comparison criterion is modular, and thus the most appropriate criterion for the domain that is being represented can be selected; the default criterion
used in classical defeasible logic programming (from which PreDeLP is derived) is generalized specificity [45], though an extension of this criterion is required for arguments using
presumptions [30]. We briefly recall this criterion next — the first definition is for generalized specificity, which is subsequently used in the definition of presumption-enabled
specificity.
Definition 5 (Generalized Specificity) Let AM = (Θ, Ω, Φ, Δ) be a PreDeLP program and let F be the set of all literals that have a defeasible derivation from AM . An

Fig. 2 Example ground arguments from the framework of Fig. 1

Belief revision in structured probabilistic argumentation

271

argument A1 , L1 
 is preferred to A2 , L2 
, denoted with A1 P S A2 iff the two following
conditions hold:
(1)

(2)

For all H ⊆ F , Ω ∪ H is non-contradictory: if there is a derivation for L1 from
Ω ∪ H ∪ DR(A1 ), and there is no derivation for L1 from Ω ∪ H , then there is a
derivation for L2 from Ω ∪ H ∪ DR(A2 ).
There is at least one set H  ⊆ F , Ω ∪ H  is non-contradictory, such that there is a
derivation for L2 from Ω ∪ H  ∪ DR(A2 ), there is no derivation for L2 from Ω ∪ H  ,
and there is no derivation for L1 from Ω ∪ H ∪ DR(A1 ).

Intuitively, the principle of specificity says that, in the presence of two conflicting lines
of argument about a proposition, the one that uses more of the available information is more
convincing. Considering the Tweety example again; there are arguments stating both that
Tweety flies (because it is a bird) and that Tweety doesn’t fly (because it is a penguin).
The latter argument uses more information about Tweety — it is more specific because it is
information that Tweety is not just a bird, but is a penguin-bird, the subset of birds that are
penguins — and is thus the stronger of the two.
Definition 6 (Presumption-enabled Specificity [30]) Given PreDeLP program AM =
(Θ, Ω, Φ, Δ), an argument A1 , L1 
 is preferred to A2 , L2 
, denoted with A1  A2 iff
any of the following conditions hold:
(1)
(2)
(3)

A1 , L1 
 and A2 , L2 
 are both factual, which is an argument using none of the
presumptions or defeasible rules and A1 , L1 
 P S A2 , L2 
.
A1 , L1 
 is a factual argument and A2 , L2 
 is a presumptive argument, which is an
argument using at least one of the presumptions or defeasible rules.
A1 , L1 
 and A2 , L2 
 are presumptive arguments, and
(a)
(b)

Φ(A1 ) ⊂ Φ(A2 ) or,
Φ(A1 ) = Φ(A2 ) and A1 , L1 
 P S A2 , L2 
.

Generally, if A and B are arguments with rules X and Y , respectively and X ⊂ Y , then
A is stronger than B . This also holds when A and B use presumptions P1 and P2 , resp., and
P1 ⊂ P2 .
Example 6 The following are some relationships between arguments from Example 4,
based on Definitions 5 and 6.

A1 and A6 are incomparable (blocking defeaters);
A6  A2 , and thus A6 defeats A2 ;
A5 and A7 are incomparable (blocking defeaters).
A sequence of arguments called an argumentation line thus arises from this attack relation, where each argument defeats its predecessor. To avoid undesirable sequences, which
may represent circular argumentation lines, in D E LP an argumentation line is acceptable
if it satisfies certain constraints (see below). A literal L is warranted if there exists a
non-defeated argument A supporting L.
Definition 7 ([15]) Let AM = (Θ, Ω, Φ, Δ) be a PreDeLP program. Two arguments
A1 , L1 
 and A2 , L2 
 are concordant iff the set Θ ∪ Ω ∪ A1 ∪ A2 is non-contradictory.

272

P. Shakarian et al.

Definition 8 ([15]) Let Λ be an argumentation line. Λ is an acceptable argumentation line
iff:
(1)
(2)
(3)
(4)

Λ is a finite sequence.
The set ΛS , of supporting arguments is concordant, and the set ΛI of interfering
arguments is concordant.
No argument Ak , Lk 
 in Λ is a subargument of an argument Ai , Li 
 appearing
earlier in Λ (i < k)
For all i, such that the argument Ai , Ki 
 is a blocking defeater for Ai−1 , Ki−1 
, if
Ai+1 , Ki+1 
 exists, then Ai+1 , Ki+1 
 is a proper defeater for Ai , Ki 
.

Clearly, there can be more than one defeater for a particular argument A, L
. Therefore,
many acceptable argumentation lines could arise from A, L
, leading to a tree structure.
The tree is built from the set of all argumentation lines rooted in the initial argument. In a
dialectical tree, every node (except the root) represents a defeater of its parent, and leaves
correspond to undefeated arguments. Each path from the root to a leaf corresponds to a different acceptable argumentation line. A dialectical tree provides a structure for considering
all the possible acceptable argumentation lines that can be generated for deciding whether
an argument is defeated. This tree is called dialectical because it represents an exhaustive
dialectical4 analysis for the argument in its root. For a given argument A, L
, we denote
the corresponding dialectical tree as T (A, L
).
Given a literal L and an argument A, L
, in order to decide whether or not a literal L is warranted, every node in the dialectical tree T (A, L
) is recursively marked
as “D” (defeated) or “U” (undefeated), obtaining a marked dialectical tree T ∗ (A, L
) as
follows:
1.
2.

All leaves in T ∗ (A, L
) are marked as “U”s, and
Let B , q
 be an inner node of T ∗ (A, L
). Then B , q
 will be marked as “U” iff every
child of B , q
 is marked as “D”. The node B , q
 will be marked as “D” iff it has at
least a child marked as “U”.

Given an argument A, L
 obtained from AM , if the root of T ∗ (A, L
) is marked as
“U”, then we will say that T ∗ (A, h
) warrants L and that L is warranted from AM . (Warranted arguments correspond to those in the grounded extension of a Dung argumentation
system [7].) There is a further requirement when the arguments in the dialectical tree contain presumptions — the conjunction of all presumptions used in even levels of the tree must
be consistent. This can give rise to multiple trees for a given literal, as there can potentially
be different arguments that make contradictory assumptions.
We can then extend the idea of a dialectical tree to a dialectical forest. For a given literal
L, a dialectical forest F (L) consists of the set of dialectical trees for all arguments for L. We
shall denote a marked dialectical forest, the set of all marked dialectical trees for arguments
for L, as F ∗ (L). Hence, for a literal L, we say it is warranted if there is at least one argument
for that literal in the dialectical forest F ∗ (L) that is labeled as “U”, not warranted if there
is at least one argument for the literal ¬L in the dialectical forest F ∗ (¬L) that is labeled as
“U”, and undecided otherwise.
With this, we have a complete description of the analytical model, and can go on to
describe the DeLP3E framework.

4 In

the sense of providing reasons for and against a position.

Belief revision in structured probabilistic argumentation

273

3 The DeLP3E framework
DeLP3E arises from the combination of the environmental model EM , and the analytical model AM ; the two models are held together by the annotation function. This allows
elements from the AM to be annotated with elements from the EM. These annotations
specify the conditions under which the various statements in the AM can potentially be
true.

3.1 Definition
Intuitively, given AM , every element of Ω ∪ Θ ∪ Δ ∪ Φ might only hold in certain worlds
in the set WEM — that is, they are subject to probabilistic events. Therefore, we associate
elements of Ω ∪ Θ ∪ Δ ∪ Φ with a formula from formEM . In doing so, we can in turn
compute the probabilities of subsets of Ω ∪ Θ ∪ Δ ∪ Φ using the information contained in
EM , as we describe shortly. The notion of an annotation function associates elements of
Ω ∪ Θ ∪ Δ ∪ Φ with elements of formEM .
Definition 9 An annotation function is any function af : Ω ∪ Θ ∪ Δ ∪ Φ → formEM . We
use [af ] to denote the set of all annotation functions.
Figure 3 shows an example of an annotation function.
We will sometimes denote annotation functions as sets of pairs (f, af(f )) in order to
simplify the presentation. Function af may come from an expert’s knowledge or the data
itself. Choosing the correct function and learning the function from data is the topic of
ongoing work.
We also note that, by using the annotation function, we may have certain statements that
appear as both facts and presumptions (likewise for strict and defeasible rules). However,
these constructs would have different annotations, and thus be applicable in different worlds.
We note that the annotation function can allow AM facts and strict rules to be true in some
EM worlds and false in others – this is why we include facts and strict rules as part of an
argument in our framework.
Example 7 Suppose we added the following presumptions to our running example:
φ3 = l

–≺

φ4 = m –≺
and suppose we extend af as follows:
af (φ3 ) = a ∧ b
af (φ4 ) = a ∧ b ∧ c

Fig. 3 Example annotation function

274

P. Shakarian et al.

So, for instance, unlike θ1 , φ3 can potentially be true in any world of the form:
{a, b}
We now have all the components to formally define a DeLP3E program.
Definition 10 Given environmental model EM , analytical model AM , and annotation
function af , a DeLP3E program is of the form I = (EM , AM , af ). We use notation [I ]
to denote the set of all possible programs.
The next step in the definition of DeLP3E is to explore entailment operations. In an
entailment query, we are given an AM literal L, probability interval p ± , and DeLP3E
program I , and we wish to determine if L is entailed by I with a probability p±. However,
before we can formally define this entailment problem, we define a warranting scenario to
determine the proper environment in question and the entailment bounds (Section 3.2). This
is followed by our formal definition and method for computing entailment in Section 3.3.

3.2 Warranting scenario
In DeLP3E, we can consider a world-based approach; that is, the defeat relationship among
arguments depends on the current state of the (EM) world.
Definition 11 Let I = (EM , AM , af ) be a DeLP3E program, argument A, L
 is valid
w.r.t. world w ∈ WEM iff ∀c ∈ A, w |= af(c).
We extend the notion of validity to argumentation lines, dialectical trees, and dialectical
forests in the expected way (for instance, an argumentation line is valid w.r.t. w iff all
arguments that comprise that line are valid w.r.t. w).
Example 8 Consider worlds w1 , . . . , w8 from Example 3 along with the argument A5 , u
from Example 4. This argument is valid in worlds w1 , w2 , w3 , w4 , w6 , and w7 .
We also extend the idea of a dialectical tree w.r.t. worlds; so, for a given world w ∈ WEM ,
the dialectical (resp., marked dialectical) tree induced by w is denoted with Tw A, L
 (resp.,
Tw∗ A, L
). We require that all arguments and defeaters in these trees be valid with respect
to w. Likewise, we extend the notion of dialectical forests in the same manner (denoted with
Fw (L) and Fw∗ (L), resp.). Based on these concepts, we introduce the notion of warranting
scenario.
Definition 12 Let I = (EM , AM , af ) be a DeLP3E program and L be a literal formed
with a ground atom from GAM ; a world w ∈ WEM is said to be a warranting scenario for
L (denoted w war L) iff there is a dialectical forest Fw∗ (L) in which L is warranted and
Fw∗ (L) is valid w.r.t. w.
We note that for a world w not being a warranting scenario for L, is not the same as
being a warranting scenario for ¬L. For that we need a dialectical tree Fw∗ (L ) in which L
is warranted and Fw∗ (L ) is valid w.r.t w where L = ¬L
Example 9 Considering the arguments from Example 8, worlds w3 , w6 , and w7 are
warranting scenarios for argument A5 , u
.

Belief revision in structured probabilistic argumentation

275

3.3 Entailment in DeLP3E
In this section, we use the idea of a warranting scenario to formally define our entailment problem. We first notice that the set of worlds in the EM where a literal L in the
AM must be true is exactly the set of warranting scenarios — these are the “necessary”
worlds:
nec(L) = {w ∈ WEM | (w war L)}.
Now, the set of worlds in the EM where AM literal L can be true is the following —
these are the “possible” worlds:
poss(L) = {w ∈ WEM | w war ¬L}.
Example 10 Following from Example 8, we have that:
nec(u) = {w3 , w6 , w7 } and poss(u) = {w1 , w2 , w3 , w4 , w6 , w7 }.


Definition 13 We define for(w) = a∈w a ∧ a ∈w
/ ¬a, which denotes the formula
 that has
w as its only model. Also, we extend this notation to sets of words: for(W ) = w∈W for
(w).
Definition 14 (Entailment) Given DeLP3E program, I = (EM , AM , af ), AM literal L
and probability interval p±, we say that I entails L with probability p± iff all probability
distributions Pr that satisfy EM satisfy for(nec(L)) : p ±  and for(poss(L)) : p ± .
We will also refer to the tightest bound [p − , p + ] such that I entails L with a
probability p ±  as the “tightest entailment bounds.” The intuition behind the above definition of entailment is as follows. Let  be the maximum value for p −  and u be the
minimum value for p +  before we can no longer say that I entails L with probability
+
−
+
p ± . In this case, we can define probability distributions Pr −
poss , Pr poss , Pr nec , Pr nec as
follows:
–

Pr −
poss satisfies EM and assigns the smallest possible probability to worlds in for

–

Pr +
poss satisfies EM and assigns the largest possible probability to worlds in for

(poss(L)).

–
–

(poss(L)).
Pr −
nec satisfies EM and assigns the smallest possible probability to worlds in for
(nec(L)).
Pr +
nec satisfies EM and assigns the largest possible probability to worlds for(nec(L)).

−
We only need to compare Pr −
poss (poss(L)) and Pr nec (nec(L)) for finding the lower bound
−
+
−
since Pr +
poss (poss(L)) ≥ Pr poss (poss(L)) and Pr nec (nec(L)) ≥ Pr nec (nec(L)). Similar reasoning holds for the case of finding the upper bound. Thus, we get the following
relationships:



−
 = min Pr −
poss (poss(L)), Pr nec (nec(L))


+
u = max Pr +
poss (poss(L)), Pr nec (nec(L))

(1)
(2)

276

P. Shakarian et al.

However, we note that as nec(L) ⊆ poss(L) we have the following:
 = Pr −
nec (nec(L))

(3)

u = Pr +
poss (poss(L))

(4)

We note that (2) and (4) is equivalent to the belief and plausibility values of L defined in
the Dempster-Shafer theory [38].
Hence, the tightest possible entailment bounds that can be assigned to a literal can be no
less than the lower bound of the probability assigned to the necessary warranting scenarios
and no more than the probability assigned to the possible warranting scenarios. Hence, we
can compute the tightest probability bound such that L is entailed (denoted PL,Pr ,I ) as
follows:


L,Pr ,I =
Pr −
uL,Pr ,I =
Pr +
nec(w) ,
poss(w)
w∈nec(L)

w∈poss(L)

L,Pr ,I ≤ PL,Pr ,I ≤ uL,Pr ,I
Thus, in interval form we have:
	

uL,Pr ,I − L,Pr ,I
uL,Pr ,I − L,Pr ,I
±
.
PL,Pr ,I = L,Pr ,I +
2
2
Now let us consider the computation of tightest probability bounds for entailment on
a literal when we are given a knowledge base KEM in the environmental model, which
is specified in I , instead of
a probability


 
 distribution
 over all worlds. For a given world
w ∈ WEM , let for(w) =
a∈w a ∧
a ∈w
/ ¬a — that is, a formula that is satisfied
only by world w. Now we can determine the upper and lower bounds on the probability of
a literal w.r.t. KEM (denoted PL,I ) as follows:
⎞
⎛

L,I = EP-LP-MIN ⎝KEM ,
for(w)⎠
w∈nec(L)

⎛



uL,I = EP-LP-MAX ⎝KEM ,

⎞
for(w)⎠

w∈poss(L)



Hence, PL,I = L,KEM

L,I ≤ PL,I ≤ uL,I

u
−
u
−
+ L,I 2 L,I ± L,I 2 L,I .

Example 11 Consider argument A5 , u
 from Example 8. We can compute Pu,I (where
I = (EM , AM , af )).
Note that for the upper bound, the linear program we need to set up is the one shown in
Example 3. For the lower bound, the objective function changes to: min x3 + x6 + x7 . From
these linear constraints, we obtain:
Pu = 0.7 ± 0.2

In the following, we study the problem of consistency in our framework, which is the
basis of the belief revision operators studied later on.

Belief revision in structured probabilistic argumentation

277

4 Belief revision in DeLP3E programs
Even though our framework relies heavily on argumentation and reasoning under uncertainty, inconsistency in our knowledge base can still arise. For instance, the knowledge
encoded in the environmental model could become contradictory, which would preclude any
probability distribution from satisfying that part of the knowledge base. Even on the argumentation side, despite that fact that argumentation formalisms in general are inconsistency
tolerant, there may be problems with inconsistency. For example, it would be problematic for DeLP3E if the set of strict facts and strict rules were contradictory, and the set of
contradictory elements all arise under the same environmental conditions.

4.1 Consistency of DeLP3E programs
In this section, we first explore what forms of inconsistency can arise in DeLP3E programs
before going on to examine in detail how ideas from belief revision can be applied to deal
with this inconsistency. We use the following notion of (classical) consistency of PreDeLP
programs:  is said to be consistent if there does not exist a ground literal a s.t.   a
and   ¬a. For DeLP3E programs, there are two main kinds of inconsistency that can be
present; the first is what we refer to as EM, or Type I, (in)consistency.
Definition 15 An environmental model EM is Type I consistent iff there exists a
probability distribution Pr over the set of worlds WEM that satisfies EM .
We illustrate this type of consistency in the following example.
Example 12 It is possible to create probabilistic knowledge bases for which there is no
satisfying probability distribution. The following formula is a simple example of such a
case:
rain ∨ hail : 0.3 ± 0;
rain ∧ hail : 0.5 ± 0.1.
The above is an example of Type I inconsistency in DeLP3E, as it arises from the fact that
there is no satisfying interpretation for the EM knowledge base.
However, even if the EM is consistent, the interaction between the annotation function
and facts and strict rules can still cause another type of inconsistency to arise. We will refer
to this as combined, or Type II, (in)consistency.
Definition 16 A DeLP3E program I = (EM , AM , af ), with AM = Θ, Ω, Φ, Δ
,
is Type II consistent iff: given any probability
distribution Pr that satisfies EM , if there

exists a world w ∈ WEM such that x∈Θ∪Ω | w|=af(x) {x} is inconsistent, then we have
Pr (w) = 0.
Thus, any EM world in which the set of associated facts and strict rules are inconsistent
(we refer to this as “classical consistency”) must always be assigned a zero probability. The
intuition is as follows: any subset of facts and strict rules are thought to be true under certain
circumstances — these circumstances are determined through the annotation function and
can be expressed as sets of EM worlds. Suppose there is a world where two contradictory
facts can both be considered to be true (based on the annotation function). If this occurs, then

278

P. Shakarian et al.

there must not exist a probability distribution that satisfies the program EM that assigns
such a world a non-zero probability, as this world leads to an inconsistency. We provide a
more concrete example of Type II inconsistency next.
Example 13 Consider the environmental model from Example 2 (Page 8), the analytical
model shown in Fig. 1 (Page 10), and the annotation function shown in Figure 3 (Page 15).
Suppose the following fact is added to the argumentation model:
θ3 = ¬p,
and that the annotation function is expanded as follows:
af (θ3 ) = k ∧ ¬f
Clearly, fact θ3 is in direct conflict with fact θ1a . However, this does not necessarily mean
that there is an inconsistency. For instance, by the annotation function, θ1a holds in the
world {k, f } while θ3 does not. However, let’s consider following world w = {k}. Note
that w |= af (θ3 ) and w |= af (θ2 ). Hence, in this world both contradictory facts can
occur. However, can this world be assigned a non-zero probability? A simple examination of the environmental model indicates that it can. Hence, in this case, we have Type II
inconsistency.
We say that a DeLP3E program is consistent iff it is both Type I and Type II consistent.
However, in this paper, we focus on Type II consistency and assume that the program is Type
I consistent. Figure 4 gives a straightforward approach to identifying Type II inconsistent
DeLP3E programs by running breath-first search on a set of Θ ∪ Ω. The algorithm works
by examining all subsets of a set of facts and strict rules to find inconsistent subsets whose
corresponding formula in the environmental model can be assigned a non-zero probability.
The following result states its correctness.
Proposition 1 For Type I consistent DeLP3E program I = (EM , AM , af ) where Θ and
Ω are the sets of facts and strict rules in AM , then
CON-CHK-BFS(EM , AM , af , d, {Θ ∪Ω}) (where d = |Θ ∪Ω|) returns INCONSISTENT
iff the DeLP3E is Type II inconsistent.
Proof The algorithm takes the set of facts and strict rules and checks the consistency of
it by checking the value of the probability distribution on the set and the subsets of the
given set. If in any step there exists a subset of facts and strict rules that is not Type I
consistent, the algorithm checks the value of the probability distribution; if it is not zero, it
will return INCONSISTENT. BWOC, suppose the algorithm has returned INCONSISTENT
for a DeLP3E program that is consistent. So, there exist a subset S of size d of facts and

Fig. 4 A straightforward BFS-based algorithm for consistency checking

Belief revision in structured probabilistic argumentation

279

strict rules for which the algorithm has returned INCONSISTENT, while S is consistent.
Because the algorithm has returned INCONSISTENT,
the set S is classically inconsistent.

It also means that  w ∈ WAM s.t. w |= s∈S {s} and ∃ P r s.t. P r(af (s)) > 0. This is
in contradiction with the assumption of consistency of S. For the other direction, consider
a DeLP3E program that is inconsistent.
Since the program is inconsistent, there exists a

world
w
∈
W
such
that
EM
x∈Θ∪Ω | w|=af(x) {x} is inconsistent and Pr (w) > 0. Since

{x}
is
a
subset
of the facts and rules, the algorithm checks its consistency
x∈Θ∪Ω | w|=af(x)
in some iteration. Since the subset is inconsistent and the probability value assigned to it is
greater than zero, the algorithm returns INCONSISTENT.
However, we note that even with an oracle for checking the classical consistency of a
subset (line 2) and for determining the upper bound on the probability of the annotations
(line 2a), this algorithm is still intractable as it explores all subsets of Θ ∪ Ω. One possible
way to attack this intractability is to restrict the depth of the search by setting d to be less
than the size of Θ ∪ Ω. In this case, we get the following result:
Proposition 2 Given Type I consistent DeLP3E program I = (EM , AM , af ), where Θ
and Ω are the sets of facts and strict rules in AM and d < |Θ ∪ Ω|, then if CONCHK-BFS(EM , AM , af , d, {Θ ∪ Ω}) returns INCONSISTENT, the program I is Type II
inconsistent.

Proof Suppose, BWOC that CON-CHK-BFS(EM , AM , af , d, {Θ ∪ Ω}) returns INCONSISTENT, and the program I is Type II consistent. We claim that by showing that,
under the condition of the statement, that if I is Type II consistent, then CON-CHKBFS(EM , AM , af , d, {Θ ∪ Ω}) must return CONSISTENT (giving a contradiction). This
is due to the following: since calling CON-CHK-BFS(EM , AM , af , d, {Θ ∪ Ω} where
d = |Θ ∪ Ω| returns CONSISTENT when the program is consistent, then the algorithm
returns CONSISTENT for every subset of Θ ∪Ω smaller than itself. As a result, CON-CHKBFS(EM , AM , af , d, {Θ ∪ Ω}) (where d < |Θ ∪ Ω|) returns CONSISTENT.
Therefore, by restricting depth, we can view this algorithm as an “anytime” approach,
essentially searching for a world leading to an inconsistent program and not halting until it
does.
In the following sections, we explore three methods for resolving Type II inconsistency
through belief revision. We summarize them briefly below.
Revise the EM. The probabilistic model can be changed in order to force the worlds that
induce contradicting strict knowledge to have probability zero. In general, this type of
revision by itself is not ideal as it will not work in all cases. We discuss this method in
Section 4.2.
Revise the AM. The argumentation model can be changed in such a way that the set of
strict rules and facts is consistent. If this is the case, then Type II consistency follows. We
discuss this method in Section 4.3.
Revise the annotation function. The annotations involved in the inconsistency can be
changed so that the conflicting information in the AM does not become induced under
any possible world. This can be viewed as a generalization of AM revision. We discuss
this method in Section 4.4.

280

P. Shakarian et al.

4.2 EM-based belief revision
We now study belief revision through updating the environmental model only (EM ). Suppose that EM is consistent, but that the overall program is Type II inconsistent. Then, there
must exist a set of worlds in the EM such that there exists a probability distribution that
assigns each of them a non-zero probability. This gives rise to the following result.
Pr that satisfies EM s.t. there exists
Proposition 3 If there exists a probability distribution

a world w ∈ WEM where Pr(w) > 0 and x∈Θ∪Ω | w|=af(x) {x} is inconsistent (Type II
inconsistency), then any change made in 
order
 to resolve
 this inconsistency by modifying

only EM yields a new EM EM such that
a
∧
a∈w
a ∈w
/ ¬a : 0±0 is entailed by EM .






Proof Suppose
a∈w a ∧ a ∈w
/ ¬a : 0 ± 0. By hypothesis,
 by contradiction that EM |=
we have that x∈Θ∪Ω | w|=af(x) {x} is inconsistent and the changes made to EM resolve this
inconsistency. Therefore,
16, Pr (w) = 0, which is equivalent to the

  according

 to Definition
condition EM |=
a
∧
¬a
:
0
±
0.
a∈w
a ∈w
/
Proposition 3 seems to imply an easy strategy to resolve Type II inconsistencies: add
formulas to EM forcing the necessary worlds to have a zero probability. However, this may
lead to Type I inconsistencies in the resulting model EM . If we are applying an EM-only
strategy to resolve inconsistencies, this would then lead to further adjustments to EM in
order to restore Type I consistency. We illustrate this situation in the following example.
Example 14 Consider two contradictory facts in an AM: a and ¬a such that af (a) = p and
af (¬a) = q. Suppose that p and q are the only atoms in the EM, and that we have:
p : 0.4 ± 0
q : 0.8 ± 0.1
¬p ∧ ¬q : 0.2 ± 0.1
which is consistent since the following distribution satisfies all constraints:
Pr ({p}) = 0.2;
Pr ({p, q}) = 0.2;
Pr ({q}) = 0.5;
Pr ({}) = 0.1.

Now, to restore Type II consistency of our simple DeLP3E program, we can add formula
p ∧ q : 0 ± 0 to the EM so that world {p, q} is forced to have probability zero. However, this
leads to another inconsistency, this time of Type I, since putting together all the constraints
we have:
Pr ({p, q}) = 0;
Pr ({p}) + Pr ({p, q}) = 0.4;
Pr ({q}) + Pr ({p, q}) = 0.8 ± 0.1;
Pr ({}) = 0.2 ± 0.1;
Pr ({p}) + Pr ({p, q}) + Pr ({q}) + Pr ({}) = 1;

which is clearly inconsistent. Repairing this inconsistency involves changing the EM further,
for instance by relaxing the bounds in the first two formulas to accommodate the probability
mass that world {p, q} had before and can no longer hold.

Belief revision in structured probabilistic argumentation

281

In the previous example, we saw how changes made to repair Type II inconsistencies
could lead to Type I inconsistencies. It is also possible that changing EM (for instance,
by removing elements, relaxing probability bounds of the sentences, etc.) causes Type II
inconsistency in the overall DeLP3E program — this would lead to the need to set more EM
worlds to a probability of zero. Unfortunately, this process is not guaranteed to arrive at a
fully consistent program before being unable to continue; consider the following example,
where the process cannot even begin.
Example 15 Consider an AM composed of several contradictory facts and an EM with just
two atoms, as in the previous example, and the following annotation function:
af (a) = p
af (¬a) = q

af (b) = ¬p
af (¬b) = ¬q

af (c) = ¬p
af (¬c) = p

af (d) = q
af (¬d) = ¬q

Modifying the EM so that no two contradictory literals ever hold at once in a world that
has a non-zero probability leads to the constraints:
Pr ({p, q}) = 0;
Pr ({p}) = 0;
Pr ({q}) = 0;
Pr ({}) = 0;
Pr ({p}) + Pr ({p, q}) + Pr ({q}) + Pr ({}) = 1;

As in the previous example, the probability mass cannot be accommodated within
these constraints. It would thus be impossible to restore consistency by only modifying
EM .
We thus arrive at the following observation from Example 15:
Observation 1 Given a Type II inconsistent DeLP3E program, consistency cannot always
be restored via modifications to EM alone.
Therefore, due to this line of reasoning, in this paper we focus our efforts on modifications to the other two components of a DeLP3E framework: the AM and the annotation
function, as described in the next two sections. Approaches combining two or more of these
methods are the topic of future work.

4.3 AM-based belief revision
The result of the previous section indicates that EM-based belief revision of a DeLP3E
framework (at least by itself) is not a tenable solution. Hence, in this section, we resort to an
alternate approach in which we only modify the AM (AM ). In this section (and the next),
given a DeLP3E program I = (EM , AM , af ), with AM = Ω ∪ Θ ∪ Δ ∪ Φ, we are
interested in solving the problem of incorporating an epistemic input (f, af  ) into I , where
f is either an atom or a rule and af  is equivalent to af , except for its expansion to include
f . For ease of presentation, we assume that f is to be incorporated as a fact or strict rule, as
incorporating defeasible knowledge can never lead to inconsistency since any contradicting
presumption can be defeated by another, and hence presumptions can rule out each other.
As we are only conducting AM revisions, for I = (EM , AM , af ) and input (f, af  ) we
denote the revision as follows: I • (f, af  ) = (EM , AM , af  ) where AM is the revised

282

P. Shakarian et al.

argumentation model. We also slightly abuse notation for the sake of presentation, as well
as introduce notation to convert sets of worlds to/from formulas:
–
–
–
–

I ∪ (f, af  ) to denote I  = (EM , AM ∪ {f }, af  ).
(f, af  ) ∈ I = (AM , EM , af ) to denote f ∈ AM and af = af  .
0 (I ) = {w ∈ W
I
WEM
EM | AM (w) is inconsistent}
0
I
WEM (I ) = {w ∈ WEM | ∃Pr s.t. Pr |= EM ∧ Pr (w) > 0}

0 (I ) contains all the EM worlds for a given program where the
Intuitively, the set WEM
I (I ) is a subset
corresponding knowledge base in the AM is classically inconsistent and WEM
of these that can be assigned a non-zero probability — the latter are the worlds where
inconsistency in the AM can arise.

4.3.1 Postulates for AM-based belief revision
We now analyze the rationality postulates for non-prioritized revision of belief bases first
introduced in [20] and generalized in [10], in the context of AM-based belief revision of
DeLP3E programs.

AM inclusion For I • (f, af  ) = (EM , AM , af  ), AM ⊆ AM ∪ {f }.
This postulate states that the revised AM knowledge base is a subset of the union of the
original AM knowledge base and the input.

AM vacuity If I ∪ (f, af  ) is consistent, then I • (f, af  ) ⊆ I ∪ (f, af  ).
If simply adding the input does not cause inconsistency, then the revision operator does
precisely that.

AM consistency preservation If I is consistent, then I • (f, af  ) is also consistent.
The operator maintains a consistent program.
AM weak success If I ∪ (f, af  ) is consistent, then (f, af  ) ∈ I • (f, af  ).
Whenever the simple addition of the input does not cause inconsistencies to arise, the result
will contain the input.
If a portion of the AM knowledge base is removed by the operator, then there exists a
subset of the remaining knowledge base that is not consistent with the removed element and
f.

AM pertinence For I • (f, af  ) = (EM , AM , af  ), where AM = Θ  ∪ Ω  ∪ Φ  ∪ Δ ,

for each g ∈ Θ ∪ Ω \ AM there exists Yg ⊇ Θ  ∪ Ω  ∪ {f } s.t. Yg is consistent and Yg ∪ {g}
is inconsistent.
If a portion of the AM knowledge base is removed by the operator, then there exists a
superset of the remaining knowledge base that is not consistent with the removed element
and f .
I (I ∪ (f, af  )) =
AM uniformity 1 Let (f, af 1 ), (g, af 2 ) be two inputs where WEM
1

I
WEM (I ∪ (g, af 2 )); for all X ⊆ Θ ∪ Ω; if X ∪ {f } is inconsistent iff X ∪ {g} is inconsistent, then Θ 1 ∪ Ω 1 \ {f } = Θ 2 ∪ Ω 2 \ {g} where I • (f, af 1 ) = (EM , AM 1 , af 1 ) and
I • (g, af 2 ) = (EM , AM 2 , af 2 ) and AM i = Θ i ∪ Ω i ∪ Φ i ∪ Δi .

If two inputs result in the same set of EM worlds leading to inconsistencies in an AM
knowledge base, and the consistency between analogous subsets (when joined with the

Belief revision in structured probabilistic argumentation

283

respective input) are the same, then the remaining elements in the AM knowledge base are
the same.
I (I ∪ (f, af  )) =
AM uniformity 2 Let (f, af 1 ), (g, af 2 ) be two inputs where WEM
1

I
WEM (I ∪ (g, af 2 )); for all X ⊆ Θ ∪ Ω; if X ∪ {f } is inconsistent iff X ∪ {g} is inconsistent,
then (Θ ∪ Ω) \ (Θ 1 ∪ Ω 1 ) = (Θ ∪ Ω) \ (Θ 2 ∪ Ω 2 ) where I • (f, af 1 ) = (EM , AM 1 , af 1 )
and I • (g, af 2 ) = (EM , AM 2 , af 2 ) and AM i = Θ i ∪ Ω i ∪ Φ i ∪ Δi .

If two inputs result in the same set of EM worlds leading to inconsistencies in an AM
knowledge base, and the consistency between analogous subsets (when joined with the
respective input) are the same, then the removed elements in the AM knowledge base are
the same.
We can show an equivalence between the Uniformity postulates under certain conditions.
Proposition 4 For operator • where for program I • (f, af  ) = (EM , AM , af  ) and
AM ⊆ AM ∪ {f }, we have that • satisfies AM Uniformity 1 iff it also satisfies AM
Uniformity 2.

Proof (If) Suppose BWOC that • satisfies AM Uniformity 1 and does not satisfy AM Uniformity 2. Then (for the two inputs as specified by the Uniformity postulates) (Θ ∪ Ω) \
(Θ 1 ∪ Ω 1 ) = (Θ ∪ Ω) \ (Θ 2 ∪ Ω 2 ) and Θ 1 ∪ Ω 1 \ {f }  = Θ 2 ∪ Ω 2 \ {g}. However, this
is equivalent to (Θ ∪ Ω) \ (Θ 1 ∪ Ω 1 ) = (Θ ∪ Ω) \ (Θ 2 ∪ Ω 2 ) — hence, we arrive at a
contradiction.
(Only-If) Mirrors the above claim.

4.3.2 AM-based revision operators
In this section, we define a class of operators that satisfies all of the AM rationality postulates of the previous section. We also show that there are no operators outside this class that
satisfy all of the postulates.
First, we introduce notation CandP gmAM (I ), which denotes a set of maximal consistent subsets of AM . So, if I is consistent, then CandP gmAM (I ) = {AM }.
CandP gmAM (I ) = {AM | AM ⊆ Θ ∪ Ω s.t. AM is consistent and

AM ⊆ Θ ∪ Ω s.t. AM ⊃ AM s.t. AM is consistent}

For our first result, we show that an operator returning any subset of an element of
CandP gmAM (I ) is a necessary and sufficient condition for satisfying both the Inclusion
and Consistency Preservation postulates.
Lemma 1 Given program I and input (f, af  ), operator • satisfies Inclusion and Consistency Preservation iff for I • (f, af  ) = (EM , AM , af  ), there exists an element
X ∈ CandP gmAM (I ∪ (f, af  )) s.t. (Θ ∪ Ω ∪ {f }) ∩ AM ⊆ X.
Proof (If) Suppose, BWOC, that there exists X ∈ CandP gmAM (I ∪ (f, af  )) s.t. (Θ ∪
Ω ∪ {f }) ∩ AM ⊆ X, but either Inclusion or Consistency Preservation is not satisfied.
However, the elements of CandP gmAM (I ∪ (f, af  )) are all classically consistent with all
subsets of AM ∪ {f }, which is a contradiction.

284

P. Shakarian et al.

(Only-If) Suppose, BWOC, that the operator satisfies both Inclusion and Consistency
Preservation and there does not exist X ∈ CandP gmAM (I ∪ (f, af  )) s.t. (Θ ∪ Ω ∪ {f }) ∩
AM ⊆ X. Then, (Θ ∪ Ω ∪ {f }) ∩ AM is a subset of AM ∪ {f } and (Θ ∪ Ω ∪ {f }) ∩ AM
is classically consistent.
However, by definition, this would mean that it must also be a subset of an element in
CandP gmAM (I ∪ (f, af  )).
Our next result extends Lemma 1 by showing that elements of AM ∪ {f } that are
retained are also elements of CandP gmAM (I ∪ (f, af  )) if and only if the operator satisfies
Inclusion, Consistency Preservation, and Pertinence (simultaneously).
Lemma 2 Given program I and input (f, af  ), operator • satisfies Inclusion, Consistency
Preservation, and Pertinence iff for I • (f, af  ) = (EM , AM , af  ), we have (Θ ∪ Ω ∪
{f }) ∩ AM ∈ CandP gmAM (I ∪ (f, af  )).
Proof (If) Suppose, BWOC, that (Θ ∪ Ω ∪ {f }) ∩ AM ∈ CandP gmAM (I ∪ (f, af  )),
(which, by Lemma 1, satisfies both Consistency and Inclusion) but does not satisfy Pertinence. As |Θ ∪ Ω \ X| > 0, then f ∈ (Θ ∪ Ω ∪ {f }) ∩ AM . This means that
(Θ ∪ Ω ∪ {f }) ∩ AM ⊇ X ∪ {f }, which also yields a contradiction.
(Only-If) Suppose, BWOC, that the operator satisfies Inclusion, Consistency Preservation,
/ CandP gmAM (I ∪ (f, af  )). As the operand Pertinence but (Θ ∪ Ω ∪ {f }) ∩ AM ∈
ator satisfies Pertinence, and by Lemma 1, (Θ ∪ Ω ∪ {f }) ∩ AM ∈ V = {X | ∃Y ∈
CandP gmAM (I ∪ (f, af  )) ∧ X ⊇ Y }. As (Θ ∪ Ω ∪ {f }) ∩ AM ∈
/ CandP gmAM (I ∪
(f, af  )), we have (Θ∪Ω∪{f })∩AM ∈ Z = {X | ∃Y ∈ CandP gmAM (I ∪(f, af  ))∧X ⊃
Y }. However, this violates Lemma 1 — we have thus arrived at a contradiction.
To support the satisfaction of the first Uniformity postulate, we provide the following
lemma that shows for a consistent program where two inputs cause inconsistencies to arise
in the same way, that the set of candidate replacement programs (minus the added AM
formula) is the same.
Lemma 3 Let I = (EM , AM , af ) be a consistent program, (f1 , af 1 ), (f2 , af 2 ) be two
I (I ) = W I (I ), then for all X ⊆ Θ ∪Ω
inputs, and Ii = (EM , AM ∪{fi }, af i ). If WEM
1
EM 2
we have that:
1.
2.

If X ∪ {f1 } is inconsistent ⇔ X ∪ {f2 } is inconsistent, then:
{X \ {f1 } | X ∈ CandP gmAM (I1 )} = {X \ {f2 } | X ∈ CandP gmAM (I2 )}.
If {X \ {f1 } | X ∈ CandP gmAM (I1 )} = {X \ {f2 } | X ∈ CandP gmAM (I2 )} then
X ∪ {f1 } is inconsistent ⇔ X ∪ {f2 } is inconsistent.

Proof (If) Suppose BWOC that for all X ⊆ Θ ∪ Ω we have that X ∪ {f1 } is inconsistent iff X ∪ {f2 } is inconsistent, but {X \ {f1 } | X ∈ CandP gmAM (I1 )}  = {X \
{f2 } | X ∈ CandP gmAM (I2 )}. However, the pre-condition of this statement implies that
{X \ {f1 } | X ⊆ CandP gmAM (I1 )} = {X \ {f2 } | X ⊆ CandP gmAM (I2 ), which gives
us a contradiction.
(Only-If) Suppose BWOC that {X \ {f1 } | X ∈ CandP gmAM (I1 )} = {X \ {f2 } | X ∈
CandP gmAM (I2 )}, but there exists a set X ⊆ Θ ∪ Ω s.t. exactly one of X ∪ {f1 }, X ∪
{f2 } is inconsistent. As a first case, let us assume that Θ ∪ Ω ∪ {f1 } is consistent. As
{X \ {f1 } | X ∈ CandP gmAM (I1 )} = {X \ {f2 } | X ∈ CandP gmAM (I2 )}, this implies

Belief revision in structured probabilistic argumentation

285

that Θ ∪ Ω ∪ {f2 } must also be consistent as each of those sets must then have exactly one
element. In this case, a contradiction arises, hence both Θ ∪ Ω ∪ {f1 } and Θ ∪ Ω ∪ {f2 }
must be classically inconsistent. Now let us consider the other case. As Θ ∪ Ω is consistent
and all its subsets are consistent, then we must consider some X ⊆ Θ ∪ Ω where X ∪ {f1 }
is not consistent. Hence, X ∪ {f2 } must be consistent. As Θ ∪ Ω ∈ CandP gmAM (I2 ), we
know that X ∈ {X \ {f2 } | X ∈ CandP gmAM (I2 )} iff X ∪ {f2 } is consistent, so it must
be in that set. However, X ∈
/ {X \ {f1 } | X ∈ CandP gmAM (w, I1 )} as X ∪ {f1 } is not
consistent — this is a contradiction.
We now define the class of AM-based Operators, denoted AMO. Essentially, this operator
selects one of the candidate programs in a deterministic fashion.
Definition 17 (AM-based Operators) A belief revision operator • is an “AM-based” operator (• ∈ AMO) iff given program I = (EM , AM , af ) and input (f, af  ), the revision is
defined as I • (f, af  ) = (EM , AM , af  ), where AM ∈ CandP gmAM (I ∪ (f, af  )).
Finally, we are able to prove our representation theorem for AM-based belief revision.
This theorem follows directly from the results presented in this section.
Theorem 1 (AM Representation Theorem) An operator • belongs to class AMO iff
it satisfies Inclusion, Vacuity, Consistency Preservation, Weak Success, Pertinence, and
Uniformity 1.

Proof (Sketch) (If) By the definition of AMO, Vacuity and Weak Success follow trivially. Further, Lemma 2 shows that Inclusion, Consistency Preservation and Pertinence are
satisfied, while Lemma 3 shows that Uniformity 1 is satisfied.
(Only-If) Suppose BWOC that an operator • satisfies all postulates from the statement
and • ∈
/ AFO. Then, one of the following conditions must hold: (i) it does not satisfy
Lemma 2; (ii) it does not satisfy Lemma 3. However, by those previous arguments, if it satisfies all postulates from the statement, these arguments must be true as well — hence a
contradiction.
Example 16 Recall the AM knowledge base of the Fig. 1. We want to add θ3a = l and
θ3b = ¬l to AM. Also recall KEM defined in Example 2. Let af (θ3a ) = a and af (θ3a ) = b.
The input is (f, af  ) = ({θ3a , θ3b }, af  ) where af  is the new annotation function. The
program I ∪ (f, af  ) = (EM , AM ∪ {f }, af  ) will be inconsistent because of f8 . The
AM-based belief revision I • (f, af  ) will remove either θ3a or θ3b . The resulting program
I  will be consistent.
We add θ3a = l and θ3b = ¬l to the AM knowledge base of the Fig. 1 and f8 = a ∧ b :
0.4 ± 0.1 to the KEM defined in the Example 2. Also, let af (θ3a ) = a and af (θ3a ) = b. In
this scenario, the AM-based revision operator will remove either θ3a or θ3b . The resulting
knowledge base will be consistent.

4.4 Annotation function-based belief revision
In this section we attack the belief revision problem from a different angle: adjusting the
annotation function. The advantage to changing the annotation function is that we might

286

P. Shakarian et al.

not need to discard an entire fact or strict rule from the argumentation model. Consider the
following example.
Example 17 Let us consider two contradictory facts in an AM: a and ¬a such that af (a) =
q ∧ r and af (¬a) = r ∧ s. If we assume that q, r, s are the only atoms in the EM, then we
know that a occurs under the environmental worlds {q, r} and {q, r, s}, and that ¬a occurs
under the environmental worlds {r, s} {q, r, s}.
Clearly, they cannot both be true in world {q, r, s}. Hence, a new annotation formula af 
where af  (a) = q ∧ r and af  (¬a) = r ∧ s ∧ ¬for({q, r, s}) easily solves the conflict (note
that for(w) specifies a formula satisfied by exactly world w). Note that we did not have to
remove ¬a from the knowledge base, which means that this information is not completely
lost. In other word, the main difference between the AM-based belief revision and adjusting
the Annotation function is that the later model allows more delicate changes to be made in
order to preserve the information gathered in AM.
We also note that modifications of the annotation function can be viewed as a generalization of AM modification. Consider the following:
Example 18 Consider again the present facts a and ¬a in the AM. Assuming that this causes
an inconsistency (that is, there is at least one world in which they both hold), one way to
resolve it would be to remove one of these two literals. Suppose ¬a is removed; this would
be equivalent to setting af(¬a) = ⊥ (where ⊥ represents a contradiction in the language of
the EM).
In this section, we introduce a set of postulates for reasoning about annotation functionbased belief revision. As in the previous section, we then go on to provide a class of
operators that satisfy all the postulates and show that this class includes all operators
satisfying the postulates.
As in this section we are only conducting annotation function revisions, for I =
(EM , AM , af ) and input (f, af  ) we denote the revision as follows: I (f, af  ) =
(EM , AM , af  ) where AM = AM ∪ {f } and af  is the revised annotation function.
Further, in this section, we often refer to “removing elements of AM ” to refer to changes to
the annotation function that cause certain elements of the AM to not have their annotations
satisfied in certain EM worlds. Further, as we are looking to change the annotation function
for a specific subset of facts and strict rules, we specify these subsets with the following
notation.
–
–
–

wld(f ) ={w | w |=
f } – the set of worlds that satisfy formula f ; and
for(w) = a∈w a ∧ a ∈w
/ ¬a – the formula that has w as its only model.
IAM (w) = {f ∈ Θ ∪ Ω | w |= af(f )}

Intuitively, IAM (w) is the subset of facts and strict rules in AM whose annotations are
true in EM world w.

4.4.1 Postulates for revising the annotation function
Just as we did for AM-based belief revision, here we introduce rationality postulates for
annotation function based belief revision. We note that except for vacuity, consistency

Belief revision in structured probabilistic argumentation

287

preservation, and weak success, the postulates are defined in a different manner from the
AM postulates. The key difference between the AM-based and the AF-based postulates
is that AF postulates consider subsets of the AM that occur in certain the environmental
conditions — as opposed to considering the entire analytical model as a whole. In this
way, the AF-based postulates will give rise to a more fine-grained revision of the overall
knowlegebase than the more coarse-grain AM-based approach.


AF inclusion For

 I (f,
 af ) = (EM , AM ∪ {f }, af ),

∀g ∈ AM , wld af  (g) ⊆ wld(af  (g)).
This postulate states that, for any element in the AM, the worlds that satisfy its annotation
after the revision are a subset of the original set of worlds satisfying the annotation for that
element.

AF vacuity If I ∪ (f, af  ) is consistent, then I (f, af  ) ⊆ I ∪ (f, af  ).
This is the same as for the AM version of the postulate: no change is made if the program
is consistent with the added input.

AF consistency preservation If I is consistent, then I (f, af  ) is also consistent.
Again, as with the AM version, the operator maintains a consistent program.

AF weak success If I ∪ (f, af  ) is consistent, then (f, af  ) ∈ I (f, af  ).
The input must be contained in the revised program if it does not cause inconsistencies.
For a given EM world, if a portion of the associated AM knowledge base is removed by
the operator, then there exists a subset of the remaining knowledge base that is not consistent
with the removed element and f .
I (I ∪
AF pertinence For I (f, af  ) = (EM , AM ∪ {f }, af  ), for each w ∈ WEM

(f, af  )), we have Xw = {h ∈ Θ ∪ Ω | w |= af  (h)}; for each g ∈ AM (w) \ Xw there
exists Yw ⊇ Xw ∪ {f } s.t. Yw is consistent and Yw ∪ {g} is inconsistent.
For a given EM world, if a portion of the associated AM knowledge base is removed by the
operator, then there exists a superset of the remaining knowledge base that is not consistent
with the removed element and f .

AF uniformity 1 Let (f, af 1 ), (g, af 2 ) be two inputs where
I (I ∪ (f, af  )) = W I (I ∪ (g, af  )); for all w ∈ W I (I ∪ (f, af  )) and for all X ⊆
WEM
1
2
EM
EM

AM (w); if {x | x ∈ X∪{f }, w |= af 1 (x)} is inconsistent iff {x | x ∈ X∪{g}, w |= af 2 (x)}
is inconsistent, then for each h ∈ AM , we have that:
I
{w ∈ WEM
(I ∪ (f, af 1 )) | w |= af 1 (h) ∧ ¬af 1 (h)} =
I
{w ∈ WEM
(I ∪ (g, af 2 )) | w |= af 2 (h) ∧ ¬af 2 (h)}.

If two inputs result in the same set of EM worlds leading to inconsistencies in an AM knowledge base, and the consistency between analogous subsets (when joined with the respective
input) are the same, then the models removed from the annotation of a given strict rule or
fact are the same for both inputs.

288

P. Shakarian et al.

AF uniformity 2 Let (f, af 1 ), (g, af 2 ) be two inputs where
I (I ∪ (f, af  )) = W I (I ∪ (g, af  )); for all w ∈ W I (I ∪ (f, af  ))and for all X ⊆
WEM
1
2
EM
EM

AM (w); if {x | x ∈ X∪{f }, w |= af 1 (x)} is inconsistent iff {x | x ∈ X∪{g}, w |= af 2 (x)}
is inconsistent, then
I
(I ∪ (f, af 1 )) | w |= af 1 (h) ∧ af 1 (h)} =
{w ∈ WEM
I
(I ∪ (g, af 2 )) | w |= af 2 (h) ∧ af 2 (h)}.
{w ∈ WEM

If two inputs result in the same set of EM worlds leading to inconsistencies in an AM knowledge base, and the consistency between analogous subsets (when joined with the respective
input) are the same, then the models retained in the the annotation of a given strict rule or
fact are the same for both inputs.

4.4.2 AF-based revision operator
In this section, we introduce a class of operators for revising a DeLP3E program. Unlike
the AM revision, this fine-grained approach requires an adjustment of the conditions in
which elements of AM can hold true. Hence, any subset of AM associated with a world
I (I ∪ (f, af  )) must be modified by the operator in order to remain consistent.
in WEM
So, for such a world w, we introduce the annotation function version of the set of candidate replacement programs for AM (w) in order to maintain consistency and satisfy the
Inclusion postulate.
CandP gmaf (w, I ) =
{AM | AM ⊆ AM (w) s.t. AM is consistent and
AM ⊆ AM (w) s.t. AM ⊃ AM s.t. AM
is consistent}
Intuitively, for each world w, this is the set of is a maximal consistent subsets of IAM (w).
However, unlike with AM based belief revision, the candidate replacement program are
specified for specific worlds - this in turn enables a more “surgical” adjustment to the
overall knowledgebase than AM belief revision. This is due to the fact that in AM revision, components of the analytical model are deemed to no longer hold in any world as
opposed to a specific subset of worlds.
Before introducing our operator, we define some preliminary notation. Let Φ : WEM →
2[Θ ]∪[Ω ] . Recall that sets of all facts and rules are denoted by [Θ] and [Ω] respectively.
For each formula h in AM ∪ {f }, where f is part of the input, we define:

¬for(w)
newFor(h, Φ, I , (f, af  )) = af  (h) ∧
I (I ∪(f,af  )) | h∈Φ(w)
w∈WEM
/

Intuitively, newFor eliminate inconsistency by adding the negation of the formulas whose
only models are the inconsistent words. These inconsistent words are the result of adding
the input f to the existing program I .
Now we define the class of operators called AFO. We show that membership in AFO is a
necessary and sufficient condition for satisfying all postulates introduced in this paper. The
supporting Lemmas and their associated proofs are included in the Appendix.
Definition 18 (AF-based Operators) A belief revision operator  is an “annotation
function-based” (or af-based) operator ( ∈ AFO) iff given program I = (EM , AM , af )

Belief revision in structured probabilistic argumentation

289

and input (f, af  ), the revision is defined as I (f, af  ) = (EM , AM ∪ {f }, af  ),
where:
∀h, af  (h) = newFor(h, Φ, I , (f, af  ))
where ∀w ∈ WEM , Φ(w) ∈ CandP gmaf (w, I ∪ (f, af  )).
Theorem 2 (Annotation Function Representation Theorem) An operator  belongs
to class AFO iff it satisfies Inclusion, Vacuity, Consistency Preservation, Weak Success,
Pertinence, and Uniformity 1.
I (I ∪
Proof (Sketch) (If) By the fact that formulas associated with worlds in the set WEM

(f, af )) are considered in the change of the annotation function, Vacuity and Weak Success follow trivially. Further, Lemma 8 shows that Inclusion, Consistency Preservation, and
Pertinence are satisfied while Lemma 9 shows that Uniformity 1 is satisfied.
(Only-If) Suppose BWOC that an operator  satisfies all postulates and  ∈
/ AFO. Then,
one of four conditions must hold: (i) it does not satisfy Lemma 8 or (ii) it does not satisfy Lemma 9. However, by those previous arguments, if it satisfies all postulates, these
arguments must be true as well – hence a contradiction.

5 Case study: an application in cyber security
In this section we develop a complete example of how the DeLP3E framework can be used
to deal with a cyber-attribution problem. In this scenario, a cyber attack has been detected
and we want to determine who is responsible for it.

5.1 Model for the attribution problem
To specify the model we need to specify the environmental model, the analytical model, and
the annotation function. First we identify two special subsets of the set of constants (C) for
this application: Cact and Cops , which specify the actors that could conduct cyber-operations
and the operations themselves, respectively:
Cact = {baja, krasnovia, mojave}
Cops = {worm123}

That is, the possible actors are the states of baja, krasnovia and mojave, and the only
operation that we consider they can conduct is a worm123 attack.
Next, we need to specify the sets of predicates, PEM , the predicates for the environmental model, and PAM , the predicates for the analytical model. These are given in Fig. 5,
which presents all the predicates with variables. The following are examples of ground
atoms over those predicates; again, we distinguish between the subset of ground atoms
from the environmental model GEM and the ground atoms from the analytical model
GAM :
GEM : origIP(mw123sam1, krasnovia), mwHint(mw123sam1, krasnovia),

inLgConf (krasnovia, baja), mseTT(krasnovia, 2)
GAM : evidOf (mojave, worm123), motiv(baja, krasnovia), expCw(baja),

tgt(krasnovia, worm123)

290

P. Shakarian et al.

Fig. 5 Predicate definitions for the environment and analytical models in the cyber attribution example

PAM and the set of constants provides all the information we need for the analytical
model. However, there is more to the environmental model than just PEM and the constants.
We need to specify the probabilities of formulae. This information is given by the following
set of probabilistic formulae KEM :

f1 = govCybLab(baja) : 0.8 ± 0.1
f2 = cybCapAge(baja, 5) : 0.2 ± 0.1
f3 = mseTT(baja, 2) : 0.8 ± 0.1
f4 = mwHint(mw123sam1, mojave)
∧ compilLang(worm123, english) : 0.7 ± 0.2
f5 = malwInOp(mw123sam1, worm123)
∧ malwareRel(mw123sam1, mw123sam2)
∧ mwHint(mw123sam2, mojave) : 0.6 ± 0.1
f6 = inLgConf (baja, krasnovia) ∨ ¬cooper(baja, krasnovia) : 0.9 ± 0.1
f7 = origIP(mw123sam1, baja) : 1 ± 0

Belief revision in structured probabilistic argumentation

291

Given this probabilistic information, we can demonstrate the linear programming approach

to the maximum entailment problem defined in Definition 2. Consider knowledge base KEM
and a set of ground atoms restricted to those that appear in that program. Hence, we have
the following worlds:
w1 = {govCybLab(baja), cybCapAge(baja, 5), mseTT(baja, 2)}
w2 = {govCybLab(baja), cybCapAge(baja, 5)}
w3 = {govCybLab(baja), mseTT(baja, 2)}
w4 = {cybCapAge(baja, 5), mseTT(baja, 2)}
w5 = {cybCapAge(baja, 5)}
w6 = {govCybLab(baja)}
w7 = {mseTT(baja, 2)}
w8 = ∅
and suppose we wish to compute the probability for formula:
q = govCybLab(baja) ∨ mseTT(baja, 2)
For each formula in KEM we have a constraint, and for each world above we have a variable.
An objective function is created based on the worlds that satisfy the query formula (in
 , q) can be written as
this case, worlds w1 , w2 , w3 , w4 , w6 , w7 ). Hence, EP-LP-MIN(KEM
follows:
max

x 1 + x2 + x3 + x4 + x6 + x7

w.r.t. :

0.7 ≤

x1 + x2 + x3 + x6

≤ 0.9

0.1 ≤

x1 + x2 + x4 + x5

≤ 0.3

0.8 ≤

x1 + x3 + x4 + x7

≤1

x1 + x 2 + x 3 + x 4 + x 5 + x 6 + x 7 + x 8 = 1
 , q) and, after an easy modification,
From this, we can solve EP-LP-MAX(KEM

EP-LP-MIN(KEM , q), and obtain the solution 0.9 ± 0.1.
Now, given PAM and C, we can assemble the ground argumentation framework of
Fig. 6 as a sample AM . From this argumentation framework, we can build the following
arguments:

A1 , condOp(baja, worm123)
 A1 = {θ1a , δ1a }
A2 , condOp(baja, worm123)
 A2 = {φ1 , φ2 , δ4 , ω2a , θ1a , θ2 }
A3 , condOp(baja, worm123)
 A3 = {φ1 , δ2 , δ4 }
A4 , condOp(baja, worm123)
 A4 = {φ2 , δ3 , θ2 }
A5 , isCap(baja, worm123)

A5 = {φ1 , δ4 }

A6 , ¬condOp(baja, worm123)
 A6 = {δ1b , θ1b , ω1a }
A7 , ¬isCap(baja, worm123)
 A7 = {φ3 , δ5a }
Note that:
A5 , isCap(baja, worm123)
is a sub-argument of both
A2 , condOp(baja, worm123)

292

P. Shakarian et al.

Fig. 6 A ground argumentation framework

and
A3 , condOp(baja, worm123)
The following are some of the attack relationships between these arguments: A1 , A2 , A3 ,
and A4 all attack A6 ; A5 attacks A7 ; and A7 attacks A2 .
In Fig. 7 we show an another example of a knowledge base for the attribution problem,
this time with a non-ground argumentation system.
With the environmental and analytical models specified, the remaining component of
the model is the annotation function; one suitable annotation function is given in Fig. 8.
Consider worlds w1 , . . . , w8 along with the argument A5 , isCap(baja, worm123)
. This
argument is valid in worlds w1 , w2 , w3 , w4 , w6 , and w7 . Similarly, worlds w3 , w6 , and w7
are warranting scenarios for argument A5 , isCap(baja, worm123)
 and
nec(isCap(baja, worm123)) = {w3 , w6 , w7 }
while
poss(isCap(baja, worm123)) = {w1 , w2 , w3 , w4 , w6 , w7 }

5.2 Applying entailment to the cyber-attribution problem
We now discuss how finding tight bounds on the entailment probability can be applied
to the cyber-attribution problem. Following the domain-specific notation introduced in

Belief revision in structured probabilistic argumentation

293

Fig. 7 A non-ground argumentation framework

the beginning of this case study (where the set of constants C includes two subsets:
Cact and Cops , that specify the actors that could conduct cyber-operations and the operations themselves, respectively), we define a special case of the entailment problem as
follows.
Definition 19 Let I = (EM , AM , af ) be a DeLP3E program, S ⊆ Cact (the set of
“suspects”), O ∈ Cops (the “operation”), E ⊆ GEM (the “evidence”), and D ⊆ GEM (the
“probabilistic fact”).
An actor A ∈ S is said to be a most probable suspect iff there does not exist A ∈ S




such that
 PcondOp(A ,O),I  > PcondOp(A,O),I where I = (EM ∪ E ∪ D , AM , af ) with
E = c∈E {c : 1 ± 0} and D = c∈D {c : p ± }.
Note that PcondOp(A ,O),I  and PcondOp(A,O),I  are midpoint of intervals PcondOp(A ,O),I  ±
 and PcondOp(A,O),I  ± . Alternative formulations are possible based on upper or lower
bound of interval.
Given the above definition, we refer to Q = (I , S , O, E ) as an attribution query, and
A as an answer to Q. We note that in the above definition, the items of evidence are added

Fig. 8 Example annotation function

294

P. Shakarian et al.

to the environmental model with a probability of 1. While, in general, this may be the case,
there are often instances in analysis of a cyber-operation where the evidence may be true
with some degree of uncertainty. For this reason we allow for probabilistic facts in the
definition.
To understand how uncertain evidence can be present in a cyber-security scenario,
consider the following scenario:
In Symantec’s initial analysis of the Stuxnet worm, analysts found the routine
designed to attack the S7-417 logic controller was incomplete, and hence would not
function [13]. However, industrial control system expert Ralph Langner claimed that
the incomplete code would run provided a missing data block is generated, which he
thought was possible [27]. In this case, though the code was incomplete, uncertainty
was clearly present regarding its usability.5
This situation provides a real-world example of the need to compare arguments — in this
case, in the worlds where both arguments are valid, Langner’s argument would likely defeat
Symantec’s by generalized specificity (the outcome, of course, will depend on the exact
formalization of the two).
In Fig. 9 we give a simple, straightforward algorithm for attribution queries. The correctness of this algorithm clearly follows from the definitions above. We note that a key source
of computational complexity lies in step 2, where all arguments supporting the hypothesis
that each actor conducted the operation are computed for each world in the EM; this leads to
a factor of 2|GEM | (exponential in the number of ground atoms in the environmental model).
However, we also note that this is equal to the time complexity required to write out a linear
program for answering the entailment query.
Note that the exact approaches presented thus far for answering attribution queries experience exponential running times in the worst case. Hence, for the creation of a real-world
system, we consider several practical approaches that can be taken to answer attribution
queries Q = (I , S , O, E ). We are currently exploring several of these ideas as we work to
build a system for cyber-attribution based on DeLP3E:
1.

2.

Approximating the warranting formula: Instead of inspecting all possible classical
dialectical trees as in Approach 1, either a subset of trees can be computed according to
a given heuristic or an anytime approach can be adopted to select such a subset F  . The
computations with respect to F  will then yield sound approximations relative to the
full forest F , which means that all probability intervals will be supersets of the exact
intervals.
Approximating the probability: Another alternative to Approach 1 is to apply approximation algorithms to the formula; for instance:
(a) Approximate satisfiability: if the formula is unsatisfiable, then the warranting
probability is zero;
(b) A lower bound on the warranting probability can be obtained from a subset of
possible worlds (k most probable worlds, random sample of worlds, etc.).

3.

“What-if” Reasoning: Given a set Wint of worlds of interest and a warranting formula φ (computed using any of the above approaches), each world can be checked to

5 Langner

block [5].

was later vindicated by the discovery of an older sample, Stuxnet 0.5, which generated the data

Belief revision in structured probabilistic argumentation

295

Fig. 9 A straightforward algorithm for finding a solution to an attribution query

see which literals condOp(Ai , O), with Ai ∈ S , are warranted. That is, instead of
computing probability of attribution, the attribution literal is analyzed in each world of
interest.

6 Conclusions
In this paper we introduced the DeLP3E framework, consisting of an environmental model,
an analytical model, and an annotation function that relates the two. DeLP3E is an extension
of the PreDeLP language in which sentences can be be annotated with probabilistic events.
Such events are connected to a probabilistic model, allowing a clear separation of interests
between certain and uncertain knowledge while allowing uncertainty to be captured and
incorporated into reasoning. After presenting the language, we focused on characterizing
belief revision operations over DeLP3E knowledge bases. We presented two sets of postulates, both inspired by the postulates that were developed for non-prioritized revision of
classical belief bases. The first set of postulates provides a coarse approach that assumes
that revision operations only allow changes to the analytical model, while the second is
a finer-grained approach based on modifications to the annotation function. We then proceeded to study constructions of operators based on these postulates, and prove that they are
equivalent to their characterizations by the respective postulates.
This paper makes a number of contributions to the literature of both argumentation and
belief revision. First, this paper contains the most complete description of DeLP3E yet published.6 This is a contribution to the study of probabilistic argumentation, and one that,
with the separation between the argumentation system and the probabilistic information in
the environmental model, makes it unique. Second, this paper presents two approaches to
belief revision in DeLP3E. This is a contribution to the study of the relationship between
argumentation systems and belief revision, one that views the problem from the position of
structured argumentation. While the study of revision of the annotation function is specific
to DeLP3E, the study of the revision of the analytical model will be relevant to all argumentation systems that combine strict and defeasible elements, such as DeLP [15], PreDeLP
[30] and ASPIC+ [31, 33]. Finally, the paper presents an extended case study of the application of DeLP3E to the attribution problem. This is a contribution to both the argumentation

6 DeLP3E

was briefly introduced in [41] and [40] as a solution to the attribution problem.

296

P. Shakarian et al.

literature, in showing how argumentation can be applied to a complex real-world problem,
and to the cyber security literature, suggesting tools that can be used to address this problem. As part of the case study we considered a special kind of query, called an attribution
query, that is useful in tackling the problem of attributing responsibility to entities given a
cyber event of interest. This is a further contribution to the cyber security literature.
After this initial proposal, there remains much work to be done with DeLP3E. As future
work, we plan to study other kinds of belief revision operators, including more general
ones that allow the modification of the environmental model along with the other two
components, as well as revision operators that function at different levels of granularity.
Furthermore, we are in the final stages of producing an implementation of the system —
important future work involves focusing on scalable inference algorithms and testing them
on real-world data from the cyber security domain. The last thing to note is that, as discussed
above, DeLP3E is less a specific formal system, and more a family of systems in which the
analytical model and the environmental model are instantiated in different ways. Here we
chose to use Nilsson’s probabilistic logic to capture the world in the environmental model,
but it is possible to use other frameworks for this purpose; for instance, Markov Logic networks [35] would be an interesting choice. Similarly, here we chose to use PreDeLP to build
the analytical model. We can easily envisage versions of DeLP3E that use frameworks other
than PreDeLP for the analytical model. For instance, an abstract argumentation model [3],
an argumentation model that includes uncertain consideration in defeat relationships (such
as a probabilistic argumentation model [28] or possibilistic argumentation model [4]) and
we might also associate varying notions of strength with attack relations as in [8]. All of
these are potential routes for future work.
Acknowledgments This work was supported by UK EPSRC grant EP/J008346/1—“PrOQAW”, by ERC
grant 246858—“DIADEM”, funds provided by CONICET and Universidad Nacional del Sur, Argentina,
by NSF grant #1117761, by the Army Research Office under the Science of Security Lablet grant (SoSL)
and project 2GDATXR042, and DARPA project R.0004972.001. The opinions in this paper are those of the
authors and do not necessarily reflect the opinions of the funders, the U.S. Military Academy, or the U.S.
Army.

Appendix
In this appendix we provide some complementary material that was not included in the
main body of the paper to enhance readability. Specifically, the results of this appendix
support the proof of Theorem 2 in Section 4.4 (the representation theorem for AF-based
belief revision).
First, we give the annotation function revision versions of Proposition 4.
Proposition 5 For operator  such that I (f, af  ) = (EM , AM ∪ {f }, af  ) and ∀w,
I (f,af  )
I ∪(f,af  )
(w) ⊆ AM
(w), it holds that  satisfies AF Uniformity 1 iff it
we have that AM
also satisfies AF Uniformity 2.
Proof (If) Suppose BWOC that  satisfies AF Uniformity 1 and does not satisfy AF UniforI (I ∪ (f, af  )) = W I (I ∪ (g, af  )) and h ∈ 
mity 2. Then ∀w ∈ WEM
AM we have:
1
2
EM
I
I
(I ∪ (f, af 1 )) | w |= af 1 (h)} ∩ {w ∈ WEM
(I ∪ (f, af 1 )) | w |= ¬af 1 (h)} =
{w ∈ WEM
I
I
{w ∈ WEM
(I ∪ (g, af 2 )) | w |= af 2 (h)} ∩ {w ∈ WEM
(I ∪ (g, af 2 )) | w |= ¬af 2 (h)}

Belief revision in structured probabilistic argumentation

297

and
I
I
(I ∪ (f, af 1 )) | w |= af 1 (h)} ∩ {w ∈ WEM
(I ∪ (f, af 1 )) | w |= af 1 (h)}  =
{w ∈ WEM
I
I
{w ∈ WEM
(I ∪ (g, af 2 )) | w |= af 2 (h)} ∩ {w ∈ WEM
(I ∪ (g, af 2 )) | w |= af 2 (h)}

However, we note that ∀h ∈ AM we have af 1 (h) = af 2 (h) and by the statement of the
I (I ∪ (f, af  )) = W I (I ∪ (g, af  )), we have the following:
postulate WEM
1
2
EM
I
{w ∈ WEM
(I ∪ (f, af 1 )) | w |= ¬af 1 (h)} =
I
(I ∪ (g, af 2 )) | w |= ¬af 2 (h)}
{w ∈ WEM
Which implies a contradiction.
(Only-If) Mirrors the above claim.

We now focus on complementary material relating to Section 4.4 on annotation functionbased belief revision.
Lemma 4 Given program I and input (f, af  ), operator  satisfies Inclusion and ConsisI (I ∪ (f, af  )),
tency Preservation iff for I (f, af  ) = (EM , AM , af  ), for all w ∈ WEM

there exists an element X ∈ CandP gmaf (w, I ∪ (f, af )) s.t. {h ∈ Θ ∪ Ω ∪ {f } | w |=
af  (h)} ⊆ X.
Proof (If) Suppose, BWOC, that there exists an element X ∈ CandP gmaf (w, I ∪(f, af  ))
s.t. {h ∈ Θ ∪ Ω ∪ {f }|w |= af  (h)} ⊆ X but either Inclusion or Consistency Preservation
is not satisfied. However, the elements of CandP gmaf (w, I ∪ (f, af  )) are all classically
consistent and all subsets of AM I ∪(f,af  ) (w), which is a contradiction. (Only-If) Suppose,
BWOC, that the operator satisfies both Inclusion and Consistency Preservation and there
does not exist X ∈ CandP gmaf (w, I ∪(f, af  )) s.t. {h ∈ Θ ∪Ω ∪{f } | w |= af  (h)} ⊆ X.
Then, {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} is a subset of AM I ∪(f,af  ) (w) and {h ∈ Θ ∪ Ω ∪
{f } | w |= af  (h)} is classically consistent. However, by definition, this would mean that it
must also be a subset of an element in CandP gmaf (w, I ∪ (f, af  )).
We now investigate the role that the set CandP gmaf plays in showing the necessary and
sufficient requirement for satisfying Pertinence.
Lemma 5 Given program I and input (f, af  ), operator  satisfies Inclusion, Consistency
I (I ∪
Preservation, and Pertinence iff for I (f, af  ) = (EM , AM , af  ), for all w ∈ WEM
(f, af  )) we have {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} ∈ CandP gmaf (w, I ∪ (f, af  )).
Proof (If) Suppose, BWOC, that
{h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} ∈ CandP gmaf (w, I ∪ (f, af  ))
(which, by Lemma 7, satisfies both Consistency and Inclusion) but does not satisfy Pertinence. As |AM (w) \ Xw | > 0, then f ∈ {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)}. This
means that {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} ⊇ Xw ∪ {f }, which also yields a contradiction.
(Only-If) Suppose, BWOC, that the operator satisfies Inclusion, Consistency Preserva/
tion, and Pertinence but there exists w s.t. {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} ∈
CandP gmaf (w, I ∪ (f, af  )). By Lemma 7, {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} ∈
V = {X | ∃Y ∈ CandP gmaf (w, I ∪ (f, af  )) ∧ X ⊇ Y }. Hence, this would mean that

298

P. Shakarian et al.

{h ∈ Θ ∪Ω ∪{f } | w |= af  (h)} ∈ Z = {X | ∃Y ∈ CandP gmaf (w, I ∪(f, af  ))∧X ⊃ Y }
in this case. However, this would violate Lemma 7 — a contradiction.
Lemma 6 Let I = (EM , AM , af ) be a consistent program, (f1 , af 1 ), (f2 , af 2 ) be two
I (I ) = W I (I ), then for all w ∈
inputs, and Ii = (EM , AM ∪ {fi }, af i ). If WEM
1
EM 2
I
WEM (I1 ) and all X ⊆ AM (w) we have that:
1.

2.

If {x | x ∈ X ∪ {f1 }, w |= af 1 (x)} is inconsistent ⇔ {x | x ∈ X ∪ {f2 }, w |= af 2 (x)}
is inconsistent, then {X \ {f1 } | X ∈ CandP gmaf (w, I1 )} = {X \ {f2 } | X ∈
CandP gmaf (w, I2 )}.
If {X \ {f1 } | X ∈ CandP gmaf (w, I1 )} =
{X \ {f2 } | X ∈ CandP gmaf (w, I2 )} then {x | x ∈ X ∪ {f1 }, w |= af 1 (x)} is
inconsistent ⇔ {x | x ∈ X ∪ {f2 }, w |= af 2 (x)} is inconsistent.

I (I ) and all X ⊆ 
Proof (If) Suppose BWOC that for all w ∈ WEM
AM (w); if {x | x ∈
1
X ∪ {f1 }, w |= af 1 (x)} is inconsistent iff {x | x ∈ X ∪ {f2 }, w |= af 2 (x)} is inconsistent,
but there exists w s.t.:

{X \ {f1 } | X ∈ CandP gmaf (w, I1 )}  = {X \ {f2 } | X ∈ CandP gmaf (w, I2 )}.
However, the pre-condition of this statement implies that {X \ {f1 } | X ⊆ CandP gmaf
(w, I1 )} = {X \ {f2 } | X ⊆ CandP gmaf (w, I2 ) which gives us a contradiction.
(Only-If) Suppose BWOC that for all w, {X \ {f1 } | X ∈ CandP gmaf (w, I1 )} = {X \
I (I ) and set X ⊆
{f2 } | X ∈ CandP gmaf (w, I2 )}, but there exists a world w ∈ WEM
1

AM (w) s.t. exactly one of {x | x ∈ X ∪ {f1 }, w |= af 1 (x)}, {x | x ∈ X ∪ {f2 }, w |=
af 2 (x)} is inconsistent. As a first case, let us assume that AM (w) ∪ {f1 } is consistent. As
{X\{f1 } | X ∈ CandP gmaf (w, I1 )} = {X\{f2 } | X ∈ CandP gmaf (w, I2 )}, this implies
that AM (w) ∪ {f2 } must also be consistent as each of those sets must then have exactly one
element. In this case a contradiction arises, hence both AM (w)∪{f1 }, AM (w)∪{f2 } must
be classically inconsistent. Now let us consider the other case. As AM (w) is consistent and
all its subsets are consistent, then we must consider some X ⊆ AM (w) where X ∪ {f1 } is
not consistent. Hence, X ∪ {f2 } must be consistent. As AM (w) ∈ CandP gmaf (w, I2 ),
we know that X ∈ {X \ {f2 } | X ∈ CandP gmaf (w, I2 )} iff X ∪ {f2 } is consistent, so it
must be in that set. However, X ∈
/ {X \ {f1 } | X ∈ CandP gmaf (w, I1 )} as X ∪ {f1 } is not
consistent — this is a contradiction.
Lemma 7 Given program I and input (f, af  ), operator  satisfies Inclusion and ConsisI (I ∪ (f, af  )),
tency Preservation iff for I (f, af  ) = (EM , AM , af  ), for all w ∈ WEM

there exists an element X ∈ CandP gmaf (w, I ∪ (f, af )) s.t. {h ∈ Θ ∪ Ω ∪ {f } | w |=
af  (h)} ⊆ X.
Proof (If) Suppose, BWOC, that there exists X ∈ CandP gmaf (w, I ∪ (f, af  )) s.t.
{h ∈ Θ ∪ Ω ∪ {f }|w |= af  (h)} ⊆ X but either Inclusion or Consistency Preservation
is not satisfied. However, the elements of CandP gmaf (w, I ∪ (f, af  )) are all classically
consistent and all subsets of AM I ∪(f,af  ) (w), which is a contradiction.
(Only-If) Suppose, BWOC, that the operator satisfies both Inclusion and Consistency
Preservation and there does not exist X ∈ CandP gmaf (w, I ∪ (f, af  )) s.t. {h ∈ Θ ∪
Ω ∪ {f } | w |= af  (h)} ⊆ X. Then, {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} is a subset of AM I ∪(f,af  ) (w) and {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} is classically consistent.

Belief revision in structured probabilistic argumentation

299

However, by definition, this would mean that it must also be a subset of an element in
CandP gmaf (w, I ∪ (f, af  )).
We now investigate the role that the set CandP gmaf plays in showing the necessary and
sufficient requirement for satisfying Pertinence.
Lemma 8 Given program I and input (f, af  ), operator  satisfies Inclusion, Consistency
I (I ∪
Preservation, and Pertinence iff for I (f, af  ) = (EM , AM , af  ), for all w ∈ WEM
(f, af  )) we have {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} ∈ CandP gmaf (w, I ∪ (f, af  )).
Proof (If) Suppose, BWOC, that
{h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} ∈ CandP gmaf (w, I ∪ (f, af  ))
(which, by Lemma 7, satisfies both Consistency and Inclusion) but does not satisfy Pertinence. As |AM (w) \ Xw | > 0, then f ∈ {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)}. This means
that {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} ⊇ Xw ∪ {f }, which also yields a contradiction.
(Only-If) Suppose, BWOC, that the operator satisfies Inclusion, Consistency Preservation, and Pertinence but there exists w s.t. {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} ∈
/
CandP gmaf (w, I ∪ (f, af  )). By Lemma 7, {h ∈ Θ ∪ Ω ∪ {f } | w |= af  (h)} ∈ V =
{X | ∃Y ∈ CandP gmaf (w, I ∪ (f, af  )) ∧ X ⊇ Y }. Hence, this would mean that
{h ∈ Θ ∪Ω ∪{f } | w |= af  (h)} ∈ Z = {X | ∃Y ∈ CandP gmaf (w, I ∪(f, af  ))∧X ⊃ Y }
in this case. However, this would violate Lemma 7 — a contradiction.
Lemma 9 Let I = (EM , AM , af ) be a consistent program, (f1 , af 1 ), (f2 , af 2 ) be two
I (I ) = W I (I ), then for all w ∈
inputs, and Ii = (EM , AM ∪ {fi }, af i ). If WEM
1
EM 2
I
WEM (I1 ) and all X ⊆ AM (w) we have that:
1.

2.

If {x | x ∈ X ∪ {f1 }, w |= af 1 (x)} is inconsistent ⇔ {x | x ∈ X ∪ {f2 }, w |= af 2 (x)}
is inconsistent, then {X \ {f1 } | X ∈ CandP gmaf (w, I1 )} = {X \ {f2 } | X ∈
CandP gmaf (w, I2 )}.
If {X \ {f1 } | X ∈ CandP gmaf (w, I1 )} =
{X \ {f2 } | X ∈ CandP gmaf (w, I2 )} then {x | x ∈ X ∪ {f1 }, w |= af 1 (x)} is
inconsistent ⇔ {x | x ∈ X ∪ {f2 }, w |= af 2 (x)} is inconsistent.

I (I ) and all X ⊆ 
Proof (If) Suppose BWOC that for all w ∈ WEM
AM (w); if {x | x ∈ X∪
1

{f1 }, w |= af 1 (x)} is inconsistent iff {x | x ∈ X ∪ {f2 }, w |= af 2 (x)} is inconsistent, but
there exists w s.t.
{X \ {f1 } | X ∈ CandP gmaf (w, I1 )}  = {X \ {f2 } | X ∈ CandP gmaf (w, I2 )}. However,
the pre-condition of this statement implies that {X \ {f1 } | X ⊆ CandP gmaf (w, I1 )} =
{X \ {f2 } | X ⊆ CandP gmaf (w, I2 ) which gives us a contradiction.
(Only-If) Suppose BWOC that for all w, {X \ {f1 } | X ∈ CandP gmaf (w, I1 )} = {X \
I (I ) and set X ⊆
{f2 } | X ∈ CandP gmaf (w, I2 )}, but there exists a world w ∈ WEM
1

AM (w) s.t. exactly one of {x | x ∈ X ∪ {f1 }, w |= af 1 (x)}, {x | x ∈ X ∪ {f2 }, w |=
af 2 (x)} is inconsistent. As a first case, let us assume that AM (w) ∪ {f1 } is consistent. As
{X\{f1 } | X ∈ CandP gmaf (w, I1 )} = {X\{f2 } | X ∈ CandP gmaf (w, I2 )}, this implies
that AM (w) ∪ {f2 } must also be consistent as each of those sets must then have exactly one
element. In this case a contradiction arises, hence both AM (w)∪{f1 }, AM (w)∪{f2 } must
be classically inconsistent. Now let us consider the other case. As AM (w) is consistent and

300

P. Shakarian et al.

all its subsets are consistent, then we must consider some X ⊆ AM (w) where X ∪ {f1 } is
not consistent. Hence, X ∪ {f2 } must be consistent. As AM (w) ∈ CandP gmaf (w, I2 ),
we know that X ∈ {X \ {f2 } | X ∈ CandP gmaf (w, I2 )} iff X ∪ {f2 } is consistent, so it
must be in that set. However, X ∈
/ {X \ {f1 } | X ∈ CandP gmaf (w, I1 )} as X ∪ {f1 } is not
consistent — this is a contradiction.

References
1. Alchourrón, C.E., Gärdenfors, P., Makinson, D.: On the logic of theory change: Partial meet contraction
and revision functions. J. Sym. Log. 50(2), 510–530 (1985)
2. Altheide, C.: Digital Forensics with Open Source Tools. Syngress (2011)
3. Bondarenko, A., Dung, P.M., Kowalski, R.A., Toni, F.: An abstract, argumentation-theoretic approach to
default reasoning. Artif. Intell. 93(1), 63–101 (1997)
4. Chesñevar, C.I., Simari, G.R., Alsinet, T., Godo, L.: A logic programming framework for possibilistic
argumentation with vague knowledge. In: Proceedings of UAI 2004, pp. 76–84 (2004)
5. Corp., S.: Stuxnet 0.5: Disrupting Uranium Processing at Natanz. Symantec Connect (2013). http://www.
symantec.com/connect/blogs/stuxnet-05-disrupting-uranium-processing-natanz
6. Doyle, J.: A truth maintenance system. Artif. Intell. 12(3), 231–272 (1979)
7. Dung, P.M.: On the acceptability of arguments and its fundamental role in nonmonotonic reasoning,
logic programming and n-person games. Artif. Intell. 77, 321–357 (1995)
8. Dunne, P.E., Hunter, A., McBurney, P., Parsons, S., Wooldridge, M.: Weighted argument systems: basic
definitions, algorithms, and complexity results. Artif. Intell. 175(2), 457–486 (2011)
9. Falappa, M.A., Garcı́a, A.J., Kern-Isberner, G., Simari, G.R.: On the evolving relation between belief
revision and argumentation. Knowl. Eng. Rev. 26(1), 35–43 (2011). doi:10.1017/S0269888910000391
10. Falappa, M.A., Kern-Isberner, G., Reis, M., Simari, G.R.: Prioritized and non-prioritized multiple change
on belief bases. J. Philosophical Logic 41(1), 77–113 (2012)
11. Falappa, M.A., Kern-Isberner, G., Simari, G.R.: Explanations, belief revision and defeasible reasoning.
Artif. Intell. 141(1/2), 1–28 (2002)
12. Falappa, M.A., Kern-Isberner, G., Simari, G.R.: Argumentation in artificial intelligence, chap. In:
Rahwan, I., Simari, G.R. (eds.) Belief Revision and Argumentation Theory, pp. 341–360. Springer
(2009)
13. Falliere, N., Murchu, L.O., Chien, E.: W32.Stuxnet Dossier Version 1.4. Symantec Corporation (2011)
14. Fazzinga, B., Flesca, S., Parisi, F.: On the complexity of probabilistic abstract argumentation. In:
Proceedings of IJCAI 2013, pp. 898–904 (2013)
15. Garcı́a, A.J., Simari, G.R.: Defeasible logic programming: an argumentative approach. TPLP 4(1–2),
95–138 (2004)
16. Gardenfors, P.: Knowledge in flux: modeling the dynamics of epistemic states. MIT Press, Cambridge
(1988)
17. Gärdenfors, P.: Belief revision, vol. 29. Cambridge University Press (2003)
18. Gottlob, G., Lukasiewicz, T., Martinez, M.V., Simari, G.I.: Query answering under probabilistic
uncertainty in Datalog+/– ontologies. AMAI, 37–72 (2013)
19. Haenni, R., Kohlas, J., Lehmann, N.: Probabilistic argumentation systems. Springer (1999)
20. Hansson, S.: Semi-revision. J. App. Non-Classical Logics 7(1–2), 151–175 (1997)
21. Hansson, S.O.: Kernel contraction. J. Symb. Log. 59(3), 845–859 (1994)
22. Heuer, R.J.: Psychology of Intelligence Analysis. Center for the Study of Intelligence (1999). http://
www.odci.gov/csi/books/19104/index.html
23. Hunter, A.: Some foundations for probabilistic abstract argumentation. In: Proceedings of COMMA
2012, pp. 117–128 (2012)
24. Hunter, A.: A probabilistic approach to modelling uncertain logical arguments. Int. J. Approx. Reasoning
54(1), 47–81 (2013)
25. Khuller, S., Martinez, M.V., Nau, D.S., Sliva, A., Simari, G.I., Subrahmanian, V.S.: Computing most
probable worlds of action probabilistic logic programs: scalable estimation for 1030,000 worlds. AMAI
51(2–4), 295–331 (2007)
26. Krause, P., Ambler, S., Elvang-Gørannson, M., Fox, J.: A logic of argumentation for reasoning under
uncertainty. Comput. Intell. 11(1), 113–131 (1995)
27. Langner, R.: Matching Langner Stuxnet analysis and Symantic dossier update. Langner Communications
GmbH (2011). http://www.langner.com/

Belief revision in structured probabilistic argumentation

301

28. Li, H., Oren, N., Norman, T.J.: Probabilistic argumentation frameworks. In: Proceedings of TAFA, pp. 1–
16 (2011)
29. Lloyd, J.W.: Foundations of Logic Programming, 2nd edn. Springer (1987)
30. Martinez, M.V., Garcı́a, A.J., Simari, G.R.: On the use of presumptions in structured defeasible
reasoning. In: Proceedings of COMMA, pp. 185–196 (2012)
31. Modgil, S., Prakken, H.: A general account of argumentation with preferences. Artif. Intell. 195, 361–
397 (2013)
32. Nilsson, N.J.: Probabilistic logic. Artif. Intell. 28(1), 71–87 (1986)
33. Prakken, H.: An abstract framework for argumentation with structured arguments. Argument and
Computation 1, 93–124 (2010)
34. Rahwan, I., Simari, G.R.: Argumentation in Artificial Intelligence. Springer (2009)
35. Richardson, M., Domingos, P.: Markov logic networks. Mach. Learn. 62(1–2), 107–136 (2006)
36. Riley, L., Atkinson, K., Payne, T., Black, E.: An implemented dialogue system for inquiry and persuasion. In: Theory and Applications of Formal Argumentation, Lecture Notes in Computer Science,
pp. 67–84. Springer, Berlin (2011)
37. Shadows in the Cloud: Investigating Cyber Espionage 2.0. Tech. rep., Information Warfare Monitor &
Shadowserver Foundation (2010)
38. Shafer, G., et al.: A mathematical theory of evidence, vol. 1. Princeton University Press, Princeton (1976)
39. Shakarian, P., Shakarian, J., Ruef, A.: Introduction to Cyber-Warfare: A Multidisciplinary Approach.
Syngress (2013)
40. Shakarian, P., Simari, G.I., Falappa, M.A.: Belief revision in structured probabilistic argumentation. In:
Proceedings of Foundations of Information and Knowledge Systems, pp. 324–343 (2014)
41. Shakarian, P., Simari, G.I., Moores, G., Parsons, S., Falappa, M.A.: An argumentation-based framework
to address the attribution problem in cyber-warfare. In: Proceedings of Cyber Security (2014)
42. Simari, G.I., Martinez, M.V., Sliva, A., Subrahmanian, V.S.: Focused most probable world computations
in probabilistic logic programs. AMAI 64(2–3), 113–143 (2012)
43. Simari, G.R., Loui, R.P.: A mathematical treatment of defeasible reasoning and its implementation. Artif.
Intell. 53(2–3), 125–157 (1992)
44. Spitzner, L.: Honeypots: catching the insider threat. In: Proceedings of ACSAC 2003, pp. 170–179. IEEE
Computer Society (2003)
45. Stolzenburg, F., Garcı́a, A., Chesñevar, C.I., Simari, G.R.: Computing generalized specificity. J NonClassical Logics 13(1), 87–113 (2003)
46. Thimm, M.: A probabilistic semantics for abstract argumentation. In: Proceedings of ECAI 2012,
pp. 750–755 (2012)
47. Thonnard, O., Mees, W., Dacier, M.: On a multicriteria clustering approach for attack attribution.
SIGKDD Explor. 12(1), 11–20 (2010)

empirStudySIRpreprint

23 August 2012

1:40

1

Preprint

arXiv:1208.4269v2 [cs.SI] 22 Aug 2012

Spreaders in the Network SIR Model:
An Empirical Study
Brian Macdonald1,2,5 , Paulo Shakarian1,3,5 , Nicholas Howard1,2 , & Geoffrey Moores1,3,4
1 Network Science Center, United States Military Academy, West Point, NY 10996
2 Department of Mathematical Sciences, United States Military Academy, West Point, NY
10996
3 Department of Electrical Engineering and Computer Science, United States Military
Academy, West Point, NY 10996
4 Department of Physics, United States Military Academy, West Point, NY 10996
5 These authors contibuted equally to this work.
(e-mail:
brian.macdonald@usma.edu,paulo@shakarian.net,nicholas.howard@usma.edu,geoffrey.moores@usma.edu)

Abstract
We use the susceptible-infected-recovered (SIR) model for disease spread over a network, and empirically study how well various centrality measures perform at identifying which nodes in a network
will be the best spreaders of disease on 10 real-world networks. We find that the relative performance
of degree, shell number and other centrality measures can be sensitive to β , the probability that an
infected node will transmit the disease to a susceptible node. We also find that eigenvector centrality
performs very well in general for values of β above the epidemic threshold.

1 Introduction
The susceptible-infected-recovered (SIR) model, first introduced in Anderson & May (1979)
is a popular model for disease spread. In recent years, this model has been applied to social
networks - situations where the interactions of individuals are modeled as a graph. A key
problem relating to this model when considering a network structure is how to identify
the nodes that, if initially infected, will result in the greatest portion of the population
(in expectation) also becoming infected. These nodes are often referred to as “spreaders.”
Unfortunately, a modification of the proof of a related problem in Chen et al. (2010)
shows that exactly computing the expected number of infected individuals in a networkedstructured population given a single initial infectee is #P-hard. This implies that solving
this problem exactly is likely beyond the ability of today’s computer systems. However,
the literature on complex networks has provided various centrality measures that can be
used as heuristics. So, inspired by the work of Kitsak et al. (2010), which empirically
examines the use of degree, betweenness, and shell number for identifying spreaders, we
conduct a comprehensive evaluation of 10 different centrality measures on 10 real-world
social network data-sets from various domains (e-mail, disease spread, blogging, power,
autonomous system, and collaboration). The major contributions of our work are two-

empirStudySIRpreprint

2

23 August 2012

1:40

Macdonald et al.

Fig. 1. Imprecision versus p for the cond-mat network with β = 11.17. Notice that for this
β , k-shell has a lower imprecision, meaning that k-shell outperforms degree. See Section 3
for the definitions of imprecision function and p.
fold. First, we show that the ability of a centrality measure to identify spreaders in the
SIR model can be sensitive to the β parameter, the probability of infection. Second, we
find that, in general, eigenvector centrality performs very well for values of β above the
epidemic threshold.
With respect to our first major contribution, we carefully selected the β parameter based
on β 0 , the epidemic threshold of the network. We can be sure that a contagion can spread to
a significant portion of the network for β > β 0 , and we studied a variety of different values
for β above this threshold.
In Figure 1 and 2, we give an example of a network where shell number outperforms
degree for one value of β , but degree outperforms shell number for another value of β . In
Section 5, we give additional examples illustrating that the imprecision functions of other
centrality measures, as well as the choice of the “best” centrality measure, can be sensitive
to β as well.
As for our second major contribution, we found that eigenvector centrality consistently
outperformed all other measures considered, including both shell number and degree (which
were considered by Kitsak et al.), in all but one of the networks examined. See Figure 3
for a comparison of k-shell (the best performing centrality measure of Kitsak et al.) with
eigenvector centrality. Also, if we average over all of our networks, including the one where
eigenvector was not the best, we find that, on average, eigenvector centrality outperforms
the other measures.
The rest of this paper is organized as follows. In Section 2, we review the SIR model,
discuss how the #P-hardness proof of Chen et al. (2010) applies to this model, and describe
how we calculate the epidemic threshold of a given complex network. This is followed by

empirStudySIRpreprint

23 August 2012

1:40

Network Science

3

Fig. 2. Imprecision plots vs. p for the cond-mat network with β = 15.95. Notice that
for this β , degree has a lower imprecision, meaning that degree outperforms k-shell, the
opposite of what we saw in Figure 1.
a discussion of the various centrality measures we considered in Section 3 along with a
review of the description of the “imprecision function” Kitsak et al. (2010) used to measure
the effectiveness of a centrality measure in identifying the top spreaders in a network.
We describe our experimental setup and datasets in Section 4 and give a description and
discussion of the experimental results in Section 5.

2 The SIR Model
As in Kitsak et al. (2010), we consider the classic susceptible-infected-recovered (SIR)
model of disease spread introduced in Anderson & May (1979). In this model, all nodes
in the network are in one of three states: susceptible (able to be infected), infected, or
recovered (no longer able to infect or be infected). At each time step, any node infected
in the last time step can infect any of its neighbors who are in a susceptible state with a
probability β . After that time step, any node previously in an infected state moves into a
recovered state and is no longer able to infect or be infected.

2.1 Complexity
In J. Goldenberg (2001) and Kempe et al. (2003), the authors present a generalization of the
SIR model known as the independent cascade (IC) model. In this model, the β parameter
can be different for each edge in the network. They define the influence spread of a set of
nodes as the expected number of individuals in the population infected under the IC model
given that the set was initially infected. In Chen et al. (2010) this problem was shown to be

empirStudySIRpreprint

4

23 August 2012

1:40

Macdonald et al.

Fig. 3. Imprecision of k-shell minus the imprecision of eigenvector centrality. Positive
values indicate that k-shell has a higher imprecision than eigenvector centrality, which
means that eigenvector centrality typically outperforms k-shell.
#P-hard. Here we reconsider their proof, with some modification, to identify the influence
spread of single node under the SIR model.
Theorem 2.1
Calculating the influence spread of a single node under the SIR models is #P-hard.
Proof
We prove this theorem by showing a reduction from the known #P-complete problem s − t
connectivity Valiant (1979). Let G = (V, E) be a directed graph, where V denotes the set of
vertices, and E denotes the set of edges. Given two vertices s,t ∈ V , the goal is to determine
the number of subgraphs of G where s is connected to t. In Chen et al. (2010), the authors
point out that it is easy to see that this is equivalent to computing the probability that s is
connected to t when each edge in G has an independent probability of 0.5 to be connected
(and 0.5 to be disconnected). Hence, to embed the s − t connectivity problem into the
influence spread on the SIR model, we first calculate Ms , the expected number of infectees
given initially infected node s with β = 50. We then create G0 which is equivalent to G but
has an additional directed edge from t to a new node t 0 . Let Ms0 be the influence spread when
we consider graph G0 . If p(s,t, G) is the probability that t is influenced by s in G (hence the
β
. Therefore, the
solution to the s − t connectivity problem) then Ms0 = Ms + p(s,t, G) · 100
solution to the s − t connectivity problem can easily be obtained in polynomial time if we
can efficiently find a solution to the influence spread problem under the SIR model.
Theorem 2.1 tells us that exact methods for identifying the influence spread of individual
nodes under the SIR models is likely not possible with today’s computer systems. Further,
as s − t connectivity has no known efficient approximation algorithm with a guarantee
of accuracy, an approximation scheme for influence spread also seems unlikely. Hence,
much work on influence spread such as Kempe et al. (2003) relies on estimating influence

empirStudySIRpreprint

23 August 2012

1:40

Network Science

5

spread using simulation, which is often expensive computationally and even impractical
for very large networks. Therefore, in this paper, we look to evaluate various centrality
measures from the literature as heuristics to identify spreaders under the SIR model. We
describe these centrality measures in Section 3. Note that the centrality measures are not
specifically designed to calculate influence spread under the SIR model, and they do not
account for the infection probability β . In the next section, we describe how we select the
different β parameters for the model in our experiments.

2.2 Selecting the Infection Probability
We note that for scale-free networks, having degree distribution P(k) ∼ k−γ , the literature
shows that for γ ≤ 3, the epidemic threshold of β approaches 0 as the number of nodes goes
to infinity Callaway et al. (2000); Cohen et al. (2000). However, the networks we examine
are of finite size and have various levels of “scale-freeness”, based on the R2 value of the
linear correlation of a log-log plot of the degree distribution (see Section 4 for details).
Instead, we explored β values based on the epidemic threshold calculation in Madar et al.
(2004). Using this method, the SIR model is mapped onto a bond percolation process.
Assuming a randomly connected network, the average number of influenced neighbors,
hni can be written
P(k) · k · (k − 1)
hni = β · ∑
,
(1)
hki
k
where k is the degree of a node, P(k) is the probability of a node having degree k, and hki
is the average degree. Since an epidemic state can only be reached when hni > 1, and from
(1) we have
!−1
P(k) · k · (k − 1)
β> ∑
= β 0.
(2)
hki
k
We note that there is some work discussing the effect of different infection probabilities
on spreading in Kitsak et al. (2010) and more recent and comprehensive study on the topic
in Castellano & Pastor-Satorras (2012). These works consider the effect of this parameter
with respect to degree and shell decomposition (and betweenness in Kitsak et al. (2010)).
Here we consider these and many other centrality measures, and find that some of them,
such as eigenvector centrality, outperform those in these previous works.

3 Centrality Measures
We now describe the centrality measures that we examine in our experiments. We note
that the major centrality measures in the literature can be classified as either radial (the
quantity of certain paths originating from the node) or medial (the quantity of certain paths
passing through the node) as done in Borgatti and Everett Borgatti & Everett (2006). Based
on the negative result concerning betweenness of Kitsak et al. (2010) and the intuitive
association between high-radial nodes and spreading, we focused our efforts on radial
measures. While the work of Kitsak et al. (2010) compares shell number to degree and
betweenness, we consider several other well-known radial measures in addition to degree,

empirStudySIRpreprint

6

23 August 2012

1:40

Macdonald et al.

including closeness and eigenvector centrality. As done in Kitsak et al. (2010), we also
develop “imprecision functions” for these centrality measures.

3.1 Degree Centrality
Of all the measures that we are examining, degree is perhaps the most simplistic measure simply the total of incident edges for a given node. As noted throughout the literature, such
as Wasserman & Faust (1994), it is perhaps the easiest centrality measure to compute.
Further, in other diffusion processes, such as the voter model on undirected networks
in Antal et al. (2006), it has been shown to be proportional to the expected number of
individuals becoming infected1 . As pointed out in Borgatti & Everett (2006), degree is a
radial measure as it is the number of paths starting from a node of length 1. Degree is one
of three measures considered in Kitsak et al. (2010).

3.2 Shell Number
The other radial measure considered in Kitsak et al. (2010), shell number, or “k-shell
number”, is determined using shell decomposition Seidman (1983). High shell-number
nodes in the network are often referred to as the “core” and are regarded by Kitsak et al.
(2010) as influential spreaders under the SIR model. Our results described later in the
paper confirm this finding, although we also show that k-shell number was generally outperformed by eigenvector centrality. There have also been some more practical applications
of this technique to find key nodes in a network. For instance, Borge-Holthoefer & Moreno
(2012); Borge-Holthoefer et al. (2012) uses shell-decomposition to find individuals likely
to initiate information cascades in an online social network while Carmi et al. (2007) uses
it to identify key nodes in a subset of autonomous systems on the Internet.
An example of this process is shown in Figure 4. Given graph G = (V, E), shell decomposition partitions a graph into shells and is described in the algorithm below.
Let ki be the degree of node i. Set S = 1. Let VS denote the first shell of G.
while |V | > 0 do
while There exists i such that ki = S do
Remove all i ∈ V where ki = S;
Also, remove all corresponding adjacent edges.
Place removed nodes into shell VS .
end while
S++
end while

1

Technically, the work of Antal et al. (2006) proves that the fixation probability for a single mutant
invader is proportional to the degree of that node. However, the expected number of mutants, in
the limit as time goes to infinity, can simply be computed by multiplying fixation probability by
the number of nodes in thee network.

empirStudySIRpreprint

23 August 2012

1:40

Network Science

7

Fig. 4. Consider the progression of the graph above, where the elimination of nodes with
degree 1 occurs in B and C. D represents the first iteration for the second shell, and E
represents the complete second shell (as well as the first). F finalizes the decomposition
with the third shell.

3.3 Betweenness Centrality
The intuition behind high betweenness centrality nodes is that they function as “bottlenecks” as many paths in the network pass through them. Hence, betweenness is a medial
centrality measure. Let σst be the number of shortest paths between nodes s and t and σst (v)
be the number of shortest paths between s and t containing node v. In Freeman (1977),
betweenness centrality for node v is defined as ∑s6=v6=t σstσst(v) . In most implementations,
including the ones used in this paper, the algorithm of Brandes (2001) is used to calculate
betweenness centrality.

3.4 Closeness Centrality
Another common measure from the literature that we examined is closeness Freeman
(1979). Given node i, its closeness Cc (i) is the inverse of the average shortest path length
from node i to all other nodes in the graph. Intuitively, closeness measures how “close” it
is to all other nodes in a graph.

empirStudySIRpreprint

23 August 2012

1:40

8

Macdonald et al.

Formally, if we define the shortest path between nodes i to j as function dG (i, j), we can
express the average path length from i to all other nodes as
Li =

∑ j∈V \i dG (i, j)
.
|V | − 1

(3)

Hence, the closeness of a node can be formally written as
Cc (i) =

1
|V | − 1
=
.
Li
∑ j∈V \i dG (i, j)

(4)

3.5 Eigenvector Centrality
The use of the principle eigenvector of the adjacency matrix of a network was first proposed as a centrality measure in Bonacich (1972). Hence, the intuition behind eigenvector
centrality is that it measures the influence of a node based on the sum of the influences of
its adjacent nodes. Given a network V = (G, E) with adjacency matrix A = (ai j ), where
ai j = 1 if an edge exists between nodes i and j, the eigenvector centrality of node i satisfies
xi =

1
λ

∑ ai j x j ,

(5)

j∈V

for some λ . If we define x to be the vector of xi ’s, this relationship can be expressed as
1
Ax, or Ax = λ x,
(6)
λ
which is the familiar equation relating A with its eigenvalues and eigenvector. The eigenvector centralities for the network are the entries of the eigenvector corresponding to the
largest real eigenvalue.
x=

3.6 PageRank
PageRank, introduced in Page et al. (1998), is computed for each node based on the
PageRank of its neighbors. Where E is the set of undirected edges, Rv , dv is the PageRank
and degree of v, and c is a normalization constant, we have the relationship
Rv = c ·

Rv0
.
d0
v0 |(v,v )∈E v

∑0

An initial value for rank is entered for each node and the relationship is then computed
iteratively until convergence is reached. Intuitively, PageRank can be thought of as the
importance of a node based on the importance of its neighbors.
3.7 Neighborhood
The next centrality measure we consider is the “neighborhood.” Given a natural number q,
the q-neighborhood of vertex i is the number of nodes in the network that are distance
q or closer from node i. For example, for q = 0, this metric is 1 for every node. For
q = 1, this metric is identical to degree centrality of node i, since it is the number of

empirStudySIRpreprint

23 August 2012

1:40

Network Science

9

nodes within a distance 1 of i. For q = 2, this metric counts the number of nodes within a
distance 2 of i, so it counts i’s neighbors along with its neighbors’ neighbors. In our work,
we computed neighborhoods using q = 2, 3, 5, 10, and denoted these measures by nghd2,
nghd3, nghd5, and nghd10, respectively. We note that the work of Chen et al. (2012)
develops a centrality measure with a similar intuition to the neighborhood and show it
preforms well in identifying influential spreaders.
3.8 The Imprecision Functions
We now define the imprecision functions from Kitsak et al. (2010) that are used to measure
the effectiveness of a centrality measure in identifying influential spreaders. We also extend
their definition for all centrality measures explored in this paper. Let N denote the number
of nodes, and let p be a real number between 0 and 100. The pN/100 highest efficiency
spreaders, ϒe f f (p), are chosen based on number of nodes infected Mi per node. Similarly, a
set ϒks (p) is defined as the pN/100 predicted most efficient spreaders, chosen with priority
to highest ks valued nodes. Let
Me f f (p) =

Mi
pN , and

(7)

Mi
pN .

(8)

Mks (p)
Me f f (p)

(9)

∑
i∈ϒe f f (p)

Mks (p)

=

∑
i∈ϒks (p)

The imprecision function of ks , εks (p), is defined as
εks (p) = 1 −
Similarly, εeig (p) and εdeg (p) are defined as
(p)

M

εeig (p) = 1 − M eig (p) ,
ef f

εdeg (p)

M

(p)

= 1 − Mdeg (p)
ef f

(10)
(11)

In general, for any centrality measure c, the imprecision function εc (p) is defined as
εc (p) = 1 −

Mc (p)
Me f f (p)

(12)

4 Experimental Setup
In this section we describe our experimental setup and the datasets we used. All simulation
and centrality analysis was done in Version 2.14.1 of R R Development Core Team (2011).
The operating system used was Windows Vista Enterprise (32 bit) and the computer had
an Intel Core 2 Quad CPU (Q9650) 3.0 GHz with 4 GB of RAM. Run times to analyze
the networks ranged from several hours for the small networks to several days for the
larger ones. Centrality measures were computed using the igraph Csardi & Nepusz (2006)
package in R.
We obtained our datasets from a variety of sources. Brief descriptions of these networks
are as follows:

empirStudySIRpreprint

10

23 August 2012

1:40

Macdonald et al.

cond-mat-GCC is an academic collaboration network from the e-print arXiv and covers
scientific collaborations between authors’ papers submitted to Condensed Matter category
from 1999 Newman (2011).
ca-GrQc-GCC is an academic collaboration network from the e-print arXiv and covers
scientific collaborations between authors’ papers submitted to the General Relativity and
Quantum Cosmology category from Jan. 1993 - Apr. 2003 Leskovec (2012).
urv-email is an e-mail network based on communications of members of the University
Rovira i Virgili (Tarragona) Arenas (2012). It was extracted in 2003.
1-edges-GCC is a network formed from YouTube, the video-sharing website that allows
users to establish friendship links Zafarani & Liu (2009). The sample was extracted in
Dec. 2008. Links represent two individuals sharing one or more subscriptions to channels
on YouTube.
std-GCC is an online sex community in Brazil in which links represent that one of the
individuals posted online about a sexual experience with the other individual, resulting in
a bipartite graph. The data was extracted from September of 2002 to October of 2008 Luis
E. C. Rocha & Holme (2010).
as20000102 is a one day snapshot of Internet routers as constructed from the border
gateway protocol logs Leskovec (2012). It was extracted on Jan 2nd, 2000.
oregon 010331 is a network of Internet routers over a one week period as inferred from
Oregon route-views, looking glass data, and routing registry from covering the week of
March 3rd, 2001 Leskovec (2012).
ca-HepTh-GCC is a collaboration network from the e-print arXiv and covers scientific
collaborations between authors’ papers submitted to the High Energy Physics - Theory
category. It covers paper from Jan 1993 to Apr 2003 Leskovec (2012).
as-22July06 is a snapshot of the Internet on 22 July 2006 at the autonomous systems level
compiled by Mark Newman Newman (2011).
netscience-GCC is a network of coauthorship of scientists working on network theory and
experiments compiled by Mark Newman in May 2006 Newman (2011).
All datasets used in this paper were obtained from one of four sources: the ASU Social Computing Data Repository Zafarani & Liu (2009), the Stanford Network Analysis
Project Leskovec (2012), Mark Newman’s data repository at the University of Michigan Newman (2011), and Universitat Rovira i Virgili Arenas (2012). All networks considered were symmetric; i.e., if a directed edge from vertex v to v0 exists, there is also an
edge from vertex v0 to v. Summary statistics for these networks can be found in Table 1.
In the cases where the network had more than one component, we used only the greatest
connected component. We append the suffix “-GCC” when referring to those networks. For
example, the cond-mat network had more than one component, so we will use the greatest
connected component and refer to this network as “cond-mat-GCC”.
As seen in the Table 1, all networks used are approximately scale free. This does not infer
that they were generated using a preferential attachment model (as introduced in AlbertLszl Barabsi (1999)), as many mechanisms can be responsible for generating scale free
networks. If they were generated using a preferential attachment model then we would see
a correlation between shell number and degree. This would also mean that degree centrality
and shell number would have little difference in predicting spreaders, but our simulations

empirStudySIRpreprint

23 August 2012

1:40

11

Network Science
Name

Type

Nodes Edges Density

1-edges-GCC
as20000102
ca-GrQc-GCC
cond-mat-GCC
oregon2 010331
std-GCC
urv-email
ca-HepTh-GCC
as-22July2006
netscience-GCC

online
router
collab
collab
router
std
email
collab
router
collab

13679
6474
4158
13861
10900
15810
1133
8638
22963
379

76741
12572
13422
44619
31180
38540
5451
24806
48436
914

β0

0.0008 2.3
0.0006 0.6
0.0016 6.3
0.0005 8.4
0.0005 0.5
0.0003 3.7
0.0085 5.7
0.0007 8.3
0.0002 0.4
0.0127 14.2

λ
1.8
1.2
2.0
2.4
1.2
1.9
1.5
2.2
1.2
1.6

R2

hki

hk2 i KS

0.90 11.2 502.6 25
0.73 3.9 640.0 12
0.88 5.5
93.2 43
0.93 5.9
75.6 17
0.79 5.7 1188.8 31
0.92 4.7 130.9 11
0.84 9.6 179.8 11
0.90 5.7
74.6 31
0.72 4.2 1103.0 25
0.76 4.8
38.7 8

Table 1. Network Summary Statistics. Note that β 0 is the minimum threshold of infection
rate for the epidemic to spread to a significant portion of the network, λ is exponent of the
power law of the degree distribution, R2 is goodness of fit between the power law and the
degree distribution, hki and hk2 i are the first and second moments of the degree distribution,
and KS is the maximum shell present in the network.
show otherwise. Figure 5 shows an example in which degree and shell number are not
correlated.

5 Results
Earlier we noted that (1) the relative performance of degree, shell number and other centrality measures can depend on the β parameter of the SIR model, and (2) eigenvector centrality performs very well in general regardless of the value of β used, typically outperforming
all of the other centrality measures that we tried. Here we present more results illustrating
these two points. Unless otherwise specified, the β values that we used when plotting
the imprecision function versus β are 1.1β 0 , 1.2β 0 , . . . , 2.0β 0 , where β 0 is the epidemic
threshold for the network in question.
5.1 Sensitivity to β
In Figures 1 and 2, we saw that the performance of degree relative to shell number changes
with β for the cond-mat network. For β = 11.17, shell number was a better indicator
of spreading, but for β = 15.95, degree was better. Another way that we could depict
this dependence on β is to fix p and plot the imprecision versus β , instead of fixing β
and plotting the imprecision versus p. In Figure 6, we fix p = 5 and plot the imprecision
function of degree, shell number, and eigenvector centrality versus β , for β between 11.17
and 15.95. Notice that at around β = 14, degree begins to outperform shell number.
The relative performance of other centrality measures can change as well. In Figure
7, we plot the imprecision functions of degree, shell number, eigenvector, and closeness
centrality versus β for p = 5. In this network, for β near β 0 , degree and shell number
perform very well. However, as β increases, the imprecision functions of those measures

empirStudySIRpreprint

12

23 August 2012

1:40

Macdonald et al.

Fig. 5. In the higher shells of these two examples, degree and shell number are not
correlated, indicating these can not be assumed to be generated by preferential attachment
models. The red line shows the average degree of each shell. Note that log scales are being
used on both axes.
increase, and other measures, like closeness and eigenvector, outperform degree and shell
number.
5.2 Eigenvector centrality
As we saw in Figure 3, eigenvector centrality outperforms shell number for all but one
of the networks we examined. Eigenvector centrality also typically outperforms all of the
other centrality measures that we tried. In Figure 8, we plot the imprecision functions of
several different centrality measures for the cond-mat network. We see that eigenvector
centrality performs best for this network. In Figures 9, 10, 11, and 12, we give an example
of a collaboration network, an online network, an STD network, and an email network in
which eigenvector performs best.
Eigenvector centrality did not outperform shell number for the ca-HepTh network, so we
can not conclude that eigenvector centrality performs best for every network that we tried.
However, it does seem that, on average, for the networks we tried, eigenvector centrality
performed best for β = 1.1β 0 , 1.2β 0 , ..., 2.0β 0 . Suppose we take the imprecision functions
for β = 1.1β 0 for each network, and we average these imprecision functions over all of our
networks, including the ca-HepTh network. This would be one way to check how well each

empirStudySIRpreprint

23 August 2012

1:40

Network Science

13

Fig. 6. Imprecision vs β for the cond-mat network. The relative performance of degree and
shell number changes near β = 14.

Fig. 7. Imprecision vs β for the ca-GrQc-GCC network.

empirStudySIRpreprint

14

23 August 2012

1:40

Macdonald et al.

Fig. 8. Imprecision vs p for the cond-mat-GCC network with β = 1.1β 0 = 8.77. We see
that eigenvalue centrality performs best for this network.
centrality measure performs on average. In Figure 13, we plot this the average imprecision
versus p for β = 1.1β 0 . We see that, on average, eigenvector centrality outperforms the
other measures. The measure nghd2 performed well also. We give similar figures for β =
1.5β 0 and β = 2.0β 0 in Figures 14 and 15. In both cases, eigenvector centrality outperforms
all of the other measures.
We believe that eigenvector centrality performs well for some of the same reasons that
shell number performs well. A node has high eigenvector centrality when the node and
its neighbors have high degree. Nghd2, nghd3, and the closely related measure of Chen
et al. (2012) also perform well for this reason. A hub, or a node with high degree, in the
periphery of a network, which does not have many neighbors with high degree, will not
typically be as good of a spreader as a node with high eigenvector centrality.
5.3 Large values of β
In Kitsak et al. (2010), only relatively small values for β were explored as it was noted
that larger values of β would likely cause spreading to a large portion of the population
regardless of the location of the initially infected node. However, in the networks we
studied, we found a difference in the ability of the starting node to spread even at seven
times the epidemic threshold. Further, the result that eigenvector centrality performs best,
based on average imprecision over all the networks, still holds for these larger values of
β . We display our imprecision functions for larger values of β in Figure 16. We also show
that for five times the epidemic threshold, eigenvector centrality still outperforms the other
centrality measures for different values of p (Figure 17).

empirStudySIRpreprint

23 August 2012

1:40

Network Science

15

Fig. 9. Imprecision vs p for the netscience-GCC network with β = 1.1β 0 = 15.67. We see
that eigenvalue centrality performs best for this network.

Fig. 10. Imprecision vs p for the 1-edges-GCC network with β = 1.1β 0 = 2.50. We see
that eigenvalue centrality performs best for this network.

empirStudySIRpreprint

16

23 August 2012

1:40

Macdonald et al.

Fig. 11. Imprecision vs p for the std-GCC network with β = 1.1β 0 = 4.01. We see that
eigenvalue centrality performs best for this network.

Fig. 12. Imprecision vs p for the urv-email network with β = 1.1β 0 = 6.22. We see that
eigenvalue centrality performs best for this network.

empirStudySIRpreprint

23 August 2012

1:40

Network Science

17

Fig. 13. Average Imprecision vs p with β = 1.1β 0 , where the average is taken over all
networks that we considered.

Fig. 14. Average Imprecision vs p with β = 1.5β 0 , where the average is taken over all
networks that we considered. We see that, on average, eigenvector performs best.

empirStudySIRpreprint

18

23 August 2012

1:40

Macdonald et al.

Fig. 15. Average Imprecision vs p with β = 2.0β 0 , where the average is taken over all
networks that we considered. We see that, on average, eigenvector performs best.

Fig. 16. Average Imprecision vs. β with p = 5. We see that, on average, eigenvector
performs best.

empirStudySIRpreprint

23 August 2012

1:40

Network Science

19

Fig. 17. Average Imprecision vs. p with β = 5β 0 , where the average is taken over all
networks that we considered. We see that, on average, eigenvector performs best.

empirStudySIRpreprint

20

23 August 2012

1:40

Macdonald et al.
6 Conclusions and Future Work

These new experiments provide further insight into the issue of identifying spreaders in
complex networks that was initiated by Kitsak et al. (2010). We extended their work by
studying multiple values of the infection probability β and showed that the relative ability
for centrality measures to identify spreaders often depends on this parameter. We also
noted that eigenvector centrality consistently outperforms the other centrality measures,
usually independent of β . Future work on identifying influential spreaders could include
identifying nodes that not only cause significant spreading, but do so quickly, thus accounting for the time it takes for individuals in the population to become infected. Further,
it would be also interesting to examine which centrality measures best identify spreaders in
non-monotonic models of diffusion processes, such as the voter model. Another aspect for
future work would be to examine group centrality. In other words, one could use a centrality
measure on sets of nodes to identify the best set of spreaders under the SIR model Moores
et al. (2012). Finally, it is also worth empirically studying centrality measures designed
specifically for the SIR model or other diffusion process, as described in recent work such
as Klemm et al. (2012) and Kang et al. (2012). However, we note that one key advantage
to the approach taken in this paper is that the centrality measures studied are already well
established - and hence common in many software tools for complex network analysis.

empirStudySIRpreprint

23 August 2012

1:40

*

21

Acknowledgments
Some of the authors of this paper are supported under OSD project F1AF262025G001 and
ARO project 2GDATXR042. The authors are very thankful to these organizations for their
support.
We would like to thank Jon Bentley for his feedback on an earlier version of this paper.
The views expressed in this article are those of the authors and do not reflect the official
policy or position of the United States Military Academy, the Department of the Army,
the Department of Defense, the United States Government, or any of the listed funding
agencies.
Bibliography
Albert-Lszl Barabsi, Rka Albert. (1999). Emergence of scaling in random networks.
286(5439), 509–512.
Anderson, Roy M., & May, Robert M. (1979). Population biology of infectious diseases:
Part i. Nature, 280(5721), 361.
Antal, T., Redner, S., & Sood, V. (2006). Evolutionary dynamics on degree-heterogeneous
graphs. Physical review letters, 96(18), 188104.
Arenas, Alex. (2012). Network data sets.
Bonacich, Phillip. (1972). Factoring and weighting approaches to status scores and clique
identification. The journal of mathematical sociology, 2(1), 113–120.
Borgatti, S., & Everett, M. (2006). A Graph-theoretic perspective on centrality. Social
networks, 28(4), 466–484.
Borge-Holthoefer, Javier, & Moreno, Yamir. (2012). Absence of influential spreaders in
rumor dynamics. Phys. rev. e, 85(026116).
Borge-Holthoefer, Javier, Rivero, Alejandro, & Moreno, Yamir. (2012). Locating
privileged spreaders on an online social network. Phys. rev. e, 85(Jun), 066123.
Brandes, Ulrik. (2001). A faster algorithm for betweenness centrality. Journal of
mathematical sociology, 25(163).
Callaway, Duncan S., Newman, M. E. J., Strogatz, Steven H., & Watts, Duncan J. (2000).
Network robustness and fragility: Percolation on random graphs. Phys. rev. lett.,
85(Dec), 5468–5471.
Carmi, Shai, Havlin, Shlomo, Kirkpatrick, Scott, Shavitt, Yuval, & Shir, Eran. (2007).
From the Cover: A model of Internet topology using k-shell decomposition. Pnas,
104(27), 11150–11154.
Castellano, & Pastor-Satorras, Romualdo. (2012). Competing activation mechanisms in
epidemics on networks. Scientific reports, 2(371).
Chen, Duanbing, L, Linyuan, Shang, Ming-Sheng, Zhang, Yi-Cheng, & Zhou, Tao. (2012).
Identifying influential nodes in complex networks. Physica a: Statistical mechanics and
its applications, 391(4), 1777 – 1787.
Chen, Wei, Wang, Chi, & Wang, Yajun. (2010). Scalable influence maximization
for prevalent viral marketing in large-scale social networks. Pages 1029–1038 of:
Proceedings of the 16th acm sigkdd international conference on knowledge discovery
and data mining. KDD ’10. New York, NY, USA: ACM.
Cohen, Reuven, Erez, Keren, ben Avraham, Daniel, & Havlin, Shlomo. (2000). Resilience
of the Internet to Random Breakdowns. Physical review letters, 85(21), 4626–4628.

empirStudySIRpreprint

22

23 August 2012

1:40

Macdonald et al.

Csardi, Gabor, & Nepusz, Tamas. (2006). The igraph software package for complex
network research. Interjournal, Complex Systems, 1695.
Freeman, Linton C. (1977). A set of measures of centrality based on betweenness.
Sociometry, 40(1), pp. 35–41.
Freeman, Linton C. (1979). Centrality in social networks conceptual clarification. Social
networks, 1(3), 215 – 239.
J. Goldenberg, B. Libai, E. Muller. (2001). Talk of the network: A complex systems look
at the underlying process of word-of-mouth. Marketing letters, 12(3), 211.
Kang, C., Molinaro, C., Kraus, S., Shavitt, Y., & Subrahmanian, V.S. 2012 (Aug.).
Diffusion centrality in social networks. Proc. 2012 ieee/acm intl. conf. on advances
in social networks analysis and mining (asonam-12).
Kempe, David, Kleinberg, Jon, & Tardos, Éva. (2003). Maximizing the spread of influence
through a social network. Pages 137–146 of: Kdd ’03: Proceedings of the ninth acm
sigkdd international conference on knowledge discovery and data mining. New York,
NY, USA: ACM.
Kitsak, Maksim, Gallos, Lazaros K., Havlin, Shlomo, Liljeros, Fredrik, Muchnik, Lev,
Stanley, H. Eugene, & Makse, Hernan A. (2010). Identification of influential spreaders
in complex networks. Nat phys, 6(11), 888–893.
Klemm, Konstantin, Serrano, M. Angeles, Eguiluz, Victor M., & San Miguel, Maxi.
(2012). A measure of individual role in collective dynamics: spreading at criticality.
Scientific reports, 2(292).
Leskovec, Jure. (2012). Stanford network analysis project (snap).
Luis E. C. Rocha, Fredrik Liljeros, & Holme, Petter. (2010). Information dynamics shape
the sexual networks of internet-mediated prostitution. Proceedings of the national
academy of sciences, March.
Madar, N., Kalisky, T., Cohen, R., ben Avraham, D., & Havlin, S. (2004). Immunization
and epidemic dynamics in complex networks. The european physical journal b condensed matter and complex systems, 38(2), 269–276.
Moores, Geoffrey, Shakarian, Paulo, Howard, Nicholas, & Macdonald, Brian. (2012).
Influential Spreaders 2. In progress.
Newman, Mark. (2011). Network data.
Page, L., Brin, S., Motwani, R., & Winograd, T. (1998). The pagerank citation ranking:
Bringing order to the web. Pages 161–172 of: Proceedings of the 7th international world
wide web conference.
R Development Core Team. (2011). R: A language and environment for statistical
computing. R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-90005107-0.
Seidman, Stephen B. (1983). Network structure and minimum degree. Social networks,
5(3), 269 – 287.
Valiant, Leslie G. (1979). The complexity of enumeration and reliability problems. Siam
j. comput., 8(3), 410–421.
Wasserman, Stanley, & Faust, Katherine. (1994). Social network analysis: Methods and
applications. 1 edn. Structural analysis in the social sciences, no. 8. Cambridge
University Press.
Zafarani, R., & Liu, H. (2009). Social computing data repository at ASU.

Mining for Geographically Disperse Communities in Social
Networks by Leveraging Distance Modularity
Paulo Shakarian

Patrick Roos

Network Science Center and
Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY 10996

Dept. of Computer Science
University of Maryland
College Park, MD 20721

roos@cs.umd.edu

arXiv:1305.3668v1 [cs.SI] 16 May 2013

paulo@shakarian.net

Devon Callahan,
Cory Kirk
Network Science Center and
Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY 10996

devon.callahan@usma.edu
cory.kirk@usma.edu
ABSTRACT

1.

Social networks where the actors occupy geospatial locations are prevalent in military, intelligence, and policing operations such as counter-terrorism, counter-insurgency, and
combating organized crime. These networks are often derived from a variety of intelligence sources. The discovery
of communities that are geographically disperse stems from
the requirement to identify higher-level organizational structures, such as a logistics group that provides support to various geographically disperse terrorist cells. We apply a variant of Newman-Girvan modularity to this problem known
as distance modularity. To address the problem of finding
geographically disperse communities, we modify the wellknown Louvain algorithm to find partitions of networks that
provide near-optimal solutions to this quantity. We apply
this algorithm to numerous samples from two real-world social networks and a terrorism network data set whose nodes
have associated geospatial locations. Our experiments show
this to be an effective approach and highlight various practical considerations when applying the algorithm to distance
modularity maximization. Several military, intelligence, and
law-enforcement organizations are working with us to further test and field software for this emerging application.

In recent years, fueled by the connectivity of our social
world and technological advances that allow for effortless
collection of connectivity data, much effort has been invested
in developing algorithms for the detection of communities in
networks (e.g. [11, 18, 17, 7, 3, 19, 9, 5]). The detection of
communities - subsets of nodes that are highly connected in
globally sparser networks - provides important insights into
the organization of networks and related hidden information
of social networks [11].
In many application domains, apart from the social network information provided by connectivity data, geospatial information is available as well, and community detection algorithms can be improved by leveraging such spatial information. Social networks where the actors occupy
geospatial locations are prevalent in military, intelligence,
and policing operations such as counter-terrorism, counterinsurgency, and combating organized crime. These networks
are often derived from a variety of intelligence sources. Community detection algorithms that specifically detect geographically dispersed communities are of interest in such application domains to identify higher-level organizational structures, such as a logistics group that provides support to
various geographically disperse terrorist cells. Such communities may be less obvious in solely the available social
network data. Hence, in order to find geographically dispersed communities, there exists a need for community detection algorithms that are optimized considering geospatial
information in addition to social network information, and
we address this need in this paper.
Blondel et al. [3] have developed a heuristic method known
as the Louvain algorithm that partitions a social network
into communities while optimizing Newman-Girvan modularity of the partition. Newman-Girvan modularity is a
common performance measure in community detection algorithms that gives a measure of how densely the detected
communities of the partition are connected relative to connections between these communities [18]. More specifically,
the modularity measure is the “fraction of edges within communities in the observed network minus the expected value
of that fraction in a null model, which serves as a reference
and should characterize some features of the observed network” [14].
In this paper, we use a variant of Newman-Girvan modu-

Categories and Subject Descriptors
Applied Computing [Law, social and behavioral sciences]: Sociology

General Terms
Algorithms, Experimentation

Keywords
complex networks, geospatial reasoning

.

INTRODUCTION

larity with the Louvain algorithm to address the problem of
mining for geographically dispersed communities in application domains where geospatial information is pertinent.
Instead of the original null model used in Newman-Girvan
modularity, we leverage a null model introduced by Liu et al.
[14]. The use of this model results in the distance modularity
measure of community structure.
We test the algorithm on two real-world location-based social networks and a network from a transnational terrorism
data set, the nodes of which have associated geospatial locations. Our experiments show that this approach is effective
at finding partitions of networks that provide near-optimal
solutions to distance modularity. We also highlight various
practical considerations when applying the algorithm with
these definitions of modularity. By testing the algorithm
on a social network that is significantly larger (ca. 2100
nodes) than the test networks commonly used in the literature on community detection algorithms (typically / 600
nodes), we also better demonstrate scalability. Further, our
results on the transnational terrorism network provide some
insight into how our approach will function on the often classified datasets of our target application. Currently, we are
working with several organizations in the U.S. Department
of Defense and the law enforcement communities to further
study and transition this technology.
Next, in Section 2, we cover some technical preliminaries, including definitions of modularity. Section 3 describes
the Louvain algorithm and our modifications to it to optimize for distance modularity. Section 4 describes our experiments and results on various data sets and an application
to transnational terrorism. We review and place our work
within related work in Section 5, and finally we conclude in
Section 6.

2.

TECHNICAL PRELIMINARIES

Throughout this paper, we shall model a network as an
undirected graph G = (V, E) where V is a set of nodes
and E is a set of relationships among nodes. We use n, m
to represent the cardninalities of V, E respectively. As the
graph is undirected, we shall assume that (vi , vj ) ∈ E implies (vj , vi ) ∈ E. We also assume that each edge (vi , vj )
has an associated weight wij (again ∀i, j, wij = wji ). For a
given node vi ∈ V , ηi = {vj |(vi , vj ) ∈ E ∨ (vj , vi ) ∈ E} and
ki = |ηi |.
We shall use the notation C = {c1 , . . . , cq } to denote a
partition over set V where eachSci ∈ C is a subset of V , for
any ci , cj ∈ C, ci ∩ cj = ∅ and i ci = V .
For a given partion, C, the modularity M (C) is a number in [−1, 1] . The modularity of a network partition can
be used to measure the quality of its community structure.
Originally introduced by Newman and Girvan. [18] this metric measures the density of edges within partitions compared
to the density of edges between partitions. A formal definition of this modularity (henceforth referred to as NG modularity) for an undirected network is
Definition 2.1 (NG modularity [18]). Given partition C = {c1 , . . . , cq }, NG modularity,
1 XX
wij − Pij
M (C) =
2m c∈C i,j∈c
where Pij =

ki kj
2m

.

Here, the null model used as a reference for comparison to
a given partition assumes edges are rewired randomly, while
the degree sequence of the input network is preserved, hence
ki kj
Pij = 2m
.
Recently, a measure for modularity that accounts for distance, as well as network topology, was introduced by Liu et
al. [14]. Their modularity, henceforth referred to as distance
modularity, is defined as follows:
Definition 2.2 (Distance Modularity [14]). Given
partition C = {c1 , . . . , cq }, distance modularity,
1 XX
wij − Pij
Mdist (C) =
2m c∈C i,j∈c
where Pij =

Pˆij +Pˆji
,
2

Pˆij =

P

ki kj f (d(vi ,vj ))
,
kq f (d(vq ,vi ))

vq ∈V

and

+

f : < → (0, 1] is the distance-decay function.
The basic idea behind this distance modularity is that
each node exerts a force on other nodes by generating a
field, and the potential of the field at any point decreases
with distance from the field source (the node generating the
field), depending on the distance decay function [13, 14].
The null model then that serves as a reference for comparison here assumes that nodes which are closer according to
the distance function are more likely to be connected. In this
paper we shall assume the existence of a distance function
d : V ×V → <+ that meets the normal axioms: d(vi , vi ) = 0,
d(vi , vj ) = d(vj , vi ), and d(vi , vj ) ≤ d(vi , vq ) + d(vq , vj ).
Previously, it has been proven that modularity-maximization
is NP-hard [4]. Clearly, setting ∀x, f (x) = 1, distance modularity reduces to NG modularity. As a direct consequence of
this observation, finding a partition that optimizes distance
modularity is also NP-hard.
Theorem 2.1. Given graph G = (V, E) and distance function d : V × V → <+ , finding a partition C of V that maximizes MS is NP-hard.
Throughout this paper, we will use an exponential distancedecay model[14, 5, 16, 20] defined as follows:
2

f (x) = e−(x/σ)

Where σ is a parameter in the interval (0, ∞) and e is the
base of the natural logarithm. One way to interpret σ is
that it is the distance where the force exerted by a point
is reduced by a fraction 1/e (roughly 0.36). We note that
in the limit as σ approaches infinity, geospatial modularity
reduces to NG modularity. In the next section, we test a
variety of settings for σ. Learning parameters such as σ has
previously been explored in various geospatial applications
– see [16, 20] for examples.

3.

APPROACH

This section describes the approach we use to mine for geographically dispersed communities in networks. Although
modularity maximization is NP-hard, a variety of practical approximation routines have been proposed [18, 17, 3]
that experimentally have produced near-optimal partitions.
In this paper, we employ the Louvain heuristic algorithm
of Blondel et al. [3], only instead of using it to maximize
NG-modularity, we use it to maximize distance modularity.
In order to use the Louvain algorithm to maximize distance

modularity, we must also modify some of it’s steps. We summarize the Louvain algorithm briefly next (for more details
on this algorithm, see [3]) and describe our modifications
and practical considerations when employing this heuristic
algorithm to optimize distance modularity.

3.1

Max
Min
Avg

Heuristic Algorithm

The Louvain algorithm is an iterated, hierarchical process
in which two phases are applied repeatedly until maximal
modularity is reached: In the first phase, each node vi ∈ V
of the given network is assigned to a community c, creating an initial partition. In [3], the singleton partition was
used. Then, for each vi ∈ V , the gains in modularity that
would result from placing vi to the community of each of
its neighbors vj ∈ ηi are calculated, and vi is removed and
placed into the community for which the maximum gain in
modularity is attained (unless no positive gain in modularity is possible). This sub-process is repeated sequentially for
each vi ∈ V until no individual move will result in a gain
in modularity, marking the end of the first phase and giving
a partition C. In the second phase, a new network is built
by using each ci ∈ C as a node in the new network, call
these nodes meta-nodes. Weights on the edges between any
two meta-nodes in the new network are assigned to be the
sum of the weights of the edges between nodes in the two
communities corresponding to the meta-nodes. In this step,
self-loops are created for each meta-node in the new network
from the links between nodes of the community corresponding to that meta-node. After this phase is complete, the
two phases are reapplied iteratively until there are no more
changes.
The efficiency of the Louvain algorithm relies on an easy
re-calculation of modularity in the first phase of the algorithm. When computing gains in modularity in phase one
of the algorithm, removing any node vi , the overall increase
in modularity (regardless if it is distance or NG) if it is
placed into community c is proportional to:
X
ki,in −
Pij
j∈c

The only difference for distance modularity is that Pij is
defined as per Definition 2.2 instead of Definition 2.1. In
terms of time complexity, the first phase of the algorithm is
O(n2 ), since for every node in the network, distance modularity must be computed according to Definition 2.2, which
is O(n) in the denominator of Pˆij . The second phase is again
O(n). Both phases are a multiple of a constant that results
from the number of iterations needed to run to completion.
We note that the input sizes decrease drastically with each
iteration, since communities are iteratively collapsed into
nodes. Hence, the proposition on time complexity follows:
Proposition 3.1. The time complexity of the Louvain algorithm, optimizing for distance modularity, is quadratic in
terms of the number of nodes n of the input network.

3.2

Table 1: Brightkite Sample Data

Practical Considerations

Apart from the main modification to use distance modularity instead of NG modularity, there are two steps of the
original Louvain algorithm that we modify when optimizing
for distance modularity. First, we must decide on an initial
partition to use. Blondel et al. [3] use the singleton partition.
However, we have found that using the Louvain partition,

Nodes
331
300
311.25

Edges
2801
787
1560.40

resulting from a normal run of the Louvain algorithm optimizing for NG modularity, provided better results at the
expense of some runtime. Second, since each node has an
associated geospatial value, a geospatial value must be assigned to the meta-nodes of the new networks being built.
Here we use the centroid of the communities that correspond to the meta-nodes. Throughout the remainder of this
paper, we shall refer to the described modified version of the
Louvain algorithm (for maximizing distance modularity) as
the Louvain-D algorithm. The implications of these considerations are discussed in more detail in our experimental
results.

4.

EXPERIMENTAL RESULTS

For our experiments, we used information extracted from
the Gowalla and Brightkite location-based online social networking sites [6].
We built our implementation in Python 2.6 on top of the
NetworkX library 1 leveraging code from Thomas Aynaud’s
implementation of the Louvain algorithm 2 . Our implementation took approximately 1000 lines of code. The experiments were run on a computer equipped with an Intel X5677
Xeon Processor operating at 3.46 GHz with a 12 MB Cache
running Red Hat Enterprise Linux version 6.1 and equipped
with 70 GB of physical memory. All statistics presented in
this section were calculated using R 2.13.1.

4.1

Distance Modularity Evaulation

In our first set of tests, we iteratively selected nodes and
their neighbors from the Brightkite network dataset provided by the authors of [6] to produce 20 small samples (of
at least 300 nodes each). Each sample originated with a
randomly selected node from the network and we iteratively
added neighbors of the selected node(s) to the sample until a
minimum desired sized was achieved. Node and edge counts
for these small networks is listed in Table 1.
On our 20 samples extracted from the Brightkite dataset,
we considered the straight-line distance between nodes in
kilometers. Hence, in calculating geomodularity, we ran experiments σ = {50, 100, 150, . . . , 500}. For each dataset and
each value of σ, we compared the distance modularity returned by three approaches: the Louvain algorithm (which
does not consider any geospatial information), the LouvainD algorithm using singleton nodes as the initial partition,
and the Louvain-D algorithm using the result of the Louvain algorithm as the initial partition.
Both variants of the Louvain-D algorithm returned a partition with a greater average geomodularity for each value
of σ than the partition returned by the Louvain algorithm
(see Figure 1). This aligns well with the previous results
of [9, 5] where space can affect on community structure not
1
2

http://networkx.github.com/
http://perso.crans.org/aynaud/communities/

Average	
  Distance	
  Modularity	
  

0.3	
  

%	
  Increase	
  in	
  Distance	
  
Modularity	
  

30	
  

A	
  

25	
  
20	
  
15	
  
10	
  
5	
  
0	
  
-­‐5	
  

-­‐10	
  
0	
  

100	
  

200	
  

300	
  

400	
  

500	
  

σ	
  (km)	
  
30	
  

%	
  Increase	
  in	
  Distance	
  
Modularity	
  

accounted for in the network topology. However, we noticed
that the percentage increase in modularity decreases with
σ (see Figure 2). This relationship also makes sense as
distance modularity reduces to NG modularity (which the
Louvain algorithm is designed to optimize) as σ approaches
infinity.
Although the Louvain-D algorithm outperformed the Louvain algorithm in terms of finding geomodularity, it generally returned higher-quality partitions if it was initialized
with the Louvain partition instead of the partition of singleton nodes. Further, when we used the Louvain partition
to initialize the Louvain-D algorithm, we never obtained a
partition with a lower geomodularity than the Louvain algorithm. With the singleton partition, on the other hand, the
Louvain-D was occasionally outperformed by the Louvain
algorithm – particularly for the higher values of σ.

B	
  

25	
  
20	
  
15	
  
10	
  
5	
  
0	
  

0.25	
  

0	
  

0.2	
  

100	
  

200	
  

300	
  

400	
  

500	
  

σ	
  (km)	
  
All	
  Trials	
  
Average	
  

0.15	
  
0.1	
  
0.05	
  
0	
  
-­‐0.05	
  
0	
  

100	
  

200	
  

300	
  

400	
  

500	
  

σ	
  (km)	
  
Louvain	
  Algorithm	
  
Louvain-­‐D	
  
Louvain-­‐D	
  Using	
  Louvain	
  ParDDon	
  

Figure 1: σ (in kilometers) vs.
(average) distance modularity for the partitions returned by the
Louvain-D and Louvain (baseline) algorithms.

However, the improvement in the quality when using the
Louvain partition as a starting point comes at the expense of
runtime. While the time to calculate the Louvain partition
was negligible (normally under 1 second in the Brightkite
tests), using it as a starting point appears to cause the
Louvain-D algorithm to take longer to reach convergence
- resulting in a runtime nearly double if the singleton partition is initially used (see Figure 3).
An analysis of variance (ANOVA) reveals that there is a
significant difference in geomodualrity of the partitions returned by the three approaches on the Brightkite dataset
(p-value 2.2 · 10−16 ). Additionally, pairwise analysis conducted using Tukey’s Honest Significant Difference (HSD)
test indicates that both instances of the Louvain-D algorithm provided results that differed significantly from the
Louvain algorithm and each other with a probability approaching 1.0 (95% confidence). Additionally, the differences among runtimes were also significant (ANOVA p-value
less than 2.2 · 10−16 ) and pairwise different by the HSD with
a probability approaching 1.0 amongst all comparisons (95%
confidence).

Figure 2: σ (in kilometers) vs. percent improvement in geomodularity (for the partition returned
by the Louvain-D algorithm) when compared to the
distance modularity for the partition returned by
the Louvain (baseline) algorithm. Panel A shows
this relationship when the Louvain-D initially uses
the singleton partition while panel B shows this relationship when the Louvain-D algorithm initially
uses the Louvain partition.
As an example of the type of result returned by our approach, we have included Figure 4 that illustrates the differences between a community returned by our approach vs.
the standard Louvain algorithm. The left panel shows a
group of individuals near the San Diego area that the Louvain algorithm identified as being in the same community.
Likely, in this case, there is a strong correlation between geographic distance and connection in the social network. The
right panel, by contrast, shows that the same individuals are
placed in multiple, different communities by the Louvain-D
algorithm. Since relatively high-degree individuals that are
geographically near each other have a higher probability of
connection in the null model, it becomes more likely for the
Louvain-D algorithm to place them in different communities.

250	
  

Run+me	
  (seconds)	
  

Table 2: Gowalla Sample Data
200	
  

Sample No.
1
2
3
4
5
6
7

150	
  
100	
  
50	
  
0	
  
0	
  

100	
  

200	
  

300	
  

400	
  

500	
  

σ	
  (km)	
  
Louvain-­‐D	
  

Nodes
301
602
876
1201
1501
1801
2101

Edges
416
1550
12373
2680
3854
4887
6445

Louvain-­‐D	
  Using	
  Louvain	
  Par++on	
  

Figure 3: σ (in kilometers) vs. (average) runtime of
the Louvain-D algorithm (using both singleton and
Louvain partition initially).
E

V,F,Y

Distance	
  Modularity	
  

0.2	
  
0.15	
  
0.1	
  
0.05	
  
0	
  
-­‐0.05	
  
1	
  
E

Y,L,V,M,F,G,B

E

Figure 4: Left: Communities identified using the
Louvain algorithm, Right: Communities found using
Louvain-D (σ = 150)

4.2

2	
  

3	
  

4	
  

Trial	
  
Louvain	
  Algorithm	
  

V,D

Tests on Larger Samples

In our second set of tests, we iteratively selected nodes and
their neighbors from the Gowala network dataset [6] to produce seven samples ranging in size from 301 to 2101 nodes
each. Samples were collected in the same manner as with the
Brightkite samples previously described. Distances between
nodes are computed in kilometers. Node and edge counts for
these small networks is listed in Table 2. Note that our tests
examine networks significantly larger than those considered
in related work where communities are determined based on
geography and network topology (100 nodes in [5] and 571
nodes in [9]).
We evaluated the Louvain-D algorithm on these samples
with σ = 100, initially using the Louvain partition, and
compared the distance modularity of the resulting partition
to that of the partition returned by the standard Louvain
algorithm. With all seven samples, the Louvain-D algorithm
outperformed the standard approach. Improvement ranged
from 2.8-14.2%. The results are depicted in Figure 5.
We also studied the runtime of the Louvain-D algorithm
and compared it to the size of the samples. As per Proposi-

5	
  

6	
  

7	
  

Louvain-­‐D	
  

Figure 5: Distance modularity of the partition found
using the Louvain (baseline) and Louvain-D algorithms for the Gowalla network samples (see Table 2).

tion 3.1, we expected a quadratic relationship. We verified
this relationship in our experiment (R2 = 0.9973). These
results are depicted in Figure 6. We note that while considering a network of 2101 nodes required just under two days
of computer time, which is acceptable for our applications,
further scaling will take prohibitively long runtimes. For
example, scaling to 104 nodes would require approximately
three months of runtime based on our regression analysis.
Further scalability is an important direction for future work.

4.3

Application: Transnational Terrorism

In this section we use the open-source derived terrorist
network of Medina and Hepner [15] as a proxy for the (often classified) networks that will be used by this software in
practice. The networks consists of 358 geolocated individuals in a transnational terrorist organization (660 unweighted
edges). A diagram of the network is shown in Figure 7 while
the locations of the individuals are shown in Figure 8.
We ran the Louvain-D algorithm (initially using the Louvain partition) with σ = {50, 100, 150, . . . , 500} and compared the distance modularity of the resulting partition to
that returned by the standard Louvain algorithm. The LouvainD algorithm consistently outperformed the baseline approach
(Figure 9) with the percent improvement ranged from 8.2 −
9.8%. The results are consistent with the other trials, where
the distance modularity of the partition produced by the
Louvain-D partition monotonically decreases with σ, slowly
approaching the distance modularity of the baseline approach.
To better understand how a practitioner would use our approach for analysis, we considered the problem of identifying

50	
  

Run1me	
  (hours)	
  

45	
  

Louvain-­‐D	
  
Algorithm	
  

40	
  
35	
  
30	
  

Quadra1c	
  
Fit	
  
R²	
  =	
  0.99734	
  

25	
  
20	
  
15	
  
10	
  
5	
  
0	
  
300	
  

800	
  

1300	
  

1800	
  

2300	
  

Number	
  of	
  Nodes	
  

Figure 8: Geographic locations of the individuals in
the transnational terrorist dataset of [15].
1	
  

Distance	
  Modularity	
  

Figure 6: Networks size (in nodes) vs. runtime (in
hours) for the Gowalla network samples. Note the
strong quadratic fit.

0.95	
  
0.9	
  
0.85	
  
0.8	
  
0.75	
  
0.7	
  
0	
  

50	
  

100	
  

150	
  

200	
  

250	
  

300	
  

350	
  

400	
  

450	
  

500	
  

σ	
  (km)	
  
Louvain	
  Algorithm	
  

Louvain-­‐D	
  Using	
  Louvain	
  ParGGon	
  

Figure 9: Comparison of distance modularity between Louvain and Louvain-D algorithms for the
transnational terrorism dataset.

Figure 7: Network relationships in the transnational
terrorist dataset of [15].

a single, important geographically disperse community. We
can identify such a group of individuals by determining the
quality of a given community. We can derive such a measure
directly from the definition of modularity. For a given given
community c ⊆ V , we can determine the quality as follows:
1 X
Mc =
wij − Pij
(1)
2|c| v ,v ∈c
i

to find partitions that could nearly maximize this quantity.
An exact method for addressing this optimization problem
was introduced in [4]. However, this method was based on
integer programming and for many problem instances may
take an exponential amount of time to complete. However,
we note that an easy modification of that program can be
used to address the problem of this paper as the quantity
Pij can be solved in a pre-processing step and treated as a
constant in the integer program formulation. Note that the
time to complete such a step would be easily dominated by
the overall runtime to even approximate a solution in such a
method. In the same paper, modularity maximization was
also shown to be NP-hard, which precludes an efficient ap-

j

We ranked all the communities for the transnational
terrorist organization (over all settings of σ we considered)
and took the top one. We show the visualization of the
network and geolocations of the individuals in Figures 1110. Note that the members of the identified community
span three continents. Identifying communities such as these
can provide intelligence analysts insight into how various
geographically-disperse terrorist cells interact with higherlevel organizations.

5.

RELATED WORK

The use of modularity maximization for community finding was first introduced in [18] which also described how

Figure 10: Geolocations of the individuals in the
top-ranked community from the transnational terrorist network.

Figure 11: Visualization of the network topology of
the community shown in Figure 10.

proaches under current theoretical assumptions. In [3] the
Louvain algorithm is introduced which is shown to provide
partitions that nearly maximize modularity and can scale
to very large networks. The modification of the Louvain
algorithm is what we leveraged in this paper.
Modularity was extended to consider geosptial relationships using a distance-decay model in [14] with the introduction of distance modularity which we use in this paper.
Their approach modifies the null model to increase the expected number of edges between close nodes, it will tend
to find communities that are more geographically disperse hence meeting the requirement of our presented application.
Our work extends on their theory - providing an algorithm to
find an approximately optimal partitions wrt distance modularity, experimental results, and describes practical considerations - none of which were included in [14] which only
introduces the the concept of distance modularity and describes the mathematical properties of their alternative null
model.
The recent work of [5] introduces “spatial modularity”
that also uses a distance-decay function in the null model though somewhat different to that introduced in [14]. They
study the difference among partitions created by attempting to optimize both standard modularity and their alternate definition on a series of small simulated networks whose
edges are formed based on varying degrees of correlation between space and node similarity (determined by randomly
assigned attributes). The results of that paper have also inspired this work as they indicate that by considering geospatial relationships in the null model often yields different community structure than with the original definition of modularity introduced by [18]. However, unlike this paper, the
work of [5] only studies simulated networks (this paper only
looks at real-world networks). The networks of this paper
are an order of magnitude larger as [5] only considers networks of 100 nodes. Further, [5] does not describe any practical concerns in their approach that must be considered
when creating a real-world system.
Another important result on community finding in geosptial networks was that of [9] where the authors also modify
modularity. However, in that work, the authors use a null
model that is based on an empirically observed probability distribution of edge existence based on distance. Their
optimization approach was tested on a network of Belgian
communes of phone users and was shown to accurately identify linguistic communities. However, unlike this paper and

the work of [14] and [5], as their null model is based on
an empirically determined probability distribution, it will
not necessarily ensure geographically-disperse communities
- which is our target application. Further, the work of [9]
does not describe practical considerations and their experimental evaluation is restricted to the Belgian phone network
data consisting of 571 nodes.
In addition to the aforementioned approaches, community
detection in networks has also been explored in other manners that could potentially be proved applicable to geospatial applications - though to our knowledge no such application has been presented in the literature. For instance, the
work of [21] identifies communities based on both network
topology and content analysis. Further, there are methods
for community detection other than modularity maximization on networks (that do not consider spatial interactions).
Leveraging one of these other approaches is an important
direction for future work. See [10] for a comprehensive survey.
There has been other recent work where geospatial networks have been explored with respect to problems other
than community finding. The work of [12] discusses linkprediction and shows that by considering geography that
results for this problem can be improved. The work of [1]
looks at identifying the location of users on Twitter using
network topology. Further, there also have been empirical
studies on social networks with a spatial component such as
[2]. Along such lines, the mobility of users in a locationbased social network is explored in [6, 8]. More domainspecific empirical studies related to this work are also prevalent in the literature. Pertinent to our application include
studies on terrorist networks [15] and criminal co-offender
networks [19].

6.

CONCLUSION

In this paper, we have presented a modified Louvain algorithm to find partitions of networks that provide nearoptimal solutions for both nearness and distance modularity,
providing a way to leverage spatial information in addition
to network connection topology when mining networks for
communities. We have evaluated this algorithm on two realworld location-based social networks, as well as a real-world
transnational terrorism network data set. Our results have
shown that using the Louvain algorithm modified to optimize for distance modularity to be an effective approach
to the problem of finding geographically disperse communities, finding near-optimal solutions to distance modularity.
Our experiments have also shown that using the Louvain
partition instead of a singleton partition in the initial partitioning step of the algorithm generally provides improved
final partitions in terms of distance modularity. We have
demonstrated the scalability of the algorithm by considering
networks of up to more than 2000 nodes, a number that is
significantly greater than network sizes typically considered
in the related literature. Finally, particularly through our
experiments applying the algorithm to a real-world transnational terrorism network data set, we have found the presented approach be useful for finding geographically disperse
communities at a time scale that is practical in the application domain.
Currently, examining scalability issues is an immediate
concern for future work, as we have initiated a relationship
with a major American police department to study gang vi-

olence - which will require the examination of networks of
size 105 nodes. In this application domain, the identification
of particularly localized communities as opposed to disperse
communities may be of interest as well, thus a modularity
definition optimizing for this is another potential item for
immediate future work. We are also working with various
agencies in the U.S. Department of Defense to transition
this technology to study networks of hundreds to thousands
of nodes. With this particular user-base, our focus is on
readying the technology for deployment to analysts in a usable system.

7.

ACKNOWLEDGMENTS

P.S. would like to thank Richard M. Medina (GMU) for
his help with the terrorist network dataset. The authors are
supported by the Army Research Office (project 2GDATXR042)
and the Office of the Secretary of Defense. The opinions in
this paper are those of the authors and do not necessarily reflect the opinions of the funders, the U.S. Military Academy,
or the U.S. Army.

8.

REFERENCES

[1] S. Abrol, L. Khan, and B. Thuraisingham. Tweeque:
Spatio-temporal analysis of social networks for
location mining using graph partitioning. In Proc.
2012 ASE Intl. Conf. on Social Informatics, Dec. 2012.
[2] M. Barthélemy. Spatial networks. Physics Reports,
499(1):1–101, 2011.
[3] V. Blondel, J. Guillaume, R. Lambiotte, and
E. Lefebvre. Fast unfolding of communities in large
networks. Journal of Statistical Mechanics: Theory
and Experiment, 2008:P10008, 2008.
[4] U. Brandes, D. Delling, M. Gaertler, R. Gorke,
M. Hoefer, Z. Nikoloski, and D. Wagner. On
modularity clustering. Knowledge and Data
Engineering, IEEE Transactions on, 20(2):172 –188,
feb. 2008.
[5] F. Cerina, V. D. Leo, M. Barthelemy, and A. Chessa.
Spatial correlations in attribute communities. PLoS
One, 7(5), May 2012.
[6] E. Cho, S. A. Myers, and J. Leskovec. Friendship and
mobility: user movement in location-based social
networks. In Proceedings of the 17th ACM SIGKDD
international conference on Knowledge discovery and
data mining, KDD ’11, pages 1082–1090, New York,
NY, USA, 2011. ACM.
[7] N. Du, B. Wu, X. Pei, B. Wang, and L. Xu.
Community detection in large-scale social networks. In
Proceedings of the 9th WebKDD and 1st SNA-KDD
2007 workshop on Web mining and social network
analysis, pages 16–25. ACM, 2007.
[8] N. Eagle and A. Pentland. Reality mining: sensing
complex social systems. Personal and Ubiquitous
Computing, 10(4):255–268, 2006.
[9] P. Expert, T. S. Evans, V. D. Blondel, and
R. Lambiotte. Uncovering space-independent
communities in spatial networks. Proceedings of the
National Academy of Sciences, 108(19):7663–7668,
2011.
[10] S. Fortunato. Community detection in graphs. CoRR,
abs/0906.0612, 2009.

[11] M. Girvan and M. Newman. Community structure in
social and biological networks. Proceedings of the
National Academy of Sciences, 99(12):7821–7826,
2002.
[12] N. D. Larusso, B. E. Ruttenberg, and A. K. Singh. A
latent parameter node-centric model for spatial
networks. CoRR, abs/1210.4246, 2012.
[13] D. Li and Y. Du. Artificial intelligence with
uncertainty. Chapman & Hall/CRC, 2007.
[14] X. Liu, T. Murata, and K. Wakita. Extending
modularity by incorporating distance functions in the
null model. CoRR, abs/1210.4007, 2012.
[15] R. M. Medina and G. F. Hepner. Advancing the
understanding of sociospatial dependencies in terrorist
networks. T. GIS, 15(5):577–597, 2011.
[16] J. C. Nekola and P. S. White. Special Paper: The
Distance Decay of Similarity in Biogeography and
Ecology. Journal of Biogeography, 26(4):867–878, 1999.
[17] M. E. J. Newman. Fast algorithm for detecting
community structure in networks. Phys. Rev. E,
69(6):066133, Jun 2004.
[18] M. E. J. Newman and M. Girvan. Finding and
evaluating community structure in networks. Phys.
Rev. E, 69(2):026113, Feb 2004.
[19] D. R. Schaefer. Youth co-offending networks: An
investigation of social and spatial effects. Social
Networks, 34(1):141 – 149, 2012.
[20] H. Skov-Petersen. Estimation of distance-decay
parameters: Gis-based indicators of recreational
accessibility. In ScanGIS, pages 237–258, 2001.
[21] T. Yang, R. Jin, Y. Chi, and S. Zhu. Combining link
and content for community detection: a discriminative
approach. In Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and
data mining, KDD ’09, pages 927–936, New York, NY,
USA, 2009. ACM.

A Novel Analytical Method for Evolutionary Graph
Theory Problems

arXiv:1301.2533v1 [cs.GT] 11 Jan 2013

Paulo Shakarian
Network Science Center and Dept. of Electrical Engineering and Computer Science,
United States Military Academy, West Point, NY 10996

Patrick Roos
Dept. of Computer Science, University of Maryland, College Park, MD 20740

Geoffrey Moores
Network Science Center and Dept. of Electrical Engineering and Computer Science,
United States Military Academy, West Point, NY 10996

Abstract
Evolutionary graph theory studies the evolutionary dynamics of populations
structured on graphs. A central problem is determining the probability that
a small number of mutants overtake a population. Currently, Monte Carlo
simulations are used for estimating such fixation probabilities on general directed graphs, since no good analytical methods exist. In this paper, we
introduce a novel deterministic framework for computing fixation probabilities for strongly connected, directed, weighted evolutionary graphs under
neutral drift. We show how this framework can also be used to calculate
the expected number of mutants at a given time step (even if we relax the
assumption that the graph is strongly connected), how it can extend to other
related models (e.g. voter model), how our framework can provide non-trivial
bounds for fixation probability in the case of an advantageous mutant, and
how it can be used to find a non-trivial lower bound on the mean time to
fixation. We provide various experimental results determining fixation probabilities and expected number of mutants on different graphs. Among these,
we show that our method consistently outperforms Monte Carlo simulations
in speed by several orders of magnitude. Finally we show how our approach
can provide insight into synaptic competition in neurology.

Preprint submitted to BioSystems

January 14, 2013

Keywords: evolutionary dynamics, Moran process, complex networks
1. Introduction
Evolutionary graph theory (EGT), introduced by [14], studies the problems related to population dynamics when the underlying structure of the
population is represented as a directed, weighted graph. This model has
been applied to problems in evolutionary biology [28], physics [25], game
theory [20], neurology [26], and distributes systems [13]. A central problem
in this research area is computing the fixation probability - the probability
that a certain subset of mutants overtakes the population. Although good
analytical approximations are available for the undirected/unweighted case
[1, 6], these break down for directed, weighted graphs as shown by [16]. As
a result, most work dealing with evolutionary graphs rely on Monte Carlo
simulations to approximate the fixation probability [22, 7, 4]. In this paper
we develop a novel deterministic framework to compute fixation probability
in the case of neutral drift (when mutants and residents have equal fitness)
in directed, weighted evolutionary graphs based on the convergence of “vertex probabilities” to the fixation probability as time approaches infinity. We
then show how this framework can be used to calculate the expected number
of mutants at a given time, how the framework can be modified to do the
same for related models, how it can provide non-trivial bounds for fixation
probability in the case of an advantageous mutant, and how it can provide
a non-trivial lower bound on the mean time to fixation. We also provide
various experiments that show how our method can outperform Monte Carlo
simulations by several orders of magnitude. Additionally, we show that the
results of this paper can provide direct insight into the problem of synaptic
competition in neurology.
Our method also fills a few holes in the literature. First, it allows for
deterministic computation of fixation probability when there is an initial
set of mutants – not just a singleton (the majority of current research on
evolutionary graph theory only considers singletons). Second, it allows us
to study how the mutant population changes as a function of time. Third,
we show (by way of rigorous proof) that fixation probability, under the case
of neutral drift is a lower bound for the case of the advantageous mutant confirming simulation observations by [15]. Fourth, we show (also by way of
rigorous proof) that fixation probability under neutral drift is additive (even
2

for weighted, directed graphs), which extends the work of [6] that proved
this for undirected/unweighted graphs. Fifth, we provide a non-trivial lower
bound for the computation of mean time to fixation in the general case which has only previously been explored for well-mixed populations [2] and
special cases of graphs [5].
This paper is organized as follows. In Section 2 we review the original
model of Lieberman et al., introduce the idea of “vertex probabilities” and
show how they can be used to find the fixation probability. We then show how
this can be used to determine the expected number of mutants at a given
time in Section 3. This is followed by a discussion of how the framework
can be extended to other update rules in Section 4 and then for bounding
fixation probability in the case of an advantageous mutant in Section 5.
We then discuss how our approach can be adopted to bound mean time to
fixation in Section 6. We use the results of the previous sections to create
an algorithm for computing fixation probability and introduce a heuristic
technique to significantly decrease the run-time. The algorithm and several
experimental evaluations are described in Section 7. In Section 8, we show
how our framework can be applied to neurology to gain insights into synaptic
competition. Finally, we discuss related work in Section 9 and conclude.
2. Directly Calculating Fixation Probability
The classic evolutionary model known as the Moran Process is a stochastic process used to describe evolution in a well-mixed population [18]. All
the individuals in the population are either mutants or residents. The aim of
such work was to determine if a set of mutants could take over a population
of residents (achieving “fixation”). In [14], evolutionary graph theory (EGT)
is introduced, which generalizes the model of the Moran Process by specifying relationships between the N individuals of the population in the form
of a directed, weighted graph. Here, the graph will be specified in the usual
way as G = (V, E) where V is a set of nodes (individuals) and E ⊆ V × V .
In most literature on evolutionary graph theory, the evolutionary graph is
assumed to be strongly connected. We make the same assumption and state
when it can be relaxed.
(i)
(i)
For any node i, the numbers kin , kout are the in- and out- degrees respectively. We will use the symbol N to denote the sized of V . Additionally,
we will specify weights on the edges in set E using a square matrix denoted
W = [wij ] whose side is of size N . Intuitively, wij is the probability that
3

member of the
P population j is replaced by i given that member i is selected.
We require j wij = 1 and that (i, j) ∈ E iff wij > 0. If for all i, j, we have
(i)

wij = 1/kout , then the graph is said to be “unweighted.” If for all (i, j) ∈ E,
we have (j, i) ∈ E the graph is said to be “undirected.” Though our results
primarily focus on the general case, we will often refer to the special case
of undirected/unweighted graphs as this special case is quite common in the
literature [1, 6].
In this paper we will often consider the outcome of the evolutionary process when there is a set of initial mutants as opposed to a singleton. Hence,
we say some set (often denoted C) is a configuration if that set specifies the
set of mutants in the population (all other members in the population then
are residents). We assume all members in the population are either mutants
or residents and have a fitness specified by a parameter r > 0. Mutants
have a fitness r and residents have a fitness of 1. At each time step, some
individual i ∈ V is selected for “birth” with a probability proportional to its
fitness. Then, an outgoing neighbor j of i is selected with probability wij
and replaced by a clone of i. Note if r = 1, we say we are in the special case
of neutral drift.
We will use the notation PV 0 ,t to refer to the probability of being in
configuration V 0 after t timesteps and PV 0 ,t|C to be the probability of being in
configuration V 0 at time t conditioned upon initial configuration C. Perhaps
the most widely studied problem in evolutionary graph theory is to determine
the fixation probability. Given set of mutants C at time 0, the fixation
probabilty is defined as follows.
FC = lim t→∞ PV,t|C

(1)

This is the probability that an initial set C of mutants takes over the entire population as time approaches infinity. Similarly, we will use the term
the extinction probability, FC , to be lim t→∞ P∅,t|C . If the graph if strongly
connected, then we have FC + FC = 1. Hence, for a strongly connected
graph, a mutant either fixates or becomes extinct. Typically, this problem
is studied using Monte Carlo simulation. This work uses the idea of a vertex probabilities to create an alternative to such an approach. The vertex
probability is the probability that a certain vertex is a mutant at a certain
time given an initial configuration. For vertex i at time t, we denote this as
Pi,t|C . Often, for ease of notation, we shall assume that the probabilities are
conditioned on some initial configuration and drop the condition, writing Pi,t
4

instead of Pi,t|C . We note that Pi,t can be expressed in terms of probabilities
of configurations as follows.
X
Pi,t =
PV 0 ,t
(2)
V 0 ∈2V
s.t. i∈V 0

Viewing the probability that a specific vertex is a mutant at a given time
has not, to our knowledge, been studied before with respect to evolutionary
graph theory (or in related processes such as the voter model). The key
insight of this paper is that studying these probabilities sheds new light on
the problem of calculating fixation probabilities in addition to providing other
insights into EGT. For example, it is easy to show the following relationship.
Proposition 1. Let V 0 be a subset of V and t be an arbitrary time point.
Iff for all i ∈ V 0 , Pi,t = 1 and for all i ∈
/ V 0 , Pi,t = 0, then PV 0 ,t = 1 and for
00
V
00
0
all V ∈ 2 s.t. V 6≡ V , PV 00 ,t = 0.
It is easy to verify that FC > 0 iff ∀i ∈ V , lim t→∞ Pi,t > 0. Hence, in this
paper, we shall generally assume that lim t→∞ Pi,t > 0 holds for all vertices i
and specifically state when it does not. As an aside, for a given graph, this
assumption can be easily checked: simply ensure for j ∈ V − C that exists
some i ∈ C s.t. there is a directed path from i to j.
Now that we have introduced the model and the idea of vertex probabilities we will show how to leverage this information to compute fixation
probability. It is easy to show that as time approaches infinity, the vertex
probabilities for all vertices converge to the fixation probability when the
graph if strongly connected.
Theorem 1. ∀i, lim t→∞ Pi,t|C = FC
Now let us consider how to calculate Pi,t for some i and t. For t = 0,
where we know that we are in the state where only vertices in a given set are
mutants, we need only appeal to Proposition 1 - which tells us that we assign
a probability of 1 to all elements in that set and 0 otherwise. For subsequent
timesteps, we have developed Theorem 2 shown next (the proof of which is
included in the supplement).

5

Theorem 2.
Pi,t = Pi,t−1 +

X

wji Pj,t−1 · S(j,t)|(j,t−1) − Pi,t−1 · S(j,t)|(i,t−1)



(j,i)∈E

(S(j,t)|(i,t−1) is the probability that j is picked for reporduction at time t given
that i was a mutant at time t − 1.)
We believe that a concise, tractable analytical solution for S(j,t)|(i,t−1) is unlikely. However, for neutral drift (r = 1), these conditional probabilities are
trivial - specifically, we have for all i, j, t, S(j,t)|(i,t−1) = 1/N as this probability
of selection is independent of the current set of mutants or residents in the
graph. Hence, in the case of neutral drift, we have the following:
Pi,t = Pi,t−1 +

X wji
· (Pj,t−1 − Pi,t−1 )
N

(3)

(j,i)∈E

Studying evolutionary graph theory under neutral drift was a central theme
in several papers on EGT in the past few years [6, 15] as it provides an
intuition on the effects of network topology on mutant spread. In Section 5
we examine the case of the advantageous mutant (r > 1). Neutral drift allows
us to strengthen the statement of Equation 1 to a necessary and sufficient
condition - showing that when the probabilities of all nodes are equal, then
we can determine the fixation probability.
Theorem 3. Assuming neutral drift (r = 1), given initial configuration C
with fixation probability FC , if at time t the quantities Pi,t|C are equal (for all
i ∈ V ), then they also equal FC .
Therefore, under neutral drift, we can determine fixation probability when
Equation 3 causes all Pi,t ’s to be equal. We can also use Equation 3 to find
bounds on the fixation probability for some time t by the following result
that holds for any time t under neutral drift.
min Pi,t ≤ FC ≤ max Pi,t
i

i

(4)

Under neutral drift, we can show that fixation probability is additive for
disjoint sets. Broom et al. proved a similar result the a special case of undirected/unweighted evolutionary graphs [6]. However, our proof (contained in
6

the supplement) differs from theirs in that we leverage Equation 3. Further,
unlike the result of Broom et al., our result applies to the more general case
of weighted, directed graphs.
Theorem 4. When r = 1 for disjoint sets C, D ⊆ V , FC + FD = FC∪D .
3. Calculating the Expected Number of Mutants
In addition to allowing for the calculation of fixation probability, our
framework can also be used to observe how the expected number of mutants
(t)
changes over time. We will use the notation ExC to denote the expected
number of mutants at time t given initial set C. Formally, this is defined
below.
X
(t)
Pi,t
(5)
ExC =
i∈V

Unlike fixation probability, which only considers the probability that mu(t)
tants overtake a population, ExC provides a probabilistic average of the
number of mutants in the population under a finite time horizon. For example, is has been noted that graph structures which amplify fixation normally
also increase time to absorption [8, 21]. Hence, finding the expected number
of mutants may be a more viable topic in some areas of research where time
is known to be limited. Following from Equation 3 where we showed how to
compute Pi,t for each node at a given time, we have the following relationship
concerning the expected number of mutants at a given time under neutral
drift.
(t−1)

(t)
ExC

=

(t−1)
ExC

ExC
+
N

−

1 X X
wji · Pi,t−1
N i∈V

(6)

(j,i)∈E

Based on Equation 6, we notice that for r = 1, at each time-step, the
number of expected mutants increases by at most the average fixation probability and decreases by a quantity related to the average “temperature.”
The temperature of vertex i (denoted Ti ) is P
defined for a given node is the
sum of the incoming edge weights [14]: Ti = j wji . Intuitively, nodes with
a higher temperature change more often between being a mutant and being a

7

resident than those with lower temperature. Re-writing Equation 6 in terms
of temperature we have the following:
(t−1)

(t)
ExC

=

(t−1)
ExC

ExC
+
N

−

1 X
Ti · Pi,t−1
N i∈V

(7)

Hence, if the preponderance of high temperature nodes are likely to be
mutants, then most likely the average number of mutants will decrease at the
next time step. We also note that Theorem 2, Equation 3, and Equation 6
do not depend on the assumption that the underlying graph is strongly connected. Therefore, as such is the case, we can study the relationship of time
vs. expected number of mutants for any evolutionary graph (under neutral
drift). This could be of particular interest to non-strongly connected evolutionary graphs that may have trivial fixation probabilities (i.e. 1 or 0) but
may have varying levels of mutants before achieving an absorbing state.
4. Applying the Framework to Other Update Rules
The results of the last two sections not only apply to the original model of
[14], but several other related models in the literature. Viewing an evolutionary graph problem as a stochastic process, where the states represent different
mutant-resident configurations, it is apparent that the original model specifies the transition probabilities. However, there are other ways to specify
the transition probabilities known as update rules. Several works address
different update rules [1, 25, 15]. Overall, we have identified three major
families of update rules - birth-death (a.k.a. the invasion process) where the
node to reproduce is chosen first, death-birth (a.k.a. the voter model) where
the node to die is chosen first, and link dynamics, where an edge is chosen.
We summarize these in Table 1.
We have already shown how our methods can deal with the original model
of Lieberman et al., often referred to as the Birth-Death (BD) process. In
this section, we apply our methods to the neutral-drift (non-biased) cases of
death-birth and link-dynamics. In these models, the weights of the edges is
typically not considered. Hence, in order to align this work with the majority
of literature on those models, we will express vertex probabilities in terms of
(i)
node in-degree (kin ) and the set of directed edges (E). We note that these
results can be easily extended to a more general case with an edge-weight
matrix as we used for the original model of EGT.
8

Table 1: Different families of update rules.

Update Rule
Birth-Death (BD)
(a.k.a. Invasion Process (IP))
Death-Birth (DB)
(a.k.a. Voter Model (VM))
Link Dynamics (LD)

Intuition
(1) Node i selected
(2) neighbor of i, node j selected
(3) Offspring of i replaces j
(1) Node i selected
(2) neighbor of i, node j selected
(3) Offspring of j replaces i
(1) Edge (i, j) selected
(2) The offspring of one node in the
edge replaces the other node

4.1. Death-Birth Updating
Under the death birth model (DB), at each time step, a vertex i is selected
for death. With a death-bias (DB-D), it is selected proportional to the inverse
of its fitness, with a birth-bias (DB-B) it is selected with a probability 1/N ,
which is also the probability under neutral drift. Then, an incoming neighbor
(j) is selected either proportional to the fitness of all incoming neighbors
(birth-bias), or with a uniform probability (in the case death-bias or neutral
drift). The selected neighbor then replaces i. Here, we compute Pi,t under
this dynamic with r = 1.
(i)

Pi,t = (1 − N −1 )Pi,t−1 + (N kin )−1

X

Pj,t−1

(8)

(j,i)∈E

We note that the proof of convergence still holds for death-birth - that
is for some time t, ∀i, the value Pi,t is the same, then Pi,t = FC . Further,
Theorem 4 holds for DB under neutral drift as well, specifically, for disjoint
sets C, D ⊆ V , FC + PD = PC∪D .
4.2. Link-Dynamics
With link dynamics (LD), at each time step an edge (i, j) is selected
either proportional to the fitness of i or the inverse of the fitness of j. It
has previously been shown that LD under birth bias is an equivalent process
9

to LD with a death bias [15]. Under neutral drift, the probability of edge
selection is 1/|E| (where |E| is the cardinality of set E). Then, i replaces j.
Now, we compute Pi,t under this dynamic with r = 1.
(i)

Pi,t = (1 − kin |E|−1 )Pi,t−1 +

1 X
Pj,t−1
|E|

(9)

(j,i)∈E

Again, convergence and additivity of the fixation probability still hold
under link dynamics just as with BD and DB.
5. Bounding Fixation Probability for r > 1
So far we have shown how our method can be used to find fixation probabilities under the case of neutral drift. Here, we show how our framework can
be useful in the case of an advantageous mutant (when the value for r, the
relative fitness, is greater than 1). First, we show that our method provides
a lower bound. We then provide an upper bound on the fixation probability that can be used in conjunction with our framework when studying the
case of the advantageous mutant. We note that certain parts of these proofs
are specific for diffent update rules, and we identify them using the abbreviations from the last section (DB-D, DB-B, and LD). The update of the
original model of [14] is known as the “birth-death” model and abbreviated
BD. If the fitness bias is on a birth event, we denote it as BD-B and if the
bias is on a death event we denote it as BD-D.
Naoki Masuda observes experimentally (through simulation) that the fixation probability computed with neutral drift appears to be a lower bound
on the fixation probability for an advantageous mutant [15]. We were able
to prove this result analytically – the proof is included in the supplementary
materials.
(1)

Theorem 5. For a given set C, let FC be the fixation probability under
(r)
neutral drift and FC be the fixation probability calculated using a mutant
fitness r > 1. Then, under BD-B, BD-D, DB-B, DB-D, or LD dynamics,
(1)
(r)
FC ≤ FC .
(r0 )

(r)

This proof leads to the conjecture that r0 > r implies FC ≥ FC . However, we suspect that proving this monotonicity property will require a different technique than used in Theorem 5. Next, to find an upper bound
10

that corresponds with the lower bound above, we use the proof technique introduced in [9], to obtain the following non-trivial upper bounds of fixation
probability for individual nodes in various update rules.
BD − B : F{i} ≤ r(r +

X

wji )−1

(10)

j

X

BD − D : F{i} ≤

j

DB − B : F{i} ≤

X

wji
r − rwji + wji

!−1

rwij (1 − wij + rwij )−1

(11)
(12)

j

DB − D : F{i} ≤ r

X

wij

(13)

j

6. A Lower Bound for Mean Time to Fixation
Another important, although less-studied problem with respect to evolutionary graph theory is the mean time to fixation - the average time it takes
for a mutant to take over the population. Closely related to this problem
are mean time to extinction (average time for the resident to take over) and
mean time to absorption (average time for either mutant or resident to take
over). This has been previously studied under the original Moran process
for well mixed populations [2] as well as some special cases of graphs [5].
However, to our knowledge, a general method to compute these quantities
(without resorting to the use of simulation) have not been previously studied.
Here we take a “first step” toward developing such a method by showing how
the techniques introduced in this paper can be used to compute a non-trivial
lower bound for mean time to fixation (and easily modified to bound mean
time to extinction and absorption).
Let Ft|C be the probability of fixation at time t. Therefore, Ft|C − Ft−1|C
is the probability of entering fixation at time t. The symbol tC is the mean
time. By the results of [2], we have the following:
Theorem 6.
∞
1 X
t · (Ft|C − Ft−1|C )
tC =
FC t=1

11

Our key intuition is noticing that at each time step t, Ft|C ≤ mini Pi,t .
From this, we use the accounting method to provide a rigorous proof for the
following theorem that provides a non-trivial lower-bound for the mean time
to fixation. This result can be easily modified for mean time to extinction
and absorption as well.
P
P∞
1
Theorem 7. F1C ∞
t=1 t·(Pmin,t −Pmin,t−1 ) ≤ FC
t=1 t·(Ft|C −Ft−1|C ) Where
Pmin,t = mini Pi,t .
7. Algorithm and Experimental Evaluation
We leverage the finding of the previous sections in Algorithm 1. As described
earlier, our method
S has found the exact fixation probability when all the
probabilities in i {Pi,t } (represented in the pseudo-code as the vector p) are
equal. We use Equation 4 to provide a convergence criteria based on value
, which we can prove to be the tolerance for the fixation probability.
Proposition 2. Algorithm 1 returns the fixation probability FC within ±.
Our novel method for computing fixation probabilities on strongly connected directed graphs allows us to compute near-exact fixation probabilities
within a desired tolerance. The running time of the algorithm is highly dependent on how fast the vertex probabilities converge. In this section we
experimentally evaluate how the vertex probabilities in our algorithms converge. We also provide results from comparison experiments to support the
claim that Algorithm 1-ACC finds adequate fixation probabilities order of
magnitudes faster than Monte Carlo simulations. We also show how the algorithm can be used to study the expected number of mutants as well as
bound mean time to fixation.
7.1. Convergence of Vertex Probabilities
We ran our algorithm to compute fixation probabilities on randomly
weighted and strongly connected directed graphs in order to experimentally
evaluate the convergence of the vertex probabilities. We generated the graphs
to be scale-free using the standard preferential attachment growth model [3]
and randomly assigned an initial mutant node. We replaced all edges in the
graph given by the growth model with two directed edges and then randomly
assigned weights to all the edges.
12

Algorithm 1 - Our Novel Solution Method to Compute Fixation Probabilities
Input: Evolutionary Graph hN, V, W i, configuration C ⊆ V , natural number
R > 0, and real number  ≥ 0.
Output: Estimate of fixation probability of mutant.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:

pi is the ith position in vector p corresponding with vertex i ∈ V .
Set pi = 1 if i ∈ C and pi = 0 otherwise. {As per Proposition 1}
q ← p {q will be p from the previous time step.}
τ ←1
while τ >  do
for i ∈ V {This loop carries out the calculation as per Equation 3}
do
sum ← 0
m ← {j ∈ V |wji > 0}
for j ∈ m do
sum = sum + wji · (qj − qi )
end for
pi ← qi + 1/N · sum
end for
q←p
τ ← (1/2)·(max p−min p) {Ensures error bound based on Equation 4}
end while
return (min p) + τ

13

106

0.10
MinP
MaxP
AvgP
Final

0.06

Speedup

Vertex Probability

0.08

0.04

105

0.02
0.00

0

20000 40000 60000 80000 100000

t

104

100

200

300

400

500

Graph Size (Number of Nodes)

Figure 1: Left: Convergence of the minimum (MinP), maximum (MaxP), and average
(AvgP) of vertex probabilities towards the final fixation probability as a function of our
algorithm’s iterations t for a graph of 100 nodes. Right: Average speedup (on a log scale)
for finding fixation probabilities achieved by our algorithm vs Monte Carlo simulation for
graphs of different sizes.

To compare Algorithm 1 with the Monte Carlo approach, we should
set the parameter R in that algorithm to be comparable with  in Algorithm 1. As  is the provable error of a solution to Algorithm 1. Based on
the commonly-accepted definition of estimated standard error from statistics, we can obtain the estimated standard error for the solution returned by
Monte Carlo approach with the following expression (where R is the number
of simulation runs).
r
FC (1 − FC )
(14)
R−1
We can use Equation 14 to estimate the parameter R for the Monte
Carlo approach as follows. We set  equal to the estimated standard error
as per Expression 14 and manipulate it algebraically. This gives us R ≈
S(S−1)
+ 1 where S is the solution to Algorithm 1,  is the input parameter
2
for Algorithm 1 and R is the number of simulation runs in the Monte Carlo
approach that we estimate to provide a comparable error bound. We also
note, that as the vertex probabilities converge, the standard deviation of the
p vector in Algorithm 1 could be a potentially faster convergence criteria.
14

0.10

Stdev of Vertex Probabilities

0.09
0.08
0.07
0.06
0.05
0.04
0.03
0.02
0.01

0

20000

40000

60000

80000

100000

t
Figure 2: Standard deviation of vertex probabilities as a function of our algorithm’s iterations for the same 100 node graph of Figure 1 (left).

Note that using standard deviation of p and returning the average vertex
probability would no longer provide us of the guarantee in Proposition 2,
however it may provide good results in practice. The modifications to the
algorithm would be as follows: line 15 would be τ ← st.dev(p) and line 17
would be return avg(p). We will refer to this as Algorithm 1 with alternate
convergence criteria or Algorithm 1-ACC for short.
Figure 1 (left) shows the convergence of the minimum, maximum, and the
average of vertex probabilities towards the final fixation probability value for
a small graph of 100 nodes. We can observe that the average converges to
the final value at a logarithmic rate and much faster than the minimum and
maximum vertex probability values. This suggests that while Algorithm 1ACC does not give the same theoretical guarantees as Algorithm 1, it is much
preferable for speed since the minimum and maximum vertex probabilities
take much longer to converge to the final solution than the average. The
fact that the average of the vertex probabilities is much preferable as a fast
estimation of fixation probabilities is supported by the logarithmic decrease
of the standard deviation of vertex probabilities (see Figure 2). Convergences
15

for other and larger graphs are not shown here but are qualitatively similar
to the relative convergences shown in the provided graphs.
7.2. Speed Comparison to Monte Carlo Simulation
In order to compare our method’s speed compared to the standard Monte
Carlo simulation method, we must determine how many iterations our algorithm must be run to find a fixation probability estimate comparable to that
of the Monte Carlo approach. Thankfully, as we have seen, we can get a
standard error on the fixation probability returned by the Monte Carlo approach as per Equation 14. While we did not theoretically prove anything
about how smoothly fixation probabilities from our methods approach the
final solution, the convergences of the average and standard deviation as
shown above strongly suggest that estimates from our method approach the
final solution quite gracefully. In fact, in the following experiments, once
our method has arrived at a fixation probability estimate within the standard error of simulations, the estimate never again fell outside the window of
standard error (although the estimate did not always approach the final estimate monotonically). This is in stark contrast to Monte Carlo simulations,
from which estimations can vary greatly before the method has completed
enough single runs to achieve a good probability estimate.
We generated a number of randomly weighted and strongly connected
directed graphs of various sizes on which we compare our solution method
to Monte Carlo approximation of fixation probabilities. The graphs were
generated as in our convergence experiments. For each graph of a different
size, we generated a number of different initial mutant configurations. We
found fixation probabilities both using Monte Carlo estimation with 2000
simulation runs and our direct solution method, terminating when we have
reached within the standard error of the Monte Carlo estimation. Since the
average vertex probability proved to be such a good fast estimate of the true
fixation probability, we used Algorithm 1-ACC.
Figure 1 (right) shows the speedup our solution provides over Monte
Carlo simulation. Here speedup is defined as the ratio of the time it takes
for simulations to complete over the time it takes our algorithm to find a
fixation probability within the standard deviation. The often extremely low
number of iterations needed by our algorithm to find fixation probabilities
within the standard error of simulations may prompt the concern that the
probabilities fall within this window so soon by mere chance. However, our
experiments have shown that the fixation probability estimation found by
16

our algorithm at each iteration approaches the final fixation probability after
termination smooothly at a logarithmic rate, asymptotically approaching the
true fixation probability. While in this case the fixation probability estimate
slightly crosses over the true fixation probability and then slowly approaches
it again, none of the fixation probability estimates from our algorithm exited
the window of standard error (from simulations) once they entered it.
We can observe from our experiments that computing fixation probabilities using Monte Carlo simulations showed to be a very time-expensive
process, highlighting the need for faster solution methods as the one we have
presented. Especially for larger graph sizes, the time complexity of our solution to achieve similar results to Monte Carlo simulation has shown to be
orders of magnitude smaller than the standard method.
7.3. Monitoring the Expected Number of Mutants
As observed in Section 3, our method not only allows for the calculation
of the fixation probability of a mutant, but also allows us to study how the
expected number of mutants change over time. In this section, we present
experimental results exploring the trajectory of the expected number of mutants over time on various undirected/unweighted graphs and under different
initial mutant placement conditions.
First, we note that the expected number of mutants (as time approaches
infinity) in an unweighted/undirected graph with respect to a single initially
infected vertex i can be computed by modifying the result of [6] (for BD
updating) to obtain the following.
(t)

lim Ex{i} =

t→∞

1
ki hk −1 i

(15)

Where hk −1 i is the average inverse of the degree for the graph. Hence, we
can determine whether a node amplifies or suppresses selection by observing
(t)
1
if lim t→∞ Ex{i} is greater or less than 1 respectively: if ki < hk−1
selection is
i
1
amplified and if ki > hk−1 i it is suppressed. We have used our algorithm to
compare the trajectory of the expected number of mutants over time when
the initial mutant is placed on amplifiers vs. suppressors under different
graph topologies and BD updating. We note that similar comparisons can
be obtained with our algorithm for the other update rules. We also note that
by Theorem 5, an amplifier for BD (with no bias) will also be an amplifier
for the (biased) BD-B and BD-D where r > 1.
17

Expected Number of Mutants

Mutant at Highest Degree

Mutant at Lowest Degree

1.4

1.4

1.2

1.2

1.0

1.0

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.00

100

200

300

400

500 0.00

100

200

t

300

400

500

t
BA

ERD

NWS

Figure 3: Expected number of mutants over time starting with a single mutant placed
on a graph for Barabási-Albert preferential attachment (BAR), Erdős-Rényi (ERD), and
Newmann-Watts-Strogatz small world (NWS) graphs. Lines are averages over 50 random
graphs of each type. In the left graph, mutants are placed at the highest degree nodes,
which are suppressors. In the right graph, mutants are placed at lowest degree nodes,
which are amplifiers.

Figure 3 shows the trajectories of the expected number of mutants over
time on random [3] preferential attachment (BAR), [10] (ER), and [19] small
world graphs (NWS), each for when the initial mutant is placed on a suppressor (highest degree node of graph) and amplifier (lowest degree node of
graph). Graphs are all of equal size at 100 nodes. We note that the highest
degree nodes are especially strong suppressors on BAR graphs, less so for
NWS graphs, and even less so for ER graphs. This makes sense when one
considers the degree distribution of the different graph topologies, which are
scale-free or power-law (P (k) ∼ k −3 ) for BR, roughly Poisson-shaped for
NWS, and relatively uniform for ER graphs. For lowest degree amplifiers,
the expected number of mutants grows faster early on in Barabási-Albert
graphs, but it plateaus earlier than and is eventually surpassed by the slower
growing expected number of mutants in the Erdős-Rényi, and NewmannWatts-Strogatz graphs. Such insights into the evolutionary process may be
18

Expected Number of Mutants

70
60
50
40
30

dcon_mn < dcon_rn
dcon_mn ≈ dcon_rn
dcon_mn > dcon_rn

20
10
0

0

20000

40000

60000

80000

100000

t
Figure 4: Expected number of mutants over time for an Erdős-Rényi graph of 100 nodes,
with an extra muntant node (mn) and resident node(rn) with directed edges to con mn
and con rn respectively. The value that the expected number of mutants converges to
depends on the relative degrees of con mn and con rn, as shown in the legend.

crucial in applications, e.g. when one may be more interested in achieving
highest number of mutants in a short amount of time rather than highest
number of mutants as t → ∞ or vice versa.
Finally, thus far we have only considered strongly connected graphs in
which the vertex probabilities converge as t → ∞, but this is not the case
for some non-strongly connected graphs. We have thus also investigated the
expected number of mutants over time for some simple cases of such graphs.
Consider a random graph that is strongly connected, and then have a resident
node (rn) and mutant node (mn) connected with only directed edges into the
strongly connected graph. Clearly, the vertex probabilities cannot converge,
since ∀ t, Pmn,t = 1 and Prn,t = 0. Our experimental results in Figure 4 show
however that while the vertex probabilities do not converge, the value for
the expected number of mutants given by our algorithm seems to converge.
What value the expected number of mutants converges to depends on the
relative degrees of the nodes that the mutant node mn and resident node
19

rn connect to. We shall call these nodes con mn and con rn, respectively.
If kcon mn ≈ kcon rn , the expected value of mutants converges at around 50%
of the graph’s nodes. If kcon mn > kcon rn , the expected value of mutants
is less than 50% of the graph’s nodes, and conversely, if kcon mn < kcon rn ,
it is greater. These results are intuitive because lower degree nodes are
better spreaders under BD updating. These results are also interesting because the expected value converges - even though the graphs are not strongly
connected. By an examination of Equation 6, this convergence is possible.
However, we have not proven that convergence always occurs. An interesting direction for future work is to identify under what conditions will the
expected number of mutants converges in a non-strongly connected graph.
7.4. Experimentally Computing the Lower Bound of the Mean Time to Fixation
We also performed experiments to examine the lower bound on mean
time to fixation (discussed in Section 6) as compared to the average fixation
time determined from simulation run. In doing so, we were able to confirm
the lower-bound experimentally. We were able to use Algorithm 1-ACC to
compute the lower bound with a few changes (noted in the supplement).
We generated random (ER) graphs of size 10, 20, 50 and 100 nodes, creating five different graphs for each number of nodes. The graphs were generated
as in our convergence experiments, and our comparison to Monte Carlo testing are shown in Figure 5 where we demonstrate experimentally that our
algorithm produces a lower bound. Our algorithm was run until the standard deviation of fixation probabilities for all vertices was 2.5 × 10−6 . The
Monte Carlo simulations were each set at 10, 000 runs.
8. Application: Competition Among Neural Axons
In recent work, [26] created a model for synaptic competition based on
death-birth updating under neutral drift. They noted that the model aligns
well with their empirical observations. In the model, the graph represents a
synaptic junction and the nodes represent sites in the junction. For every two
adjacent sites in the synaptic junction, there is an undirected edge between
the corresponding two nodes in the graph. Hence, in- and out- degrees of
each node are the same. Initially, there are K different axon types located
in the junction configured in a manner where all sites are initially occupied
by one axon type. At each time step, an axon occupying one of the sites is
20

106
Sim
Alg

Time Steps

105

104

103

102

10

20

50

100

Graph Size (Number of Nodes)
Figure 5: Mean-time-to-fixation comparison between algorithm and simulation. Note that
the y-axis is a logarithmic scale.

eliminated - making the site open. The selection of the axon for elimination
(death) is with a uniform probability. Hence, there is no bias in this model.
Following the elimination of an axon, an adjacent axon grows into the site.
The adjacent axon is selected with a uniform probability of the eliminated
axon’s neighbors. Hence, based on the results of this paper, we can provide
the following insights into synaptic competition.
1. After t axons are eliminated,1 the probability of any site being occupied
by an axon of a certain type can be calculated directly by Theorem 8.
Even though there are K axon types, this theorem still applies as it
only considers the probability of a node being a mutant (resp. a site
being a one of the K axon types).
2. Using point 1 above, we can determine the expected number of axons
of a given type after t axons being eliminated.
1

Note that the number of axons eliminated corresponds directly to the number of
timesteps in the model.

21

3. After t axons are eliminated, the probability of any set of sites being
occupied by a certain axon type is simply the sum of the probabilities
of the individual sites being occupied by that axon. As a result, the
fixation probability is additive.
4. Leveraging point 3 above combined with an easy modification of the
result of Broom et al. [6] for the BD model, the fixation probability
ki
where ki is the number of sites
of an axon originating at site i is 2·Θ
adjacent to site i (hence the degree of node i in the corresponding
graph) and Θ is the total number of adjacencies in the synapse (hence,
half the number of directed edges in the corresponding graph).
5. Based on item 4 above and the results from Section 3, we can conclude
that for a given axon type (let’s call it “axon type A”) occupying a
set of sites, that if the average adjacencies of those sites is greater
than (resp. less than) the overall average adjacencies for the sites in
the entire synaptic junction, then as the number of eliminated axons
approaches infinity, we can expect the number of axon type A in the
synaptic junction will increase (resp. decrease) in expectation.
6. We can directly apply Theorem 7 to find a lower-bound on the number
of eliminated axons before fixation occurs.
We note that the results stated above are either precise mathematical arguments or calculations that can be found exactly with a deterministic algorithm. They are not theoretical approximations and do not rely on simulation. As such is the case, we can make more precise statements about
synaptic competition (given the model) and can avoid the variance that
accompanies simulation results. Insights such as these may lead to future
biological experiments.
9. Related Work
Evolutionary graph theory was originally introduced in [14]. Previously,
we have compiled a comprehensive review [24] for a general overview of the
work in this exciting new area.
While most work dealing with evolutionary graphs rely on Monte Carlo
simulation, there are some good analytical approximations for the undirected/unweighted cased based on the degree of the vertices in question.
Antal et al. [1] use the mean-field approach to create these approximations
for the undirected/unweighted case. Broom et al. [6] derive an exact analytical result for the undirected/unweighted case in neutral drift, which agrees
22

with the results of Antal et al. They also show that fixation probability is
additive in that case (a result which we extend in this paper using a different
proof technique). However, the results of [16] demonstrate that mean-field
approximations break down in the case of weighted, directed graphs. [15]
also studied weighted, directed graphs, but does so by using Monte Carlo
simulation. [22] derive exact computation of fixation probability through
means of linear programming. However, that approach requires an exponential number of both constraints and variables and is intractable. The recent
work of [27] introduces a parameter called graph determinacy which measures the degree to which fixation or extinction is determined while starting
from a randomly choses initial configuration. This property is then used
to analyze some special cases of evolutionary graphs under birth-death updating. There has been some work on algorithms for fixation probability
calculation that rely on a randomized approach [4, 9]. [4] present a heuristic technique for speeding up Monte Carlo simulations by early termination
while [9] present utilize simulation runs in a fully-polynomial randomized
approximation scheme. However, our framework differs in that it does not
rely on simulation at all and provides a deterministic result. Further, our
non-randomized approach also allows for additional insights into the evolutionary process - such as monitoring the expected number of mutants as a
function of time. Recently, [12] study the related problem of determining the
probability of fixation given a single, randomly placed mutant in the graph
where the vertices are “islands” and there are many individuals residing on
each island in a well-mixed population. They use quasi-fixed points of ODE’s
to obtain an approximation of the fixation probability and performed experiments with a maximum of 5 islands (vertices) containing 50 individuals each.
This continuous approximation provides the best results when the number
of individuals in each island is much larger than the number of islands. As
the problem of this paper can be thought of as a special case where each
island has just one individual, it seems unlikely that the approximation of
Houchmandzadeh and Vallade’s approach will hold here.
Some of the results in this paper were previously presented in conferences
by the authors [23, 17]. The analysis and experiments concerning the expected number of mutants at a given time, the extension of the framework
for other update rules (beyond birth-death), the use of the framework for the
case of r > 1, and the neurology applications are all new results appearing
for the first time in this paper.

23

10. Conclusion
In this paper, we introduced a new approach to deal with problems relating to evolutionary graphs that rely on “vertex probabilities.” Our presented
analytical method is the first deterministic method to compute fixation probability and provides a number of novel uses and results for EGT problems:
• Our method can be used to solve for the fixation probability under
neutral drift orders of magnitude faster than Monte Carlo simulations,
which is currently the presiding employed method in EGT studies. We
have extended the method to all of the commonly used update processes in EGT. The special case of neutral drift is not only of interest
in the literature [6, 15] but also it has been applied to problems in
neurology [26].
• While the presented method is currently constrained to the case of
neutral drift, we have demonstrated how it can inform cases of nonneutral drift by using it to provide both a lower and upper bound for
this case. Combined with our analytical method’s speed, this means
that it can be used to acquire useful knowledge to guide general EGT
studies interested in the case of advantageous mutants.
• We have shown how our analytical method can be used to calculate a
non-trivial lower bound to the mean time to fixation, providing a first
step for a general method to computing this and related quantities that
is lacking in the current literature.
• We have shown how our method can be used to calculate deterministically the expected number of mutants, which is useful for applications
that require predictions on the number of mutants in the population
under a specific finite time horizon. We have also provided results on
the expected number of mutants on different common graph topologies,
showing differences in the growth trajectories of amplifiers and suppressors on these different topologies. These results may prove highly
significant in the recent application of EGT to distributed systems [13]
where the problem of information diffusion is considered among computer systems. In such a domain, it may be insufficient to guarantee
fixation in the limit of time - which may be impractical - but rather to
make guarantees on the outcome of the process after a finite amount
of time.
24

• Finally, we have shown how our method can provide insight when applied to the problem of synaptic competition in neuroscience.
Though evolutionary graph theory is still a relatively new research area, it
is actively being studied in a variety of disciplines [14, 24, 28, 25, 20, 26, 13].
We believe that more real-world applications will appear as this area gains
more popularity. As illustrated by recent work [26, 13], experimental scientists with knowledge of EGT may be more likely to recognize situations
where the model may be appropriate. As these cases arise, deterministic
methods for addressing issues related to EGT may prove to be highly useful.
However, this paper is only a starting point - there are still many important directions for future work. Foremost among such topics are scenarios
where the topology of the graph also changes over time or where additional
attributes of the nodes/edges in the graph affect the dynamics.
Acknowledgments
P.S. is supported by ARO projects 611102B74F and 2GDATXR042 as well as
OSD project F1AF262025G001. P.R. is supported by ONR grant W911NF0810144.
P.S. would like to thank Stephen Turney (Harvard University) for several
discussions concerning his work. The opinions in this paper are those of the
authors and do not necessarily reflect the opinions of the funders, the U.S.
Military Academy, the U.S. Army, or the U.S. Navy.
References
1 Antal, T., Redner, S., Sood, V., 2006. Evolutionary dynamics on degreeheterogeneous graphs. Physical Review Letters 96 (18), 188104.
2 Antal, T., Scheuring, I., 2006. Fixation of strategies for an evolutionary
game in finite populations. Bulletin of Mathematical Biology 68, 1923–
1944.
3 Barabási, A., Albert, R., 1999. Emergence of scaling in random networks.
science 286 (5439), 509–512.
4 Barbosa, V. C., Donangelo, R., Souza, S. R., Oct 2010. Early appraisal
of the fixation probability in directed networks.

25

5 Broom, M., Hadjichrysanthou, C., Rychtář, J., 2009. Evolutionary games
on graphs and the speed of the evolutionary process. Proceedings of the
Royal Society A.
6 Broom, M., Hadjichrysanthou, C., Rychtář, J., Stadler, B. T., Apr. 2010.
Two results on evolutionary processes on general non-directed graphs.
Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences 466 (2121), 2795–2798.
7 Broom, M., Rychtář, J., May 2009. An analysis of the fixation probability
of a mutant on special classes of non-directed graphs. Proceedings of the
Royal Society A 464, 2609–2627.
8 Broom, M., Rychtář, J., Stadler, B., 2011. Evolutionary dynamics on
graphs - the effect of graph structure and initial placement on mutant
spread. Journal of Statistical Theory and Practice 5 (3), 369–381.
9 Dı́az, J., Goldberg, L., Mertzios, G., Richerby, D., Serna, M., Spirakis,
P., Jan. 2012. Approximating Fixation Probabilities in the Generalized
Moran Process. In: Proceedings of the ACM-SIAM Symposium on Discrete Algorithms (SODA), Kyoto, Japan. ACM.
10 Erdős, P., Rényi, A., 1960. On the evolution of random graphs. Akad.
Kiadó.
Hagberg et al. Hagberg, Aric A. and Schult, Daniel A. and Swart, Pieter J..
Exploring network structure, dynamics, and function using NetworkX. In
Proceedings of the 7th Python in Science Conference (SciPy2008), pages
11–15, Pasadena, CA USA, August 2008.
12 Houchmandzadeh, B., Vallade, M., July 2011. The fixation probability
of a beneficial mutation in a geographically structured population. New
Journal of Physics 13 (7), 073020.
URL http://stacks.iop.org/1367-2630/13/i=7/a=073020
13 Jiang, C., Chen, Y. C., Liu, K. J. R., Dec 2012. Distributed Adaptive Networks: A Graphical Evolutionary Game-Theoretic View. arXiv:
1212.1245.
14 Lieberman, E., Hauert, C., Nowak, M. A., 2005. Evolutionary dynamics
on graphs. Nature 433 (7023), 312–316.
26

15 Masuda, N., 2009. Directionality of contact networks suppresses selection
pressure in evolutionary dynamics. Journal of Theoretical Biology 258 (2),
323 – 334.
16 Masuda, N., Ohtsuki, H., 2009. Evolutionary dynamics and fixation probabilities in directed networks. New Journal of Physics 11 (3), 033012
(15pp).
17 Moores, G., Shakarian, P., 2012. A fast and deterministic method for
mean time to fixation in evolutionary graphs. Presented at INSNA Sunbelt XXXII, Redondo Beach, CA.
18 Moran, P., 1958. Random processes in genetics. Mathematical Proceedings of the Cambridge Philosophical Society 54 (01), 60–71.
19 Newman, M., Watts, D., 1999. Renormalization group analysis of the
small-world network model. Physics Letters A 263 (4-6), 341–346.
20 Pacheco, J. M., Traulsen, A., Nowak, M. A., December 2006. Active
linking in evolutionary games. Journal of Theoretical Biology 243 (3),
437–443.
21 Paley, C. J., Taraskin, S. N., Elliott, S. R., 2007. Temporal and dimensional effects in evolutionary graph theory. Physical Review Letters 98,
098103.
22 Rychtář, J., Stadler, B., Winter 2008. Evolutionary dynamics on smallworld networks. International Journal of Computational and Mathematical Sciences 2 (1).
23 Shakarian, P., Roos, P., Nov. 2011. Fast and deterministic computation
of fixation probability in evolutionary graphs. In: CIB ’11: The Sixth
IASTED Conference on Computational Intelligence and Bioinformatics.
IASTED.
24 Shakarian, P., Roos, P., Johnson, A., 2012. A review of evolutionary
graph theory with applications to game theory. Biosystems 107 (2), 66 –
80.
URL
http://www.sciencedirect.com/science/article/pii/
S0303264711001675

27

25 Sood, V., Antal, T., Redner, S., 2008. Voter models on heterogeneous
networks. Physical Review E 77 (4), 041121.
26 Turney, S., Lichtman, J., June 2012. Reverseing the outcome of synapse
elimination at devloping neuromuscular junction in vivo: Evidence for
synapcitc competition and its mechansm. PLoS Biology 10.
27 Voorhees, B., 2012. Birth-Death Fixation Probabilities for Structured
Populations. Proceedings of the Royal Society A: Mathematical, Physical
and Engineering Sciences (accepted).
28 Zhang, P. A., Nie, P. Y., Hu, D. Q., Zou, F. Y., 2007. The analysis of
bi-level evolutionary graphs. Biosystems 90 (3), 897–902.

28

Supplementary Material
11. Notes
Throughout this supplement, we will use an extended notation. Fixation
probability given initial configuration C is denoted FC . For vertex i at time
(t)
(t)
t, we denote this as Pr(Mi ). We will use Si to denote the event that vertex
(t)
i was selected for reproduction and Rij to denote the event of i replacing
(t)
j. We will often use conditional probabilities. For example, Pr(Mi |C (0) )
is the probability that vi is a mutant given the initial set C of mutants.
Throughout this supplement, unless noted otherwise, all of our probabilities will be conditioned on C (0) . We will drop it for ease of notation with
the understanding that some set C of V were mutants at t = 0. Hence,
(t)
(t)
Pr(Mi ) = Pr(Mi |C (0) ).
12. Proof of Theorem 1

(t)

∀i, lim t→∞ Pr(Mi |C (0) ) = FC
(t)

Proof. Consider the following definition property of Pr(Mi |C (0) )
X
(t)
Pr(V 0(t) |C (0) )
Pr(Mi |C (0) ) =

(16)

0 ∈2V

V
s.t. vi ∈V 0

We note that as time approaches infinity, for all V 0 ∈ 2V − ∅ − V we have
Pr(V 0(t) |C (0) ) = 0. As vi ∈
/ ∅, the statement follows. Q.E.D.
13. Proof of Theroem 2
(t)

Pr(Mi ) =
(t−1)

Pr(Mi

X

)+

(t−1)

wji · Pr(Mj

(t)

(t−1)

) · Pr(Sj |Mj

(vj ,vi )∈E
(t)

Where Si is true iff vi is selected for reproduction at time t.

29

(t−1)

) − wji · Pr(Mi

(t)

(t−1)

) · Pr(Sj |Mi

)

(t)

Proof. Note we use the variable Rj i is true iff vj replaces vi at time t.
CLAIM 1:
(t)

(t−1)

Pr(Mi ) = Pr(Mi

^

∧

(vj ,vi )∈E

X

(t)

X

(t)

¬Sj ) +

(t)

(t)

(t−1)

Pr(Sj ∧ Rji ∧ Mj

)+

(vj ,vi )∈E
(t)

(t−1)

Pr(Sj ∧ ¬Rji ∧ Mi

)

(vj ,vi )∈E

This is shown by a simple examination of exhaustive and mutually exclusive
events based on the original model of [14].
CLAIM 2:

(t−1)

Pr(Mi

^

∧

(t)

(t−1)

¬Sj ) = Pr(Mi


X

) · 1 −

(vj ,vi )∈E

(t)

(t−1)

Pr(Sj |Mi

)

(vj ,vi )∈E

(Proof of claim 2) By exhaustive and mutual exclusive events, we have the
following.
^
X
(t−1)
(t)
(t−1)
(t)
(t−1)
)
)−
Pr(Sj ∧ Mi
∧
¬Sj ) = Pr(Mi
Pr(Mi
(vj ,vi )∈E

(vj ,vi )∈E

By the definition of conditional probability, we have the following

^
X 
(t−1)
(t)
(t−1)
(t)
(t−1)
(t−1)
Pr(Mi
∧
¬Sj ) = Pr(Mi
)−
Pr(Sj |Mi
) · Pr(Mi
)
(vj ,vi )∈E

(vj ,vi )∈E

=

(t−1)
Pr(Mi
)

(t−1)

− Pr(Mi

)·

X

(t)

(vj ,vi )∈E


(t−1)

= Pr(Mi


X

) 1 −

(t)

(t−1)

Pr(Sj |Mi

(vj ,vi )∈E

The claim immediately follows.
CLAIM 3: For all edges (vj , vi ), we have the following.
(t)

(t)

(t−1)

Pr(Sj ∧ Rji ∧ Mj

(t−1)

) = wji · Pr(Mj
30

(t)

(t−1)

Pr(Sj |Mi

(t−1)

) · Pr(Sj |Mj

)

)

)

(Proof of claim 3) The following is a direct application of the definition of
conditional probability.
(t)

(t)

(t−1)

Pr(Sj ∧ Rji ∧ Mj

(t)

(t−1)

) = Pr(Rji ∧ Mj

(t)

(t)

|Sj ) · Pr(Sj )

(t)

From our model, we note that given even Sj , the fitness of the nodes is not
(t)
considered in determining if the event associated with Rji is to occur. Hence,
(t−1)
(t)
(t)
(t) (t)
it follows that Mj
is independent of Rji given Sj . As Pr(Rji |Sj ) = wji ,
we have the following.
(t)

(t)

(t−1)

Pr(Sj ∧ Rji ∧ Mj

(t)

(t)

(t−1)

) = Pr(Rji |Sj ) · Pr(Mj
(t−1)

= wji · Pr(Mj

(t)

(t)

|Sj ) · Pr(Sj )

(t)

(t)

|Sj ) · Pr(Sj )
(t)

By Bayes Theorem, and that the model causes ∀iPr(Si ) > 0, we have the
following.
(t−1)

(t)
Pr(Sj

∧

(t)
Rji

∧

(t−1)
Mj )

= wji ·

(t−1)
(t)
Pr(Sj |Mj )
(t−1)

= wji · Pr(Mj

)·

·

Pr(Mj

)

(t)
Pr(Sj )
(t)
(t−1)
Pr(Sj |Mj )

(t)

· Pr(Sj )

The claim follows immediately.
CLAIM 4: For all edges (vj , vi ), we have the following.
(t)

(t)

(t−1)

Pr(Sj ∧ ¬Rji ∧ Mi

(t−1)

) = (1 − wji ) · Pr(Mi

(t)

(t−1)

) · Pr(Sj |Mi

)

(Proof of claim 4) This mirrors claim 3.
(Proof of theorem) From claims 1-4, we have the following.


X
(t)
(t−1)
(t)
(t−1) 
Pr(Mi ) = Pr(Mi
) · 1 −
Pr(Sj |Mi
) +

(17)

(vj ,vi )∈E

X 

(t−1)

wji · Pr(Mj

(t)

(t−1)

) · Pr(Sj |Mj


) +

(18)

(vj ,vi )∈E

X 

(t−1)

(1 − wji ) · Pr(Mi

(t)

(t−1)

) · Pr(Sj |Mi


)
(19)

(vj ,vi )∈E

Which, after re-arranging some terms, gives us the statement of the theorem.
Q.E.D.
31

14. Proof of Theorem 3
(t)

When r = 1, if for some time t, ∀i, the value Pr(Mi ) is the same, then
(t)
Pr(Mi ) = FC .
(t)

(t−1)

Proof Sketch. Consider Pr(Mi ) = Pr(Mi
(t−1)

)+ N1

(t−1)
)−
(vj ,vi )∈E wji ·(Pr(Mj
(t−1)
Pr(Mi
). Clearly,

P

(t−1)

Pr(Mi
)) when for t − 1, ∀i, j we have Pr(Mj ) =
(t)
(t−1)
in this case, the value for Pr(Mi ) = Pr(Mi
). As the probabilities of all
vertices was the same at t − 1, they remain so at t. Therefore, in this case,
(t)
(t)
lim t→∞ Pr(Mi ) = Pr(Mi ). QED

15. Proof of Inequality 4
For any time t, under neutral drift (r = 1),
(t)

(t)

min Pr(Mi ) ≤ FC ≤ max Pr(Mi )
i

i

Proof.
PART 1: For any time t, under neutral drift (r = 1), FC ≤
(t)
maxi Pr(Mi ).
(t)
(t−1)
) ≥ maxi Pr(Mi ). Hence,
We show that for each time step t, maxi Pr(Mi
0
(t)
(t )
by showing that, for any time t0 , we have maxi Pr(Mi ) ≥ lim t→∞ maxi Pr(Mi )
which by allows us to apply Theorem 1 and obtain the statement of this theo(t−1)
(t)
rem. Suppose BWOC that at time t we have max` Pr(M` ) < maxi Pr(Mi ).

32

Then we have:
(t−1)

max Pr(M`
`

) <

1
N

X



(t−1)
(t−1)
wji · Pr(Mj ) − Pr(Mi
)

(vj ,vi )∈E
(t−1)

≤

+Pr(Mi
1 X
N

)



(t−1)
(t−1)
wji · max Pr(M` ) − Pr(Mi
)
`

(vj ,vi )∈E
(t−1)

+Pr(Mi
P
=
P
(t−1)
max Pr(M` )(1
`

−

(vj ,vi )∈E

wji

)

(vj ,vi )∈E wji

N
(t−1)
)
+Pr(Mi

(t−1)
max Pr(M` )
`

P
) <

(t−1)
)(1
Pr(Mi

N
(t−1)
(t−1)
)
max Pr(M` ) < Pr(Mi

−

(vj ,vi )∈E

N

wji

−

)

`

Which is clearly a contradiction and completes this part of the proof.
(t)
PART 2: For any time t, under neutral drift (r = 1), FC ≥ mini Pr(Mi ).
(t−1)
(t)
We show that for each time step t, mini Pr(Mi
) ≤ mini Pr(Mi ). Hence,
(t0 )
(t)
by showing that, for any time t0 , we have mini Pr(Mi ) ≤ lim t→∞ maxi Pr(Mi )
which by allows us to apply Theorem 1 and obtain the statement of this theor(t−1)
(t)
erm. Suppose BWOC that at time t we have min` Pr(M` ) > mini Pr(Mi ).

33



(t−1)
)
Pr(Mi

Then we have:
(t−1)

min Pr(M`
`

) >

1
N

X



(t−1)
(t−1)
wji · Pr(Mj ) − Pr(Mi
)

(vj ,vi )∈E
(t−1)

≥

+Pr(Mi
1 X
N

)



(t−1)
(t−1)
wji · min Pr(M` ) − Pr(Mi
)
`

(vj ,vi )∈E
(t−1)

+Pr(Mi
P
=
P
(t−1)
min Pr(M` )(1
`

(vj ,vi )∈E

−

wji

)

(vj ,vi )∈E wji

N
(t−1)
)
+Pr(Mi

(t−1)
min Pr(M` )
`

P
) >

(t−1)
)(1
Pr(Mi

N
(t−1)
(t−1)
)
min Pr(M` ) > Pr(Mi

−

(vj ,vi )∈E

wji

N

−

(t−1)
)
Pr(Mi

)

`

Which is clearly a contradiction and completes this part of the proof. Q.E.D.
16. Proof of Theorem Theorem 4
When r = 1 for disjoint sets C, D ⊆ V , FC + FD = FC∪D .
(t)
Proof. Consider some time t and vertex vi . Clearly, by Corollary 1, Pr(Mi )
P
(0)
can be expressed as a linear combination of the form vj ∈V (Cj · Pr(Mj ))
where Cj is a coefficient. We note that these coefficients are the same re(t)
gardless of the initial configuration of mutants that Mi is conditioned on.
(0)
(t)
Hence, Pr(Mi |C (0) ) is this positive function with Pr(Mj ) = 1 if vj ∈ C
and 0 otherwise (see Proposition 3). Hence, for disjoint C, D, for any vi ∈ V ,
(t)
(t)
(t)
we have Pr(Mi |C (0) )+Pr(Mi |D(0) ) = Pr(Mi |(C ∪D)(0) ). The statement
follows. Q.E.D.
17. Proof of Equation 9

(t)
Pr(Mi )


=

1
1−
N



(t−1)

· Pr(Mi

)+

34

1
N·

X

(i)
kin (vj ,vi )∈E

(t−1)

Pr(Mj

)



Under death-birth dynamics with neutral drift (r = 1).
(t)
(t)
Proof. Di and Bi are random variables associated with birth and death
events for vertex vi .
P
(t)
(t−1)
(t)
(t)
(t)
(t−1)
CLAIM 1: Pr(Mi ) = Pr(Mi
∧¬Di )+ (vj ,vi )∈E Pr(Di ∧Bj ∧Mj )
Follows directly form exhaustive and mutually
exclusive events.

(t−1)
(t−1)
(t)
)
CLAIM 2: Pr(Mi
∧ ¬Di ) = 1 − N1 · Pr(Mi
(t)
(t−1)
By the definition of conditional probabilities, we have Pr(¬Di |Mi
)·
(t−1)
Pr(Mi
). Also, we know the probability of a given node dying is always
(t)
(t−1)
(t)
1/N . Hence, Pr(¬Di |Mi
) = Pr(¬Di ) = 1 − N1 and the claim follows.
CLAIM 3: For any (vj , vi ) ∈ E, we have
(t)
(t)
(t−1)
(t−1)
Pr(Di ∧ Bj ∧ Mj ) = 1 (i) · Pr(Mj )
N ·kin

As both birth and death events occur independent of any node being a mutant
at the previous time step, the definition of conditional probabilities gives us
the following:
(t)

(t)

(t−1)

Pr(Di ∧ Bj ∧ Mj

(t)

(t−1)

(t)

) = Pr(Di ∧ Bj ) · Pr(Mj
=

(t)
(t)
Pr(Bj |Di )

·

(t)
Pr(Di )

·

)

(20)

(t−1)
Pr(Mj )

(21)

From the model, we have the following:
(t)

(i)

(t)

Pr(Bj |Di ) = 1/kin

(22)

(t)

Pr(Di ) = 1/N

(23)

Hence, the claim follows. QED Q.E.D.
18. Proof of Equation 10

(i)

(t)

Pr(Mi ) =

k
1 − in
|E|

!
(t−1)

· Pr(Mi

)+

1
|E|

X

(t−1)

Pr(Mj

)

(vj ,vi )∈E

Under link dynamics with neutral drift (r = 1).
(t)
Proof. Here Sij is the random variable associated with the selection of edge
(vi , vj ).
V
P
(t)
(t−1)
(t)
(t)
CLAIM 1: Pr(Mi ) = Pr(Mi
∧ (vj ,vi )∈E ¬Sji ) + (vj ,vi )∈E Pr(Sji ∧
(t−1)

Mj

)
35

Follows directly form exhaustive and mutually exclusive events.
(i)
V
kin
(t)
CLAIM 2: Pr( (vj ,vi )∈E ¬Sji ) = 1 − |E|
V
W
(t)
(t)
Clearly, we have Pr( (vj ,vi )∈E ¬Sji ) = Pr( {(vβ ,vα )∈E|β6=i} Sβα ). As there are
(i)
W
kin
(i)
(t)
,
kin incoming edges to vi , we know that Pr( {(vβ ,vα )∈E|β6=i} Sβα ) = 1 − |E|
giving us the claim.


(i)
V
kin
(t−1)
(t)
(t−1)
CLAIM 3: Pr(Mi
∧ (vj ,vi )∈E ¬Sji ) = 1 − |E| · Pr(Mi
)
(t)

(t−1)

For any α, β, the random variable Sαβ is independent from Mi
the claim immediately follows from this fact and claim 2.
(t−1)
(t)
(t−1)
1
· Pr(Mj )
CLAIM 4: Pr(Sji ∧ Mj ) = |E|
(t)

(t−1)

. Hence,

(t)

1
As, by the definition of the model, Pr(Sji |Mj ) = Pr(Sji ) = |E|
, the
claim follows directly form the definition of conditional probabilities. QED
Q.E.D.

19. Proof of Theorem 5
For a given set C, let F (1) (C) be the fixation probability under neutral
drift and F (r) (C) be the fixation probability calculated using a mutant fitness
r > 1. Then, under BD-B, BD-D, DB-B, DB-D, or LD dynamics, F (1) (C) ≤
F (r) (C).
Proof. First, some notation.
• We define an interpretation, I : 2V → [0, 1] as probability
P distribution
over mutant configurations. Hence, for some I we have V 0 ∈2V I(V 0 ) =
1.
• Next, we define a transition function that maps configurations
P of mutants to probabilities, χ : 2V → [0, 1] where for any C ∈ 2V , C 0 ∈2V χ(C, C 0 ) =
1. We will use χ+ and χ− to indicate if the transition is made with a
mutant being selected for birth (χ+ ) or resident (χ− ). Hence, for some
C ∈ V and v ∈
/P
C, χ− (C, C ∪ {v}) = 0 and χ+ (C ∪ {v}, C) = 0. Hence,
V
for all C ∈ 2 , C 0 ∈2V (χ+ (C, C 0 ) + χ− (C, C 0 )) = 1.
• If the transitioon function is based on birth-death and computed with
(r)
(r)
some r > 1, then we will write it as χ+ , χ− respectively. If computed
(nd)
(nd)
with r = 1, then we write χ+ , χ− respectively.

36

• For some C ∈ 2C , let inc(C) be the set of all elements D ∈ 2V s.t.
|D| ≥ |C| and χ+ (C, D) > 0.
• For some C ∈ 2C , let dec(C) be the set of all elements D ∈ 2V s.t.
|D| ≤ |C| and χ− (C, D) > 0.
(r)

• Given set C ⊆ V , we will use FC to denot the probability of fixation
given initial set of mutants C where the value r is used to calculate all
transition probabilities.
CLAIM 1: If a some time period, the probability
over mutant
P distribution
(r)
configurations is I, the fixation probability is C∈2V I(C) · FC .
(r)

Clearly, for any time t, FC = lim i→∞ Pr(V (i) |C (t) ). Under the assumption that there exists some tim ω s.t. fixation is reached, we have:
(r)

FC

= Pr(V (ω) |C (t) )
Pr(V (ω) ∧ C (t) )
=
Pr(C (t) )

(r)

Hence, FC · Pr(C (t) ) = Pr(V (ω) ∧ C (t) ). The statement then follows by the
summation of exhaustive and mutually exclusive events.
CLAIM 2: If a some time period t, the probability distribution over mutant
configurations is I, and the transition functions used to reach the next time
step are χ+ , χ− , then the probability
of being in some mutant configuration
P
C at time t + 1 is given by D∈2V I(D) · (χ+ (D, C) + χ− (D, C)).
Follows directly from the rules of dynamics.
CLAIM 3: If a some time period t, the probability distribution over mutant configurations is I, mutant fitness r, and the transition functions used
(r)
(r)
to reach the next time step are χ+ , χ− , and all subsequent transitions are
computed using the same dynamics with neutral drift, then the fixation probability is:


X
X
X
(r)
(1)
(r)
(1)
(χ− (C, D) · FD ))
P(I, r) =
I(C) · 
(χ+ (C, D) · FD ) +
C∈2V

D∈inc(C)

D∈dec(C)

37

Follows directly from claims 1-2.
CLAIM 4: Under BD-B, BD-D, DB-B, DB-D, or LD dynamics, for some
(r)
(r0 )
(r)
r ≤ r0 , for all C, D ∈ 2V , we have χ+ (C, D) ≤ χ+ (C, D) and χ− (C, D) ≥
0
(r )
χ− (C, D).
(r)

CLAIM 4a: For some r ≤ r0 , for all C, D ∈ 2V , we have χ+ (C, D) ≤
(r0 )
χ+ (C, D).
Let {vj } = D − C. For each vertex vi , fi = 1 if vi ∈
/ C (a resident) and fi = r
if vi ∈ C (a mutant). When D ≡ C, the following are all summed over the
set {vj ∈ C|∃vi ∈ C ∧ (vi , vj ) ∈ E}.
• Under BD-B,
X

(r)

χ+ (C, D) =

vi ∈C|
(vi ,vj )∈E

r · wij
r · |C| + N − |C|

• Under BD-D,
wij

X
vi ∈C|
(vi ,vj )∈E

N·

P

vq |(vi ,vq )∈E

wiq · fq−1

• Under DB-B,
(r)

χ+ (C, D) =

wij · r

X
vi ∈C|
(vi ,vj )∈E

N·

P

vq |(vq ,vj )∈E

wqj · fq

• Under DB-D,
(r)

χ+ (C, D) =

wij

X
P
vi ∈C|
(vi ,vj )∈E

vq ∈V

fq−1

• Under LD,
(r)

χ+ (C, D) =

wij · r

X
P
vi ∈C|(vi ,vj )∈E

38

vq ,v` |(vq ,v` )∈E

wq` · fq

By simple algebraic manipulation, for each of these, when all values other
than r are fixed, they increase as r increases.
(r)

CLAIM 4b: For some r ≤ r0 , for all C, D ∈ 2V , we have χ− (C, D) ≥
(r0 )
χ− (C, D). Let {vj } = C − D. For each vertex vi , fi = 1 if vi ∈
/ C (a
resident) and fi = r if vi ∈ C (a mutant). When D ≡ C, the following are
all summed over the set {vj ∈ V − C|∃vi ∈ V − C ∧ (vi , vj ) ∈ E}.
• Under BD-B,
X

(r)

χ+ (C, D) =

vi ∈V −C|
(vi ,vj )∈E

wij
r · |C| + N − |C|

• Under BD-D,
X
vi ∈V −C|
(vi ,vj )∈E

N·

wij · r−1
−1
vq |(vi ,vq )∈E wiq · fq

P

• Under DB-B,
wij

X

(r)

χ+ (C, D) =

vi ∈V −C|
(vi ,vj )∈E

N·

P

vq |(vq ,vj )∈E

wqj · fq

• Under DB-D,
(r)
χ+ (C, D)

=

X
vi ∈V −C|
(vi ,vj )∈E

w · r−1
P ij
−1
vq ∈V fq

• Under LD,
(r)

χ+ (C, D) =

wij

X
P
vi ∈V −C|(vi ,vj )∈E

39

vq ,v` |(vq ,v` )∈E

wq` · fq

By simple algebraic manipulation, for each of these, when all values other
than r are fixed, they decrease as r increases.
CLAIM 5: Given some C ∈ 2V , for all pairs D, D0 where D ∈ inc(C) and
(1)
(1)
D0 ∈ dec(C), we have FD ≥ FD0 .
Follows directly from Theorem 5.
CLAIM 6: Given interpretation I, under BD-B, BD-D, DB-B, DB-D, or LD
dynamics, for some r > 1, P(I, r) ≥ P(I, 0).
Let us consider some set C from the outermsot summation in the computation of P(I, r). Suppose, BWOC, there exists some C ∈ 2V s.t.:
X

(r)

(1)

(χ+ (C, D) · FD ) +

D∈inc(C)

(r)

X

(1)

(χ− (C, D) · FD )

D∈dec(C)

(1)

X

<

(1)

X

(χ+ (C, D) · FD ) +

D∈inc(C)

(1)

(1)

(r)

(1)

(χ− (C, D) · FD )

D∈dec(C)

This give us:
X

(r)

(1)

(χ+ (C, D) · FD ) −

D∈inc(C)

X

(1)

(1)

(χ+ (C, D) · FD )

X

<

D∈inc(C)

(1)

(1)

X

(χ− (C, D) · FD ) −

D∈dec(C)

(χ− (C, D) · FD )

D∈dec(C)

(1)

(1)

Let Fsm = inf {FD |D ∈ inc(C)} and Flg = sup{FD |D ∈ dec(C)}, this give
us:
X

Fsm

(r)

(1)

(χ+ (C, D) − χ+ (C, D))

<

D∈inc(C)

X

Flg

(1)

(r)

(χ− (C, D) − χ− (C, D))

D∈dec(C)

Consider ther following:
X

(r)

χ+ (C, D) +

D∈inc(C)

X
D∈inc(C)

X

(r)

χ− (C, D)

=

D∈dec(C)
(r)

χ+ (C, D) −

X

X

(1)

χ+ (C, D) +

D∈inc(C)
(1)

χ+ (C, D)

=

D∈inc(C)

X
D∈dec(C)

X

(1)

χ− (C, D)

D∈dec(C)
(1)

χ− (C, D) −

X

(r)

χ− (C, D)

D∈dec(C)

Note that by claim 4, both sides of the above equation are positive numbers.
Hence, we have Fsm < Flg , which contradicts claim 5.
PROOF OF THEOREM: Let P (1) (I, r) = P(I, r) and P (i+1) (I, r) = P(P (i) (I, r), r).
By claim 6, for any i, P (i+1) (I, r) ≥ P(P (i) (I, r), r). Consider an interpretation I that describes the initial probability distribution over mutant
configurations. The fixation probability under neutral drift is P(I, 1). For
some value r > 1, the fixation probaiblity is lim i→∞ P (i) (I, r). Clearly,
lim i→∞ P (i) (I, r) ≥ P(I, 1). Q.E.D.
40

20. Proof of Theorem 6

∞
1 X
t · (Ft|C − Ft−1|C )
tC =
FC t=1

Proof. This proof was first presented in [2]. The mean time to fixation is
described as the expected time to fixation given that the process fixates. Let
Ft|C be the probability that fixation is reached in exactly t time-steps or less.
Hence, the probability of reaching fixation in exactly t time steps conditioned
on the process reaching fixation is (Ft|C − Ft−1|C )/FC . The remainder of the
theorem follows from the definition of an expected value. Q.E.D.
21. Proof of Theorem 7
We introduce two pieces of notation tf ix , tconvg . We define tf ix as a time
Ptf ix
(t
)
t · (Ft|C − Ft−1|C ). and tconvg s.t. ∀i, Pr(Mi convg ) = FC .
s.t. tC = F1C t=1
While in reality, both of these values could be infinite, we note that the
relationship ∞ ≥ tf ix ≥ tconvg holds and that using a lower value for tf ix
and/or tconvg will still ensure we have a lower bound.
∞
∞
1 X
1 X
t · (Pmin,t − Pmin,t−1 ) ≤
t · (Ft|C − Ft−1|C )
FC t=1
FC t=1
(t)

Where Pmin,t = mini Pr(Mi ).
Proof. First, we have the following.
tconvg

X

t · (Pmin,t − Pmin,t−1 ) ≤

t=1

tf ix
X

t · (Ft|C − Ft−1|C )

(24)

t=1
(t)

(t)

For any time t, let PC = Ft|C − Ft−1|C and Pr(∆Mmin ) = Pmin,t − Pmin,t−1 .
(t)
As for each time t, we have Pmin,t ≥ Ft|C , we can define θt0 as the portion of
0
(t)
(t )
(t)
PC accounted for in Pr(∆Mmin ). This results in having θt0 = 0 whenever

41

t0 > t or t > tconvg as well as the following:
(t)

PC

t
X

=

(t)

θt0

(25)

t0 =1
(t)
Pr(∆Mmin )

tf ix
X

=

(26)

t0 =t
tconvg tf ix

tconvg

X

(t0 )

θt

X X

t · (Pmin,t − Pmin,t−1 ) =

(t0 )

tθt

(27)

t0 =t

t=1

t=1
tconvg tf ix

X X

=

(t0 )

tθt

(28)

t=1 t0 =1
tf ix tconvg

X X

=

t0 =1

t=1

tf ix

0

t
XX

=

(t0 )

tθt

(t0 )

tθt

(29)

(30)

t0 =1 t=1

We also note that the following is true:
tf ix
X

t · (Ft|C − Ft−1|C ) =

tf ix
X

(t0 )

t0 PC

(31)

t0 =1

t=1

0

tf ix
t
X
X
(t0 )
0
=
t
θt
t0 =1
tf ix

≥

(32)

t=1
0

t
XX

(t0 )

tθt

(33)

t0 =1

t=1
tconvg

=

X

t · (Pmin,t − Pmin,t−1 )

(34)

t=1

Which concludes the proof. Q.E.D.
22. Materials and Methods
Except for the experiments dealing with time to fixation/extinction, all
algorithms were implemented in Python and run on a 2.33GHz Intel Xeon
42

CPU. The time-to-fixation experiments were run on a machine equipped with
an Intel Core i7 M620 processor running at 2.67 GHz with 4 GB RAM.
All graphs in the experiments were generated using the Python NetworkX
package [Hagberg et al.]. Parameters used for the experiments concerning the
expected number of mutants were m=1 for BA, p = 0.5 for ER, and k = 2
and p = 0.5 for NWS graph generator functions.
We modified Algorithm 1-ACC based on the results on mean time to
fixation as follows:
• Before line 14, insert: t += 1; Sum += t*(min(p)-min(q))
• Replace line 17 with: return = Sum/average(p), where average(q)
is the algorithm’s best estimate for Pc at termination.

43

2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining

Large Social Networks can be Targeted for Viral Marketing with Small Seed Sets
Paulo Shakarian and Damon Paulo
Network Science Center and
Department of Electrical Engineering and Computer Science
United States Military Academy
West Point, New York 10996
Email: paulo[at]shakarian.net, damon.paulo[at]usma.edu

we provide formal deﬁnitions of the tipping model. This
is followed by the presentation of our new algorithm in
Section III. We then describe our experimental results in
Section IV. Finally, we provide an overview of related work
in Section V.

Abstract—In a “tipping” model, each node in a social
network, representing an individual, adopts a behavior if a
certain number of his incoming neighbors previously held that
property. A key problem for viral marketers is to determine
an initial “seed” set in a network such that if given a property
then the entire network adopts the behavior. Here we introduce
a method for quickly ﬁnding seed sets that scales to very large
networks. Our approach ﬁnds a set of nodes that guarantees
spreading to the entire network under the tipping model. After
experimentally evaluating 31 real-world networks, we found
that our approach often ﬁnds such sets that are several orders
of magnitude smaller than the population size. Our approach
also scales well - on a Friendster social network consisting of
5.6 million nodes and 28 million edges we found a seed sets
in under 3.6 hours. We also ﬁnd that highly clustered local
neighborhoods and dense network-wide community structure
together suppress the ability of a trend to spread under the
tipping model.

II. T ECHNICAL P RELIMINARIES
Throughout this paper we assume the existence of a social
network, G = (V, E), where V is a set of vertices and E is
a set of directed edges. We will use the notation n and m
for the cardinality of V and E respectively. For a given node
vi ∈ V , the set of incoming neighbors is ηiin , and the set of
outgoing neighbors is ηiout . The cardinalities of these sets
out
(and hence the in and out degrees of node vi ) are din
i , di
respectively. We now deﬁne a threshold function that for
each node returns the fraction of incoming neighbors that
must be activated for it to become activate as well.
Deﬁnition 1 (Threshold Function): We deﬁne the threshold function as mapping from V to (0, 1]. Formally: θ :
V → (0, 1].
For the number of neighbors that must be active, we will
use the shorthand ki . Hence, for each vi , ki = θ(vi ) · din
i .
We now deﬁne an activation function that, given an initial
set of active nodes, returns a set of active nodes after one
time step.
Deﬁnition 2 (Activation Function): Given a threshold
function, θ, an activation function Aθ maps subsets of V
to subsets of V, where for some V  ⊆ V ,

Keywords-social networks; viral marketing

I. I NTRODUCTION
A much studied model in network science, tipping [1]–[3]
(a.k.a. deterministic linear threshold [4]) is often associated
with “seed” or “target” set selection, [5] (a.k.a. the maximum
inﬂuence problem). In this problem we have a social network
in the form of a directed graph and thresholds for each
individual. Based on this data, the desired output is the
smallest possible set of individuals such that, if initially
activated, the entire population will adopt the new behavior
(a seed set). This problem is NP-Complete [4], [6]. Although
approximation algorithms have been proposed, [5], [7]–[9]
none seem to scale to very large data sets. Here, inspired by
shell decomposition, [10]–[12] we present a method guaranteed to ﬁnd a set of nodes that causes the entire population
to activate - but is not necessarily of minimal size. We then
evaluate the algorithm on 31 large real-world social networks
and show that it often ﬁnds very small seed sets (often
several orders of magnitude smaller than the population
size). We also show that the size of a seed set is related
to Louvain modularity and average clustering coefﬁcient.
Therefore, we ﬁnd that dense community structure and tightknit local neighborhoods together inhibit the spreading of
trends under the tipping model.
The rest of the paper is organized as follows. In Section II,
978-0-7695-4799-2 2012
U.S. Government Work Not Protected by U.S. Copyright
DOI 10.1109/ASONAM.2012.11

Aθ (V  ) = V  ∪ {vi ∈ V s.t. |ηiin ∩ V  | ≥ ki }

(1)

We now deﬁne multiple applications of the activation
function.
Deﬁnition 3 (Multiple Applications of the Activation Function):

Given a natural number i > 0, set V  ⊆ V , and threshold
function, θ, we deﬁne the multiple applications of the
activation function, Aiθ (V  ), as follows:

Aθ (V  )
if i = 1
i

Aθ (V ) =
(2)

(V
))
otherwise
Aθ (Ai−1
θ


Clearly, when Aiθ (V  ) = Ai−1
θ (V ) the process has
converged. Further, this occurs in no more than n steps (as,

1

in each step, at least one new node must be activated). Based
on this idea, we deﬁne the function Γ which returns the set
of all nodes activated upon the convergence of the activation
function.
Deﬁnition 4 (Γ Function): Let j be the least value such
(V  ). We deﬁne the function Γθ : 2V →
that Ajθ (V  ) = Aj−1
θ
V
2 as follows.
(3)
Γθ (V  ) = Ajθ (V  )
We now have all the pieces to introduce our problem ﬁnding the minimal number of nodes that are initially active
to ensure that the entire set V becomes active.
Deﬁnition 5 (The MIN-SEED Problem): The
MINSEED Problem is deﬁned as follows: given a threshold
function, θ, return V  ⊆ V s.t. Γθ (V  ) = V , and there does
not exist V  ⊆ V where |V  | < |V  | and Γθ (V  ) = V .
The following theorem is from the literature [4], [6] and
tells us that the MIN-SEED problem is NP-complete.
Theorem 1 (Complexity of MIN-SEED [4], [6]): MINSEED in NP-Complete.

Figure 1. Example of our algorithm for a simple network depicted in box
A. We use a threshold value set to 50% of the node degree. Next to each
din

i
node label (lower-case letter) is the value for din
i −ki (where ki =  2 ).
In the ﬁrst four iterations, nodes e, f, h, and i are removed resulting in the
network in box B. This is followed by the removal of node j resulting in
the network in box C. In the next two iterations, nodes a and b are removed
(boxes D-E respectively). Finally, node c is removed (box F). The nodes
of the ﬁnal network, consisting of d and g, have negetive values for di − θi
and become the output of the algorithm.

III. A LGORITHM
To deal with the intractability of the MIN-SEED problem,
we design an algorithm that ﬁnds a non-trivial subset of
nodes that causes the entire graph to activate, but we do not
guarantee that the resulting set will be of minimal size. The
algorithm is based on the idea of shell decomposition often
cited in physics literature [10]–[13] but modiﬁed to ensure
that the resulting set will lead to all nodes being activated.
The algorithm, TIP DECOMP is presented in this section.

there are no nodes for which din
i − ki is positive (or 0), the
algorithm outputs the remaining nodes in the network.
Now, we prove that the resulting set of nodes is guaranteed
to cause all nodes in the graph to activate under the tipping
model. This proof follows from the fact that any node
removed is activated by the remaining nodes in the network.
Theorem 2: If all nodes in V  ⊆ V returned by
TIP DECOMP are initially active, then every node in V
will eventually be activated, too.
Proof: Let w be the total number of nodes removed
by TIP DECOMP, where v1 is the last node removed and
vw is the ﬁrst node removed. We prove the theorem by
induction on w as follows. We use P (w) to denote the
inductive hypothesis which states that all nodes from v1 to
vw are active. In the base case, P (1) trivially holds as we
are guaranteed that from set V  there are at least k1 edges
to v1 (or it would not be removed). For the inductive step,
assuming P (w) is true, when vw+1 was removed from the
graph distw+1 ≥ 0 which means that din
w+1 ≥ kw+1 . All
in
at the time when vw+1 was removed are now
nodes in ηw+1
active, so vw+1 will now be activated - which completes the
proof.
We also note that by using the appropriate data structure
(we used a binomial heap in our implementation), for a
network of n nodes and m edges, this algorithm can run
in time O(m log n).
Proposition 1: The complexity of TIP DECOMP is
O(m · log(n)).

Algorithm 1 TIP DECOMP
Require: Threshold function, θ and directed social network
G = (V, E)
Ensure: V 
1:
2:
3:
4:
5:
6:
7:
8:
9:

10:
11:
12:

For each vertex vi , compute ki .
For each vertex vi , disti = din
i − ki .
FLAG = TRUE.
while FLAG do
Let vi be the element of v where disti is minimal.
if disti = ∞ then
FLAG = FALSE.
else
Remove vi from G and for each vj in ηiout , if
distj > 0, set distj = distj − 1. Otherwise set
distj = ∞.
end if
end while
return All nodes left in G.

Intuitively, the algorithm proceeds as follows (Figure 1).
Given network G = (V, E) where each node vi has threshold
ki = θ(vi ) · din
i , at each iteration, pick the node for which
−
k
is
the
least but positive (or 0) and remove it. Once
din
i
i

2

IV. R ESULTS
All experiments were run on a computer equipped with an
Intel X5677 Xeon Processor operating at 3.46 GHz with a 12
MB Cache. The machine was running Red Hat Enterprise
Linux version 6.1 and equipped with 70 GB of physical
memory. TIP DECOMP was written using Python 2.6.6
in 200 lines of code that leveraged the NetworkX library
available from http://networkx.lanl.gov/. The code used a
binomial heap library written by Björn B. Brandenburg
available from http://www.cs.unc.edu/∼bbb/. All statistics
presented in this section were calculated using R 2.13.1.
A. Datasets
In total, we examined 31 networks: nine academic collaboration networks, three e-mail networks, and 19 networks
extracted from social-media sites. The sites included included general-purpose social-media (similar to Facebook
or MySpace) as well as special-purpose sites (i.e. focused
on sharing of blogs, photos, or video).
All datasets used in this paper were obtained from one
of four sources: the ASU Social Computing Data Repository, [14] the Stanford Network Analysis Project, [15]
the University of Michigan, [16] and Universitat Rovira
i Virgili. [17] All networks considered were symmetric –
i.e. if a directed edge from vertex v to v  exists, there is
also an edge from vertex v  to v. Tables I (A-C) show
some of the pertinent qualities of these networks. The
networks are categorized by the results (explained later
in this section). The networks we obtained were from a
variety of sources. These included samples from the online
social media sites BlogCatalog, Buzznet, Douban, Flickr,
Flixster, FourSquare, Friendster, Last.Fm, LiveJournal, Livemocha, Delicious, Digg, Hyves, Yelp, and YouTube (all
obtained from [14]); communications networks such as
WikiPedia communications (WikiTalk), e-mail from an European Union research institution (EU E-Mail), and the Enron e-mail network (Enron E-Mail) (all obtained from [15])
as well as the University Rovira i Virgili e-mail network
(URV E-Mail) [17]; and academic collaboration networks
on Astro Physics, (CA-AstroPh), General Relativity and
Quantum Cosmology (CA-GrQc), High Energy Physics Phenomenology (CA-HepPh), High Energy Physics - Theory
(CA-HepTh), Condense Matter Physics (CA-CondMat) (all
obtained from [15]) as well as other Condense Matter
Physics collaboration network samples (CA-CondMat) and
a Network Science collaboration network (CA-NetSci) from
[16].

Table I
I NFORMATION ON THE NETWORKS IN C ATEGORIES A, B,

AND

C.

processed by our algorithm in at most 12.2 minutes. The
often-cited LiveJournal dataset consisting of 2.2 million
nodes and 25.6 million directed edges was processed in
no more than 66 minutes - a short time for an NP-hard
combinatorial problem on a large-sized input.
C. Seed Size
For each network, we performed 10 “integer” trials. In
these trials, we set θ(vi ) = min(din
i , k) where k was kept
constant among all vertices for each trial and set at an integer
in the interval [1, 10]. We evaluated the ability of a network
to promote spreading under the tipping model based on the
size of the set of nodes returned by our algorithm (as a
percentage of total nodes). For purposes of discussion, we

B. Runtime
First, we examined the runtime of the algorithm (see
Figure 2). Our experiments aligned well with our time
complexity result (Proposition 1). For example, a network
extracted from the Dutch social-media site Hyves consisting
of 1.4 million nodes and 5.5 million directed edges was

3

Figure 2. m ln n vs. runtime in seconds (log scale, m is number of
edges, n is number of nodes). The relationship is linear with R2 = 0.9015,
p = 2.2 · 10−16 .

have grouped our networks into three categories based on
results (Figure 3 and Table II). In general, online social
networks had the smallest seed sets - 13 networks of this
type had an average seed set size less than 2% of the
population. We also noticed, that for most networks, there
was a linear realtion between threshold value and seed size.
Category A can be thought of as social networks highly
susceptible to inﬂuence - as a very small fraction of individuals initially having a behavior can lead to adoption by the
entire population. In our ten trials, the average seed size was
under 2% for each of these 13 networks. All were extracted
from social media websites. For some of the lower threshold
levels, the size of the set of seed nodes was particularly
small. For a threshold of three we had 11 of the Category A
networks with a seed size less than 0.5% of the population.
For a threshold of four, we had nine networks meeting that
criteria.

Figure 3. Threshold value (assigned as an integer in the interval [1, 10])
vs. size of initial seed set as returned by our algorithm in our three
identiﬁed categories of networks (categories A-C are depicted in panels
A-C respectively). Average seed sizes were under 2% for Categorty A,
2 − 10% for Category B and over 10% for Category C. The relationship,
in general, was linear for categories A and B and lograthimic for C. CANetSci had the largest Louvain Modularity and clustering coefﬁcient of all
the networks. This likely explains why that particular network seems to
inhibit spreading.

Networks in Category B are susceptible to inﬂuence with
a relatively small set of initial nodes - but not to the extent
of those in Category A. They had an average initial seed
size greater than 2% but less than 10%. Members in this
group included two general purpose social media networks,
two specialty social media networks, and an e-mail network.

D. Seed Size as a Function of Community Structure
In this section, we view the results of our heuristic
algorithm as a measurement of how well a given network
promotes spreading. Here, we use this measurement to gain
insight into which structural aspects make a network more
likely to be “tipped.” We compared our results with two
network-wide measures characterizing community structure.
First, clustering coefﬁcient (C) is deﬁned for a node as the
fraction of neighbor pairs that share an edge - making a

Category C consisted of networks that seemed to hamper
diffusion in the tipping model, having an average initial seed
size greater than 10%. This category included all of the
academic collaboration networks, two of the email networks,
and two networks derived from friendship links on YouTube.

4

triangle. For the undirected case, we deﬁne this concept
formally below.
Deﬁnition 6 (Clustering Coefﬁcient): Let r be the number of edges between nodes with which vi has an edge
and di be the degree of vi . The clustering coefﬁcient,
2r
Ci =
.
di (di − 1)
Intuitively, a node with high Ci tends to have more pairs
of friends that are also mutual friends. We use the average
clustering coefﬁcient as a network-wide measure of this local
property.
Second, we consider modularity (M ) deﬁned by Newman
and Girvan. [18]. For a partition of a network, M is a
real number in [−1, 1] that measures the density of edges
within partitions compared to the density of edges between
partitions. We present a formal deﬁnition for an undirected
network below.
Deﬁnition 7 (Modularity [18]): Modularity,
1 
di d j
M =
]δ(ci , cj ), where m is the
[1 −
m i,j∈E
2m
number of undirected edges, di is node degree, ci is the
community to which vi belongs and δ(x, y) = 1 if x = y
and 0 otherwise.
The modularity of an optimal network partition can be
used to measure the quality of its community structure.
Though modularity-maximization is NP-hard, the approximation algorithm of Blondel et al. [19] (a.k.a. the “Louvain
algorithm”) has been shown to produce near-optimal partitions.1 We call the modularity associated with this algorithm
the “Louvain modularity.” Unlike the C, which describes
local properties, M is descriptive of the community level.
For the 31 networks we considered, M and C appear
uncorrelated (R2 = 0.0538, p = 0.2092).
We plotted the initial seed set size (S) (from our algorithm
- averaged over the 10 threshold settings) as a function of
M and C (Figure 4a) and uncovered a correlation (planar
ﬁt, R2 = 0.8666, p = 5.666 · 10−13 , see Figure 4 A).
The majority of networks in Category C (less susceptible to
spreading) were characterized by relatively large M and C
(Category C includes the top nine networks w.r.t. C and top
ﬁve w.r.t. M ). Hence, networks with dense, segregated, and
close-knit communities (large M and C) suppress spreading.
Likewise, those with low M and C tended to promote
spreading. Also, we note that there were networks that
promoted spreading with dense and segregated communities,
yet were less clustered (i.e. Category A networks Friendster
and LiveJournal both have M ≥ 0.65 and C ≤ 0.13).
Further, some networks with a moderately large clustering
coefﬁcient were also in Category A (two networks extracted
from BlogCatalog had C ≥ 0.46) but had a relatively
less dense community structure (for those two networks
M ≤ 0.33).

Figure 4. (A) Louvain modularity (M ) and average clustering coefﬁcient
(C) vs. the average seed size (S). The planar ﬁt depicted is S = 43.374 ·
M +33.794·C −24.940 with R2 = 0.8666, p = 5.666·10−13 . (B) Same
plot at (A) except the averages are over the 12 percentage-based threshold
values. The planar ﬁt depicted is S = 18.105 · M + 17.257 · C − 10.388
with R2 = 0.816, p = 5.117 · 10−11 .

We also studied the effects on spreading when the threshold values would be assigned as a certain fraction of the
node’s in-degree. [3], [20] This results in heterogeneous θi ’s
for the nodes. We performed 12 trials for each network.
Thresholds for each trial were based on the product of indegree and a fraction in the interval [0.05, 0.60] (multiples
of 0.05). The results (Figure 5 and Table II) were analogous
to our integer tests. We also compared the averages over
these trials with M and C and obtained similar results as
with the other trials (Figure 4 B).

1 Louvain modularity was computed using the implementation available
from CRANS at http://perso.crans.org/aynaud/communities/.

5

Table II
R EGRESSION ANALYSIS AND NETWORK - WIDE MEASURES FOR THE
NETWORKS IN C ATEGORIES A, B, AND C.

Figure 5. Threshold value (assigned as a fraction of node in-degree as
a multiple of 0.05 in the interval [0.05, 0.60]) vs. size of initial seed set
as returned by our algorithm in our three identiﬁed categories of networks
(categories A-C are depicted in panels A-C respectively, categories are the
same as in Figure 1). Average seed sizes were under 5% for Categorty A,
1 − 7% for Category B and over 3% for Category C. In general, the
relationship between threshold and initial seed size for networks in all
categories was exponential.

activated. Dryer and Roberts [6] introduce the MIN-SEED
problem, study its complexity, and describe several of its
properties w.r.t. certain special cases of graphs/networks.
The hardness of approximation for this problem is described
in [5]. The work of [8] presents an algorithm for target-set
selection whose complexity is determined by the tree-width
of the graph - though it provides no experiments or evidence
that the algorithm can scale for large datasets. The recent
work of [21] prove a non-trivial upper bound on the smallest
seed set.
Our algorithm is based on the idea of shell-decomposition
that currently is prevalent in physics literature. In this
process, which was introduced in [13], vertices (and their

V. R ELATED W ORK
Tipping models ﬁrst became popular by the works of
[1] and [2] where it was presented primarily in a social
context. Since then, several variants have been introduced
in the literature including the non-deterministic version of
[4] (described later in this section) and a generalized version
of [3]. In this paper we focused on the deterministic version.
In [20], the authors look at deterministic tipping where each
node is activated upon a percentage of neighbors being

6

adjacent edges) are iteratively pruned from the network until
a network “core” is produced. In the most common case, for
some value k, nodes whose degree is less than k are pruned
(in order of degree) until no more nodes can be removed.
This process was used to model the Internet in [10] and
ﬁnd key spreaders under the SIR epidemic model in [11].
More recently, a “heterogeneous” version of decomposition
was introduced in [12] - in which each node is pruned
according to a certain parameter - and the process is studied
in that work based on a probability distribution of nodes
with certain values for this parameter.
A. Notes on Non-Deterministic Tipping
We also note that an alternate version of the model
where the thresholds are assigned randomly has inspired
approximation schemes for the corresponding version of the
seed set problem. [4], [7], [9] Work in this area focused on
ﬁnding a seed set of a certain size that maximizes of the
expected number of adopters. The main ﬁnding by Kempe
et al., the classic work for this model, was to prove that the
expected number of adopters was submodular - which allowed for a greedy approximation scheme. In this algorithm,
at each iteration, the node which allows for the greatest
increase in the expected number of adopters is selected.
The approximation guarantee obtained (less than 0.63 of
optimal) is contingent upon an approximation guarantee for
determining the expected number of adopters - which was
later proved to be #P -hard. [9] Though ﬁnding a such
a guarantee is still an open question, work on countingcomplexity problems such as that of Dan Roth [22] indicate
that a non-trivial approximation ratio is unlikely. Further, the
simulation operation is often expensive - causing the overall
time complexity to be O(x · n2 ) where x is the number of
runs per simulation and n is the number of nodes (typically,
x > n). In order to avoid simulation, various heuristics have
been proposed, but these typically rely on the computation
of geodesics - an O(n3 ) operation - which is also more
expensive than our approach.
Additionally, the approximation argument for the nondeterministic case does not directly apply to the original
(deterministic) model presented in this paper. A simple
counter-example shows that sub-modularity does not hold
here. Sub-modularity (diminishing returns) is the property
leveraged by Kempe et al. in their approximation result.

Figure 6. Integer threshold values vs. the seed size divided by Reichman’s
upper bound [21] the three categories of networks (categories A-C are
depicted in panels A-C respectively). Note that in nearly every trial, our
algorithm produced an initial seed set signiﬁcantly smaller than the bound
- in many cases by an order of magnitude or more.

were developed independently. We also note that Reichman
performs no experimental evaluation of the algorithm.

B. Note on an Upper Bound of the Initial Seed Set

Given undirected network G where each node vi has
degree di and the threshold value for all nodes is k,
Reichman proves
that the size of the minimal seed set can
be bounded by i min{1, dik+1 }. For our integer tests, we
compared our results to Reichman’s bound. Our seed sets
were considerably smaller - often by an order of magnitude
or more. See Figure 6 for details.

Very recently, we were made aware of research by Daniel
Reichman that proves an upper bound on the minimal size
of a seed set for the special case of undirected networks
with homogeneous threshold values. [21] The proof is constructive and yields an algorithm that mirrors our approach
(although Reicshman’s algorithm applies only to that special
case). We note that our work and the work of Reichman

7

VI. C ONCLUSION
As recent empirical work on tipping indicates that it can
occur in real social networks, [23], [24] our results are encouraging for viral marketers. Even if we assume relatively
large threshold values, small initial seed sizes can often be
found using our fast algorithm - even for large datasets. For
example, with the FourSquare online social network, under
majority threshold (50% of incoming neighbors previously
adopted), a viral marketeer could expect a 297-fold return
on investment. As results of this type seem to hold for many
online social networks, our algorithm seems to hold promise
for those wishing to “go viral.”

[8] O. Ben-Zwi, D. Hermelin, D. Lokshtanov, and I. Newman,
“Treewidth governs the complexity of target set selection,”
Discrete Optimization, vol. 8, no. 1, pp. 87–96, 2011.
[9] W. Chen, C. Wang, and Y. Wang, “Scalable inﬂuence maximization for prevalent viral marketing in large-scale social
networks,” in Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining,
ser. KDD ’10. New York, NY, USA: ACM, 2010, pp. 1029–
1038.
[10] S. Carmi, S. Havlin, S. Kirkpatrick, Y. Shavitt, and E. Shir,
“From the Cover: A model of Internet topology using k-shell
decomposition,” PNAS, vol. 104, no. 27, pp. 11 150–11 154,
2007.

ACKNOWLEDGMENTS
We would like to thank Gaylen Wong (USMA) for his
technical support. Additionally, we would like to thank (in
no particular order) Albert-László Barabási (NEU), Sameet
Sreenivasan (RPI), Boleslaw Szymanski (RPI), John James
(USMA), and Chris Arney (USMA) for their discussions
relating to this work. Finally, we would also like to thank
Megan Kearl, Javier Ivan Parra, and Reza Zafarani of ASU
for their help with some of the datasets. The authors are
supported under by the Army Research Ofﬁce (project
2GDATXR042) and the Ofﬁce of the Secretary of Defense
(project F1AF262025G001). The opinions in this paper are
those of the authors and do not necessarily reﬂect the
opinions of the funders, the U.S. Military Academy, or the
U.S. Army.

[11] M. Kitsak, L. K. Gallos, S. Havlin, F. Liljeros, L. Muchnik,
H. E. Stanley, and H. A. Makse, “Identiﬁcation of inﬂuential
spreaders in complex networks,” Nat Phys, no. 11, pp. 888–
893, Nov.
[12] G. J. Baxter, S. N. Dorogovtsev, A. V. Goltsev, and J. F. F.
Mendes, “Heterogeneous k-core versus bootstrap percolation
on complex networks,” Phys. Rev. E, vol. 83, May 2011.
[13] S. B. Seidman, “Network structure and minimum degree,”
Social Networks, vol. 5, no. 3, pp. 269 – 287, 1983.
[14] R. Zafarani and H. Liu, “Social computing data
repository
at
ASU,”
2009.
[Online].
Available:
http://socialcomputing.asu.edu
[15] J. Leskovec, “Stanford network analysis project (snap),”
2012. [Online]. Available: http://snap.stanford.edu/index.html

R EFERENCES

[16] M. Newman, “Network data,” 2011. [Online]. Available:
http://www-personal.umich.edu/ mejn/netdata/

[1] M. Granovetter, “Threshold models of collective behavior,”
The American Journal of Sociology, no. 6, pp. 1420–1443.

[17] A. Arenas, “Network data sets,” 2012. [Online]. Available:
http://deim.urv.cat/ aarenas/data/welcome.htm

[2] T. C. Schelling, Micromotives and Macrobehavior.
Norton and Co., 1978.

[18] M. E. J. Newman and M. Girvan, “Finding and evaluating
community structure in networks,” Phys. Rev. E, vol. 69,
no. 2, p. 026113, Feb 2004.

W.W.

[3] M. Jackson and L. Yariv, “Diffusion on social networks,” in
Economie Publique, vol. 16, no. 1, 2005, pp. 69–82.

[19] V. Blondel, J. Guillaume, R. Lambiotte, and E. Lefebvre,
“Fast unfolding of communities in large networks,” Journal
of Statistical Mechanics: Theory and Experiment, vol. 2008,
p. P10008, 2008.

[4] D. Kempe, J. Kleinberg, and E. Tardos, “Maximizing the
spread of inﬂuence through a social network,” in KDD
’03: Proceedings of the ninth ACM SIGKDD international
conference on Knowledge discovery and data mining. New
York, NY, USA: ACM, 2003, pp. 137–146.

[20] D. J. Watts and P. S. Dodds, “Inﬂuentials, networks, and
public opinion formation,” Journal of Consumer Research,
vol. 34, no. 4, pp. 441–458, 2007. [Online]. Available:
http://www.journals.uchicago.edu/doi/abs/10.1086/518527

[5] N. Chen, “On the approximability of inﬂuence in social
networks,” SIAM J. Discret. Math., vol. 23, pp. 1400–1415,
September 2009.

[21] D. Reichman, “New bounds for contagious sets,” Discrete
Mathematics (in press), no. 0, pp. –, 2012.

[6] P. Dreyer and F. Roberts, “Irreversible -threshold processes:
Graph-theoretical threshold models of the spread of disease
and of opinion,” Discrete Applied Mathematics, vol. 157,
no. 7, pp. 1615 – 1627, 2009.

[22] D. Roth, “On the hardness of approximate reasoning,” Artiﬁcial Intelligence, vol. 82, pp. 273–302, 1996.
[23] D. Centola, “The Spread of Behavior in an Online Social
Network Experiment,” Science, vol. 329, no. 5996, pp. 1194–
1197, Sep. 2010.

[7] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, J. VanBriesen, and N. Glance, “Cost-effective outbreak detection
in networks,” in KDD ’07: Proceedings of the 13th ACM
SIGKDD international conference on Knowledge discovery
and data mining. New York, NY, USA: ACM, 2007, pp.
420–429.

[24] M. P. Zhang, L., “Two is a crowd: Optimal trend adoption in
social networks,” in Proceedings of International Conference
on Game Theory for Networks (GameNets), 2011.

8

Early Identification of Violent Criminal Gang Members
Elham Shaabani∗, Ashkan Aleali∗ , and
Paulo Shakarian†
Arizona State University
Tempe, AZ

John Bertetto
Chicago Police Department
Chicago, IL

john.bertetto@chicagopolice.org

arXiv:1508.03965v1 [cs.SI] 17 Aug 2015

{shaabani, aleali, shak}@asu.edu

ABSTRACT
Gang violence is a major problem in the United States accounting for a large fraction of homicides and other violent crime. In this paper, we study the problem of early
identification of violent gang members. Our approach relies on modified centrality measures that take into account
additional data of the individuals in the social network of
co-arrestees which together with other arrest metadata provide a rich set of features for a classification algorithm. We
show our approach obtains high precision and recall (0.89
and 0.78 respectively) in the case where the entire network
is known and out-performs current approaches used by lawenforcement to the problem in the case where the network
is discovered overtime by virtue of new arrests - mimicking real-world law-enforcement operations. Operational issues are also discussed as we are preparing to leverage this
method in an operational environment.
Categories and Subject Descriptors: J.4 [Computer
Applications]: Sociology
General Terms: Security; Experimentation
Keywords: Social Network Analysis; Criminology

1.

INTRODUCTION

Gang violence is a major problem in the United States [1,
2] - accounting for 20 to 50 percent of homicides in many
major cities [10]. Yet, law enforcement actually has existing data on many of these groups. For example the underlying social network structure is often recorded by lawenforcement and has previously been shown useful in enabling “smart policing” tactics [17] and improving law
-enforcement’s understanding of a gang’s organizational structure [19]. In this paper we look to leverage this gang social
network information to create features that allows us to classify individuals as potentially violent. While the results of
such a classifier are insufficient to lead to arrests, it is able
to provide the police leads to individuals who are likely to
be involved in violence, allowing for a more focused policing
with respect to patrols and intelligence gathering. Our key
aim is to significantly reduce the population of potential violent gang members which will lead to more efficient policing.
In this paper, we introduce our method for identifying
potentially violent gang members that leverages features derived from the co-arestee social network of criminal gangs in
∗

These authors contributed equally to this work.
U.S. Provisional Patent 62/191,086. Contact shak@asu.edu for
licensing information.
†

a classifier to identify potentially violent individuals. We
note that this classification problem is particularly difficult
due to not only data imbalances, but also due to the fact that
many violent crimes are conducted due to heightened emotions - and hence difficult to identify. Though we augment
our network-based features with some additional meta-data
from the arrest records, our approach does not leverage features concerning the race, ethnicity, or gender of individuals
in the social network. We evaluate our method using realworld offender data from the Chicago Police Department.
This paper makes the following contributions:
• We discuss how centrality measurements such as degree, closeness, and betweenness when modified to account for metadata about past offenses such as the
type of offense and whether the offense was classified
as “violent” can serve as robust features for identifying
violent offenders.
• We show how the network features, combined with
other feature categories provide surprisingly robust performance when the entire offender is known in terms of
both precision (0.89) and recall (0.78) using cross-fold
validation.
• We then test our methods in the case where the network is exposed over time (by virtue of new arrests)
which mimics an operational situation. Though precision and recall are reduced in this case, we show that
our method significantly outperforms the baseline approach currently in use by law-enforcement - on average increasing precision and recall by more than two
and three times respectively.
In addition to these main results, we also present some side
results on the structure and nature of the police dataset we
examine. The paper is organized as follows. In Section 2 we
motivate this difficult problem within the law-enforcement
community. This is followed by a description of our dataset
along with technical notation in Section 3. There, we also
describe some interesting aspects of the gang arrest dataset
and our co-arrestee network. In Section 4 we formally define our problem, describe existing approaches, and then describe the features we use in our approach. Then we present
our results in Section 5 for both cases where we assume the
underlying network is known and when we discover the network over time (mimicking an operational scenario). Finally,
related work is discussed in Section 6.

2.

BACKGROUND

A recent study shows that the network for gunshot victimization is denser than previously believed [16]. According
to the authors, within the city of Chicago over 70% of all
gunshot victims are contained within only 6% of the total
population These findings validate what has been considered common knowledge among police for decades: who you
hang out with matters, and if you hang out with those who
engage in or are victims of violence you are more likely to
become an offender or victim yourself.
Identifying potential offenders of gun violence has also
been a staple practice for most law enforcement agencies
as an attempt to curtail future victimization. When gang
conflicts get “hot,” it’s common for law enforcement agents
to put together a list of known “shooters”: those known
gang members with an existing criminal history for gun violence and a predilection for engaging in such illegal activity. Law enforcement agents then attempt to make contact
with these individuals with the expectation that such direct
contact might prevent violence. For most law enforcement
agencies, however, this practice is performed in a very adhoc manner. Identifying these individuals for intervention
has relied primarily on the ability of law enforcement agents
to remember and identify at-risk individuals. While feasible
for small or discreet networks, the ability to recall multiple
individuals in large networks that cross large geographic regions and interact with multiple networks becomes increasing difficult. This difficulty increases significantly as relationships between networks change, known individuals leave
the network, and new individuals enter it. In particular,
the practice is less than idea because it requires officers to
attempt to recall criminal history and network association
data that varies between network members. For example,
a subject who has been arrested on multiple occasions for
carrying a gun or has been arrested for shooting another individual is easy to recall, but recalling and quantifying the
risk for a subject with multiple arrests for non-gun violence
and a direct association with several offenders and victims
of gun violence can be much more difficult. In short, identifying a known “shooter” is relatively straightforward: they
are known. The approach in this paper synthesizes network
connectivity other attributes of the subject to identify those
individuals at risk that law enforcement might not yet know.
Using this information, law enforcement agents may not
only more reliably and consistently identify those individuals
most likely to engage in acts of violence or become victims
of violence due to their personal associations with it, but
also to more effectively manage agency resources. Intervention strategies may include service providers outside law enforcement, such as family members, social service providers,
current or former educators, and clergy. This diversity in
approach not only delivers a more powerful “stop the violence” message but provides a kind of force multiplier for
law enforcement, increasing the number of persons involved
in the effort to prevent violence. Identifying specific individuals for intervention also allows for a more targeted effort by
law enforcement in terms of personnel and geographic areas
needing coverage. Blanketing violence reduction strategies
that saturate geographic areas with law enforcement agents
and rely on direct contact with large numbers of criminal
network members are inefficient and resource consuming.
Focusing efforts on those individuals most likely to engage in

violence allows law enforcement to focus on smaller groups
of people and smaller geographic areas (those areas within
which those individuals identified are known to frequent).
Therefore, our approach can significantly improve such efforts to identify violent individuals. In this paper, we see
how our method not only out-performs the current social
network heuristic used by police, but also that it provides
a much smaller and more precise list of potentially violent
offenders than simply listing those with a violent criminal
record.

3.

GANG CO-OFFENDER NETWORK

In this section, we introduce the necessary basic notation
to describe our co-offender network and then provide details of our real-world criminal dataset and study some of
its properties.

3.1

Technical Preliminaries

Throughout this paper we shall represent an offender network as an undirected graph G = (V, E) where the nodes
correspond with previous offenders and an undirected edge
exists between offenders if they were arrested together. We
will use τ to denote the set of timepoints (dates). We also
have three sets of labels for the nodes: V, S, gang which
are the sets of violent crimes, non violent crimes, and gangs.
For each time point t and each node v, the binary variable
arrtv ∈ {true, false} denotes if v was arrested at time t and
distrtv , beattv , gangtv to denote the district, beat, and gang affiliation of v at time t (we will assume that time is fine-grain
enough to ensure that at each time unit an individual is arrested no more than once). If we drop the t superscript for
these three symbols, it will denote the most recent district,
beat, and gang associated with v in the knowledgebase. We
shall use the sets Vvt and Svt to denote the set of violent and
non violent offenses committed by v at time t respectively.
Note if arrtv = false then Vvt = ∅. We will drop the superscript t for this symbol to denote the union of labels at any
time t in the historical knowledgebase. We also note that
the edges in the graph also depend on time, but for sake of
readability, we shall state with words the duration of time
considered for the edges.
For a given violent crime c ∈ V∪S, we will use the notation
Vct = {v ∈ V s.t. c ∈ Vvt } (intuitively, the subset of the
population who have committed crime c at time t). Again,
we will drop the superscript t if v could have committed
crime c at any time in the historical knowledgebase. For
a set of labels C ⊆ V ∪ S, we will extend this notation:
VCt = {v ∈ V s.t. C ∩ Vvt 6= ∅}. We will slightly abuse
notation here: V∅t = V . We will use similar notation for
denoting a subset of the population that are members of a
certain gang. For instance, Vgangv refers to the set of nodes
who are in the same gang as node v. Likewise, we shall use
the same notation for subgraphs: GtC is the subgraph of G
containing only nodes in VCt and their adjacent edges. We
will use the function d : V × V → N to denote the distance
between two nodes - which for this paper will be the number
of links in the shortest path. For a given node v, the set
Nvi = {v 0 ∈ V s.t. d(v, v 0 ) = i} – the set of nodes that are
whose shortest path is exactly i hops from v. For two nodes
v, v 0 , we will use the notation σ(v, v 0 ) to be the number of
shortest paths between v and v 0 . For nodes u, v, v 0 , σu (v, v 0 )
will be the number of shortest paths between v and v 0 that
pass through u.

Table 1: Summary of arrest data.
Name
Value
Number of records
64466
Violent offense
4450
Homicide
312
Criminal sexual assault
153
Robbery
1959
Aggravated assault
1441
Aggravated battery
896
Non violent offense
60016

For a given subgraph G0 of G, we shall use C(G0 ) to denote the largest connected component of G0 and for node
v ∈ G0 , we will use the notation Cv (G0 ) to denote the connected component of G0 to which v belongs. If we apply a
community finding algorithm to subgraph G0 , we will use
the notation Pv (G0 ) to denote the partition of G0 to which
v belongs. We will use the notation |·| to denote the size of
a set or the number of nodes in a subgraph.

3.2

Overview of Network Data

In this section we describe our police dataset and the associated co-offender network as well as some interesting characteristics that we have noticed.
Police Dataset. Our dataset consists of gang-related arrest incidents gathered from August 2011 - August 2014 in
Chicago as well as their immediate associates. This data set
includes locations, dates, the links between the joint arrests,
and the gang affiliation of the offenders. In Table 1, we summarize some of the important characteristics of the dataset.
Violent Crimes. In our dataset, the set V consists of the
following crimes have been identified by the Chicago Police
as violent crimes: homicide (first or second degree murder),
criminal sexual assault, robbery, aggravated assault, and aggravated battery. All aforementioned offenses are also FBI
“index” crimes as well. A key aspect about the violent crimes
is that the dataset is highly imbalanced with much more arrests for non violent crimes vs. arrests for violent crimes
(60016 vs. 4450).
Network Properties. From the arrest data, we were able
to construct the co-offender network. In this network, the

Figure 1: The gang co-offender network. Each color corresponds with a different gang.
isolated vertices are eliminated due to the lack of structural
information. A visualization of the network is depicted in
Figure 1 and we have included summary statistics in Table 2.
In studying this network, we studied its degree distribution
(Figure 2). Unlike the degree distribution for other scale free
social networks, the degree distribution for the offender network is exponential rather than power law. However, despite
the degree distribution being similar to that of a random (ER) or small world network topology [27], we noticed other
characteristics that indicate differently. The co-offender network has a much higher average clustering coefficient than in
a random network and does not follow the properties of the
small world topology due to the relative high diameter and
average shortest path (computed for the largest connected
component.)

40	
  

Number	
  of	
  Ver+ces(Hundreds	
  )	
  

Table 2: Network properties.
Name
Values
Vertices
9373
Edges
17197
Average degree
3.66
Average clustering
0.5
Transitivity
0.62
Connected components
1843
Largest connected component di36
ameter
Largest connected component aver12.22
age path length
Largest connected component aver0.63
age clustering

35	
  
30	
  
25	
  
20	
  
15	
  
10	
  
5	
  
0	
  
1	
   3	
   5	
   7	
   9	
   11	
  13	
  15	
  17	
  19	
  21	
  23	
  25	
  27	
  29	
  31	
  33	
  35	
  37	
  39	
  41	
  43	
  45	
  47	
  49	
  

Degree	
  

Figure 2: Network degree distribution. The exponential
function fits to the distribution (R2 = 0.77).
Repeat Offenders. There are many instances of repeated
offenses from the same offender. Figure 3 shows the distribution of the repeated arrests for each individual in the
dataset. This indicates that arrest records have utility in

6	
  

In this section, we describe our problem, some of the existing practical approaches used by law-enforcement, and our
approach based on supervised learning with features primarily generated by the network topology.

5	
  

4.1

Number	
  of	
  individuals(Thousands	
  )	
  

identifying future offenders.

4	
  
3	
  
2	
  
1	
  

4.2

0	
  
2	
   4	
   6	
   8	
   10	
   12	
   14	
   16	
   18	
   20	
   22	
   24	
   26	
   28	
   31	
   38	
  

Number	
  of	
  arrests	
  

Figure 3: Repeated arrests. 12866 instances of one-time
arrests have been removed.
Seasonality of Crime. There is also a higher chance of
criminal activities in different months of the year. Figure 4
demonstrates some of these variations. As per police observations, both violent and non-violent crime incidents are
lower in the winter months (Dec.-Feb.).

Number	
  of	
  violent	
  individuals	
  

180	
  
160	
  
140	
  
120	
  
100	
  
80	
  
60	
  
40	
  
20	
  
0	
  
Aug	
   Sep	
   Oct	
   Nov	
   Dec	
   Jan	
   Feb	
   Mar	
   Apr	
   May	
   Jun	
   Jul	
  

Number	
  of	
  non	
  violent	
  individuals	
  

Month	
  
2500	
  
2000	
  
1500	
  
1000	
  
500	
  
0	
  
Aug	
   Sep	
   Oct	
   Nov	
   Dec	
   Jan	
   Feb	
   Mar	
   Apr	
   May	
   Jun	
   Jul	
  

Month	
  
2011-­‐2012	
  

2012-­‐2013	
  

2013-­‐2014	
  

Figure 4: Seasonality of crime.

4.

Problem Statement

Given a co-offender network, G = (V, E) and for each
historical timepoint t ∈ τ = {1, . . . , tmax } and v ∈ V , we
have the values of arrtv , distrtv , beattv and elements of the
sets Vvt , gangtv , we wish to identify set {v ∈ V s.t. ∃t >
tmax where |Vvt |> 0}. In other words, we wish to find a set
of offenders in our current co-offender network that commit
a violent crime in the future.

IDENTIFYING VIOLENT OFFENDERS

Existing Methods

Here we describe two common techniques often used by
law-enforcement to predict violent offenders. The first is
a simple heuristic based on violent activities in the past.
The second is a heuristic that was based on the findings of
[17] which was designed to locate future victims of violent
crime. Both of these approaches are ad-hoc practical approaches that have become “best practices” for predicting
violent offenders. However, we are not aware of any datadriven, formal evaluation of these methods in the literature.
Past Violent Activities (PVA). The first ad-hoc approach is quite simple: if an offender has committed a violent crime in the past, we claim that he will commit a
violent crime in the future. An obvious variant of this approach is to return the set of violent offenders from the last
∆t days. We note in practice, if police also have records of
those who are incarcerated, and such individuals would be
removed from the list (due to the different jurisdictions of
police and corrections in the Chicago area, we did not have
access to incarceration data - however discussed re-arrests
observed in the data in the previous section).
Two-Hop Heuristic (THH). The two-hop heuristic is
based on the result of [17] which investigated a social network of gunshot victims in Boston and found an inverse relationship between the probability of being a gunshot victim
and the shortest path distance on the network to the nearest
previous gunshot victim. Hence, THH returns all neighbors
one and two hops away from previous violent criminals (see
Algorithm 1 for details on the version we used in our experiments - which was the best-performing variant for our
data). The Chicago Police have adopted a variant of this
method to identify potential gang victims using a combination of arrest and victim data - the co-arrestee network of
criminal gang members includes many individuals who are
also victims of violent crime (this is a direct result of gang
conflict). We note that victim information did not offer a
significant improvement to our approach, except the trivial
case that a homicide victim cannot commit any crime in the
future.

4.3

Supervised Learning Approach

We evaluated many different supervised learning approaches
including Naive Bayes (NB), Linear Regression (LR), Decision Tree (DT), Random Forest (RF), Neural Network (NN),
and support vector machines (SVM) on the same set of features for the nodes in the network that we shall describe in
this section. We also explored combining these approaches

Algorithm 1 Two-Hop Heuristic
1: procedure TwoHop(G)
. Offender network G.
2:
R ← {}
. Identified violent offenders.
3:
V ICT IM S ← {u ∈ G|is homicide victim(u)}
4:
for v ∈ V ICT IM S do
5:
N ← Nv1 ∪ Nv2
. Immediate neighbors
6:
R ← R ∪ {u ∈ N s.t. Vu = ∅}
7:
return R

with techniques for imbalanced data such as SMOTE [4] and
Borderline SMOTE [9], however we do not report the results
of Borderline SMOTE as it provided no significant difference
from SMOTE. We group our features into four categories:
(1.) neighborhood-based (having to do with the immediate neighbors of a given node), (2.) network-based (features
that require the consideration of more than a nodes immediate and nearby neighbors), (3.) temporal characteristics,
and (4.) geographic characteristics.

4.3.1

Neighborhood-Based Features

Neighborhood-based features are the features computed
using each node and its first and/or second level neighbors
in G – often with respect to some C ⊆ V. The simplest such
measure is the degree of vertex v – corresponding to the
number of offenders arrested with v. We can easily extend
this for some set of crimes of interest (C) where we look at
all the neighbors of v who have committed a crime in C.
This generalizes degree (as that is the case where C = ∅).
In our experiments, we found the most useful neighborhood
features to be in the case where C = V though standard
degree (C = ∅) was also used. We also found that using
combinations of the following booleans based on the below
definition also proved to be useful:
majv (C, i)

= |{u|u ∈ (∪i Nvi ) ∩ VC }|≥ 0.5 × |(∪i Nvi )|

Intuitively, majv (C, i) is true if at least half of the nodes
within a network distance of i from node v have committed
a crime in C and false otherwise. Using these intuitions, we
explored the space of variants of these neighborhood-based
features and list those we found to be best-performing in
Table 3.

4.3.2

Network-Based Features

Network-based features fall into two sub-categories that
we shall describe in this section: community-based and pathbased.
Network-based community features. We use several
notions of a node’s community when engineering features:
the connected component to which a node belongs, the gang
to which a node belongs, and what we will refer to as an individual’s group. The connected component is simply based
on the overall network structure, while the gang is simply the subgraph induced by the individuals in the network who belong to the same gang (the social network of
node v’s gang is denoted Ggangv . A nodes group is defined
as the partition he/she belongs to based on a partition of
Ggangv found using the Louvain algorithm [5]. We found
in our previous work [19] and ensuing experience with the
Chicago Police that the groups produced in this method

Table 3: Neighborhood-Based Features
Description

Definition

Degree (w.r.t. C)

|{u|u ∈ Nv1 ∩ VC }|

Fraction of 1-hop
neighbors committing a crime
in C

|{u|u ∈ Nv1 ∩ VC }|/|Nv1 |

Fraction of 2-hop
neighbors committing a crime
in C

|{u|u ∈ Nv2 ∩ VC }|/|Nv2 |

Majority of 1-hop
and 2-hop neighbors committing
a crime in C

majv (C, 1) ∧ majv (C, 2)

Minority of 1-hop
and majority of
2-hop neighbors
comitting a crime
in C

¬majv (C, 1) ∧ majv (C, 2)

Table 4: Network-Based Features (Community)
Description

Definition

Component
size when v is
removed

|C(Cv (G) \ {v})|

Largest component size with a
violent node after
v is removed

maxv0 ∈C(Cv (G){v}∩VV |Xv0 |
where Xv0 = Cv0 (Cv (G){v})

Group size

|Pv (Ggangv )|

Relationships
within the group

|{(u, v)
∈
Pv (Ggangv )}|

Number of violent members in
the group

|{v 0 ∈ Pv (Ggangv ) s.t. Vv 6= ∅}|

Triangles
group

in

Transitivity
group

of

No. of triangles within subgraph Pv (Ggangv )
No. of triangles in Pv (Ggangv )
No. of “∨”’s in Pv (Ggangv )

E s.t. u, v

∈

Group-to-group
connections

|{u ∈ Pv (Ggangv ) s.t. ∃(u, w) ∈
E where w ∈
/ Pv (Ggangv )}|

Gang-to-gang
connections

|{u ∈ Ggangv s.t. ∃(u, w) ∈ E
where w ∈
/ Ggangv }|

were highly relevant operationally. In this work, we also
examined other community finding methods (i.e. Infomap,
and Spectral Clustering) and found we obtained the best results by using the Louvain algorithm. We provide our best
performing network-based community features that we used
in Table 4. Of particular interest, we found for individual

Table 6: Geographic Features

Table 5: Network-Based Features (Path)
Description
Betweenness
(w.r.t. C)

Name

Definition
P
σv (u,w)
u,w∈VC

District
quency

σ(u,w)

P

Closeness (w.r.t.
C)

(|VC |−1)/

Shell
Number
(w.r.t. C)

shellC (v) (see appendix for further details)

Propagation
(w.r.t. C)

1 if v ∈ Γκ (VV ), 0 otherwise.
(see appendix for further details)

u∈VC

d(u, v)

v that features relating to the size of the largest connected
component resulting v 0 removal of his/her connected component was useful. Another interesting pair of features we
noted for both group and gang were the number of edges
from members of that group/gang to a different group or
gang. We hypothesize that the utility of these features is a
result of conflicts between groups/gangs they are connected
to as well as the spread of violence amongst different groups
(i.e. if two groups are closely connected, one may conduct
violent activities on behalf of the other).
Network-based path features. We looked at several features that leveraged the paths in the network by adopting
three common node metrics from the literature: betweenness, closeness [6], and shell-number [23] as well as a propagation process based on a deterministic tipping model [8].
The features are listed in Table 5. We examined our modified definitions of closeness, betweenness, and shell number
where C was a single element of V, where C = V and where
C = ∅ (which provides the standard definitions of these
measures). Our intuition was that individuals nearer in the
network to other violent individuals would also tend to be
more violent - and we found several interesting relationships
such as that for closeness (where C = VV ) discussed in section 5.1 when we run the classifier on each feature group.
Shell number and the propagation process were used to capture the idea of the spread of violence (as shell number was
previously shown to correspond with “spreaders” in various
network epidemic models [11]). For the propagation process,
we set the threshold (κ) equal to two, three, four, five, and
six. Further details on shell number and the propogation
process can be found in the appendix.

4.3.3

Geographic Features

Geographic features capture the information related to
the location of a crime incident. The intuition is that the
individuals who commit crimes in violent districts are more
likely to become violent than the others. We found that the
beat the individual has committed a crime in is an important feature for our problem. This is in accordance with
previous well known literature in criminology [3, 21] which
studies spatio-temporal modeling of criminal behavior. The
complete list is shown in Table 6.

4.3.4

Temporal Features

We considered couple of temporal features: average inter-

Definition
Fre-

|{(t, v 0 ) s.t. arrvt 0 = true ∧
0
∃t0 s.t. distrvt 0 = distrvt }|

Beat Frequency

|{(t, v 0 ) s.t. arrvt 0 = true ∧
0
∃t0 s.t. beattv0 = beattv }|

Beat Violence

|{(t, v 0 ) s.t. arrvt 0 = true ∧ Vvt 0 6=
0
∅ ∧ ∃t0 s.t. beattv0 = beattv }|

District Violence

|{(t, v 0 ) s.t. arrvt 0 = true ∧ Vvt 0 6=
0
∅ ∧ ∃t0 s.t. distrvt 0 = distrvt }|

val month and number of violent groups. Average interval
time considers the average time duration of consecutive arrests of the offender. The other feature, which we examine,
is number of violent groups appeared over time in the environment. We examined that the number of violent groups
has been an important temporal aspect for identifying the
violent criminals. The key intuition here is, if at least one
member of the offender’s groups (formed over time) is violent then we consider the offender as a part of that violent
group. For an individual v, we define the partially ordered
set tvC = {t s.t. arrtv = true ∧ VCt 6= ∅} (intuitively the set
of the time points where v has committed at least on of the
crimes in C.) We also define ∆vi (C) = tvi − tvi−1 for each
tvi ∈ tvC . Considering these definitions, we formally define
the temporal features in Table 7.
Table 7: Temporal Features
Name
Average interval
time (w.r.t. C)
Number of violent groups

Definition
P v
v
i ∆i (C)/|tC |
|{t s.t. arrvt = true ∧
∃v 0 s.t. arrvt 0 = true ∧
Vvt 6= ∅ ∧
v 0 ∈ Nvt }|

5.

EXPERIMENTAL RESULTS

In this section, we review the results of our experiments.
We looked at two types: experiments where the entire cooffender network is known before-hand (Section 5.1) and experiments where the network is discovered over time (Section 5.2). The intuition behind the experiments where the
co-offender network is known is that the police often have
additional information to augment co-arrestee data. This
information can include informant reporting, observed individuals interacting by patrolmen, intelligence reporting, and
information discovered on social media and the Internet. In
our second type of experiment we discover the network over
time in an effort to mimic real-world operations - however,
we also show that this makes the problem more difficult as
it reduces the power of neighborhood-based and networkbased features. Based on our discussions with the Chicago

Police, we believe that real-world results will most likely fall
somewhere between these two experiments. Operationally,
we will not have full arrest data, but the aforementioned
augmenting data sources are available (even though we did
not have access to them for our experiments).

5.1

Known Co-Offender Network

1	
  

1	
  

0.9	
  

0.9	
  

0.8	
  

0.8	
  

0.7	
  

0.7	
  

0.6	
  

0.6	
  

0.5	
  

0.5	
  

0.4	
  

0.4	
  

0.3	
  

0.3	
  

0.2	
  

0.2	
  

0.1	
  

In this experiment we assume that the entire offender network is known. In other words, to compute the features for
each vertex v, we assume that the set Vv is unknown while
the rest of the network is observable. In here we compared
our approach with THH but not with the PVA as we do not
utilize time. In each of the experiments described in this section, we conduct 10-fold cross validation. We consider the
result of each approach as a set of nodes that the approach
considers to be a set of potentially violent individuals. Our
primary metrics are precision (fraction of reported violent
individual who were actually violent in the dataset), recall
(fraction of violent individuals in the dataset reported by the
approach), F1 (the harmonic mean of precision and recall)
and area under the curve. We conduct two types of experiments: first, we study classification performance using only
features within a given category (neighborhood, network,
temporal, and geographic), then we study the classification
performance when the entire feature set is used but with
various different classification algorithms and compare the
result to THH.

0.1	
  

0	
  

0	
  
Precision	
  

Recall	
  

F1	
  

Precision	
  

(a)

Recall	
  

F1	
  

(b)

1	
  

1	
  

0.9	
  

0.9	
  

0.8	
  

0.8	
  
0.7	
  

0.7	
  

0.6	
  

0.6	
  

0.5	
  

0.5	
  

0.4	
  

0.4	
  

0.3	
  

0.3	
  

0.2	
  

0.2	
  

0.1	
  
0	
  

0.1	
  

Precision	
  

0	
  
Precision	
  

Recall	
  

Recall	
  

Violent	
  

F1	
  

(c)

F1	
  

Non	
  violent	
  

(d)

Figure 6: Example features from each category. (a)
Neighborhood-based: Minority of 1-hop and majority of 2-hop neighbors committing a crime in C.
(b) Network-based: Closeness (w.r.t. V). (c) Geographic: Beat violence. (d) Temporal: Average
interval months.

True	
  posi*ve	
  

Classification using single feature categories. Here
we describe classification results using single feature categories. In this set of experiments, we use a random forest
classifier (which we will later show provides the best performance of the classifiers that we examined). Figure 5 shows
the performance of RF for the described categories. The
network-based features are highly-correlated to violent behavior with average F1 value of 0.72 compared to 0.63 for
neighborhood, 0.21 for geographic, and 0.03 for temporal
features. In Figure 6, we show the performance of a feature
from each category to classify violent vs. non violent crimes;
the performance of each example is a good indicator of the
performance of its category.

1	
  
0.9	
  
0.8	
  
0.7	
  
0.6	
  
0.5	
  
0.4	
  
0.3	
  
0.2	
  
0.1	
  
0	
  
0	
  

0.2	
  

0.4	
  

0.6	
  

0.8	
  

1	
  

False	
  posi*ve	
  
Network-­‐Based	
  

Neighborhood-­‐Based	
  	
  

Geographic	
  

Temporal	
  

All	
  

Figure 7: ROC curve for each feature set.

1	
  
0.9	
  
0.8	
  
0.7	
  
0.6	
  
0.5	
  
0.4	
  
0.3	
  
0.2	
  
0.1	
  
0	
  
Neighborhood-­‐ Network-­‐Based	
   Geographic	
  
Based	
  
Features	
  	
  

Precision	
  

Recall	
  

Temporal	
  

Table 8, RF provides the best performance (F1=0.83); we
also note that using SMOTE for RF, did not improve this
result. Figure 8 shows that our algorithm outperforms THH.
The performance of our features are also illustrated in Figure 7. The area under the curve (AUC) of applying all
features is 0.98 – a higher overall accuracy. The AUC for
network-based, neighborhood-based, geographic, and temporal categories are 0.92, 0.91, 0.65, and 0.7 respectively.
This indicates the importance of network features for this
classification task.

F1	
  

5.2
Figure 5: Precision, recall, and F1 comparison between
each group of features.
Classification comparison. Table 8 shows the performance of different classification algorithms. According to

Co-Offender Network Emerges Over Time

In this section, we present a more difficult experiment where the co-arrestee network is discovered over time (by
virtue of arrests). To simulate this phenomenon, we split
our data into two disjoint sets: the first set for learning
and identification, and the second one for measuring the

Table 8: K-fold cross validation.
Method
Precision Recall F1
RF
0.89
0.78
0.83
RF w. SMOTE 0.86
0.78
0.82
NB
0.45
0.49
0.47
LR
0.68
0.49
0.57
DT
0.71
0.66
0.68
NN
0.64
0.57
0.6
SVM
0.73
0.2
0.31
1	
  
0.9	
  
0.8	
  
0.7	
  
0.6	
  

and number of false positives and display the results in Figures 10 and 11. In FRF (Filtered Random Forest) we filter the offenders who have not committed any crime in the
last 200 days. This simple heuristic increase the precision
drastically while preserving the recall. The main advantage
of our method, besides the high precision, is its ability to
significantly reduce the population of potentially violent offenders when compared to PVA - which for each month had
between 1813 and 3571 false positives. Figure 11 compares
the number of true and false positives instances for all the
approaches for each month except PVA (PVA was omitted
due to readability because of the large amount of false positives). While the F1 measure for PVA is higher than that of
the others, the large number of false positives prevents the
law enforcement from using it effectively in practice. Furthermore, as time progresses, PVA likely rises in recall due
to the drop in the number of violent criminals to predict.

0.5	
  
0.4	
  

6.

0.3	
  
0.2	
  
0.1	
  
0	
  
THH	
  

RF	
  

Precision	
  

Recall	
  

F1	
  

Figure 8: Performance comparison between THH and RF
in K-fold cross validation.

Frac%on	
  of	
  full	
  dataset	
  

performance. We do monthly split and start from February
2013. To illustrate the difficulty of this test, we show the
number of nodes, edges, and violent individuals per month in
Figure 9. We note that in the early months, we are missing
much of the graphical data (over 40% of nodes and edges in
the first two months) - hence making many of our features
less effective. However, as the months progress, there are less
violent individuals to identify (due to the temporal nature of
the dataset) - hence amplifying the data imbalance as time
progresses.
1	
  
0.9	
  
0.8	
  
0.7	
  
0.6	
  
0.5	
  
0.4	
  
0.3	
  
0.2	
  
0.1	
  
0	
  

RELATED WORK

Though we believe that the prediction of violent offenders
using co-offender social networks is new, there has previously
been work on both co-offender networks in general as well
as crime forecasting. In this section, we briefly review some
of the relevant contributions in both of these areas.
There has been much previous work on co-offender networks. The earlier work that studied these special social
networks primarily came from the criminology literature.
For instance, [14] utilizes social network analysis techniques
to study several case studies where the social network of the
criminal organization was known. In [13], the authors study
the stability of these networks change over time. More recently, graphical features derived from networks comprised
of both offenders and victims has been shown to be related
to the the probability of an individual becoming a victim
of a violent crime [17, 16]. Previous work has also looked
at the relationship between network structure and geography [18] and has leveraged both network and geographic
features to predict criminal relationships [25] as well as influence gang members to dis-enroll [24]. There have also
been several software tools developed for conducting a widerange of analysis on co-offender networks including CrimeFighter [20], CrimeLink [22], and ORCA [19]. However, our
work departs from this is that we are looking to leverage
the network topology and other features to identify violent
offenders - which was not studied in any of the previous
work.
There has also been a large amount of work on crime forecasting (i.e. [7, 12]) though historically, this work has relied
on spatio-temporal modeling of criminal behavior [3, 21] or
was designed to identify suspects for specific crimes [26, 15].
None of this previous work was designed to identify future
violent offenders nor did it leverage social network structure.

Month	
  
Edges	
  

Nodes	
  

Violent	
  individuals	
  

Figure 9: Number of nodes, edges, and violent individuals
over time. More training data, less offenders to identify.
In these experiments, we compared our approach using
random forests with the full feature set to THH and PVA.
We measure precision, recall, F1, number of true positives,

7.

CONCLUSION

In this paper we explored the problem of identifying repeat offenders who will commit violent crime. We showed
a strong relationship between network-based features and
whether a criminal will commit a violent offense providing
an unbiased F1 score of 0.83 in our cross-validation experiment where we assumed that the underlying network was
known. When we moved to the case where the network

90	
  

Number	
  of	
  true	
  posi.ve	
  

0.4	
  
0.35	
  

Recall	
  

0.3	
  
0.25	
  
0.2	
  
0.15	
  
0.1	
  

80	
  
70	
  
60	
  
50	
  
40	
  
30	
  
20	
  
10	
  
0	
  

13
	
  
Ap
r-­‐1
3	
  
Ju
n-­‐
13
	
  
Au
g-­‐
13
	
  
Oc
t-­‐1
3	
  
De
c-­‐
13
	
  
Fe
b-­‐
14
	
  
Ap
r-­‐1
4	
  
Ju
n-­‐
14
	
  

0.05	
  

13
	
  
Ap
r-­‐1
3	
  
Ju
n-­‐
13
	
  
Au
g-­‐
13
	
  
Oc
t-­‐1
3	
  
De
c-­‐
13
	
  
Fe
b-­‐
14
	
  
Ap
r-­‐1
4	
  
Ju
n-­‐
14
	
  

Fe
b-­‐

0	
  

Fe
b-­‐

Month	
  

Month	
  

FRF	
  

0.2	
  
0.15	
  
0.1	
  
0.05	
  

1000	
  
800	
  
600	
  
400	
  
200	
  

13
	
  

Ap
r-­‐1
3	
  
Ju
n-­‐
13
	
  
Au
g-­‐
13
	
  
Oc
t-­‐1
3	
  
De
c-­‐
13
	
  
Fe
b-­‐
14
	
  
Ap
r-­‐1
4	
  
Ju
n-­‐
14
	
  

0	
  

Month	
  

Fe
b-­‐

13
	
  
Ap
r-­‐1
3	
  
Ju
n-­‐
13
	
  
Au
g-­‐
13
	
  
Oc
t-­‐1
3	
  
De
c-­‐
13
	
  
Fe
b-­‐
14
	
  
Ap
r-­‐1
4	
  
Ju
n-­‐
14
	
  

0	
  

Fe
b-­‐

Precision	
  

THH	
  

1200	
  

Number	
  of	
  false	
  posi/ve	
  

0.25	
  

RF	
  

Month	
  

FRF	
  

0.18	
  

RF	
  

THH	
  

Figure 11: Number of true and false positive instances.

0.16	
  
0.14	
  

F1	
  

0.12	
  

belongs. For a given node v and C ⊆ V, we define shellC (v)
as the shell number of node v on the subgraph consisting
of v and all nodes v 0 where C ∩ Vv 6= ∅. We slightly abuse
notation and define shell∅ (v) as the shell number of v on the
full network.

0.1	
  
0.08	
  
0.06	
  
0.04	
  
0.02	
  

Fe
b-­‐

13
	
  
Ap
r-­‐1
3	
  
Ju
n-­‐
13
	
  
Au
g-­‐
13
	
  
Oc
t-­‐1
3	
  
De
c-­‐
13
	
  
Fe
b-­‐
14
	
  
Ap
r-­‐1
4	
  
Ju
n-­‐
14
	
  

0	
  

Month	
  
THH	
  

FRF	
  

RF	
  

PVA	
  

Figure 10: Precision, recall, and F1 over time.
was discovered over time, our method significantly outperformed baseline approaches significantly increasing precision
and recall. We are currently discussing ways to operationalize this technology with the Chicago Police as well as design
strategies to best deploy police assets to areas with higher
concentrations of potentially violent offenders. We are also
working with the police to identify other sources of data to
build a more complete social network of the offenders.

Appendix
Shell Number. For a given graph, the k-core is the largest
subgraph where each node has at least degree k. The k-shell
is the set of nodes in core k but not in any higher core. A
node’s shell number is k value of the shell to which that node

Propogation Process. For a given node v and the set of
activated nodes V 0 , we define v’s active neighbors as follows:
actv (V 0 ) = {u|u ∈ Nv1 ∩ V 0 }
We now define an activation function A that, given an initial
set of active nodes, returns a set of active nodes after one
time step.
Aκ (V 0 ) = V 0 ∪ {v ∈ V s.t. |actv (V 0 )|≥ κ}
We also note that the activation function can be applied
iteratively, to model a diffusion process. Hence, we shall use
the following notation to signify multiple applications of A
(for natural numbers t > 1).

Aκ (V 0 )
if t = 1
t
0
Aκ (V ) =
0
Aκ (At−1
otherwise
κ (V ))
0
Clearly, when AtG,κ (V 0 ) = At−1
G,κ (V ) the process has converged. Further, this always converges in no more than |V |
steps, since the process must activate at least one new node
in each step prior to converging. Based on this idea, we
define the function Γ which returns the set of all nodes activated upon the convergence of the activation function. We

define Γκ (V 0 ) = Aκ (V 0 ) where t is the least value such that
0
Atκ (V 0 ) = At−1
κ (V ).

8.

REFERENCES

[1] J. Bertetto. Countering criminal street gangs: Lessons from
the counterinsurgent battlespace. Law Enforcement Executive
Forum, 12(3):43, 2012.
[2] A. Braga, D. Hureau, and A. Papachristos. Deterring
gang-involved gun violence: Measuring the impact of boston’s
operation ceasefire on street gang behavior. Journal of
Quantitative Criminology, pages 1–27, 2013.
[3] P. Brantingham and P. Brantingham. Crime Pattern Theory.
In R. Wortley and L. Mazerolle, editors, Enviromental
Criminology and Crime Analysis, pages 78–93. 2008.
[4] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P.
Kegelmeyer. Smote: synthetic minority over-sampling
technique. Journal of artificial intelligence research,
16(1):321–357, 2002.
[5] P. Expert, T. S. Evans, V. D. Blondel, and R. Lambiotte.
Uncovering space-independent communities in spatial
networks. Proceedings of the National Academy of Sciences,
108(19):7663–7668, 2011.
[6] L. C. Freeman. A set of measures of centrality based on
betweenness. Sociometry, 40(1):pp. 35–41, 1977.
[7] W. Gorr and R. Harries. Introduction to crime forecasting.
International Journal of Forecasting, 19(4):551 – 555, 2003.
[8] M. Granovetter. Threshold models of collective behavior. The
American Journal of Sociology, (6):1420–1443.
[9] H. Han, W.-Y. Wang, and B.-H. Mao. Borderline-smote: a new
over-sampling method in imbalanced data sets learning. In
Advances in intelligent computing, pages 878–887. Springer,
2005.
[10] J. C. Howell. Gangs in America’s Communities. Sage, 2012.
[11] M. Kitsak, L. K. Gallos, S. Havlin, F. Liljeros, L. Muchnik,
H. E. Stanley, and H. A. Makse. Identification of influential
spreaders in complex networks. Nat Phys, 6(11):888–893, Nov.
2010.
[12] H. Liu and D. E. Brown. Criminal incident prediction using a
point-pattern-based density model. International Journal of
Forecasting, 19(4):603–622, Oct. 2003.
[13] J. M. Mcgloin, C. J. Sullivan, A. R. Piquero, and S. Bacon.
Investigating the stability of co-offending and co-offenders
among a sample of youthful offenders. Criminology,
46(1):155–188, 2008.
[14] C. Morselli. Inside Criminal Networks. Springer, 2009.
[15] C. Overall and G. Day. The Hammer Gang: an exercise in
spatial analyis of an armed robbery series using the probability
grid method. In S. Chainey and L. Tompson, editors, Crime
Mapping Case Studies, pages 55–62. 2008.

[16] A. Papachristos, C. Wildeman, and E. Roberto. Tragic, but
not random: The social contagion of nonfatal gunshot injuries.
Social Science and Medicine, page 139.
[17] B. A. H. D. Papachristos, A. Social networks and the risk of
gunshot injury. J. Urban Health, 2012.
[18] H. D. B. A. Papachristos, A. The corner and the crew: The
influence of geography and social networks on gang violence.
American Sociological Review, 2013.
[19] D. Paulo, B. Fischl, T. Markow, M. Martin, and P. Shakarian.
Social network intelligence analysis to combat street gang
violence. In Proceedings of the 2013 IEEE/ACM
International Conference on Advances in Social Networks
Analysis and Mining, ASONAM ’13, pages 1042–1049, New
York, NY, USA, 2013. ACM.
[20] R. R. Petersen and U. K. Wiil. Crimefighter investigator: A
novel tool for criminal network investigation. In EISIC, pages
197–202. IEEE, 2011.
[21] D. K. Rossmo and S. Rombouts. Geographic Profiling. In
R. Wortley and L. Mazerolle, editors, Enviromental
Criminology and Crime Analysis, pages 136–149. 2008.
[22] J. Schroeder, J. Xu, and H. Chen. Crimelink explorer: Using
domain knowledge to facilitate automated crime association
analysis. In H. Chen, R. Miranda, D. Zeng, C. Demchak,
J. Schroeder, and T. Madhusudan, editors, Intelligence and
Security Informatics, volume 2665 of Lecture Notes in
Computer Science, pages 168–180. Springer Berlin Heidelberg,
2003.
[23] S. B. Seidman. Network structure and minimum degree. Social
Networks, 5(3):269 – 287, 1983.
[24] P. Shakarian, J. Salmento, W. Pulleyblank, and J. Bertetto.
Reducing gang violence through network influence based
targeting of social programs. In Proceedings of the 20th ACM
SIGKDD International Conference on Knowledge Discovery
and Data Mining, KDD ’14, pages 1829–1836, New York, NY,
USA, 2014. ACM.
[25] M. A. Tayebi, M. Ester, U. Glässer, and P. L. Brantingham.
Spatially embedded co-offence prediction using supervised
learning. In Proceedings of the 20th ACM SIGKDD
International Conference on Knowledge Discovery and Data
Mining, KDD ’14, pages 1789–1798, New York, NY, USA,
2014. ACM.
[26] M. A. Tayebi, M. Jamali, M. Ester, U. Glässer, and R. Frank.
Crimewalker: A recommendation model for suspect
investigation. In Proceedings of the Fifth ACM Conference on
Recommender Systems, RecSys ’11, pages 173–180, New York,
NY, USA, 2011. ACM.
[27] D. J. Watts and S. H. Strogatz. Collective dynamics of
“small-world” networks. nature, 393(6684):440–442, 1998.

An Argumentation-Based Framework to Address the
Attribution Problem in Cyber-Warfare
Paulo Shakarian1

Gerardo I. Simari2

Geoffrey Moores1

Simon Parsons3

Marcelo A. Falappa4

1

Dept. of Electrical Engineering and Computer Science, U.S. Military Academy, West Point, NY
2
Dept. of Computer Science, University of Oxford, Oxford, UK
3
Dept. of Computer Science, University of Liverpool, Liverpool, UK
4
Dep. de Cs. e Ing. de la Computación, Univ. Nac. del Sur, Bahı́a Blanca, Argentina and CONICET
paulo@shakarian.net, gerardo.simari@cs.ox.ac.uk, geoffrey.moores@usma.edu
s.d.parsons@liverpool.ac.uk, mfalappa@cs.uns.edu.ar

arXiv:1404.6699v1 [cs.CR] 27 Apr 2014

Abstract
Attributing a cyber-operation through the use of multiple pieces of technical evidence (i.e., malware reverseengineering and source tracking) and conventional intelligence sources (i.e., human or signals intelligence) is a difficult problem not only due to the effort required to obtain
evidence, but the ease with which an adversary can plant
false evidence. In this paper, we introduce a formal reasoning system called the InCA (Intelligent Cyber Attribution)
framework that is designed to aid an analyst in the attribution of a cyber-operation even when the available information is conflicting and/or uncertain. Our approach combines argumentation-based reasoning, logic programming,
and probabilistic models to not only attribute an operation
but also explain to the analyst why the system reaches its
conclusions.

1

Introduction

An important issue in cyber-warfare is the puzzle of determining who was responsible for a given cyber-operation –
be it an incident of attack, reconnaissance, or information
theft. This is known as the “attribution problem” [1]. The
difficulty of this problem stems not only from the amount of
effort required to find forensic clues but also the ease with
which an attacker can plant false clues to mislead security
personnel. Further, while techniques such as forensics and
reverse-engineering [2], source tracking [3], honeypots [4],
and sinkholing [5] are commonly employed to find evidence
that can lead to attribution, it is unclear how this evidence
is to be combined and reasoned about. In a military setting,
such evidence is augmented with normal intelligence collection, such as human intelligence (HUMINT), signals intelligence (SIGINT) and other means – this adds additional
complications to the task of attributing a given operation.
Essentially, cyber-attribution is a highly-technical intelligence analysis problem where an analyst must consider a
variety of sources, each with its associated level of confidence, to provide a decision maker (e.g., a military commander) insight into who conducted a given operation.
As it is well known that people’s ability to conduct intelligence analysis is limited [6], and due to the highly technical nature of many cyber evidence-gathering techniques,
an automated reasoning system would be best suited for
the task. Such a system must be able to accomplish sev-

eral goals, among which we distinguish the following main
capabilities:
1. Reason about evidence in a formal, principled manner,
i.e., relying on strong mathematical foundations.
2. Consider evidence for cyber attribution associated with
some level of probabilistic uncertainty.
3. Consider logical rules that allow for the system to draw
conclusions based on certain pieces of evidence and iteratively apply such rules.
4. Consider pieces of information that may not be compatible with each other, decide which information is
most relevant, and express why.
5. Attribute a given cyber-operation based on the abovedescribed features and provide the analyst with the
ability to understand how the system arrived at that
conclusion.
In this paper we present the InCA (Intelligent Cyber Attribution) framework, which meets all of the above qualities.
Our approach relies on several techniques from the artificial intelligence community, including argumentation, logic
programming, and probabilistic reasoning. We first outline the underlying mathematical framework and provide
examples based on real-world cases of cyber-attribution (cf.
Section 2); then, in Sections 3 and 4, we formally present
InCA and attribution queries, respectively. Finally, we discuss conclusions and future work in Section 5.

2

Two Kinds of Models

Our approach relies on two separate models of the world.
The first, called the environmental model (EM) is used
to describe the background knowledge and is probabilistic in
nature. The second one, called the analytical model (AM)
is used to analyze competing hypotheses that can account
for a given phenomenon (in this case, a cyber-operation).
The EM must be consistent – this simply means that there
must exist a probability distribution over the possible states
of the world that satisfies all of the constraints in the model,
as well as the axioms of probability theory. On the contrary,
the AM will allow for contradictory information as the system must have the capability to reason about competing
explanations for a given cyber-operation. In general, the

EM
“Malware X was compiled
on a system using the
English language.”
“Malware W and malware X
were created in a similar
coding style.”
“Country Y and country Z
are currently at war.”
“Country Y has a significant
investment in math-scienceengineering (MSE) education.”

AM
“Malware X was compiled
on a system in Englishspeaking country Y.”
“Malware W and
malware X are
related.”
“Country Y has a motive to
launch a cyber-attack against
country Z.”
“Country Y has the capability
to conduct a cyber-attack.”

condOp(baja, worm123 ) is true if baja was responsible for
cyber-operation worm123 . A sample set of predicate symbols for the analysis of a cyber attack between two states
over contention of a particular industry is shown in Figure 2;
these will be used in examples throughout the paper.
A construct formed with a predicate and constants as
arguments is known as a ground atom (we shall often deal
with ground atoms). The sets of all ground atoms for EM
and AM are denoted with GEM and GAM , respectively.
Example 2.2 The following are examples of ground atoms
over the predicates given in Figure 2.

Figure 1: Example observations – EM vs. AM.

GEM :
EM contains knowledge such as evidence, intelligence reporting, or knowledge about actors, software, and systems.
The AM, on the other hand, contains ideas the analyst concludes based on the information in the EM. Figure 1 gives
some examples of the types of information in the two models. Note that an analyst (or automated system) could assign a probability to statements in the EM column whereas
statements in the AM column can be true or false depending
on a certain combination (or several possible combinations)
of statements from the EM. We now formally describe these
two models as well as a technique for annotating knowledge
in the AM with information from the EM – these annotations specify the conditions under which the various statements in the AM can potentially be true.
Before describing the two models in detail, we first introduce the language used to describe them. Variable and
constant symbols represent items such as computer systems,
types of cyber operations, actors (e.g., nation states, hacking groups), and other technical and/or intelligence information. The set of all variable symbols is denoted with
V, and the set of all constants is denoted with C. For our
framework, we shall require two subsets of C, Cact and Cops ,
that specify the actors that could conduct cyber-operations
and the operations themselves, respectively. In the examples in this paper, we will use capital letters to represent
variables (e.g., X, Y, Z). The constants in Cact and Cops
that we use in the running example are specified in the following example.
Example 2.1 The following (fictitious) actors and cyberoperations will be used in our examples:
Cact
Cops

=
=

{baja, krasnovia, mojave}
{worm123 }

(1)
(2)


The next component in the model is a set of predicate
symbols. These constructs can accept zero or more variables or constants as arguments, and map to either true
or false. Note that the EM and AM use separate sets of
predicate symbols – however, they can share variables and
constants. The sets of predicates for the EM and AM are
denoted with PEM , PAM , respectively. In InCA, we require
PAM to include the binary predicate condOp(X, Y ), where
X is an actor and Y is a cyber-operation. Intuitively, this
means that actor X conducted operation Y . For instance,

origIP (mw123sam1 , krasnovia),
mwHint (mw123sam1 , krasnovia),
inLgConf (krasnovia, baja),
mseTT (krasnovia, 2)

GAM :

evidOf (mojave, worm123 ),
motiv (baja, krasnovia),
expCw (baja),
tgt (krasnovia, worm123 )


For a given set of ground atoms, a world is a subset of the
atoms that are considered to be true (ground atoms not in
the world are false). Hence, there are 2|GEM | possible worlds
in the EM and 2|GAM | worlds in the AM, denoted with WEM
and WAM , respectively.
Clearly, even a moderate number of ground atoms can
yield an enormous number of worlds to explore. One way
to reduce the number of worlds is to include integrity constraints, which allow us to eliminate certain worlds from
consideration – they simply are not possible in the setting
being modeled. Our principle integrity constraint will be of
the form:
oneOf(A′ )
where A′ is a subset of ground atoms. Intuitively, this says
that any world where more than one of the atoms from
set A′ appear is invalid. Let ICEM and ICAM be the sets
of integrity constraints for the EM and AM, respectively,
and the sets of worlds that conform to these constraints be
WEM (ICEM ), WAM (ICAM ), respectively.
Atoms can also be combined into formulas using standard
logical connectives: conjunction (and), disjunction (or), and
negation (not). These are written using the symbols ∧, ∨, ¬,
respectively. We say a world (w) satisfies a formula (f ),
written w |= f , based on the following inductive definition:
• if f is a single atom, then w |= f iff f ∈ w;
• if f = ¬f ′ then w |= f iff w 6|= f ′ ;
• if f = f ′ ∧ f ′′ then w |= f iff w |= f ′ and w |= f ′′ ; and
• if f = f ′ ∨ f ′′ then w |= f iff w |= f ′ or w |= f ′′ .
We use the notation f ormulaEM , f ormulaAM to denote the
set of all possible (ground) formulas in the EM and AM,
respectively. Also, note that we use the notation ⊤, ⊥ to

PEM :

origIP (M, X)
malwInOp(M, O)
mwHint(M, X)
compilLang (M, C)
nativLang(X, C)
inLgConf (X, X ′ )
mseTT (X, N )
infGovSys(X, M )
cybCapAge(X, N )
govCybLab(X)

Malware M originated from an IP address belonging to actor X.
Malware M was used in cyber-operation O.
Malware M contained a hint that it was created by actor X.
Malware M was compiled in a system that used language C.
Language C is the native language of actor X.
Actors X and X ′ are in a larger conflict with each other.
There are at least N number of top-tier math-science-engineering universities in country X.
Systems belonging to actor X were infected with malware M .
Actor X has had a cyber-warfare capability for N years or less.
Actor X has a government cyber-security lab.

PAM :

condOp(X, O)
evidOf (X, O)
motiv (X, X ′ )
isCap(X, O)
tgt(X, O)
hasMseInvest (X)
expCw (X)

Actor X conducted cyber-operation O.
There is evidence that actor X conducted cyber-operation O.
Actor X had a motive to launch a cyber-attack against actor X ′ .
Actor X is capable of conducting cyber-operation O.
Actor X was the target of cyber-operation O.
Actor X has a significant investment in math-science-engineering education.
Actor X has experience in conducting cyber-operations.

Figure 2: Predicate definitions for the environment and analytical models in the running example.
represent tautologies (formulas that are true in all worlds)
and contradictions (formulas that are false in all worlds),
respectively.

2.1

Environmental Model

In this section we describe the first of the two models,
namely the EM or environmental model. This model is
largely based on the probabilistic logic of [7], which we now
briefly review.
First, we define a probabilistic formula that consists of a
formula f over atoms from GEM , a real number p in the
interval [0, 1], and an error tolerance ǫ ∈ [0, min(p, 1 − p)].
A probabilistic formula is written as: f : p ± ǫ. Intuitively,
this statement is interpreted as “formula f is true with probability between p − ǫ and p + ǫ” – note that we make no
statement about the probability distribution over this interval. The uncertainty regarding the probability values stems
from the fact that certain assumptions (such as probabilistic independence) may not be suitable in the environment
being modeled.
Example 2.3 To continue our running example, consider
the following set ΠEM :
f1

=

govCybLab(baja) : 0.8 ± 0.1

f2
f3

=
=

cybCapAge(baja, 5) : 0.2 ± 0.1
mseTT (baja, 2) : 0.8 ± 0.1

f4

=

mwHint(mw123sam1 , mojave)
∧ compilLang (worm123 , english) : 0.7 ± 0.2

f5

=

malwInOp(mw123sam1 , worm123 )
∧ malwareRel (mw123sam1 , mw123sam2 )
∧ mwHint (mw123sam2 , mojave) : 0.6 ± 0.1

f6

=

inLgConf (baja, krasnovia)
∨ ¬cooper (baja, krasnovia) : 0.9 ± 0.1

f7

=

origIP (mw123sam1 , baja) : 1 ± 0

Throughout the paper, let Π′EM = {f1 , f2 , f3 }.



We now consider a probability distribution Pr over the
set WEM (ICEM ). We say that Pr satisfies probabilistic
P formula f : p ± ǫ iff the following holds: p − ǫ ≤
w∈WEM (ICEM ) Pr (w) ≤ p + ǫ. A set ΠEM of probabilistic
formulas is called a knowledge base. We say that a probability distribution over WEM (ICEM ) satisfies ΠEM if and
only if it satisfies all probabilistic formulas in ΠEM .
It is possible to create probabilistic knowledge bases for
which there is no satisfying probability distribution. The
following is a simple example of this:
condOp(krasnovia, worm123 )
∨ condOp(baja, worm123 ) : 0.4 ± 0;
condOp(krasnovia, worm123 )
∧ condOp(baja, worm123 ) : 0.6 ± 0.1.
Formulas and knowledge bases of this sort are inconsistent. In this paper, we assume that information is properly
extracted from a set of historic data and hence consistent;
(recall that inconsistent information can only be handled in
the AM, not the EM). A consistent knowledge base could
also be obtained as a result of curation by experts, such that
all inconsistencies were removed – see [8, 9] for algorithms
for learning rules of this type.
The main kind of query that we require for the probabilistic model is the maximum entailment problem: given
a knowledge base ΠEM and a (non-probabilistic) formula
q, identify p, ǫ such that all valid probability distributions
Pr that satisfy ΠEM also satisfy q : p ± ǫ, and there does
not exist p′ , ǫ′ s.t. [p − ǫ, p + ǫ] ⊃ [p′ − ǫ′ , p′ + ǫ′ ], where
all probability distributions Pr that satisfy ΠEM also satisfy q : p′ ± ǫ′ . That is, given q, can we determine the
probability (with maximum tolerance) of statement q given
the information in ΠEM ? The approach adopted in [7] to
solve this problem works as follows. First, we must solve
the linear program defined next.
Definition 2.1 (EM-LP-MIN) Given a knowledge base
ΠEM and a formula q:

• create a variable xi for each wi ∈ WEM (ICEM );
• for each fj : pj ± ǫj ∈ ΠEM , create constraint:
X
xi ≤ pj + ǫj ;
pj − ǫ j ≤
wi ∈WEM (ICEM ) s.t. wi |=fj

• finally, we also have a constraint:
X
xi = 1.
wi ∈WEM (ICEM )

The objective is to minimize the function:
X
xi .
wi ∈WEM (ICEM ) s.t. wi |=q

We use the notation EP-LP-MIN(ΠEM , q) to refer to the
value of the objective function in the solution to the EMLP-MIN constraints.
Let ℓ be the result of the process described in Definition 2.1. The next step is to solve the linear program a
second time, but instead maximizing the objective function
(we shall refer to this as EM-LP-MAX) – let u be the result of this operation. In [7], it is shown that ǫ = u−ℓ
2 and
p = ℓ + ǫ is the solution to the maximum entailment problem. We note that although the above linear program has an
exponential number of variables in the worst case (i.e., no
integrity constraints), the presence of constraints has the
potential to greatly reduce this space. Further, there are
also good heuristics (cf. [8, 10]) that have been shown to
provide highly accurate approximations with a reduced-size
linear program.
Example 2.4 Consider KB Π′EM from Example 2.3 and a
set of ground atoms restricted to those that appear in that
program. Hence, we have:
w1

= {govCybLab(baja), cybCapAge(baja, 5),

We
can
now
solve
EP-LP-MAX(Π′EM , q)
′
EP-LP-MIN(ΠEM , q) to get solution 0.9 ± 0.1.

2.2

and


Analytical Model

For the analytical model (AM), we choose a structured argumentation framework [11] due to several characteristics that
make such frameworks highly applicable to cyber-warfare
domains. Unlike the EM, which describes probabilistic information about the state of the real world, the AM must
allow for competing ideas – it must be able to represent
contradictory information. The algorithmic approach allows for the creation of arguments based on the AM that
may “compete” with each other to describe who conducted
a given cyber-operation. In this competition – known as a
dialectical process – one argument may defeat another based
on a comparison criterion that determines the prevailing argument. Resulting from this process, the InCA framework
will determine arguments that are warranted (those that
are not defeated by other arguments) thereby providing a
suitable explanation for a given cyber-operation.
The transparency provided by the system can allow analysts to identify potentially incorrect input information and
fine-tune the models or, alternatively, collect more information. In short, argumentation-based reasoning has been
studied as a natural way to manage a set of inconsistent information – it is the way humans settle disputes. As we will
see, another desirable characteristic of (structured) argumentation frameworks is that, once a conclusion is reached,
we are left with an explanation of how we arrived at it
and information about why a given argument is warranted;
this is very important information for analysts to have. In
this section, we recall some preliminaries of the underlying argumentation framework used, and then introduce the
analytical model (AM).

mseTT (baja, 2)}
w2
w3

= {govCybLab(baja), cybCapAge(baja, 5)}
= {govCybLab(baja), mseTT (baja, 2)}

w4
w5

= {cybCapAge(baja, 5), mseTT (baja, 2)}
= {cybCapAge(baja, 5)}

w6
w7

= {govCybLab(baja)}
= {mseTT (baja, 2)}

w8

= ∅

and suppose we wish to compute the probability for formula:
q = govCybLab(baja) ∨ mseTT (baja, 2).
For each formula in ΠEM we have a constraint, and for
each world above we have a variable. An objective function
is created based on the worlds that satisfy the query formula
(here, worlds w1 –w4 , w6 , w7 ). Hence, EP-LP-MIN(Π′EM , q)
can be written as:
max
0.7 ≤

x1 + x2 + x3 + x4 + x6 + x7
x1 + x2 + x3 + x6

0.1 ≤
0.8 ≤

x1 + x2 + x4 + x5
x1 + x3 + x4 + x7
x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8

w .r .t . :
≤ 0.9
≤ 0.3
≤1
=1

Defeasible Logic Programming with Presumptions
DeLP with Presumptions (PreDeLP) [12] is a formalism
combining Logic Programming with Defeasible Argumentation. We now briefly recall the basics of PreDeLP; we
refer the reader to [13, 12] for the complete presentation.
The formalism contains several different constructs: facts,
presumptions, strict rules, and defeasible rules. Facts are
statements about the analysis that can always be considered to be true, while presumptions are statements that
may or may not be true. Strict rules specify logical consequences of a set of facts or presumptions (similar to an
implication, though not the same) that must always occur,
while defeasible rules specify logical consequences that may
be assumed to be true when no contradicting information
is present. These constructs are used in the construction
of arguments, and are part of a PreDeLP program, which
is a set of facts, strict rules, presumptions, and defeasible
rules. Formally, we use the notation ΠAM = (Θ, Ω, Φ, ∆)
to denote a PreDeLP program, where Ω is the set of strict
rules, Θ is the set of facts, ∆ is the set of defeasible rules,
and Φ is the set of presumptions. In Figure 3, we provide
an example ΠAM . We now describe each of these constructs
in detail.

Facts (Θ) are ground literals representing atomic information or its negation, using strong negation “¬”. Note that
all of the literals in our framework must be formed with a
predicate from the set PAM . Note that information in this
form cannot be contradicted.

Θ:

θ1a =
θ1b =
θ2 =

evidOf (baja, worm123 )
evidOf (mojave, worm123 )
motiv (baja, krasnovia)

Ω:

ω1a =

¬condOp(baja, worm123 ) ←
condOp(mojave, worm123 )
¬condOp(mojave, worm123 ) ←
condOp(baja, worm123 )
condOp(baja, worm123 ) ←
evidOf (baja, worm123 ),
isCap(baja, worm123 ),
motiv (baja, krasnovia),
tgt(krasnovia, worm123 )
condOp(mojave, worm123 ) ←
evidOf (mojave, worm123 ),
isCap(mojave, worm123 ),
motiv (mojave, krasnovia),
tgt(krasnovia, worm123 )

Strict Rules (Ω) represent non-defeasible cause-and-effect
information that resembles an implication (though the semantics is different since the contrapositive does not hold)
and are of the form L0 ← L1 , . . . , Ln , where L0 is a ground
literal and {Li }i>0 is a set of ground literals.

ω1b =
ω2a =

Presumptions (Φ) are ground literals of the same form as
facts, except that they are not taken as being true but rather
defeasible, which means that they can be contradicted. Presumptions are denoted in the same manner as facts, except
that the symbol –≺ is added. While any literal can be used
as a presumption in InCA, we specifically require all literals
created with the predicate condOp to be defeasible.
Defeasible Rules (∆) represent tentative knowledge that
can be used if nothing can be posed against it. Just as presumptions are the defeasible counterpart of facts, defeasible
rules are the defeasible counterpart of strict rules. They
are of the form L0 –≺ L1 , . . . , Ln , where L0 is a ground literal and {Li }i>0 is a set of ground literals. Note that with
both strict and defeasible rules, strong negation is allowed
in the head of rules, and hence may be used to represent
contradictory knowledge.
Even though the above constructs are ground, we allow
for schematic versions with variables that are used to represent sets of ground rules. We denote variables with strings
starting with an uppercase letter; Figure 4 shows a nonground example.
When a cyber-operation occurs, InCA must derive arguments as to who could have potentially conducted the
action. Derivation follows the same mechanism of Logic
Programming [14]. Since rule heads can contain strong
negation, it is possible to defeasibly derive contradictory
literals from a program. For the treatment of contradictory
knowledge, PreDeLP incorporates a defeasible argumentation formalism that allows the identification of the pieces of
knowledge that are in conflict, and through the previously
mentioned dialectical process decides which information prevails as warranted.
This dialectical process involves the construction and
evaluation of arguments that either support or interfere
with a given query, building a dialectical tree in the process. Formally, we have:
Definition 2.2 (Argument) An argument hA, Li for a
literal L is a pair of the literal and a (possibly empty) set
of the EM (A ⊆ ΠAM ) that provides a minimal proof for L
meeting the requirements: (1.) L is defeasibly derived from
A, (2.) Ω ∪ Θ ∪ A is not contradictory, and (3.) A is a
minimal subset of ∆ ∪ Φ satisfying 1 and 2, denoted hA, Li.
Literal L is called the conclusion supported by the argument, and A is the support of the argument. An argument
hB, Li is a subargument of hA, L′ i iff B ⊆ A. An argument
hA, Li is presumptive iff A ∩ Φ is not empty. We will also
use Ω(A) = A ∩ Ω, Θ(A) = A ∩ Θ, ∆(A) = A ∩ ∆, and
Φ(A) = A ∩ Φ.

ω2b =

Φ:

φ1 =
φ2 =
φ3 =

hasMseInvest (baja) –≺
tgt (krasnovia, worm123 ) –≺
¬expCw (baja) –≺

∆:

δ1a =

condOp(baja, worm123 ) –≺
evidOf (baja, worm123 )
condOp(mojave, worm123 ) –≺
evidOf (mojave, worm123 )
condOp(baja, worm123 ) –≺
isCap(baja, worm123 )
condOp(baja, worm123 ) –≺
motiv (baja, krasnovia),
tgt(krasnovia, worm123 )
isCap(baja, worm123 ) –≺
hasMseInvest (baja)
¬isCap(baja, worm123 ) –≺ ¬expCw (baja)
¬isCap(mojave, worm123 ) –≺
¬expCw (mojave)

δ1b =
δ2 =
δ3 =

δ4 =
δ5a =
δ5b =

Figure 3: A ground argumentation framework.
Θ:

θ1 =
θ2 =

evidOf (baja, worm123 )
motiv (baja, krasnovia)

Ω:

ω1 =
ω2 =

¬condOp(X, O) ← condOp(X ′ , O),
X 6= X ′
condOp(X, O) ← evidOf (X, O),
isCap(X, O), motiv (X, X ′ ),
tgt(X ′ , O), X 6= X ′

Φ:

φ1 =
φ2 =
φ3 =

hasMseInvest (baja) –≺
tgt (krasnovia, worm123 ) –≺
¬expCw (baja) –≺

∆:

δ1
δ2
δ3
δ4
δ5

=
=
=
=
=

condOp(X, O) –≺ evidOf (X, O)
condOp(X, O) –≺ isCap(X, O)
condOp(X, O) –≺ motiv (X, X ′ ), tgt(X ′ , O)
isCap(X, O) –≺ hasMseInvest (X)
¬isCap(X, O) –≺ ¬expCw (X)

Figure 4: A non-ground argumentation framework.

hA1 , condOp(baja, worm123 )i
hA2 , condOp(baja, worm123 )i
hA3 , condOp(baja, worm123 )i
hA4 , condOp(baja, worm123 )i
hA5 , isCap(baja, worm123 )i
hA6 , ¬condOp(baja, worm123 )i
hA7 , ¬isCap(baja, worm123 )i

A1 = {θ1a , δ1a }
A2 = {φ1 , φ2 , δ4 , ω2a ,
θ1a , θ2 }
A3 = {φ1 , δ2 , δ4 }
A4 = {φ2 , δ3 , θ2 }
A5 = {φ1 , δ4 }
A6 = {δ1b , θ1b , ω1a }
A7 = {φ3 , δ5a }

Figure 5: Example ground arguments from Figure 3.
Note that our definition differs slightly from that of [15]
where DeLP is introduced, as we include strict rules and
facts as part of the argument. The reason for this will become clear in Section 3. Arguments for our scenario are
shown in the following example.
Example 2.5 Figure 5 shows example arguments based on
the knowledge base from Figure 3. Note that the following
relationship exists:
hA5 , isCap(baja, worm123 )i is a sub-argument of
hA2 , condOp(baja, worm123 )i and
hA3 , condOp(baja, worm123 )i.

Given argument hA1 , L1 i, counter-arguments are arguments that contradict it. Argument hA2 , L2 i counterargues
or attacks hA1 , L1 i literal L′ iff there exists a subargument
hA, L′′ i of hA1 , L1 i s.t. set Ω(A1 )∪Ω(A2 )∪Θ(A1 )∪Θ(A2 )∪
{L2 , L′′ } is contradictory.
Example 2.6 Consider the arguments from Example 2.5.
The following are some of the attack relationships between
them: A1 , A2 , A3 , and A4 all attack A6 ; A5 attacks A7 ;
and A7 attacks A2 .

A proper defeater of an argument hA, Li is a counterargument that – by some criterion – is considered to be
better than hA, Li; if the two are incomparable according
to this criterion, the counterargument is said to be a blocking defeater. An important characteristic of PreDeLP is
that the argument comparison criterion is modular, and
thus the most appropriate criterion for the domain that
is being represented can be selected; the default criterion
used in classical defeasible logic programming (from which
PreDeLP is derived) is generalized specificity [16], though
an extension of this criterion is required for arguments using presumptions [12]. We briefly recall this criterion next
– the first definition is for generalized specificity, which is
subsequently used in the definition of presumption-enabled
specificity.
Definition 2.3 Let ΠAM = (Θ, Ω, Φ, ∆) be a PreDeLP
program and let F be the set of all literals that have a defeasible derivation from ΠAM . An argument hA1 , L1 i is preferred to hA2 , L2 i, denoted with A1 ≻P S A2 iff the two
following conditions hold:
1. For all H ⊆ F , Ω(A1 )∪Ω(A2 )∪H is non-contradictory:
if there is a derivation for L1 from Ω(A2 ) ∪ Ω(A1 ) ∪
∆(A1 ) ∪ H, and there is no derivation for L1 from
Ω(A1 ) ∪ Ω(A2 ) ∪ H, then there is a derivation for L2
from Ω(A1 ) ∪ Ω(A2 ) ∪ ∆(A2 ) ∪ H.

2. There is at least one set H ′ ⊆ F , Ω(A1 ) ∪ Ω(A2 ) ∪
H ′ is non-contradictory, such that there is a derivation
for L2 from Ω(A1 ) ∪ Ω(A2 ) ∪ H ′ ∪ ∆(A2 ), there is no
derivation for L2 from Ω(A1 )∪Ω(A2 )∪H ′ , and there is
no derivation for L1 from Ω(A1 )∪Ω(A2 )∪H ′ ∪∆(A1 ).
Intuitively, the principle of specificity says that, in the
presence of two conflicting lines of argument about a proposition, the one that uses more of the available information is
more convincing. A classic example involves a bird, Tweety,
and arguments stating that it both flies (because it is a
bird) and doesn’t fly (because it is a penguin). The latter
argument uses more information about Tweety – it is more
specific – and is thus the stronger of the two.
Definition 2.4 ([12]) Let ΠAM = (Θ, Ω, Φ, ∆) be a PreDeLP program. An argument hA1 , L1 i is preferred to
hA2 , L2 i, denoted with A1 ≻ A2 iff any of the following
conditions hold:
1. hA1 , L1 i and hA2 , L2 i are both factual arguments and
hA1 , L1 i ≻P S hA2 , L2 i.
2. hA1 , L1 i is a factual argument and hA2 , L2 i is a presumptive argument.
3. hA1 , L1 i and hA2 , L2 i are presumptive arguments, and
(a) ¬(Φ(A1 ) ⊆ Φ(A2 )), or
(b) Φ(A1 ) = Φ(A2 ) and hA1 , L1 i ≻P S hA2 , L2 i.
Generally, if A, B are arguments with rules X and Y , resp.,
and X ⊂ Y , then A is stronger than B. This also holds when
A and B use presumptions P1 and P2 , resp., and P1 ⊂ P2 .
Example 2.7 The following are relationships between arguments from Example 2.5, based on Definitions 2.3
and 2.4:
A1 and A6 are incomparable (blocking defeaters);
A6 ≻ A2 , and thus A6 defeats A2 ;
A6 ≻ A3 , and thus A6 defeats A3 ;
A6 ≻ A4 , and thus A6 defeats A4 ;
A5 and A7 are incomparable (blocking defeaters).

A sequence of arguments called an argumentation line
thus arises from this attack relation, where each argument
defeats its predecessor. To avoid undesirable sequences,
that may represent circular or fallacious argumentation
lines, in DeLP an argumentation line is acceptable if it satisfies certain constraints (see [13]). A literal L is warranted
if there exists a non-defeated argument A supporting L.
Clearly, there can be more than one defeater for a particular argument hA, Li. Therefore, many acceptable argumentation lines could arise from hA, Li, leading to a tree
structure. The tree is built from the set of all argumentation lines rooted in the initial argument. In a dialectical
tree, every node (except the root) represents a defeater of
its parent, and leaves correspond to undefeated arguments.
Each path from the root to a leaf corresponds to a different
acceptable argumentation line. A dialectical tree provides
a structure for considering all the possible acceptable argumentation lines that can be generated for deciding whether

an argument is defeated. We call this tree dialectical because it represents an exhaustive dialectical1 analysis for
the argument in its root. For argument hA, Li, we denote
its dialectical tree with T (hA, Li).
Given a literal L and an argument hA, Li, in order to decide whether or not a literal L is warranted, every node in
the dialectical tree T (hA, Li) is recursively marked as “D”
(defeated ) or “U” (undefeated ), obtaining a marked dialectical tree T ∗ (hA, Li) where:
• All leaves in T ∗ (hA, Li) are marked as “U”s, and
• Let hB, qi be an inner node of T ∗ (hA, Li). Then, hB, qi
will be marked as “U” iff every child of hB, qi is marked
as “D”. Node hB, qi will be marked as “D” iff it has at
least a child marked as “U”.
Given argument hA, Li over ΠAM , if the root of T ∗ (hA, Li)
is marked “U”, then T ∗ (hA, hi) warrants L and that L is
warranted from ΠAM . (Warranted arguments correspond to
those in the grounded extension of a Dung argumentation
system [17].)
We can then extend the idea of a dialectical tree to a
dialectical forest. For a given literal L, a dialectical forest
F (L) consists of the set of dialectical trees for all arguments
for L. We shall denote a marked dialectical forest, the set of
all marked dialectical trees for arguments for L, as F ∗ (L).
Hence, for a literal L, we say it is warranted if there is at
least one argument for that literal in the dialectical forest
F ∗ (L) that is labeled “U”, not warranted if there is at least
one argument for literal ¬L in the forest F ∗ (¬L) that is
labeled “U”, and undecided otherwise.

3

af (θ1 ) =

af (θ2 ) =
af (ω1 ) =
af (ω2 ) =
af (φ1 ) =
af (φ2 ) =
af (φ3 ) =
af (δ1 ) =
af (δ2 ) =
af (δ3 ) =
af (δ4 ) =
af (δ5 ) =

Figure 6: Example annotation function.
Suppose we added the following presumptions to our running example:
φ3 = evidOf (X, O) –≺ , and
φ4 = motiv (X, X ′ ) –≺ .
Note that these presumptions are constructed using the
same formulas as facts θ1 , θ2 . Suppose we extend af as
follows:
af (φ3 ) =

malwInOp(M, O) ∧ malwareRel (M, M ′ )
∧mwHint(M ′ , X)

af (φ4 ) =

inLgConf (Y, X ′ ) ∧ cooper (X, Y )

The InCA Framework

Having defined our environmental and analytical models
(ΠEM , ΠAM respectively), we now define how the two relate, which allows us to complete the definition of our InCA
framework.
The key intuition here is that given a ΠAM , every element of Ω ∪ Θ ∪ ∆ ∪ Φ might only hold in certain worlds
in the set WEM – that is, worlds specified by the environment model. As formulas over the environmental atoms
in set GEM specify subsets of WEM (i.e., the worlds that
satisfy them), we can use these formulas to identify the
conditions under which a component of Ω ∪ Θ ∪ ∆ ∪ Φ can
be true. Recall that we use the notation f ormulaEM to
denote the set of all possible formulas over GEM . Therefore, it makes sense to associate elements of Ω ∪ Θ ∪ ∆ ∪ Φ
with a formula from f ormulaEM . In doing so, we can in
turn compute the probabilities of subsets of Ω ∪ Θ ∪ ∆ ∪ Φ
using the information contained in ΠEM , which we shall describe shortly. We first introduce the notion of annotation
function, which associates elements of Ω ∪ Θ ∪ ∆ ∪ Φ with
elements of f ormulaEM .
We also note that, by using the annotation function (see
Figure 6), we may have certain statements that appear as
both facts and presumptions (likewise for strict and defeasible rules). However, these constructs would have different annotations, and thus be applicable in different worlds.
1 In

the sense of providing reasons for and against a position.

origIP (worm123 , baja)∨
malwInOp(worm123 , o)∧
mwHint (worm123 , baja)∨
(compilLang (worm123
 , c)∧
nativLang(baja, c))
inLgConf (baja, krasnovia)
True
True
mseTT (baja, 2) ∨ govCybLab(baja)
malwInOp(worm123 , o′ )∧
infGovSys(krasnovia , worm123 )
cybCapAge(baja, 5)
True
True
True
True
True

So, for instance, unlike θ1 , φ3 can potentially be true in any
world of the form:
{malwInOp(M, O), malwareRel (M, M ′ ), mwHint (M ′ , X)}
while θ1 cannot be considered in any those worlds.
With the annotation function, we now have all the components to formally define an InCA framework.
Definition 3.1 (InCA Framework) Given environmental model ΠEM , analytical model ΠAM , and annotation
function af , I = (ΠEM , ΠAM , af ) is an InCA framework.
Given the setup described above, we consider a worldbased approach – the defeat relationship among arguments
will depend on the current state of the world (based on the
EM). Hence, we now define the status of an argument with
respect to a given world.
Definition 3.2 (Validity) Given InCA framework
I = (ΠEM , ΠAM , af ), argument hA, Li is valid w.r.t. world
w ∈ WEM iff ∀c ∈ A, w |= af (c).
In other words, an argument is valid with respect to w
if the rules, facts, and presumptions in that argument are

present in w – the argument can then be built from information that is available in that world. In this paper, we
extend the notion of validity to argumentation lines, dialectical trees, and dialectical forests in the expected way (an
argumentation line is valid w.r.t. w iff all arguments that
comprise that line are valid w.r.t. w).
Example 3.1 Consider worlds w1 , . . . , w8 from Example 2.4 along with the argument hA5 , isCap(baja, worm123 )i
from Example 2.5. This argument is valid in worlds w1 –w4 ,
w6 , and w7 .

We now extend the idea of a dialectical tree w.r.t.
worlds – so, for a given world w ∈ WEM , the dialectical
(resp., marked dialectical) tree induced by w is denoted
by Tw hA, Li (resp., Tw∗ hA, Li). We require that all arguments and defeaters in these trees to be valid with respect
to w. Likewise, we extend the notion of dialectical forests in
the same manner (denoted with Fw (L) and Fw∗ (L), respectively). Based on these concepts we introduce the notion
of warranting scenario.
Definition 3.3 (Warranting Scenario) Let I = (ΠEM ,
ΠAM , af ) be an InCA framework and L be a ground literal
over GAM ; a world w ∈ WEM is said to be a warranting
scenario for L (denoted w ⊢war L) iff there is a dialectical
forest Fw∗ (L) in which L is warranted and Fw∗ (L) is valid
w.r.t w.
Example 3.2 Following from Example 3.1, argument
hA5 , isCap(baja, worm123 )i is warranted in worlds w3 , w6 ,
and w7 .

Hence, the set of worlds in the EM where a literal L in the
AM must be true is exactly the set of warranting scenarios
– these are the “necessary” worlds, denoted:
nec(L) = {w ∈ WEM | (w ⊢war L).}
Now, the set of worlds in the EM where AM literal L can
be true is the following – these are the “possible” worlds,
denoted:
poss(L) = {w ∈ WEM | w 6⊢war ¬L}.
The following example illustrates these concepts.
Example 3.3 Following from Example 3.1:
nec(isCap(baja, worm123 )) = {w3 , w6 , w7 } and
poss(isCap(baja, worm123 )) = {w1 , w2 , w3 , w4 , w6 , w7 }.


Hence, for a given InCA framework I, if we are given
a probability distribution Pr over the worlds in the EM,
then we can compute an upper and lower bound on the
probability of literal L (denoted PL,Pr ,I ) as follows:
X
Pr (w),
ℓL,Pr,I =
w∈nec(L)

uL,Pr ,I =

X

w∈poss(L)

Pr (w),

and
ℓL,Pr,I ≤ PL,Pr ,I ≤ uL,Pr,I .
Now let us consider the computation of probability
bounds on a literal when we are given a knowledge base
ΠEM in the environmental model, which is specified in I,
instead of a probability distribution over
V all worlds.
V For a
given world w ∈ WEM , let f or(w) =
a
∧
a∈w
a∈w
/ ¬a
– that is, a formula that is satisfied only by world w. Now
we can determine the upper and lower bounds on the probability of a literal w.r.t. ΠEM (denoted PL,I ) as follows:


_
f or(w) ,
ℓL,I = EP-LP-MIN ΠEM ,
w∈nec(L)



uL,I = EP-LP-MAX ΠEM ,

_

w∈poss(L)



f or(w) ,

and
Hence, PL,I

ℓL,I ≤ PL,I ≤ uL,I .

−ℓ
u
u
−ℓ
= ℓL,I + L,I 2 L,I ± L,I 2 L,I .


Example 3.4 Following from Example 3.1, argument hA5 , isCap(baja, worm123 )i, we can compute
PisCap(baja,worm123 ),I (where I = (Π′EM , ΠAM , af )). Note
that for the upper bound, the linear program we need to set
up is as in Example 2.4. For the lower bound, the objective
function changes to: min x3 + x6 + x7 . From these linear
constraints, we obtain: PisCap(baja,worm123 ),I = 0.75 ± 0.25.


4

Attribution Queries

We now have the necessary elements required to formally
define the kind of queries that correspond to the attribution
problems studied in this paper.
Definition 4.1 Let I = (ΠEM , ΠAM , af ) be an InCA
framework, S ⊆ Cact (the set of “suspects”), O ∈ Cops
(the “operation”), and E ⊆ GEM (the “evidence”). An actor A ∈ S is said to be a most probable suspect iff there does
not exist A′ ∈ S such that PcondOp(A′ ,O),I ′ > PcondOp(A,O),I ′
where I ′ = (ΠEM ∪ ΠE , ΠAM , af ′ ) with ΠE defined as
S
c∈E {c : 1 ± 0}.
Given the above definition, we refer to Q = (I, S, O, E)
as an attribution query, and A as an answer to Q. We note
that in the above definition, the items of evidence are added
to the environmental model with a probability of 1. While
in general this may be the case, there are often instances
in analysis of a cyber-operation where the evidence may be
true with some degree of uncertainty. Allowing for probabilistic evidence is a simple extension to Definition 4.1 that
does not cause any changes to the results of this paper.
To understand how uncertain evidence can be present in
a cyber-security scenario, consider the following. In Symantec’s initial analysis of the Stuxnet worm, they found the
routine designed to attack the S7-417 logic controller was

incomplete, and hence would not function [18]. However, industrial control system expert Ralph Langner claimed that
the incomplete code would run provided a missing data
block is generated, which he thought was possible [19]. In
this case, though the code was incomplete, there was clearly
uncertainty regarding its usability. This situation provides
a real-world example of the need to compare arguments –
in this case, in the worlds where both arguments are valid,
Langner’s argument would likely defeat Symantec’s by generalized specificity (the outcome, of course, will depend on
the exact formalization of the two). Note that Langner
was later vindicated by the discovery of an older sample,
Stuxnet 0.5, which generated the data block.2
InCA also allows for a variety of relevant scenarios to the
attribution problem. For instance, we can easily allow for
the modeling of non-state actors by extending the available
constants – for example, traditional groups such as Hezbollah, which has previously wielded its cyber-warfare capabilities in operations against Israel [1]. Likewise, the InCA can
also be used to model cooperation among different actors
in performing an attack, including the relationship between
non-state actors and nation-states, such as the potential
connection between Iran and militants stealing UAV feeds in
Iraq, or the much-hypothesized relationship between hacktivist youth groups and the Russian government [1]. Another aspect that can be modeled is deception where, for
instance, an actor may leave false clues in a piece of malware to lead an analyst to believe a third party conducted
the operation. Such a deception scenario can be easily created by adding additional rules in the AM that allow for
the creation of such counter-arguments. Another type of
deception that could occur include attacks being launched
from a system not in the responsible party’s area, but under
their control (e.g., see [5]). Again, modeling who controls a
given system can be easily accomplished in our framework,
and doing so would simply entail extending an argumentation line. Further, campaigns of cyber-operations can also
be modeled, as well as relationships among malware and/or
attacks (as detailed in [20]).
As with all of these abilities, InCA provides the analyst
the means to model a complex situation in cyber-warfare
but saves him from carrying out the reasoning associated
with such a situation. Additionally, InCA results are constructive, so an analyst can “trace-back” results to better
understand how the system arrived at a given conclusion.

5

Conclusion

In this paper we introduced InCA, a new framework that
allows the modeling of various cyber-warfare/cyber-security
scenarios in order to help answer the attribution question
by means of a combination of probabilistic modeling and argumentative reasoning. This is the first framework, to our
knowledge, that addresses the attribution problem while allowing for multiple pieces of evidence from different sources,
including traditional (non-cyber) forms of intelligence such
as human intelligence. Further, our framework is the first
2 http://www.symantec.com/connect/blogs/stuxnet-05-disruptinguranium-processing-natanz

to extend Defeasible Logic Programming with probabilistic information. Currently, we are implementing InCA and
the associated algorithms and heuristics to answer these
queries. We also feel that there are some key areas to explore relating to this framework, in particular:
• Automatically learning the EM and AM from data.
• Conducting attribution decisions in near real time.
• Identifying additional evidence that must be collected
in order to improve a given attribution query.
• Improving scalability of InCA to handle large datasets.
Future work will be carried out in these directions, focusing
on the use of both real and synthetic datasets for empirical
evaluations.

Acknowledgments
This work was supported by UK EPSRC grant
EP/J008346/1 – “PrOQAW”, ERC grant 246858 –
“DIADEM”, by NSF grant #1117761, by the Army
Research Office under the Science of Security Lablet grant
(SoSL) and project 2GDATXR042, and DARPA project
R.0004972.001.
The opinions in this paper are those of the authors and
do not necessarily reflect the opinions of the funders, the
U.S. Military Academy, or the U.S. Army.

References
[1] P. Shakarian, J. Shakarian, and A. Ruef, Introduction to Cyber-Warfare: A Multidisciplinary Approach.
Syngress, 2013.
[2] C. Altheide, Digital Forensics with Open Source Tools.
Syngress, 2011.
[3] O. Thonnard, W. Mees, and M. Dacier, “On a multicriteria clustering approach for attack attribution,”
SIGKDD Explorations, vol. 12, no. 1, pp. 11–20, 2010.
[4] L. Spitzner, “Honeypots:
Catching the Insider
Threat,” in Proc. of ACSAC 2003. IEEE Computer
Society, 2003, pp. 170–179.
[5] “Shadows in the Cloud: Investigating Cyber Espionage
2.0,” Information Warfare Monitor and Shadowserver
Foundation, Tech. Rep., 2010.
[6] R. J. Heuer, Psychology of Intelligence Analysis. Center for the Study of Intelligence.
[7] N. J. Nilsson, “Probabilistic logic,” Artif. Intell.,
vol. 28, no. 1, pp. 71–87, 1986.
[8] S. Khuller, M. V. Martinez, D. S. Nau, A. Sliva, G. I.
Simari, and V. S. Subrahmanian, “Computing most
probable worlds of action probabilistic logic programs:
scalable estimation for 1030,000 worlds,” AMAI, vol.
51(2–4), pp. 295–331, 2007.

[9] P. Shakarian, A. Parker, G. I. Simari, and V. S. Subrahmanian, “Annotated probabilistic temporal logic,”
TOCL, vol. 12, no. 2, p. 14, 2011.
[10] G. I. Simari, M. V. Martinez, A. Sliva, and V. S. Subrahmanian, “Focused most probable world computations in probabilistic logic programs,” AMAI, vol. 64,
no. 2-3, pp. 113–143, 2012.
[11] I. Rahwan and G. R. Simari, Argumentation in Artificial Intelligence. Springer, 2009.
[12] M. V. Martinez, A. J. Garcı́a, and G. R. Simari, “On
the use of presumptions in structured defeasible reasoning,” in Proc. of COMMA, 2012, pp. 185–196.
[13] A. J. Garcı́a and G. R. Simari, “Defeasible logic
programming: An argumentative approach,” TPLP,
vol. 4, no. 1-2, pp. 95–138, 2004.
[14] J. W. Lloyd, Foundations of Logic Programming, 2nd
Edition. Springer, 1987.
[15] G. R. Simari and R. P. Loui, “A mathematical treatment of defeasible reasoning and its implementation,”
Artif. Intell., vol. 53, no. 2-3, pp. 125–157, 1992.
[16] F. Stolzenburg, A. Garcı́a, C. I. Chesñevar, and G. R.
Simari, “Computing Generalized Specificity,” Journal
of Non-Classical Logics, vol. 13, no. 1, pp. 87–113,
2003.
[17] P. M. Dung, “On the acceptability of arguments and its
fundamental role in nonmonotonic reasoning, logic programming and n-person games,” Artif. Intell., vol. 77,
pp. pp. 321–357, 1995.
[18] N. Falliere, L. O. Murchu, and E. Chien, “W32.Stuxnet
Dossier Version 1.4,” Symantec Corporation, Feb. 2011.
[19] R. Langner, “Matching Langner Stuxnet analysis and
Symantic dossier update,” Langner Communications
GmbH, Feb. 2011.
[20] “APT1: Exposing one of China’s cyber espionage
units,” Mandiant (tech. report), 2013.

arXiv:1309.2900v1 [cs.SI] 11 Sep 2013

Mining for Spatially-Near Communities in Geo-Located Social Networks
Joseph Hannigan

Guillermo Hernandez

Richard M. Medina

Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY
Joseph.Hannigan@usma.edu

Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY
Guillermo.Hernandez@
usma.edu

Dept. of Geography
and GeoInformation Science
George Mason University
Fairfax, VA
rmedina3@gmu.edu

Patrick Roos

Paulo Shakarian

Dept. of Computer Science
University of Maryland
College Park, MD
roos@cs.umd.edu

Dept. of Electrical Engineering
and Computer Science
U.S. Military Academy
West Point, NY
paulo@shakarian.net

Abstract
Current approaches to community detection in social networks often ignore the spatial location of the nodes. In this
paper, we look to extract spatially-near communities in a
social network. We introduce a new metric to measure the
quality of a community partition in a geolocated social networks called “spatially-near modularity” a value that increases based on aspects of the network structure but decreases based on the distance between nodes in the communities. We then look to find an optimal partition with respect
to this measure - which should be an “ideal” community with
respect to both social ties and geographic location. Though
an NP-hard problem, we introduce two heuristic algorithms
that attempt to maximize this measure and outperform nongeographic community finding by an order of magnitude. Applications to counter-terrorism are also discussed.

Introduction
Community detection in social networks remains an important and active area of research in the study of social network
mining (Girvan and Newman 2002; Newman and Girvan
2004; Newman 2004; Du et al. 2007; Blondel et al. 2008;
Schaefer 2012; Expert et al. 2011; Cerina et al. 2012;
Shakarian et al. 2013). However, many real-world social networks also have a geographic context. Social networks are
tethered to geographic locations. People and their relationships are tied to places. Even in the information age communications are dependent on access. Though access can seem
ubiquitous in many cases, digital interaction cannot yet completely replace face-to-face contact, especially for planned
activities of spatiotemporal coincidence and the transfer of
tangible objects.
Primary considerations for research in many social science disciplines today include characteristics of human activities and interactions in defined spaces. The interactions
can be between humans, or between humans and their environments. These characteristics describe aspects of social
complexity that are necessary to understand when attempt-

ing to model open or closed social systems. In studies of human security there is a new emphasis on implementations
of Activity Based Intelligence (ABI) to better understand
drivers toward specific actions and interactions, as well as
to generate an understanding of the system outside of targeted activities (Miller 2013). Though the concepts of ABI
are new to many, its academic foundations of activity spaces,
social interaction, and spatio-temporal research are well established.
Attempts to identify sociogeographic based activity
spaces, as demonstrated here, are vital to the understanding of human behavior. Multi-spatial or hybrid space (Batty
and Miller 2000) studies are much more valuable in this information age than their single space counterparts. Multiple
spaces are converging into hybrid spaces as interactions in
social systems become more complex.
In this paper, we look to develop a framework for deriving communities from social network that is relevant not
only with respect to network topology, but also geography. The main geographic concept we use to relate nodes
based on space is “nearness.” On a general level, there exists a connection between nearness and similarity. “Near”
is a spatial concept, though not necessarily geographically
spatial. Social space nearness, or adjacency, typically describes relationships between people or things that interact
in some way. Nearness based similarities need not be comprehensive. Single or few similar traits can exist to maintain interaction; however, relatively more similar traits between people can drive further or deeper interaction. Geographers and sociologists have developed concepts that
seek to explain the phenomenon of nearness and similarity in their respective disciplines. In geography Tobler’s
First Law (TFL) describes this effect in physical space
and homophily describes it in social space (Tobler 1970;
McPherson, Smith-Lovin, and Cook 2001). Geographic and
homophilic similarities are inherently connected, as one of
the greatest sources of homophily is propinquity. Furthermore, interaction is driven by nearness and similarity. The
likelihood for interaction between people increases as dis-

tance decreases between them. Community finding at the
convergence of geographic and social space nearness will
lead to the identification of communities where place and
social traits drive interaction. Results of this method may be
most meaningful in studies of social systems that are greatly
influenced by ethnicity and culture among other geographically based factors. For example, communities identified using geographic and social closeness may apply more to terrorist and criminal networks than globally dispersed business networks.
Hence, our intuition is to find communities that are
tightly-knit based on network topology, but also spatially
“near.” To do this, we create a new measure of partition quality that we term “spatial nearness modularity” that borrows
concepts from network modularity (Newman and Girvan
2004) and K-means clustering (MacQueen and others 1967;
Lloyd 1982). Hence, to find a high-quality set of communities with respect to this geography and network connections,
it stands to reason to search for an optimal partition with
respect to this measure. Unfortunately, we are able to show
that doing so is NP-hard based on the results of (Brandes
et al. 2008). To address this issue of intractability, we introduce two heuristics and we then experimentally evaluate
them, where we find that our approach provides an order-ofmagnitude improvement in spatially-near modularity over
non-geographic approaches. This is followed by a description of how this technique could apply to counter-terrorism
and a discussion of related work.

latter. Modularity will give a number in [−1, 1], a higher
value meaning better quality partition. Previous work, such
as (Brandes et al. 2008; Expert et al. 2011), has focused
on finding a partition that optimizes this quantity. However,
modularity maximization only considers network topology
and does not make any effort to group individuals that are
geographically close to each other. An alternative is to find
a partition of K clusters of nodes that minimizes the sumof-squares distance to the center of each cluster. This is
known as K-means clustering (MacQueen and others 1967;
Lloyd 1982). K-means clustering algorithms attempt to find
a partition of points on a plane into K clusters, such that the
following quantity is minimized (here xc is the centroid of
the points in cluster c):

Technical Preliminaries

Note that the additive 1 in the denominator is to avoid
division by zero and to ensure that the result will be within
the range [−1, 1]. The above optimization function has
the useful property that we can embed both modularity
maximization and K-means clustering - the first by placing
all nodes in the same location, the second by ignoring
edges among any nodes in the network and restricting the
number of clusters to be exactly K. However, one aspect
the above definition misses is that it cannot measure the
quality of an individual community. Hence, we introduce
an alternative definition below that we term “spatially-near
(SN) modularity.”

We assume the existence of a undirected graph G = (V, E)
where set V are vertices and E are edges among them. As
the graph in undirected, (i, j) ∈ E implies (j, i) ∈ E. We
shall use n, m to represent the sizes of V, E respectively.
Each edge (i, j) will be associated with a positive real
weight denoted by wij (if there is no edge between i and j,
wij = 0). For a given node i ∈ V , we shall use the symbol
ηi to represent the set {j ∈ V |∃(i, j) ∈ E} and ki is the
size of this set. We shall also assume a distance function
d : V × V → < that meets the normal distance axioms:
d(i, i) = 0, d(i, j) = d(j, i), and d(i, j) ≤ d(i, j 0 )+d(j, j 0 ).
For ease of notation, we shall use dij instead of d(i, j). In
this paper we will often use the notation C = c1 , . . . , cx
to denote a partition of V . Hence, ∪ci ∈C ci = V and for
all ci , cj ∈ C ci ∩ cj = ∅. We define the modularity
of a partition (M (C)) in accordance with the definition
introduced by (Newman and Girvan 2004) as follows:
NG-Modularity. (Newman and Girvan 2004) Given a social network G = (V, E) and partition C the NewmanGirvan (NG) modularity is defined as follows:
1 XX
ki kj
MN G (C) =
wij −
.
(1)
2m
2m
i,j∈c
c∈C

The modularity of a network partition measures the quality of its partition structure as the density of edges within
partitions compared to the density of edges between partitions. The former is ideally very high compared to the

X

aggi∈c d(i, xc )2 .

(2)

c∈C

In the above definition, agg is some aggregate
function.
P
Common aggregates used here are max and . For the purpose of this paper, as modularity is maximized, we wish to
minimize some aggregate of the distances to the center of
each cluster. Thus, one potential quantity that could be optimized is the following:
P
P
ki kj
wij − 2m

1
c∈C
P i,j∈c
.
2
2m 1 + c∈C aggi∈c d(i, xc )

(3)

SN-Modularity. Given a social network G = (V, E), partition C, and scaling parameter σ ∈ <+ , the spatially-near
(SN) modularity is defined as follows:
P
ki kj
1 X
i,j∈c wij − 2m
(4)
MSN (C, σ) =

2 .
2m
d(i,xc )
c∈C 1 + aggi∈c
σ
So, for a given community, we can measure its quality
with the following:
1
2m

P

i,j∈c

wij −


1 + aggi∈c

ki kj
2m

d(i,xc )
σ

2 .

(5)

We also note that as σ increases, distance is deemphasized. This parameter would be specified based on

the relative importance of distance to to network structure
as well as the unit of measurement used for distance. Practically, a user could potentially provide this parameter in many
different ways. Simple methods would include setting σ to
1, the average distance among all pairs of nodes, or the average distance among all pairs of nodes that have an edge between them. Alternatively, this parameter could also learned
from historical data, if such a corpus is available. Another
approach is for the user to explore various parameter settings. In this work, we leave advanced methods for determining σ to future work and conduct experiments with multiple
settings for this parameter. However, we note that for particularly large values of σ, SN-modularity becomes equivalent
to NG-modularity. It is easy to show the following property:
lim σ→∞ MSN (C, σ) = MN G (C).

(6)

However, maximizing MSN (C, σ) remains NP-hard.
Hence, in this paper we introduce two heuristic algorithms
to find a partition C where MSN (C) is near-optimal.
Theorem. For a given social network G = (V, E) and
scaling factor σ, identifying a partition C s.t. MSN (C, σ)
is maximized is NP-hard.
Proof. We can embed an instance of finding a partition C that maximizes MN G (C) into the problem from
the statement by creating a distance function d where
∀i, j, d(i, j) = 0 and setting σ to an arbitrary value. Hence,
any algorithm that maximizes MSN using this construction
also maximizes MN G . Since finding a partition that maximizes MN G is NP-hard by the results of (Brandes et al.
2008), the statement of the theorem follows. 

Algorithms
In the previous section, we found that identifying a spatiallynear partition is an NP-hard problem. Hence, in this section,
we propose two heuristic approaches to deal with this intractability. We later describe our evaluation of these approaches. In our first heuristic, which we call “Louvain-SN”,
we employ the modification of the Louvain algorithm of
Blondel et al. (Blondel et al. 2008), only instead of using
it to maximize NG-modularity, we use it to maximize SNmodularity (the Louvain algorithm was designed to find a
near-optimal parition w.r.t. NG-modularity). Our second algorithm, the SNIC (Spatially Near Iterative Constraining)
algorithm, relies on multiple calls to the Louvain-SN algorithm - but each with a limit on the aggregate distance permitted in a community.

The Louvain-SN Algorithm
The original Louvain algorithm of (Blondel et al. 2008) is
an iterated, hierarchical process in which two phases are applied repeatedly until maximal modularity is reached: During the first phase, each node vi ∈ V of the given social network is assigned to a community c, creating an initial partition. In (Blondel et al. 2008), the singleton partition was
used - which we use in this work as well. Then, for each
vi ∈ V , the gains in modularity that would result from moving vi to the community of each of its neighbors vj ∈ ηi are

calculated, and vi is removed and placed into the community for which the maximum improvement in modularity is
achieved (unless no positive gain in modularity is possible).
This sub-process is repeated sequentially for each vi ∈ V
until no individual move will result in a gain in modularity, marking the end of the first phase and giving a partition
C. During the second phase, a new network is built by using each ci ∈ C as a node in the new network, call these
nodes meta-nodes. Weights on the edges between any two
meta-nodes in the new network are assigned to be the sum
of the weights of the edges between nodes in the two communities corresponding to the meta-nodes. Here, self-loops
are created for each meta-node in the new network from the
links between nodes of the community corresponding to that
meta-node. After this phase is complete, the two phases are
reapplied iteratively until there are no more changes.
The efficiency of the Louvain algorithm relies on an easy
re-calculation of modularity in the first phase of the algorithm. When computing gains in modularity in phase one of
the algorithm, removing any node vi , the overall increase in
modularity if it is placed into community c is proportional
to:
ki,in −

X ki kj
j∈c

2m

(7)

In our modification for optimizing SN-modularity, we can
retain some of this efficiency by retaining the previous denominator and numerator of Equation 5 (multiplied by 2m)
for each community. By retaining these values along with
the value of Equation 7, computing the increase or decrease
in modularity for a community can be performed quickly
(though this ultimately depends on how the aggregate function agg and the centers of the communities xc are computed). Additionally, in the creation of the meta-nodes, we
use the centers from the previous step as their location. Additionally, we also found that we obtained improvement in
performance by allowing a removed node to be moved back
to a community containing just itself, as unlike in the maximization of standard modularity, isolating a node in this
fashion could potentially increase the overall modularity due
to the denominator of Expression 4.

The SNIC Heuristic
Next, we introduce the “Spatially Near, Iterative Constraining” (SNIC) Heuristic. This idea was created as the result
from a pilot experiment where we noticed that constraining
a node to join only communities where it was geographically “near” to all the members would sometimes improve
the resulting quantity of MSN . The question is how does
one determine where to set this distance constraint. In our
experiments we ran our modified Louvain approach iteratively, returning only the maximum distance between two
points in the community upon each iteration. This distance is
then set as the distance constraint for the next iteration. Once
the distance constraint reaches zero (or a maximum number
of iterations is reached), the algorithm then returns the partition found which is associated with the greatest value for
Expression 4.

Experimental Results

0.4

SN Modularity

0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0

1000

2000

3000

4000

5000

σ (km)
SNIC

Louvain-SN

Louvain

Figure 1: σ (in kilometers) vs. (average) SN-modularity for
the partitions returned by the Louvain, Louvain-SN, and
SNIC algorithms.
were found between the Louvain and Louvain-SN algorithms; however, the SNIC algorithm was found to be different than both the Louvain (at p = 0.010) and the LouvainSN (at p = 0.020). Additionally, the differences for runtimes
of the three approaches were found to be different with a
p-value of 0.000 (see Figure 2). As with the difference in
SN-modularity, runtime differences exist between the Louvain and the SNIC algorithms (at p = 0.000) and between
the Louvain-SN and the SNIC algorithms (at p = 0.000).
These results are also provided through use of Tukey’s HSD.
Differences in SN-modularity and runtimes for the three approaches can be seen in Figures 1 and 2, respectively. Further, we also note that although the SNIC algorithm has significantly greater runtime than the Louvain and Louvain-SN,
it still appear to scale linearly with the number of nodes in
the network (R2 = 0.992). Hence, it may still be a viable
solution for very large networks. We are currently studying
the scalability of this algorithm.
500
R² = 0.992
450
400

Run Time (seconds)

For our experiments, we used information extracted from
the Brightkite location-based online social networking
sites (Cho, Myers, and Leskovec 2011).
We built our implementation in Python 2.6 on top of the
NetworkX library1 leveraging code from Thomas Aynaud’s
implementation of the Louvain algorithm2 . Our implementation took approximately 1000 lines of code. The experiments were run on a computer equipped with an Intel Core i7
Processor operating at 2.67 GHz (one core utilized) running
Microsoft Windows 7 and equipped with 4.0 GB of physical
memory. All statistics presented in this section were calculated using SPSS 19. We use our heuristics to find partitions
based on Expression 4 where agg = max.
In our first set of tests, we iteratively selected nodes and
their neighbors from the Brightkite network dataset provided
by the authors of (Cho, Myers, and Leskovec 2011) to produce 10 samples of 1000 nodes. To generate the samples,
each sample begins with a randomly selected node from the
network. The selected node and all of its connected nodes
are then included in the next iteration, in which a new random node is chosen. This continues until 1000 nodes are
reached for each sample. The minimum edge count for all
samples processed is 1729, while the maximum is 2282. The
average number of edges is 1929.
In our trials, we varied the σ parameter with the values
{300, 500, 1000, 2000, 3000, 4000, 5000}. For each dataset
and each value of σ, we compare the SN-modularity returned by three approaches: the Louvain algorithm (does
not consider geospatial information), the Louvain-SN algorithm (the modified version of the Louvain algorithm for
SN-modularity optimization), and the SNIC algorithm (an
iterated version of the Louvain-SN that selects the best result based on updating the distance constraint).
The SNIC algorithm returned a partition with greater average SN-modularity for each value of σ than the partitions
returned by the Louvain and Louvain-SN algorithms (see
Figure 1). In general, the SNIC algorithm consistently outperformed the Louvain algorithm in terms of SN-modularity
- producing a partition of greater SN-modularity on all trials. The Louvain-SN outperformed the standard Louvain in
all but 11 (of 70) trials, though (as we discuss later in this
section) this improvement is likely not statistically significant, unlike the SNIC heuristic.3
To determine significant difference in SN-modularity of
the three approaches on the Brightkite dataset, analysis
of variance (ANOVA) tests were used. Difference in SNmodularity for the three approaches was confirmed with
a p-value of 0.006. A Tukey’s Honest Significant Difference (HSD) test was also used to determine pairwise differences between the approaches. No significant differences

0.5
0.45

350
300
250
200
150
100
R² = 0.988

50

R² = 0.992

0
0

1000

2000

3000

4000

5000

6000

Network Size (nodes)
SNIC

Louvain-SN

Louvain

1

http://networkx.github.com/
http://perso.crans.org/aynaud/communities/
3
There were 11 such trials out of the 70 trials where the Louvain outperformed the Louvain-SN. Of the cases where there was
decreased quality over standard Louvain, the maximum decrease
in quality was 26.52% and the average decrease was 15.10%. The
SNIC algorithm outperformed the Louvain algorithm on all trials.
2

Figure 2: Network size (by nodes) vs. runtime for the partitions returned by the Louvain, Louvain-SN, and SNIC algorithms.
Figure 3 shows the increase in quality of community find-

10000%

A
% Increase in SN-Modularity

1000%

100%

10%

1%

0%
0

1000

2000

3000

4000

5000

σ (km)
100000%

B
% Increase in SN-Modularity

ing (SN-modularity) over iterations of the SNIC algorithm.
Recall that the SNIC algorithm decreases the distance constraint at each iteration. As the geographic constraint decreases, such that community proximity becomes more important, the quality of community (number of connections
within vs outside) increases. Here we introduce an axiom that as the geographic space of interaction for a social network shrinks, it is more likely that those left within the community are more connected. Spatial outliers, which are also
social outliers can be conceptualized as weak links (Granovetter 1973) and are removed through community proximity limiting iterations. Through 100 iterations, the quality of
community increases and in most social networks this value
may continue to increase given high enough spatial resolution data. In other words, humans form communities and interact mostly with those they are geographically near, such
that the strongest communities will be those shared within
small geographic proximities. However, we note that more
iterations of the SNIC algorithm will not result in singleton
communities, as that is the initial partition considered by the
algorithm. Also note that the improvement in SN-modularity
as a function of number of iterations of the SNIC heuristic
is also likely dependent on the parameter σ.

10000%

1000%

100%

10%

1%
0

0.002

1000

2000

3000

4000

5000

σ (km)
0.0018

Trials

Averages

0.0016
R² = 0.9573

SN Modularity

0.0014
0.0012
0.001
0.0008
0.0006
0.0004
0.0002
0
0

10

20

30

40

50

60

70

80

90

100

Figure 4: σ (in kilometers) vs. percent improvement in SNmodularity for the partition returned by the Louvain-SN
(panel A) and SNIC (panel B) algorithms. Not depicted in
panel A (Louvain-SN) are results where the Louvain-SN
algorithm produced lower-quality results than the standard
Louvain (due to the log-scale, see text for further details).3
Note that for the SNIC algorithm (panel B) outperformed
the standard Louvain on all trials.

Iterations of SNIC

Figure 3: SN-modularity vs. number of iterations for the partitions returned by the SNIC algorithms for the Britekite network data.
As with the example above in Figure 3, Figure 4 shows
that a stronger influence of geographic distance on community finding leads to greater quality communities based on
the SN-modularity measure. Recall that σ is the scaling parameter in SN-modularity. Decreasing the scaling parameter, in turn strengthening the geographic influence on the
equation, leads to an increase in the quality of communities identified by the SNIC algorithm. Increasing the σ value
will result in an asymptotic trend for SN-modularity toward
that expected from the non-spatial Louvain algorithm. This
trend is shown for the Brightkite network in percent increase
in SN-modularity over the Louvain algorithm for (A) the
Louvain-SN and (B) the SNIC algorithms.
The difference in Brightkite communities identified by the
Louvain and SNIC algorithms is clear in Figure 5. There is
a quantitative difference as suggested by the SN-modularity

metric results, but also a very qualitative difference in which
the communities identified by the SNIC algorithm are much
more spatially constrained. The bottom half of Figure 5 represents the SNIC algorithm results with σ = 1. In today’s
information age where global networks are common, methods to identify geograhically unconstrained communities, as
well as those methods that identify their geographically constrained counterparts are both equally valuable. Implications
for strength of ties, activity and operations spaces, and interactions are different when considering geographic network
characteristics.
Additionally, we also studied the NG-modularity of the
partition returned by the SNIC algorithm. We found that although the SNIC algorithm was not designed to maximize
NG-modularity, it still provided a positive value - which
indicates that there is a greater density of edges within
the communities as opposed to between communities (Figure 6). We also found that the solution returned by the NGmodularity of the partition returned by the SNIC algorithm
seems to approach the NG-modularity of the solution of the
Louvain algorithm as σ increases. Although this is not guar-

Figure 5: Top: Brightkite Communities identified using the
Louvain algorithm, Bottom: Communities identified using
the SNIC algorithm.
anteed theoretically, it should be expected based on the relationship between NG-modularity and SN-modularity shown
in Equation 6.
0.7

0.65

0.6

NG-Modularity

0.55

0.5

0.45

0.4

0.35

0.3

0.25
0

1000

2000

3000

4000

5000

6000

σ (km)

Figure 6: NG-modularity of the partition returned by the
SNIC algorithm (10 iterations) as a function of σ.

Applications
There are many fitting applications for algorithms that detect sociogeographic communities. In general, any network
that requires or benefits from geographic propinquity can
serve as a test case for the SNIC algorithm. For example,
the diffusion of a disease through a social network requires
geographic closeness, or face-to-face interaction, between

people. While much of the diffusion may not be social network based, but solely spatial, those that have stronger social
ties and in turn interact more in geographic space are more
likely to contract or spread a disease. This phenomenon exists at various levels of physical interaction for contagious
diseases. This model of diffusion works with the spread of
any biologically contagious, material, or even ideological
transfer that requires coincidence in space and time. The
following example shows the value of the SNIC algorithm
for sociogeographic analysis on a transnational terrorist network.
Figure 7 illustrates the difference between community finding results using both the Louvain (non-spatial)
and SNIC algorithms on a transnational terrorist network
dataset. The dataset used for this research is representative
of a global Islamist terrorist network from the late 1970s to
approximately 2010 (see (Medina and Hepner 2011) for a
full description and discussion of the dataset). The SNIC algorithm application shown here uses σ = 1600. The transnational Islamist terrorist network is a cellular based, decentralized structure and heavily dependent on relative location and proximity (Medina and Hepner 2013). Because
this is the case, identifying sociogeographic communities
requires only a small spatial component additional to the
social component. Applications of the SNIC algorithm on
other network structures may require more spatial influence
to identify sociogeographic communities. For example, the
Brightkite application shown in Figure 5 uses σ = 1. The
terrorist network is much smaller with 358 nodes and 660
edges, and is much more geographically based for operational necessity.
As stated previously, research results that identify social
closeness vs. those that identify sociogeographic closeness
are quantitatively and qualitatively different for many social
networks. The top graphic in Figure 7 shows the modularity results using the Louvain algorithm, which highlight the
transnational network connections. Many of the Islamist terrorist network cells have foundations or affiliates in Europe
and the Middle East. While the strength of social communities can be equal over long distances, especially if network connections were made at some point coincident in
space and time, it is beneficial to isolate communities in
geographic space for some applications. In this case, the
SNIC algorithm successfully identifies operational communities (A) the 9/11 cell planning and preparing for the attack in Southern California and Arizona, (B) a father and
son diad working with, specifically financing, al-Qaeda in
Canada, (C) a sociogeographic community of al-Qaeda tied
members in Montreal, Canada, some of which were plotting to attack Los Angeles International Airport in 1999, (D)
two al-Qaeda linked cells in Boston, MA with members in
the Boston sleeper cell and plotting a large scale bombing
attack in Jordan at multiple sites, (E) the al-Qaeda based
cell operating in New York responsible for the first World
Trade Center Attack in 1993, and (F) communities of 9/11
hijackers operating in Florida and other eastern US states.
The SNIC algorithm can be additionally adjusted to further
separate cellular communities based on geography (by varying σ and the number of iterations of the algorithm).

In systems such as this terrorist network, connected individuals that are close in geographic space, but not as close
socially, can be more important to identify when attempting
to counter operations. For example, identification of weaker
but closer social links, such as those providing materials to
a terrorist cell can be used as valuable intelligence to understand and dismantle terrorist operations in local to regional settings. Knowledge of international connections is
important for understanding the global terrorist system, and
cells in decentralized networks often maintain communications over long distances. However, many of these cells can
operate independently, though in most cases they will need
proximal resources. These local system interactions can be
detected through use of the SNIC algorithm.

manners that have potential to be applicable to the geospatial case - though to our knowledge no such application
has been presented in the literature. See (Yang et al. 2009;
Mucha et al. 2010) for examples.
There also exist many approaches for community detection in networks not based on modularity maximization. Examples use label propagation (Raghavan, Albert, and Kumara 2007), random walks (Rosvall and Bergstrom 2008),
or bottom-up voting approaches (Coscia et al. 2012). See
(Fortunato 2010) for comprehensive surveys. These do not
consider spatial interactions - leveraging these approaches
in a geospatial context is an important possibility for future
work.
Geospatial networks have been explored with respect
to problems other than community finding such as linkprediction (Larusso, Ruttenberg, and Singh 2012) and identifying user location (Abrol, Khan, and Thuraisingham
2012). There have also been several empricial studies on social networks with a spatial component such as (Barthélemy
2011; Cho, Myers, and Leskovec 2011; Eagle and Pentland
2006). More domain-specific empirical studies related to
this work are also prevalent in the literature. Pertinent to our
application are studies on terrorist networks (Medina and
Hepner 2011) and criminal co-offender networks (Schaefer
2012).

Conclusion

Figure 7: Top: Terrorist communities identified using the
Louvain algorithm, Bottom: Terrorist communities identified using the SNIC algorithm.

Related Work
Modularity maximization for community finding was first
introduced in (Newman and Girvan 2004). In (Blondel et
al. 2008), the Louvain algorithm is introduced, which can
scale to very large networks and is shown to provide partitions that nearly maximize modularity. We leverage a modification of the Louvain algorithm in this paper. Finding geographically disperse communities in a social network has
also been previously studied (Shakarian et al. 2013; Liu,
Murata, and Wakita 2012; Cerina et al. 2012; Expert et al.
2011). Our approach in this paper differs in that we desire to
find communities where the nodes are spatially-near and not
distant. In addition to the aforementioned approaches, community detection in networks has also been explored in other

In this work, we introduced spatially-near modularity - a
measure of the quality of a geographically-near partition
in a social network. Though finding an optimal partition
with respect to this measure is NP-hard, we were able
to obtain quality partitions with two heuristic algorithms
that we introduced in this paper and tested on real-world
datasets. We have also discussed various ways in which
our algorithms can be applied to gain useful knowledge in
counter-terrorism applications. Our immediate concern for
future work is exploring the scalability of this approach
(106 nodes and greater). Additionally, we are also pursuing
temporal dynamics of such communities and the differences
between the communities formed based on the current
state of the nodes (i.e. “work” vs “home”). In our more
practical research, we are also working to integrate the
generation of geographically-near partitions into our Organizational, Relationship, and Contact Analyzer (ORCA)
software (Paulo et al. 2013) that we are currently fielding to
several American law-enforcement agencies.
Acknowledgements. This work was supported by ARO
(project 2GDATXR042 and grant W911NF-08-1-0144),
AFOSR (grant FA9550-12-1-0021) and the Office of the
Secretary of Defense. The opinions in this paper are those
of the authors and do not necessarily reflect the opinions of
the funders, the U.S. Military Academy, or the U.S. Army.

References
[Abrol, Khan, and Thuraisingham 2012] Abrol, S.; Khan,
L.; and Thuraisingham, B. 2012. Tweeque: Spatio-temporal
analysis of social networks for location mining using graph

partitioning. In Proc. 2012 ASE Intl. Conf. on Social Informatics.
[Barthélemy 2011] Barthélemy, M. 2011. Spatial networks.
Physics Reports 499(1):1–101.
[Batty and Miller 2000] Batty, M., and Miller, H. J. 2000.
Representing and Visualizing Physical, Virtual and Hybrid
Information Spaces. In Janelle, D. G., and Lodge, D. C.,
eds., Information, Place, and Cyberspace: Issues in Accessibility. Springer. 133–146.
[Blondel et al. 2008] Blondel, V.; Guillaume, J.; Lambiotte,
R.; and Lefebvre, E. 2008. Fast unfolding of communities
in large networks. Journal of Statistical Mechanics: Theory
and Experiment 2008:P10008.
[Brandes et al. 2008] Brandes, U.; Delling, D.; Gaertler, M.;
Gorke, R.; Hoefer, M.; Nikoloski, Z.; and Wagner, D. 2008.
On modularity clustering. Knowledge and Data Engineering, IEEE Transactions on 20(2):172 –188.
[Cerina et al. 2012] Cerina, F.; Leo, V. D.; Barthelemy, M.;
and Chessa, A. 2012. Spatial correlations in attribute communities. PLoS One 7(5).
[Cho, Myers, and Leskovec 2011] Cho, E.; Myers, S. A.; and
Leskovec, J. 2011. Friendship and mobility: user movement in location-based social networks. In Proc. ACM KDD,
1082–1090. New York, NY, USA: ACM.
[Coscia et al. 2012] Coscia, M.; Rossetti, G.; Giannotti, F.;
and Pedreschi, D. 2012. Demon: a local-first discovery
method for overlapping communities. In Yang, Q.; Agarwal, D.; and Pei, J., eds., KDD, 615–623. ACM.
[Du et al. 2007] Du, N.; Wu, B.; Pei, X.; Wang, B.; and Xu,
L. 2007. Community detection in large-scale social networks. In Proc. 9th WebKDD and 1st SNA-KDD 2007 workshop on Web mining and social network analysis, 16–25.
ACM.
[Eagle and Pentland 2006] Eagle, N., and Pentland, A. 2006.
Reality mining: sensing complex social systems. Personal
and Ubiquitous Computing 10(4):255–268.
[Expert et al. 2011] Expert, P.; Evans, T. S.; Blondel, V. D.;
and Lambiotte, R. 2011. Uncovering space-independent
communities in spatial networks. PNAS 108(19):7663–
7668.
[Fortunato 2010] Fortunato, S. 2010. Community detection
in graphs. Physics Reports 486(3):75–174.
[Girvan and Newman 2002] Girvan, M., and Newman, M.
2002. Community structure in social and biological networks. PNAS 99(12):7821–7826.
[Granovetter 1973] Granovetter, M. S. 1973. The strength of
weak ties. American Journal of Sociology 78(6):1360–1380.
[Larusso, Ruttenberg, and Singh 2012] Larusso, N. D.; Ruttenberg, B. E.; and Singh, A. K. 2012. A latent parameter node-centric model for spatial networks. CoRR
abs/1210.4246.
[Liu, Murata, and Wakita 2012] Liu, X.; Murata, T.; and
Wakita, K. 2012. Extending modularity by incorporating
distance functions in the null model. CoRR abs/1210.4007.

[Lloyd 1982] Lloyd, S. 1982. Least squares quantization in
pcm. Information Theory, IEEE Transactions on 28(2):129–
137.
[MacQueen and others 1967] MacQueen, J., et al. 1967.
Some methods for classification and analysis of multivariate
observations. In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability, volume 1,
14. California, USA.
[McPherson, Smith-Lovin, and Cook 2001] McPherson, M.;
Smith-Lovin, L.; and Cook, J. M. 2001. Birds of a feather:
Homophily in social networks. Annual Review of Sociology
27:415–444.
[Medina and Hepner 2011] Medina, R. M., and Hepner, G. F.
2011. Advancing the understanding of sociospatial dependencies in terrorist networks. Transactions in GIS
15(5):577–597.
[Medina and Hepner 2013] Medina, R. M., and Hepner, G. F.
2013. The Geography of International Terrorism: An Introduction to Spaces and Places of Violent Non-State Groups.
CRC Press.
[Miller 2013] Miller, G. 2013. Activity-based intelligence
uses metadata to map adversary networks. Online publication. C4ISR Journal July 8.
[Mucha et al. 2010] Mucha, P. J.; Richardson, T.; Macon, K.;
Porter, M. A.; and Onnela, J.-P. 2010. Community structure
in time-dependent, multiscale, and multiplex networks. Science 328(5980):876–878.
[Newman and Girvan 2004] Newman, M. E. J., and Girvan,
M. 2004. Finding and evaluating community structure in
networks. Phys. Rev. E 69(2):026113.
[Newman 2004] Newman, M. E. J. 2004. Fast algorithm for
detecting community structure in networks. Phys. Rev. E
69(6):066133.
[Paulo et al. 2013] Paulo, D.; Fischl, B.; Markow, T.; Martin,
M.; and Shakarian, P. 2013. Social network intelligence
analysis to combat street gang violence. In Proc. 2013 Intl.
Symposium on Foundations of Open Source Intelligence and
Security Informatics (FOSINT-SI).
[Raghavan, Albert, and Kumara 2007] Raghavan, U. N.; Albert, R.; and Kumara, S. 2007. Near linear time algorithm to
detect community structures in large-scale networks. Physical Review E 76(3):036106.
[Rosvall and Bergstrom 2008] Rosvall, M., and Bergstrom,
C. T. 2008. Maps of random walks on complex networks
reveal community structure. Proceedings of the National
Academy of Sciences 105(4):1118–1123.
[Schaefer 2012] Schaefer, D. R. 2012. Youth co-offending
networks: An investigation of social and spatial effects. Social Networks 34(1):141 – 149.
[Shakarian et al. 2013] Shakarian, P.; Roos, P.; Callahan, D.;
and Kirk, C. 2013. Mining for geographically disperse communities in social networks by leveraging distance modularity. In Proc. 2013 ACM KDD.
[Tobler 1970] Tobler, W. 1970. A computer movie simulating urban growth in the Detroit region. Economic Geography 46(2):234–240.

[Yang et al. 2009] Yang, T.; Jin, R.; Chi, Y.; and Zhu, S.
2009. Combining link and content for community detection:
a discriminative approach. In Proc. ACM KDD, 927–936.
New York, NY, USA: ACM.

The Dragon and the Computer: Why Intellectual Property Theft is
Compatible with Chinese Cyber-Warfare Doctrine
Paulo Shakarian*, Jana Shakarian, Andrew Ruef

*Please direct correspondence on this article to paulo <at-symbol> Shakarian <dot> net or visit
http://shakarian.net
This is an excerpt from the upcoming book Introduction to Cyber-Warfare: A Multidisciplinary Approach
published by Syngress (ISBN: 978-0124078147). Used with permission.

Abstract: Along with the USA and Russia, China is often considered one of the leading cyberpowers in the world. In this excerpt, we explore how Chinese military thought, developed in the
1990’s, influenced their cyber-operations in the early 2000’s. In particular, we examine the ideas
of Unrestricted Warfare and Active Offense and discuss how they can permit for the theft of
intellectual property. We then specifically look at how the case study of Operation Aurora – a
cyber-operation directed against many major U.S. technology and defense firms, reflects some
of these ideas.

Over the past five years, the news media is seemingly littered with alleged Chinese cyberincidents. These activities have included instances of theft of guarded scientific data,1
monitoring of communication of the Dalai Lama,2 and theft of intellectual property from
Google.3 In a testimony to the Congressional Armed Services Committee, General Keith
Alexander, the commander of U.S. Cyber Command and head of the National Security Agency
(NSA), stated that China is stealing a “great deal” of military-related intellectual property from
the U.S.4 Clearly, cyber-espionage, which includes the theft of intellectual property, is already a
key component of Chinese cyber-strategy. The recently released report by the security firm
Mandiant provides technical analysis leading to the conclusion that an organization within the
People’s Liberation Army (Unit 61398) has been responsible for a great deal of cyber-espionage
against English-speaking countries.5 In this paper, we highlight some of the relevant Chinese
doctrine that we believe led to organizations like Unit 61398 and others.
The activities of exfiltration, monitoring, and theft of digital information described here
can be easily labeled as incidents of cyber-espionage. The apparent goal of this type of cyberoperation is not to take the computers offline or destroy the data that they contain but rather
to capture data of the opposing force. This being the case, such activities could not be labeled
as cyber-attacks, because the targeted systems and their data must remain intact in order to
obtain the desired data. Hence, we can define cyber-espionage as the act of obtaining access to
data from a computer system without the authorization of that system’s owner for intelligence
collection purposes.
However, like incidents of computer network attack, these incidents of cyber-espionage
too are notoriously difficult to attribute. What then, leads us to believe Chinese involvement in

the cyber-espionage incidents? If attribution is so difficult, then why do these actions cause
corporations like Google and Northrop Grumman, as well as high-level diplomats such as U.S.
Secretary of State Hilary Clinton to issue strong statements against the Chinese government in
the wake of such attacks? The issue lies in the origin of the incidents.6 Often computers
involved with the theft of digital information are traced back to networks that are located on
the Chinese mainland. Further, forensic analysis of malware from such incidents often indicates
the use of Chinese-language software development tools. Though it is virtually impossible to
implicate the government of the People’s Republic of China (PRC) in these cyber-espionage
actions, the fact that they can be consistently traced to the Chinese mainland raises serious
policy questions. Is the Chinese government conducting active investigations against the
hackers, and what legal actions are they taking once hackers are identified? Is the Chinese
government transparently sharing information of these supposed investigations with the
victims of the cyber-espionage? What legal actions is Beijing taking to prevent individual
hackers from attacking organizations outside of China? These questions must be given serious
consideration in the wake of attempted cyber-espionage to when there is evidence of Chinese
origin.
What would China have to gain by offering a permissive environment for hackers? It is
unlikely that the Chinese government - hallmarked by state monitoring7 - would not have the
resources to reduce such activity. It can further be expected that the fire drawn by the
international community is diplomatically undesirable. These activities provide key benefits to
the PRC. The nature of the stolen information – which ranges from details of American
weaponry and trade secrets to the communications of the Dalai Lama – are all of highly
particular interest to Beijing. Further, in the late 1990’s and early 2000’s several Chinese
military thinkers wrote on the topic cyber-warfare.8 These writings indicate that obtaining
unauthorized access to computer systems for the purpose of information exfiltration is an
integral part of Chinese cyber-strategy.
To understand Chinese doctrine, we must consider how that nation’s culture and
traditions have shaped their military thinking in ways vastly different from the West. In a SANS
paper,9 COL Edward Sobiesk highlights an example that illustrates the vast differences in
Western and Chinese thought that is noted in a 2002 Report to Congress on The Military Power
of the PRC by the US Secretary of Defense.10 This report identifies one of China’s strategic
objectives as maximizing “strategic configuration of power” called “shi.” In the report, a
footnote for “shi” states “There is no Western equivalent to the concept of ‘shi’. Chinese
linguists explain it as ‘the alignment of forces,’ the ‘propensity of things,’ or ‘potential born of
disposition,’ that only a skilled strategist can exploit to ensure victory over a superior force.”
Another interpretation of “shi” could focus on setting favorable conditions. If a nation state
attains a higher level of “shi” than a rival, the latter will be easily defeated when conflict does
arise, because any battle (if even necessary) will be conducted in conditions extremely
favorable to the first nation – as the first nation has already set favorable conditions through
the attainment of “shi”. By attaining a high-level of access to an adversary’s active computer
systems – the information stored on those systems has lost two critical aspects – confidentiality
and integrity.11 Confidentiality ensures that the information is not viewed by unauthorized

individuals, while integrity ensures that the information, once retrieved, was not tampered
with. Taking away these aspects of an adversary’s information can contribute greatly to setting
the conditions of the battlefield – perhaps even avoiding battle all-together. Considering “shi”
cyber-espionage appears to be a formidable strategic tool – by accessing the opponent’s
computer systems, the rival’s information advantage is reduced while the same is gained on the
initiating side.

From Active Defense to Active Offense
Traditionally, the People’s Liberation Army (PLA) was focused on the traditional Chinese
idea of “active defense” which refers to the idea of not initiating conflict, but being prepared to
respond to aggression.12 In a 2008 Military Review article, Timothy Thomas points out that the
late 1990’s and early 2000’s saw a shift from this mentality, particularly with regard to cyberwarfare. The paradigm that seemed to emerge at this time was “active offense.” Under this
new rubric, the idea of setting the conditions of the battlefield (i.e. developing “shi”) is still preeminent but the manner in which it is pursued takes a different turn. In the cyber-arena this
entails not only building one’s defenses to deter attack, but utilizing cyber-operations to obtain
the upper hand in the case of a larger conflict.
This idea of “active offense” is introduced in the 1999 book Information War by Zhu
Wenguan and Chen Taiyi. In this book, they include a section entitled “Conducting Camouflaged
Attacks” where pre-emption and active-offense are laid out.13 A key component of activeoffense is network surveillance which includes obtaining an understanding of an opponent’s
command and control (C2), electronic warfare (EW), and key weapon systems. In 2002 and
2003, General Dai Qingmin echoes some of these ideas.14 He stresses that it is necessary for
information and cyber operations to be both “precursory” (i.e. done before operations take
place) and “whole course” (performed throughout the operation). Where does cyber-espionage
fit into this schema? Pre-emption can take many forms. For instance, Russian hackers leveraged
denial of service cyber-attacks in the early phases of the Georgia campaign to hamper the
opposing force’s government, banking, and news media websites. However pre-emption can
take other, more subtle forms as well. For example, having constant access to the Tibetian
information systems would certainly be an advantage and would perhaps yield the possibility to
avoid open conflict altogether. Theft of military secrets relating to new weapon systems may
give the Chinese the technical intelligence (TECHINT) needed to find vulnerabilities, or even
develop their own copies of said weapons. Stealing intellectual property from software vendors
may give Chinese hackers a wealth of insight needed to identify new vulnerabilities for future
cyber-attack and cyber-espionage operations.
The work Information War and the writings of General Dai illustrate the importance of
the cyber-aspect to Chinese military operations. However, many of the cyber-espionage
incidents that we will discuss in this paper deal with theft of information from private
companies during peace-time. How is this accounted for in the Chinese literature on cyberwarfare? Answers to questions of this type seem to lay in the 1999 book Unrestricted Warfare

by PLA Colonels Qiao Liang and Wang Xiangsui.15 In this work, the authors assert that modern
warfare extends beyond simply a military domain. Modern warfare includes political, scientific,
and economic leaders in addition to military personnel. The notion of “unrestricted” warfare
extends not only the domains of war, but also the time at which such actions of war can take
place. “Military” operations –that now include information, economic, and psychological
aspects, can take place in peacetime in this perspective – further supporting the notion of
“active offense.” This may help explain why the early 21st century has been littered with stories
of Chinese cyber-espionage against corporations and scientific laboratories.
In this same vein, Colonel Wang Wei and Major Yang Zhen of the Nanjing Military
Academy’s Information Warfare and Command Department wrote in China Military Science
that in a war against an information-centric society, a nation’s political system, economic
potential, and strategic objectives will be high-value targets.16 They then go on to describe that
the preferred method to attack such a society would be through the use of asymmetric warfare
techniques. Asymmetric warfare refers to the ability of a combatant to defeat a superior force
by using tactics that exploit a major weakness in their weapon systems, tactics, or information
technology. In the America’s war in Iraq from 2003-2011, insurgent often used asymmetric
attacks such as road-side bombs as opposed to more traditional attacks that would otherwise
expose them to the superior firepower of the Americans. Colonel Wei and Major Zhen espouse
asymmetric attacks on a more strategic level – specifically calling for peacetime operations
which have military and economic goals. To achieve such goals, under “informatized
conditions” they state that both economic and trade warfare must be carried out.17 Clearly,
these authors were influenced by the earlier ideas of Unrestricted Warfare. It seems that the
peacetime cyber-espionage operations launched from the Chinese mainland against scientific,
military, and commercial targets align well with this line of thinking.
Another line of thought in Chinese writing to justify their seemingly bold moves in
cyber-space is that they believe these activities can be done with relative impunity. In a 2009
article in China Military Science, Senior Colonel Long Fangcheng and Senior Colonel Li Decai
state that cyber-operations directed against social, economic, and political targets can be done
without fear of such activities leading to large-scale military engagements.18 As such is the case,
they generally regard cyber-warfare as an element of soft-power – albeit one with great effects.
They then proceed to claim that the ultimate effect of this highly effective form of soft-power is
that the line between peacetime and wartime becomes blurred. This blurring may be a
hallmark of cyber-operations in general and might lead to the metaphorical endless war in the
near future.

INEW and Cyber in the PLA
The general information warfare (IW) strategy in use by the PLA is known as Integrated
Network Electronic Warfare (INEW).19 This strategy was originally outlined in a book by General
Dai Qingmin in 1999 known as On Information Warfare. This integration of cyber-operations to
traditional information warfare assets is a key component of the INEW strategy. INEW relies on

simultaneous application of both electronic warfare and cyber-operations to overwhelm an
adversary’s command, control, communication, computers, intelligence, surveillance, and
reconnaissance (C4ISR). Hence, the mission of key pieces of cyber-warfare (cyber-attack, cyberespionage, and cyber-defense) – are assigned to elements of the PLA General Staff traditionally
given similar roles in electronic warfare.
The General Staff of the PLA is divided into several departments. INEW generally assigns
offensive tasks (cyber-attack and more conventional electronic counter measures (ECM)) to the
4th Department – which has traditionally played a large role in offensive information warfare.20
Notably, General Dai Qingmin was promoted to the head of the 4th Department in 2000 –
perhaps an indication that the PLA intended to adopt his vision of INEW. Defensive and
intelligence tasks – specifically cyber-defense and cyber-espionage are assigned to the 3rd
Department – which traditionally focused on signal intelligence (SIGINT).21 It is thought that the
3rd Department is the headquarters for the Technical Reconnaissance Bureaus, whose normal
mission is SIGINT collection. In the late 1990’s several of these Bureaus received awards relating
to research in information warfare.22 Some analysts believe this indicates their role in cyberoperations.23
To augment the information warfare specialists in the 3rd and 4th GSD’s the Chinese have
also established information warfare militia units.24 These militias can be thought of as a “cyber
national guard” as they consist largely of personnel from the commercial information
technology (IT) and academia. Open-source reporting indicates that these units have been
created from 2003-2008 in Guangzhou, Tianjin, Henan, and Ningxia provinces.25 There is even
evidence that some of these militia received specific wartime tasks – most of which appear to
be focused on cyber-attack.26
The main ideas of Chinese cyber-operations grew out of the writings of PLA officers in
the late 1990’s and ultimately implemented in the INEW strategy, which aligns cyber-attack and
cyber-espionage responsibilities with organizations conducting similar operations in the realm
of electronic warfare.27 Though the Chinese hacker community came to prominence in the late
1990’s and early 2000’s with attacks that seemingly had goals congruent to the government,
the PRC ultimately disapproved of these actions.28 As a result, many of the hackers turned
“white hat” by either transforming their hacker groups into consulting firms or by obtaining
employment with the government and/or academia.29 Chinese academia also appears to be
highly involved with cyber-warfare – not only in research but also potentially with operations.30

A Case Study in Cyber War through Intellectual Property Theft: Operation
Aurora
On January 12th, 2010, Google announced shocking news. The firm published on its official blog
that it had been the victim of a cyber-warfare originating from China. According to the blog, the
purpose of the operation was to access the Gmail email-accounts of Chinese human rights
activists.31 As a result of this cyber-espionage operation, Google announced that it would no
longer censor results on its flagship search engine in China – google.cn – a move that caused

consternation with the PRC. The company stated that if they could not run their search engine
uncensored, they would be willing to close operations in China.
Literally minutes after the announcement from Google, Adobe - another major software
vendor - announced that their corporate systems had also been hacked.32 It turns out that both
Google and Adobe were targets of the same adversary – an adversary that conducted the very
same operation against thirty-two more companies. These firms included Dow Chemical,
Northrop Grumman, Symantec, and Yahoo.33 It seems the purpose of the operation was to
exfiltrate not only information about Chinese human rights activists, but intellectual property as
well – namely source code of commercially developed software.34
This operation – known as “Operation Aurora” - is the topic of this section. It leveraged
social engineering along with an advanced Trojan known as Hydraq to steal intellectual
property. Several analysts strongly suspect PRC involvement. Here we review the attack,
review the evidence of PRC involvement, and discuss the implications of intellectual property
theft from corporations.
This act of cyber-espionage employed a vulnerability in Microsoft Internet Explorer that
was exploited by software referred to as Trojan.Hydraq by the Security firm Symantec. As with
several of the cyber-espionage operations discussed in this paper, Operation Aurora was
initiated with spear phishing. In the case of the Google break-in, it is thought that this initial
spear phishing was directed at an employee using the Microsoft Messenger instant chat
software. The user supposedly received a link to a malicious website during one of his chat.35 It
is unknown, if the operations against the other firms were also initiated with chat software.
Based on similar operations it seems likely that email may have also been used as a way to
initiate the infiltration of the malicious software. Either way, the initial communication to these
firms had three characteristics. First, they were sent to a select group of individuals, which
suggests that this type of targeting (spear phishing) indicates that the hackers had some
additional source of intelligence on their targets. Second, the communications were engineered
in a way to appear as though they originated from a trusted source, which also shows that the
perpetrators were operating with profiles of their targets. Third, they all contained a link to a
website – clicking upon which initiated a certain series of events.
Once the user clicked on the link, their web browser would visit a site based out of
Taiwan. This website, in turn, executed malicious JavaScript code – this is source code that runs
on a website normally used to provide interactive features to the user. The malicious JavaScript
code exploited a weakness in the Microsoft Internet Explorer web browser that was largely
unknown at the time. Often such a new vulnerability is termed a “zero-day exploit”. The
malevolent JavaScript code proceeds to download a second piece of malware from Taiwan disguised as an image file. This secondary malicious software would proceed to run in Windows
and set up a back door allowing a cyber-spy access to the targeted system.36 A back door refers
to a method of accessing a system that allows an intruder to circumvent the normal security
mechanism. The use of a zero-day exploit is significant because identifying such a vulnerability
most likely required a skillful engineering effort. This, along with the highly-targeted spear-

phishing campaign (suggesting that the hackers had access to some additional intelligence on
their targets), might hint at the backing of a larger organization – possibly a nation-state.

Theft of Intellectual Property
Several months after Google announced that it had been hacked, the New York Times reported
that more than just email accounts of Chinese human rights activists had been compromised.
Citing an unnamed source with direct knowledge of the Google investigation, reporter John
Markoff wrote that the source code to Google’s state of the art password system had likely
been stolen during Operation Aurora.37 The system, known as Gaia, was designed to allow
users of Google’s software to use a single username and password to access the myriad of
Google services. This software is also known as “Single Sign-On.” Markoff reported that Google
addressed the problem by adding an additional layer of encryption to their password system.
The compromise of Gaia is significant for more than one reason. First, obtaining
software source code of a commercial system is intellectual property theft and thus unlawful in
the U.S. As with the data stolen during Titan Rain, the stolen source code could allow certain
developers to illicitly create software similar to Gaia. If we view Operation Aurora as the actions
of a nation state, theft of intellectual property can be thought of as a form of economic warfare
– leveling the technological playing field in order to reduce the advantage of an adversary
nation’s industrial capability. Clearly, this is in line with the Chinese ideas of Unrestricted
Warfare – where various forms of information warfare occur constantly (including during
peacetime) and attack all aspects of a nation’s power (including industry).
However, beyond the economic advantages gained by the theft of source code, major
security implications are also imminent – particularly in the case of Gaia. For instance, analysts
working with the hackers would most likely determine technical vulnerabilities in the password
system.
Though it is clear that the theft of intellectual property is an important consideration for
corporations, it also raises an important question. How were the attackers able to obtain
source code for a system such as Gaia by leveraging a relatively small number of compromised
computer systems? It turns out that many corporations work with specialized servers as storehouses for this type of data – often fittingly termed “intellectual property repositories.”
Centralized locations of this type of data make it easier for teams to work collaboratively on a
project and share information with each other. These systems often take the form of Software
Configuration Management (SCM) systems such as IBM Rationale© or content management
systems such as Microsoft SharePoint©.
Operation Aurora invalidated a key assumption made by many system administrators
and IP repository software vendors at the time. The professionals operating those networks
assumed that the intellectual property would not be accessed due to security countermeasures
taken to protect the network as a whole. The result of this perspective is a lesser focus on the

security of an IP repository lying within the perimeter of a corporation’s network. By utilizing a
zero-day vulnerability for their mission, the perpetrators behind Operation Aurora were able to
exploit this assumption.
Theft of intellectual property presents another key difficulty – determining what was
actually stolen. In the wake of Operation Aurora, security researcher George Kurtz wrote an
article entitled “Where’s the body?”38 As opposed to a physical theft where it is relatively easy
to determine what was stolen, with cyber-espionage and data-exfiltration this is much more
difficult to establish. Though systems administrators have a few tools at hand - such as the
examination of server logs and the analysis of network traffic - in advanced cyber-espionage
operations hackers often take various steps to cover-up their tracks and operate in a manner,
which makes it difficult to ascertain what data was stolen. Though security vendors provide
software solutions to help with this issue, determining “where’s the body” in the wake of a
cyber-espionage operation is still often a difficult task.

Indicators of PRC Involvement
It is interesting that Google’s announcement of the security breach seems to implicate Chinese
involvement – or suggests at least complacency on the side of the government. Here are some
indicators that Operation Aurora was executed with the full knowledge or even under the
directive of the Chinese government.
The earliest signs of Chinese involvement were made public in January 2010 – several
weeks after Google’s initial blog post. A report released by the security firm VeriSign stated that
the “source IP’s and drop server of the attack correspond to a single foreign entity consisting of
either agents of the Chinese state or proxies thereof.”39 The researchers at VeriSign also found
that the Aurora hackers used HomeLinux DynamicDNS and “borrowed” IP addresses from the
American firm Linode (a company specializing in Virtual Private Server Hosting). These are the
same circumstances as in a July 2009 DDoS attacks against South Korea and Washington, D.C.
When considered with other similarities, VeriSign researchers concluded that Aurora and the
attacks against Washington, D.C. and South Korea were possibly conducted by the same entity.
Just a few weeks later, New York Times reporters John Markoff and David Barboza
published an article which stated that investigators had identified two Chinese schools of higher
education involved in the attack40 - Shanghai Jiaotong University and the Lanxiang Vocational
School. The former’s Information Security Engineering Institute is the workplace of Peng Yinan
(alleged to be the Chinese hacker “CoolSwallow”). When New York Times reporters conducted
an anonymous telephone interview with a professor from that institute, they were surprised
with the candid response. He stated that students hacking into foreign computer networks
were “quite normal”.41 However, as an alternate explanation, the professor stated that the
university’s IP address could also have been hijacked which he said “frequently happens”.42
At the Lanxiang Vocational School, the investigators were able to identify a specific class taught
by a Ukrainian professor suspected to be involved in Operation Aurora.43 When confronted

with the suspicion, the dean of the computer science department there (identified in the media
only as Mr. Shao) stated that the students at the school simply would not have the ability to
carry out such an attack. However, he did acknowledge that students from the school were
often recruited into the military.44
The reports of Chinese involvement might have inspired U.S. Secretary of State Hillary
Clinton’s speech on Internet freedom given shortly after Google’s announcement.45 In this
speech she called upon China to perform a transparent investigation on the intrusions into
Google. This was perhaps the strongest statement by a high-ranking U.S. government official
made in response to a cyber-warfare incident at the time.
Operation Aurora illustrates the continued evolution of cyber-espionage in the early 21st
century. In this case of cyber-espionage the targeted information was deemed so important
that the operators utilized a zero-day exploit and spear-phishing to gain access to corporate
systems, locate the target’s intellectual property repositories, and steal company secrets.
Originally reported by Google, this operation affected over thirty big-name companies. The
stolen information was unlikely to only further economic gain, but is also feasibly beneficial for
technical intelligence, such as the evaluation of vulnerabilities – possibly for use in further
cyber-attacks. Operation Aurora invalidated existing assumptions about the security of
intellectual property repositories in corporations and again highlighted the difficulty of
determining the specifics of the captured data. The news media accounts of potential
involvement of China led to a diplomatic statement by the U.S. Secretary of State. Operation
Aurora is not unique. In its aftermath, there have been other Chinese-attributed cyber
maneuvers performed with the goal of stealing intellectual property. A series of events known
as Nitro46 (directed against the chemical industry) and Night Dragon47 (against the energy
sector) are but two examples. Finally, there are many potential second and third order effects
of a major software vendor such as Google or Adobe being hacked. It is unknown what
consequences the knowledge of potentially widely-used software, such as Google’s Gaia
password system, will have in follow-on cyber-operations. Though currently not connected to
Aurora, it was recently revealed that Adobe’s software certificate system was hacked – allowing
malicious software to create seemingly safe add-ons too many of that firm’s software.48 In this
case, a development server at Adobe was broken into. It is a clear example of how the cybersecurity of a major software vendor’s own systems can have a direct impact on an extremely
large population of users – hence potentially providing ample opportunities to an adversary
conducting follow-on cyber-attacks.
---Here we discussed several ideas espoused by China’s military thinkers on information
warfare – highlighting the ideas of Unrestricted Warfare – in which cyber operations are
thought to extend into peacetime and involves military, political, economic, and scientific
domains. We looked at how the Chinese structured their cyber-warriors around the INEW
strategy. In the PLA, cyber-operations were put under the responsibility of organizations with
similar missions in the realm of electronic warfare. Finally, we saw how some of these ideas

may have been put into practice with Operation Aurora where a zero-day exploit allowed
operators to steal intellectual property from repositories at Google, Adobe, and many other
major companies in late 2009.

Notes
1

Steve DeWeese, Bryan Krekel, George Bakos, Christopher Barnett, Capability of the People’s
Republic of China to Conduct of Cyber Warfare and Computer Network Exploitation, Northrop
Grumman, October 2009.
2

Information Warfare Monitor, Tracking Gh0stNet: Investigating a Cyber Espionage Network,
March, 2009.
3

Kim Zetter, “Google Hackers Targeted Source Code of More Than 30 Companies,” Wired
Threat Level, 13 Jan. 2010, accessed 8 Jan. 2012. Available at:
http://www.wired.com/threatlevel/2010/01/google-hack-attack/.
4

J. Nicholas Hoover.(2012, March, 27).NSA Chief: China behind RSA Attacks.InformationWeek.
Retrieved from:
http://www.informationweek.com/news/government/security/232700341?cid=RSSfeed_IWK_
All.
5

“APT1: Exposing One of China’s Cyber Espionage Units,” Mandiant. Retrieved from
http://intelreport.mandiant.com/.
6

Origin cannot only refer to the source-IP addressed (traced through intermediate proxies) but
also the origin of the software as determined by technical analysis of the code (i.e. the origin
based on the version of the compiler and the language of the operating system used to create
the software in question).
7

“Chinese Internet Giants Agree to Help Government Monitor Information,” Voice of America
News, 5 Nov., 2011, http://www.voanews.com/content/chinese-internet-giants-agree-to-helpgovernment-monitor-information-133327903/168182.html (accessed 25 Mar. 2013).
8

Timothy Thomas, “China’s Electronic Long-Range Reconnaissance,” Military Review,
November-December 2008, 47-54.
9

Edward Sobiesk, “Redefining the Role of Information Warfare in Chinese Strategy” SANS
Institute InfoSec Reading Room, March 2003,
http://www.sans.org/reading_room/whitepapers/warfare/redefining-role-informationwarfare-chinese-strategy_896 (accessed 22 December, 2011).
10

Office of the Secretary of Defense of the United States of America, Report to Congress on The
Military Power of the People’s Republic of China, 12 July 2002, 5-6.

11

W. V. Maconachy, Corey D. Schou, Daniel Ragsdale, Don Welch, “A Model for Information
Assurance: An Integrated Approach,” Proceedings of the 2001 IEEE Workshop on Information
Assurance and Security, June 2001,
http://it210web.groups.et.byu.net/lectures/MSRW%20Paper.pdf (accessed 22 December,
2011).
12

Timothy Thomas, “China’s Electronic Long-Range Reconnaissance,” Military Review,
November-December 2008, 47-54.
13

Ibid.

14

Ibid.

15

Sobiesk, 8.

16

Timothy Thomas, “Google Confronts China’s Three Warfares,” Parameters, Summer 2010,
101-105.
17

Wang Wei and Yang Zhen, “Recent Development in the Study of the Thought of People’s War
under Informatized Conditions,” China Military Science, 2d iss. 2009.
18

Long Fangcheng and Li Decai, “On the Relationship of Military Soft Power to Comprehensive
National Power and State Soft Power,” China Military Science, Issue 5, 2009, 120-29.
19

Steve DeWeese, Bryan Krekel, George Bakos, Christopher Barnett, Capability of the People’s
Republic of China to Conduct of Cyber Warfare and Computer Network Exploitation, Northrop
Grumman, October 2009.
20

Ibid.

21

Ibid.

22

Ibid.

23

Ibid.

24

Ibid.

25

Ibid.

26

Ibid.

27

Ibid.

28

Ibid.

29

Ibid.

30

Ibid.

31

David Drummond, “A new approach to China,” The Official Google Blog, 12 Jan. 2010.
Accessed 8 Jan. 2012. Available at: http://googleblog.blogspot.com/2010/01/new-approach-tochina.html.
32

Pooja Prasad, “Adobe Investigates Corporate Network Security Issue,” Adobe Featured Blogs,
12 Jan. 2010. Accessed 8 Jan. 2012. Available at:
http://blogs.adobe.com/conversations/2010/01/adobe_investigates_corporate_n.html.
33

Kelly Jackson Higgins, “More Victims Of Chinese Hacking Attacks Come Forward,” Dark
Reading, 14 Jan. 2010, accessed 8 Jan. 2012. Available at
http://www.darkreading.com/security/attacks-breaches/222301032/index.html.
34

Kim Zetter, “Google Hackers Targeted Source Code of More Than 30 Companies,” Wired
Threat Level, 13 Jan. 2010, accessed 8 Jan. 2012. Available at:
http://www.wired.com/threatlevel/2010/01/google-hack-attack/.
35

John Markoff, “Cyberattack on Google Said to Hit Password System,” New York Times, 19
April, 2010. Available from http://www.nytimes.com/2010/04/20/technology/20google.html,
accessed 15 Jan., 2012.
36

McAfee Labs and McAfee Foundation Professional Service, “Protecting Your Critical Assets:
Lessons Learned from Operation Aurora,” McAfee White Paper, 2010.
37John

Markoff, “Cyberattack on Google Said to Hit Password System,” New York Times, 19
April, 2010. Available from http://www.nytimes.com/2010/04/20/technology/20google.html,
accessed 15 Jan., 2012.
38

George Kurtz, “Where’s the body,” McAfee Blog Central, Jan. 25, 2010. Available from:
http://siblog.mcafee.com/cto/where%E2%80%99s-the-body/, accessed 15 Jan. 2012.
39

VeriSign iDefense Security Lab report quoted by Ryan Paul, “Researchers identify command
servers behind Google attack,” ArsTechnica, January 2010. Available from:
http://arstechnica.com/security/news/2010/01/researchers-identify-command-servers-behindgoogle-attack.ars, accessed 15 Jan. 2012.

40

John Markoff and David Barboza, “Two Chinese Schools Said to be Tied to Online Attacks,”
New York Times, Feb. 19, 2010.
41

Ibid.

42

Ibid.

43

As of the time of this writing, the extent of the involvement of the class and the name of the
Ukranian professor appear unavailable in open-source reporting.
44

Ibid.

45

Hillary Rodham Clinton, “Remarks on Internet Freedom,” U.S. Department of State, 21 Jan.
2010. Available at http://www.state.gov/secretary/rm/2010/01/135519.htm, accessed 15 Jan.
2010.
46

Eric Chien, Gavin O’Gorman, “The Nitro Attacks, Stealing Secrets from the Chemical Industry,”
Symantec Security Response, 2011.
47

“Global Energy Cyberattacks: ‘Night Dragon,’” McAffe White Paper, 10 Feb. 2011.

48

Lucian Constantin, “Hackers Compromise Adobe Server, Use it to Digitally Sign Malicious
Files,” CIO, 27 Sep. 2012, available at:
http://www.cio.com/article/717494/Hackers_Compromise_Adobe_Server_Use_it_to_Digitally_
Sign_Malicious_Files. Accessed 14 Oct. 2012.

The opinions in this excerpt are those of the authors and do not necessarily reflect the opinions
of the U.S. Department of Defense, the U.S. Army, or the U.S. Military Academy.

Modeling cyber-attacks on Industrial Control
Systems
Vivin Paliath

Paulo Shakarian

Arizona State University
vivin.paliath@asu.edu

Arizona State University
shak@asu.edu

Abstract—Despite the prevalence of markets for malware and
exploits and their potential threat to industrial control systems
(ICS), existing paradigms for modeling of such cyber-adversarial
behavior do not account for the complex nature of ICS systems
consisting of multiple interconnected components. This paper
takes the first steps toward addressing this need. Here, we introduce a framework that allows for modeling of ICS systems with
highly interconnected components and study this model through
the lens of lattice theory. We then turn our attention to the
problem of determining the optimal/most dangerous for a cyberadversary with respect to this model and find it to be an NPComplete problem. To address this complexity, we utilize an A*based approach and develop admissible heuristics. We provide an
implementation and show through a suite of experiments using
both simulated and actual vulnerability data that this method
performs well in practice for identifying adversarial courses of
action in this domain.
Index Terms—Adversarial modeling, Cybersecurity

I. I NTRODUCTION
Contemporary cyber-threat actors rely on a variety of malware and exploits purchased through various channels such as
the darkweb [1], in order to carry out their attacks. The trend
toward automation of industrial control systems (ICS) toward
“smart” utilities have made understanding such adversarialbehavior directed against ICS, a priority. For instance, code
from the infamous Stuxnet [2] attack against Iranian nuclear
facilities is available for public download 1 . The Stuxnet
case is also informative as it illustrates the complex nature
of industrial control systems which consist of interconnected
components. For example, when Stuxnet infected Siemens
S7-300 PLCs by exploiting various zero-day exploits on
the Windows operating-system, it gained the ability to send
commands to modify the rotational-frequency of motors that
operated nuclear-centrifuges, and also gained the ability to
hide its behavior from operators [3].
However, despite the prevalence of markets for malware and
exploits, and their potential threat to ICS, existing paradigms
for the modeling of such cyber-adversary behavior [4] do
not account for the complex nature of ICS systems consisting of multiple interconnected components. We introduce a
framework that allows for modeling of ICS systems with
highly-interconnected components study this model through
the lens of lattice theory [5]. We then turn our attention to
the problem of determining the optimal/most dangerous for a
1 https://archive.org/details/Stuxnet

978-1-5090-3865-7/16/$31.00 ©2016 IEEE

cyber-adversary with respect to this model and find it to be an
NP-Complete problem. We then present a suite of algorithms
to this problem based on A* search and introduce provablycorrect algorithms. We demonstrate the performance of these
algorithms by implementing them and performing a suite of
experiments using both simulated and actual vulnerability data.
II. M ODEL AND P ROPERTIES
ICS components are networked [6], and any publiclyaccessible component, or a component reachable through one,
is potentially vulnerable to attack. If the attacker was to
compromise one of these devices, they could take control of
that device or even disable it completely, for example, by a
denial-of-service attack against it. Even if the system employs
privilege-checks or authentication mechanisms, it is possible
for attackers to escalate their privileges through certain kinds
of attacks, giving them access to privileged-commands. In this
section, we define a formal mathematical-model to capture this
behavior.
We first define a set V , which is the set of all vulnerabilities,
and a set C, which is the set of capabilities supported by a
component on the ICS network. The set 2C is the powerset of
C.
Right away, we notice the following property:
Observation 2.1. h⊆, 2C i is a partial ordering and 2C specifies a complete lattice.
This is straightforward as ⊆ is clearly reflexive, transitive,
and antisymmetric. Further, the set 2C has a clear top element
(set C) and a bottom element (the empty set). As C is simply a
set of elements, the powerset as under the ordering relationship
specified by ⊆ is the classic example of a complete lattice.
To exploit a system, an attacker sends a command or tries
to leverage a capability associated with some vulnerability
on the system. However, attackers usually have incomplete
information about system vulnerabilities. By profiling a system
through various methods, they can identify some set of vulnerabilities that exist, though not necessarily all vulnerabilities
on the system. That said, it is still possible for attackers to use
additional commands or capabilities to expose vulnerabilities
outside the set of initial, known vulnerabilities. We model this
through the following function:
Definition 2.1. We define expose : 2C → 2V as a function that
satisfies the following axioms:

316

1) If C1 ⊆ C2 then expose(C1 ) ⊆ expose(C2 )
2) expose(∅) 6≡ ∅
The intuition behind the first axiom is that access to
additional capabilities can allow the attacker to expose more
vulnerabilities; it can never result in the attacker concealing
a previously-exposed vulnerability, and at worst they end up
with the same set of exposed vulnerabilities as before.
The intuition behind the second axiom is that it is possible
for attackers to have prior information about existing vulnerabilities on a system. Hence, it follows from our definition
that expose(C) is the complete set of vulnerabilities that exist
on this system, and expose(∅) is the set of initial, known
vulnerabilities.
The end goal of the attacker is to gain capabilities by using
exploits against the system they are attacking. These capabilities include access to local commands on the system, as well
as those that can be used to exploit specific-vulnerabilities
(for example, sending malformed data to cause a denial-ofservice attack). To model this behavior, we first define the set
of exploits E as follows:
Definition 2.2. Given a set C1 of capabilities that the attacker
has already gained so far, and a set C2 of capabilities gained
by exploiting vulnerability v, the set of exploits E is a set of
tuples of the form hC1 , C2 , vi.
For some set of exploits E 0 ⊆ E available to the attacker,
we now define the operator TE 0 : 2C → 2C as follows:
Definition 2.3. Given E 0 ⊆ E and C 0 ∈ 2C we define the
operator TE 0 : 2C → 2C as:
[
TE 0 (C 0 ) = C 0 ∪ {C2 | hC1 , C2 , vi ∈ E 0 ∧
C1 ⊆ C 0 ∧
v ∈ expose(C 0 )}
An attacker can progressively gain more capabilities as he
uses his set of exploits against the system. We can model this
through repeated applications of TE 0 , defined as follows:
Definition 2.4. Given some i ∈ Z where i > 0, we define i
applications of TE 0 on C 0 ⊆ C as:
TE 0 ↑i (C 0 ) = TE 0 (TE 0 ↑i−1 (C 0 ))
where TE 0 ↑0 (C 0 ) = TE 0 (C 0 )
Using the definition of the repeated application of TE 0 , we
can define its fixed point as follows:
Definition 2.5. T∗E 0 , the fixed point of TE 0 is defined as:
T∗E 0 (C 0 ) = TE 0 ↑i (C 0 ) where:
TE 0 ↑i (C 0 ) = TE 0 ↑i+1 (C 0 )
We will now prove that this fixed point exists.
T HEOREM 2.1. T∗E 0 has a least fixed point.
An attacker uses a set of exploits to gain capabilities on the
system, and must do so within a budget. But first, we need a
way to calculate the cost associated with a set of exploits:

Definition 2.6. Given a set of exploits E, we define a cost
function cost : E → R+ that associates a real-valued cost
with each exploit.
For simplicity, we will use a single cost-function throughout
this paper. However, all of the results can be extended for
separate cost-functions for the attacker. Also, throughout this
paper, we will use a unit cost-function, where for each e ∈ E,
cost(e) = 1. In ongoing work, we are currently looking at
data-driven cost functions [4], and our theoretical results do
not depend on the use of the unit cost-function. Having defined
the cost function, we can now formally define the attacker’s
preferred strategy:
Definition 2.7. Given the attacker’s budget c ∈ R+ , set of
desired capabilities C 0 , and initial set of capabilities C 00 , the
preferred attack-strategy is the set of exploits E 0 satisfying
the following conditions:
∗
00
0
• TE 0 (C ) ⊇ C
P
•
e∈E 0 cost(e) ≤ c
PIn the optimization variant of this problem, the quantity
e∈E 0 cost(e) is minimized, and the associated strategy is
called the optimal strategy.
We examine the computational complexity of solving the
preferred attack-strategy problem and show that the finding
such a strategy is NP-complete.
T HEOREM 2.2. Finding a preferred attack-strategy is NP-complete
III. A LGORITHMIC A PPROACH AND E XPERIMENTS
In this section we examine several algorithms to solve
the preferred attack-strategy problem. We first examined a
standard DFS approach that performs a depth-first search
across the strategy-space. It is immediately evident that this
approach has shortcomings; we are not guaranteed to find an
optimal solution, and we have exponential-time complexity.
Given that both the branching-factor of the search-tree and
the maximum number of exploits that can be used is |E|, time
|E|
2
and space complexity are O(|E| ) and O(|E| ) respectively.
Regardless of these shortcomings, DFS can be used as an
anytime algorithm and is guaranteed to return a solution,
though not necessarily optimal. To address this problem, we
prune non-viable subtrees by discarding exploits that cannot be
part of a solution. When expanding a node, pruning determines
the viability of a subtree corresponding to an available exploit
by ensuring that following conditions hold:
1) The cost of the exploit does not cause the attacker to
exceed their budget.
2) The attacker has the required set of capabilities to apply
the exploit.
3) The exploit offers capabilities that the attacker does not
already have.
If these three conditions hold, the exploit is included. Otherwise, the corresponding subtree is pruned. The correctness
of this pruning technique follows directly from our original
model.

317

We obtain further improvement by adopting A* search. With
an admissible heuristic-function, the tree-search variant of A∗
is both complete and optimal. A sensible heuristic would be
to select an applicable exploit that is both inexpensive, and
gives us the desired set of capabilities we want. A∗ evaluates
nodes by combining g(e), the cost to reach the node, and h(e),
the lower bound of the cost to get from the node to the goal.
We have to define a few other things before formally defining
h(e), namely the remaining set of commands and exploits.
For the initial set of capabilities C 00 , current set of exploits
and capabilities (E 0 , C 0 ), the overall set of exploits E, and
exploit under consideration e = hC1 , C2 , vi, we define the
following:
0

Crem = C \

T∗E 0 (C 00 )

TABLE I
C OMPARISON OF RUNTIME AND EFFECTIVE BRANCHING - FACTOR FOR
SOLUTION DEPTHS 1 THROUGH 10 FOR ALL ALGORITHMS
Budget
1
2
3
4
5
6
7
8
9
10

\ C2

Algorithm
A∗ with h2
A∗ with h1
DFS-P RUNED
DFS

C1 ⊆ T∗E 0 (C 00 ) ∧ C2 ∩ Crem 6= ∅}

c∈Crem

where e0 = hC1 , C2 , vi
We can show that both heuristics are admissible, ensuring
completeness and optimality of A* search.
T HEOREM 3.1. h1 (e) is admissible
T HEOREM 3.2. h2 (e) is admissible
We performed two experiments: one with simulated data to
evaluate the performance of the algorithms at various solutiondepths, and the other to evaluate the general performance
against actual CVE data NIST NVD. We randomly generated
a sets of exploits and desired-capabilities out of actual CVE
data, that would guarantee a solution at a particular depth for
the first experiment. For the second, we used a subset of CVE
data that we gathered from NIST NVD. We use the unit-cost
function in these trials.
We examined DFS, pruning, and both A* variants against
problems with solution depths 1 through 10 (see Table I).
By using the unit cost-function, the solution-depth ends up
equal to the attacker’s budget. We used the same set of
1,139 exploits in each of the problem instances and capped
maximum execution-time at one hour. Performance and effective branching-factor improved across DFS, pruning and
both A* variants, with the best overall-performance being
seen in A* with h2 . h2 significantly outperformed h1 , with
a lower effective branching-factor and runtime. With solution
depths greater than 6, A* with h1 failed to complete within
an hour, whereas A* with h2 was not affected significantly.
This suggests that h2 makes an excellent heuristic to direct
the search.
In our second experiment, we used 458 exploits generated
out of CVE data gathered from NIST NVD, with the attacker

A* using h1
Runtime
b*
16ms
7.416
128ms
6.028
228ms
5.987
232ms
4.179
38.425s 7.209
1m20s
5.978
–
–
–
–
–
–
–
–

DFS-Pruned
Runtime
b*
35ms
7.416
226ns
12.203
4.6s
15.259
30m
28.143
–
–
–
–
–
–
–
–
–
–
–
–

DFS
Runtime
b*
32ms
33.749
346ms
50.190
7m17s
133.456
–
–
–
–
–
–
–
–
–
–
–
–
–
–

TABLE II
C OMPARISON OF RUNTIME AND EFFECTIVE BRANCHING - FACTOR ON A
SUBSET OF NIST NVD DATA FOR ALL ALGORITHMS

Erem = {hC1 , C2 , vi | hC1 , C2 , vi ∈ E \ E 0 \ {e}∧
We will now define two heuristics for the exploit e under
consideration:
cost(e0 )
h1 (e) = 0 min
× |Crem |
e ∈Erem |C2 ∩ Crem |
X
cost(e0 )
h2 (e) =
min
{e0 ∈Erem |c∈C2 } |C2 ∩ Crem |

A* using h2
Runtime
b*
44ms
7.416
43ms
6.028
175ms
4.649
365ms
4.179
650ms
3.69
707ms
3.09
2.518s
3.122
6.819s
3.016
6.206s
2.684
28.894s 2.789

Runtime
13.634s
8m30s
4.468s
2m23s

b*
5.018
10.220
5.501
13.522

budget set at 4 (see Table II). Results were as expected, except
when pruning. Here, runtimes seem better than A* due to an
artifact of the data; a large number of exploits from NIST NVD
data had no required capabilities. If the pruning algorithm
chooses a subtree from the root that offers a quick path to the
solution, it can outperform A*. Generally, A* still performs
better as can be seen from the effective branching-factor for
both algorithms. Something similar happens when comparing
DFS to A* with h1 . In this case DFS has a significantly-lower
runtime, but its branching factor is around 13.5, compared to
10 for A* with h1 .
IV. C ONCLUSION
In future work we plan to examine the problem from the
defender’s perspective. Specifically, we aim to identify the set
of vulnerabilities a defender must patch in order to deny the
attacker a specific set of capabilities.
V. ACKNOWLEDGMENTS
This work was supported by ASU Global Security Initiative
(GSI) and the Office of Naval Research (ONR) Neptune
program.
R EFERENCES
[1] P. Shakarian and J. Shakarian, “Considerations for the development of
threat prediction in the cyber domain,” in AAAI-16 Workshop on Artificial
Intelligence for Cyber Security, 2016.
[2] P. Shakarian, “Stuxnet: Cyberwar revolution in military affairs,” Small
Wars Journal, April 2011.
[3] N. Falliere, L. O. Murchu, and E. Chien, “W32. stuxnet dossier,” White
paper, Symantec Corp., Security Response, vol. 5, 2011.
[4] J. J. Robertson, V. Paliath, J. Shakarian, A. Thart, and P. Shakarian, “Data
driven game theoretic cyber threat mitigation,” Innovative Applications of
Artificial Intelligence, vol. 28, 2016.
[5] B. Knaster and A. Tarski, “Un théoreme sur les fonctions densembles,”
Ann. Soc. Polon. Math, vol. 6, no. 133, p. 2013134, 1928.
[6] L. Stouffer, V. Pilitteri, S. Lightman, M. Abrams, and A. Hahn. (2015)
Guide to industrial control systems (ICS) security. [Online]. Available:
http://dx.doi.org/10.6028/NIST.SP.800-82r2

318

arXiv:1607.02171v1 [cs.AI] 7 Jul 2016

Argumentation Models for Cyber Attribution
Eric Nunes, Paulo Shakarian

Gerardo I. Simari

Andrew Ruef

Arizona State University
Tempe, AZ 85281, USA
Email: {enunes1, shak} @asu.edu

Inst. for CS and Eng. (CONICET–UNS)
DCIC, UNS, Bahia Blanca, Argentina
Email: gis@cs.uns.edu.ar

Trail of Bits, Inc.
New York, NY 10003, USA
Email: andrew@trailofbits.com

Abstract—A major challenge in cyber-threat analysis is combining information from different sources to find the person or
the group responsible for the cyber-attack. It is one of the most
important technical and policy challenges in cyber-security. The
lack of ground truth for an individual responsible for an attack
has limited previous studies. In this paper, we take a first step
towards overcoming this limitation by building a dataset from
the capture-the-flag event held at DEFCON, and propose an
argumentation model based on a formal reasoning framework
called DeLP (Defeasible Logic Programming) designed to aid
an analyst in attributing a cyber-attack. We build models from
latent variables to reduce the search space of culprits (attackers),
and show that this reduction significantly improves the performance of classification-based approaches from 37% to 62% in
identifying the attacker.

I. I NTRODUCTION
A major challenge in cyber-threat analysis is to find the
person or the group responsible for a cyber-attack. This is
known as cyber-attribution [17] and it is one of the central
technical and policy challenges in cyber-security. Oftentimes,
the evidence collected from multiple sources provides a contradictory viewpoint. This gets worse in cases of deception
where either an attacker plants false evidence or the evidence
points to multiple actors, leading to uncertainty. In the text
on cyber-warfare [17] the authors discuss the difficulties that
an intelligence analyst faces in attributing an attack to a
perpetrator given that deception might have occurred, and how
the analyst needs to explore deception hypotheses under the
given attack scenario.
However, one of the major drawbacks of the study and
evaluation of cyber-attribution models is the lack of datasets
with the ground truth available regarding the individual party
responsible for the attack—this has limited previous studies.
To overcome this, we built and leveraged a dataset from the
capture-the-flag event held at DEFCON. In previous work,
this dataset was used to study cyber-attribution, framing it
as a multi-label classification problem to predict the attacker [13]. Machine learning approaches struggle in situations
of deception, where similar attributes point towards multiple
attackers—we propose to address this issue using a formal
logical framework.
Specific contributions of this paper include:
•

description of how a model for cyber-attribution can
be designed and implemented in the DeLP structured
argumentation framework;

•

•

experiments demonstrating that using argumentationbased tools can significantly reduce the number of potential culprits that need to be considered in the analysis
of a cyber-attack; and
experiments showing that the reduced set of culprits,
used in conjunction with classification, leads to improved
cyber-attribution decisions.

Related work: Adversarial machine learning is an emerging
field of study. It uses effective machine learning techniques to
identify or defend against an adversary’s opponents. Understanding the limits of adversary’s knowledge and capabilities
is crucial for coming up with countermeasures, as discussed
in [9]. Here the authors propose models to study these limitations to come up with evasion techniques. On the contrary,
Lowd and Meek [12] explore the problem from an adversarial
point of view. They propose strategies that an adversary can
use to reverse engineer a classifier so that his attacks are
undetected by the classifier. They use a real world application
in spam filtering to demonstrate their method, which they call
adversarial classifier evasion. In a spam filtering setting an
example of such a technique is replacing feature words that
raise a red flag with their synonyms to evade detection. This
feature cross substitution technique is discussed in [10]. Here
the authors offer a simple heuristic method based on mixedinteger linear programming with constraint generation to make
the classifier robust to cross substitution techniques. There is
research that looks at modeling the interaction between the
learner (adversary) and the classifier in terms of a competition
using Stackelberg games [4], [3]. Most adversarial machine
learning applications deal with modeling classifiers to be robust against evasive techniques in real world applications like
malware detection and spam filtering. Cyber-attribution falls in
the domain of adversarial learning, but looks at analyzing the
evidence in the aftermath of an attack to discover the attacker.
Currently, cyber-attribution is limited to identifying machines [2] as opposed to the hacker or their affiliation to a
group or a state. An example of such a technical attribution
approach is WOMBAT [5], where a clustering technique is
used to group attacks to common IP sources. A method that
combines information from different sources was proposed by
Walls [22], who considered forensic information from diverse
sources but did not account for inconsistency or uncertainty
due to deception. A less rigorous mathematical model, known
as the Q model [15], was proposed recently; the model answers

queries from an analyst, and by combining these answers the
analyst attributes an attack to a party. Unfortunately, there
are no experimental evaluations of its effectiveness. Argumentation has been used for cyber reasoning [1] by leveraging
arguments to deal with incomplete and contradictory data,
allowing to derive big-picture conclusions to keep systems
secure and online in case of an attack. This is a different
application than the one we are addressing.
In [20], a tool was presented to support human decisions, focusing on how user trust in the evidence influences
the process; a user study demonstrating the hypotheses was
presented in [16]. Concurrently, a formal logical framework
for reasoning about cyber-attribution has been devised [18],
[19]; it explores multiple competing hypotheses based on the
evidence for and against a particular attacker to help analysts
decide on an attribution, providing a map of the reasoning that
led to the decision.
The rest of the paper is organized as follows. We present
a description of our DEFCON capture-the-flag dataset and an
analysis on the occurrence of deception within this data in
Section II. This is followed by the argumentative model based
on [8] in Section III. We then summarize results from [13] and
discuss how we built our baseline argumentation model along
with two other extended baseline models for cyber-attribution
with DeLP in Section V and Section VI, with a discussion of
the experimental results obtained with each of these models.
Conclusions are discussed in Section VII.
II. DEFCON CTF DATASET
The DEFCON security conference sponsors and hosts a
capture the flag (CTF) competition every year, held on site
with the conference in Las Vegas, Nevada. DEFCON CTF is
one of the oldest and best-known competitions. The ctftime.org
site provides a ranking for CTF teams and CTF competitions,
and in this system DEFCON CTF has the highest average
weight of all other CTF competitions.
CTF competitions can be categorized by what role the
competitors play in the competition: either red team, blue
team, or a combination. In a blue team focused CTF the
competitors harden their systems against a red team played
by the organizers of the CTF. In a combined red/blue team
CTF every team plays both blue and red team simultaneously.
The NCCDC and CDX competitions are examples of a blue
team CTF, while DEFCON CTF is a combined red/blue team.
Each team is simultaneously responsible for hardening and
defending their systems as well as identifying vulnerabilities
and exploiting them in other teams’ systems.
The game environment is created primarily by the DEFCON
CTF organizers. The game focuses around programs (known in
the game as services) written by the organizers. These services
are engineered to contain specific vulnerabilities. The binary
image of the service is made available to each team at the
start of the game, but no other information about the service
is released. Part of the challenge of the game is identifying the
purpose of each service as well as the vulnerabilities present
in the service. Identification of vulnerabilities serves both a

defensive and offensive goal. Once a vulnerability has been
identified, a team may patch this vulnerability in the binary
program. Additionally, the teams may create exploits for that
vulnerability and use them to attack other teams and capture
digital flags from those teams’ systems.
Each team is also provided with a server running the
services, which contains the digital flags to be defended. To
deter defensive actions such as powering off the server or
stopping the services, the white team (a third team, played
by the organizers) conducts periodic availability tests of the
services running on each team’s server. A team’s score is the
sum of the value of the flags they have captured, minus the sum
of the flags that have been captured from that team, multiplied
by an availability score determined by how often the white
team was able to test that team’s services. This scoring model
incentivizes teams to keep their server online, identify the
vulnerabilities in services and patch them quickly, and exploit
other teams services to capture their flags. It disincentivizes
teams’ from performing host-level blocking and shutting down
services, as this massively impacts their final score.
This game environment can be viewed as a microcosm of
the global Internet and the careful game of cat and mouse
between hacking groups and companies. Teams are free to use
different technical means to discover vulnerabilities. They may
use fuzzing and reverse engineering on their own programs,
or, they may monitor the network data sent to their services
and dynamically study the effects that network data has on
unpatched services. If a team discovers a vulnerability and uses
it against another team, the first team may discover that their
exploit is re-purposed and used against them within minutes.
The organizers of DEFCON CTF capture all of the network
traffic sent and received by each team, and publish this traffic
at the end of the competition [6]. This includes IP addresses
for source and destination, as well as the full data sent and
received and the time the data was sent or received. This data
is not available to contestants; depending on the organizers’
choice from year to year, the contestants either have a real time
feed but with the IP address obscured, or a full feed delivered
on a time delay of minutes to hours.
Analysis: We use the data from the CTF tournament held at
DEFCON 21 in 2013. The CTF data set is very large, about
170 GB in compressed format. We used multiple systems
with distributed and coordinated processing to analyze the
entire dataset—fortunately, analyzing individual streams is
easy to parallelize. To analyze this data, we identified the
TCP ports associated with each vulnerable service. From
this information, we used the open source tool tcpflow to
process the network captures into a set of files, with each file
representing data sent or received on a particular connection.
With these data files identified, we analyzed some of them
by hand using the Interactive Disassembler (IDA) to determine
if the data contained shell-code, which in fact was the case. We
used an automated tool to produce a summary of each data
file as a JSON encoded element. Included in this summary
was a hash of the contents of the file and a histogram of the
processor instructions contained in the file. These JSON files

TABLE 1: Fields in an instance of network attack
Field

Intuition

Value

byte hist

Histogram of byte sequences
in the payload

0×43:245, 0×69:8,
0×3a:9, .....

inst hist

Histogram of instructions
used in the payload

cmp:12,
subs:8,
movtmi:60 ......

from team

The team where the payload
originates (attacking team)

Blue Lotus

to team

The team being attacked by
the exploit

Robot Mafia

time

Indicates the date and time of
the attack

2013-08-03T23:45:17

were the final output of the low-level analysis, transforming
hundreds of gigabytes of network traffic into a manageable set
of facts about exploit traffic in the data. Each JSON file is a list
of tuples (time-stamp, byte-histogram, instruction-histogram,
attack team and target team). The individual fields of the tuple
are listed in Table 1.
The pre-processing can be summarized in the following
steps:
• Un-tarring the archives available from the organizers. The
archives produce a large number of pcap-ng formatted
files that contain the traffic captures.
• Conversion of the pcap-ng files to tcpdump format capture using the editcap utility. This is to allow tcpflow to
process the data.
• Use of xargs and GNU parallel to run tcpflow on each
pcap. This is a time-consuming process, and produced a
directory structure with files for data sent and received
on host-port socket pairs. This step of processing allows
file-based tools to process the network data.
• A tool to process each file containing data sent or received
by network ports associated with CTF challenges. These
tools produced summary statistics for each data stream,
to include a byte histogram, overall size, a hash, and an
ARM instruction histogram (we ran a linear sweep with
the Capstone instruction decoder to produce this). This
data was saved via JSON.
After this pre-processing of the network data packets, we
have around 10 million network attacks consisting of around
1 million unique exploits built and used by 20 teams in the
competition. In order to attribute an attack to a particular
team, apart from analyzing the payloads used by the team,
we also need to analyze the behavior of the attacking team
towards their adversary. For this purpose, we divide the attacks
according to the team being targeted. Thus, we have 20 such
subsets, which we represent as T-i, where i ∈ {1, 2, 3, ..., 20}.
The processed dataset is publicly available 1 .
We now discuss two important observations from the
dataset, which make the task of attributing an observed network attack to a team difficult.
Deception: In the context of this paper we define an attack to
1 http://lab.engineering.asu.edu/cysis/cyber-attribution/

be deceptive when multiple adversaries get mapped to a single
attack pattern; deception is thus a scenario in which the same
exploit is used by multiple teams to target the same team. The
number of unique deceptive attacks amount to just under 35%
of the total unique attacks in our dataset—clearly, deception
is a heavily-used technique in this domain.
Duplicate attacks: A duplicate attack occurs when the same
team uses the same payload to attack the same team at different
points in time. We group duplicates as either being nondeceptive or deceptive. Non-deceptive duplicates are the copies
of the attacks launched by the team that first initiated the use
of a particular payload; on the other hand, deceptive duplicates
are all the attacks from the teams that did not initiate the use.
III. A RGUMENTATION M ODEL
Our approach relies on a model of the world where we can
analyze competing hypotheses in a cyber-operation scenario.
Such a model should allow for contradictory information so it
can handle inconsistency in cases of deception.
Before describing the argumentation model in detail, we
introduce some necessary notation. Variables and constant
symbols represent items such as the exploits/payloads used
for the attack, and the actors conducting the cyber-attack (in
this case, the teams in the CTF competition). We denote the
set of all variable symbols with V and the set of all constants
with C. For our model we require two subsets of C: Cact ,
denoting the actors capable of conducting the cyber-operation,
and Cexp , denoting the set of unique exploits used. We use
symbols in all capital letters to denote variables. In the running
example, we use a subset of our DEFCON CTF dataset.
Example 1. Actors and cyber-operations from the CTF
data: Cact = {bluelotus, robotmafia, apt8}, Cexp =
{exploit1 , exploit2 , ..., exploitn }.
The language also contains a set of predicate symbols that
have constants or variables as arguments, and denote events
that can be either true or false. We denote the set of predicates
with P; examples of predicates are shown in Table 2. For
instance, culprit(exploit1 , apt8) will either be true or false, and
denotes the event where apt8 used exploit1 to conduct a cyberoperation.
TABLE 2: Example predicates and explanation
Predicate

Explanation

attack(exploit1 , bluelotus)

exploit1 was targeted towards the
team Blue Lotus.

replay attack(E, Y)

Exploit E was replayed by team Y.

deception(exploit1 , apt8)

Team apt8 used exploit1 for deception.

time diff(I, Y)

Team Y was deceptive within the
given time interval I.

culprit(exploit1 , apt8)

Team apt8 is the likely culprit for
the attack (using exploit1 on the
target team).

A ground atom is composed by a predicate symbol and
a tuple of constants, one for each argument. The set of all

ground atoms is denoted as G. A ground literal L is a ground
atom or a negated ground atom; hence, ground literals have
no variables. An example of a ground atom for our running
example is attack(exploit1 , bluelotus). We denote a subset of
G with G0 .
We choose a structured argumentation framework [14] for
our model; our approach works by creating arguments (in
the form of a set of rules and facts) that compete with each
other to attribute an attack to a given perpetuator. In this case,
arguments are defeated based on contradicting information in
other arguments. This procedure is known as a dialectical
process, where the arguments that are undefeated prevail.
An important result is the set of all the arguments that are
warranted (not defeated) by any other argument, which give
a clear map supporting the conclusion. Such transparency
lets a security analyst not only add new arguments based
on new evidence discovered in the system, but also get rid
of incorrect information and fine-tune the model for better
performance. Since the argumentation model can deal with
inconsistent information, it draws a natural analogy to the way
humans settle disputes when there is contradictory information
available. Having a clear explanation of why one argument is
chosen over others is a desirable characteristic for both the
analyst and for organizations to make decisions and policy
changes. We now briefly discuss some preliminaries on DeLP.
Defeasible Logic Programming: DeLP is a formalism that
combines logic programming with defeasible argumentation;
full details are discussed in [8]. The formalism is made up
of several constructs, namely facts, strict rules, and defeasible
rules. Facts represent statements obtained from evidence, and
are always true; similarly, strict rules are logical combinations
of elements (facts or other inferences) that can always be
performed. On the contrary, defeasible rules can be thought
of as strict rules that may be true in some situations, but
could be false if contradictory evidence is present. These three
constructs are used to build arguments, and DeLP programs
are sets of facts, strict rules and defeasible rules. We use the
usual notation for DeLP programs, denoting the knowledge
base with Π = (Θ, Ω, ∆), where Θ is the set of facts, Ω is
the set of strict rules, and ∆ is the set of defeasible rules.
Examples of the three constructs are provided with respect to
the dataset in Fig. 1. We now describe the constructs in detail.
Facts (Θ) are ground literals that represent atomic information
or its (strong) negation (¬).
Strict Rules (Ω) represent cause and effect information; they
are of the form L0 ← L1 , ...Ln , where L0 is a literal and
{Li }i>0 is a set of literals.
Defeasible Rules (∆) are weaker versions of strict rules, and
are of the form L0 -≺ L1 , ...., Ln , where L0 , is the literal and
{Li }i>0 is a set of literals.
When a cyber-attack occurs, the model can be used to derive
arguments as to who could have conducted the attack. Derivation follows the same mechanism as logic programming [11].
DeLP incorporates defeasible argumentation, which decides
which arguments are warranted and it blocks arguments that

Θ:

θ1
θ2
θ3
θ4
θ5

=
=
=
=
=

Ω:

ω1 =
ω2 =

∆:

δ1 =
δ2 =
δ3 =
δ4 =

attack(exploit1 , bluelotus)
first attack(exploit1 , robotmafia)
last attack(exploit1 , apt8))
time diff(interval, robotmafia)
most frequent(exploit1 , pwnies)
culprit(exploit1 , pwnies) ←
most frequent(exploit1 , pwnies),
replay attack(exploit1 )
¬ culprit(exploit1 , robotMafia) ←
last attack(exploit1 , apt8),
replay attack(exploit1 )
replay attack(exploit1 ) -≺
attack(exploit1 , bluelotus),
last attack(exploit1 , apt8)
deception(exploit1 , apt8) -≺
replay attack(exploit1 ),
first attack(exploit1 , robotmafia)
culprit(exploit1 , apt8) -≺
deception(exploit1 , apt8),
replay attack(exploit1 )
¬culprit(exploit1 , apt8) -≺
time diff(interval, robotmafia)

Fig. 1: A ground argumentation framework.
hA1 ,
hA2 ,
hA3 ,
hA4 ,

replay attack(exploit1 ) i
deception(exploit1 , apt8) i
culprit(exploit1 , apt8)i
¬culprit(exploit1 , apt8)i

A1
A2
A3
A4

= {δ1 , θ1 , θ3 }
= {δ1 , δ2 , θ2 }
= {δ1 , δ2 , δ3 }
= {δ1 , δ4 , θ3 }

Fig. 2: Example ground arguments from Figure 1.

are in conflict and a winner cannot be determined. Fig. 1 shows
a ground argumentation framework demonstrating constructs
derived from the CTF data. For instance, θ1 indicates the fact
that exploit1 was used to target the team Blue Lotus, and θ5
indicates that team pwnies is the most frequent user of exploit1 .
For the strict rules, ω1 says that for a given exploit1 the attacker
is pwnies if it was the most frequent attacker and the attack
exploit1 was replayed. Defeasible rules can be read similarly;
δ2 indicates that exploit1 was used in a deceptive attack by
APT8 if it was replayed and the first attacker was not APT8.
By replacing the constants with variables in the predicates we
can derive a non-ground argumentation framework.
Definition 1. (Argument) An argument for a literal L is a
pair hA, Li, where A ⊆ Π provides a minimal proof for L
meeting the requirements: (1) L is defeasibly derived from A2 ,
(2) Θ ∪ Ω ∪ ∆ is not contradictory, and (3) A is a minimal
subset of ∆ satisfying 1 and 2, denoted hA, Li.
Literal L is called the conclusion supported by the argument, and A is the support. An argument hB, Li is a
subargument of hA, L0 i iff B ⊆ A. The following examples
show arguments for our scenario.
Example 2. Fig. 2 shows example arguments based on the
2 This means that there exists a derivation consisting of a sequence of rules
that ends in L—that possibly includes defeasible rules.




KB from Fig. 1;
 here, A1 , replay attack(exploit
 1 ) 
is a
subargument of A2 , deception(exploit1 , apt8) and A3 ,
culprit(exploit1 , apt8) .
For a given argument there may be counter-arguments that
contradict it. For instance, referring to Fig. 2, we can see that
A4 attacks A3 . A proper defeater of an argument hA, Li is
a counter-argument that—by some criterion—is considered to
be better than hA, Li; if the two are incomparable according
to this criterion, the counterargument is said to be a blocking
defeater. The default criterion used in DeLP for argument
comparison is generalized specificity [21].
A sequence of arguments is called an argumentation line.
There can be more than one defeater argument, which leads to
a tree structure that is built from the set of all argumentation
lines rooted in the initial argument. In this dialectical tree,
every child can defeat its parent (except for the root), and the
leaves represent unchallenged arguments; this creates a map
of all possible argumentation lines that decide if an argument
is defeated or not. Arguments that either have no attackers or
all attackers have been defeated are said 
to be warranted.
Given a literal L and an argument A, L , in order to
decide whether or not a literal L is warranted, every node
in the dialectical tree T (hA, Li) is recursively marked as “D”
(defeated) or “U” (undefeated), obtaining a marked dialectical
tree T ∗ (hA, Li) where:
∗
• All leaves in T (hA, Li) are marked as “U”s, and
∗
• Let hB, qi be an inner node of T (hA, Li). Then, hB, qi
will be marked as “U” iff every child of hB, qi is marked
as “D”. Node hB, qi will be marked as “D” iff it has at
least one child marked as “U”.
Given argument hA, Li over Π, if the root of T ∗ (hA, Li)
is marked “U”, then T ∗ (hA, hi) warrants L and that L is
warranted from Π. (Warranted arguments correspond to those
in the grounded extension of a Dung argumentation system
[7].)
In practice, an implementation of DeLP accepts as input sets
of facts, strict rules, and defeasible rules. Note that while the
set of facts and strict rules is consistent (non-contrdictory),
the set of defeasible rules can be inconsistent. We engineer
our cyber-attribution framework as a set of defeasible and
strict rules whose structure was created manually, but are
dependent on values learned from a historical corpus of data.
Then, for a given incident, we instantiate a set of facts for
that situation. This information is then provided as input
into a DeLP implementation that uses heuristics to generate
all arguments for and against every possible culprit for the
cyber attack. Dialectical trees based on these arguments are
analyzed, and a decision is made regarding which culprits are
warranted. This results in a reduced set of potential culprits,
which we then use as input into a classifier to obtain an
attribution decision.
IV. BASELINE A RGUMENTATION M ODEL (BM)
In [13] machine learning techniques were leveraged on the
CTF data to identify the attacker. We will now provide a sum-

ω1 =

culprit(E, Y) ← last attack(E, Y), replay attack(E).

δ1 =

replay attack(E) -≺ attack(E, X), last attack(E, Y).

Fig. 3: Defeasible and strict rule for non-deceptive attack.

mary of the results obtained. The experiment was performed
as follows. The dataset was divided according to the target
team, building 20 subsets, and all the attacks were then sorted
according to time. The first 90% of the attacks were reserved
for training and the remaining 10% for testing. The byte and
instruction histograms were used as features to train and test
the model. Models constructed using a random forest classifier
performed the best, with an average accuracy of 0.37. Most
of the misclassified samples tend to be deceptive attacks and
their duplicates.
When using machine learning approaches it is difficult to
map the reasons why a particular attacker was predicted,
especially in cases of deception where multiple attackers were
associated with the same attack. Knowing the arguments that
supported a particular decision would greatly aid the analyst in
making better decisions dealing with uncertainty. To address
this issue we now describe how we can form arguments/rules
based on the latent variables computed from the training data,
given an attack for attribution.
We use the following notation: let E be the test attack
under consideration aimed at target team X, Y represent all
the possible attacking teams, and D be the set of all deceptive
teams (those using the same payload to target the same team)
if the given attack is deceptive in the training set. For nondeceptive attacks, D will be empty. We note that facts cannot
have variables, only constants (however, to compress the
program for presentation purposes, we use meta-variables in
facts). To begin, we define the facts: θ1 = attack (E, X), θ2 =
first attack (E, Y), θ3 = last attack (E, Y); θ1 states that
attack E was used to target team X, θ2 states that team Y
was the first team to use the attack E in the training data, and
similarly θ3 states that team Y was the last team to use the
attack E in the training data. The first and last attacking team
may or may not be the same. We study the following three
cases:
Case 1: Non-deceptive attacks. In non-deceptive attacks, only
one team uses the payload to target other teams in the training
data. It is easy to predict the attacker for these cases, since
the search space only has one team. To model this situation,
we define a set of defeasible and strict rules.
In Fig. 3, defeasible rule δ1 checks whether the attack was
replayed in the training data. Since it is a non-deceptive attack,
it can only be replayed by the same team. The strict rule ω1
then puts forth an argument for the attacker (culprit) if the
defeasible rule holds and there is no contradiction for it.
Case 2: Deceptive attacks. These attacks form the majority
of the misclassified samples in [13]. The set D is not empty
for this case; let Di denote the deceptive teams in D. We
also compute the most frequent attacker from the training
data given a deceptive attack. Let the most frequent deceptive

θ1 = decep (E, X), θ2 = frequent (E, F )

Attacker Time Analysis: The CTF data provides us with time
stamps for the attacks in the competition. We can use this
information to come up with rules for/against an argument for
a team being the attacker. We compute the average time for a
team to replay its own attack given that it was the first one to
deploy the attack (see Fig. 5). It can be observed that teams
like more smoked leet chicken (T-13) and Wowhacker-bios (T8) are very quick to replay their own attacks as compared to
other teams. Fig. 5 also shows the average time for a team
to perform a deceptive attack. Teams like The European (T-7)
and Blue lotus (T-10) are quick to commit deception, while
others take more time.
We use this time information to narrow down our search
space for possible attackers. In particular, for a deceptive
test sample, we compute the time difference between the test
sample and the training sample that last used the same payload.
We denote this time difference as 4t, and include it as a

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

Deceptive

attacker be denoted as F . The DeLP components that model
this case are shown in Figure 4; fact θ1 indicates if the attack
E was deceptive towards the team X and θ2 indicates the most
frequent attacker team F from the training set. The strict rule
ω1 indicates that in case of deception the first team to attack
(Y) is not the attacker, ω2 states that the attacker should be
F if the attack is deceptive and F was the most frequent
deceptive attacker. For the defeasible rules, δ1 deals with the
case in which the attack E was replayed, δ2 deals with the
case of deceptive teams from the set D, δ3 indicates that all the
deceptive teams are likely to be the attackers in the absence of
any contradictory information. and δ4 states that the attacker
should be F if the attack is deceptive and F was the most
frequent attacker.
Case 3: Previously Unseen Attacks. The most difficult
attacks to attribute in the dataset are the unseen ones, i.e.
attacks first encountered in the test set and thus did not occur
in the training set. To build constructs for this kind of attack
we first compute the k nearest neighbors from the training set
according to a simple Euclidean distance between the byte
and instruction histograms of the two attacks. In this case
we choose k = 3. For each of the matching attacks from
the training data we check if the attack is deceptive or nondeceptive. If non-deceptive, we follow the procedure for Case
1, otherwise we follow the procedure for Case 2. Since we
replace one unseen attack with three seen attacks, the search
space for the attacker increases for unseen attacks.

T-10

T-8

T-7

T-6

1

T-1

Fig. 4: Facts and rules for deceptive attacks.

10

T-5

δ3 =

100

T-4

replay attack(E) -≺ attack(E, X), last attack(E, Y)
deception(E, Di ) -≺ replay attack(E),
first attack(E, Y)
culprit(E, Di ) -≺ deception(E, Di ), first attack(E, Y)

T-3

δ1 =
δ2 =

1000

T-2

¬culprit(E, Y) ← first attack(E, Y), decep(E, X)
culprit(E, F ) ← frequent(E, F ), deception (E, Di )

Average time (sec) - Log Scale

ω1 =
ω2 =

10000

Replay

Fig. 5: Average time for team to perform a deceptive attack
and replay its own attack (Log-scale).
Θ:

θ1 =

timedifference (E, X)

∆:

δ1 =

For Y ∈
/ interval:
¬culprit(E, Y) -≺ timedifference (E, X).

Fig. 6: Time facts and rules. Interval indicates a small portion
of the entire deceptive time (for instance < 2000 sec, > 8000
sec and so on).

fact θ1 . We then divide the deceptive times from Fig. 5 into
appropriate intervals; each team is assigned to one of those
time intervals. We then check which time interval 4t belongs
to and define a defeasible rule δ1 that makes a case for all
teams not belonging to the interval to not be the culprits, as
shown in Fig. 6.
We now provide a summary of the experimental results—
the setup is similar to [13]: the dataset is sorted by time for
each target team, the first 90% of the data is used for training
and the remaining 10% for testing. The constructs for all test
samples based on the cases discussed in the previous section
are computed, and these arguments are used as input to the
DeLP implementation. For each test sample the DeLP system
is queried to find all possible attackers (culprits) based on
the arguments provided. If there is no way to decide between
contradicting arguments, these are blocked and thus return no
answers. Initially, the search space for each test sample is 19
teams (all except the one being attacked).
After running the queries to return the set of possible
culprits, the average search space across all target teams is
5.85 teams. This is a significant reduction in search space
across all target teams; to gauge how much the reduced search
space can aid an analyst in predicting the actual culprit, a
metric is computed that checks if the reduced search space
contains the ground truth (actual culprit). For all the target
teams, the ground truth is present on average in almost 66%
of the samples with reduced search space. For some teams
like more smoked leet chicken (T-13) and raon ASRT (whois)
(T-17) the average reduced search space is as low as 1.82 and
2.9 teams, with high ground truth fraction of 0.69 and 0.63,
respectively.
Predictive analysis is then performed on the reduced search

space. The experimental setup is similar to the one described
earlier; the only difference this time is instead of having a 19
team search space as in [13], the machine learning approach is
allowed to make a prediction from the reduced search space
only; a random forest is used for learning, which has been
shown to have the best performance for CTF data [13].
We report the following average accuracies across 20
target teams; the accuracy achieved after running Random
forest without applying the argumentation-based techniques,
as reported in [13], is 0.37. This was the best performing
approach using standard machine learning techniques. The
baseline model achieves an average accuracy of 0.5, which is
significantly better than the average accuracy of 0.37 in [13].
V. E XTENDED BASELINE M ODEL I (EB1)
Previously Unseen attacks make up almost 20% of the test
samples for each target team. On analyzing the misclassification from the baseline argumentation model, we observe that
the majority of the previously unseen attacks get misclassified
(>80%). The misclassifications can be attributed to two reasons: (i) the reduced search space is not able to capture the
ground truth for unseen attacks, leading the learning model to
a wrong prediction; and (ii) we represent each unseen attack
by the 3 most similar attacks in the training data; this leads
to an increase in the search space and many choices for the
learning model.
We address these issues by proposing two sets of defeasible
rules. First, for each target team we compute from the training
set the top 3 teams that come up with the most unique exploits,
as these teams are more likely to launch an unseen attack in
the test set. The intuition behind this rule is the fact that not
all teams write their own exploits, most teams just capture a
successful exploit launched by other teams and repackage it
and use it as their own (deception). The second set of rules
is proposed to avoid addition of less similar teams to the
reduced search space. In the baseline model we use 3-nearest
neighbors to represent an unseen attack. In this extended
version we consider only the nearest neighbors that are less
than a particular threshold value T , which is decided for each
target team separately. So, each attack will be represented by
k ≤ 3 teams depending upon the threshold requirement. In
addition to the baseline model rules, we propose the following
rules for deceptive attacks. Let U denote the set of teams with
the three highest numbers of unique attacks in the training
data. Also, let N denote the set of three most similar culprits
for the given unseen attack.
The extended model is shown in Fig. 7; the fact θ1 indicates
the teams present in N and whose similarity is less than a
particular threshold T , and θ2 indicates if the team ui was
one of most unique attackers from set U. For the defeasible
rules, δ1 makes use of the fact θ1 stating that the teams in N
that satisfy the threshold condition are likely to be the culprits,
and δ2 indicates that if ui is a unique attacker then it can be
the culprit unless contradictory information is available. U is
independent of the test samples and will be the same for all
unseen attacks given a target team.

Θ:

θ1 =
θ2 =

∆:

δ1 =
δ2 =

For (ni ∈ N and sim < T ):
threshold(E, T )
For ui in U:
unique(E, ui )
culprit(E, ui ) -≺ threshold(E, T )
For ui ∈ U:
culprit(E, ui ) -≺ unique(E, ui )

Fig. 7: Rules for unseen attacks.
Θ:

θ1 =

timedifference (E, X)

∆:

δ1 =

For Y ∈ interval:
culprit(E, Y) -≺ timedifference (E, X).

Fig. 8: Time facts and rules. Interval indicates a small portion
of the entire deceptive time (for instance < 2000 sec, > 8000
sec and so on).

On the contrary, for each of the similar payloads (three or
fewer) computed from the training data we check if the attack
is deceptive or non-deceptive. If non-deceptive, we follow the
procedure for Case 1, otherwise we follow the procedure for
Case 2 stated in the baseline argumentation model.
Experiment: We evaluate EB1 using an experimental setup
similar to the one for the baseline argumentation model.
We report the average reduced search space and prediction
accuracy for both EB1 and baseline model to provide a
comparison. EB1 performs better than the baseline with an
average accuracy of 0.53 vs. 0.50, and significantly better than
the machine learning model without argumentation that has an
average accuracy of 0.37. The improvement in performance
is due to the larger fraction of reduced search spaces with
ground truth present in them. Also, the search space reduced
from on average 6.07 teams to 5.025 (less teams to consider).
The results are reported in Table 3 along with a comparison
to the second extended baseline argumentation model (EB2).
VI. E XTENDED BASELINE M ODEL II (EB2)
Another source of misclassification in the baseline argumentation model is the presence of unseen deceptive teams
and their duplicates. These refer to teams that did not use the
exploit in the training set but started using it in the test set. It
is difficult for a machine learning approach to predict such a
team as being the culprit if it has not encountered it using the
exploit in the training set. In our dataset these attacks comprise
15% of the total, and up to 20% for some teams.
In order to address this issue we propose an extension
of EB1, where we group together teams that have similar
deceptive behavior based on the time information available to
us from the training set; for instance teams that are deceptive
within a certain interval of time (e.g., less than 2,000 secs.)
after the first attack has been played are grouped together. For
a given test attack we compute the time difference between
the test attack and the last time the attack was used in the
training set. We then assign this time difference to a specific

group based on which interval the time difference falls in.
In order to fine tune the time intervals, instead of using the
average deceptive times averaged across all target teams (as
used in the baseline model), we compute and use deceptive
times for each target team separately. We model the time rules
as stated in Fig. 8; fact θ1 states the time difference between
the test sample and the last training sample to use that attack,
defeasible rule δ1 on the other hand states that teams belonging
to that interval (in which the time difference lies) are likely to
be the culprits unless a contradiction is present. It is clear that
this rule will increase the search space for the test sample,
as additional teams are now being added as likely culprits.
We observe that for EB2 the search space is increased by an
average of almost 2.5 teams per test sample from EB1; at the
same time the presence of ground truth in the reduced search
space increased to 0.78, which is a significant improvement
over 0.68.
Experiment: We evaluate EB2 using an experimental setup
similar to the one discussed in the baseline argumentation
model. We report the prediction accuracies for each of the
proposed baseline argumentation models for each of the target
teams and compare it with the previous accuracy reported
in [13], denoted as ML. In Table 3 the second extended
baseline model (EB2) performs the best with an average
prediction accuracy of 62% as compared to other proposed
methods. The additions of teams based on time rules not only
benefits detection of unseen deceptive teams but it also helps
in predicting attackers for unseen attacks. The major reason
for the jump in performance is that for most unseen deceptive
team samples, the time rules proposed in the baseline model
block all deceptive teams from being the culprit, leading to
an empty set of culprits. The new set of rules proposed in
EB2 adds similar-behaving teams to this set based on time
information; the learning algorithm can then predict the right
one from this set.
VII. C ONCLUSION
In this paper we demonstrated how an argumentationbased framework (DeLP) can be leveraged to improve cyberattribution decisions by building DeLP programs based on
CTF data; this affords a reduction of the set of potential
culprits and thus greater accuracy when using a classifier for
cyber attribution. We are currently looking at implementing a
probabilistic variant of DeLP [19], as well as designing our
own CTF event in order to better mimic real-world scenarios.
Our new CTF will encourage deceptive behavior among the
participants, and we are also enhancing our instrumentation of
the CTF, allowing for additional data collection (host data is
of particular interest).
VIII. ACKNOWLEDGMENTS
Authors of this work were supported by the U.S. Department of the Navy, Office of Naval Research, grant N00014-151-2742 as well as the Arizona State University Global Security
Initiative (GSI) and by CONICET and Universidad Nacional
del Sur, Argentina.

TABLE 3: Results Summary
Team

ML [13]

BM

EB1

EB2

T-1

0.45

0.51

0.52

0.60

T-2

0.22

0.45

0.38

0.43

T-3

0.30

0.40

0.47

0.66

T-4

0.26

0.44

0.42

0.44

T-5

0.26

0.45

0.45

0.56

T-6

0.5

0.49

0.55

0.7

T-7

0.45

0.53

0.56

0.66

T-8

0.42

0.61

0.58

0.74

T-9

0.41

0.50

0.53

0.76

T-10

0.30

0.42

0.41

0.41

T-11

0.37

0.44

0.5

0.73

T-12

0.24

0.43

0.36

0.52

T-13

0.35

0.63

0.64

0.75

T-14

0.42

0.52

0.53

0.67

T-15

0.30

0.38

0.55

0.64

T-16

0.43

0.48

0.55

0.65

T-17

0.42

0.58

0.58

0.68

T-18

0.48

0.50

0.52

0.65

T-19

0.41

0.51

0.56

0.68

T-20

0.48

0.51

0.64

0.71

R EFERENCES
[1] A. Applebaum, K. Levitt, Z. Li, S. Parsons, J. Rowe, and E. Sklar.
Cyber reasoning with argumentation: Abstracting from incomplete and
contradictory evidence. In Proc. of MILCOM, 2015.
[2] W. E. Boebert. A survey of challenges in attribution. In Proc. of a
workshop on Deterring CyberAttacks, pages 41–54, 2010.
[3] M. Brückner, C. Kanzow, and T. Scheffer. Static prediction games
for adversarial learning problems. The Journal of Machine Learning
Research, 13(1):2617–2654, 2012.
[4] M. Brückner and T. Scheffer. Stackelberg games for adversarial prediction problems. In Proceedings of the 17th ACM SIGKDD international
conference on Knowledge discovery and data mining, pages 547–555.
ACM, 2011.
[5] M. Dacier, V.-H. Pham, and O. Thonnard. The wombat attack attribution
method: some results. In Information Systems Security, pages 19–37.
Springer, 2009.
[6] DEFCON. DEFCON: Capture the flag. https://media.defcon.org/, 2013.
[Online; accessed January-2015].
[7] P. M. Dung. On the acceptability of arguments and its fundamental role
in nonmonotonic reasoning, logic programming and n-person games.
Artificial intelligence, 77(2):321–357, 1995.
[8] A. J. Garcı́a and G. R. Simari. Defeasible logic programming: An
argumentative approach. Theory and practice of logic programming,
4(1+ 2):95–138, 2004.
[9] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. Tygar.
Adversarial machine learning. In Proceedings of the 4th ACM workshop
on Security and artificial intelligence, pages 43–58. ACM, 2011.
[10] B. Li and Y. Vorobeychik. Feature cross-substitution in adversarial
classification. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence,
and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 27, pages 2087–2095. Curran Associates, Inc., 2014.
[11] J. W. Lloyd. Foundations of logic programming. Springer Science &
Business Media, 2012.
[12] D. Lowd and C. Meek. Adversarial learning. In Proceedings of
the eleventh ACM SIGKDD international conference on Knowledge
discovery in data mining, pages 641–647. ACM, 2005.

[13] E. Nunes, N. Kulkarni, P. Shakarian, A. Ruef, and J. Little. Cyberdeception and attribution in capture-the-flag exercises. In Proceedings
of the 2015 IEEE/ACM International Conference on Advances in Social
Networks Analysis and Mining, ASONAM 2015, Paris, France, August
25 - 28, 2015, pages 962–965, 2015.
[14] I. Rahwan, G. R. Simari, and J. van Benthem. Argumentation in artificial
intelligence, volume 47. Springer, 2009.
[15] T. Rid and B. Buchanan. Attributing cyber attacks. Journal of Strategic
Studies, 38(1-2):4–37, 2015.
[16] J. Salvit, Z. Li, S. Perumal, H. Wall, J. Mangels, S. Parsons, and E. I.
Sklar. Employing argumentation to support human decision making:
A user study. In AAMAS Workshop on Argumentation in Multiagent
Systems, 2014.
[17] P. Shakarian, J. Shakarian, and A. Ruef. Introduction to cyber-warfare:
A multidisciplinary approach. Elsevier, 2013.
[18] P. Shakarian, G. I. Simari, G. Moores, and S. Parsons. Cyber attribution:
An argumentation-based approach. In Cyber Warfare: Building the
Scientific Foundation, pages 151–171. Springer, 2015.
[19] P. Shakarian, G. I. Simari, G. Moores, D. Paulo, S. Parsons, M. Falappa,
and A. Aleali. Belief revision in structured probabilistic argumentation.
Annals of Mathematics and Artificial Intelligence, pages 1–43, 2015.
[20] E. I. Sklar, S. Parsons, Z. Li, J. Salvit, S. Perumal, H. Wall, and J. Mangels. Evaluation of a trust-modulated argumentation-based interactive
decision-making tool. Autonomous Agents and Multi-Agent Systems,
pages 1–38, 2015.
[21] F. Stolzenburg, A. J. Garcı́a, C. I. Chesnevar, and G. R. Simari.
Computing generalized specificity. Journal of Applied Non-Classical
Logics, 13(1):87–113, 2003.
[22] R. J. Walls. Inference-based Forensics for Extracting Information from
Diverse Sources. PhD thesis, University of Massachusetts Amherst,
2014.

The Workshops of the Thirtieth AAAI Conference on Artificial Intelligence
Artificial Intelligence for Cyber Security: Technical Report WS-16-03

Toward Argumentation-Based Cyber Attribution
Eric Nunes and Paulo Shakarian

Gerardo I. Simari

Arizona State University
Tempe, AZ 85281, USA
Email: {enunes1, shak}@asu.edu

Inst. for Computer Science and Engineering
(Univ. Nac. del Sur–CONICET), Bahia Blanca, Argentina
E-mail: gis@cs.uns.edu.ar

Abstract

multi-label classification problem and applied several machine learning and pruning techniques; the results of this
work are discussed in (Nunes et al. 2015). Based on our observations, machine learning approaches fail in situations of
deception, where similar attributes point towards multiple
attackers. Standard machine learning approaches treat this
problem as “labeling noise” leading to a random selection
of attacker. We propose to address this issue using a formal
logical framework. Specific contributions of this paper include,
• a model for cyber-attribution created in the DeLP argumentation framework;

A major challenge in cyber-threat analysis is combining information from different sources to find the person or the
group responsible for the cyber-attack. It is one of the most
important technical and policy challenges in cyber-security.
The lack of ground truth for an individual responsible for an
attack has limited previous studies. In this paper, we overcome this limitation by building a dataset from the capturethe-flag event held at DEFCON, and propose an argumentation model based on a formal reasoning framework called
DeLP (Defeasible Logic Programming) designed to aid an
analyst in attributing a cyber-attack to an attacker. We build
argumentation-based models from latent variables computed
from the dataset to reduce the search space of culprits (attackers) that an analyst can use to identify the attacker. We show
that reducing the search space in this manner significantly improves the performance of classification-based approaches to
cyber-attribution.

• experiments demonstrating that using argumentationbased tools can significantly reduce the number of potential culprits in a cyber-attack; and
• experiments showing that the reduced set of culprits,
used in conjunction with classification, leads to improved
cyber-attribution decisions.

Introduction
A major challenge in cyber-threat analysis is to find the
person or the group responsible for a cyber-attack. This is
known as cyber-attribution (Shakarian, Shakarian, and Ruef
2013) and it is one of the central technical and policy challenges in cyber-security. Oftentimes, the evidence collected
from multiple sources provides a contradictory viewpoint.
This gets worse in cases of deception where either an attacker plants false evidence or the evidence points to multiple actors, leading to uncertainty. In our text on cyberwarfare (Shakarian, Shakarian, and Ruef 2013) we discuss
the difficulties that an intelligence analyst faces in attributing an attack to a perpetrator given that deception might have
occurred, and how the analyst needs to explore deception hypotheses under the given attack scenario.
However, one of the major drawbacks of the study and
evaluation of cyber-attribution models is the lack of datasets
with the ground truth available regarding the individual party
responsible for the attack—this has limited previous studies.
To overcome this, we built and leveraged a dataset from the
capture-the-flag event held at DEFCON (cf. the dataset section for a detailed discussion). In previous work, we used
this dataset to study cyber-attribution, and framed it as a

Related Work
Currently, cyber-attribution is limited to identifying machines (Boebert 2010) as opposed to the hacker or their affiliation to a group or a state organization. An example of
such a technical attribution approach is WOMBAT (Dacier,
Pham, and Thonnard 2009), where a clustering technique
is used to group attacks to common IP sources. A method
that combines information from different sources was proposed in (Walls 2014), where forensic information from diverse sources is considered but inconsistency or uncertainty
due to deception is not considered. A less rigorous mathematical model, known as the Q model (Rid and Buchanan
2015), has been proposed recently; there, the model answers queries from an analyst, both technical (tools used)
and non-technical (environment related), and by combining
these query answers the analyst tries to attribute an attack
to a party. Unfortunately, there are no experimental results
evaluating the effectiveness of this model.
Concurrently, we have devised a formal logical framework for reasoning about cyber-attribution (Shakarian et
al. 2015a; 2015b). This reasoning model explores multiple
competing hypotheses based on the evidence for and against
a particular attacker before it attributes the attack to a specific party. With this approach we get a clear map regarding

c 2016, Association for the Advancement of Artificial
Copyright 
Intelligence (www.aaai.org). All rights reserved.

177

tion, we used the open source tool tcpflow1 to process the
network captures into a set of files, with each file representing data sent or received on a particular connection.
This produced a corpus of data that could be searched and
processed with standard UNIX tools, like grep. Further analysis of the game environment provided an indicator of when
a data file contained an exploit. The game stored keys for
services in a standard, hard-coded location on each competitor’s server. By searching for the text of this location in the
data, we identified data files that contained exploits for services.
With these data files identified, we analyzed some of them
by hand using the Interactive Disassembler (IDA) to determine if the data contained shell-code, which in fact was the
case. We used an automated tool to produce a summary of
each data file as a JSON encoded element. Included in this
summary was a hash of the contents of the file and a histogram of the processor instructions contained in the file.
These JSON files were the final output of the low level analysis, transforming hundreds of gigabytes of network traffic into a manageable set of facts about exploit traffic in
the data. Each JSON file is a list of tuples (time-stamp,
hash, byte-histogram, instruction-histogram). The individual
fields of the tuple are listed in Table 1.

the arguments that led to the decision. This paper is the first
to provide experimental results using a formal logical framework to build a reasoning model.
The rest of the paper is organized as follows. We present
the argumentative model based on Default Logic Programming (DeLP) (Garcı́a and Simari 2004). This is followed by
a description of our DEFCON capture-the-flag dataset and
an analysis on the use of deception within this data. We then
give a summary of our results from (Nunes et al. 2015) and
discuss how we built our argumentation model for cyberattribution with DeLP. Experimental results are discussed in
the subsequent section.

DEFCON CTF Dataset
The DEFCON security conference sponsors and hosts a
capture-the-flag (CTF) competition every year, held on site
with the conference in Las Vegas, Nevada. The CTF competition can be viewed as a microcosm of the global Internet and the careful game of cat and mouse between hacking
groups and security firms. Teams are free to use different
technical means to discover vulnerabilities: they may reverse
engineer programs, monitor the network data sent to their
services, and dynamically study the effects that network data
has on unpatched services. If a team discovers a vulnerability and uses it against another team, the first team may discover that their exploit is re-purposed and used against them
within minutes.
The organizers of DEFCON CTF capture all of the network traffic sent and received by each team, and publish this
traffic at the end of the competition (DEFCON 2013). This
includes IP addresses for source and destination, as well as
the full data sent and received and the time the data was sent
or received. This data is not available to contestants; depending on the organizers’ choice from year to year, the contestants either have a real time feed but with the IP address
obscured, or a full feed delivered on a time delay ranging
from minutes to hours.
In addition to the traffic captures, copies of the vulnerable services are distributed by the organizers, who usually
do not disclose the vulnerabilities they engineered into each
service; however, competitors frequently disclose this information publicly after the game is finished by preparing technical write-ups.
The full interaction of all teams in the game environment
are captured by this data. We cannot build a total picture of
the game at any point in time, since there is state information
from the servers that is not captured, but any exploit attempt
would have to travel over the network and that would be
observed in the data set.

Table 1: Fields in an instance of network attack
Field

Intuition

byte hist

Histogram of byte sequences in the payload

inst hist

Histogram of instructions used in the
payload

from team

The team where the payload originates
(attacking team)

to team

The team being attacked by the exploit

svc

The service that the payload is running

payload hash

The md5 of the payload used

time

Date and time of the attack

Table 2: Example event from the dataset
Field

Value

byte hist

0×43:245, 0×69:8, 0×3a:9, 0×5d:1,
.....

inst hist

cmp:12, svcmi:2, subs:8, movtmi:60
......

Analysis

from team

Robot Mafia

We use the data from the CTF tournament held at DEFCON 21 in 2013; the dataset is very large, about 170 GB
in compressed format. We used multiple systems with distributed and coordinated processing to analyze the entire
corpus—fortunately, analyzing individual streams is easy to
parallelize. To analyze this data, we identified the TCP ports
associated with each vulnerable service. From this informa-

to team

Blue Lotus

svc

02345

payload hash

2cc03b4e0053cde24400bbd80890446c

time

2013-08-03T23:45:17

1

178

https://github.com/simsong/tcpflow

Number of Attacks

400000

tion, as it must have the capability to reason about inconsistency in cases of deception.
Before describing the argumentation model in detail, we
introduce some necessary notation. Variables and constant
symbols represent items such as the exploits/payloads used
for the attack, and the actors conducting the cyber-attack (in
this case, the teams in the CTF competition). We denote the
set of all variable symbols with V and the set of all constants
with C. For our model we require two subsets of C: Cact , denoting the actors capable of conducting the cyber-operation,
and Cexp , denoting the set of unique exploits used. We use
symbols in all capital letters to denote variables. The running
example is based on a subset of our DEFCON CTF dataset:
Example 1. Consider the following actors and cyberoperations from the CTF data:

300000

200000

100000

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

T-10

T-8

T-7

T-6

T-5

T-4

T-3

T-2

T-1

0

Teams

Unique Attacks

Deceptive Attacks

Figure 1: Number of unique and deceptive attacks directed
towards each team.

Cact

After this pre-processing of the network data packets, we
obtained around 10 million network attacks. There are 20
teams in the CTF competition; in order to attribute an attack to a particular team, apart from analyzing the payloads
used by the team, we also need to analyze the behavior of
the attacking team towards their adversary. For this purpose,
we separate the network attacks according to the team being
targeted. Thus, we have 20 such subsets, which we represent
as T-i, where i ∈ {1, 2, 3, ..., 20}. An example of an event in
the dataset is shown in Table 2.
We now discuss two important observations from the
dataset, which make the task of attributing an observed network attack to a team difficult.
Deception: In the context of this paper we define an attack
to be deceptive when multiple adversaries get mapped to a
single attack pattern. In the current setting we define deception as the scenario in which the same exploit is used by
multiple teams to target the same team. Figure 1 shows the
distribution of unique deception attacks with respect to the
total unique attacks in the dataset based on the target team.
These unique deceptive attacks amount to just under 35% of
the total unique attacks.

Cexp

= {bluelotus, robotmafia, apt8}
= {exploit1 , exploit2 , ..., exploitn }


The language also contains a set of predicate symbols that
have constants or variables as arguments, and denote events
that can be either true or false. We denote the set of predicates with P; examples of predicates are shown in Table 3.
For instance, culprit(exploit1 , bluelotus) will either be true
or false, and denotes the event where bluelotus used exploit1
to conduct a cyber-operation.
A ground atom is composed by a predicate symbol and a
tuple of constants, one for each of the predicate’s arguments.
The set of all ground atoms is denoted as G. A literal L
is a ground atom or a negated ground atom; hence, literals
have no variables. Examples of ground atoms formed using
predicates in Table 3 are shown in the following example.
We denote a subset of G with G0 .

Example 2. The following are examples of ground atoms
over the predicates given in Table 3.
G0 :

Duplicate attacks: A duplicate attack occurs when the same
team uses the same payload to attack a team at different
points in time. Duplicate attacks can be attributed to two reasons. First, when a team is trying to compromise another’s
system, it does not just launch a single attack but a wave
of attacks with very little time difference between consecutive attacks. Second, once a successful payload is created
that can penetrate the defense of other systems, it is used
more by the original attacker as well as the deceptive one as
compared to other payloads. We group duplicates as either
being non-deceptive or deceptive. Non-deceptive duplicates
are the copies of the attacks launched by the team that first
initiated the use of a particular payload; on the other hand,
deceptive duplicates are all the attacks from the teams that
did not initiate the use.

attack(exploit1 , bluelotus),
deception(exploit1 , apt8),
culprit(exploit1 , apt8)

Table 3: Example Predicates and explanation

Argumentation Model
Our approach relies on a model of the world where we
can analyze competing hypotheses in a cyber-operation scenario. Such a model must allow for contradictory informa-

179

Predicate

Explanation

attack(exploit1 , bluelotus)

exploit1 was targeted towards
the team Blue Lotus.

replay attack(E, Y)

Exploit E was replayed by
team Y.

deception(exploit1 , apt8)

Team apt8 used exploit1 for deception.

time diff(I, Y)

Team Y was deceptive within
the given time interval I.

culprit(exploit1 , apt8)

Team apt8 is the likely culprit
for the attack (using exploit1 on
the target team).



We choose a structured argumentation framework (Rahwan, Simari, and van Benthem 2009) to build our argumentation model, which allows for competing ideas to deal
with contradictory information. Due to such characteristics,
argumentation-based models are favorable for cyber-attack
scenarios. Our approach works by creating arguments (in the
form of a set of rules and facts) that compete with each other
to attribute an attack to a given perpetrator. In this case, arguments are defeated based on contradicting information in
other arguments. This procedure is known as a dialectical
process, where the arguments that are undefeated prevail.
An important result is the set of all the arguments that are
warranted (not defeated) by any other argument, which give
a clear map of not only the set of attackers responsible for
the cyber-operation but also the arguments supporting the
conclusion.
The transparency of the model lets a security analyst not
only add new arguments based on new evidence discovered
in the system, but also get rid of incorrect information and
fine-tune the model for better performance. Since the argumentation model can deal with inconsistent information, it
draws a natural analogy to the way humans settle disputes
when there is contradictory information available (Garcı́a
and Simari 2004). The model provides a clear explanation as
to why one argument is chosen over others, which is a desirable characteristic for both the analyst and for organizations
to make decisions and policy changes. We now discuss some
preliminaries for the argumentation model.

Θ:

θ1
θ2
θ3
θ4
θ5

=
=
=
=
=

Ω:

ω1 =
ω2 =

∆:

δ1 =
δ2 =
δ3 =
δ4 =

attack(exploit1 , bluelotus)
first attack(exploit1 , robotmafia)
last attack(exploit1 , apt8))
time diff(interval, robotmafia)
most frequent(exploit1 , pwnies)
culprit(exploit1 , pwnies) ←
most frequent(exploit1 , pwnies),
replay attack(exploit1 )
¬ culprit(exploit1 , robotMafia) ←
last attack(exploit1 , apt8),
replay attack(exploit1 )
replay attack(exploit1 ) -≺
attack(exploit1 , bluelotus),
last attack(exploit1 , apt8)
deception(exploit1 , apt8) -≺
replay attack(exploit1 ),
first attack(exploit1 , robotmafia)
culprit(exploit1 , apt8) -≺
deception(exploit1 , apt8),
replay attack(exploit1 )
¬culprit(exploit1 , apt8) -≺
time diff(interval, robotmafia)

Figure 2: A ground argumentation framework.
the defeasible counterparts of strict rules; they are of the
form L0 -≺ L1 , ...., Ln , where L0 , is the ground literal and
{Li }i>0 is a set of ground literals. Strong negation is allowed for both strict and defeasible rules to represent contradictory information.

Defeasible Logic Programming
DeLP is a formalism that combines logic programming
with defeasible argumentation; full details are discussed
in (Garcı́a and Simari 2004). The formalism is made up of
several constructs, namely facts, strict rules, and defeasible
rules. Facts represent statements obtained from evidence,
and are always true; similarly, strict rules are logical combinations of facts that always hold. On the contrary, defeasible rules can be thought of as strict rules that may be true in
some situations, but could be false if contradictory evidence
is present. These three constructs are used to build arguments. DeLP programs are sets of facts, strict rules and defeasible rules. We use the usual notation to denote DeLP programs: denoting the knowledge base with Π = (Θ, Ω, ∆),
where Θ is the set of facts, Ω is the set of strict rules, and
∆ is the set of defeasible rules. Examples of the three constructs are provided with respect to the dataset in Figure 2
and in the Latent variables section. We now describe the
constructs in detail.
Facts (Θ) are ground literals that represent atomic information or its negation (¬). The facts are always true and cannot
be contradicted.
Strict Rules (Ω) represent cause and effect information that
is always true. They are built from using a combination of
ground literals and are of the form L0 ← L1 , ...Ln , where
L0 is a ground literal and {Li }i>0 is a set of ground literals.
Defeasible Rules (∆) comprise knowledge that can be true
if no contradictory information is provided. These rules are

When a cyber-attack occurs, the model derives arguments
as to who could have conducted the attack. Derivation follows the same mechanism as logic programming (Lloyd
2012). DeLP incorporates defeasible argumentation, which
decides which arguments are warranted and it blocks arguments that are in conflict.
Figure 2 shows a ground argumentation framework
demonstrating constructs derived from the CTF data. For
instance, θ1 indicates the fact that exploit1 was used to target
the team Blue Lotus, and θ5 indicates that team pwnies is the
most frequent user of exploit1 . For the strict rules, ω1 says
that for a given exploit1 the attacker is pwnies if it was the
most frequent attacker and the attack exploit1 was replayed.
Defeasible rules can be read similarly; δ2 indicates that
exploit1 was used in a deceptive attack by APT8 if it was
replayed and the first attacker was not APT8. By replacing
the constants with variables in the predicates we can derive
a non-ground argumentation framework.

Definition 1. (Argument) An argument for a literal L is a
pair hA, Li, where A ⊆ Π provides a minimal proof for L
meeting the requirements: (1) L is defeasibly derived from
A, (2) Θ∪Ω∪∆ is not contradictory, and (3) A is a minimal
subset of ∆ satisfying 1 and 2, denoted hA, Li.

180





A1 , replay attack(exploit1 ) 

A2 , deception(exploit1 , apt8)


A3 , culprit(exploit1 , apt8) 
A4 , ¬culprit(exploit1 , apt8)

A1
A2
A3
A4

= {δ1 , θ1 , θ3 }
= {δ1 , δ2 , θ2 }
= {δ1 , δ2 , δ3 }
= {δ1 , δ4 , θ3 }

Θ:

θ1 =
θ2 =
θ3 =

attack (E, X)
first attack (E, Y)
last attack (E, Y)

Figure 4: Facts defined for each test sample.

Figure 3: Example ground arguments from Figure 2.
while the set of facts and strict rules is consistent (noncontradictory), the set of defeasible rules can be inconsistent. We engineer our cyber-attribution framework as a series of defeasible and strict rules whose structure we have
created, but are dependent on values learned from a historical corpus. Then, for a given incident, we instantiate a set
of facts for that situation. This information is then provided
as input into a DeLP implementation that uses heuristics to
generate all arguments for and against every possible culprit
for the cyber attack. Then, the DeLP implementation creates dialectical trees based on these arguments and decides
which culprits are warranted. This results in a reduced set of
potential culprits, which we then use as input into a classifier
to obtain an attribution decision.

Literal L is called the conclusion supported by the argument, and A is the support. An argument hB, Li is a subargument of hA, L0 i iff B ⊆ A.
The following shows arguments for our running example
scenario.
Example 3. Figure 3 shows example arguments based on
the knowledge base from Figure 2. Note that the following
relationship exists:




A1 , replay attack(exploit1 ) is
 a subargument of
A
,
deception(exploit
,
apt8)
and
2
1 


A3 , culprit(exploit1 , apt8) .


Latent Variables

For a given argument there may be counter-arguments that
contradict it. For instance, referring to Figure 3, we can see
that A4 attacks A3 . A proper defeater of an argument hA, Li
is a counter-argument that—by some criterion—is considered to be better than hA, Li; if the two are incomparable
according to this criterion, the counterargument is said to be
a blocking defeater. The default criterion used in DeLP for
argument comparison is generalized specificity (Stolzenburg
et al. 2003).
A sequence of arguments is referred to as an argumentation line. There can be more than one defeater argument,
which leads to a tree structure that is built from the set of
all argumentation lines rooted in the initial argument. In a
dialectical tree, every child can defeat its parent (except for
the root), and the leaves represent the undefeated arguments.
The tree thus creates a map of all possible argumentation
lines that decide if an argument is defeated


or not.
Given a literal L and an argument A, L , in order to decide whether or not a literal L is warranted, every node in the
dialectical tree T (hA, Li) is recursively marked as “D” (defeated) or “U” (undefeated), obtaining a marked dialectical
tree T ∗ (hA, Li) where:

In (Nunes et al. 2015) we leveraged machine learning techniques on the CTF data to identify the attacker. We will now
provide a summary of the results obtained.
The experiment was performed as follows. We divide the
dataset according to the target team, building 20 subsets, and
all the attacks are then sorted according to time. We reserve
the first 90% of the attacks for training and the remaining
10% for testing. The byte and instruction histograms are
used as features to train and test the model. Models constructed using a random forest classifier performed the best,
with an average accuracy of 0.37. Most of the misclassified
samples tend to be deceptive attacks and their duplicates.
When using machine learning approaches it is difficult to
map the reasons why a particular attacker was predicted, especially in cases of deception where multiple attackers were
associated with the same attack. Knowing the arguments that
supported a particular decision would greatly aid the analyst in making better decisions dealing with uncertainty. To
address this issue we now describe how we can form arguments/rules based on the latent variables computed from the
training data, given an attack for attribution.
We use the following notation: let E be the test attack under consideration aimed at target team X, Y represent all the
possible attacking teams, and D be the set of all deceptive
teams (those using the same payload to target the same team)
if the given attack is deceptive in the training set. For nondeceptive attacks, D will be empty. We note that facts cannot have variables, only constants (however, to compress the
program for presentation purposes, we use meta-variables
in facts). To begin, we define the facts described in Figure 4;
fact θ1 states that attack E was used to target team X, θ2
states that team Y was the first team to use the attack E in the
training data, and similarly θ3 states that team Y was the last
team to use the attack E in the training data. The first and
last attacking team may or may not be the same. We study

• All leaves in T ∗ (hA, Li) are marked as “U”s, and
• Let hB, qi be an inner node of T ∗ (hA, Li). Then, hB, qi
will be marked as “U” iff every child of hB, qi is marked
as “D”. Node hB, qi will be marked as “D” iff it has at
least a child marked as “U”.
Given argument hA, Li over Π, if the root of T ∗ (hA, Li) is
marked “U”, then T ∗ (hA, hi) warrants L and that L is warranted from Π. (Warranted arguments correspond to those
in the grounded extension of a Dung argumentation system
(Dung 1995).)
In practice, an implementation of DeLP accepts as input sets of facts, strict rules, and defeasible rules. Note that

181

Ω:

ω2 =
∆:

δ1 =
δ2 =
δ3 =

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

T-10

T-8

culprit(E, Df ) ← frequent(E, Df ),
deception (E, Di )
¬culprit(E, Y) ← first attack(E, Y),
deception(E, X)

0

T-7

ω1 =

200

T-6

deception (E, X)
frequent (E, Df )

400

T-5

θ1 =
θ2 =

600

Teams

Figure 7: Average time for duplicate attacks for each team.
16000

Average time (sec) to issue deceptive
attack

Θ:

800

T-1

Figure 5: Defeasible and strict rule for non-deceptive attack.

1000

T-4

replay attack(E) -≺ attack(E, X),
last attack(E, Y).

1200

T-3

δ1 =

culprit(E, Y) ← last attack(E, Y),
replay attack(E).

T-2

∆:

ω1 =

Average time (sec) to replay own attacks

Ω:

replay attack(E) -≺ attack(E, X),
last attack(E, Y)
deception(E, Di ) -≺ replay attack(E),
first attack(E, Y)
culprit(E, Di ) -≺ deception(E, Di ),
first attack(E, Y)

14000
12000
10000
8000
6000
4000
2000

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-9

T-11

Figure 6: Facts and rules for deceptive attacks.

T-10

T-8

T-7

T-6

T-5

T-4

T-3

T-2

T-1

0

Teams

Figure 8: Average time for deceptive attacks for each team.
the following three cases:
Case 1: Non-deceptive attacks. In non-deceptive attacks,
only one team uses the payload to target other teams in the
training data. It is easy to predict the attacker for these cases,
since the search space only has one team. To model this situation, we define the set of defeasible and strict rules shown
in Figure 5. Defeasible rule δ1 checks whether the attack was
replayed in the training data—since it is a non-deceptive attack, it can only be replayed by the same team. Strict rule ω1
then puts forth an argument for the attacker (culprit) if the
defeasible rule holds and there is no contradiction for it.

the K nearest neighbors from the training set according to
a simple Euclidean distance between the byte and instruction histograms of the two attacks. In this case we choose
K = 3. For each of the matching attack from the training
data we check if the attack is deceptive or non-deceptive. If
non-deceptive, we follow the procedure for Case 1, otherwise we follow the procedure for Case 2. Since we replace
one unseen attack with three seen attacks, the search space
for the attacker increases for unseen attacks.

Case 2: Deceptive attacks. These attacks form the majority of the misclassified samples in (Nunes et al. 2015). The
set D is not empty for this case; let Di denote the deceptive
teams in D. We also compute the most frequent deceptive
attacker from D. Let the most frequent attacker be denoted
as Df . Figure 6 shows some of the DeLP components that
model this case. Fact θ1 indicates if the attack E was deceptive towards the team X and θ2 indicates the most frequent
attacker team Df from the deceptive team set D. The strict
rules ω1 states that the attacker should be Df if the attack is
deceptive and ω2 indicates that in case of deception the first
attack team Y is not the attacker. For the defeasible rules, δ1
deals with the case in which the attack E was replayed, δ2
deals with the case of deceptive teams from the set D and
δ3 indicates that all the deceptive teams are likely to be the
attackers in the absence of any contradictory information.

Attacker Time Analysis
The CTF data provides us with time stamps for the attacks
in the competition. We can use this information to come up
with rules for/against an argument for a team being the attacker. We compute the average time for a team to replay its
own attack given that it was the first one to initiate the attack (see Figure 7). It can be observed that teams like more
smoked leet chicken (T-13) and Wowhacker-bios (T-8) are
very quick to replay their own attacks as compared to other
teams.
Figure 8 on the other hand shows the average time for a
team to replay an attack initiated by some other team. This
refers to the time the team takes to commit a deceptive attack. Teams like The European (T-7) and Blue lotus (T-10)
are quick to commit deception, while others take more time.
We use this time information to narrow down our search
space for possible attackers. In particular, for a deceptive
test sample, we compute the time difference between the test
sample and the training sample that last used the same payload. We denote this time difference as 4t, and include it

Case 3: Unseen Attacks. The most difficult attacks to attribute in the dataset are the unseen ones, i.e., attacks encountered in the test set that did not occur in the training set.
To build constructs for this kind of attack we first compute

182

9

as a fact θ1 . We then divide the deceptive times from Figure 8 into appropriate intervals; each team is assigned to one
of those time intervals. We then check which time interval
4t belongs to and define a defeasible rule δ1 that makes a
case for all teams not belonging to the interval to not be the
culprits, as shown in Figure 9.
Θ:

θ1 =

timedifference (E, X)

δ1 =

For Y ∈
/ interval:
¬culprit(E, Y) -≺ timedifference (E, X).

Average number of Teams

8
7
6

5
4
3
2
1

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-9

T-10

T-8

T-7

T-6

T-5

T-4

T-3

T-2

Teams

Figure 10: Average Search space after running the query to
compute warranted arguments.

Figure 9: Time facts and rules. Interval indicates a small portion of the entire deceptive time (for instance < 2000 sec.,
> 8000 sec., and so on).

Fraction of test samples with ground
truth

1

Experiments
We use the same experimental setup as in (Nunes et al.
2015). We sort the dataset by time for each target team and
then use the first 90% of the data for training and the rest
10% for testing. We compute the constructs for all test samples based on the cases discussed in the previous section, and
then input these arguments to the DeLP implementation. For
each test sample we query the DeLP system to find all possible attackers (culprits) based on the arguments provided. If
there is no way to decide between contradicting arguments,
these are blocked and thus return no answers. Initially, the
search space for each test sample is 19 teams.
Figure 10 shows the average search space after running
the queries to return set of possible culprits. There is a significant reduction in search space across all target teams. The
average search space is reduced from 19 teams to 5.8 teams
(standard deviation of 1.92). To evaluate how much the reduced search space can aid an analyst in predicting the actual culprit, we compute one more metric—we check if the
reduced search space has the ground truth (actual culprit)
present in it. Figure 11 shows the fraction of test samples
with ground truth present in it. For the majority of the target
teams, we have ground truth present in more than 70% of
the samples with reduced search space. For some teams like
more smoked leet chicken (T-13) and raon ASRT (whois) (T17) the average reduced search space is as low as 1.82 and
2.9 teams, with high ground truth fraction of 0.69 and 0.63
respectively. The reason why there is a large search space
for some teams is the presence of a larger number of unseen
attacks. As discussed earlier, each unseen attack is replaced
by the three most similar attacks from the training set, and
hence the search space becomes larger.
We next perform predictive analysis on the reduced search
space. The experimental setup is similar to the one described
earlier; the only difference is that now instead of having a
19-team search space as in the previous case, the machine
learning approach is allowed to make a prediction from the
reduced search space only. We use random forest as the machine learning approach, which has shown to have the best
performance for CTF data (Nunes et al. 2015). Table 4 gives
a summary of the results.

0.8

0.6

0.4

0.2

T-20

T-19

T-18

T-17

T-16

T-15

T-14

T-13

T-12

T-11

T-10

T-9

T-8

T-7

T-6

T-5

T-4

T-3

T-1

0

T-2

∆:

T-1

0

Teams

Figure 11: Fraction of test samples with the ground truth in
the reduced search space.
We report three accuracies for the 20 teams. “Prev. Acc.”
represents the accuracies achieved after running Random
forest without applying the argumentation based techniques,
as reported in (Nunes et al. 2015). “Acc. (ground truth)” considers only the test samples where ground truth is present
in the reduced search space. With this setting we are able
to correctly predict on average more than 70% of the test
samples, with T-4, T-13 and T-14 having accuracies over
80%. On the other hand, “Acc. (all)” also takes into account
test samples where ground truth was not present in the reduced search space. It is clear that all those test samples will
be misclassified since the ground truth is not present in the
search space at all. Even accounting for those samples, the
average accuracy is 0.5, which is significantly better than the
average accuracy of 0.37 in (Nunes et al. 2015). The results
are statistically significant (t(20) = 6.83, p < 0.01).

Conclusion
In this paper we showed how an argumentation-based framework (DeLP) can be leveraged to improve cyber-attribution
decisions. We demonstrated this concept using the DeLP
framework applied to CTF data, which reduced the set of
potential culprits allowing for greater accuracy when using
a classifier for cyber-attribution.
We are currently looking at implementing our probabilistic variant of DeLP (Shakarian et al. 2015b), which assigns
probabilities to the arguments, helping in this way to decide
which arguments prevail when contradictory information is

183

Table 4: Summary of Results
Team

Acc. (ground
truth)

Acc. (all)

Prev.
Acc.

T-1

0.69

0.51

0.45

T-2

0.72

0.45

0.22

T-3

0.55

0.40

0.30

T-4

0.81

0.44

0.26

T-5

0.68

0.45

0.26

T-6

0.62

0.49

0.5

T-7

0.70

0.53

0.45

T-8

0.75

0.61

0.42

T-9

0.68

0.50

0.41

T-10

0.77

0.42

0.30

T-11

0.62

0.44

0.37

T-12

0.76

0.43

0.24

T-13

0.85

0.63

0.35

T-14

0.71

0.52

0.42

T-15

0.57

0.38

0.30

T-16

0.68

0.48

0.43

T-17

0.80

0.58

0.42

T-18

0.68

0.50

0.48

T-19

0.70

0.51

0.41

T-20

0.74

0.51

0.48

programming and n-person games. Artificial intelligence
77(2):321–357.
Garcı́a, A. J., and Simari, G. R. 2004. Defeasible logic programming: An argumentative approach. Theory and practice of logic programming 4(1+ 2):95–138.
Lloyd, J. W. 2012. Foundations of logic programming.
Springer Science & Business Media.
Nunes, E.; Kulkarni, N.; Shakarian, P.; Ruef, A.; and Little,
J. 2015. Cyber-deception and attribution in capture-the-flag
exercises. In Proceedings of the 2015 International Symposium on Foundation of Open Source Intelligence and Security Informatics (FOSINT-SI).
Rahwan, I.; Simari, G. R.; and van Benthem, J. 2009. Argumentation in artificial intelligence, volume 47. Springer.
Rid, T., and Buchanan, B. 2015. Attributing cyber attacks.
Journal of Strategic Studies 38(1-2):4–37.
Shakarian, P.; Simari, G. I.; Moores, G.; and Parsons, S.
2015a. Cyber attribution: An argumentation-based approach. In Cyber Warfare. Springer. 151–171.
Shakarian, P.; Simari, G. I.; Moores, G.; Paulo, D.; Parsons,
S.; Falappa, M.; and Aleali, A. 2015b. Belief revision in
structured probabilistic argumentation. Annals of Mathematics and Artificial Intelligence 1–43.
Shakarian, P.; Shakarian, J.; and Ruef, A. 2013. Introduction
to cyber-warfare: A multidisciplinary approach. Newnes.
Stolzenburg, F.; Garcı́a, A. J.; Chesnevar, C. I.; and Simari,
G. R. 2003. Computing generalized specificity. Journal of
Applied Non-Classical Logics 13(1):87–113.
Walls, R. J. 2014. Inference-based Forensics for Extracting Information from Diverse Sources. Ph.D. Dissertation,
University of Massachusetts Amherst.

present. We are also designing our own CTF event in order
to obtain more realistic data.

Acknowledgments
Authors of this work were supported by the U.S. Department of the Navy, Office of Naval Research, grant N0001415-1-2742 as well as the Arizona State University Global
Security Initiative (GSI) and funds provided by CONICET
and Universidad Nacional del Sur, Argentina. Any opinions,
findings, and conclusions or recommendations expressed in
this material are those of the author(s) and do not necessarily
reflect the views of the Office of Naval Research.

References
Boebert, W. E. 2010. A survey of challenges in attribution.
In Proceedings of a workshop on Deterring CyberAttacks,
41–54.
Dacier, M.; Pham, V.-H.; and Thonnard, O. 2009. The wombat attack attribution method: some results. In Information
Systems Security. Springer. 19–37.
DEFCON. 2013. Defcon: Capture the flag.
Dung, P. M. 1995. On the acceptability of arguments
and its fundamental role in nonmonotonic reasoning, logic

184

Annotated Probabilistic Temporal Logic: Approximate
Fixpoint Implementation
PAULO SHAKARIAN, GERARDO I. SIMARI, and V. S. SUBRAHMANIAN,
University of Maryland, College Park

Annotated Probabilistic Temporal (APT) logic programs support building applications where we wish to
reason about statements of the form “Formula G becomes true with a probability in the range [L, U] within
(or in exactly) t time units after formula F became true.” In this paper, we present a sound, but incomplete
fixpoint operator that can be used to check consistency and entailment in APT logic programs. We present
the first implementation of APT-logic programs and evaluate both its compute time and convergence on
a suite of 23 ground APT-logic programs that were automatically learned from two real-world data sets.
In both cases, the APT-logic programs contained up to 1,000 ground rules. In one data set, entailment
problems were solved on average in under 0.1 seconds per ground rule, while in the other, it took up to 1.3
seconds per ground rule. Consistency was also checked in a reasonable amount of time. When discussing
entailment of APT-logic formulas, convergence of the fixpoint operator refers to (U − L) being below a certain
threshold. We show that on virtually all of the 23 automatically generated APT-logic programs, convergence
was quick—often in just 2-3 iterations of the fixpoint operator. Thus, our implementation is a practical first
step towards checking consistency and entailment in temporal probabilistic logics without independence or
Markovian assumptions.
Categories and Subject Descriptors: I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods—Temporal logic; I.2.3 [Artificial Intelligence]: Deduction and Theorem Proving—
Probabilistic reasoning
General Terms: Algorithms, Languages
Additional Key Words and Phrases: Probabilistic and temporal reasoning, threads, frequency functions,
imprecise probabilities
ACM Reference Format:
Shakarian, P., Simari, G. I., and Subrahmanian, V. S. 2012. Annotated probabilistic temporal logic: Approximate fixpoint implementation. ACM Trans. Comput. Logic 13, 2, Article 13 (April 2012), 33 pages.
DOI = 10.1145/2159531.2159535 http://doi.acm.org/10.1145/2159531.2159535

1. INTRODUCTION

There are numerous applications where we need to make statements of the form:
Formula G becomes true with 50–60% probability 5 time units after formula F became
P. Shakarian is currently affiliated with US Military Academy.
G. I. Simari is currently affiliated with the University of Oxford.
P. Shakarian is funded under the US Army ACS/West Point Instructor (EECS) program.
Some of the authors of this article were funded in part by AFOSR grant FA95500610405, ARO grant
W911NF0910206, and ONR grant N000140910685.
Authors’ addresses: P. Shakarian, Department of Electrical Engineering and Computer Science, US Military
Academy, Thayer Hall (Bldg. 601), West Point, NY 10996; email: paulo@shakarian.net; G. I. Simari, Department of Computer Science, University of Oxford, Oxford OXI 3QD, UK; email: gerardo.simari@cs.ox.ac.uk;
V. S. Subrahmanian, University of Maryland, College Park, MD; email: vs@umiacs.umd.edu.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for profit or commercial advantage and that
copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights
for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of
this work in other works requires prior specific permission and/or a fee. Permissions may be requested from
the Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, USA, fax +1 (212)
869-0481, or permissions@acm.org.
c 2012 ACM 1529-3785/2012/04-ART13 $10.00

DOI 10.1145/2159531.2159535 http://doi.acm.org/10.1145/2159531.2159535

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13

13:2

P. Shakarian et al.

Fig. 1. Kstock , an example APT-Logic Program about stocks.

true. Statements of this kind arise in a wide variety of application domains. These
are some examples.
(1) When reasoning about stock markets, we might automatically learn rules (using
machine learning algorithms) such as: There is a 70 − 80% probability of a drop in
the Dow Jones index within 3 days of the release of a report showing an increase
in unemployment. An example of an APT-program for reasoning about stocks is
shown in Figure 1.
(2) When we wish to reason about environmental phenomena, we might wish to express statements such as: There is a 20–30% probability that over 1,000 birds will
die within 3 days of an oil spill.
(3) Likewise, when reasoning about medical treatments, we might automatically learn
rules from historical data saying things such as: There is a 0–5% probability that
a patient will experience vomiting within 5 days of beginning a course of drug D.
(4) In military applications, an officer might wish to reason about the relationship between our actions (or those of an adversary) and subsequent actions that might
occur. Figure 2 provides an example set of APT rules derived from real-world
counter-insurgency data describing how attacks, weapons cache discoveries, and
detainments are temporally related and dependent on each other.
(5) When reasoning about a terrorist group, a counterterror analyst may wish to understand the relationship between when a condition was true in the environment
in which the group operates and when the group carries out a certain action.
Figure 3 provides a set of APT rules we have extracted automatically.
While logic programmers wrote such rules manually in the past, today we can
automatically learn them from historical data, leading to a resurgence of work
in probabilistic logic and probabilistic logic programs. These rules mix time and
probabilities. Temporal probabilistic logic programs (or tp-LPs) [Dekhtyar et al.
1999] provide a framework within which we can express rules of the form “If some
condition is true, then some atom is true at some time (or time interval) with some
probability distribution over the points in the time interval.” Dekhtyar et al. [1999]
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:3

Fig. 2. K ISW an APT-Logic Program extracted from counterinsurgency data.

provided a syntax and semantics for tp-LPs and provided important complexity
results. Heterogeneous temporal probabilistic agents (HTP-agents) [Dix et al. 2006]
allow us to make statements about the permissions/obligations and forbidden actions
that an agent may take at future times if some condition is true now or in the future.
Though temporal probabilistic logics have been studied extensively for many years,
there is less work on temporal probabilistic logic programs and, until this article,
there has not been a single prototype implementation and/or experimental result.
This article builds upon recent work on Annotated Probabilistic Temporal (APT)
logic programs [Shakarian et al. 2011] which defines a syntax and semantics for APT
LPs, together with algorithms to check consistency and entailment of formula by an
APT LP K. Although sound and complete, the algorithms of [Shakarian et al. 2011],
are not practical for general problems. This article takes a more practical approach.
We develop a fixpoint operator for APT-logic that we prove to be sound. We can use this
operator to correctly identify many inconsistent APT-programs, although we cannot
guarantee a program to be consistent by this means. Additionally, this operator can
infer probability ranges for queries, but we cannot guarantee that they are the tightest
possible bounds. Most importantly, finding the fixpoint of this operator is efficient to
compute. We also show that some of the techniques can also be adopted in a sound
algorithm for nonground APT-programs, where we only require a partial grounding.
We also implement both algorithms and perform experiments on two datasets: the
well-known Minorities at Risk Organization Behavior (MAROB) dataset [Asal et al.
2008] that tracks behaviors of numerous terror groups, and another real-world data
counter-insurgency data from the Institute for the Study of War [ISW 2008] (ISW). We
used the algorithm APT-EXTRACT in Shakarian et al. [2011] to automatically learn
23 APT-logic programs; no bias exists in these APT-logic programs as no one manually
wrote them. We then conducted experiments using those APT-logic programs and
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:4

P. Shakarian et al.

Fig. 3. KMAROB an APT-Logic Program extracted from Minorities at Risk Organizational Behavior data.

entailment problems were solved on an average in under 0.1 seconds per ground
rule, while in the other, it took up to 1.3 seconds per ground rule. Consistency was
also checked in a reasonable amount of time. To the best of our knowledge, ours
is the first implementation of a system for reasoning simultaneously about logic,
time, and probabilities without making independence or Markovian assumptions.
Shakarian et al. [2011] has demonstrated that Markov Decision Processes (MDPs)
can be expressed as APT-logic programs, but not vice versa, and similar results were
also derived for logics like PCTL [Aziz et al. 1995; Hansson and Jonsson 1994] that do
make independence assumptions.
The article is organized as follows. Section 2 recalls the definition of APT LPs
from Shakarian et al. [2011] and add syntax for integrity constraints (ICs) as well as
probabilistic time formulas (ptf ’s); a generalization of the “annotated formulas” from
Dekhtyar et al. [1999] and Shakarian et al. [2011]. The material after Section 2 is
new. Section 3 shows that consistency and entailment in APT-logic are NP-complete
and coNP-complete, respectively, improving on a previous hardness result [Shakarian
et al. 2011]. Section 4 describes our approximate fixpoint algorithm which is based
on a sound (but not complete) fixpoint operator. The operator works by syntactically
manipulating the rules in the APT-program to iteratively tighten the probability
bounds of the formula whose entailment is being checked. We adapt the techniques
for a consistency-checking and entailment algorithms for nonground APT-programs in
Section 5 (note that these algorithms do not require a full grounding of a program).
In Section 6 we present our implementation of the fixpoint approach to solving
consistency and entailment problems for ground programs. Finally, in Section 7, we
provide an overview of related work.
Before continuing, we note that applications such as those we have mentioned use
automated rule learning (e.g., using the APT-Extract algorithm of Shakarian et al.
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:5

[2011]) to automatically learn relationships and correlations between atoms. In particular, the existence of specific such relationships make independence and Markovian
assumptions invalid for these types of applications.
2. TECHNICAL BACKGROUND

This section recapitulates the syntax and semantics of APT LPs from Shakarian et al.
[2011]; with the exception of integrity constraints and probabilistic time formulas, this
section does not contain new material.
2.1. Syntax

We assume the existence of a logical language L, with a finite set Lcons of constant
symbols, a finite set Lpred of predicate symbols, and an infinite set Lvar of variable
symbols. Each predicate symbol p ∈ Lpred has an arity (denoted arity(p)). We also
assume the existence of a finite set F whose members are called frequency function
symbols [Shakarian et al. 2011]; these are new to APT-logic and, to our knowledge,
have not been studied before. A (ground) term is any member of Lcons ∪ Lvar (resp.
Lcons ); if t1 , . . . , tn are (ground) terms, and p ∈ Lpred has arity n, then p(t1 , . . . , tn) is a
(resp. ground) atom. We use BL to denote the Herbrand base (set of all ground atoms)
of L. It is easy to see that BL is finite. Formulas are defined as follows: A (ground)
atom is a (ground) formula. If F1 and F2 are (ground) formulas, then F1 ∧ F2 , F1 ∨ F2 ,
and ¬F1 are (ground) formulas.
We assume that all applications are interested in reasoning about an arbitrarily
large, but fixed size window of time, and that τ = {1, . . . , tmax } denotes the entire set of
time points we are interested in. tmax can be as large as an application user wants, and
the user may choose his granularity of time according to his needs.
Definition 2.1 Time Formula. A time formula is defined as follows.
— If F is a (ground) formula and t ∈ [1, tmax ] then F : t is an (ground) elementary time
formula.
— If φ, ρ are (ground) time formulas, then ¬φ, φ ∧ρ, and φ ∨ρ are (respectively, ground)
time formulas.
Example 2.1. Consider the ground atoms in the APT-program from Figure 1. The
expression (¬sec rumor ∧ ¬rum incr(10%) ∧ ¬stock decr(10%) ∧ ¬cfo resigns) : 1 is an
elementary time formula.
Throughout, we will use Greek letters φ, ρ for time formulas and capital letters
F, G for regular formulas. We now extend a time formula to include a probability
annotation.
Definition 2.2. If φ is a (ground) time formula and [, u] ⊆ [0, 1], then φ : [, u] is a
(respectively, ground) probabilistic time formula, or ptf for short.
Note that when considering ptf ’s of the form F : t : [, u], we will sometimes abuse
notation and write F : [t, , u].
Example 2.2. Item 5 in the APT-program from Figure 1 is a ptf.
Intuitively, φ : [, u] says time formula φ is true with a probability in [, u].1
Throughout the article we assume, for both ptf ’s and APT-rules, that the numbers , u can
be represented as rationals a/b where a and b are relatively prime integers and the length of the binary
representations of a and b is fixed.

1 Assumption.

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:6

P. Shakarian et al.

A word on probability intervals. The reader may notice immediately that APT-logic does
not use point probabilities but instead probability intervals. There are two purposes
for this. First, if extracting ptf ’s or rules from historical data (as we do in our experiments), it is often the case that probability is determined within a certain range (i.e.,
“the probability of event X is 45% + / − 5%”). The second purpose for using intervals
rather than point probabilities is that when reasoning without independence assumptions, it is often only possible to obtain a bound on the probability rather than a single
value.

Definition 2.3 Integrity constraint. Suppose A i ∈ BL and [loi, upi] ⊆ [0, tmax ]. Then
OCC(A i) : [loi, upi] is called an occurrence IC. If blki ∈ [2, tmax + 1] is an integer, then
BLK(A i) :< blki is called a block-size IC. If A i is ground then the occurrence (resp.
block-size) IC is ground, otherwise it is nonground.
An occurrence IC OCC(A i) : [loi, upi] says that A must be true at least loi times and
at most upi times. Likewise, the block-size IC says that A cannot be consecutively true
for blki or more time points. Figure 1 also contains an example occurrence IC and an
example block-size IC.
Example 2.3 Integrity Constraints. Consider the ground atoms in the APT-program
from Figure 1 and tmax = 6. Suppose historical data indicates that for a sequence of 6
days, there is never more than 1 day where the CFO resigns. Hence, we should add the
constraint OCC(cfo resigns) : [0, 1] to the program. There are other types of integrity
constraints that could be useful in this domain. For example, a drastic stock price
decrease may never occur more than a few times a quarter.
To see why block-size constraints are natural, consider the ground atom sec rumor.
Suppose there is never more than 3 days historically where an SEC rumor is reported.
This would make the constraint BLK(sec rumor) :< 4 appropriate. Other examples of
such constraints in this domain would be reports of profits, which only occur once per
quarter (i.e., we would have blk = 2 for such a case).
We have automatically extracted APT-programs from the ISW and MAROB datasets
mentioned earlier. In the case of the ISW dataset, occurrence and block-size constraints are needed because militant groups have constrained resources, that is, a
limited amount of personnel and munitions to carry out an attack. Hence, an occurrence integrity constraint can limit the amount of attacks we believe they are capable
of in a given time period. Likewise, such groups often limit the number of consecutive attacks, as police and military often respond with heightened security. Block-size
constraints allow us to easily encode this into our formalism.
Definition 2.4 APT Rules and Programs. (i) Suppose F, G are (ground) formulas, t
is a time interval, [, u] is a probability interval, and fr ∈ F is a frequency function
fr

symbol. Then F ; G : [t, , u] is an (ground) APT rule.
(ii) An (ground) APT logic program is a finite set of (ground) APT rules, ptf ’s, and
integrity constraints.
(iii) Given a nonground APT-logic program K(ng) , the set of ground instances of all rules,
ptf ’s, and IC’s in K(ng) is called the grounding of K(ng) .
Note. Unless specified otherwise, throughout this article, APT-logic programs, rules,
IC’s, and ptf ’s are ground.

Example 2.4. Figure 1 shows a small APT LP dealing with the stock market,
together with an intuitive explanation of each rule.
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:7

fr

We would like to point out that for an APT-rule F ; G : [t, , u], there is no
dependence implied or expressed between worlds satisfying formulas F and G. This
follows directly from our semantics (described in the next section). A similar implication known as the “leads-to” operator is described in the probabilistic computational
tree logic (PCTL) of Hansson and Jonsson [1994]. However, unlike an APT-rule, the semantics of this operator is completely different as the satisfying structure is a Markov
Process in that case, which make independence assumptions between nonconsecutive
transitions. In Shakarian et al. [2011], we provided a detailed comparison between
APT-logic and PCTL.
2.2. Semantics

We now recapitulate the semantics of APT LPs from Shakarian et al. [2011].
Definition 2.5 World. A world is any set of ground atoms.
The power set of BL (denoted 2 BL ) is the set of all possible worlds. Intuitively, a world
describes a possible state of the (real) world phenomenon being modeled by an APTlogic program. As worlds are just ordinary Herbrand interpretations [Lloyd 1987], we
use w |= F to denote the standard definition of satisfaction of a ground formula F by
world w as expressed in Lloyd [1987]. We say world w satisfies nonground formula F
iff w satisfies all ground instances of F. A thread is a standard temporal interpretation
[Emerson and Halpern 1984; Lamport 1980].
Definition 2.6 Thread. A thread is a mapping Th : {1, . . . , tmax } → 2 BL .
Th(i) says that according to thread Th, the world at time i will be Th(i). We use T to
denote the set of all possible threads, and Th∅ to denote the “null” thread which assigns
∅ to all time points. A thread represents a possible way the domain being modeled will
evolve over all time points.
Definition 2.7. (i) Given thread Th and ground time formula φ, we say Th satisfies
φ (written Th |= φ) iff:
—φ
—φ
—φ
—φ

≡ F : t: Th |= φ iff Th(t) |= F
≡ ¬ρ: Th |= φ iff Th 
|= ρ
≡ ρ ∧ ρ  : Th |= φ iff Th |= ρ and Th |= ρ 
≡ ρ ∨ ρ  : Th |= φ iff Th |= ρ or Th |= ρ 

(ii) Given thread Th and ground occurrence IC OCC(A i) : [loi, upi], we say Th satisfies
OCC(A i) : [loi, upi] iff |{i | Th(i) |= A i}| ∈ [loi, upi].
(iii) Given thread Th and block-size IC BLK(A i) :< blki, we say Th satisfies BLK(A i) :<
blki iff there does not exist an interval [i, i + blki − 1] such that for all j ∈ [i, i + blki − 1],
Th( j) |= A i.
(iv) Th satisfies a nonground formula or IC iff it satisfies all its ground instances.
Given a set T of threads and a set IC of integrity constraints, we use T (IC) to refer to
the set {Th ∈ T |Th |= IC}.
We use the symbol |= to denote entailment between two time formulas.
Definition 2.8. Given time formulas φ, ρ, we say: φ |= ρ iff ∀Th ∈ T s.t. Th |= φ, it is
the case that Th |= ρ.
If we view time formulas as sets of threads, we can think of φ |= ρ, as equivalent to
φ ⊆ ρ. A temporal probabilistic (tp) interpretation gives us a probability distribution
over all possible threads.
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:8

P. Shakarian et al.

Definition 2.9 Temporal-Probabilistic Interpretation. A temporal-probabilistic (tp)
interpretation
I is a probability distribution over the set of all possible threads, that

is, th∈T I(th) = 1.
Thus, a tp-interpretation I assigns a probability to each thread. This reflects the probability that the world will in fact evolve over time in accordance with what the thread
says. We now define what it means for a tp-interpretation to satisfy a ptf or integrity
constraint.
Definition 2.10. (i) Given interpretation I and ptf φ : [, u], we say I satisfies φ :
[, u] (written I |= φ : [, u]) iff:

≤
I(Th) ≤ u.
Th∈T
Th|=φ

(ii) Given interpretation I and occurrence IC OCC(A i) : [loi, upi], we say I satisfies
OCC(A i) : [loi, upi] (written I |= OCC(A i) : [loi, upi]) iff ∀Th ∈ T s.t. Th 
|= OCC(A i) :
[loi, upi], it is the case that I(Th) = 0.
(iii) Given interpretation I and block-size IC BLK(A i) :< blki, we say I satisfies
BLK(A i) :< blki (written I |= BLK(A i) :< blki) iff ∀Th ∈ T s.t. Th 
|= BLK(A i) :< blki,
it is the case that I(Th) = 0.
(iv) Interpretation I satisfies a nonground formula or IC iff it satisfies all ground
instances of it.
With this definition, we now define a special type of ptf that can be used to specify
a set of threads that start with the same worlds; the intuition is based on the idea of a
prefix in Cleaveland et al. [2005].
Definition 2.11. For n ≤ tmax , let F1 , . . . , Fi, . . . , Fn be formulas s.t. each Fi is satisfied by exactly one world. Then, the following ptf:
F1 : 1 ∧ · · · ∧ Fi : i ∧ . . . ∧ Fn : n : [1, 1]
is called a prefix.
Example 2.5. Item 5 in the APT-program from Figure 1 is a prefix.
Intuitively, including a prefix in an APT-program forces the first n worlds of every
thread assigned a nonzero probability to satisfy certain formulas. Further, we can use
a prefix to force the first n worlds of every thread with a nonzero probability to be the
same. For example, if we want the i’th world of thread Th
to world w, we
to be set
would simply use the following formula as Fi in the prefix:
a∈w a ∧
a/
∈w ¬a .
As shown in Shakarian et al. [2011], one of the ways APT-logic separates itself from
past work is the introduction of the frequency function. The basic idea behind a frequency function is to represent temporal relationships within a thread. For instance,
we are interested in the frequency with which G will be true t units after F is true.
When we study this w.r.t. a specific thread Th, we need to identify when F was true in
thread Th, and whether G really was true t units after that. Consider Figure 5, there
are many ways to determine the frequency at which a world satisfying F is followed
by world satisfying G within a certain number of time steps.
— The probability (within the thread of Figure 5) that G follows F in exactly two units
of time is 0.67 if we ignore the occurrence of F at time 8. If on the other hand, we
count the occurrence of F at time 8 (even though no times beyond that are possible),
then the probability that G follows F in exactly two units of time is 0.5.
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:9

Fig. 4. Ktrain , an APT-Logic Program modeling rail transit. Items 1-2 are nonground APT-Rules, the
formulas in 3 are probabilistic temporal formulas, and items 4-5 are annotated formulas. The English
translation of each rule is also provided.

Fig. 5. Example thread, Th with worlds Th(1), . . . , Th(8). This figure shows each world that satisfies
formula F or formula G.

— The probability that G follows F in at most 2 units of time is 1.0 if we ignore the
occurrence of F at time 8; otherwise it is 0.75 (this would be an example of the
frequency function efr, described later).
Each of these intuitions leads to different ways to measure the frequency (within a
thread) with which G follows F.2 Hence, rather than adhering to a single definition of
what it means for F to be followed by G, we define this relationship in terms of axioms.
Therefore, the use of frequency functions allow us to parameterize this relationship.
Definition 2.12 Frequency Function. Let Th be a thread, F and G be ground
formulas, and t > 0 be an integer. A frequency function fr maps quadruples of the
form (Th, F, G, t) to [0, 1] such that the following axioms hold:
(FF1). If G is a tautology, then fr(Th, F, G, t) = 1.
(FF2). If F is a tautology and G is a contradiction, then fr(Th, F, G, t) = 0.
(FF3). If F is a contradiction, fr(Th, F, G, t) = 1.
(FF4). If G is not a tautology, and either F or ¬G is not a tautology, and F is not a
contradiction, then there exist threads Th1 , Th2 ∈ T such that fr(Th1 , F, G, t) = 0 and
fr(Th2 , F, G, t) = 1.
Axiom FF1 says that if G is a tautology, then fr(Th, F, G, t) must behave like
material implication and assign 1 to the result. Likewise, if F is a tautology and G is
a contradiction, then FF2 says that fr(Th, F, G, t) must behave like implication and
2 Note. Throughout this article, we assume that frequency functions can be computed in polynomial time
(i.e., O(|BL | · tmax )). We also assume that frequency functions return rational numbers and that the length
of the binary representations of a and b is fixed.

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:10

P. Shakarian et al.

have a value of 0 (A → B is false when A is a tautology and B is a contradiction).
Axiom FF3 requires fr(Th, F, G, t) to be 1 when F is a contradiction, also mirroring
implication. Axiom FF4 ensures that in all cases not covered already, the frequency
function will be nontrivial by allowing at least one thread that perfectly satisfies
(probability 1) and perfectly contradicts (probability 0) the conditional. Note that any
function not satisfying Axiom FF4 can be made to do so as long as it returns distinct
values: simply map the lowest value returned to 0 and the highest value returned to 1.
Shakarian et al. [2011] provide several different frequency functions corresponding
to different intuitions that satisfy the given axioms. For the sake of simplicity and
due to space constraints, in this article we use the existential frequency function from
Shakarian et al. [2011]. The key intuition behind this frequency function is to represent how often a world satisfying formula F is followed by a world satisfying formula
G. We also provide special treatment of the boundary condition in this definition, that
is where F is satisfied by worlds after time tmax − t. If F is satisfied by a world after this time, we do not include it in the denominator unless it is followed by G. The
reason for this is that the thread ends at tmax , hence we have no knowledge of events
after this point. As a result, when a world satisfies F after time tmax − t without being
followed by a world in the thread satisfying G, we have no knowledge as to whether
an event represented by G occurred within t time units later.
Of course, there are other definitions of efr that are possible. For instance, perhaps
there are some applications where it makes sense to not consider this boundary case.
This is why frequency functions are defined axiomatically. The majority of the results
in this article do not hinge on efr; when they do, we make a note of it.
Definition 2.13 Existential Frequency Function. Let Th be a thread, F and G be
formulas, and t ≥ 0 be an integer. An Existential Frequency Function, denoted
efr(Th, F, G, t), is defined as follows:3
efn(Th, F, G, t, 0, tmax )

efr(Th, F, G, t) = 
.
{t : (t ≤ tmax − t) ∧ Th(t) |= F} + efn(Th, F, G, t, tmax − t, tmax )

If the denominator is zero (if there is no t ∈ [0, tmax − t] such that Th(t) |= F and
efn(Th, F, G, t, tmax − t, tmax ) = 0), then we define efr to be 1.
In Shakarian et al. [2011], we show that efr satisfies Axioms FF1-FF4. We are now
ready to define satisfaction of an Annotated Probabilistic Temporal (APT) rule.
fr

Definition 2.14 Satisfaction of APT rules. Let r = F ; G : [t, , u] be an APT rule
and I be a tp-interpretation.
(i) If r is a ground rule, interpretation I satisfies r (denoted I |= r) iff

I(Th) · fr(Th, F, G, t) ≤ u.
≤
Th∈T

(ii) Interpretation I satisfies a nonground rule r iff I satisfies all ground instances of r.
Interpretation I satisfies an APT-program iff it satisfies all rules, ptf ’s, and IC’s in
that program. Given an APT-program K, we will often refer to the set of integrity
constraints in K as simply IC.
fr

Intuitively, the APT rule F ; G : [t, , u] evaluates the probability that F leads
to G in t time units as follows: for each thread, it finds the probability of the thread
efn(Th, F, G, t, t1 , t2 ) = |{t : (t1 ≤ t ≤ t2 ) and Th(t) |= F and there exists t ∈ [t + 1, min(t2 , t + t)] such
that Th(t ) |= G}|.

3 Where

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:11

according to I and then multiplies it by the frequency (in terms of fraction of times)
with which F is followed by G in t time units according to frequency function fr. This
product is like an expected value in statistics where a value (frequency) is multiplied
by a probability (of the thread). It then sums up these products across all threads.
To our knowledge, APT-rules represent the first time an attempt to reason about
frequencies within threads in the temporal-probabilistic logic and LP literature.
Definition 2.15 Entailment/consistency. An APT-LP K is consistent iff there is at
least one interpretation that satisfies K. K entails ptf φ : [, u] iff every interpretation
that satisfies K also satisfies φ : [, u].
3. COMPLEXITY

Shakarian et al. [2011] showed that consistency and entailment in APT-logic is
NP-hard (consistency) and coNP-hard (entailment). In this section, we prove that
consistency is in NP and entailment is in coNP. The result is somewhat surprising,
because the exact algorithms presented in Shakarian et al. [2011] relied on the
solution to linear programs with an exponential number of variables. For example,
consider the following linear program.
Definition 3.1 CONS. Given an APT-logic program, K, where IC ⊂ K is the set of
integrity constraints in K, we can create the linear constraints CONS(K) as follows.
For each Th j ∈ T (IC), variable v j denotes the probability of thread Th j.
(1)

|T (IC)|
j=1
fr
∀Fi ;i

vj = 1

|T (IC)|
G i : [ti, i, ui] ∈ K (a) i ≤ j=1 fri(Th j, Fi, G i, ti) · v j
|T (IC)|
(b) ui ≥ j=1 fri(Th j, Fi, G i, ti) · v j

(3) ∀φi : [i, ui] ∈ K
(a) i ≤ Th j∈T (IC)
vj
Th j|=φi

(b) ui ≥ Th j∈T (IC)
vj
(2)

Th j|=φi

Shakarian et al. [2011] proved the following.
P ROPOSITION 3.2. K is consistent iff there is a solution to CONS(K).
Given ptf φ : [, u], let L be the minimization and U be the maximization of

v j subject to CONS(K). Then φ : [, u] is entailed by K iff [L, U] ⊆ [, u].
Th j∈T (IC)
Th j|=φ

However, it turns out that we can be guaranteed a solution to the linear program where
only a polynomial number of the variables are set to a value other than 0. Consider the
following theorem from [Chvtal 1983] and later used in [Fagin et al. 1990] to show that
deciding the validity of a formula in the logic of Fagin et al. [1990] is NP-Complete.
T HEOREM 3.3 [C HVTAL 1983; FAGIN ET AL . 1990]. If a system of m linear equalities and/or inequalities has a nonnegative solution, then it has a nonnegative solution
with at most m positive variables.
We can leverage the previous two results to guarantee the existence of an interpretation that assigns a zero probability to all but a polynomial number of threads, thus
giving us a “small model” theorem.
T HEOREM 3.4. Deciding if APT-program K is consistent is NP-complete if |K| is a
polynomial in terms of |BL |.
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:12

P. Shakarian et al.

T HEOREM 3.5. Deciding if APT-rule r is entailed by APT-program K is coNPcomplete if |K| is a polynomial in terms of |BL |.
One may wonder if APT-programs can be made more tractable if we assume a single
probability distribution over threads, that is a single tp-interpretation. Unfortunately,
even if we assume a uniform probability distribution, this special case is still not
tractable.
T HEOREM 3.6. Given APT-program K, interpretation I, and ptf φ, determining the
maximum  and minimum u such that φ : [, u] is entailed by K and is satisfied by
I is #P-hard. Furthermore, for constant  > 0, approximating either the maximum 
1−
and/or minimum u within 2|BL | is NP-Hard.
Theorem 3.6 is proved using an interpretation that assigns a uniform probability
across all threads. The negative approximation result follows from a result of Roth
[1996].
In Shakarian et al. [2011], we examined hardness results and provided various sets
of linear constraints for solving APT-logic consistency and entailment problems exactly. Methods to approximate the entailment problem within a certain factor were not
examined in that paper. Although it remains an open question if the APT-entailment
problem (without the single-interpretation requirement) can be approximated in this
manner, this result is not encouraging.4 Further, Definition 3.1 illustrates several
challenges relating the intractability of this problem. (i) First, we need to compute
T (IC), which is a challenge because T contains 2tmax ·|BL | possible threads and each
must be examined to see if it satisfies IC; (ii) Second, the constraints in items (1-2)
may contain up to O 2tmax ·|BL | variables (this bound can be tightened), so even though
linear programming is polynomial [Karmarkar 1984], the input is exponential in the
size of tmax and BL . In practice, even if we consider tmax = 10 and BL to consist of just
100 ground atoms, we are looking at the possibility of examining 21,000 threads to find
T (IC) and writing constraints containing exponentially large numbers of variables. In
practice, we will not be able to even write these constraints. With these intractability
results in mind, we proceed to develop heuristics in the next two sections.
4. A SOUND BUT INCOMPLETE FIXPOINT-COMPUTATION ALGORITHM: THE GROUND CASE

This section presents a heuristic algorithm based on a fixpoint operator  which maps
APT-programs to APT-programs and iteratively tightens the probability bounds on
rules and ptf ’s in the program. To find probability bounds on some time formula φ,
we simply add the ptf φ : [0, 1] to the program, iteratively apply  until a fixed point is
reached, and then examine the bounds on the ptf formed with φ in the resulting program. Our approach is sound; so, if the interval [, u] is assigned to φ, then K entails
φ : [, u] (provided, of course, that K is consistent). However, there may exist some
[ , u ] ⊂ [, u] such that φ : [ , u ] is also entailed.
Our algorithm requires that K contain at least one APT-rule of the form F : [, u].
This is not really a restriction in most applications where a prefix would exist (cf.
Definition 2.11). The rest of the section is organized as follows. Section 4.1 describes
how to find bounds on a frequency function given ptf’s. Section 4.2 describes how to use
frequency bounds to syntactically manipulate rules and ptf ’s in APT-programs, which
in turn allow us to tighten the probability bounds. Section 4.3 performs various syntactic manipulations in the  operator and shows that the operator has a least fixed point.
Finally, Section 4.4 demonstrates how  can also be used to check the consistency of
4 As an aside, as the construction in the proof of Theorem 3.6 does not depend on multiple time-points, this
result holds for the probabilistic logic of Nilsson [1986] as well.

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:13

an APT logic program. Again, such a consistency check is sound but not complete, 
correctly identifies inconsistent programs but does not guarantee consistency.
4.1. Bounding Frequency Function Values

In this article, we only use the efr frequency function. However, our techniques can be
easily adapted to other frequency functions such as pfr from Shakarian et al. [2011].
Our first definition is a function, EFR, which returns tight bounds on efr given F, G,
and t.
Definition 4.1. Suppose F, G are formulas, t is a time point, and φ is a time
formula. We define EFR(F, G, t, φ) = [αtight , βtight ] where
αtight = inf{ef r(Th, F, G, t) | Th ∈ T ∧ Th |= φ}.
βtight = sup{ef r(Th, F, G, t) | Th ∈ T ∧ Th |= φ}.
The intuition in the given definition is that αtight is the least value of ef r (w.r.t.
formulas F, G and time interval t) for all threads satisfying φ. Likewise, βtight is the
greatest value of ef r (w.r.t. formulas F, G and time interval t) for all threads satisfying φ. We can easily approximate [αtight , βtight ] when we make certain assumptions on
φ. Consider the following special case of a ptf:
Definition 4.2. Suppose ET F ≡ {F1 : t1 , . . . , Fn : tn} is a set of elementary time

 t j.
formulas, where n ≤ tmax and for any two such formulas, Fi : ti, F j : t j ∈ ET F, ti =
Then F1 : t1 ∧ . . . ∧ Fn : tn is a time conjunction.
Example 4.1. Item 5 in the APT-program from Figure 1 is a time-conjunction. We
shall refer to this time-conjunction as φstock in later examples.
We notice right away that a prefix (Definition 2.11) is simply a special case of time
conjunction annotated with probability [1, 1]. One useful property of time conjunctions
that we leverage in our operator is the following.

and G 1 : t1 ∧. . .∧ G n :
Observation 4.1. If F1 : t1 ∧. . .∧ Fn : tn ∧ Fn+1 : t1 ∧. . .∧ Fn+m : tm


tn ∧ G n+1 : t1 ∧ . . . ∧ G n+k : tk are time conjunctions, then

(F1 ∧ G 1 ) : t1 ∧ . . . ∧ (Fn ∧ G n) : tn ∧ Fn+1 : t1 ∧ . . . ∧ Fn+m : tm
∧ G n+1 : t1 ∧ . . . ∧ G n+k : tk

is also a time conjunction.
We leverage this property in the following way: If we know a bound for
EFR(F, G, t, φ) and EFR(F, G, t, φ ∧ ρ), we may be able to use this information to
find probability bounds on ρ. We will describe this further when we discuss syntactic
manipulation. Next, with a time conjunction in mind, we will show how to find a tight
bound on EFR. In this case, we introduce the following notation and obtain a bound
on EFR in Proposition 4.4.
Definition 4.3. For formulas F, G, time t, and time conjunction φ, we define the
following:
— cnt(φ, F, G, t) = |{t ∈ [1, tmax − t]|∃t ∈ (t, t + t] s.t. (φ |= F : t ∧ G : t )}|
— end(φ, F, G, t) = |{t ∈ (tmax − t, tmax )|∃t ∈ (t, tmax ] s.t. (φ |= F : t ∧ G : t )}|
— denom(φ, F, t) = |{t ∈ [1, tmax − t]|∃Th s.t. (Th |= φ) ∧ (Th |= F : t)}|
— poss(φ, F, G, t) = |{t ∈ [1, tmax − t]|∃t ∈ (t, t + t] s.t. ∃Th s.t. (Th |= φ) ∧ (Th |= F :
t ∧ G : t )}|
— endposs(φ, F, G, t) = |{t ∈ (tmax − t, tmax )|∃t ∈ (t, tmax ] s.t. ∃Th s.t. (Th |= φ) ∧ (Th |=
F : t ∧ G : t )}|
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:14

P. Shakarian et al.

The intuitions behind the components of Definition 4.3 are as follows. For a given
F, G, t, cnt is simply the number of times in the first tmax −t timesteps (of all threads
satisfying some ptf φ) where a world satisfying F is followed by a world satisfying G
within t time units. Likewise, end performs this count for the last t time units.
Similarly, poss and endposs perform similar calculations, but rather than considering
all threads that satisfy φ, there must only exist a thread satisfying φ where a world
satisfying F is followed by a world satisfying G in t time units. The definition of
denom captures the total number of times F is satisfied in the first tmax − t worlds (for
all threads satisfying φ). Due to the boundary condition of efr (refer to Section 2 for
details), we use end and endposs to perform this count in the last tmax − t worlds of
the threads. Hence, in the below proposition, we are able to show that EFR(F, G, t, φ)
is a subset of two fractions created from the components we defined.
P ROPOSITION 4.4. For formulas F, G, time t, and time conjunction φ,
EFR(F, G, t, φ) ⊆
	

cnt(φ, F, G, t) + end(φ, F, G, t) poss(φ, F, G, t) + endposs(φ, F, G, t)
,
.
denom(φ, F, t) + end(φ, F, G, t) denom(φ, F, t) + endposs(φ, F, G, t)
Example 4.2. Consider the APT-program from Figure 1 that includes time conjunction φstock (see Example 4.1). Consider the pre and post conditions of rules 1-2; we shall
refer to them as follows (in this and later examples):
F1
G1
F2
G2

≡ sec rumor ∧ rum incr(10%)
≡
stock decr(10%)
≡ sec rumor ∧ rum incr(10%)
≡ stock decr(10%) ∧ cfo resigns

Using Definition 4.3, we can determine that:
EFR(φstock , F1 , G 1 , 2) ⊆ [0.5, 1.0]
and
EFR(φstock , F2 , G 2 , 1) ⊆ [0.0, 0.667].
4.2. Theorems for Syntactic Manipulation

In the last section, we bounded the values that efr can have for a thread given some
time formula φ. This section leverages that information to obtain tighter bounds
on ptf ’s and APT-rules. First, we introduce a simple result that allows for syntactic
manipulation of ptf ’s without these bounds.
L EMMA 4.5. Let ρ : [ , u ] be a ptf and I be an interpretation; then:
(1)
(2)
(3)
(4)
(5)

If
If
If
If
If

I
I
I
I
I

|= φ
|= φ
|= φ
|= φ
|= φ

: [, u], then I |= φ ∧ ρ : [max(0,  +  − 1), min(u, u )]
: [, u], then I |= φ ∨ ρ : [max(,  ), min(1, u + u )]
: [, u] and φ |= ρ then I |= ρ : [, 1]
: [, u] and ρ |= φ then I |= ρ : [0, u]
: [, u] then I |= ¬φ : [1 − u, 1 − ].

Example 4.3. Suppose program Kstock entails ptf sec rumor : 6 : [0.3, 0.6]. Then, it
also entails ¬sec rumor : 6 : [0.4, 0.7].
We notice right away that syntactic manipulation sometimes identifies inconsistent
APT-programs. For example, if φ : [0.7, 0.6] is entailed via Lemma 4.5, then we know
that K is not consistent. We explore this issue further in Section 4.4. Next, we use
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:15

the bounds on EFR to syntactically manipulate APT-rules, yielding rules with tighter
probability bounds, perhaps uncovering an inconsistent program. Theorem 4.6 tightens the bound when the APT-program includes a ptf that happens with probability 1.
Its corollary tightens the lower bound given any ptf.
T HEOREM 4.6. Suppose I is an interpretation and φ is a time formula such that
efr

I |= φ : [1, 1] and EFR(F, G, t, φ) ⊆ [α, β]. Then I |= F ; G : [t, α, β].
C OROLLARY 4.7. Suppose I is an interpretation and φ is a time formula such that
efr

I |= φ : [, u] and EFR(F, G, t, φ) ⊆ [α, β]. Then I |= F ; G : [t, α · , 1].
Theorem 4.6 and Corollary 4.7 are proved by showing that the lower probability
bound of an APT-rule has to be at least as much as the lower bound on the associated
EFR for all threads.
Example 4.4. Consider the scenario from Example 4.2. By the result of that example and Corollary 4.7, we know that Kstock must entail:
ef r

sec rumor ∧ rum incr(10%) ; stock decr(10%) : [2, 0.5, 1.0] and
ef r

sec rumor ∧ rum incr(10%) ; stock decr(10%) ∧ cfo resigns : [1, 0.0, 0.667].
Note that we can now find a tighter bound on rule 2, obtaining a probability bound of
[0.5, 0.667], that is substantially tighter than [0.5, 1] from the original rule using just
one syntactic manipulation.
We can use APT-rules, EFR, and Theorem 4.5 to further tighten the bounds on ptf ’s
with the following theorem.
T HEOREM 4.8. Suppose F, G are formulas, φ, ρ are time formulas, I is an interpretation, and [α1 , β1 ], [α2 , β2 ] are intervals such that EFR(F, G, t, φ) ⊆ [α1 , β1 ] and
efr

EFR(F, G, t, φ ∧ ρ) ⊆ [α2 , β2 ], I |= φ : [1, 1] (see note5 ) and I |= F ; G : [t, , u]. Then:




1
(1) If β2 < β1 , then I |= ρ : 0, min β−β
,
1
−β


 2 1 
1
(2) If α2 > α1 , then I |= ρ : 0, min αu−α
,1 .
2 −α1
From Theorem 4.8, we can easily obtain the following corollary that can be used with
just one time formula (i.e., only ρ). Simply consider the case where φ is TRUE : tmax
and [α1 , β1 ] = [0, 1].
C OROLLARY 4.9. Suppose F, G are formulas, ρ is a time formula, I is an interpreefr

tation, and [α, β] is an interval such that EFR(F, G, t, ρ) ⊆ [α, β] and I |= F ; G :
[t, , u]. Then:




−1
(1) If β < 1 then I |= ρ : 0, min β−1
,1



(2) If α > 0 then I |= ρ : 0, min αu , 1 .
Example 4.5. Following from Example 4.4, consider the time-formula stock decr
(10%) : 5. Using Definition 4.3, we find that EFR(φstock ∧ stock decr(10%) : 5, F1 ,
G 1 , 2) ⊆ [1, 1]. Previously, we saw that EFR(φstock , F1 , G 1 , 2) ⊆ [0.5, 1]. As the
lower bound on frequency increases (by conjuncting the new time formula), that is
5 Note

that Theorem 4.6 requires  ≤ β1 and α1 ≤ u.
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:16

P. Shakarian et al.

1 > 0.5, we apply part 2 of Theorem 4.8 (and/or Corollary 4.9) to obtain an upper
probability bound on stock decr(10%) : 5. Hence, this formula is no more probable
than 0.94.
Finally, we show that we can also use integrity constraints to aid in syntactic
manipulation. For certain ptf ’s with probability 1, a given IC may cause another ptf
(or multiple ptf ’s) to be entailed with a probability of 0, which can also contribute to
bounding EFR.
P ROPOSITION 4.10. For atom A i and program K where BLK(A i) :< blki ∈ K, if there
exists a ptf φ : [1, 1] ∈ K such that φ |= A i : t − blki + 1 ∧ A i : t − blki + 2 ∧ . . . ∧ A i : t − 1,
then K entails A i : t : [0, 0].
P ROPOSITION 4.11. For atom A i and program K where OCC(A i) : [loi, upi] ∈ K, if
there exists a ptf φ : [1, 1] ∈ K such that there are numbers t1 , . . . , tupi ∈ {1, . . . , tmax }
where φ |= A i : t1 ∧ . . . ∧ A i : tupi then for any t ∈
/ {t1 , . . . , tupi } K entails A i : t : [0, 0].
Example 4.6. Consider Kstock from the previous examples. As this program includes
OCC(cfo resigns) : [0, 1] and entails cfo resigns : 4 : [1, 1] (by the included prefix), we
can conclude that cfo resigns : 5 : [0, 0] and cfo resigns : 6 : [0, 0] are entailed by this
program.
4.3. The Fixpoint-Based Heuristic

We are now ready to use the results of the last section to create the  operator. First,
we present some preliminary definitions to tighten probability bounds for ptf ’s and
rules. Note that the correctness of these bounds follows directly from the results of the
previous section. First we show how, given an APT-program, we can tighten the lower
and upper bound of a ptf.
Definition 4.12. Suppose K is an APT-program and φ is a time formula. We define:


l bnd(φ, K) = sup { 0 } ∪ {  | ρ : [, u] ∈ K ∧ (ρ |= φ) } .
u bnd(φ, K) is the inf of the set:
{
{
{ min

{ min





1
u



−β1
,1
β2 −β1



u−α1
,1
α2 −α1

}∪
| ρ : [, u] ∈ K ∧ (φ |= ρ) } ∪
efr

| (F ; G : [t, , u], ρ : [1, 1] ∈ K ∪ {true : tmax : [1, 1]}) ∧
(EFR(F, G, t, ρ) ⊆ [α1 , β1 ]) ∧
(EFR(F, G, t, ρ ∧ φ) ⊆ [α2 , β2 ]) ∧ (β2 < β1 ) } ∪
efr

| (F ; G : [t, , u], ρ : [1, 1] ∈ K ∪ {true : tmax : [1, 1]}) ∧
(EFR(F, G, t, ρ) ⊆ [α1 , β1 ]) ∧
(EFR(F, G, t, ρ ∧ φ) ⊆ [α2 , β2 ]∧ (α2 > α1 ) }.

This bound on a time formula is derived from its relationship with other time
formulas (by Lemma 4.5) or it relationship with rules (by Theorem 4.8 and/or
Corollary 4.9). We now show an example.
Example 4.7. Following from Example 4.5, consider, once again, the time-formula
stock decr(10%) : 5. For program Kstock , we know that l bnd(stock decr(10%) :
5, Kstock ) = 0.0. This is due to the simple fact that there is no lower probability bound
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:17

assigned to the time formula stock decr(10%) : 5 by Kstock that is greater than 0.0.
Examining the upper bound, we consider the inf of set {1, 0.94} as 1 is the trivial upper bound, there are no other upper probability bounds for stock decr(10%) : 5 seen
directly in Kstock and we have already used Example 4.5 to derive the upper bound of
0.94 based on syntactic manipulation of rules in Kstock (which reflects the last two parts
of the u bnd definition). Hence, u bnd(stock decr(10%) : 5, Kstock ) = 0.94.
Note that for ptf ’s we do not include any manipulation that relies on the bounds of
the negated time formula in these definitions. We handle this type of manipulation in
the definition of the operator. The following are versions of l bnd, u bnd for rules.
Definition 4.13. Suppose K is an APT-program, F, G are formulas, and t > 0 is an
integer.
— The quantity l bnd(F, G, t, K) is the sup of the following set:
{

0

{
{


α·

}∪
efr

| F ; G : [t, , u] ∈ K } ∪
| (φ : [, u], ρ : [1, 1] ∈ K ∪ {true : tmax : [1, 1]}) ∧
(EFR(F, G, t, ρ ∧ φ) ⊆ [α, β]) } ∪
{ α · (1 − u) | (φ : [, u], ρ : [1, 1] ∈ K ∪ {true : tmax : [1, 1]}) ∧
(EFR(F, G, t, ρ ∧ ¬φ) ⊆ [α, β]) }.

— The quantity u bnd(F, G, t, K) is the inf of the following set:
{ 1 }∪
efr

{ u | F ; G : [t, , u] ∈ K } ∪
{ β | (ρ : [1, 1] ∈ K) ∧ (EFR(F, G, t, ρ) ⊆ [α, β]) }.
Hence, the new probability bound assigned to a rule is based on how the bounds on
the frequency function are tightened given the ptf ’s present in the program. Given a
ptf, we use a bound on EFR, which allows us to leverage Theorem 4.6 and Corollary 4.7
to obtain a tighter bound on the rule. Tighter bounds on rules are useful for two
reasons: (1) subsequent applications of the fixpoint operator will in turn use these
new bounds to tighten bounds on ptf ’s and (2) they can be used to identify inconsistent
program (as we discuss in Section 4.4).
We now define set formula(K), which intuitively means “all time formulas that appear in K.” These are the formulas upon which Definition 4.12 will act, and also
through syntactic manipulation, affect other ptf ’s in K. As stated earlier, we can find
bounds for any time formula ρ by adding ρ : [0, 1] to the initial APT program.
Definition 4.14. Given program K consisting of ptf ’s and constrained rules,
formula(K) is the following set:
{

φ

| φ : [, u] ∈ K } ∪
efr

{ F : t | (t ∈ [1, tmax ]) ∧ (F ; G : [t, , u] ∈ K) } ∪
efr

{ G : t | (t ∈ [1, tmax ]) ∧ (F ; G : [t, , u] ∈ K) }.
We now have all the pieces we need to define our operator .
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:18

P. Shakarian et al.

Definition 4.15. Given program K, (K) is defined as the following set:
{

efr

F ; G : [t, l bnd(F, G, t, K),
efr

{
{
{

{
{

u bnd(F, G, t, K)]
| F ; G : [t, , u] ∈ K } ∪
φ : [l bnd(φ, K), u bnd(φ, K)] ∩
[1 − u bnd(¬φ, K), 1 − l bnd(¬φ, K)] | φ ∈ formula(K) } ∪
A i : t : [0, 0]
| (BLK(A i) :< blki ∈ K) ∧ (φ : [1, 1] ∈ K) ∧
(φ |= A i : t − blki + 1 ∧ . . . ∧ A i : t − 1)} ∪
A i : t : [0, 0]
| (OCC(A i) : [loi, upi] ∈ K) ∧ (φ : [1, 1] ∈ K) ∧
(∃t1 , . . . , tupi ∈ {1, . . . , tmax }) ∧
(φ |= A i : t1 ∧ . . . ∧ A i : tupi ) ∧
(t ∈
/ {t1 , . . . , tupi })} ∪
BLK(A i) :< blki
| BLK(A i) :< blki ∈ K} ∪
OCC(A i) : [loi, upi]
| OCC(A i) : [loi, upi] ∈ K}.

Intuitively,  tightens the probability bounds on rules by leveraging probabilistic
time formulas using the results we proved in Theorem 4.6 and Corollary 4.7. It
tightens the probability bounds on time formulas based on other time formulas, rules,
and integrity constraints. This uses the results proved in Lemma 4.5, Theorem 4.8
(and/or Corollary 4.9), and Propositions 4.10–4.11, respectively.
Example 4.8. Consider the program Kstock from the previous examples. By
Definition 4.14, we know that a ptf time-formula stock decr(10%) : 5 will be included
in (Kstock ). We saw in Example 4.7 that l bnd(stock decr(10%) : 5, Kstock ) = 0.0 and
u bnd(stock decr(10%) : 5, Kstock ) = 0.94. In the same manner, we can compute that
l bnd(¬stock decr(10%) : 5, Kstock ) = 0.0 and u bnd(¬stock decr(10%) : 5, Kstock ) = 0.667
(this follows from the fact that EFR(φstock ∧ ¬stock decr(10%) : 5, F1 , G 1 , 2) ⊆
[0.5, 0.667]). Hence, we know that the ptf stock decr(10%) : 5 : [0.333, 0.94] is included
in (Kstock ).
Note that  returns an APT-program that is satisfied by the exact same set of interpretations as the original program; this follows directly from the results in the previous
section.
P ROPOSITION 4.16. Suppose I is an interpretation and K is an APT-program. Then:
I |= K iff I |= (K).
We can also make the following statement about the complexity of the operator.
P ROPOSITION 4.17. One iteration of  can be performed in time complexity O(|K|2 ·
CHK) where CHK is the bound on the time it takes to check (for arbitrary time formulas
φ, ρ) if φ |= ρ is true.
One source of complexity is comparing ptf ’s with other ptf ’s. If a ptf is formed with
an elementary time formula, then it only needs to be compared to other ptf ’s that share
the same time point – this could reduce complexity. As is usual in logic programming,
 can be iteratively applied as follows.
Definition 4.18. We define multiple applications of  as follows.
— (K) ↑ 0 = K
— (K) ↑ (i + 1) = ((K) ↑ i).
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:19

Now, we will show that  has a least fixed point. First, we define a partial ordering
of APT-programs.
Definition 4.19 Preorder over APT-Programs. Given K1 , K2 , we say K1 pre K2 if and
only if:
— ∀φ : [, u] ∈ K1 , ∃φ : [ , u ] ∈ K2 s.t. [ , u ] ⊆ [, u]
efr

efr

— ∀F ; G : [t, , u] ∈ K1 , ∃F ; G : [t,  , u ] ∈ K2 s.t. [ , u ] ⊆ [, u]
— If BLK(A i) :< blki ∈ K1 , then BLK(A i) :< blki ∈ K2
— If OCC(A i) : [loi, upi] ∈ K1 , then OCC(A i) : [loi, upi] ∈ K2 .
The intuition behind this definition is that program K1 is “below” K2 if it has fewer
rules or ptf ’s or rules/ptf ’s with tighter probability bounds. Note that if K2 is above K1 ,
then K1 has at least as many satisfying interpretations, and possibly more, than K2 .
Let PROG BL ,tmax be the set of all APT-programs given Herbrand base BL and time tmax .
It is easy to see that PROG BL ,tmax , pre  is a reflexive and transitive, and therefore a
preorder. In the following, we will say that K1 ∼ K2 , read “K1 is equivalent to K2 ”
if and only if K1 pre K2 and K2 pre K1 . The “∼” relation is clearly an equivalence
relation; we will use [K] to denote the equivalence class corresponding to K w.r.t. this
relation.
Definition 4.20 Partial Ordering of APT-Programs. Given two equivalence classes
[K1 ], [K2 ] w.r.t. relation ∼, we say [K1 ]  [K2 ] if and only if K1 pre K2 .
The “” relation is clearly reflexive, antisymmetric, and transitive, and therefore a
partial order over sets of APT-programs. Note that when we use the symbol , we will
often write K1  K2 as shorthand for [K1 ]  [K2 ]. We will also overload the symbol
PROG BL ,tmax to mean “all equivalence classes of APT-programs” (for a given tmax and
BL ) where appropriate. Therefore, we can now define a complete lattice, where the top
element is a set containing all inconsistent programs, and the bottom element is set
containing the empty program.
L EMMA 4.21. Given ⊥ = {∅} and  = {K | K is inconsistent}, then the partial order
PROG BL ,tmax ,  defines a complete lattice.
What remains to be shown is that  is monotonic; if this holds, we can state it has a
least fixed point.
L EMMA 4.22. K  (K).
L EMMA 4.23.  is monotonic.
By the Tarski-Knaster theorem,  has a least fixed point.
T HEOREM 4.8.  has a least fixed point.
4.4. Using  for Consistency Checking

As noted earlier, the  operator can be used to find “loose” entailment bounds by simply adding an entailment time formula (φ) with probability bounds [0, 1] to the logic
program, and then examining the tightened bounds after one or more applications of
the operator. In this section, we examine how to use  for consistency checking. First,
we have a straightforward lemma on consistency.
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:20

P. Shakarian et al.
efr

L EMMA 4.25. Let K be an APT-logic program that entails rule F ; G : [t, , u] or
φ : [, u] such that one of the following is true:
— > u
—  < 0 or  > 1
— u < 0 or u > 1.
Under this circumstance, K is inconsistent, that is, there is no interpretation I such that
I |= K.
The following result follows immediately.
C OROLLARY 4.26. Let K be an APT-logic program where there exists natural
efr

number i such that (K) ↑ i entails rule F ; G : [t, , u] or φ : [, u] such that one of
the following is true:
— > u
—  < 0 or  > 1
— u < 0 or u > 1.
Under this circumstance, K is inconsistent.
We note that the  adds time formulas whose probability bounds is determined by
an intersection operation. We observe that an empty intersection of the probability
bounds is equivalent to the case where  > u, which allows us to apply Corollary 4.6
to correctly state that the program is not consistent. We illustrate this in the below
example.
Example 4.9. Consider Kstock from the previous examples. By the definition of ,
the ptf stock decr(10%) ∧ cfo resigns : 5 : [0.499, 1] is in (Kstock ). By Example 4.6, we
know that cfo resigns : 5 : [0, 0] is also in (Kstock ). However, another application of 
entails cfo resigns : 5 : [0.499, 0] (equivalently, cfo resigns : 5 : ∅). As 0.499 > 0, we
know that Kstock is not consistent.
In addition to checking consistency with the  operator, we can check for inconsistencies based on the block and occurrence ICs via the following result.
P ROPOSITION 4.27. If there does not exist at least one thread that satisfies all
integrity constraints in an APT-logic program, then that program is inconsistent.
The Thread Existence Problem (ThEX) problem is that of checking existence of a
thread that satisfies all block and integrity constraints. Here we show that ThEX can
be solved in constant time – this can allow us to quickly identify certain inconsistencies
in an APT-program. First, we define a partial thread.
Definition 4.28. A partial thread PTh is a thread such that for all 1 ≤ i ≤ tmax , PTh(i)
is a singleton set.
For any ground atom A i with a single associated block-size and occurrence
max
constraint6 if more than (blki−1)·t
worlds must satisfy A i in each partial thread,
blki
then all partial threads will have a block of size blki. This allows us to derive the
following results.
6 There is no loss of generality looking at just one block-size IC per ground atom as multiple such ICs can
be coalesced into one by taking the minimum; likewise, there is no loss of generality in considering just one
occurrence per ground atom as they can be merged into one by intersecting the [lo, up] intervals for that
atom.

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:21



max
then there does not exist a partial thread
P ROPOSITION 4.29. If loi > (blki−1)·t
blki
for ground atom A i such that the single block-size and occurrence IC associated with
A i hold.


max
P ROPOSITION 4.30. For ground atom A i (with associated ICs), if upi > (blki−1)·t
blki
we know that 
the number of worlds satisfying A i cannot be in the range


(blki −1)·tmax
, upi .
blki
The reason for this is simple: It would force the partial thread to have a sequence
of blki consecutive worlds satisfying A i. We also notice that these checks can be performed based solely on the values of loi, upi, blki, and tmax . Hence, we have the following
proposition.
P ROPOSITION 4.31. ThEX can be solved in constant time.
In the next section we extend these results for nonground APT-programs.
5. CONSISTENCY AND ENTAILMENT ALGORITHMS FOR NONGROUND PROGRAMS

The fixpoint procedure described via the  operator works in the ground case. In this
section, we study how we may avoid grounding. We start (Section 5.1) with a sampling
based approach for consistency checking of nonground programs. Section 5.2 defines
a nonground fixpoint operator for entailment queries. This operator avoids grounding
the entire program, but guaranteed to provide entailment bounds for a query that
are as tight as our ground operator. We remind the reader that both our consistencychecking algorithm and our fixpoint operator presented in this section are sound, but
not complete.
5.1. Consistency Checking for Nonground Programs

In this section, we present a sound algorithm for consistency checking of non-ground
programs. We avoid complete grounding of the rules, while still maintaining soundness
of the algorithm through random sampling of ground instances of rules. The larger the
sample, the more potential inconsistencies can be found.
For a nonground 
time formula, φng , we shall use the notation gnd(φng ) to refer to
the ground formula {φ | is a ground instance of φng }. We are now ready to describe a
nonground analog to the bounds EFR described in the previous section.
Definition 5.1. For nonground formulas Fng , G ng , time t, and nonground time
formula φng , we define
(1)
EFR SET(Fng , G ng , t, φng ) =

{EFR(F, G, t, gnd(φng ))|
F, G are ground instances of Fng , G ng }

(2)
EFR IN(Fng , G ng , t, φng ) = (αin , βin )
Where ∃[αin , β  ], [α  , βin ] ∈ EFR SET(Fng , G ng , t, φng ), and 
 ∃[α ∗ , β  ], [α  , β ∗ ] ∈
EFR SET(Fng , G ng , t, φng ) s.t. α ∗ > αin and β ∗ < βin
(3)
EFR OUT(Fng , G ng , t, φng ) = [αout , βout ]
Where ∃[αout , β  ], [α  , βout ] ∈ EFR SET(Fng , G ng , t, φng ), and 
 ∃[α ∗ , β  ], [α  , β ∗ ] ∈
EFR SET(Fng , G ng , t, φng ) s.t. [α ∗ , β ∗ ] ⊃ [αout , βout ]
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:22

P. Shakarian et al.

The intuition behind Definition 5.1 is as follows. EFR SET is the set of all frequency
bounds for the different ground instances of Fng , G ng . EFR IN is a pair consisting of
the greatest lower bound of efr (αin ) and the least upper bound of efr (βin ) of all the
elements of EFR SET. (αin , βin ) is a tuple, not a bound. It is possible for αin > βin .
EFR OUT represents the tight bound of ef r for any ground instance of Fng , G ng . We
now prove these bounds to be tight.
L EMMA 5.2. Suppose Fng , G ng are nonground formulas, time t > 0 is an integer,
and φng is a nonground time formula. Let (αin , βin ) = EFR IN(Fng , G ng , t, φng ) and
[αout , βout ] = EFR OUT(Fng , G ng , t, φng ). If Th |= φng , then:
(1) for all ground instances F, G of Fng , G ng we have efr(F, G, t, Th) ∈ [αout , βout ];
(2) there exist ground instances F, G of Fng , G ng , and we have efr(F, G, t, Th) ≥ αin ;
(3) there exist ground instances F, G of Fng , G ng , and we have efr(F, G, t, Th) ≤ βin .
Note that if we were to use the techniques of Section 4 for entailment, we would
most likely need to find tight bounds on the elements in the tuple returned by
EFR OUT(Fng , G ng , t, φng ) (specifically a tight lower bound on EFR, as we can be
sure that for all ground instances F, G of Fng , G ng that EFR(F, G, t, gnd(φng )) will fall
within these bounds). However, there are a few difficulties with this. First, we conjecture that to find a good bound on EFR OUT, we would most likely have to examine
all combinations of ground instances of Fng , G ng , which is most likely equivalent to
grounding out the logic program and using . Second, even if we could efficiently find
tight bounds on EFR OUT, they would most likely be trivial – i.e., [0, 1].
Conversely, consider the tuple (αin , βin ) = EFR IN(Fng , G ng , t, φng ). We know that
for all ground instances F, G of Fng , G ng such that for [α, β] = EFR(F, G, t, gnd(φng )),
we have αin ≥ α and βin ≤ β  . We also know that finding a lower bound on αin and an
upper bound on βin can be done by simply considering any subset of combinations of
ground instances of Fng and G ng .
Example 5.1. Consider Ktrain from Figure 4 with tmax = 4. Suppose we add the
following ptf (called φ) to the program.
at station(train1, stnA) : 1 ∧ adjEast(stnA , stnB) : 1∧
¬(at station(train1, stnA) : 2) ∧ at station(train1, stnA) : 3 : [1, 1]
Clearly, as EFR(at station(train1, stnA) ∧ adjEast(stnA , stnB), at station(train1, stnA), 2,
φ) = [1, 1], we know for (αin , βin ) = EFR IN(at station(T, S1 ) ∧ adjWest(S1 , S2 ),
at station(T, S2 ), 2, φ), that αin = 1 and βin ≤ 1.
Algorithm 1 Finds bounds on EFR IN
FIND-EFR-IN(Fsam , Gsam subsets of ground instances of nonground
formulas Fng , G ng , t natural number , φng nonground time formula),
−
+
, βin
returns natural numbers αin
(1) Compute gnd(φng )
−
+
= 0 and βin
=1
(2) Set αin
(3) For each F ∈ Fsam
(a) For each G ∈ Gsam
i. Let (α, β) = EFR(F, G, t, gnd(φng ))
−
−
ii. αin
= max(α, αin
)
+
+
iii. βin = min(β, βin )

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:23

Algorithm 1 leverages this technique; if φng is already ground, algorithm FIND-EFRIN runs in time quadratic in the size of the sample of ground instances of Fng , G ng .
Clearly, this simple algorithm is guaranteed to return a lower bound on αin and an
upper bound on βin .
This information can be leveraged in order to perform consistency checks similar to
those described in Section 4.4 without resorting to fully grounding out Fng , G ng and
considering all combinations of those ground instances. The intuition is simple: if
there is just one ground instance of a nonground rule where  > u, then the program is
inconsistent. The theorem and corollary below mirror Theorem 4.6 and Corollary 4.7
that we described in Section 4.2 for the ground case.
T HEOREM 5.3. Let K(ng) be a nonground APT-program that contains the following:
efr

Nonground rule : Fng ; G ng : [t, , u]
Nonground ptf :
φng : [1, 1]
−
+
≤ αin and βin
≥ βin , then,
and (αin , βin ) = EFR IN(Fng , G ng , t, φng ). If we are given αin
−
+
(ng)
K
is not consistent if either αin > u or βin < .

C OROLLARY 5.4. Let K(ng) be a nonground APT-program that contains the following:
efr

Nonground rule : Fng ; G ng : [t, , u]
Nonground ptf :
φng : [ , u ]
−
+
≤ αin and βin
≥ βin , then,
and (αin , βin ) = EFR IN(Fng , G ng , t, φng ). If we are given αin
−
(ng)

K
is not consistent if αin ·  > u.

Algorithm 2 is a sound (but not complete) method to quickly check for inconsistency
in the nonground case.
Algorithm 2 Checks for inconsistencies in a nonground program
NG-INCONSIST-CHK(K(ng) nonground program)
returns list of rules that cause inconsistencies
(1) Let L be a list of rules initialized to ∅
(2) For each ptf φng : [ , u ] ∈ K(ng) where u = 1, do the following.
efr

(a) For each rule Fng ; G ng : [t, , u] ∈ K(ng) , do the following.
i. Generate sample sets Fsam , Gsam of ground instances of Fng , G ng .
−
+
, βin
) = FIND-EFR-IN(Fsam , Gsam , t, φng )
ii. Let (αin
efr

−
iii. If αin
·  > u, then add Fng ; G ng : [t, , u] ∈ K(ng) to L
efr

+
iv. Elseif  = 1 and βin
< , then add Fng ; G ng : [t, , u] ∈ K(ng) to L
(3) Return list L

P ROPOSITION 5.5. If the list returned by NG-INCONSIST-CHK contains any elements, then K(ng) is not consistent.
Note that the algorithm performs only a quadratic number of comparisons.
P ROPOSITION 5.6. NG-INCONSIST-CHK performs O(|K(ng) |2 ) comparisons.7
7 Note.

Each comparison requires generating samples of ground instances of two formulas in a rule and
running FIND-EFR-IN.

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:24

P. Shakarian et al.

5.2. Entailment for the Nonground Case

In this section, we introduce a nonground operator, K(ng) , that maps ground programs
to ground programs. Using the same lattice of APT-programs we used in Section 4.3,
we show that K(ng) also has a least fixed point. Our intuition is as follows. Suppose we
want to find the tightest entailment bounds on some ptf φ; if we compute lfp(K(ng) (φ :
[0, 1])), the result will be an APT-program (let us call this program Kφ ) s.t. lfp((Kφ ))
will provide the same entailment bounds on φ as if we had computed the least fixed
point of  on the grounding of K(ng) . However, in most cases, Kφ will be much smaller
than the grounding of K(ng) .
Definition 5.7. For nonground program K(ng) and ground program K (note that
formula(K) is a set of ground formulas, as defined in Definition 4.14), K(ng) maps
ground programs to ground programs and is defined as follows. K(ng) (K) =
K
efr

∪
efr

{F ; G : [t, , u]| F ; G : [t, , u] is a ground instance of a rule in K(ng) s.t.
∃φ ∈ formula(K) where φ is ground and
∃t ∈ [1, tmax ] s.t. φ |= F : t or φ |= G : t
or φ |= ¬F : t or φ |= ¬G : t} ∪
{ρ : [, u]|

{BLK(A) :< blk|

ρ : [, u] is a ground instance of a ptf in K(ng) s.t.
∃φ ∈ formula(K) where φ is ground and φ |= ρ
or φ |= ¬ρ} ∪
BLK(A) :< blk is a ground instance of a constraint in K(ng) s.t.
∃φ ∈ formula(K) where φ is ground and
∃t ∈ [1, tmax ] s.t. φ |= A : t or φ |= ¬A : t} ∪

{OCC(A) : [lo, up]| OCC(A) : [lo, up] is a ground instance of a constraint in K(ng) s.t.
∃φ ∈ formula(K) where φ is ground and }
∃t ∈ [1, tmax ] s.t. φ |= A : t or φ |= ¬A : t}
We will now present an example for this operator.
Example 5.2. Recall Ktrain from Figure 4 with tmax = 4. The following rules comprise
the set Ktrain ({at station(train1, stnB) : 4}):
at station(train1, stnB) : 4
ef r

at station(train1, stnA) ∧ adjEast(stnA, stnB) ; at station(train1, stnB) : [4, 0.85, 1.0]
ef r

at station(train1, stnB) ∧ adjEast(stnB, stnB) ; at station(train1, stnB) : [4, 0.85, 1.0]
ef r

at station(train1, stnC) ∧ adjEast(stnC, stnB) ; at station(train1, stnB) : [2, 0.85, 1.0]
ef r

at station(train1, stnA) ∧ adjWest(stnA, stnB) ; at station(train1, stnB) : [2, 0.6, 0.7]
ef r

at station(train1, stnB) ∧ adjWest(stnB, stnB) ; at station(train1, stnB) : [2, 0.6, 0.7]
ef r

at station(train1, stnC) ∧ adjWest(stnC, stnB) ; at station(train1, stnB) : [2, 0.6, 0.7]
We use the same partial ordering and lattice from Section 4.3, and show the monotonicity of K(ng) as follows.
L EMMA 5.8. K  K(ng) (K) w.r.t. PROG BL ,tmax , 
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:25

Fig. 6. Number of ground rules vs. runtime (Left: ISW, Right: MAROB). Note these runtimes include the
full computation of the fixed point of the  operator.

L EMMA 5.9. K(ng) is monotonic.
Now, we show that K(ng) has a least fixed point.
Definition 5.10. We define multiple applications of  as follows.
— K(ng) (K) ↑ 0 = K
— K(ng) (K) ↑ (i + 1) = K(ng) (K(ng) (K) ↑ i)
T HEOREM 5.11. K(ng) has a least fixed point.
The next two results demonstrate the soundness of . Given nonground program
K(ng) , let ground(K(ng) ) be the grounding of this program. The lemma below follows
directly from the definition of the operator. It states that the least fixed point of the
operator is a subset of the grounding of K(ng) .
L EMMA 5.12. Given nonground program K(ng) , and ground program K, lfp(K(ng) (K))
⊆ ground(K(ng) ) ∪ K.
Additionally, the following result states that, for a given entailment query, we obtain
the same result whether we use K(ng) or simply ground out K(ng) .
T HEOREM 5.13. Given nonground program K(ng)
φ : [, u] ∈ lf p((lf p(K(ng) ({φ : [0, 1]}))))
iff
φ : [, u] ∈ lf p((ground(K(ng) ) ∪ {φ : [0, 1]}))
In the next section, we will show the results of our experimental analysis of the
algorithms provided in the previous sections for the nonground case.
6. EXPERIMENTAL RESULTS

This section reports on experiments carried out in the ground case with our fixpoint
algorithm. We demonstrate the  operator on 23 different ground APT-programs
automatically extracted from two different datasets using a slight improvement of
the APT-EXTRACT algorithm from Shakarian et al. [2011]. We were able to compute
fixpoints of APT-programs consisting of over 1,000 ground rules in about 20 minutes
(see the left-hand side of Figure 6). Note that this is the time to compute the fixpoint,
not to perform a deduction (i.e., via the  operator), which can be done for specific
entailment queries, and would be faster.
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:26

P. Shakarian et al.

This section is organized as follows. Section 6.1 describes our experimental setup,
dataset, and how we extracted rules, integrity constraints, and ptf ’s while Section 6.2
examines the runtime of the fixpoint operator.
6.1. Experimental Setup

All experiments were run on multiple multicore Intel Xeon E5345 processors at
2.33GHz, 8GB of memory, running the Scientific Linux distribution of the GNU/Linux
OS, kernel version 2.6.9-55.0.2.ELsmp.8 Our implementation consists of approximately 4,000 lines of Java code (JDK 1.6.0).
Iraq Special Groups (ISW). This dataset contains daily counterinsurgency events from
Baghdad in 2007–2008. The event data was provided by the Institute for the Study
of War (ISW) and augmented with neighborhood data from the International Medical
Corps. The historical data was represented with 187 ground atoms over 567 days,
which is the time granularity we used. Using the APT-Extract algorithm (presented
in [Shakarian et al. 2011]), we extracted 3,563 ground rules using the efr frequency
function.
We considered 13 logic programs from this dataset; each smaller program is a subset
of any of the larger ones, so we have K1 ⊆ K2 ⊆ . . . ⊆ K12 ⊆ K13 . In each program, we
included a prefix consisting of 50 worlds (for more on prefixes, refer to Definition 2.11).
The same prefix was used for each ISW program. We set tmax = 60 for all ISW programs. Additionally, for all ground atoms appearing in a given program, we added
the appropriate block and occurrence integrity constraints. Later we will present our
extraction algorithms for these constraints.
Minorities at Risk Organizational Behavior (MAROB). This dataset contains yearly
attributes for a variety of political and violent groups over a period of 25 years
[Wilkenfeld et al. 2007]. Overall, we have extracted over 21.4 million APT-rules
from this dataset. These rules were also extracted using APT-EXTRACT with the efr
frequency function.
We considered 10 APT-logic programs from this dataset, each corresponding to a
different group. As each of these logic programs is associated with actions for a specific
group, all 10 of the MAROB programs are pairwise disjoint. In each MAROB program,
we included a unique prefix of 10 worlds specific to the group in the program. We set
tmax = 13 for each MAROB program. Block-size and occurrence constraints were also
included in each program. Table I provides some information on these APT-programs.
While integrity constraints (as with rules) could come from an expert, we decided
to extract our ICs from the data. We have included the straightforward algorithms
OC-EXTRACT and BLOCK-EXTRACT to show how we extracted occurrence and
block-size IC’s (respectively) for each of the 187 atoms in the dataset.

P ROPOSITION 6.1. OC-EXTRACT runs in time O((n − tmax ) · tmax ).
P ROPOSITION 6.2. There are no historical threads such that atom ai is satisfied by
less than loi or more than upi worlds when loi, upi are produced by OC-EXTRACT.
P ROPOSITION 6.3. BLOCK-EXTRACT runs in time O(n).
P ROPOSITION 6.4. Given blki as returned by BLOCK-EXTRACT, there is no sequence
of blki or more consecutive historical worlds that satisfy atom ai.
8 We note that this implementation makes use of only one processor and one core for a single run, though
different runs were distributed across the cluster.

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:27

Algorithm 3 Extracts occurrence constraints
OC-EXTRACT(ai ground atom , W1 , . . . , Wn historical worlds, tmax maximum time),
returns natural numbers loi, upi
(1) Set upi = 0 and loi = tmax
(2) For i = 1, i ≤ n − tmax + 1, loop
(a) Set cur = 0
(b) For j = i, j < i + tmax loop
i. If W j |= ai, then cur = cur + 1
(c) If cur < loi then set loi = cur
(d) If cur > upi then set upi = cur
(3) Return loi, upi
Algorithm 4 Extracts block-size constraints
BLOCK-EXTRACT(ai ground atom , W1 , . . . , Wn historical worlds),
returns natural number blki
(1) Set cur = 0
(2) Set best = 0
(3) For i = 1, i ≤ n, loop
(a) If Wi |= ai
i. cur = cur + 1
(b) Else
i. If cur > best then set best = cur
ii. Set cur = 0
(4) If cur > best set best = cur
(5) Set blki = best + 1
(6) Return blki
6.2. Runtime Evaluation

To evaluate performance, for each logic program, we clocked 10 trials until  reached
a fixpoint. In all our trials, a fixpoint was reached after only two or three applications
(see Table I). We also note that the experimental relationship between runtime and
the number of rules was linear; we conducted a statistical R2 -test for this and came
up with an R2 value of 0.97 for ISW programs and 0.77 for MAROB programs (refer to
Figure 6). We must point out that the disjoint relationship among MAROB programs
may account for why the runtime relationship is not as linear as that for the ISW
programs. This graceful degradation in performance is most likely due to the fact that
the number of rules/ptfs that can tighten the bound of a given rule or ptf is much
smaller than the set of entire rules, which makes the running time of the inner loop
very small. Hence, for practical purposes, the O(|K|2 ) is a loose bound; this worst case
is likely to occur only in very rare circumstances.
We checked entailment by looking at the probability bounds of formulas in
formula(K) (see Definition 4.14), which is obtained by finding the fixpoint for the
 operator on a consistent APT-program. After our initial runs of  on the 23 logic
programs, we found that 21 of them were inconsistent. As inconsistencies are found
in a constructive way (refer to Section 4.4), we could eliminate rules that caused
inconsistencies (we designate the “consistent” subset of a program with a tick mark,
that is, K2 is K2 with inconsistency-causing rules removed). Using these “consistent” APT-programs, we first looked to revalue the performance of the  operator
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:28

P. Shakarian et al.
Table I.
APT-logic programs used in the runtime evaluations. Programs K1 −K13 (top) are based
on the ISW dataset, while the rest (bottom) are based on MAROB.
Post. Gr. Atoms

Range of t

tmax

Time Points

 App.

K1

92

76

[2,10]

60

567

2

K2

102

76

[2,10]

60

567

3

K3

126

76

[2,10]

60

567

3

K4

144

76

[2,10]

60

567

2

K5

169

76

[2,10]

60

567

2

K6

214

76

[2,10]

60

567

3

K7

241

76

[2,10]

60

567

3

K8

278

76

[2,10]

60

567

3

K9

360

79

[2,10]

60

567

3

K10

503

80

[2,10]

60

567

3

K11

644

80

[2,10]

60

567

3

K12

816

80

[2,10]

60

567

3

K13

1081

84

[2,10]

60

567

3

KH

586

189

[2,3]

13

23

3

KJ

679

192

[3,3]

13

25

2

KA

661

162

[2,3]

13

25

2

KB

163

175

[3,3]

13

24

2

KD

539

176

[3,3]

13

25

2

K FT

482

188

[2,3]

13

22

3

K FR

310

177

[3,3]

13

25

2

KH A

458

168

[3,3]

13

13

2

KH I

330

182

[2,3]

13

25

2

KK

94

181

[1,3]

13

25

3

Program

Gr. Rules

Fig. 7. Number of ground rules vs. runtime for entailment checking (Left: ISW, Right: MAROB).

for entailment. Unsurprisingly, as with the runtime evaluation we performed for
consistency checking, we found that the runtime was related linearly to the number
of ground rules considered. We obtained R2 values of 0.95 for ISW programs and 0.94
for MAROB programs. See Figure 7 for details; runtimes are based on the average of
10 trials for each logic program.
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:29

Fig. 8. Attributes of ptf ’s entailed by the different logic programs (ISW dataset).

As a consequence of Definition 4.14, the logic program returned by multiple applications of  includes several ptf ’s not in the original program. These ptf ’s were either
based on formulas seen in the rules, or atoms seen in the rules where an integrity
constraint forces the associated atomic ptf to be assigned probability 0. Many of these
ptf ’s have probability bounds tighter than [0, 1], some extremely tight. We note, as
shown in Figure 8, that all of our ISW logic program produce over 300 ptfs where the
difference between  and u is less than 0.1 (the number steadily increases with larger
ISW programs9 ). We also looked at “decision ptf ’s”; these are ptf ’s where either  ≤ 0.5
or u ≤ 0.5 – the intuition is that the probability mass is either above or below 0.5,
allowing a user to make a decision. The  operator also was successful in producing
many ptf ’s of this type, producing well over 400 in over half of the logic programs we
considered from the ISW dataset.
7. RELATED WORK

APT-Logic distinguishes itself from other temporal logics in the following ways: (i) It
supports reasoning about probability of events over time, (ii) Future worlds can depend
on more than just the current world (i.e., it does not assume the Markov property). (iii)
It provides probability bounds instead of a point probability. (iv) No independence
assumptions are made.
Though probabilistic extensions to different logics [Fagin et al. 1990; Giugno and
Lukasiewicz 2002; Nilsson 1986] and probabilistic logic programs [Dekhtyar and
Dekhtyar 2005; Kern-Isberner and Lukasiewicz 2004; Ng and Subrahmanian 1992]
have been extensively studied, together with approaches to logic programming with
uncertainty [Kifer and Lozinskii 1992], as well as approaches to learn such programs
[De Raedt and Kersting 2003], logic programming with time has not been extensively
studied. Dekhtyar et al. [1999] was the first such effort and provided a declarative
semantics for temporal probabilistic LPs. The problem of finding entailment bounds
on a formula was not studied there. Moreover, that logic did not include frequency
functions. No implementation was proposed and thus no experimental results were
studied. Dix et al. [2006] provided a logic programming language within which agents
that reason about time and uncertainty could be encoded. Such agents could make
statements about when they were obliged/permitted to take certain actions and
when they were forbidden from doing so. A fixpoint semantics for such agents was
9 It is important to point out that all numbers of ptf ’s with tight bounds are associated with a world outside
the range of the prefix.

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:30

P. Shakarian et al.

provided, but there was no notion corresponding to a frequency function, no way
of reducing the complexity of the problem, and moreover, no analog of our entailment problem was studied. Our work builds on that in Shakarian et al. [2011],
where APT-programs were proposed and consistency/entailment of ground atoms
is studied. However, it did not provide practical algorithms for entailment, or had
implementation/experiments.
Mateus et al. [2001] introduce an extension to the Situation Calculus for handling
actions with uncertain effects. The semantics of their logical language is given in terms
of a “Randomly Reactive Automaton,” which allows for probabilistic effects of actions
but has no notion of the current time apart from that implied by the sequence of actions. They examine next move determination where the results of a move are dependent on the move chosen as well as on draws from single or from multiple distributions.
Santos and Young [1999] propose the Probabilistic Temporal Network model
(PTNs), which allows to represent temporal (and atemporal) information in combination with probabilistic semantics. PTNs are suitable for representing causality
constrained by time, conditions for the occurrence of events (and at what time
they occur), and periodic and recurrent processes. This model is based on Bayesian
networks (for the probabilistic aspect) and on work by Allen [Allen and Ferguson
1994] on temporal interval algebra for the temporal aspect. Even though this work’s
goals overlap to some extent with those of our own, the fundamental difference lies
in the initial assumptions made. In order to build a PTN, one must have available
information regarding dependencies, prior probabilities for all random variables,
temporal causal relationships between random variables in temporal aggregates, etc.
The focus of our work is to reason about events making no independence assumptions,
and only based on limited information relating small subsets of events. The PTN
framework is, however, very useful for scenarios in which the required information is
available, as is the case in probabilistic reasoning with traditional Bayesian Networks.
The key aspect that separates APT-logic from PTN’s, is the fact that APT-logic makes
no assumptions about independence. For example, consider item 1 of Theorem 4.5,
one of the key building blocks of our fixpoint heuristic. In this case, if I |= φ : [ p, p]
and ρ : [ p , p ], then I |= φ ∧ ρ : [max(0, p + p − 1), min( p, p )]. If we had assumed independence, then I |= φ ∨ ρ : [ p2 , p2 ] – clearly a different answer and not appropriate for
domains where we do not wish to make assumptions about dependence/independence
(i.e., the counterinsurgency data that we used for our experiments). This also is our
motivation for the use of probability intervals, rather than point probabilities.
7.1. Work in Veriﬁcation and PRISM

Logics merging time and probabilities have been studied quite a bit in the area of
verification. Vardi [1985] was one of the pioneers in this, followed by many including probabilistic CTL [Hansson and Jonsson 1994], and others [Cleaveland et al.
2005]. Building on this work, Kwiatkowska et al. [2000, 2009] developed a tool
known as PRISM to perform this type of model checking. PRISM has the following
characteristics.
(1) The user specifies a model – a discrete-time Markov chain (DTMC), continuoustime Markov chain (CTMC) or Markov decision processes (MDP)
(2) The user also specifies a property – which is normally a CTL formula
(3) PRISM returns a value (normally a probability or expected value) associated with
the property
One can view our implementation in the same light; taking an APT-program as a
model, time formula as a property, and returning entailment bounds as the value.
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:31

However, PRISM operates under some very different assumptions than APT-logic
which are appropriate for some applications but not for all.
(1) The model specified by the user in PRISM is a stochastic process that assumes the
Markov property - that is the probability of being in the next state only depends
on the current state and action. Conversely, an APT-program does not assume the
Markov property. Further, we demonstrated translations from stochastic processes
to APT-programs in Shakarian et al. [2011]. Also, in that paper, we showed how it
is easy to construct a very simple APT-program where there is no analogous MDP
(using a natural construction).
(2) Based on the model specified by the user, PRISM also makes an independence
assumption. Suppose we are in initial state S1 and consider the following sequence
a

b

of states, actions, and probabilities in an MDP: S1 → p1 S2 → p2 S3 which states that
“state 1 transitions to state 2 on action a with probability p1 and state 2 transitions
to state on action b with probability p2 .” PRISM would calculate the probability
of such a sequence, p1 · p2 , hence it has assumed independence between the two
transitions. Likewise, consider the formulas F(S1 ), F(S2 ), F(S3 ), formulas satisfied
exactly by states S1 , S2 , S3 . Using the natural translation described in [Shakarian
et al. 2011], we can create an analogous APT-program as follows.
— (F(S1 ) ∧ a ∧ ¬b ) : 1 ∧ F(S2 ) : 2 : [ p1 , p1 ].
— (F(S2 ) ∧ b ∧ ¬a) : 2 ∧ F(S3 ) : 3 : [ p2 , p2 ].
By item 1 of Theorem 4.5, the following ptf is tightly entailed:
(F(S1 ) ∧ a∧ ¬b ) : 1 ∧ (F(S2 ) ∧ b ∧ ¬a) : 2 ∧ F(S3 ) : 3 : [max(0, p1 + p2 − 1), min( p1 , p2 )]
With APT-logic, we allow for uncertainty; all we can say about the sequence is it
has a probability in [max(0, p1 + p2 −1), min( p1 , p2 )], which is clearly different from
p1 · p2 .
(3) The property specified by the user in PRISM is based on PCTL [Aziz et al. 1995;
Hansson and Jonsson 1994]. Although there are constructs in PCTL that appear
similar to the syntax of APT-logic, as our semantics differ substantially, the statements have different meanings. Even if an MDP is encoded in an APT-program,
a “leads-to” PCTL operator (which has a strikingly similar intuition to an APTrule) has a very different meaning. We explore the specifics of these differences in
Shakarian et al. [2011].
Basically, PRISM is best suited for situations where the underlying model can
be represented as a stochastic process. Popular applications have included software
verification and certain biology problems that can be easily represented as stochastic
processes. APT-logic is best suited for situations where there are no independence
or Markov assumptions made about the model, which is often the case when we are
working with extracted rules. We have shown APT-logic to be viable for studying the
actions of militia groups in a counter-insurgency environment. Other applications
where APT-logic is well suited include policy analysis and stock price movement.
8. CONCLUSIONS

Logical reasoning with time and probabilities is essential in any application where the
occurrence of certain conditions at time t may cause or imply that other phenomena
may occur δ units in the future. There are numerous such applications including ones
relating to how stock markets will move in the future based on current or past conditions, medicine where the condition of a patient in the future depends on various things
true now, behavior modeling where the behavior of an individual or group in the future
may depend on his current/past situation. In addition, most applications where we reason about the future are fraught with uncertainty. Annotated Probabilistic Temporal
ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

13:32

P. Shakarian et al.

Logic (APT-logic for short) was first introduced in Shakarian et al. [2011] as a paradigm
for reasoning about sentences of the form “If formula F is true at time t, then formula
G will be true at time t with a probability in the range [L, U].” More importantly,
APT-logic programs were introduced in a manner that did not require independence or
Markovian assumptions, many of which are inapplicable for several applications.
To date, no implementation of probabilistic temporal logic exists that does not make
use of Markovian or independence assumptions. To our knowledge, this is the first
paper that attempts any implementation of such logics. However, due to the high
complexity of such reasoning (which may also explain why implementations may not
exist), practical temporal probabilistic reasoning systems may not always be complete.
In this article, we developed, implemented, and evaluated a fixpoint-based heuristic
for consistency and entailment problems in APT-logic programs. This article makes
the following contributions.
(1) We show NP-completeness of the APT-logic consistency problem, and coNPcompleteness of the APT-logic entailment problem, extending hardness results in
Shakarian et al. [2011].
(2) We developed a fixpoint based heuristic from the following observations.
— The presence of ptf ’s with the probability of 1 in an APT-program allows us to
tightly bound values for frequency functions.
— The bound on frequency functions, in turn, allows us to tighten the bounds of
elements in an APT-program
— These two characteristics can be employed in an operator that maps APTprograms to APT-programs and has a least fixed point
(3) We developed consistency and entailment algorithms for the nonground case.
(4) We implemented our fixpoint heuristic and applied it to 23 real world APT-logic
programs derived automatically from two different real world datasets. This suite
of test programs was not written by us. Our experiments show that our fixpoint
based heuristical can calculate fixpoints in time roughly linear w.r.t. the number
of ground rules
(5) We also show that using our implementation, we can solve the “tight entailment
problem” where the goal is to find the tightest interval [, u] such that F : [t, , u] is
entailed by an APT-logic program for a given time t and formula F.
ELECTRONIC APPENDIX

The electronic appendix for this article can be accessed in the ACM Digital Library.
REFERENCES
A LLEN, J. F. AND F ERGUSON, G. 1994. Actions and events in interval temporal logic. J. Logic Comput. 4,
531–579.
A SAL , V., C ARTER , J., AND W ILKENFELD, J. 2008. Ethnopolitical violence and terrorism in the middle east.
In Peace and Conflict 2008, J. Hewitt, J. Wilkenfeld, and T. Gurr Eds., Paradigm.
A ZIZ , A., S INGHAL , V., B ALARIN, F., B RAYTON, R. K., AND S ANGIOVANNI - VINCENTELLI , A. L. 1995. It
Usually Works: The Temporal Logic of Stochastic Systems. Springer, 155–165.
C HVTAL , V. 1983. Linear Programming. W.H.Freeman, New York.
C LEAVELAND, R., I YER , P., AND N ARASIMHA , M. 2005. Probabilistic temporal logics via the modal mucalculus. Theor. Comput. Sci. 342, 2–3, 316–350.
D EKHTYAR , A. AND D EKHTYAR , M. I. 2005. Revisiting the semantics of interval probabilistic logic programs. In Proceedings of the International Conference on Logic Programming and Non-Monotonic Reasoning (LPNMR). 330–342.
D EKHTYAR , A., D EKHTYAR , M. I., AND S UBRAHMANIAN, V. S. 1999. Temporal probabilistic logic programs.
In Proceedings of the International Conference on Logic Programming. MIT Press, Cambridge, MA,
109–123.

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation

13:33

D E R AEDT, L. AND K ERSTING, K. 2003. Probabilistic logic learning. SIGKDD Explor. Newsl. 5, 1, 31–48.
D IX , J., K RAUS, S., AND S UBRAHMANIAN, V. S. 2006. Heterogeneous temporal probabilistic agents. ACM
Trans. Comput. Lang. 7, 1, 151–198.
E MERSON, E. A. AND H ALPERN, J. Y. 1984. “Sometimes” and “not never” revisited: On branching versus
linear time. Tech. rep., Austin, TX.
FAGIN, R., H ALPERN, J. Y., AND M EGIDDO, N. 1990. A logic for reasoning about probabilities. Inf. Comput.
87, 78–128.
G IUGNO, R. AND L UKASIEWICZ , T. 2002. P-shoq(d): A probabilistic extension of shoq(d) for probabilistic
ontologies in the semantic web. In Proceedings of the European Conference on Logics in Artificial Intelligence (JELIA’02). Springer, 86–97.
H ANSSON, H. AND J ONSSON, B. 1994. A logic for reasoning about time and probability. Formal Asp. Comput.
6, 512–535.
ISW. 2008. Map of special groups activity in Iraq. Institute for the Study of War.
K ARMARKAR , N. 1984. A new polynomial-time algorithm for linear programming. Combinatorica 4, 4,
373–395.
K ERN -I SBERNER , G. AND L UKASIEWICZ , T. 2004. Combining probabilistic logic programming with the
power of maximum entropy. Artif. Intell. 157, 1–2, 139–202.
K IFER , M. AND L OZINSKII , E. L. 1992. A logic for reasoning with inconsistency. J. Autom. Reason. 9, 2,
179–215.
K WIATKOWSKA , M., N ORMAN, G., AND PARKER , D. 2000. Verifying randomized distributed algorithms
with PRISM. In Proceedings of the Workshop on Advances in Verification (WAVE’00).
K WIATKOWSKA , M., N ORMAN, G., AND PARKER , D. 2009. Prism: Probabilistic model checking for performance and reliability analysis. SIGMETRICS Perform. Eval. Rev. 36, 4, 40–45.
L AMPORT, L. 1980. “Sometime” is sometimes “not never”: On the temporal logic of programs. In Proceedings
of the ACM Symposium on Principles of Programming Languages. ACM, New York, NY, 174–185.
L LOYD, J. W. 1987. Foundations of Logic Programming 2nd Ed. Springer-Verlag.
M ATEUS, P., PACHECO, A., P INTO, J., S ERNADAS, A., AND S ERNADAS, C. 2001. Probabilistic situation
calculus. Ann. Math. Artif. Intell. 32, 1, 393–431.
N G, R. T. AND S UBRAHMANIAN, V. S. 1992. Probabilistic logic programming. Inf. Comput. 101, 2, 150–201.
N ILSSON, N. 1986. Probabilistic logic. Artif. Intel. 28, 71–87.
R OTH , D. 1996. On the hardness of approximate reasoning. Artif. Intel. 82, 273–302.
S ANTOS, E. AND Y OUNG, J. D. 1999. Probabilistic temporal networks: A unified framework for reasoning
with time and uncertainty. Int. J. Approx. Reason. 20.
S HAKARIAN, P., PARKER , A., S IMARI , G., AND S UBRAMANIAN, V. 2011. Annotated probabilistic temporal
logic. ACM Trans. Comput. Logic 12, 2.
VARDI , M. Y. 1985. Automatic verification of probabilistic concurrent finite state programs. In Proceedings
of the Symposium on Foundations of Computer Science. 327–338.
W ILKENFELD, J., A SAL , V., J OHNSON, C., PATE , A., AND M ICHAEL , M. 2007. The use of violence by ethnopolitical organizations in the middle east. Tech. rep., National Consortium for the Study of Terrorism
and Responses to Terrorism.
Received June 2010; accepted March 2011

ACM Transactions on Computational Logic, Vol. 13, No. 2, Article 13, Publication date: April 2012.

Darknet and Deepnet Mining for Proactive
Cybersecurity Threat Intelligence
Eric Nunes, Ahmad Diab, Andrew Gunn, Ericsson Marin, Vineet Mishra,
Vivin Paliath, John Robertson, Jana Shakarian, Amanda Thart, Paulo Shakarian
Arizona State University
Tempe, AZ 85281, USA
Email: {enunes1, ahmad.diab, andrewgunn, ericsson.marin, vvmishra,
vivin.paliath, jj.robertson, jshak, amanda.thart, shak} @asu.edu

Abstract—In this paper, we present an operational system
for cyber threat intelligence gathering from various social platforms on the Internet particularly sites on the darknet and
deepnet. We focus our attention to collecting information from
hacker forum discussions and marketplaces offering products and
services focusing on malicious hacking. We have developed an
operational system for obtaining information from these sites for
the purposes of identifying emerging cyber threats. Currently, this
system collects on average 305 high-quality cyber threat warnings
each week. These threat warnings include information on newly
developed malware and exploits that have not yet been deployed
in a cyber-attack. This provides a significant service to cyberdefenders. The system is significantly augmented through the use
of various data mining and machine learning techniques. With
the use of machine learning models, we are able to recall 92%
of products in marketplaces and 80% of discussions on forums
relating to malicious hacking with high precision. We perform
preliminary analysis on the data collected, demonstrating its
application to aid a security expert for better threat analysis.

I.

TABLE 1: Exploit example.

Pre-reconnaissance cyber threat intelligence refers to information gathered before a malicious party interacts with
the defended computer system. An example demonstrating the
importance of cyber threat intelligence is shown in Table 1.
A Microsoft Windows vulnerability was identified in Feb.
2015. The release of the vulnerability was essentially Microsoft
warning its customers of a security flaw. Note that at this time,
there was no publicly known method to leverage this flaw in a
cyber-attack (i.e. an available exploit). However, about a month
later an exploit was found to be on sale in darknet market. It
was not until July when FireEye, a major cybersecurity firm,
identified that the Dyre Banking Trojan designed to steal credit
cards exploited this vulnerability - the first time an exploit
was reported. This vignette demonstrates how threat warnings
gathered from the darknet can provide valuable information
for security professionals. The average global exposure of the
Dyre Banking Trojan was 57.3% along with another banking
malware Dridex1 . It means that nearly 6 out of 10 organizations
in the world were affected, and this is a significantly high
number on a global level.

Microsoft identifies Windows vulnerability MS15010/CVE 2015-0057 for remote code execution. There
was no publicly known exploit at the time the vulnerability was released.

April 2015

An exploit for MS15-010/CVE 2015-0057 was found
on a darknet market on sale for 48 BTC (around
$10,000-15,000).

July 2015

FireEye identified that the Dyre Banking Trojan, designed to steal credit card number, actually exploited
this vulnerability1 .

TABLE 2: Current Database Status

Markets

Forums

Total Number

17

Total products

11991

Hacking related

1573

Vendors

434

Total Number

21

Topics/Posts

23780/162872

Hacking related

4423/31168

Users

5491

We are providing this information to cyber-security
professionals to support their strategic cyder-defense planning
to address questions such as, 1) What vendors and users
have a presence in multiple darknet/deepnet markets/ forums?
2)What zero-day exploits are being developed by malicious
hackers? 3) What vulnerabilities do the latest exploits target?

In this paper, we examine how such intelligence can be
gathered and analyzed from various social platforms on the In-

978-1-5090-3865-7/16/$31.00 ©2016 IEEE

Event

Feb. 2015

ternet particularly sites on the darknet and deepnet. In doing so,
we encounter several problems that we addressed with various
data mining techniques. Our current system is operational and
actively collecting approximately 305 cyber threats each week.
Table 2 shows the current database statistics. It shows the total
data collected and the data related to malicious hacking. The
vendor and user statistics cited only consider those individuals
associated in the discussion or sale of malicious hackingrelated material, as identified by the system. The data is
collected from two sources on the darknet/deepnet: markets
and forums.

I NTRODUCTION

1 https://www.fireeye.com/blog/threat-research/2015/06/evolution

Timeline

of dridex.html

7

Specific contributions of this paper include, 1) Description
of a system for cyber threat intelligence gathering from various
social platforms from the Internet such as deepnet and darknet
websites. 2) The implementation and evaluation of learning
models to separate relevant information from noise in the
data collected from these online platforms. 3) A series of
case studies showcasing various findings relating to malicious
hacker behavior resulting from the data collected by our
operational system.

were able to find forums and marketplaces populated by
malicious hackers. Other platforms were discovered through
links posted on forums either on the Tor-network or on the
Clearnet. The system consists of three main modules built
independently before integration. The system is currently fully
integrated and actively collecting cyber threat intelligence.
Crawler: The crawler is a program designed to traverse the
website and retrieve HTML documents. Topic based crawlers
have been used for focused crawling where only webpages of
interest are retrieved [17], [6]. More recently, focused crawling
was employed to collect forum discussions from darknet [10].
We have designed separate crawlers for different platforms
(markets/forums) identified by experts due to the structural
difference and access control measures for each platform. In
our crawler, we address design challenges like accessibility,
unresponsive server, repeating links creating a loop etc. to
gather information regarding products from markets and discussions on forums.
Parser: We designed a parser to extract specific information
from marketplaces (regarding sale of malware/exploits) and
hacker forums (discussion regarding services and threats).
This well-structured information is stored in a relational
database. We maintain two databases, one for marketplaces
and the other for forums. Like the crawler, each platform
has its own parser. The parser also communicates with
the crawler from time to time for collection of temporal
data. The parser communicates a list of relevant webpages
to the crawler, which are re-crawled to get time-varying
data. For markets we collect the following important products fields: {item title, item description, vendor name, shipping details, item reviews, items sold, CVE, items left, transaction details, ratings}. For forums we collect the following
fields: {topic content, post content, topic author, post author,
author status, reputation, topic interest}.
Classifier: We employ a machine learning technique using an
expert-labeled dataset to detect relevant products and topics
from marketplaces and forums respectively discussed in Section III. These classifiers are integrated into the parser to filter
out products and topics relating to drugs, weapons, etc. not
relevant to malicious hacking.

Background: Many of the individuals behind cyber-operations
– originating outside of government run labs or military
commands – rely on a significant community of hackers.
They interact through a variety of online forums (as means
to both stay anonymous and to reach geographically dispersed
collaborators).
Darknet and Deepnet Sites: Widely used for underground
communication, “The Onion Router” (Tor) is free software
dedicated to protect the privacy of its users by obscuring
traffic analysis as a form of network surveillance [9]. The
network traffic in Tor is guided through a number of volunteeroperated servers (also called “nodes”). Each node of the
network encrypts the information it blindly passes on neither
registering where the traffic came from nor where it is headed
[9], disallowing any tracking. Effectively, this allows not
only for anonymized browsing (the IP-address revealed will
only be that of the last node), but also for circumvention
of censorship2 . Here, we will use “darknet” to denote the
anonymous communication provided by crypto-networks like
“Tor”, which stands in contrast to “deepnet” which commonly
refers to websites hosted on the open portion of the Internet
(the “Clearnet”), but not indexed by search engines [15].
Markets: Users advertise and sell their wares on marketplaces.
Darknet marketplaces provide a new avenue to gather information about the cyber threat landscape. The marketplaces
sell goods and services relating to malicious hacking, drugs,
pornography, weapons and software services. Only a small
fraction of products (13% in our collected data to date) are
related to malicious hacking. Vendors often advertise their
products on forums to attract attention towards their goods
and services.

III.

Forums. Forums are user-oriented platforms that have the
sole purpose of enabling communication. It provides the opportunity for the emergence of a community of like-minded
individuals - regardless of their geophysical location. Administrators set up Darknet forums with communication safety
for their members in mind. While structure and organization
of Darknet-hosted forums might be very similar to more
familiar web-forums, the topics and concerns of the users
vary distinctly. Forums addressing malicious hackers feature
discussions on programming, hacking, and cyber-security.
Threads are dedicated to security concerns like privacy and
online-safety - topics which plug back into and determine the
structures and usage of the platforms.
II.

We consider the classification of identifying relevant products in darknet/deepnet marketplaces and relevant topics on
forum post containing communication relevant to malicious
hacking in this paper. It is a binary classification problem
with the data sample (in this case products/forum topics)
being relevant or not. We look at both supervised and semisupervised approaches to address the classification.
A. Machine Learning Approaches
In this work, we leverage a combination of supervised
and semi-supervised methods. Supervised methods include
the well-known classification techniques of Naive Bayes
(NB), random forest (RF), support vector machine (SVM)
and logistic regression (LOG-REG). However, supervised
techniques required labeled data, and this is expensive and
often requires expert knowledge. Semi-supervised approaches
work with limited labeled data by leveraging information
from unlabeled data. We discuss popular semi-supervised

SYSTEM OVERVIEW

Fig. 1 gives the overview of the system. Through search
engines and spider services on the Tor network, human analysts
2 See

E VALUATION

the Tor Project’s official website (https://www.torproject.org/)

8

Fig. 1: System overview

approaches used in this work. We perform a grid search to
find optimal parameters for the learning techniques.

description. This, in tandem with standard stop-word removal,
greatly improved classification performance.

Label propagation (LP). The label propagation approach
[22] has been widely used for semi-supervised classification
task [3], [16], [21], [8]. It estimates the label values based
on graph Laplacian [1] where the model is represented by a
weighted graph G = (V, E) , where V indicates the vertices
representing the samples, while the edges E are the weights
indicating the similarity between points. A subset of these
vertices are labeled and these vertices are then used to estimate
the labels of the remaining under the assumption that the edges
are able to capture the similarity between samples. Hence,
the performance of these methods depends on the similarity
measure used. The most commonly used similarity measures
include k-NN and Gaussian kernel.

Misspellings and Word Variations. Misspellings frequently
occur on forums and marketplaces, which is an obstacle for the
standard bag-of-words classification approach. Additionally,
with the standard bag-of-words approach, variations of words
are considered separately (e.g. hacker, hack, hackers, etc.).
Word stemming mitigates these issue of word variations, but
fails to fix the issue of misspellings. To address this we use
character n-gram features. As an example of character n-gram
features, consider the word “hacker”. If we were using tri-gram
character features, the word “hacker” would yield the features
“hac”, “ack”, “cke”, “ker”. The benefit of this being that the
variations or misspellings of the word in the forms “hack”,
“hackz”, “”hackker”, will all have some common features.
We found that using character n-grams in the range (3, 7)
outperformed word stemming in our experiments.

Co-training (CT). The Co-training approach was proposed
by Blum and Mitchell [4]. In this approach, the feature set is
divided into two sets (assumed to be independent), and two
classifiers are trained using the limited labeled set denoted by
L . These trained classifiers are then used to estimate the labels
for the unlabeled points. High confidence label estimates from
classifier-1 are added to the labeled set L of classifier-2 and
vice versa. For the current setting we set the confidence to
70%. Every time the labeled set L is updated, the classifiers
are retrained. This procedure repeats until all of the unlabeled
points are labeled. It can be viewed as two classifiers teaching
each other.

Large Feature Space. In standard bag-of-words approach, as
opposed to the character n-gram approach, the feature matrix
gets very large as the number of words increase. As the number
of unique words grow, this bloated feature matrix begins to
greatly degrade performance. Using n-gram features further
increases the already over-sized feature matrix. To address
this issue, we leveraged the sparse matrix data structure in
the scipy3 library, which leverages the fact that most of the
entries will be zero. If a word or n-gram feature is not present
in a given sample, there is simply no entry for that feature in
the sparse matrix.
Preserving Title Feature Context. As the title and description
of the product are disjoint, we found that simply concatenating
the description to the product title before extracting features
led to sub-optimal classification performance. We believe that
by doing a simple concatenation, we were losing important
contextual information. There are features that should be
interpreted differently should they appear in the title versus the
description. Initially, we used two separate classifiers: one for
the title and one for the description. With this construction,
when an unknown product was being classified, we would
pass the title to the title classifier and the description to the
description classifier. If either classifier returned a positive
classification, we would assign the product a positive classification. However, we believe that this again led to the loss of
important contextual information. To fix this, we independently
extract character n-gram features from the title and description.

B. Experiments: Marketplaces
Marketplaces sell goods and services that do not relate to
malicious hacking, including drugs, pornography, weapons and
software services. Only a small fraction of products (13%)
are related to malicious hacking. We thus require a model
that can separate relevant products from the non-relevant ones.
The data collected from marketplaces is noisy and hence not
suitable to use directly as input to a learning model. Hence,
the raw information undergoes several steps of automated data
cleaning. We now discuss the challenges associated with the
dataset obtained and the data processing steps taken to address
them. We note that similar challenges occur for forum data.
Text Cleaning. Product title and descriptions on marketplaces
often have much text that serves as noise to the classifier
(e.g. *****SALE*****). To deal with these instances, we first
removed all non-alphanumeric characters from the title and

3 http://www.scipy.org/

9

and time investment can be reduced by applying a semisupervised approach which leverages the unlabeled data to
aid in classification. It takes approximately one minute for a
human to label 5 marketplace products or 2 topics on forums as
relevant or not, highlighting the costliness of manual labeling.
The experimental setup is similar to the supervised approach,
but this time we also utilize the large unlabeled data from each
marketplace (75%) for training.

TABLE 3: Markets and Number of products collected.
Markets

Products

Markets

Products

Market-1

439

Market-6

497

Market-2

1329

Market-7

491

Market-3

455

Market-8

764

Market-4

4018

Market-9

2014

Market-5

876

Market-10

600

1

This step yields a title feature vector and a description feature
vector. We then horizontally concatenate these vectors, forming
a single feature vector which includes separate feature sets for
the title and description.

Average

0.9

0.8

0.7

Results: We consider 10 marketplaces to train and test our
learning model. A summary of these marketplaces is shown
in Table 3. Table 4 gives an instance of products defined as
being relevant or not. With the help of security experts we label
25% of the products from each marketplace. The experimental
setup is as follows. We perform a leave-one-marketplace-out
cross-validation. In other words, given n marketplaces we
train on n − 1 and test on the remaining one. We repeat
this experiment for all the marketplaces. For the supervised
experiment, we only use the 25% labeled data from each
marketplace. We evaluate the performance based primarily
on three metrics: precision, recall and unbiased F1. Precision
indicates the fraction of products that were relevant from the
predicted ones. Recall is the fraction of relevant products
retrieved. F1 is the harmonic mean of precision and recall.
The results are averaged and weighted by the number of
samples in each market. In this application, a high recall is
desirable as we do not want to omit relevant products. In the
supervised approaches, SVM with linear kernel performed the
best, recalling 87% of the relevant products while maintaining
a precision of 85% (Fig. 2). SVM performed the best likely due
to the fact it maximizes generality as opposed to minimizing
error.

0.6

Precision
LP
CT-NB

Recall
CT-LOG-REG
CT-RF

F1
CT-SVM

Fig. 3: Average Precision, Recall and F1 comparisons for LP, CT-NB, CT-LOG-REG,
CT-RF and CT-SVM for product classification.

Fig. 3 shows the performance comparison for the semisupervised approaches. For the co-training approach, we divide
the feature space into two sets. The two feature sets used are
both based on character n-grams. However, the set of words
from which the character n-grams are derived are disjoint
between the two sets. In this way, the two corresponding
feature vectors can be treated as being independent from
one another. Hence we get two views of the same sample.
Co-training with Linear SVM is able to recall 92% of the
relevant products as compared to label propagation and other
variants of co-training while maintaining a precision of 82%,
which is desirable. In this case, the unlabeled data aided
the classification in improving the recall to 92% without
significantly reducing the precision.
C. Experiment: Forums

TABLE 4: Example of Products.
Product Title

Relevant

20+ Hacking Tools (Botnets Keyloggers Worms and More!)

YES

5 gm Colombian Cocaine

NO

In addition to the darknet/deepnet marketplaces that we
have already discussed, there are also numerous darknet forums on which users discuss malicious hacking related topics.
Again, there is the issue that only a fraction of these topics with
posts on these forums contain information that is relevant to
malicious hacking or the trading of exploits. Hence, we need a
classifier to identify relevant topics. This classification problem
is very similar to the product classification problem previously
discussed, with similar set of challenges.

0.9

Average

0.8

0.7

We performed evaluation on two such English forums.
The dataset consisted of 781 topics with 5373 posts. Table 5
gives instance of topics defined as being relevant or not.
We label 25% of the topics and perform a 10-fold cross
validation using supervised methods. We show the results
from the top two performing supervised and semi-supervised
methods. In the supervised setting, LOG-REG performed the
best with 80% precision and 68% recall (Fig. 4). On the other
hand, leveraging unlabeled data in a semi-supervised technique
improved the recall while maintaining the precision. We note
that in this case the 10-fold cross validation was performed
only on the labeled points. In the semi-supervised domain

0.6

0.5

Precision

Recall
NB

LOG-REG

RF

F1
SVM

Fig. 2: Average Precision, Recall and F1 comparisons for NB, LOG-REG, RF and SVM
for product classification.

As stated, only 25% of the data is labeled, as labeling
often requires expert knowledge. However, this significant cost

10

co-training with LOG-REG improved the recall to 80% with
precision of 78%.

TABLE 6: Example of Zero-day exploits.

TABLE 5: Example of Topics.
Topic

Relevant

Bitcoin Mixing services

YES

Looking for MDE/MDEA shipped to Aus

NO

Average

0.8

0.7

0.6

0.5

LOG-REG

Recall
SVM

CT-LOG-REG

F1
CT-SVM

Fig. 4: Average Precision, Recall and F1 comparisons for LOG-REG, SVM, CT-LOGREG, and CT-SVM for English forum topic classification.

IV.

Price (BTC)

Internet Explorer 11 Remote Code Execution 0day

20.4676

Android WebView 0day RCE

40.8956

cross-site connections that were previously unstudied. We are
able to produce this connected graph using the “usernames”
used by vendors and users in each domain. A subgraph of
this network containing some of the individuals who are
simultaneously selling products related to malicious hacking
and publishing in hacking related forums is shown in Fig. 5.
In most cases, the vendors are trying to advertise/discuss their
products on the forums, demonstrating their expertise. Using
these integrated graphic representations, one can visualize
the individuals’ participation in both domains, making the
right associations that lead to a better comprehension of the
malicious hacker networks. It is helpful in determining social
groups within the forums of user interaction. The presence
of users on multiple markets and forums follows a power law.
From Fig. 6, majority of users only belong to a single market or
forum. We note that there are 751 users that are present in more
than two platforms. Fig. 7 considers one such user/vendor. The
vendor is active in 7 marketplaces and 1 forum . The vendor
offers 82 malicious hacking related products and discusses
these products on the forum. The vendor has an average rating
of 4.7/5.0, rated by customers on the marketplace with more
than 7000 successful transactions, indicating the reliability of
the products and the popularity of the vendor.

0.9

Precision

Zero-day exploit

C ASE S TUDIES

We analyze the data with the purpose of answering the
questions raised in the Section I. We will be using the following key security terms. Vulnerability is a security flaw that
allows an attacker to compromise a software or an operating
system. Exploit is a piece of software that takes advantage of
a vulnerability in a piece of software or operating system to
compromise it. Patch is a piece of software used to improve
existing software by fixing vulnerabilities to improve security.
We discuss the following case-studies.
A. Discovery of Zero-Day Exploits.
Over a 4 week period, we detected 16 zero-day exploits
from the marketplace data. Zero-day exploits leverage vulnerabilities that are unknown to the vendor. Table 6 shows a
sample of zero-day exploits with their selling price in Bitcoin.
The Android WebView zero-day affects a vulnerability in the
rendering of web pages in Android devices. It affects devices
running on Android 4.3 Jelly Bean or earlier versions of the
operating system. This comprised of more than 60% of the
Android devices in 2015. After the original posting of this
zero-day, a patch was released in Android KitKat 4.4 and
Lollipop 5.0 which required devices to upgrade their operating
system. As not all users have/will update to the new operating
system, the exploit continues to be sold for a high price.
Detection of these zero-day exploits at an earlier stage can help
organizations avoid an attack on their system or minimize the
damage. For instance, in this case, an organization may decide
to prioritize patching, updating, or replacing certain systems
using the Android operating system.

Fig. 5: Vendor/User network in marketplace and forum.

Number of Users (Log scale)

10000
1000
100
10

1
0

2

4
Number of Platforms

6

8

Fig. 6: Users in multiple markets and
forums.
Fig. 7: A centric network of a Vendor.

B. Users having presence in markets/ forums.
Previous studies on darknet crawling [10], [2] explore a
single domain, namely forums. We create a social network
that includes both types of information studied in this paper:
marketplaces and forums. We can thus study and find these

V.

R ELATED W ORK

Web crawling is a popular way of collecting large amounts
of data from the Internet. In many applications, researchers

11

are interested in specific topics for their application. Hence,
the need for a topic-based crawler popularly referred to as
a focused crawler [6], [5]. Most of the focused crawlers are
designed to collect information from the surface web with
little concentration on the darknet websites. More recently,
a focused crawler concentrating on dark web forums was
designed [10]. This research primarily concentrated on forums,
collecting data over a period of time and then performing
static analysis to study online communities. The authors also
describe different data mining techniques for these forums
in [7]. We, on the other hand, not only look at darknet forums
but also collect information from marketplaces hosting a range
of products relating to malicious hacking. Another application
of leveraging darknet information to counter human trafficking
is developed by DARPA through the Memex program4 - a
program with different goals than the work described in this
paper.

[2]

Previous work leverages the exploit information from
marketplaces in a game theoretic framework to formulate
system configurations that minimize the potential damage of
a malicious cyber attack [19]. Work analyzing hacker forums
to detect threats that pose great risk to individuals, businesses,
and government have been discussed in [2]. It further states
that knowledge is distributed in forums. That minimally skilled
people could learn enough by simply frequenting such platforms. Studying these hacker communities gives insights in
the social relationships. Also, the distribution of information
amongst users in these communities based on their skill level
and reputation [13], [14], [11]. These forums also serve as markets where malware and stolen personal information are shared
/ sold [12]. Samtani et al. analyze hacker assets in underground
forums [20]. They discuss the dynamics and nature of sharing
of tutorials, source code, and “attachments” (e.g. e-books,
system security tools, hardware/software). Tutorials appear to
be the most common way of sharing resources for malicious
attacks. Source code found on these particular forums was
not related to specific attacks. Additionally underground (not
malicious hacking related) forums have also been analyzed
to captures the dynamic trust relationships forged between
mutually distrustful parties [18].

[8]

VI.

[3]

[4]

[5]

[6]

[7]

[9]

[10]

[11]

[12]

[13]

[14]
[15]

[16]

C ONCLUSION

In this paper, we implement a system for intelligence
gathering related to malicious hacking. Our system is currently
operational. We are in the process of transitioning this system
to a commercial partner. We consider social platforms on
darknet and deepnet for data collection. We address various
design challenges to develop a focused crawler using data
mining and machine learning techniques. The constructed
database is made available to security professionals in order
to identify emerging cyber-threats and capabilities.

[17]

[18]

[19]
[20]

Acknowledgments: Some of this work is supported by ONR NEPTUNE, ASU GSI, ASU ISSR and CNPq-Brazil.

[21]

R EFERENCES
[22]

[1] M. Belkin and P. Niyogi. Using manifold structure for partially labelled
classification. In Advances in NIPS, 2002.
4 http://opencatalog.darpa.mil/MEMEX.html

12

V. Benjamin, W. Li, T. Holt, and H. Chen. Exploring threats and
vulnerabilities in hacker web: Forums, irc and carding shops. In
Intelligence and Security Informatics (ISI), 2015 IEEE International
Conference on, pages 85–90. IEEE, 2015.
C. M. Bishop and I. Ulusoy. Object recognition via local patch labelling.
In Deterministic and Statistical Methods in Machine Learning, pages
1–21, 2004.
A. Blum and T. Mitchell. Combining labeled and unlabeled data with
co-training. In Proceedings of the Eleventh Annual Conference on
Computational Learning Theory, COLT’ 98, pages 92–100, New York,
NY, USA, 1998. ACM.
S. Chakrabarti, K. Punera, and M. Subramanyam. Accelerated focused
crawling through online relevance feedback. In Proceedings of the 11th
international conference on World Wide Web, pages 148–159. ACM,
2002.
S. Chakrabarti, M. Van den Berg, and B. Dom. Focused crawling: a new
approach to topic-specific web resource discovery. Computer Networks,
31(11):1623–1640, 1999.
H. Chen. Dark web: Exploring and data mining the dark side of the
web, volume 30. Springer Science & Business Media, 2011.
H. Cheng, Z. Liu, and J. Y. 0001. Sparsity induced similarity measure
for label propagation. In ICCV, pages 317–324. IEEE, 2009.
R. Dingledine, N. Mathewson, and P. Syverson. Tor: The secondgeneration onion router. In Proceedings of the 13th Conference on
USENIX Security Symposium - Volume 13, SSYM’04, pages 21–21,
2004.
T. Fu, A. Abbasi, and H. Chen. A focused crawler for dark web
forums. Journal of the American Society for Information Science and
Technology, 61(6):1213–1231, 2010.
T. J. Holt. Subcultural evolution? examining the influence of on-and offline experiences on deviant subcultures. Deviant Behavior, 28(2):171–
198, 2007.
T. J. Holt and E. Lampke. Exploring stolen data markets online:
products and market forces. Criminal Justice Studies, 23(1):33–50,
2010.
T. J. Holt, D. Strumsky, O. Smirnova, and M. Kilger. Examining the
social networks of malware writers and hackers. International Journal
of Cyber Criminology, 6(1):891–903, 2012.
T. Jordan and P. Taylor. A sociology of hackers. The Sociological
Review, 46(4):757–780, 1998.
D. Lacey and P. M. Salmon. It’s dark in there: Using systems analysis
to investigate trust and engagement in dark web forums. In D. Harris,
editor, Engineering Psychology and Cognitive Ergonomics, volume
9174 of Lecture Notes in Computer Science, pages 117–128. Springer
International Publishing, 2015.
A. Levin, D. Lischinski, and Y. Weiss. A closed form solution to natural
image matting. In Proceedings of the 2006 IEEE Computer Society
Conference on Computer Vision and Pattern Recognition - Volume 1,
CVPR ’06, pages 61–68, Washington, DC, USA, 2006. IEEE Computer
Society.
F. Menczer, G. Pant, and P. Srinivasan. Topical web crawlers: Evaluating
adaptive algorithms. ACM Transactions on Internet Technology (TOIT),
4(4):378–419, 2004.
M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G. M. Voelker.
An analysis of underground forums. In Proceedings of the 2011 ACM
SIGCOMM conference on Internet measurement conference, pages 71–
80. ACM, 2011.
J. Robertson, V. Paliath, J. Shakarian, A. Thart, and P. Shakarian. Data
driven game theoretic cyber threat mitigation. In IAAI, 2016.
S. Samtani, R. Chinn, and H. Chen. Exploring hacker assets in
underground forums. In Intelligence and Security Informatics (ISI),
2015 IEEE International Conference on, pages 31–36. IEEE, 2015.
C. Wang, S. Yan, L. Z. 0001, and H.-J. Zhang. Multi-label sparse
coding for automatic image annotation. In CVPR, pages 1643–1650.
IEEE, 2009.
X. Zhu, J. Lafferty, and Z. Ghahramani. Combining active learning and
semi-supervised learning using gaussian fields and harmonic functions.
In ICML 2003 workshop on The Continuum from Labeled to Unlabeled
Data in Machine Learning and Data Mining, pages 58–65, 2003.

An Empirical Evaluation Of Social Influence
Metrics
Nikhil Kumar, Ruocheng Guo, Ashkan Aleali, Paulo Shakarian

arXiv:1607.00720v3 [cs.SI] 23 Jul 2016

Arizona State University,
Tempe, AZ
Email: {nikhilkumar, rguosni, aleali, shak}@asu.edu

Abstract—Predicting when an individual will adopt a new
behavior is an important problem in application domains such
as marketing and public health. This paper examines the performance of a wide variety of social network based measurements
proposed in the literature - which have not been previously
compared directly. We study the probability of an individual
becoming influenced based on measurements derived from neighborhood (i.e. number of influencers, personal network exposure),
structural diversity, locality, temporal measures, cascade measures, and metadata. We also examine the ability to predict
influence based on choice of classifier and how the ratio of positive
to negative samples in both training and testing affect prediction
results - further enabling practical use of these concepts for social
influence applications.

I. I NTRODUCTION
Predicting when an individual will adopt a new behavior is
an important problem in application domains such as marketing [1], the spread of innovation [2], countering extremism [3],
and public health [4]. As a result, a variety of social network
based measurements have been proposed in the literature and
shown to predict how likely an individual will adopt a new
behavior given information about his immediate social ties.
However, when such measures are proposed, they are often
evaluated under different conditions - making it difficult to
understand which of these measurements should be used in
a real-world application. Further complicating the issue is
that the choice of classification algorithm and the effect of
class imbalance in both training and testing are often not
explored in most research. In our lab, we have the goal
of creating and deploying a system for counter-extremism
messaging. Hence, understanding how influence measurements
work in experimental settings that closely resemble real-world
scenarios is an important first step.
In this paper, we study measurements based on neighborhood (i.e. number of influencers [4], personal network
exposure [2]), structural diversity [5], locality [6], temporal
measures [7], cascade measures [8], and metadata [9]. We
examine the probability of an individual becoming influenced
based on these measurements (probability of adoption). We
also examine the ability to predict influence based on choice
of classifier and how the ratio of positive to negative samples in
both training and testing affect prediction results. Specifically,
we make the following contributions.

1) We review a variety of measurements used to predict
social influence and we group them in six categories
(Section III).
2) We evaluate how these measurements relate to the probability of a user being influenced using real-world microblog data (Section IV).
3) We evaluate how these measurements perform when used
as features in a machine learning approach and compare
performance across a variety of supervised machine learning approaches (Section V).
4) We evaluate how the ratio of positive to negative samples in both training and testing affect predictive results
(Section VI).
We note that contribution 4 is of particular importance, as
(particularly with microblog data) users are exposed to large
number of messages that they do not retweet (negative samples). Hence, in both training and testing, researchers can
increase the negative samples utilized by large amounts - hence
arbitrarily determining the level of class imbalance. As with
this study as a whole, the experiments on data imbalance were
to better understand these previous research results in tests that
better mimicked real-world scenarios.
Related work. Beyond the work that we shall describe
concerning the various measures for social influence we investigate in Section IV, there has been some general work
in the area of social influence that have taken approaches not
necessarily amenable to comparison. For instance, the seminal
work of Kempe et al. [10] describes two popular models for
information cascades which spawned several techniques to
learn the parameters (which also correspond to edge weights
in the graph). For example, Saito et al. [11] assigned such
probabilities based on an expectation-maximization appproach
while Goyal et al. [7] leveraged a variety of simple models
based on ideas such as a empirically-learned probabilities and
similarity measurements. See [12] for a review of some of
this work. There has also been related work on predicting cascades [13], [14], [8] which are more focused on determining
if a trend in social media exceeds a certain size. That said,
some of the ideas from these approaches, such as structural
diversity [5] are examined here (though this paper is focused
on a different problem). Other work such as Myers et al. [15]
studied the external factors influencing information diffusion,
Liu et al. [16] and Tang et al. [17] focused their studies

on topic influence. Jenders et al. [9] studied a combination
of different features including some of the metadata features
like mentions and hashtags, along with latent features like
sentiments and emotional divergence for predicting the virality
of a tweet - many of which we examine in this study as well.
Hong et al. [18] have also considered a wide spectrum of features including structural, content and temporal information.
However, their study focused more on content-based features
and not the structural features considered here - many of which
were introduced after that work.

cascades. We create the social network G from the retweeting
relationships of microblogs published between May 1, 2011
and July 31, 2011. We use the microblogs published in August
2011 to train and test our approach. Table I lists the statistics
of the dataset we used.

II. T ECHNICAL P RELIMINARIES

We found that the network derived from the dataset had
7,668,693 users with 55,381,104 edges between them. For this
network, the number of active users in August (the time period
used to study social influence) is 5,910,608 while 5,664,625 of
them have at least have one out-neighbor. During the month
of August, there were 22,182,703 retweet chains. From this
data, we removed the users who are not present in V ; we
also removed 2,660,421 empty repost chains caused by this
elimination. The dataset does not contain the repost time for
the nodes in the middle of chains. We estimated this time for
each node in the chain based on the original post time and
the final repost time. Table I lists the statistics of this dataset
during the period of study.
Among all the retweeted users we further extract the top
retweeters defined as those who had at least 100 retweets
during the period. This set of high frequency tweeters will be
used as a base for deriving the sample set for our experiments.
For each user in the above mentioned group, an occurrence of
them retweeting a post when they have an active in-neighbor
is considered as a positive instance. If any of their followees
have tweeted and they haven’t retweeted, it is considered as a
negative instance.

Here we introduce the necessary notation and describe our
social network data. We represent a social network as a graph
G = (V, E) where V is the set of vertices and E is the set
of directed edges that have sizes |V |, |E| respectively. The
intuition behind edge (v, v 0 ) is that node v can influence v 0 .
This intuition stems from how we create the edges in our
network: (v, v 0 ) is an edge if during a specified time period
there is at least one microblog posted by v that is reposted
by v 0 . For node v ∈ V , the set of in-neighbors is denoted as
ηvin , and the set of out-neighbors as ηvout . We use din
v and
to
denote
the
in-degree
and
out-degree
respectively.
We
dout
v
also assume a partition over nodes that specifies a community
structure. We assume that such a partition is static (based on
the same time period from which the edges were derived) and
the function P (V ) : V → C maps the set of nodes (V ) to the
set of communities (C), where C consists of k communities:
{C1 , C2 , ..., Ck }. We utilize the Louvain algorithm [19] to
identify our communities in this paper due to its ability to
scale.
Cascades. For a given microblog θ, we define t as the number
of time units from the initial post of θ before the microblog
was reposted by one of v’s incoming neighbors - intuitively
the time at which v was exposed to θ. We denote the subset
of nodes who originally posted or reposted θ for time period
t as Vθt . Likewise, the set of reposting relationships within
the same time period will be denoted by Rθt . Taken together,
we have a cascade: Dθt = (Vθt , Rθt ). Any valid original
microblog θ could be treated as a unique identifier for a
cascade. Given a microblog θ, vθ is the originator at instance
t0θ , which is defined as the origin time when the originator
posted the microblog θ. We denote the size of a cascade at
any particular time t as |Vθt |. For v ∈ Vθt , the set of all active
neighbors with respect to θ is defined as Sθv = Vθt ∩ ηvin . We
also define the distance dtθ (v, u) as the shortest path length
between v and u in Dθt .
Sina Weibo Dataset. The dataset we used was provided by the
WISE 2012 Challenge1 . It included a sample of microblogs
posted on Sina Weibo from 2009 to 2012. In this dataset, we
are provided with time and user information for each post and
the last repost in a chain which enabled us to derive a corpus of
1 http://www.wise2012.cs.ucy.ac.cy/challenge.html

#Users
5,910,608

#Edges
52,472,547

#Reposted tweets
2,238,659

#Reposted Users
394,441

TABLE I: Graph statistics

III. M EASUREMENTS TO P REDICT S OCIAL I NFLUENCE
In this section, we categorize several approaches for predicting social influence.
1) Neighborhood-based measures
2) Structural diversity measures
3) Influence locality
4) Cascade-based measures
5) Temporal measures
6) Metadata
We examine each of these categories in turn.
Neighborhood-based measures. These are the measures computed using each node and its immediate neighbors. These
measures represents the pair wise influence that the neighboring nodes exert on a given node. Retweeting from followees
is the primary mode of tweet visibility in a microblogging
site, as usually a tweet is visible to a user from its followee
subgraph. Specifically, we study the following
θ
• Number of active neighbors. (|Sv |) This represents
the count of active neighbors for a node v. In Damon
Centola’s notable empirical study [4], he noted that additional “social signals” – or active neighbors – significantly

•

•

increased the likelihood of an individual adopting a new
behavior.
Personal Network Exposure (PNE). (|Svθ |/din
v ) Is a
measure adopted from the social science community (i.e.
see [2] ) and has obtained recent interest (i.e. [20]). As
per [2], PNE quantifies the extent to which a person is
exposed to direct and indirect influence. This value is
defined as the ratio of number of active neighbors to total
number of neighbors. It is a measure of the fraction of
influence an active neighbor u has on v. If v has many
in-neighbors aka followees, then u’s influence is diluted
and PNE represents that dilution.
Average in-neighbor count of active neighbors.
θ
(|Σu∈Svθ din
u |/|Sv |) This is calculated by averaging the
number of in-neighbors of each active neighbor of a node.
This defines the dilution of the influence path and is
similar to the measure, number of uninfected neighbors
as described in [14]. Other releated studies include Cha
et al. [21], where they studied the effect of a social
network user’s indegree in depth, and observed that high
indegree is not necessarily correlated to influence in terms
of spawning retweets.

Structural diversity measures. This group of measurements
taken into account the structural diversity in the local neighborhood of the node - which refers to the communities present
in the neighborhood.
Ugander et al. [5] introduced structural diversity where
they studied the effect of number of connected components of
a friendship network. Fortunato et al [22] defined communities
as the set of graph vertices which are organized into groups
that seem to live fairly independently of the rest of the graph.
Weng et al. [23] used the community structure to predict the
increase in cascade size. We use the modularity maximization
method [24] for detecting communities in our dataset. The
Louvain Algorithm [19] which comes under this method is
used to derive the communities in this study due to its ability
to scale. We use two community based measures.
•

•

Active community count. (|P (Svθ )|) This is defined as
the number of adjacent communities of a given user v
with at least one active neighbor of v. The communities
that include active neighbors are more significant in this
context than rest of the adjacent communities. Shakarian
et al. have studied this measure in their book [12]
highlighting the importance of structural diversity.
Active community ratio (|P (Svθ )|/|P (ηvin )|) It is calculated as the ratio of the active community count to
the total number of adjacent communities. This is similar
to the personal network exposure [2] and represents the
dilution of the effect of active community count with
respect to other neighboring communities.

Influence locality. We examine the Influence Locality model
known as LRC-Q, introduced by Zhang et al. [6]. LRC-Q
is defined by the influence locality function Q which is a
combination of peer influence factor (g) and structural factor
(f ). Peer influence factor is obtained as a linear combination

of the geometric mean of random walk probabilities of active
neighbors and structural factor as a linear combination of the
number of circles formed by the active neighbors in the ego
network of the user v. These are defined in their paper by the
following equations.
Q = w × g + (1 − w) × f
s Y
(tvθ − tvθi ) × pvi
g = |Svθ |

(1)
(2)

vi ∈Svθ
θ

f = a log(|Svθ | + 1) + be−µ|C(Sv )|

(3)

In the above equations, pvi is the random walk probability
from the active user vi to the given user v, C(Sv ) is the
collection of circles formed by the active neighbors, tvθ is the
time at which v posted or reposted the microblog θ, µ is the
decay factor and, a, b and w are balance parameters. For our
experiments we set the value of µ as 1 and, a, b and w to be
0.5, as per the parameter settings of [6].
Cascade-based measures.
This group of measurements take into account the various
parameters that are part of a microblog cascade. There has
been many studies in the area of predicting the cascades
including Bakshy et al. [25] , Cheng et al. [13] and more
recently Guo et al. [8]. Unlike our study, there hasn’t been
many attempts to utilize the cascade parameters in predicting
retweet behavior. We study the following measures.
t
• Cascade size. (|Vθ |) Cascade size is computed as the
count of people who have retweeted a particular microblog θ at time t. This number is usually visible to the
microblog user and can have an impact on their retweet
behavior.
t
• Path length. (dθ (v, vθ )) Path length is the length of a
tweet trace path from the original tweeter to a given user
in the cascade. Watts et al. [26] were the first to study
the path length where they found that many social and
technological networks have small path lengths. Kwak et
al. [27] studied the path length in twitter, and Weng et
al. [23] studied a distance measure called Average step
distance which was based on the path length. Our study
focuses on the path length with respect to a particular
cascade Dθt .
Temporal Measure Temporal measures were given prominence in many of the prior studies either by itself, or as a
factor in combination with other measures. Goyal et al. [7]
utilized the temporal factor and attempted to predict the time
by which an influenced user will perform an action. Hong et al.
[18] studied a variety of temporal measures and observed that
they have a stronger effect on messages with low and medium
volume of retweets, compared to highly popular messages. We
study the following temporal measure.
• Retweet Time delay. (t) This is defined as the time
delay between the original tweet and the time when
v is exposed to microblog θ. The time at which a

tweet was made is another piece of information which
people are exposed to while viewing a tweet. This
can affect their decision to retweet it or not. This is
one of the temporal measures studied by Hong et al. [18].
Metadata. These are simple measures derived from the metadata associated with the tweets. We consider the presence
or absence of links, mentions and hashtags as measures for
our study. Jenders et al. [9] did an extensive analysis of a
wide range of tweet and user features regarding their influence
on the spread of tweets. They considered the number of
mentions and number of hashtags among the obvious tweet
features. They observed that tweets containing both hashtags
and mentions are more likely to be retweeted than those with
out, however as the number of hashtags/mentions in a tweet
grows, the expected number of retweets decreases. In this
study we only consider their presence or absence as a measure
and do not go into any deeper analysis.
• Presence of a link (hasLink). This is a binary value
which represents whether the original tweet had a link.
Links are usually shown as part of the tweet content. The
measure of Links in tweets is similar to that of mentions
and hashtags, but has not been studied as extensively as
either in the context of social influence.
• Presence of a mention (hasMention). A binary value
which represents whether the original tweet had a mention. Intuitively, a user might be more willing to retweet
if there is a mention of him/her or someone he/she knows.
Similar to [9], Cha et al. [21] analyzed the effect of the
number of mentions and found that mentions can be an
important measure of an individual influence in the social
network.
• Presence of a hashtag (hasHashtag). A binary value
which represents whether the original tweet had hashtags.
Hashtags are also means by which tweets become visible
to users and thus are of significance in this regard. A
deeper analysis such as [9], is beyond the scope of this
work and we only focus on how the presence or absence
of a hashtag affects the retweeting behavior.
IV. S OCIAL I NFLUENCE M EASUREMENT S TUDY
Here, we examine the distribution of various measurements
which were defined in Section III. For each of those measures,
the values are put into intervals of equal sizes and the fraction
of positive samples in the interval is plotted as the probability.
The horizontal axis shows the value intervals of the measure,
while the vertical one shows the number of occurrences for
positive instances with respect to the total amount in that
particular interval. The error bar shows twice the standard
deviation of the sample. These are shown in Fig. 1 and Fig. 2.
A detailed analysis of their distribution is given below.
Neighborhood-based measures. Active neighbor count
intuitively has a positive correlation with the influence as
shown in Fig. 1(a). Fig. 1(b) shows the active neighbor count

for the lower values which also shows similar correlation. This
is consistent with the empirical study of [4]. As the number
of retweeters among in-neighbors increases, the probability of
a person retweeting the particular tweet increases. Fig. 1(c)
shows that PNE also exhibits positive correlation like active
neighbor count. This shows the significance of PNE measure
as demonstrated by other studies such as [2] and [20].
Average in-neighbor count of Active Neighbors does not
show a clear correlation in its distribution as seen in Fig. 1(d).
Structural diversity measures. Number of active
communities shows a good positive correlation with the
retweet behavior. This result is consistent with the related
studies such as [23] and [13]. Active community ratio
also demonstrates a reasonable correlation with the positive
instances as this measure represents the dilution of community
influence based on the total number of adjacent communities.
Cascade-based measures. Intuitively, cascade size is an
important influencer in retweet behavior. If a tweet is
reasonably popular it tends to attract further retweets. The
same is revealed from the distribution in Fig. 2(c). This is
consistent with the research of [25] and [13] although they
studied a different problem. The intuition for path length is
that, as the distance from the original tweeter increases a user
is less interested in retweeting the tweet. Our results show
(Fig. 2(d)) that this intuition holds between path length 1 and
2. But, for the remaining intervals, results doesn’t correlate
well. This can be explained by comparing to the results
of [9] where they found similiar pattern while analyzing
mentions and hashtags. Further, the results of [13] indicate
that information cascade depth is related to popularity. Hence,
the microblogs that are far from the original poster may be
inherently popular as the information cascade has proceeded
to a larger depth.
Temporal. Fig. 2(e) shows that retweet time delay has slight
inverse correlation with the influence. Intuitively, the influence
of a tweet decays with time, and as people are exposed to
date/time information in the social network they are less
likely to retweet old tweets. This decay factor has been used
in works like [7], [6] etc. and above result shows the same.
Metadata. Table II shows the conditional probability of
positive instances given the meta measure value of 0 and 1,
respectively. The values from the table shows that presence or
absence of a link doesn’t seem to have much correlation with
the influence. It also shows that, the presence of mentions
seem have slight negative correlation to influence though
there is no actual intuition to base this on. But, this can be
explained by the observation in the paper [9] that as the
number of mentions in a tweet grows, the expected number
of retweets decreases. The presence of hashtag shows an
interesting correlation in Table II. This is consistent with the
study of [9] and illustrates the significance of hashtags in
enhancing the visibility of the tweet and motivating a user to

P (yi = pos |Vi = 1)
0.48
0.45
0.66

1.0
0.8

Probability

P (yi = pos |Vi = 0)
0.51
0.51
0.50

1.0
0.8
0.6
0.4
0.2
0.0

~ is a column of the design matrix corresponding
TABLE II: V
to a certain binary feature, pos represents positive label and i
is the index of the sample.

0

1

2

3

4

5

Active community count
(a)

(b)
1.0

0.2
0.0

0.4
0.2

Active neighbor count

(b)

1.0

0.2

0.2

Path length

(c)

Probability

0.6
0.4
0.2

(d)

0.6
0.4
0.2
0.0

10 99
0
20 0-19
00 99
30 -29
0 99
40 0-39
00 99
50 -49
0 99
60 0-59
00 99
70 -69
0 99
80 0-79
0 99
90 0-89
9
10 00-99 9
00 99
0-1
09
99

0-9

.6)

.5)

[0.

5-0

.4)

[0.

4-0

.3)

[0.

3-0

.2)

[0.

2-0

.1)

1-0

[0.

0-0
[0.

PNE

0 1 2 3 4 5 6 7 8 9

1.0

0.0

0.0

0.2
0.0

Avg. in-neighbor count

010 99
0-1
20 99
0
30 -299
0
40 -399
0
50 -499
0
60 -599
0-6
70 99
0
80 -799
0-8
90 99
0-9
99

Probability

0.4

0.4

0.8

0.8

0.6

0.6

Cascade size

1.0

0.8

Probability

0 1 2 3 4 5 6 7 8 9

Active neighbor count (lower values)

(a)

0.4
0.0

0.0

0-9 10-19 20-29 30-39 40-49 50-59

0.6

040 399
0
80 -799
0
12 -119
0
16 0-15 9
0 9
20 0-19 9
0 9
24 0-23 9
0 9
28 0-27 9
0 9
32 0-31 9
0 9
36 0-35 9
0 9
40 0-39 9
00 99
-43
99

0.4

0.6

0.8

0.8

Probability

0.8

Probability

Probability

0.8
0.6

0.2

Active community ratio

Probability

1.0

0.4
0.0

1.0

1.0

0.6

[0.
0-0
[0. .1)
1-0
[0. .2)
2-0
[0. .3)
3-0
[0. .4)
4-0
[0. .5)
5-0
[0. .6)
6-0
[0. .7)
7-0
.8)

~
V
hasLink
hasMention
hasHashtag

Probability

retweet them.

Time Delay
(e)

(c)

(d)

Fig. 1: Plots of Neighborhood and temporal measures. Error
bars represent two standard deviations.
V. I NFLUENCE P REDICTION
A. Methods
We derive our graph G from the dataset as described
under Section II. We use the microblogs published in August
2011 to extract the instances to train and test our approach.
Positive and negative instances are extracted as described in
Section II, and the measures described in Section III were
extracted as features for each of them. This set is used to
obtain a random sample with 1:1 negative to positive ratio,
which we will use for the classification experiments.
Classification experiments Here we examine our experiments
for predicting whether a user under given conditions will
retweet or not. As this is a binary classification task we report
the performance measurements (precision, recall and unbiased
F1) for only the positive (retweeting) class. We also examine
the classification performances of various learning algorithms.
For each of the experiments we use a training to test set ratio of
70:30 and used a 10 fold cross validation. We use the following
classification algorithms for our experiment.

Fig. 2: Plots of Structural Diversity and Cascade-based measures. Error bars represent two standard deviations.

Random Forest (RF). Random Forest [28] is a popular
ensemble method used for classification and regression.
Ensemble methods use multiple classifier algorithms to obtain
better accuracy than that could be obtained using any of the
individual classifiers. We use random forest algorithm with
bootstrap aggregating, that fits a number of decision trees
on different sub-samples of the dataset. Each decision tree
provides its own predictions which are then merged obtain a
better accuracy.
AdaBoost Classifier (AB). The AdaBoost algorithm [29]
proposed by Yoav Freund and Robert Schapire is one of the
most important ensemble methods. It is prominent among the
boosting techniques [29] which are used in conjuction with
other learning algorithms. In this method, the weak learners
are combined into a final sum representing the boosted
output. We use the particular algorithm called AdaBoostSAMME [30] and use the decision trees as the base estimator.
Logistic Regression (LR). Logistic regression is a generalized
linear model which uses a logistic function to infer the

relationship between a dependent variable and one or more
independent variables. We utilizes the binomial logistic
regression which predicts the probability that an observation
falls into one of the two categories. Logistic regression has
low varience and is less prone to overfitting.
Naive Bayes Classifier (NB). Naive Bayes is a probabilistic
classifier which is based on applying Bayes’ theorem with
independence assumption between every feature pairs. Naive
Bayes classifiers are highly scalable and less prone to the
curse of dimensionality, making it one of the top machine
learning algorithms. We implement the Gaussian Naive Bayes
algorithm for classification where the likelihood of the features
is assumed to be Gaussian.

1.0

Precision

Recall

F1

0.8
0.6
0.4
0.2
0.0

Nbr

Structural Cascade Temporal

Meta

LRC-Q Multi-Meas

(a)

1.0

Precision

Recall

F1

0.8
0.6

B. Measurement Group Comparison

0.4

Here we compare the classification performance of the
various measurement groups described in Section III. Fig. 3
shows the behavior of different feature groups using multiple
classifier algorithms, which provides a better understanding of
this all-important component in a deployed system. Generally
Random Forest provides the best performance among all
the classifier algorithms. Neighborhood-based (Nbr) measures
perform quite well in Random Forest, AdaBoost and Logistic
regression. This is consistent with what we discussed in Section IV. Structural diversity measures show less performance
compared to other groups. This can be attributed to the fact that
it is not often used independently in classification, and usually
this group performs well in conjunction with other measures
such as Neighborhood-based. LRC-Q gives performance measure comparable to the results in [6]. Cascade-based measures
are observed to perform reasonably well in Random Forest,
Logistic Regression and AdaBoost. This once again illustrates
the significance of cascade size and brings into focus the
path length measure. Temporal measure performs well in all
classifiers except Naive Bayes. Although time based measures
are frequently used as a decay factor in conjunction with other
measures ([7], [6]), our results show that it could yield high
predictive power by itself. Metadata measures show good and
consistent performance across all classifiers. As research by
[9] shows, hashtag and mentions have high predictive power
with respect to retweet behaviour and our results confirm the
significance of this measure along with the hasLinks measure.
With an eye toward a deployed system, we also examine
a “Multi-Measurement model” which is a combination of
Neighborhood, Structural, Cascade, Temporal and Metadata
measures. The Multi-Measurement model shows better performance than individual groups generally among Random
Forest, Logistic Regression and AdaBoost classifiers. The
other measures such as neighborhood-based, temporal and
LRC-Q perform reasonably well compared to rest of the individual future groups. The performance of Multi-Measurement
model shows real value in combining the various features and
individual feature groups to improve our ability to predict
retweet behavior in real world datasets.

0.2
0.0

Nbr

Structural Cascade Temporal

Meta

LRC-Q Multi-Meas

(b)

1.0

Precision

Recall

F1

0.8
0.6
0.4
0.2
0.0

Nbr

Structural Cascade Temporal

Meta

LRC-Q Multi-Meas

Meta

LRC-Q Multi-Meas

(c)

1.0

Precision

Recall

F1

0.8
0.6
0.4
0.2
0.0

Nbr

Structural Cascade Temporal
(d)

Fig. 3: Performance with different classifier algorithms. a)
Random Forest b) Logistic Regression c) Naive Bayes d)
AdaBoost.

C. Multi-Measurement Model Compared to Influence Locality
We compare our results with the LRC-Q model described in
[6]. We experimented with multiple classification algorithms
for this task and the best results were obtained using Random
Forest classifier. The results obtained using Random Forest
(RF), Logistic Regression (LR), Naive Bayes (NB) and
AdaBoost (AB) are shown in the Table III. As LRC-Q uses

Precision
0.679
0.95
0.794
0.602
0.764

Recall
0.573
0.947
0.765
0.704
0.285

F1
0.622
0.948
0.784
0.649
0.415

TABLE III: Performance of retweet behavior prediction
VI. VARYING N EGATIVE TO P OSITIVE RATIO
An important question when deploying the aforementioned
methods in a real-world application is how to best train the
model to cope with data imbalance observed in-practice. As
individuals are exposed to an arbitrarily large number of
microblogs that they do not rebroadcast, this is a difficult and unfortunately relatively unstudied problem. Here, we conducted experiments to analyse how classification performance
varies with different negative to positive ratio in both training
and test set. The surface and linear plots in Fig. 4 show the
precision, recall and F1 values obtained using Random Forest
classifier, when negative to positive ratio is varied from 1:1
to 9:1. The ratio was varied in both training set and test
set to observe the effects on overall performance. Precision
is observed to decrease as we increase the size of negative
samples in test set while keeping the ratio in training set
constant. Recall is observed to remain the same with changing
ratio in test set. Change in negative to positive ratio in training
set on the hand, shows slight increase in precision where as
recall decreases. Results for LRC-Q follows a similar pattern
except for the convergence of recall for increased imbalance in

Precision

1.00
0.95
0.90
0.85
0.80
0.75
0.70
N to 9
P tr8a765
0.65
inin432 1 9 8 7 6 5 4 3 2 1
gs
P test set

et

Precision

1
2

N to

N to P for training
3
5
7
4
6
8

9

1.00
0.95
0.90
0.85
0.80
0.75
0.70
0.65
0.60
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(a)

(b)

Recall

0.95
0.90
0.85
0.80
0.75
0.70
0.65
89

1
2

6 7 set
1 2
4 5 test
N to3P tr4 5 6
3
P
aining s7 8
2
et 9 1 N to

N to P for training
3
5
7
4
6
8

9

1.00
0.95
0.90
0.85
0.80
0.75
0.70
0.65
0.60
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(c)

(d)
1
2

0.95
0.90

F10.85

F1

Model
LRC-Q (LR)
Multi-Meas (RF)
Multi-Meas (AB)
Multi-Meas (LR)
Multi-Meas (NB)

training set. From these results, it can be generally observed
that 1:1 is the ideal ratio of negative to positive samples in
training set for an unknown imbalance in test data.

Recall

only a single feature, we only use Logistic Regression for
its evaluation. It can be observed that Multi-Measurement
model outperforms the LRC-Q model in all classifiers except
for Naive Bayes. This can be attributed to the fact that
while LRC-Q takes into account pairwise and structural
influence along with time decay, Multi-Measurement model
incorporates more parameters in addition to the above.
LRC-Q has combined the pairwise and structural factor
into a single feature and uses time measure as a decay
factor. The Multi-Measurement model on the other hand
treats them individually, along with including different
kinds of pairwise influence (such as active neighbor count,
personal network exposure and average in-neighbors of active
neighbors), considering both direct as well as ratio based
measures for structural diversity, and using temporal measure
as an independent feature. In addition to that, this model
also includes cascade and metadata based features giving
it a broader view of the parameters that can influence an
individual’s retweeting behavior. This demonstrates that in
any attempt of retweet prediction, a broader approach is
required, which incorporates multiple measures that are are
closely related (within the measurement groups) and those
that are mutually exclusive (across groups) to obtain the best
prediction in classification.

0.80
1 et
0.75
4 3 2 ng s
1 2 3 4 5 6
7 6 5 aini
N to P test set 7 8 9 9 t8o P tr

N

N to P for training
3
5
7
4
6
8

9

1.00
0.95
0.90
0.85
0.80
0.75
0.70
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(e)

(f)

Fig. 4: Plots for classification on imbalanced data for MultiMeasurement model using Random Forest. a) Precision surface plot b) Precision line plot c) Recall surface plot d) Recall
line plot e) F1 surface plot f) F1 line plot.

VII. C ONCLUSION
In this paper, we examines the performance of a wide
variety of social network based measurements and study the
probability of an individual becoming influenced based on
them. In this study, we grouped those measures under various
measurement groups to understand their group wise predictive
power. We designed these experiments so that they would
move beyond standard research-based experiments used to
evaluate an idea - we designed these experiments to understand
how well these ideas can be used in a deployed system. We
look to use these results in a system that we intend to deploy
or license for real-world influence operations such as counterextremism.

Precision

N to 9
P tr8a765
inin432 1 9 8 7 6 5 4 3 2 1
g se
N to P test set
t

Precision

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1

1
2

9

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(a)

(b)

Recall

0.6
0.5
0.4
0.3
0.2
0.1
0.0
9
8

Recall

1
2

6 7 set
1 2
4 5 test
N to3P tr4 5 6
3
P
aining s7 8
2
et 9 1 N to

N to P for training
3
5
7
4
6
8

9

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(c)

(d)

F1

1
2

0.7
0.6
0.5
F1 0.4
0.3
0.2
0.1
0.0

N to P for training
3
5
7
4
6
8

1 et
4 3 2 ng s
1 2 3 4 5 6
7 6 5 aini
N to P test set 7 8 9 9 t8o P tr

N

N to P for training
3
5
7
4
6
8

9

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
1 2 3 4 5 6 7 8 9
Negative to positive ratio in test set

(e)

(f)

Fig. 5: Plots for classification on imbalanced data for LRCQ using Logistic Regression. a) Precision surface plot b)
Precision line plot c) Recall surface plot d) Recall line plot e)
F1 surface plot f) F1 line plot.

ACKNOWLEDGMENTS
Some of the authors are supported through the AFOSR
Young Investigator Program (YIP) grant FA9550-15-1-0159,
ARO grant W911NF-15-1-0282, the DoD Minerva program
grant N00014-16-1-2015 and the EU RISE program.
R EFERENCES
[1] D. Watts and J. Peretti, “Viral marketing for the real world,” Harvard
Business Review, May 2007.
[2] T. W. Valente, Network models of the diffusion of innovations, ser.
Quantitative methods in communication.
Cresskill, N.J.: Hampton
Press, 1995, thomas W. Valente. Includes bibliographical references (p.
153-163) and indexes.
[3] S. Al-khateeb and N. Agarwal, “Examining botnet behaviors for propaganda dissemination: A case study of isil’s beheading videos-based
propaganda,” in ICDM Workshops. IEEE, 2015, pp. 51–57.
[4] D. Centola, “The Spread of Behavior in an Online Social Network
Experiment,” Science, vol. 329, no. 5996, pp. 1194–1197, Sep. 2010.
[5] J. Ugander, L. Backstrom, C. Marlow, and J. Kleinberg, “Structural
diversity in social contagion,” Proceedings of the National Academy
of Sciences, vol. 109, no. 16, pp. 5962–5966, 2012.

[6] J. Zhang, B. Liu, J. Tang, T. Chen, and J. Li, “Social influence locality
for modeling retweeting behaviors.” in IJCAI, vol. 13, 2013, pp. 2761–
2767.
[7] A. Goyal, F. Bonchi, and L. V. Lakshmanan, “Learning influence
probabilities in social networks,” in Proceedings of the third ACM
international conference on Web search and data mining. ACM, 2010,
pp. 241–250.
[8] R. Guo, E. Shaabani, A. Bhatnagar, and P. Shakarian, “Toward order-ofmagnitude cascade prediction,” in Proceedings of the 2015 IEEE/ACM
International Conference on Advances in Social Networks Analysis and
Mining 2015. ACM, 2015, pp. 1610–1613.
[9] M. Jenders, G. Kasneci, and F. Naumann, “Analyzing and predicting
viral tweets,” in Proceedings of the 22nd international conference
on World Wide Web companion.
International World Wide Web
Conferences Steering Committee, 2013, pp. 657–664.
[10] D. Kempe, J. Kleinberg, and É. Tardos, “Maximizing the spread of
influence through a social network,” in Proceedings of the ninth ACM
SIGKDD international conference on Knowledge discovery and data
mining. ACM, 2003, pp. 137–146.
[11] K. Saito, R. Nakano, and M. Kimura, “Prediction of information
diffusion probabilities for independent cascade model,” in Knowledgebased intelligent information and engineering systems. Springer, 2008,
pp. 67–75.
[12] P. Shakarian, A. Bhatnagar, A. Aleali, R. Guo, and E. Shaabani,
Diffusion in Social Networks. Springer, 2015.
[13] J. Cheng, L. Adamic, P. A. Dow, J. M. Kleinberg, and J. Leskovec,
“Can cascades be predicted?” in Proceedings of the 23rd international
conference on World wide web. ACM, 2014, pp. 925–936.
[14] L. Weng, F. Menczer, and Y.-Y. Ahn, “Virality prediction and community
structure in social networks,” Scientific reports, vol. 3, 2013.
[15] S. A. Myers, C. Zhu, and J. Leskovec, “Information diffusion and
external influence in networks,” in Proceedings of the 18th ACM
SIGKDD international conference on Knowledge discovery and data
mining. ACM, 2012, pp. 33–41.
[16] L. Liu, J. Tang, J. Han, M. Jiang, and S. Yang, “Mining topic-level
influence in heterogeneous networks,” in Proceedings of the 19th ACM
international conference on Information and knowledge management.
ACM, 2010, pp. 199–208.
[17] J. Tang, J. Sun, C. Wang, and Z. Yang, “Social influence analysis
in large-scale networks,” in Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and data mining.
ACM, 2009, pp. 807–816.
[18] L. Hong, O. Dan, and B. D. Davison, “Predicting popular messages in
twitter,” in Proceedings of the 20th international conference companion
on World wide web. ACM, 2011, pp. 57–58.
[19] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast
unfolding of communities in large networks,” Journal of Statistical
Mechanics: Theory and Experiment, vol. 2008, no. 10, p. P10008, 2008.
[20] A. Halavais, K. H. Kwon, S. Havener, and J. Striker, “Badges of
friendship: Social influence and badge acquisition on stack overflow,”
in 2014 47th Hawaii International Conference on System Sciences, Jan
2014, pp. 1607–1615.
[21] M. Cha, H. Haddadi, F. Benevenuto, and P. K. Gummadi, “Measuring
user influence in twitter: The million follower fallacy.” ICWSM, vol. 10,
no. 10-17, p. 30, 2010.
[22] S. Fortunato, “Community detection in graphs,” Physics reports, vol.
486, no. 3, pp. 75–174, 2010.
[23] L. Weng, F. Menczer, and Y.-Y. Ahn, “Predicting successful memes
using network and community structure,” in Eighth International AAAI
Conference on Weblogs and Social Media, 2014.
[24] M. Chen, K. Kuzmin, and B. K. Szymanski, “Community detection
via maximization of modularity and its variants,” Computational Social
Systems, IEEE Transactions on, vol. 1, no. 1, pp. 46–65, 2014.
[25] E. Bakshy, J. M. Hofman, W. A. Mason, and D. J. Watts, “Everyone’s
an influencer: quantifying influence on twitter,” in Proceedings of the
fourth ACM international conference on Web search and data mining.
ACM, 2011, pp. 65–74.
[26] D. J. Watts and S. H. Strogatz, “Collective dynamics of smallworldnetworks,” nature, vol. 393, no. 6684, pp. 440–442, 1998.
[27] H. Kwak, C. Lee, H. Park, and S. Moon, “What is twitter, a social
network or a news media?” in Proceedings of the 19th international
conference on World wide web. ACM, 2010, pp. 591–600.
[28] L. Breiman, “Random forests,” Machine learning, vol. 45, no. 1, pp.
5–32, 2001.

[29] Y. Freund, R. Schapire, and N. Abe, “A short introduction to boosting,”
Journal-Japanese Society For Artificial Intelligence, vol. 14, no. 771780, p. 1612, 1999.
[30] J. Zhu, H. Zou, S. Rosset, and T. Hastie, “Multi-class adaboost,”
Statistics and its Interface, vol. 2, no. 3, pp. 349–360, 2009.

Toward Order-of-Magnitude Cascade Prediction
Ruocheng Guo , Elham Shaabani, Abhinav Bhatnagar and Paulo Shakarian

arXiv:1508.03371v1 [cs.SI] 13 Aug 2015

Arizona State University
Tempe, AZ
Email: {rguosni, shaabani, abhatn, shak}@asu.edu
Abstract—When a piece of information (microblog, photograph, video, link, etc.) starts to spread in a social network, an
important question arises: will it spread to “viral” proportions
– where “viral” is defined as an order-of-magnitude increase.
However, several previous studies have established that cascade
size and frequency are related through a power-law - which leads
to a severe imbalance in this classification problem. In this paper,
we devise a suite of measurements based on “structural diversity”
– the variety of social contexts (communities) in which individuals
partaking in a given cascade engage. We demonstrate these
measures are able to distinguish viral from non-viral cascades,
despite the severe imbalance of the data for this problem. Further,
we leverage these measurements as features in a classification
approach, successfully predicting microblogs that grow from 50
to 500 reposts with precision of 0.69 and recall of 0.52 for the
viral class - despite this class comprising under 2% of samples.
This significantly outperforms our baseline approach as well as
the current state-of-the-art. Our work also demonstrates how we
can tradeoff between precision and recall.

I.

I NTRODUCTION

When a piece of information (microblog, photograph,
video, link, etc.) starts to spread in a social network, an
important question arises: will it spread to “viral” proportions
– where “viral” is defined as an order-of-magnitude increase.
Several previous studies [1], [2] have established that cascade
size and frequency are related through a power-law - which
leads to a severe imbalance in this classification problem.
In this paper, we devise a suite of measurements based on
“structural diversity” that are associated with the growth of a
viral cascade in a social network. Structural diversity refers
to the variety of social contexts in which an individual engages and is typically instantiated (for social networks) as the
number of distinct communities represented in an individual’s
local neighborhood. Previously, Ugander et al. identified a
correlation between structural diversity and influence [?]. We
demonstrate these measures are able to distinguish viral from
non-viral cascades, despite the severe imbalance of the data
for this problem. Further, we leverage these measurements as
features in a classification approach, successfully predicting
microblogs that grow from 50 to 500 reposts with precision
of 0.69 and recall of 0.52 for the viral class (under 2% of the
samples).
We note that our results on the prediction of cascades
rely solely upon the use of our structural diversity based
measures for features and limited temporal features - hence
the prediction is based on network topology alone (no content
information was utilized). We also achieved these results while
maintaining the imbalances of the dataset - which we felt better
U.S. Provisional Patent 62/201,517. Contact shak@asu.edu for licensing
information

mimics reality. This differs from some previous studies which
balance the data before conducting classification. Further,
we note that we obtained prediction of order-of-magnitude
increases in the size of the cascade - which also differs from
other work (i.e. [1]) which focus on identifying cascades that
double in size.
II.

T ECHNICAL P RELIMINARIES

Here we introduce necessary notation and describe our
social network data. We represent a social network as a graph
G = (V, E) where V is the set of vertices and E as set
of directed edges that have sizes |V |, |E| respectively. The
intuition behind edge (v, v 0 ) is that node v can influence v 0 .
This intuition stems from how we create the edges in our
network: (v, v 0 ) is an edge if during a specified time period
there is at least one microblog posted by v that is reposted by
v 0 (we leave other thresholds beyond 1 repost to future work).
We shall also assume a partition over nodes that specifies a
community structure. We shall assume that such a partition is
static (based on the same time period from which the edges
were derived) and that the partition C consists of k communities: {C1 , C2 , ..., Ck }. There are many possible methods to
derive the communities (if user-reported communities are not
available). We utilize the Louvain algorithm to identify our
communities in this paper due to its ability to scale.
Cascades. For a given microblog θ, we denote the subset
of first-m nodes who originally posted or reposted θ as Vθm
and refer to them as adopters (at size m). Likewise, the
set of reposting relationships within the same time period
will be denoted Rθm . Taken together, we have a cascade:
Dθm = (Vθm , Rθm ). Any valid original microblog θ could
be treated as a unique identifier for a cascade. Given a
microblog θ, vθ is the originator at instance t0θ , which is
defined as the origin time when the originator posted the
microblog θ and time t is time since t0θ . The mth repost
of the microblog θ happens at time tm
θ . As m increases, a
cascade accumulates nodes and edges over time. We shall
use Nθ to denote the final size of a cascade while the size
of a cascade at any particular instance is the set of nodes
present at that instance is simply |Vθm |. For a given size m,
we shall refer to the frontiers as the outgoing neighbors of the
adopters in graph G who are not adopters themselves. Formally: Fθm = {v ∈ V /Vθm s.t. ∃vi ∈ Vθm where (vi , v) ∈ E}.
For nodes in G that are outside the adopters, we shall use
the notation texp (v, θ, m) to denote the number of time units
from the initial post of θ before the microblog was reposted
by one of v’s incoming neighbors - intuitively the time at
which v was exposed to θ. For a given natural number λ
(used to specify a time period), we define the λ frontiers
as a subset of the frontiers that have been exposed to θ

no earlier than λ time units previously. Formally this set
is defined as follows: Fθm,λ = {v ∈ Fθm |texp (v, θ, m) ≤ λ}.
Finally, the complement of this set are the λ non-adopters:
F̄θm,λ = {v ∈ Fθm |texp (v, θ, m) > λ}.
Sina Weibo Dataset. The dataset we used was provided by
WISE 2012 Challenge1 . It included a sample of microblogs
posted on Sina Weibo from 2009 to 2012. In this dataset, we
are provided with time and user information for each post
and subsequent repost which enabled us to derive a corpus
of cascades. From this data, we derived our social network
G = (V, E) (with 17.9 M vertices and 52.4 M edges) that
was created from reposts that were published during the 3
month period between May 1, 2011 and July 31, 2011. For this
network, the average clustering coefficient is 0.107. There are
4974 connected components in the network. Louvain algorithm
outputs 379,416 communities with average size of 47.5 for
this network. As expected, this network exhibits a power-law
degree distrubtion. For this network, the number of active
nodes in August (the time period we studied for cascade
prediction) is 5,910,608, while 5,664,625 of them at least have
one out-neighbor. During the month of August, there were
9,323,294 reposts with 2,252,368 different original microblogs.
1,920,763 (86.6%) of them were written by authors who at
least published one microblog during May 1, 2011 to July
31, 2011 (the time period we used to create the underlying
network). The average time it took for viral cascades to become
viral is approximately 18 hours. The distribution of final
size of cascades mimics a power-law distribution which can
demonstrate that this dataset is more representative of cascade
behavior observed “in the wild”. This differs significantly
from the previous works which conduct biased sampling to
artificially provide balanced classes. We selected λ as 30
minutes as 90% of all reposts in the initial 3 month period
occurred in under this time.
Number of communities. For V 0 ⊆ V , the associated communities C(V 0 ) are the communities represented by V 0 . Formally:
C(V 0 ) = {Ci ∈ C s.t. V 0 ∩ Ci 6= ∅}. The cardinality of this set
(number of communities) will be denoted K(V 0 ). We measure
the number of communities represented by the above three
populations of nodes: K(Vθm ), K(Fθm,λ ), K(F̄θm,λ ) observed
at either a given cascade size.
Gini impurity. For V 0 ⊆ V , the gini impurity, IG (V 0 ) is the
probability of a node in V 0 being placed into the incorrect
community if assigned a community based on the distribution
of communities represented in V 0 . Formally: IG (V 0 ) =
P |Ci ∩V 0 |
1 − i ( |V 0 | )2 . We study the gini impurity of the adopters,
λ non-adopters and λ frontiers for either a given cascade size
m: IG (Vθm ), IG (Fθm,λ ), IG (F̄θm,λ ). The intuition is to capture
a notion of how the communities are distributed amongst the
nodes in each of these sets with a single scalar value. We note
that the impurity of the adopter set IG (Vθm ) behaves similar
to the entropy of this set (a measurement introduced in [3]).
However, as we will see in the next two sections, we found
that the impurity of the λ frontiers is a more discriminating
feature.
Overlap. For Va , Vb ⊂ V , the overlap (O(Va , Vb )) is simply
the number of shared communities. Formally: O(Va , Vb ) =
1 http://www.wise2012.cs.ucy.ac.cy/challenge.html

|C(Va ) ∩ C(Vb )|. We study overlap between adopters and λ
frontiers, between adopters and λ non-adopters, and between
λ frontiers and λ non-adopters: O(Vθm , Fθm,λ ), O(Vθm , F̄θm,λ ),
and O(Fθm,λ , F̄θm,λ ) respectively. The intuition with overlap
stems directly from the original structural diversity results
of [?] - for instance a high overlap between adopters and
λ frontiers may indicate that the λ frontiers are linked to
adopters with inner-community connections and high structural
diversity - hence increasing the probability of adoption.
Average time to adoption. The average time to adoption for
the nodes in P
the current set of adopters (once the cascade grows
m
tiθ
to size m): i=1
. We also use average time to adoption as
m
a baseline measure.
III.

R ESULTS

Here we examine the behavior of the various structural diversity measurements as viral and non-viral cascades
progress. We define a cascade as viral if the number of
reposts reaches a threshold (denoted T H) of 500 (in the
next section we will explore other settings for T H when
describing our classification results). We look at snapshots of
the cascades as they progress both in terms of size (denoted
m). For m = {10, 30, 50, 100, 200}, the number of samples
is {98832, 26733, 13285, 4722, 1324} respectively with 208 of
the samples are viral. With each size m we consider the
m
Cascades with m adopters at some time tm
θ , tθ can vary for
different θ. Hence, cascades with final size N < m are ignored
in our analysis task. This leads to a decrease in the number of
non-viral Cascades as m increases.
Average time to adoption. As a baseline measurement, we
study the average time to adoption for each size-based stage
of the cascade process (Fig. 1i, Fig. 1j). As expected, viral
cascades exhibit a faster rate of reposting. While we note that
significant differences are present - especially in the early
stages of the cascade, the whiskers of the non-viral class
indicate a significant proportion of non-viral cascades that
exhibit rapid adoption. We believe this is likely due to the fact
that certain cascades may have very high appeal to specialized
communities.
Number of communities. Fig. 1a, Fig. 1b, Fig. 1c and Fig. 1d
display how the number of communities K(V 0 ) n
increases over
o
m = {10, 30, 50, 100, 200} for the sets V 0 = Vθm , Fθm,λ .
We note that K(Vθm ) (the communities represented in the
set of adopters) was shown to be a useful feature in [3]
for tasks where the target class had fewer reposts than in
this study. Here, we note that while statistically significant
differences exist, the average and median values at each of the
examined stages are generally similar. On the other hand, the
communities represented by the set of λ frontiers (K(Fθm,λ ))
shows viral Cascades have stronger capability than non-viral
ones to keep a diverse set of λ frontiers. We also noted that the
median of K(F̄θm,λ ) (not pictured) shows viral cascades start
with smaller K(Fθm,λ ). However, it increases faster in viral
cascades as nodes in λ frontiers becomes λ non-adopters.
Gini impurity. Cascades in both classes tend to accumulate
diversity in the process of collecting more adopters - and we
have also noted that a related entropy measure (studied in [3])
performed similarly. We also noted (not pictured) that in the

Cm

Pm
i
i=1 tθ
m

, m = 50

early stages, viral cascades can show more diversity in λ frontiers measured by IG (Fθm,λ ) (m = {10, 30, 50}). But, perhaps
most striking, that non-viral Cascades gain more uniformly
distributed nodes over communities in λ non-adopters, shown
by IG (F̄θm,λ ) (Fig. 1g, Fig. 1h). We believe that this is due to
non-viral cascades likely have an appeal limited to a relatively
small number of communities - hence those not adopting the
trend may represent a more diverse set of communities.
Overlap. We found that overlap grows with the number
of adopters in the three types of overlap considered. For
O(Vθm , Fθm ), viral cascades start with a larger initial value
and keep leading non-viral ones in the diffusion process of first
200 nodes (Fig. 1e, Fig. 1f). This may hint that viral cascades
also take advantage of the densely linked communities to help
them become viral. However, in the case of O(Vθm , F̄θm ) and
O(Fθm,λ , F̄θm,λ ), viral cascades begin with lower value but
grow much faster than non-viral Cascades.
Classification Experiments. Here we examine our experiments for predicting whether a cascade becomes viral - when
a size threshold (T H) exceeds 500 adopters given that the
cascade has 50 adopters (s = 50). Based on the distribution
of final size of cascades in this dataset, this is a binary
classification task with two heavily imbalanced classes. Hence,
we report performance measurements (precision, recall and
F1 score) for only the minority (viral) class. Throughout the
course of our experiments, we found that varying threshold
(slightly modifying the definition of “viral”) for only the training set allows for a trade-off between precision and recall. We
study the trend of performance measures in two cases: (1.) The
threshold for test set is maintained as T Hts = 500 while the
training threshold is varied T Htr = {300, 400, 500, 600, 700}.
(2.) The two thresholds are kept as the same T H while we
modify this value T H = {300, 400, 500, 600, 700}.
Table I shows the groups of features used in our prediction
tasks. The features introduced in this paper is group Am . As
a baseline method for size-based prediction (feature group
Cm ) we used average time to adoption. We also compare our
features (Group Am ) with the community features extracted
in [3] (Group Bm ). This was the best performing feature set
in that paper for a comparable task.2 Additionally, we study
the average size of recalled and non-recalled viral cascades by
classifiers using features in groups Am . We also investigate
the significance and performance of individual and certain
combinations of features introduced in this paper.
We used ten-fold cross-validation in our experiments to
2 This was their highest-performing set of features for predicting cascades
that grew from 50 to 367 and 100 to 417 reposts. We also included the
baseline feature in this set as we found it improved the effectiveness of this
approach.

10

30

50

100

Number of Adopters

48.0
47.6

200

(a) Number of communities amongst
adopters (K(Vθm )) for non-viral cascades

1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0

M: 7.0
A: 25.7

10

15.0
39.6

20.0
53.2

30

50

100

Number of Adopters

200

M: 3.0
A: 3.7

9.0
8.7

12.0
12.3

19.0
18.5

1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0

60

50

50

40

40

30
10
0

30

50

100

Number of Adopters

34.0
34.0

46.5
46.5

30

50

100

200

Number of Adopters

M: 21.0
A: 24.3

10

30.0
41.7

30.0
44.4

33.5
78.7

42.5
88.6

30

50

100

200

Number of Adopters

M: 7.0
A: 6.7

13.0
12.7

17.0
16.5

22.5
22.2

31.0
29.5

30

50

100

200

30
20

M: 0.8
A: 0.8

0.9
0.9

0.9
0.9

0.9
0.9

0

200

10

Number of Adopters

(f) Overlap of adopters and λ frontiers (O(Vθm , Fθm,λ )) for viral cascades

0.9
0.9

1.0

0.8

M: 0.0
A: 0.4

0.9
0.8

0.9
0.9

0.9
0.9

0.9
0.9

30

50

100

200

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0

0.0

10

30

50

100

Number of Adopters

200

(g) Gini impurity of λ non-adopters
(IG (F̄θm,λ )) for non-viral cascades

1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0

23.0
23.5

10
10

(e) Overlap of adopters and λ frontiers (O(Vθm , Fθm,λ )) for non-viral
cascades

1.0

10

17.0
17.3

(d) Number of communities amongst
λ frontiers (K(Fθm,λ )) for viral cascades

26.0
25.2

20

M: 8.0
A: 8.1

(b) Number of communities amongst
adopters (K(Vθm )) for viral cascades

27.0 33.0
88.5 111.1

(c) Number of communities amongst
λ frontiers (K(Fθm,λ )) for non-viral
cascades

60

70
60
50
40
30
20
10
0

Number of Communities

Community Features Mentioned in [3] and Cm

35.0
34.9

Overlap

, m ∈ {30, 50}

Bm

25.0
24.0

Gini

Pm
i
i=1 tθ
m

18.0
17.5

M: 865.9
A: 780.3

10

853.1 804.5 754.6 765.2
790.1 771.0 753.8 759.9

30

50

100

Number of Adopters

(i) Non-viral cascades

200

10

Number of Adopters

(h) Gini impurity of λ non-adopters
(IG (F̄θm,λ )) for viral cascades

Average Time(103 )

|Fθm,λ |, |F̄θm,λ |,

Number of Communities

O(Vθm , Fθm,λ ),O(Vθm , F̄θm,λ ),O(Fθm,λ , F̄θm,λ ),

Number of Communities(102 )

Am

Overlap

K(Fθm,λ ),K(F̄θm,λ ),IG (Vθm ),IG (Fθm,λ ),IG (F̄θm,λ ),

M: 8.0
A: 7.7

Gini

Feature(s) over size

Average Time(103 )

Group

70
60
50
40
30
20
10
0

Number of Communities(102 )

TABLE I: Features: Cascade Prediction over Time and Size

1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0

M: 15.3
A: 40.9

10

49.7 78.4 168.1 301.1
86.9 129.4 215.8 347.7

30

50

100

Number of Adopters

200

(j) Viral cascades

Fig. 1: Number of communities, gini impurity, overlap and average time since t0θ to adoption for m = {10, 30, 50, 100, 200}

Am
Bm

Cm

precision

1.0

recall

f1 score

0.8

Size (103 )

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0 Precision

0.6
0.4
Recall

F1 Score

Fig. 2: Classification results based on groups of features
(Am ,Bm ,Cm ) extracted when m = 50 for fixed T Htr = 500,
T Hts = 500. Error bars represent one standard deviation.
ensure the results do not take any advantage of randomness in picking training and testing sets. First we carried
out the prediction tasks with fixed thresholds T Htr =
500, T Hts = 500. Then we modify the training threshold T Htr = {300, 400, 500, 600, 700} to show how this
achieves a trade-off between precision and recall. The difference in average final size between correctly classified viral
cascades and incorrectly classified ones is also monitored
over T Htr = {300, 400, 500, 600, 700} to show the potential
to predict exact number of adopters by features. Furthermore, we modify threshold of both training and testing sets
T H = {300, 400, 500, 600, 700} to show the robustness of
our features on related classification problems. We used the
oversampling method SMOTE with random forest classifier to
generate synthetic samples for the viral class. Other, lesserperforming classifiers were also examined (including SVM,
MLP, and other ensemble methods) and are not reported here.
All results shown in this section is a sample mean produced by
ten repeated experiments under each combination of variables.
Size-based prediction. We studied cascades of size 50 that
reached 500 for this task. There are 13,285 cascades that can
reach the size m = 50 while 208 out of them reached the size
of 500. Maintaining the threshold T H = 500, Fig. 2 shows
random forest classifier trained with features in group Am can
outperform the other groups. The trade-off between precision
and recall can be achieved by changing the training threshold T Htr while maintaining the testing threshold (Fig. 3a).
We also note that the average final size of viral cascades
recalled by the classifier increases with the training threshold
(Fig. 3b). With threshold T H = {300, 400, 500, 600, 700}
on both training and testing samples, the features of group
Am consistently outperform those previously introduced (Bm )
(Fig. 3c, Fig. 3d).
Feature investigation. Here we investigate the importance of
each feature in Am . With T Htr = 500 and T Hts = 500,
we trained 100 randomized logistic regressions models - each
assigning weights to the features in those sets. We then
categorized the features with weight larger than 0.01 (on
average) into groups such as overlap, gini impurity, etc. Then,
we performed classification on the basis of single feature
categories or combination of such categories. The average
weights assigned are shown in Table II. As shown by these
results, overlaps can make significant contribution to cascade
prediction. Intuitively, communication between two sets of
nodes is more likely to happen in their shared communities which is consistent with the results of [?]. This implies that the
larger overlap value, the more influence of one set on the other.
For example, we can infer that viral cascades tend to have

0.2

300

400
500 600
Training Threshold

700

1.4
recalled
not recalled
1.3
1.2
1.1
1.0
0.9
0.8
0.7
0.6 300
400
500
600
Training Threshold

mean

700

(a) Results for features in Am with (b) Average final size of viral cascades
different T Htr .
(recalled, mean and not recalled)
1.0

precision

recall

f1 score

1.0

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0 300

400
500 600 700
Training/Testing Threshold

precision

0.0 300

recall

f1 score

400
500 600 700
Training/Testing Threshold

(c) Results for features in group Am (d) Results for features in group Bm
when T Htr and T Hts change.
when T Htr and T Hts change.

Fig. 3: Prediction results for Am when T Htr and T Hts
change. Error bars represent one standard deviation.

Name
Gini

Baseline

Features

Weights

IG (Fθ50,λ )
IG (F̄θ50,λ )
IG (F̄θ30,λ )
P50
i
i=1 tθ
50

0.02
0.02
0.52

Name

Features

Weights

O(Vθ30 , Fθ30,λ )

0.50

O(Vθ30 , F̄θ30,λ )

0.04

Overlap O(F 30,λ , F̄ 30,λ )
θ
θ

1.00

0.23

O(Vθ50 , Fθ50,λ )

0.50

O(Fθ50,λ , F̄θ50,λ )

0.26

TABLE II: Weights of features assigned by randomized logistic
regression models
larger O(Vθm , Fθm,λ ) value for adopters have larger chance to
influence the λ frontiers than non-viral cascades. Moverover,
the gini impurity of λ non-adopters also shows its importance.
Intuitively, non-viral cascades are easier to be trapped in a
relatively small amount of communities. This means even if
they could show up in people’s timeline with high structural
diversity but can not get them infected.
IV.

ACKNOWLEDGMENT

This work is supported through the AFOSR Young Investigator Program (YIP), grant number FA9550-15-1-0159.
R EFERENCES
[1]

J. Cheng, L. Adamic, P. A. Dow, J. M. Kleinberg, and J. Leskovec,
“Can cascades be predicted?” in Proceedings of the 23rd international
conference on World wide web.
International World Wide Web
Conferences Steering Committee, 2014, pp. 925–936.
[2] P. Shakarian, A. Bhatnagar, A. Aleali, R. Guo, and E. Shaabani,
Diffusion in Social Networks. Springer (in press), 2015. [Online].
Available: http://lab.engineering.asu.edu/cysis/diffusion/
[3] L. Weng, F. Menczer, and Y.-Y. Ahn, “Predicting successful memes
using network and community structure,” in Eighth International AAAI
Conference on Weblogs and Social Media, 2014.

2012 ASE International Conference on Social Informatics (SocialInformatics 2012) / 2012 ASE International Conference on Cyber
2012
International
Conference
on Social
Informatics
Security (CyberSecurity
2012)
/ 2012 ASE
International
Conference
on BioMedical Computing

Shaping Operations to Attack Robust Terror
Networks
Devon Callahan, Paulo Shakarian

Jeffrey Nielsen, Anthony N. Johnson

Network Science Center and
Dept. of Electrical Engineering and Computer Science
United States Military Academy
West Point, NY 10996
devon.callahan[at]usma.edu, paulo[at]shakarian.net

Network Science Center and
Dept. of Mathematical Science
United States Military Academy
West Point, NY 10996
jeffrey.nielsen[at]usma.edu, anthony.johnson[at]usma.edu

on individuals likely to emerge as new leaders [2]. However,
targeting or obtaining information about certain individuals
may not always be possible. Hence, in this paper, we target
nodes that affect the reduce the network’s ability regenerate
leadership as a whole.
The main contributions of this paper is the introduction of a
formal problem we call FRAGILITY (Section II) which seeks
to ﬁnd a set of nodes whose removal would maximize the
network-wide centrality. We also included in the problem a
“no strike list” - nodes in the network that cannot be targeted
for various reasons. This is because real-world targeting of terrorist or insurgent networks often includes restrictions against
certain individuals. We also prove that this problem is NPcomplete (and the associated optimization problem is NP-hard)
which means that an efﬁcient algorithm to solve it optimally
is currently unknown. We then provide two algorithms for
solving this problem (Section III). We introduce a greedy
heuristic that we show experimentally (in Section IV) to
provide good results in practice (as we demonstrate on six
different real-world terrorist networks). In examining ﬁve realworld terrorist networks, we found that successful targetting
operations against only 12% (or less) of nodes can increase the
network-wide centrality between 17% and 45%. Additionally,
we discuss related work further in Section V.
We would like to note that the targeting of individuals in a
terrorist or insurgent network does not necessarily mean to that
they should be killed. In fact, for “shaping operations” as the
ones described in this paper, the killing of certain individuals
in the network may be counter-productive. This is due to the
fact that the capture of individuals who are likely emergent
leaders may provide further intelligence on the organization
in question.

Abstract—Security organizations often attempt to disrupt terror or insurgent networks by targeting “high value targets”
(HVT’s). However, there have been numerous examples that
illustrate how such networks are able to quickly re-generate
leadership after such an operation. Here, we introduce the notion
of a shaping operation in which the terrorist network is ﬁrst
targeted for the purpose of reducing its leadership re-generation
ability before targeting HVT’s. We look to conduct shaping by
maximizing the network-wide degree centrality through node
removal. We formally deﬁne this problem and prove solving it is
NP-Complete. We introduce a greedy heuristic for to approximate
this problem. We implement the greedy heuristic and found in
examining ﬁve real-world terrorist networks that removing only
12% of nodes can increase the network-wide centrality between
17% and 45%.
Index Terms—complex networks, terrorism, algorithms, sociology

I. I NTRODUCTION
Terrorist and insurgent networks are known for their ability
to regenerate leadership after targeted attacks. For example,
the infamous Al Qaeda in Iraq terrorist leader Abu Musab alZarqawi was killed on June 8th, 2006 1 only to be replaced
with Abu Ayyub al-Masri about a week later. 2 Here, we
introduce the notion of a shaping operation in which the
terrorist network is ﬁrst targeted for the purpose of reducing
its leadership re-generation ability. Such shaping operations
would then be followed by normal attacks against high value
targets – however the network would be less likely to recover
due to the initial shaping operations. In this paper, we look
to shape such networks by increasing network-wide centrality,
ﬁrst introduced in [1]. Intuitively, this measure provides insight
into the criticality of high-degree nodes. Hence, a network
with a low network-wide centrality is a more decentralized
organization and likely to regenerate leadership. In the shaping
operations introduced in this paper, we seek to target nodes
that will maximize this measure - making follow-on attacks
against leadership more effective. Previous work has primarily
dealt with the problem of leadership regeneration by focusing

II. T ECHNICAL P RELIMINARIES AND C OMPUTATIONAL
C OMPLEXITY
We assume that an undirected social network is represented by the graph G = (V, E). Additionally, we assume
a “no strike” set, S ⊆ V . Intuitively, these are nodes in a
terrorist/insurgent network that cannot be targeted. This set
is a key part of our framework, as real-world targeting of
terrorist and/or insurgents in a terrorist/insurgent network is

1 http://www.nytimes.com/2006/06/08/world/middleeast/08cndiraq.html? r=1
2 http://articles.cnn.com/2006-06-15/world/iraq.main 1 al-zarqawi-alqaeda-leader-zawahiri? s=PM:WORLD

978-0-7695-5015-2/12 $26.00 © 2012 IEEE
978-0-7695-4938-5/12
DOI 10.1109/SocialInformatics.2012.22

13

degree centrality of a network G, denoted CG is deﬁned as:
 ∗
i dG − di
CG =
(1)
(NG − 1)(NG − 2)

Fig. 1.

We note that there are other types of network-wide centrality
(i.e. network-wide betweenness, closeness, etc.). We leave the
consideration of these alternate deﬁnitions of network-wide
centrality to future work.
 Freeman [1] shows that for a star
network, the quantity i d∗G − di equals (NG − 1)(NG − 2)
- and this is the maximum possible value for this quantity.
Hence, the value for CG can be at most 1. As this equation
is clearly always positive, network-wide degree centrality is a
scalar in [0, 1]. Turning back to Example 2.1, we can compute
CGsam = 0.38 - which seems to indicate that in this particular
terrorist/insurgent network that, after leadership is targeted,
there is a cadre of second-tier individuals who can eventually
take control of the organization. Throughout this paper, we
ﬁnd it useful to manipulate Equation 1 as follows.

Sample network (Gsam ) for Example 2.1.

often accompanied by real-world constraints. For example,
consider the following:
•

•
•

•

We may know an individual’s relationships in the terrorist/insurgent network, but may not have enough information (i.e. where he or she may reside, enough evidence,
etc.) to actually target him or her.
The potential target may be politically sensitive.
The potential target may have ﬂed the country or area of
operations but still maintains his or her role in the terrorist/insurgent network through electronic communication.
The potential “target” may actually be a source of intelligence and/or part of an ongoing counter-intelligence
operation (i.e. as described in [3]).

CG

=

NG d∗G − 2MG
(NG − 1)(NG − 2)

(2)

We notice that the centrality of a network really depends
on three things: number of nodes, number of edges, and
the highest degree of any node in the network. We leverage
this re-arranged equation in many of our proofs. Further, we
will use the function f ragileG : V →  to denote the
level of network-wide of the graph after some set of nodes
is removed. Hence, f ragileG (V  ) = CG(V −V  ) . We note
that this function has some interesting characteristics. For
example, for some subset V  ⊂ V and element i ∈ V − V  ,
it is possible that f ragileG (V  ) > f ragile(V  ∪ {i}) or
f ragileG (V  ) < f ragile(V  ∪ {i}), hence f ragileG is not
necessarily monotonic or anti-monotonic in this sense. Further,
given some additional element j ∈ V − V  , it is possible
that f ragileG (V  ∪ {j}) − f ragileG (V  ) > f ragileG (V  ∪
{i, j}) − f ragileG (V  ∪ {j}) or f ragileG (V  ∪ {j}) −
f ragileG (V  ) < f ragileG (V  ∪{i, j})−f ragileG (V  ∪{j}).
Hence, f ragileG is not necessarily sub- or super- modular
either. Consider Example 2.2.
Example 2.2: Consider the network Gsam in Figure 1.
Here, f ragileGsam (∅) = 0.33, f ragileGsam ({a}) =
f ragileGsam ({b}) = 0.57, f ragileGsam ({c}) = 0.30, and
f ragileGsam ({a, b}) = 0.0. The fact that f ragileGsam ({c} <
f ragileGsam (∅) and f ragileGsam ({a} > f ragileGsam (∅)
illustrate that f ragileGsam is not necessarily monotonic or
anti-monotonic. Now let us consider the incremental increase
of adding an additional element. Adding a to ∅ causes
f ragileGsam to increase by 0.24 while adding a to {b} ⊃ ∅
causes f ragileGsam to decrease by 0.57 - implying submodularity. However, adding c to ∅ causes f ragileGsam to
decrease by 0.03 while adding c to set {a, b} ⊃ ∅ causes
f ragileGsam to increase by 0.1 (as f ragileGsam ({a, b, c} =
0.1) - implying super-modularity. Hence, f ragileGsam is not
necessarily sub- or super- modular.

Throughout this paper we will also use the following
notation. The symbols NG , MG will denote the sizes of V, E
respectively. For each i ∈ V , we will use di to denote the
degree of that node (the number of individuals he/she is conwe extend
nected to) and ηi to denote the set of neighbors and 
this notation for subsets of V (for V  ⊆ V, η(V  ) = i∈V  ηi ).
We will use the notation κi to denote all edges in E that are
adjacent to node i and the notation d∗G to denote the maximum
degree of the network. Given some subset V  ⊆ V , we will
use the notation G(V  ) to denote the subgraph of G induced
by V  . We describe an example network in Example 2.1.
Example 2.1: Consider network Gsam in Figure 1. Nodes a
and b may be leaders of a strategic cell that provides guidance
to attack cells (nodes c-f and g-j). Note that no members in
the attack cells are linked to each other. Also note that if node
a is the leader, and targeted, he could easily be replaced by
b.
A. Network-Wide Degree Centrality
We now introduce the notion of network-wide degree centrality as per [1]. The key intuition of this paper is to use this
centrality as a measure of the network’s ability to re-generate
leadership.
Deﬁnition 2.1 (Network-Wide Degree Centrality [1]): The

14

B. Problems and Complexity Results

Algorithm 1 GREEDY FRAGILE
Require: Network G = (V, E), no-strike set S ⊆ V ,
cardinality constraint k
Ensure: Subset V 

We now have all the pieces to introduce our problems of
interest. We include decision and optimization versions.
F RAGILIT Y (k, x, G, S):
INPUT: Natural number k, real number x, network
G = (V, E), and no-strike set S
OUTPUT: “Yes” if there exists set V  ⊆ V − S s.t. |V  | ≤ k
and f ragileG (V  ) > x – “no” otherwise.

1:
2:
3:
4:

F RAGILIT Y OP T (k, G, S):
INPUT: Natural number k, network G = (V, E), and no-strike
set S
OUTPUT: Set V  ⊆ V − S s.t. |V  | ≤ k s.t.  ∃V  ⊆ V − S
s.t. |V  | ≤ k and f ragileG (V  ) > f ragileG (V  ).

5:
6:
7:
8:
9:
10:
11:
12:
13:

As our problems seek to ﬁnd sets of nodes, rather than individual ones, it raises the question of “how difﬁcult are these
problems.” We prove that F RAGILIT Y is NP-Complete
- meaning an efﬁcient algorithm to solve it optimally is
currently unknown. Following directly from this result is the
NP-hardness of F RAGILIT Y OP T . Below we state and
prove this result.
Theorem 1 (Complexity of F RAGILIT Y ):
F RAGILIT Y is NP-Complete.
Corollary 1 (Hardness of F RAGILIT Y OP T ):
F RAGILIT Y OP T is NP-hard

14:
15:
16:
17:
18:
19:

V =∅
f lag = T RU E
while |V  | ≤ k and f lag do
curBest
=
null, curBestScore
=
0,
haveV alidScore = F ALSE
for i ∈ V − (V  ∪ S) do
curScore = f ragileG (V  ∪ {i}) − f ragileG (V  )
if curScore ≥ curBestScore then
curBest = i
curBestScore = curScore
haveV alidScore = T RU E
end if
end for
if haveV alidScore = F ALSE then
f lag = F ALSE
else
V  = V  ∪ {curBest}
end if
end while
return V  .

0.57). In the next iteration, it selects node j, giving us
f ragileGsam ({a, j}) = 0.57. Finally, in the third iteration,
it picks node c. This results in f ragileGsam ({a, j, c}) = 0.6.
The algorithm then terminates.

III. A LGORITHM
Now with the problems and their complexity identiﬁed, we
proceed to develop algorithms to solve them. In this paper,
we use a greedy heuristic. Though we cannot guarantee that
the greedy heuristic provides an optimal solution, it often
provides a natural approach to approximating many NP-hard
optimization problems. The ideas is to iteratively pick the node
in the network that provides the greatest increase in f ragile
- and does not cause a decrease.
The following two propositions describe characteristics of
the output and run-time of GREEDY F RAGILE, respectively.
Proposition 3.1: If GREEDY F RAGILE returns a nonempty solution (V  ), then |V  | ≤ k and f ragileG (V  ) >
f ragileG (∅).
Proposition 3.2: GREEDY F RAGILE
runs
in
2
) time.
O(kNG
Though our guarantees on GREEDY F RAGILE are
limited, we show that it performs well experimentally in the
next section.
Example 3.1: Following from Examples 2.1-2.2 using the
terrorist/insurgent network Gsam from Figure 1, suppose a
user wants to identify 3 nodes that will cause the network to
become “as fragile as possible” and is able to target any node.
Hence, he would like to solve F RAGILE OP T (3, Gsam , ∅)
and decides to do so using GREEDY F RAGILE. Initially,
f ragileGsam (∅) = 0.33. In the ﬁrst iteration, it selects and
removes node a, increasing the fragility (f ragileGsam ({a}) =

IV. I MPLEMENTATION AND E XPERIMENTS
All experiments were run on a computer equipped with an
Intel Core 2 Duo CPU T9550 processor operating at 2.66 GHz
(only one core was used). The machine was running Microsoft
Windows 7 (32 bit) and equipped with 4.0 GB of physical
memory. We implemented the GREEDY FRAGILE algorithm
using Python 2.6 in under 30 lines of code that leveraged the
NetworkX library available from http://networkx.lanl.gov/.
We compared the results of the GREEDY FRAGILE to
three other more traditional approaches to targeting that rely on
centrality measures from the literature. Speciﬁcally, we look at
the top closeness and betweenness nodes in the network. Given
node i, its closeness is the inverse of the average shortest
path length from node i to all other nodes in the graph.
Betweenness, on the other hand, is deﬁned as the number of
shortest paths between node pairs that pass through i. Formal
deﬁnitions of both of these measures can be found in [4].
A. Datasets
We studied the effects of our algorithm on ﬁve different
datasets. The network Tanzania [5] is a social network
of the individuals involved with the Al Qaeda bombing
of the U.S. embassy in Dar es Salaam in 1998. It was

15

TABLE I
N ETWORK DATASETS
Name
Tanzania
GenTerrorNw1
GenTerrorNw2
GenTerrorNw3
GenTerrorNw4
URV E-Mail
CA-NetSci

Nodes
17
57
102
105
135
1, 133
1, 463

Edges
29
162
388
590
556
5, 541
2, 743

Density
0.213
0.102
0.0753
0.108
0.0615
0.00864
0.00256

Avg. Degree
3.412
5.684
7.608
11.238
8.237
9.781
3.750

collected from newspaper accounts by subject matter experts in the ﬁeld. The remainder networks, GenTerrorNw1GenTerrorNw4 are terrorist networks generated from realworld classiﬁed datasets[6], [7]. The Tanzania and the GenTerrorNw1-GenTerrorNw4 datasets used in our analysis
were multi-modal networks, meaning they contain multiple
node classes such as Agents, Resources, Locations, etc. The
presence of the different node classes generate multiple or
meta networks, which, in their original state, do not provide
the single-mode Agent by Agent network needed to test
our algorithms. Johnson and McCulloh [8] demonstrated a
mathematical technique to convert meta networks into singlemode networks without losing critical information. Using this
methodology, we were able to derive distant relationships
between nodes as a series of basic matrix algebra operations on
all ﬁve networks. The result is an agent based social network of
potential terrorist. Characteristics of the transformed networks
of agent node class only can be found in Table I.

Fig. 2.
Visualization of the Tanzania network after nodes removed by
GREEDY FRAGILE. Panel A shows the original network. Panel B shows
the network after 3 nodes are removed, panel C shows the network after
5 nodes are removed, and panel D shows the network after 9 nodes are
removed. Notice that the network becomes more “star-like” after subsequent
node removals. In our experiment, after GREEDY FRAGILE removed 11 of
the nodes in the network, it took the topology of a star.

Additionally, pairwise analysis conducted using Tukey’s Honest Signiﬁcant Difference (HSD) test indicates that the results
of our algorithm differ signiﬁcantly from any of the three
centrality measures with a probability approaching 1.0 (95%
conﬁdence, calculated with R version 2.13). Typically, the
ratio of percent increase in fragility to the percent of removed
nodes is typically 2 : 1 or greater.

B. Increasing the Fragility of Networks
In our experiments, we showed that our algorithm was able
to signiﬁcantly increase the network-wide degree centrality
by removing nodes - hence increasing the f ragile function
with respect to a given network. In each of the ﬁve real-world
terrorist networks that we examined, removal of only 12% of
nodes can increase the network-wide centrality between 17%
and 45% (see Figures 3-7). In Figure 2 we show a visualization
of how the Tanzania network becomes more “star-like” with
subsequent removal of nodes by the greedy algorithm.
For comparison, we also looked at the removal of high
degree, closeness, and betweenness nodes. Removal of highdegree, closeness, or betweenness nodes tended to increase
the network-wide centrality. In other words, traditional efforts
of targeting leadership without ﬁrst conducting shaping operations may actually increase the organization’s ability to
regenerate leadership - as such targeting operations effectively
cause an organization to de-centralize. We display these results
graphically in Figures 3-7. Notice that GREEDY FRAGILE
consistently causes an increase in the network-wide degree
centrality. An analysis of variance (ANOVA) reveals that
there is a signiﬁcant difference in the performance among
our algorithm and the centrality measures with respect to
increase or decrease in network-wide degree centrality (pvalue less than 2.2 · 10−16 , calculated with R version 2.13).

Fig. 3. Percent of nodes removed vs. percent increase in fragility for the
Tanzania network using GREEDY FRAGILE, top degree, top closeness, and
top betweenness. The scale of the x-axis is positioned at 0%.

C. Runtime
We also evaluated the run-time of the GREEDY FRAGILE
algorithm. With the largest terror network considered (GenTerrorNw4), we achieved short runtime (under 7 seconds) on
standard commodity hardware (see Figure 8). Hence, in terms
of runtime, our algorithm is practical for use by a real-world
analyst. As predicted in our time complexity result, we found
that the runtime of GREEDY FRAGILE increases with the
number of nodes removed. We note that the implementations
of top degree, closeness, and betweenness calculate those

16

Fig. 4.
Percent of nodes removed vs. percent increase in fragility for
the GenTerrorNet1 network using GREEDY FRAGILE, top degree, top
closeness, and top betweenness. The scale of the x-axis is positioned at 0%.

Fig. 6.
Percent of nodes removed vs. percent increase in fragility for
the GenTerrorNw3 network using GREEDY FRAGILE, top degree, top
closeness, and top betweenness. The scale of the x-axis is positioned at 0%.

Fig. 5.
Percent of nodes removed vs. percent increase in fragility for
the GenTerrorNw2 network using GREEDY FRAGILE, top degree, top
closeness, and top betweenness. The scale of the x-axis is positioned at 0%.

Fig. 7.
Percent of nodes removed vs. percent increase in fragility for
the GenTerrorNw4 network using GREEDY FRAGILE, top degree, top
closeness, and top betweenness. The scale of the x-axis is positioned at 0%.

measures for the entire network at once - hence increasing
the number of nodes to remove does not affect their runtime.

in the network. Additionally, fragmentation of a network may
result in the splintering of an organization into smaller, but
more radical and deadly organizations. This happens because
in some cases, it may be desirable to keep certain terrorist
or insurgent leaders in place to restrain certain, more radical
elements of their organization. Such splinter was observed
for the insurgent organization Jaysh al-Mahdi in Iraq [14].
Further, these techniques do not speciﬁcally address the issue
of emerging leaders. Hence, if they were to be used for
counter-terrorism or counter-insurgency, they would likely still
beneﬁt from a shaping operation to reduce organization’s
ability to regenerate leadership.
There has been some previous work on identifying emerging
leaders in terrorist networks. Although such an approach could
be useful in identifying certain leaders, it does not account
the organizations ability as a whole to regenerate leadership.
In [2], the topic of cognitive demand is studied. The cognitive
load of an individual deals with their ability to handle multiple
demands on their time and work on complex tasks. Typically,
this can be obtained by studying networks where the nodes

V. R ELATED W ORK
Various aspects of the resiliency of terrorist networks have
been previously explored in the literature. For instance, [9]
studies the ability such network to facilitate communication
while maintaining secrecy while [10] studies how such networks are resilient to cascades. However, to our knowledge,
the network-wide degree centrality in such networks - and how
to increase this property - has not been previously studied.
There has been much work dealing with the removal of
nodes from a network to maximize fragmentation [11], [12],
[13] where the nodes removed are mean to either increase
fragmentation of the network or reduce the size of the largest
connected component. While this work has many applications,
it is important to note that there are special considerations
of terrorist and insurgent networks that we must account for
in a targeting strategy. For instance, if conducting a counterintelligence operation while targeting, as in the case of [3],
it may be desirable to preserve some amount of connectivity

17

to maximize this network-wide degree centrality is NP-hard,
our greedy approach proved to be a viable heuristic for this
problem, increasing this quantity between 17% − 45% in our
experiments. Future work could include an examination of
other types of network-wide centrality – for instance networkwide closeness centrality – instead of network-wide degree
centrality. Another aspect that we are considering in ongoing research is determining the effectiveness of the shaping
strategy when we have observed only part of the terrorist or
insurgent organization – as is often the case as such networks
are created from intelligence data.
ACKNOWLEDGEMENTS
We would like to thank Jon Bentley and Charles Weko for
their feedback on an earlier version of this paper.
Some of the authors are supported under by the Army
Research Ofﬁce (project 2GDATXR042). The opinions in this
paper are those of the authors and do not necessarily reﬂect
the opinions of the funders, the U.S. Military Academy, or the
U.S. Army.

Fig. 8.
Number of nodes removed vs. runtime for the GenTerrorNw4
network using GREEDY FRAGILE, top degree, top closeness, and top
betweenness.

may represent more than individual people - but tasks, events,
and responsibilities. However, it may often be the case that
this type of information is often limited or non-existent in
many situations. Additionally, as discussed throughout this
paper, the targeting of individual nodes may often not be
possible for various reasons. Hence, our framework, that
focuses on the network’s ability to regenerate leadership as
opposed to ﬁnding individual emerging leaders may be more
useful as we can restrict the available nodes in our search
using the “no strike list.” By removing these nodes from
targeting consideration - but by still considering their structural
role - our framework allows a security force to reduce the
regenerative ability of a terror network by “working around”
individuals that may not be targeted.
In more recent work [15] looks at the problem of removing
leadership nodes from a terrorist or criminal network in a
manner that accounts for new links created in the aftermath
of an operation. Additionally, [16] look at identifying leaders
in covert terrorist network who attempt to minimize their
communication due to the clandestine nature of their operations. They do this by introducing a new centrality measure
called “covertness centrality.” Both of these approaches are
complementary to ours as they focus on the leadership of the
terrorist or insurgent group - as this approach focuses on the
networks ability to re-generate leadership. A more complete
integration of this approach leadership targeting method such
as these (i.e. using a network-wide version of covertness
centrality) is an obvious direction for future work.

R EFERENCES
[1] L. Freeman, “Centrality in social networks conceptual clariﬁcation,”
Social networks, vol. 1, no. 3, pp. 215–239, 1979.
[2] K. Carley, “Estimating Vulnerabilities in Large Covert Networks,”
Carnegie Mellon University, Tech. Report, 2004.
[3] O. Deforest and D. Chanoff, Slow Burn: The Rise and Bitter Fall of
American Intelligence in Vietnam. Simon and Schuster, 1990.
[4] S. Wasserman and K. Faust, Social Network Analysis: Methods and
Applications, 1st ed., ser. Structural analysis in the social sciences.
Cambridge University Press, 1994, no. 8.
[5] I.-C. Moon, “Destabilization of adversarial organizations with strategic
interventions,” Ph.D. dissertation, School of Computer Science, Institute for Software Research, Computation, Organizations and Society,
Carnegie Mellon University, Pittsburgh, PA, USA, June 2008.
[6] K. M. Carley, “Ficta data,” Center for Computational Analysis of Social
and Organizational Systems, 2009.
[7] Dynamic Network Analysis (DNA) and ORA.
San Francisco, CA:
2nd International Conference on Cross-Cultural Decision Making: Focus
2012, July 2012.
[8] A. N. Johnson and I. A. McCulloh, Advanced Network Analysis and
Targeting (ANAT), 1st ed., Joint Training Counter IED Operational
Integration Center, Washington D.C., January 2009.
[9] R. Lindelauf, P. Borm, and H. Hamers, “The inﬂuence of secrecy on the
communication structure of covert networks,” Social Networks, vol. 31,
no. 2, pp. 126 – 137, 2009.
[10] A. Gutfraind, “Optimizing topological cascade resilience based on the
structure of terrorist networks,” PLoS ONE, vol. 5, no. 11, p. e13448,
11 2010.
[11] R. Albert, H. Jeong, and A. Barabási, “Error and attack tolerance of
complex networks,” Nature, vol. 406, pp. 378–382, 2000.
[12] S. Borgatti, “Identifying sets of key players in a social network,” vol. 12,
pp. 21–34, 2006.
[13] A. Arulselvan, C. Commander, L. Elefteriadou, and P. M. Pardalos,
“Detecting critical nodes in sparse graphs,” Computers and Operations
Research, vol. 36, pp. 2193–2200, 2009.
[14] M. Cochrane, “The Fragmentation of the Sadrist Movement,” The
Institute for the Study of War, Iraq Report 12, January 2009.
[15] R. Petersen, C. Rhodes, and U. Wiil, “Node removal in criminal
networks,” in Intelligence and Security Informatics Conference (EISIC),
2011 European, sept. 2011, pp. 360 –365.
[16] M. Ovelgonne, C. Kang, A. Sawant, and V. Subrahmanian, “Covertness
centrality in networks,” in Proc. 2012 Intl. Symposium on Foundations
of Open Source Intelligence and Security Informatics, Aug. 2012.

VI. C ONCLUSIONS
In this paper we described how to target nodes in a terrorist
or insurgent network as part of a shaping operation designed
to reduce the organization’s ability to regenerate leadership.
Our key intuition was to increase the network-wide degree
centrality which would likely have the effect of eliminating
emerging leaders as maximizing this quantity would intuitively
increase the organization’s reliance on a single leader. In
this paper, we found that though identifying a set of nodes

18

GAPs: Geospatial Abduction Problems
PAULO SHAKARIAN and V. S. SUBRAHMANIAN, University of Maryland
MARIA LUISA SAPINO, Università di Torino

There are many applications where we observe various phenomena in space (e.g., locations of victims of a
serial killer), and where we want to infer “partner” locations (e.g., the location where the killer lives) that
are geospatially related to the observed phenomena. In this article, we define geospatial abduction problems
(GAPs for short). We analyze the complexity of GAPs, develop exact and approximate algorithms (often
with approximation guarantees) for these problems together with analyses of these algorithms, and develop
a prototype implementation of our GAP framework. We demonstrate accuracy of our algorithms on a real
world data set consisting of insurgent IED (improvised explosive device) attacks against U.S. forces in Iraq
(the observations were the locations of the attacks, while the “partner” locations we were trying to infer were
the locations of IED weapons caches).
Categories and Subject Descriptors: I.2.3 [Artificial Intelligence]: Deduction and Theorem Proving—
Nonmonotonic reasoning and belief revision; I.2.3 [Artificial Intelligence]: Problem Solving, Control
Methods, and Search—Heuristic methods; I.2.1 [Artificial Intelligence]: Applications and Expert
Systems—Cartography
General Terms: Theory, Algorithms, Experimentation
Additional Key Words and Phrases: Abduction, complexity analysis, heuristic algorithms
ACM Reference Format:
Shakarian, P., Subrahmanian, V. S., and Sapino, M. L. 2011. GAPs: Geospatial abduction problems. ACM
Trans. Intell. Syst. Technol. 3, 1, Article 7 (October 2011), 27 pages.
DOI = 10.1145/2036264.2036271 http://doi.acm.org/10.1145/2036264.2036271

1. INTRODUCTION

There are numerous applications where we wish to draw geospatial inferences from
observations. For example, criminologists [Rossmo and Rombouts 2008; Brantingham
and Brantingham 2008] have found that there are spatial relationships between a serial killer’s house (the geospatial inference we wish to make), and locations where the
crimes were committed (the observations). A marine archaeologist who finds parts of
a wrecked ship or its cargo at various locations (the observations) is interested in determining where the main portion of the wreck lies (the geospatial inference). Wildlife
experts might find droppings of an endangered species such as the Malayan sun bear
(observations) and might want to determine where the bear’s den is (the geospatial
inference to be made). In all these cases, we are trying to find a single location that

Some of the authors of this article were funded in part by AFOSR grant FA95500610405 and ARO grants
W911NF0910206 and W911NF0910525.
Author’s addresses:
P. Shakarian, U.S. Military Academy, West Point, NY 10996; email:
paulo@shakarian.net; V. S. Subrahmanian, University of Maryland, College Park, MD 20742; email:
vs@cs.umd.edu; M. L. Sapino, Universita di Torino, Torino, Italy; email: mlsapino@di.unito.it
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for profit or commercial advantage and that
copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights
for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of
this work in other works requires prior specific permission and/or a fee. Permissions may be requested from
the Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212)
869-0481, or permissions@acm.org.
c 2011 ACM 2157-6904/2011/10-ART7 $10.00

DOI 10.1145/2036264.2036271 http://doi.acm.org/10.1145/2036264.2036271

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7

7:2

P. Shakarian et al.

best explains the observations (or the k locations that best explain the observations).
There are two common elements in such applications.
First, there is a set O of observations of the phenomena under study. For the sake of
simplicity, we assume that these observations are points where the phenomenon being
studied was known to have been present. Second, there is some domain knowledge
D specifying known relationships between the geospatial location we are trying to
find and the observations. For instance, in the serial killer application, the domain
knowledge might tell us that serial killers usually select locations for their crimes that
are at least 1.2km from their homes and at most 3km from their homes. In the case of
the sun bear, the domain knowledge might state that the sun bear usually prefers to
have a den in a cave, while in the case of the wreck, it might be usually within a radius
of 10 miles of the artifacts that have been found.
The geospatial abduction problem (GAP for short) is the problem of finding the most
likely set of locations that is compatible with the domain knowledge D and that best
“explains” the observations in O. To see why we look for a set of locations, we note
that the serial killer might be using both his home and his office as launching pads for
his attacks. In this case, no single location may best account for the observations. In
this paper, we show that many natural problems associated with geospatial abduction
are NP-Complete, which causes us to resort to approximation techniques. We then
show that certain geospatial abduction problems reduce to several well-studied combinatorial problems that have viable approximation algorithms. We implement some of
the more viable approaches with heuristics suitable for geospatial abduction, and test
them on a real-world data-set. The organization and main contributions of this article
are as follows.
— Section 2 formally defines geospatial abduction problems (GAPs for short), and
Section 3 analyzes their complexity.
— Section 4 develops a “naive” algorithm for a basic geospatial abduction problem
called k-SEP and shows reductions to set-covering, dominating set, and linearinteger programming that allow well-known algorithms for these problems to be
applied to GAPs.
— Section 5 describes two greedy algorithms for k-SEP and compares them to a reduction to the set-covering problem.
— Section 6 describes our implementation and shows that our greedy algorithms
outperform the set-covering reduction in a real-world application on identifying
weapons caches associated with Improvised Explosive Device (IED) attacks on US
troops in Iraq. We show that even if we simplify k-SEP to only cases where k-means
classification algorithms work, our algorithms outperform those.
— Section 7 compares our approach with related work.
2. GEOSPATIAL ABDUCTION PROBLEM (GAP) DEFINITION

Throughout this article, we assume the existence of a finite, 2-dimensional M × N
space S 1 for some integers M, N ≥ 1 called the geospatial universe (or just universe).
Each point p ∈ S is of the form (x, y) where x, y are integers and 0 ≤ x ≤ M and
0 ≤ y ≤ N. We assume that all observations we make occur within space S. We
use the space shown in Figure 1 throughout this article to illustrate the concepts we
introduce. We assume that S has an associated distance function d which assigns a
nonnegative distance to any two points and satisfies the usual distance axioms.2
1 We use integer coordinates as most real world geospatial information systems (GIS) systems use discrete
spatial representations.
2
d(x, x) = 0; d(x, y) = d(y, x); d(x, y) + d(y, z) ≥ d(x, z).

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:3

Fig. 1. A space. Red dots denote observations. Yellow squares denote infeasible locations. Green stars show
one (0,3) explanation, while pink triangles show another (0,3) explanation.

Definition 2.1 Observation. An observation O is any finite subset of S.
Consider the geospatial universe shown in Figure 1. In the serial killer application, the
red dots would indicate the locations of the murders, while in the shipwreck example,
they would indicate the locations where artifacts were found. We wish to identify the
killer’s location (or the sunken ship or the sun bear’s den).
As mentioned earlier, there are many constraints that govern where such locations
might be. For instance, it is unlikely that the sunbear’s den (or the killer’s house or
office) is in the water, while the sunken ship is unlikely to be on land.
Definition 2.2 Feasibility predicate. A feasibility predicate feas is a function from S
to {TRUE, FALSE}.
Thus, feas( p) = TRUE means that point p is feasible and must be considered in the
search. Figure 1 denotes infeasible places via a yellow square. Throughout this article, we assume that feas is an arbitrary, but fixed predicate.3 Further, as feas is defined
as a function over {TRUE, FALSE}, it can allow for user input based on analytical processes currently in place. For instance, in the military, analysts often create “MCOO”
overlays where “restricted terrain” is deemed infeasible [US Army 1994]. We can also
easily express feasibility predicates in a Prolog-style language; we can easily state (in
the serial killer example) that point p is considered feasible if p is within R units of
distance from some observation and p is not in the water. Likewise, in the case of the
sun bear example, the same language might state that p is considered feasible if p is
within R1 units of distance from marks on trees, within R2 units of scat, and if p has
some landcover that would allow the bear to hide. A Prolog-style language that can
express such notions of feasibility is the hybrid knowledge base paradigm [Lu et al.
1996] in which Prolog style rules can directly invoke a GIS system.
Definition 2.3 (α, β) Explanation. Suppose O is a finite set of observations, E is a
finite set of points in S, and α ≥ 0, β > 0 are some real numbers. E is said to be an
(α, β) explanation of O iff:
— p ∈ E implies that feas( p) = TRUE, that is, all points in E are feasible and
— (∀o ∈ O)(∃ p ∈ E) α ≤ d( p, o) ≤ β, that is, every observation is neither too close nor
too far from some point in E.
Thus, an (α, β) explanation is a set of points (e.g., denoting the possible locations
of the home/office of the serial killer or the possible locations of the bear’s den). Each
3 We also assume throughout the article that feas is computable in constant time. This is a realistic assumption, as for most applications, we assume feas to be user-defined. Hence, we can leverage a data-structure
indexed with the coordinates of S to allow for constant-time computation.

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:4

P. Shakarian et al.

point must be feasible and every observation must have an analogous point in the
explanation which is neither too close nor too far.
Given an (α, β) explanation E, there may be an observation o ∈ O such that there
are two (or more) points p1 , p2 ∈ E satisfying the conditions of the second bullet above.
If E is an explanation for O, a partnering function ℘E is a function from O to E such
that for all o ∈ O, α ≤ d(℘E (o), o) ≤ β. ℘E (o) is said to be o’s partner according to the
partnering function ℘E . We now present a simple example of (α, β) explanations.
Example 2.1. Consider the observations in Figure 1 and suppose α = 0, β = 3. Then
the two green stars denote an (α, β) explanation, that is, the set {(6, 6), (12, 8)} is a
(0, 3) explanation. So is the set of three pink triangles, that is, the set {(5, 6), (10, 6),
(13, 9)} is also an (0, 3) explanation.
The basic problem that we wish to solve in this article is the following.
The Simple (α, β) Explanation Problem (SEP)
INPUT: Space S, a set O of observations, a feasibility predicate feas, and numbers
α ≥ 0, β > 0.
OUTPUT: “Yes” if there exists an (α, β) explanation for O — “no” otherwise.
A variant of this problem is the k-SEP problem which requires, in addition, that E
contains k elements or less, for k < |O|. Yet another variant of the problem tries to find
an explanation E that is “best” according to some cost function.
Definition 2.4 Cost function χ . A cost function χ is a mapping from explanations to
nonnegative reals.
We will assume that cost functions are designed so that the smaller the value they
return, the more desirable an explanation is. Some example cost functions are given
below. The simple one below merely looks at the mean distances between observations
and their partners.
Example 2.2 Mean-distance. Suppose S, O, feas, α, β are all given and suppose E is
an (α, β) explanation for O and ℘E is a partnering function. We could initially set the
cost of an explanation E (with respect to this partnering function) to be:
χ℘E (E) =

o∈O d(o, ℘E (o))
.
|O|

Suppose ptn(E) is the set of all partner functions for E in the above setting. Then we
can set the cost of E as:
χmean(E) = inf{χ℘E (E) | ℘E ∈ ptn(E)}.
This definition removes reliance on a single partnering function as there may be several partnering functions associated with a single explanation. We illustrate this definition using our sun bear example.
Example 2.3. Wildlife experts have found droppings and other evidence of the
Malayan sun bear in a given space, S, depicted in Figure 2. Points {o 1 , o 2 , o 3 } indicate locations of evidence of the Malayan sun bear (we shall refer to these as set O).
Points { p1 , p2 , . . . , p8 } indicate feasible dwellings for the bear. The concentric rings
around each element of O indicate the distance α = 1.7km and β = 3.7km. The set
{ p3 , p6 } is a valid (1.7, 3.7) explanation for the set of evidence, O. However, we note
that observation o 2 can be partnered with either point. If we are looking to minimize
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:5

Fig. 2. Left: Points {o 1 , o 2 , o 3 } indicate locations of evidence of the Malayan sun bear (we shall refer to
these as set O). Points { p1 , p2 , . . . , p8 } indicate feasible dwellings for the bear. The concentric rings around
each element of O indicate the distance α = 1.7km and β = 3.7km. Right: Points { p1 , p2 , p3 } are feasible
for crime-scenes {o 1 , o 2 }. { p1 , p2 } are safe-houses within a distance of [1, 2] km. from crime scene o 1 and
{ p2 , p3 } are safe-houses within a distance of [1, 2] km. from crime scene o 2 .

distance, we notice that d(o 2 , p3 ) = 3km and d(o 2 , p6 ) = 3.6km; hence, p3 is the partner
for o 2 such that the distance is minimized.
We now define an “optimal” explanation as one that minimizes cost.
Definition 2.5. Suppose O is a finite set of observations, E is a finite set of points
in S, α ≥ 0, β > 0 are some real numbers, and χ is a cost function. E is said to be
an optimal (α, β) explanation iff E is an (α, β) explanation for O and there is no other
(α, β) explanation E  for O such that χ(E  ) < χ(E).
We present an example of optimal (α, β) explanations in the following.
Example 2.4. Consider the sun bear from Example 2.3 whose behavior is depicted
in Figure 2 (left). While { p3 , p6 } is a valid solution for the k-SEP problem (k = 2),
it does not optimize mean distance. In this case the mean distance would be 3km.
However, the solution { p3 , p7 } provides a mean-distance of 2.8km.
Suppose we are tracking a serial killer who has struck at locations O = {o 1 , o 2 }. The
points { p1 , p2 , p3 } are feasible locations as safe houses for the killer (partners). This
is depicted in Figure 2 (right). Based on historical data, we know that serial killers
strikes are at least 1km away from a safe-house and at most 2km from the safe house
(α = 1, β = 2). Thus, for k = 2, any valid explanation of size 2 provides an optimal
solution wrt mean-distance as every feasible location for a safe-house is within 2km of
a crime scene.
We are now ready to define the cost-based explanation problem.
The Cost-based (α, β) Explanation Problem.
INPUT: Space S, a set O of observations, a feasibility predicate feas, numbers α ≥ 0,
β > 0, a cost function χ and a real number v > 0.
OUTPUT: “Yes” if there exists an (α, β) explanation E for O such that χ(E) ≤ v, “no”
otherwise.
It is easy to see that standard classification problems like k-means4 can be captured
within our framework by simply assuming that α = 0, β > max(M, N)2 and that all
4

See Alpaydin [2010] for a survey on classification work.

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:6

P. Shakarian et al.

points are feasible. In contrast, standard classification algorithms cannot take feasibility into account, and this is essential for the above types of applications.
3. COMPLEXITY OF GAP PROBLEMS

SEP can be easily solved in PTIME. Given a set O of observations, for each o ∈ O, let
Po = { p ∈ S | f eas( p) = TRUE ∧ α ≤ d( p, o) ≤ β}. If Po 	= ∅ for each o, we return
“yes.” We call this algorithm STRAIGHTFORWARD-SEP. Another algorithm would
merely find the set F of all feasible points and return “yes” iff for every observation
o, there is at least one point p ∈ F such that α ≤ d( p, o) ≤ β. In this case, F is the
explanation produced, but it is a very poor explanation. In the serial killer example,
F merely tells the police to search all feasible locations without trying to do anything
intelligent. k-SEP allows the user to constrain the size of the explanation so that “short
and sweet” explanations that are truly meaningful are produced. The following result
states that k-SEP is NP-Complete; the proof is a reduction from Geometric Covering
by Discs (GCD) [Johnson 1982].
T HEOREM 3.1. k-SEP is NP-Complete.
In the associated optimization problem with k-SEP, we wish to produce an explanation of minimum cardinality. Note that minimum cardinality is a common criterion
for parsimony in abduction problems [Reggia and Peng 1990]. We shall refer to this
problem as MINSEP. This problem is obviously NP-hard by Theorem 3.1. We can adjust STRAIGHTFORWARD-SEP to find a solution to MINSEP by finding the minimum
hitting set of the Po ’s.
Example 3.1. Consider the serial killer scenario in Example 2.4 and Figure 2
(right). Crime scene (observation) o 1 can be partnered with two possible safe houses
{ p1 , p2 } and crime scene o 2 can be partnered with { p2 , p3 }. We immediately see that
the potential safe house located at p2 is in both sets. Therefore, p2 is an explanation for both crime scenes. As this is the only such point, we conclude that { p2 } is
the minimum-sized solution for the SEP problem. However, while it is possible for
STRAIGHTFORWARD-SEP to return this set, there are no assurances it does. As we
saw in Example 2.4, E = { p1 , p2 } is a solution to SEP, although a solution with lower
cardinality ({ p2 }) exists. This is why we introduce the MINSEP problem.
With the complexity of k-SEP, the following corollary tells us the complexity class
of the Cost-based Explanation problem. We show this reduction by simply setting the
cost function χ(E) = |E|.
C OROLLARY 3.1. Cost-based Explanation is NP-Complete.
As described earlier, MINSEP has the feel of a set-covering problem. Although the
generalized cost-based explanation cannot be directly viewed with a similar intuition
(as the cost maps explanations to reals, not elements of S), there is an important
variant of the Cost-based problem that does. We introduce weighted SEP, or WT-SEP
here.
Weighted Spatial Explanation (WT-SEP)
INPUT: A space S, a set O of observations, a feasibility predicate feas, numbers α ≥ 0,
β > 0, a weight function c : S → , and a real number v > 0.

OUTPUT: “Yes” if there exists an (α, β) explanation E for O such that p∈E c( p) ≤ v —
“no” otherwise.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:7

In this case, we can easily show NP-Completeness by reduction
from k-SEP, we

simply set the weight for each element of S to be one, causing p∈E c( p) to equal the
cardinality of E.
C OROLLARY 3.2. WT-SEP is NP-Complete.
Cost-based explanation problems presented in this section are very general. While the
complexity results hold for an arbitrary function in a general case, we also consider
specific functions as well. In the following, we present the total-distance minimization
explanation problem (TD-SEP). This is a problem where we seek to minimize the
sum of distances between observations and their closest partners while imposing a
restriction on cardinality.
Total Distance Minimization Explanation Problem (TD-SEP)
For space S, let d : S × S →  be the Euclidean distance between two points in S.
INPUT: A space S, a set O of observations, a feasibility predicate feas, numbers α ≥ 0,
β > 0, positive integer k < |O|, and real number v > 0.
OUTPUT:
“Yes” if there exists an (α, β) explanation E for O such that |E| = k and

o i ∈O min p j∈E d(o i, p j) ≤ v, “no” otherwise.
T HEOREM 3.2. TD-SEP is NP-Complete.
The NP-hardness of the TD-SEP is based on a reduction from the k-Median Problem [Papadimitriou 1981]. This particular reduction (details in the appendix) also
illustrates how the k-median problem is a special case of GAPs, but k-median problems cannot handle arbitrary feasibility predicates of the kind that occur in real-life
geospatial reasoning. The same argument applies to k-means classifiers as well.
4. EXACT ALGORITHM FOR GAP PROBLEMS

This section presents four exact approaches to solve k-SEP and WT-SEP. First, we provide an enumerative approach that exhaustively searches for an explanation. Then,
we show that the problem reduces to set-cover, dominating set, and linear-integer
programming. Existing algorithms for these problems can hence be used directly.
Throughout this section, we shall use the symbols  to represent the bound on the
number of partners that can be associated with a single observation and f to represent the bound on the number of observations supported by a single partner. Note
that both values are bounded by π(β 2 − α 2 ), however they can be much less in practice;
specifically, f is normally much smaller than .
4.1 Naive Exact Algorithm

We now show correctness of NAIVE-KSEP-EXACT. This algorithm provides an exact
solution to k-SEP but takes exponential time (in k). The algorithm first identifies a
set L of all elements of S that could be possible partners for O. Then, it considers all
subsets of L of size less than or equal to k. It does this until it identifies one such
subset as an explanation.
P ROPOSITION 4.1. If there is a k-sized simple (α, β) explanation for O, then NAIVEKSEP-EXACT returns an explanation. Otherwise, it returns NO.
Finally, we have the complexity of the algorithm.
1
P ROPOSITION 4.2. The complexity of NAIVE-KSEP-EXACT is O( (k−1)!
(π(β 2 −
(k+1)
α )|O|)
).
2

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:8

P. Shakarian et al.

Algorithm 1 (NAIVE-KSEP-EXACT)
INPUT: Space S, a set O of observations, a feasibility predicate feas, real numbers α ≥ 0, β > 0,
and natural number k > 0
OUTPUT: Set E ⊆ S of size k (or less) that explains O
(1)

(2)
(3)

(4)
(5)
(6)

Let M be a matrix array of pointers to binary string {0, 1}|O| . M is of the same dimensions
as S. Each element in M is initialized to NULL. For a given p ∈ S, M[ p] is the place in the
array.
Let L be a list of pointers to binary strings. L is initialized as null.
For each o i ∈ O do the following
(a) Determine all points p ∈ S such that α ≤ d(o, p) ≤ β such that feas( p) = TRUE.
(b) For each of these points, p, if M[ p] = NULL then initialize a new array where only bit i
is set to 1. Then add a pointer to M[ p] in L.
(c) Otherwise, set bit i of the existing array to 1.
For any k elements of L (actually the k elements pointed to by elements of L), we shall
designate 	1 , . . . , 	 j, . . . 	k as the elements. We will refer to the ith bit of element 	 j as 	 j(i).
Exhaustively generate all possible
combinations of k elements of L until one such combination is found where ∀i ∈ [1, |O|], kj=1 (	 j(i)) > 0
If no such combination is found, return NO. Otherwise, return the first combination that
was found.

An exact algorithm for the cost-based explanation problems follows trivially from
the NAIVE-KSEP-EXACT algorithm by adding the step of computing the value for χ for
each combination. Provided this computation takes constant time, this does not affect
1
(π(β 2 − α 2 )|O|)(k+1) ) runtime of that algorithm.
the O( (k−1)!
4.2 An Exact Set-Cover Based Approach

We now show that k-SEP polynomially reduces to an instance of the popular setcovering problem [Karp 1972] which allows us to directly apply the well-known greedy
algorithm reviewed in Paschos [1997]. Set-Cover is defined as follows.
The Set-Cover Problem (Set-Cover)
INPUT: Set of elements, E and a family of subsets of E, F ≡ {S1 , . . . , Smax }, and
positive integer k.

OUTPUT: “Yes” if there exists a k-sized subset of F, Fk , such that ki=1 {Si ∈ Fk } ≡ E.
Through a simple modification of NAIVE-KSEP-EXACT, we can take an instance of
k-SEP and produce an instance of Set-Cover. We run the first four steps, which only
takes O( · |O|) time by the proof of Proposition 4.2.
T HEOREM 4.1. k-SEP polynomially reduces to Set-Cover.
Example 4.1. Consider the serial killer scenario in Example 2.4 and Figure 2
(right). Suppose we want to solve this problem as an instance of k-SEP by a reduction to set-cover. We consider the set of crime-scene locations, O ≡ {o 1 , o 2 } as the set
we wish to cover. We obtain our covers from the first four steps of NAIVE-KSEP-EXACT.
Let us call the result list L. Hence, we can view the values of the elements in L as
the following sets S1 ≡ {o 1 }, S2 ≡ {o 1 , o 2 }, S3 ≡ {o 2 }. These correspond with points
p1 , p2 , p3 respectively. As S2 covers O, p2 is an explanation.
The traditional approach for approximation of set-cover has a time complexity of
O(|E|·|F|·size), where size is the cardinality of the largest set in the family F (i.e. size =
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:9

Algorithm 2 (NAIVE-KSEP-SC)
INPUT: Space S, a set O of observations, a feasibility predicate feas, and real numbers α ≥ 0,
β>0
OUTPUT: Set E ⊆ S that explains O
(1)
(2)
(3)
(4)
(5)
(6)

(7)

(8)

Initialize list E to null
Let M be a matrix array of the same dimensions as S of lists of pointers initialized to null.
For a given p ∈ S, M[ p] is the place in the array.
Let L be a list of pointers to lists in M, L is initialized to null.
Let O be an array of Booleans of length |O|. ∀i ∈ [1, |O|], initialize O [i] = TRUE. For some
element o ∈ O, O [o] is the corresponding space in the array.
Let numObs = |O|
For each element o ∈ O, do the following.
(a) Determine all elements p ∈ S such that feas( p) = TRUE and d(o, p) ∈ [α, β]
(b) If there does not exist a p ∈ S meeting the above criteria, then terminate the program
and return IMPOSSIBLE.
(c) If M[ p] = null then add a pointer to M[ p] to L
(d) Add a pointer to o to the list M[ p].
While numObs > 0 loop
(a) Initialize pointer cur ptr to null
(b) Initialize integer cur size to 0
(c) For each ptr ∈ L, do the following:
(i) Initialize integer this size to 0
(ii) Let M[ p] be the element of M pointed to by ptr
(iii) For each ob s ptr in the list M[ p], do the following
A. Let i be the corresponding location in array O to ob s ptr
B. If O [i] = TRUE, increment this size by 1
(iv) If this size > cur size, set cur size = this size and have cur ptr point to M[ p]
(d) Add p to E
(e) For every ob s ptr in the list pointed to by cur ptr, do the following:
(i) Let i be the corresponding location in array O to ob s ptr
(ii) If O [i], then set it to FALSE and decrement numObs by 1
(f) Add the location in space S pointed to by cur ptr to E
Return E

maxi≤|F| |Si|). This approach obtains an approximation ratio of 1 + ln(size) [Paschos
1997]. As f is the quantity of the largest number of observations supported by a single
partner, the approximation ratio for k-SEP using a greedy-scheme after a reduction
from set-cover is 1 + ln( f ). The NAIVE-KSEP-SC algorithm below leverages the above
reduction to solve the k-SEP problem.
P ROPOSITION 4.3. NAIVE-KSEP-SC has a complexity of O( · f · |O|2 ) and an
approximation ratio of 1 + ln( f ).
P ROPOSITION 4.4. A solution E to NAIVE-KSEP-SC provides a partner to every
observation in O if a partner exists – otherwise, it returns IMPOSSIBLE.
The algorithm NAIVE-KSEP-SC is a naive, straight-forward application of the O(|E|·
|F| · size) greedy approach for set-cover as presented in Paschos [1997]. We note that it
is possible to implement a heap to reduce the time-complexity to O(· f ·|O|·lg(·|O|)),
avoiding the cost of iterating through all possible partners in the inner-loop.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:10

P. Shakarian et al.

Algorithm 3 (KSEP-TO-DOMSET)
INPUT: Space S, a set O of observations, a feasibility predicate feas, and real numbers α ≥ 0,
β>0
OUTPUT: Graph G O for use in an instance of a DomSet problem
(1)
(2)

(3)

(4)
(5)

Let G O = (VO , EO ) be a graph. Set VO = S and EO = ∅.
Let S be a mapping defined as S : S → VO . In words, S takes elements of the space and
returns nodes from G O as defined in the first step. This mapping does not change during
the course of the algorithm.
For each o i ∈ O do the following
(a) Determine all points p ∈ S that are such that α ≤ d(o, p) ≤ β. Call this set Pi
(b) For all p ∈ Pi calculate feas( p). If feas( p) = FALSE, remove p from Pi.
(c) Let Vi = {v ∈ VO |∃ p ∈ Pi such that S( p) = v}.
(d) Add |Pi| new nodes to VO . Add these nodes to Vi as well.
(e) For every pair of nodes v1 , v2 ∈ Vi , add edge (v1 , v2 ) to EO .
Remove all v ∈ VO where there does not exist an v  such that (v, v  ) ∈ EO
If any Pi ≡ ∅ return IMPOSSIBLE. Otherwise return G O .

In addition to the straightforward greedy algorithm for set-covering, there are several other algorithms that provide different time complexity/approximation ratio combinations. However, with a reduction to the set-covering problem we must consider the
result of Lund and Yannakakis [1994], which states that set-cover cannot be approximated within a ratio c · log(n) for any c < 0.25 (where n is the number of subsets in the
family F) unless NP ⊆ DT IME[npoly log n].
A reduction to set-covering has the advantage of being straightforward. It also allows us to leverage the wealth of approaches developed for this well-known problem.
In the next section, we show that k-SEP reduces to the dominating set problem as well.
We then explore alternate approximation techniques based on this reduction.
4.3 An Exact Dominating Set Based Approach

We show below that k-SEP also reduces to the well known dominating set problem
(DomSet) [Garey and Johnson 1979] allowing us to potentially leverage fast algorithms such as the randomized-distributed approximation scheme in Jia et al. [2002].
DomSet is defined as follows.
Dominating Set (DomSet)
INPUT: Graph G = (V, E) and positive integer K ≤ |V|.
OUTPUT: “Yes” if there is a subset V  ⊂ V such that |V  | ≤ K and such that every
vertex v ∈ V − V  is joined to at least one member of V  by an edge in E.
As the dominating set problem relies on finding a certain set of nodes in a graph,
then, unsurprisingly, our reduction algorithm, Algorithm 3, takes space S, an
observation set O, feasibility predicate feas, and numbers α, β and returns graph G O
based on these arguments.
We now present an example to illustrate the relationship between a dominating set
of size k in G O and a k-sized simple (α, β) explanation for O. The following example
illustrates the relationship between a k-SEP problem and DomSet.
Example 4.2. Consider the serial killer scenario in Example 2.4, pictured in
Figure 2 (right). Suppose we want to solve this problem as an instance of k-SEP by a
reduction to DomSet. We want to find a 1-sized simple (α, β) explanation (safe-house)
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:11

Fig. 3. Results of KSEP-TO-DOMSET based on data seen in Figure 2 (right). Note that { p1 , p2 , p1 , p2 } form
a complete graph and { p2 , p3 , p2 , p3 } also form a complete graph. Note that { p2 } is a dominating set of size
1. Hence, { p2 } is a 1-sized simple (α, β) explanation for O, as depicted in Figure 2 (right).

for O (the set of crime scenes, {o 1 , o 2 }). Suppose that after running an algorithm such
as STRAIGHFORWARD-SEP, we find that { p1 , p2 , p3 } are elements of S that are feasible. { p1 , p2 } are all within a distance of α, β from o 1 and { p2 , p3 } are all within a
distance of α, β from o 2 . We run KSEP-TO-DOMSET, which creates graph G O . Refer to
Figure 3 for the graph. We can see that { p2 } is a 1-sized dominating sets for G O , hence
a 1-sized explanation for O.
We notice that the inner loop of KSEP-TO-DOMSET is bounded by O() operations
and the outer loop will iterate |O| times. Thus, the complexity of KSEP-TO-DOMSET
is O( · |O|).
P ROPOSITION 4.5. The complexity of KSEP-TO-DOMSET is O( · |O|).
Example 4.2 should give us some intuition into why the reduction to DomSet works.
We provide the formal proof in the Appendix.
T HEOREM 4.2. k-SEP is polynomially reducible to DomSet.
The straightforward approximation scheme for DomSet is to view the problem as
an instance of Set-Cover and apply a greedy algorithm. The reduction would view the
set of vertices in G O as the elements, and the family of sets as each vertex and its
neighbors. This results in both a greater complexity and a worse approximation ratio
when compared with the reduction directly to Set-Cover.
P ROPOSITION 4.6. Solving k-SEP by a reduction to DomSet using a straightforward greedy approach has time-complexity O(3 · f · |O|2 ) and an approximation
ratio bounded by O(1 + ln(2 · f · )).
There are other algorithms to approximate DomSet [Jia et al. 2002; Kuhn and Wattenhofer 2003]. By leveraging Jia et al. [2002], we can obtain an improved complexity
while retaining the same approximation ratio as the greedy approach.
P ROPOSITION 4.7. Solving k-SEP by a reduction to DomSet using the distributed,
randomized algorithm presented in Jia et al. [2002] has a time complexity O( · |O| +
ln(2 ·  · |O|) · ln(2 ·  · f )) with high probability and approximation ratio of O(1 + ln(2 ·
f · )).
Hence, although a reduction to dominating set generally gives us a worse approximation guarantee, we can (theoretically) outperform set-cover with the randomized
algorithm for dominating set in terms of complexity.
4.4 An Exact Integer Linear Programming Based Approach

Given an instance of k-SEP, we show how to create a set of integer constraints that if
solved, will yield a solution to the problem.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:12

P. Shakarian et al.

Algorithm 4 (NAIVE-KSEP-ROUND)
INPUT: Space S, a set O of observations, a feasibility predicate feas, and real numbers α ≥ 0,
β>0
OUTPUT: Set E ⊆ S that explains O
(1)
(2)
(3)
(4)

Run the first four steps of NAIVE-KSEP-EXACT
Solve the relaxation of OPT-KSEP-IPC
For the o ∈ O with the most possible partners, let  be the number of possible partners
associated with o. This can be done in line 1
Return all p j ∈ L where x j ≥ 1

Definition 4.1 OPT-KSEP-IPC. The k-SEP integer programming constraints (OPTKSEP-IPC) require the following information, obtained in O(|O| · π(β 2 − α 2 ) time:
— Let L be the set of all possible partners generated in the first four steps of NAIVEKSEP-EXACT.
— For each p ∈ L, let str( p) be the string of |O| bits, where bit str( p)i is 1 if p is a
partner of the ith observation (this is also generated in the first four steps of NAIVEKSEP-EXACT).
For each p j ∈ L, let x j ∈ {0, 1}. x j = 1 iff p j is in E.
Then KSEP-IPC
consists of the following:

Minimize p j∈L x j subject to

(1) ∀o i ∈ O, p j∈L x j · str( p j)i ≥ 1
(2) ∀ p j ∈ L, x j ∈ {0, 1} (for the relaxed linear program: x j ≤ 1)
P ROPOSITION 4.8. OPT-KSEP-IPC consists of O(|O|π(β 2 −α 2 )) variables and O(|O|·
π(β 2 − α 2 )) constraints.
P ROPOSITION 4.9. Fora given instance of the optimization version k-SEP, if OPTp j is an optimal solution to k-SEP.
KSEP-IPC is solved, then p j∈L
x j=1

Example 4.3. Consider the serial killer scenario in Example 2.4, pictured in Figure 2 (right). Suppose we want to solve this problem as an instance of MINSEP. We
would set up the constraints as follows:
Minimize x1 + x2 + x3 subject to 1 · x1 + 1 · x2 + 0 · x3 ≥ 1 and 0 · x1 + 1 · x2 + 1 · x3 ≥ 1,
where x1 , x2 , x3 ∈ {0, 1}
Obviously, setting x1 = 0, x2 = 1, x3 = 0 provides an optimal solution. Hence, as x2 is
the only nonzero variable, p2 is the explanation for the crime scenes.
A solution to the constraints OPT-KSEP-IPC can be approximated using the wellknown “rounding” technique [Hochbaum 1982; Vazirani 2004] that relaxes constraints.
We present an OPT-KSEP-IPC using rounding.
P ROPOSITION 4.10. NAIVE-KSEP-ROUND returns an explanation for O that is
within a factor  from optimal, where  is the maximum number of possible partners
associated with any observation.
There are several things to note about this approach. First, it can be easily adapted
to many of the weighted variants - such as WT-SEP. Second, we note that the rounding
algorithm is not a randomized rounding algorithm – which often produces a solution
that satisfies all of the constraints in the linear-integer program. The above algorithm guarantees that all of the observations will be covered (if an explanation exists).
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:13

Algorithm 5 (GREEDY-KSEP-OPT1)
INPUT: Space S, a set O of observations, a feasibility predicate feas, and real numbers α ≥ 0,
β>0
OUTPUT: Set E ⊆ S that explains O
(1)
(2)
(3)
(4)

(5)

Run lines 2-2 of NAIVE-KSEP-SC
Let OBS be an array, size |O| of lists to pointers in M. For some observation o, let OBS[o]
be the corresponding list in the array.
Run the loop in line 2 of NAIVE-KSEP-SC but when partner p of observation o is considered,
add a pointer to M[ p] in the list OBS[o]. The list L need not be maintained.
While numObs > 0 loop
(a) Randomly select an element o ∈ O such that O [o] = TRUE
(b) Run the greedy-selection loop of line 2 of NAIVE-KSEP-SC, but consider the list OBS[o]
instead of L
Return E

Finally, this approach allows us to leverage numerous software packages for solving
linear and linear-integer programs.
5. GREEDY HEURISTICS FOR GAP PROBLEMS
5.1 A Linear Time Greedy Approximation Scheme

In this section, we introduce a greedy approximation scheme for the optimization version of k-SEP that has a lower time-complexity than NAIVE-KSEP-SC but still maintains the same approximation ratio. Our GREEDY-KSEP-OPT1 algorithm runs in linear time with respect to O. The key intuition is that NAIVE-KSEP-SC iterates through
O( · |O|) possible partners in line 2. Our algorithm first randomly picks an observation and then greedily selects a partner for it. This results in the greedy step iterating
through only O() partners.
Example 5.1. Consider the sun bear from Example 2.3 and Figure 2. After initializing the necessary data structures in lines 1–3, GREEDY-KSEP-OPT1 iterates through
the observations in O where the associated position in O is TRUE. Suppose the algorithm picks o 1 first. It now accesses the list pointed to from OBS[o 1 ]. This gives us
a set of pointers to the following elements of S: { p1 , p2 , p3 , p4 }. Following the greedy
selection outlined in line 2 of NAIVE-KSEP-SC, the algorithm iterates through these
points, visiting the list of observations associated with each one in the matrix array M.
First, the algorithm accesses the list pointed to by M[ p1 ]. Figure 4 (left) shows the
observations considered when p1 is selected. As there is only one observation in list
M[ p1 ] whose associated Boolean in O is TRUE, the variable cur size is set to 1 (see
line 2 of NAIVE-KSEP-SC). cur ptr is then set to M[ p1 ].
Now we consider the next element, p2 . Figure 4 (right) shows the list pointed to by
M[ p2 ]. As M[ p2 ] points to more observations whose associated O Boolean is TRUE,
we update cur size to 2 and cur ptr to M[ p2 ].
The algorithm then iterates through p3 and p4 , but finds they do not offer more
observations than p2 . Hence, p2 is added to the solution set (E). The algorithm updates
the array of Booleans, O and sets O [o 1 ] and O [o 2 ] to FALSE (depicted by X’s over those
observations in subsequent figures). numObs is decremented by 2.
Now, we enter the second iteration of line 4. The only element for the algorithm to
pick at this point is o 3 , as only O [o 3 ] is TRUE. The list OBS[o 3 ] points to the positions
{ p6 , p7 , p8 }. In Figure 5 we look at what happens as the algorithm considers the p7 .
As OBS[o 2 ] = FALSE, it only considers o 3 when computing this size.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:14

P. Shakarian et al.

Fig. 4. Left: GREEDY-KSEP-OPT1 accesses the list pointed to by M[ p1 ] thus considering all observations
available to p1 . Right: GREEDY-KSEP-OPT1 accesses the list pointed to by M[ p2 ] and finds it has more
active observations than it found in the list pointed to by M[ p1 ].

Fig. 5. GREEDY-KSEP-OPT1 considers the observations available to p7 . The X’s on o 1 and o 2 signify that
OBS[o 1 ] and OBS[o 2 ] are set to FALSE.

When the algorithm finishes its consideration of all the elements pointed to by
OBS[o 3 ], it will return the first element of that set ( p6 ) as neither p7 nor p8 were partners to more available observations than p6 (in our implementation of this algorithm,
we use a coin-flip to break ties among partners with the same number of observations).
GREEDY-KSEP-OPT1 then adds p6 to E and terminates. The final solution returned,
{ p2 , p6 }, is a valid (and in this case, optimal) explanation.
P ROPOSITION 5.1 C OMPLEXITY OF GREEDY-KSEP-OPT1. GREEDY-KSEP-OPT1
has a complexity of O( · f · |O|) and an approximation ratio of 1 + ln( f ).
P ROPOSITION 5.2. GREEDY-KSEP-OPT1 returns a |E|-sized (α, β) explanation
for O.
GREEDY-KSEP-OPT1 returns IMPOSSIBLE if there is no explanation for O.
We can bound the approximation ratio for GREEDY-KSEP-OPT1 by O(1 + ln( f )), as
it is still essentially a greedy algorithm for a covering problem. The main difference
between GREEDY-KSEP-OPT1 is the way it greedily chooses covers (partners). This
algorithm randomly picks an uncovered observation in each loop and then greedily
chooses a cover that covers that observation. Improving the accuracy of this algorithm (in practice) is tied directly to the selection criteria used to pick observations,
which is random in GREEDY-KSEP-OPT1. In Section 5.2 we develop an algorithm that
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:15

“smartly” picks observations with a dynamic ranking scheme while maintaining a time
complexity lower than the standard set-covering approach.
5.2 Greedy Observation Selection

GREEDY-KSEP-OPT1 randomly selects observations although subsequent partner selection was greedy. It is easy to implement an a-priori ranking of observations based
on something like the maximum number of other observations which share a partner
with it. Such a ranking could be implemented at the start of GREEDY-KSEP-OPT1 with
no effect on complexity, but the ranking would be static and may lose its meaning after
several iterations of the algorithm. We could also implement a dynamic ranking. We
present a version of GREEDY-KSEP-OPT1 that we call GREEDY-KSEP-OPT2 that picks
the observations based on dynamic ranking, runs in time O(· f 2 ·|O|+|O|·ln(|O|)), and
maintains the usual approximation ratio of 1 + ln( f ) for greedy algorithms. Our key
intuition was to use a Fibonacci heap [Fredman and Tarjan 1987]. With such a data
structure, we can update the rankings of observations at constant amortized cost per
observation being updated. The most expensive operation is to remove an observation
from the heap, which costs an amortized O(ln(|O|)), however as we can never remove
more than |O| items from the heap, this cost is most likely dominated by the cost of the
rest of the algorithm, which is more expensive than GREEDY-KSEP-OPT1 by a factor
of f . Recall that f is the bound on the number of observations supported by a single
partner and is often very small in practice.
In order to leverage the Fibonacci heap, there are some restrictions on how the
ranking can be implemented. First, the heap puts an element with the minimal key
on top, and can only decrease the key of elements; an element in the heap can never
have its key increased. Additionally, there is a need for some auxiliary data structures
as searching for an element in the heap is very expensive. Fortunately, the k-SEP
problem is amenable to these type of data structures.
We based the key (ranking) on a simple heuristic for each observation. The key for a
given observation o is the number of unique observations that share a partner with o.
As we are extracting the minimum-keyed observation, we are taking the observation
that has the “least in common” with the other observations. The intuition of choosing
an observation with “less in common” with other observations ensures that outliers get
covered with larger covers. Meanwhile, elements with a higher rank in this scheme
are covered last, which may lead to a more efficient cover. In Section 6 we show experimentally that this heuristic was viable for the data-set we considered - providing
more accurate results than the reduction from set-covering.
Example 5.2. The basic intuition behind GREEDY-KSEP-OPT2 is similar to
GREEDY-KSEP-OPT1 in that it iterates through the observations and greedily chooses
a partner. The main difference is that it ranks the observations instead of just randomly selecting them. Consider the sun bear from Example 2.3 whose behavior is
depicted in Figure 2. In Example 5.1, we used GREEDY-KSEP-OPT1 to solve the associated k-SEP problem for this situation. We shall discuss how GREEDY-KSEP-OPT2
differs.
The first main difference is that the algorithm assigns a rank to each observation o i,
called keyi, which is also the key used in the Fibonacci heap. This is done in the loop at
line 4. It not only calculates keyi for each observation, but it also records the elements
“related” to it in the array REL OBS. Note that a “related” observation needs only to
share a partner with a given observation. Not all related observations need to have the
same partner. For the sun bear scenario, we show the keys and related observations
in Table I.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:16

P. Shakarian et al.

Algorithm 6 GREEDY-KSEP-OPT2
INPUT: Space S, a set O of observations, a feasibility predicate feas, and real numbers α ≥ 0,
β>0
OUTPUT: Set E ⊆ S that explains O
(1)
(2)
(3)
(4)

(5)

(6)

(7)

Run lines 1-3 of GREEDY-KSEP-OPT1.
Let key1 , . . . key|O| be natural numbers associated with each observation. Initially, they are
set to 0. For some o ∈ O let keyo be the associated number.
Let REL OBS be an array of lists of pointers to elements of O. The size of the array is O.
For element o ∈ O, let REL OBS[o] be the corresponding space in the array.
For each o ∈ O, do the following:
(a) For each element p ∈ OBS[o], do the following.
i. For each element ob s ptr of the list pointed to by M[ p], do the following
A. If ob s ptr points to an element of O not pointed to in the list REL OBS[o],
then add ob s ptr to REL OBS[o] and increment keyo by 1.
Let OBS HEAP be a Fibonacci heap. Let QUICK LOOK be an array (size O) of pointers to
elements of the heap. For each o ∈ O, add the tuple o, keyo  to the heap, along with a
pointer to the tuple to QUICK LOOK[o]. Note we are using keyo as the key for each element
in the heap.
While OBS HEAP is not empty, loop
(a) Take the minimum element of OBS HEAP, let o be the associated observation with this
element.
(b) Greedily select an element of OBS[o] as done in the loop at line 4 of GREEDY-KSEPOPT1. We shall call this element p.
(c) For every o  ∈ O pointed to by a pointer in M[ p], such that O [o  ] = TRUE, do the
following.
i. Set O [o  ] = FALSE
ii. Remove the element pointed to by QUICK LOOK[o  ] from OBS HEAP
iii. For every element o  ∈ O pointed to by an element of REL OBS[o  ] where O [o  ] =
TRUE do the following.
A. Decrease the keyo  by 1.
Return E

Table I. key values and related observations for
observations in the sun bear scenario introduced
in Example 2.3
Observation

keyi

REL OBS[o i]

o1

2

{o 1 , o 2 }

o2

2

{o 1 , o 2 }

o3

2

{o 2 , o 3 }

As the key values are the same for all elements of O, let’s assume the algorithm first
considers o 1 as in Example 5.1. As written, we would take the minimum element in the
Fibonacci heap (a constant time operation). We would then consider the partners for
o 1 which would result in the greedy selection of p2 , (just as in GREEDY-KSEP-OPT1
and NAIVE-KSEP-SC. Also notice we retain the array of Booleans, O as well as the
array of lists, M to help us with these operations.).
Now the issue arises that we must update the keys for the remaining observations,
as well as remove observations covered by p2 . As we maintain REL OBS and O , the
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:17

Fig. 6. Left: GREEDY-KESP-OPT2 considers all observations that can be partnered with p2 . Notice that
in this figure by each observation we show a box that represents the key of the observation in the Fibonacci heap. Right: GREEDY-KSEP-OPT2 removes o 1 from the heap, and iterates through the elements in
REL OBS[o 1 ], causing it to decrease the key of o 2 .

procedure quickly iterates through the elements covered by p2 : o 1 and o 2 . Figure 6
shows the status of the observations at this point.
We remove o 1 from the heap, and set O [o 1 ] to FALSE. This prevents us from considering it in the future. We now iterate through each o  in the list pointed to by
REL OBS[o 1 ] where O [o  ] is TRUE and decrease the key of each by one. As per table I,
REL OBS[o 1 ] = {o 1 , o 2 }. As O [o 1 ] = FALSE we do nothing. As O [o 2 ] = TRUE, we decrease the key of the associated node in the Fibonacci heap. The array QUICK LOOK
ensures we can access that element in constant time. Figure 6 (left) graphically depicts
this action.
Next, we consider the other element covered by partner p2 : o 2 . After removing this
element from the heap and setting O [o 2 ] to FALSE, we can easily see that there does
not exist any o  ∈ REL OBS[o 2 ] where O [o  ] = TRUE. Hence, we can proceed to pick a
new minimum observation from the heap, which is o 3 in this case. The greedy selection
proceeds (resulting in the choice of p6 ), followed by the update procedure (which simply
removes the node associated with o 3 from the heap and sets O [o 3 ] = FALSE). As there
are no more elements in the heap, GREEDY-KSEP-OPT2 returns the solution { p2 , p6 }.
T HEOREM 5.1 C OMPLEXITY OF GREEDY-KSEP-OPT2. GREEDY-KSEP-OPT2 has
a complexity of O( · f 2 · |O| + |O| · ln(|O|)) and an approximation ratio of 1 + ln( f ).
P ROPOSITION 5.3. GREEDY-KSEP-OPT2 returns a |E|-sized (α, β) explanation
for O.
GREEDY-KSEP-OPT2 returns IMPOSSIBLE if there is no explanation for O.
6. IMPLEMENTATION AND EXPERIMENTS

In this section, we show that our geospatial abduction framework and algorithms are
viable in solving real-world geospatial abduction problems. Using a real-world dataset
consisting of counterinsurgency information from Iraq, we were able to accurately locate insurgent weapons cache sites (partners) given previous attacks (observations)
and some additional data (used for feas and α, β). This validates our primary research
goal for the experiments; to show that geospatial abduction can be used to solve problems in the real world.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:18

P. Shakarian et al.

Algorithm 7 (FIND-BOUNDS)
INPUT: Historical, time-stamped observations Oh, historical, time-stamped partners, Eh, real
number (distance threshold) βmax
OUTPUT: Real numbers α, β
(1)
(2)
(3)

(4)

Set α = 0 and β = βmax
Set Boolean variable f lag to TRUE
For each o ∈ Oh, do the following:
(a) For each p ∈ Eh that occurs after o, do the following.
i. Let d be the Euclidean distance function.
ii. If f lag, and d(o, p) ≤ βmax then set α = d(o, p) and β = d(o, p)
iii. If not f lag, then do the following:
A. If d(o, p) < α then set α = d(o, p)
B. If d(o, p) > β and d(o, p) ≤ βmax then set β = d(o, p)
Return reals α, β

We considered the naive set-covering approach along with GREEDY-KSEP-OPT1
and GREEDY-KSEP-OPT2, which according to our analytical results, had the best
approximation ratios and time-complexities. We implemented these algorithms in
4000 lines of Java code, running on a Lenovo T400 ThinkPad laptop running Vista
with an Intel Core 2 Duo T9400 2.53 GHz processor and 4.0 GB of RAM. Our SCARE
(Social-Cultural Abductive Reasoning Engine) system [Shakarian et al. 2009] enabled
us to carry out tests on real-world data. This data includes 21 months of Improvised
Explosive Device or IED attacks in Baghdad5 (a 25x27 km region) – these constitute
our observations. It also included information on locations of caches associated with
those attacks discovered by U.S. forces. The locations of the caches constitute the (α, β)
explanation we want to learn. We used data from the International Medical Corps to
define feasibility predicates that took the following factors into account: (i) the ethnic
makeup of neighborhoods in Baghdad; specifically, Sunni locations were deemed infeasible for cache locations, (ii) the locations of U.S. bases in Baghdad were also considered
infeasible and (iii) bodies of water were also deemed infeasible. We also separately ran
tests on that part of the above data focused on Sadr City (a 7x7 km district in Baghdad)
alone. On both these regions, we overlaid a grid whose cells were 100m x 100m each
— about the size of a standard US city block. All timings were averaged over 100 runs.
We split the data into 2 parts; the first 7 months of data was used as a “training”
set and the next 14 months of data was used for experimental evaluation. We used the
following simple algorithm, FIND-BOUNDS, to determine the α, β values. We set βmax
to 2.5 km. We leave more advanced procedures for learning these parameters to future
work. Such parameters could also come from an expert.
Accuracy. Our primary goal in the experiments was to determine if the geospatial abduction framework and algorithms could provide viable results in a real-world setting.
“Accuracy” in this section refers to two aspects - size of the solution, and the distance
to the nearest actual cache site. The distance to nearest cache site was measured by
taking the straight-line Euclidean distance to the nearest cache site that was found
after the first attack supported by the projected cache site. We used the raw coordinate for the actual cache in the data set, not the position closest to the nearest point
in the 100 m resolution grid that we overlaid on the areas. The accuracy results are
summarized in Tables II, III.
5

Attack and cache location data was provided by the Institute for the Study of War.

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:19

Table II. k-SEP Algorithm Results—Solution Size
Area

Algorithm

Sample Mean
Solution Size

Sample Mean
Number of Partners
≤ 0.5 km
to actual cache

Baghdad

NAIVE-KSEP-SC
GREEDY-KSEP-OPT1
GREEDY-KSEP-OPT2

14.53
15.02
14.00

8.13
7.89
7.49

Sadr City

NAIVE-KSEP-SC
GREEDY-KSEP-OPT1
GREEDY-KSEP-OPT2

8.00
6.61
6.00

3.00
4.44
5.28

Table III. k-SEP Algorithm Results—Distances to Actual Cache Sites
Area

Algorithm

Sample Mean
Avg Dist to
actual cache

Sample Std Dev
of Avg Dist to
actual cache

Sample Mean
Std Dev of Dist to
actual cache

Baghdad

NAIVE-KSEP-SC
GREEDY-KSEP-OPT1
GREEDY-KSEP-OPT2

0.79 km
0.76 km
0.72 km

0.02
0.07
0.03

0.64
0.60
0.63

Sadr City

NAIVE-KSEP-SC
GREEDY-KSEP-OPT1
GREEDY-KSEP-OPT2

0.72 km
0.45 km
0.35 km

0.03
0.03
0.03

0.46
0.46
0.47

Overall, GREEDY-KSEP-OPT2 consistently found the smallest solution—of cardinality 14 for Baghdad and 6 for Sadr City—on all 100 trials. For Baghdad, the other
two algorithms both found a solution of size 14, but both averaged a higher solution.
For Sadr City, GREEDY-KSEP-OPT1 often did find a solution of 6 caches while NAIVEKSEP-SC only found solutions of size 8. Additionally, in both tests, the solution sizes
for GREEDY-KSEP-OPT1 varied more than the other two algorithms. Moreover, the
HSD for both Baghdad and Sadr City indicated significant difference between all pairs
of algorithms wrt solution size.
Of the partners in a given solution, we also recorded the number of partners less
than 0.5km away from an actual cache. For Baghdad, NAIVE-KSEP-SC performed
best in this regard, averaging 8.13 partners less than 0.5km from an actual cache
site. Although this result for Baghdad is significant based on an analysis of variance
(ANOVA) and honest significant differences (HSD) ( p-value of 2.3 · 10−9 ), we also note
that the greatest difference among averages was still less than one partner. This same
result for Sadr City, however, tells a different story. For this test, NAIVE-KSEP-SC
performed poorly with regard to the other two algorithms, finding only 3 partners
meeting these criteria for each of the 100 trials. GREEDY-KSEP-OPT2 performed very
well in this aspect (for Sadr City). It averaged over 5 partners less than 0.5 km from an
actual cache. Further, for Sadr City, all partners found by GREEDY-KSEP-OPT2 were
within 600 m of an actual cache site. The ANOVA ( p-value of 2.2 · 10−16 ) and HSD of
partners less than 0.5 km from an actual cache for the Sadr City trials indicate that
these results are significant.
Our primary metric of accuracy was average distance to actual cache. In this
regard, GREEDY-KSEP-OPT2 performed the best. It obtained an average distance of
0.72km for Baghdad and 0.35km for Sadr City. This number was 40m less for Baghdad
and 100m less for Sadr City when compared to GREEDY-KSEP-OPT1, whose average
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:20

P. Shakarian et al.
Table IV. k-SEP Algorithm Performance Results
Area

Algorithm

Sample Mean Runtime

Sample Runtime
Standard Deviation

Baghdad

NAIVE-KSEP-SC
GREEDY-KSEP-OPT1
GREEDY-KSEP-OPT2

354.75 ms
162.08 ms
201.40 ms

12.86
40.83
36.44

Sadr City

NAIVE-KSEP-SC
GREEDY-KSEP-OPT1
GREEDY-KSEP-OPT2

28.85 ms
25.44 ms
24.64 ms

10.52
9.33
8.95

distance varied widely among the trials. With regard to this metric, NAIVE-KSEP-SC
performed the worst, particularly in Sadr City, where it predicted caches over twice as
far from actual caches as GREEDY-KSEP-OPT2 (on average). For both Baghdad and
Sadr City, the simple ANOVA yielded a p-value of 2.2 · 10−16 , which suggests with a
99% probability that there is a difference among the algorithms. Also, for both areas,
Tukey’s HSD indicates significant difference between each pair-wise comparison of
algorithms.
Algorithm Runtimes. Table IV shows the runtimes of our algorithms. In order to validate the findings suggested by Table IV statistically, we ran analysis of variance
(ANOVA) and Tukey’s Honest Significant Difference test (HSD) for pair-wise comparisons [Freedman et al. 2007]. An ANOVA for the Baghdad runtimes gave a p-value of
2.2 · 10−16 , which suggests with well over 99% probability that GREEDY-KSEP-OPT1 is
statistically faster than GREEDY-KSEP-OPT2. The HSD for Baghdad indicates that,
with regard to runtimes, all pair-wise-comparison of the three algorithms are significantly different. For Sadr City, the ANOVA gave a p-value of 4.9 · 10−3 , which suggests
with a 99% probability that the algorithms differ in run-times. However, the HSD indicates, with an 82% probability, that there is no difference among GREEDY-KSEP-OPT1
and GREEDY-KSEP-OPT2, while both differ significantly from NAIVE-KSEP-SC.
6.1 A Simple Heuristic to Improve Accuracy

In our implementation of all three algorithms, “ties” in greedy selection of partners
were determined by a “coin toss.” Specifically, we are considering the case where
this size = cur size in line 2 of NAIVE-KSEP-SC in Section 4.2. Let us re-phrase the
situation as follows. Let O be the entire set of observations and O ⊆ O be the set of
observations currently not assigned a partner. Let p be the current partner that best
meets the criteria for greedy selection and p be the partner we are considering. We
define P and P as subsets of O that are the observations associated with p and p respectively. Hence, if |P ∩O | > |P∩O |, we pick p . As implemented, if |P ∩O | = |P∩O |,
we flip a coin. We add a simple heuristic that simply states that “partners that cover
more observations are preferred.” We change the criteria as follows.
— If |P ∩ O | = |P ∩ O |, then do the following:
— If |P | > |P|, pick p
— If |P| > |P |, pick p
— If |P| = |P |, flip a coin.
We shall refer to this as the “tie-breaker” heuristic. The result is that the solution set
of partners covers more observations and hence provides a more “dense” solution.
We added this heuristic to our existing code for all three algorithms and ran each
one 100 times for both the Baghdad and Sadr City areas. Unsurprisingly, as this is
a constant-time operation, runtimes were not affected. However, accuracy improved
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:21

Table V. The Tie-Breaker heuristic on GREEDY-KSEP-OPT2 Solution Size
Area

Tie-Breaker
Heuristic

Sample Mean
Solution Size

Sample Mean
Number of Partners
≤ 0.5 km
to actual cache

Baghdad

No
Yes

14.00
14.00

7.49
7.87

Sadr City

No
Yes

6.00
6.00

5.28
6.00

Table VI. The Tie-Breaker heuristic on GREEDY-KSEP-OPT2 - Distances to
Actual Cache Sites
Area

Tie-Breaker
Heuristic

Sample Mean
Avg Dist to
actual cache

Sample Std Dev
of Avg Dist to
actual cache

Sample Mean
Std Dev of Dist to
actual cache

Baghdad

No
Yes

0.72 km
0.69 km

0.03
0.02

0.63
0.64

Sadr City

No
Yes

0.35 km
0.28 km

0.03
0.02

0.47
0.11

in all cases. As GREEDY-KSEP-OPT2 still provided the most accurate results, the
following exposition shall focus on how the heuristics affected the solution size and
accuracy for this algorithm.
Because the tie-breaker heuristic only adjusts how two partners are chosen, both of
which can be paired with the same uncovered observations, the size of the solution was
unaffected in both the Baghdad and Sadr City trials. However, the number of predicted
cache sites less than 500m from an actual site increased for both the Baghdad and Sadr
City tests. For Baghdad, more trials returned solutions with 8 predictions less than
500m from an actual site than returned 7, the opposite being the case without the tiebreaker heuristic. For Sadr City, all elements of every solution set returned were less
than 500m from an actual cache site. Using the well known T-Test [Freedman et al.
2007], we showed that these results are statistically significant as this test returned
a p-value of 6.2 · 10−8 for Baghdad and 2.2 · 10−16 for Sadr City. The results of these
experiments with the tie-breaker heuristic are shown in Tables V and VI.
Summary. Those experiments demonstrate statistically that GREEDY-KSEP-OPT2
provides a viable solution, consistently producing the smaller solution sets which
were closer to actual cache sites faster than the basic set-covering approach, at times
approaching the faster, although less-accurate GREEDY-KSEP-OPT1. The proximity of
the elements of the solution set to actual cache sites is encouraging for real-world use.

7. RELATED WORK

In this section we present related work of three different varieties. We compare GAPs
to other forms of abduction, facility location, k-means clustering, and constrained clustering. As an aside, readers interested in a discussion of the SCARE software from the
perspective of military analysis or social science can refer to Shakarian et al. [2009],
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:22

P. Shakarian et al.

where the software package was introduced. However, that work does not include any
formal technical details on the framework of geospatial abduction, complexity results,
or algorithm analysis.
GAPs and other forms of Abduction. Abduction [Peirce 1955] has been extensively
studied in medicine [Peng and Reggia 1986; Reggia and Peng 1990], fault diagnosis [Console et al. 1991], belief revision [Pagnucco 1996], database updates [Console
et al. 1995; Kakas and Mancarella 1990] and AI planning [do Lago Pereira and
de Barros 2004]. Two major existing theories of abduction include logic-based abduction [Eiter and Gottlob 1995] and set-covering abduction [Bylander et al. 1991].
Though none of these papers deals with spatial inference, Shanahan [1996] presents a
logical formalism dealing with objects’ spatial occupancy, while Santos and Shanahan
[2002] describe the construction of a qualitative spatial reasoning system based on
sensor data from a mobile robot. In Santos and Shanahan [2002], sensor data are explained by hypothesizing the existence of physical objects along with the dynamic relationships that hold between them, all with respect to a (possibly moving) viewpoint.
This approach combines both space and time. Kuipers [1996] describes the Spatial
Semantic Hierarchy which formalizes, the spatial context in which a robot moves. In
the hierarchy, the topological level defines a map which describes the environment as
a collection of places, paths, and regions, linked by topological relations such as connectivity, order, containment, boundary, and abstraction. Places (i.e., zero-dimensional
points), paths (i.e., one dimensional subspaces, denoting for example a street in a city,
possibly represented as an ordering relation on the places they contain), and boundary
regions (i.e., two-dimensional subspaces of the robot environment) are created from
experience represented as a sequence of views and actions. They are created by abduction, positing the minimal additional set of places, paths, and regions required to
explain the sequence of observed views and actions.
Set-covering abduction [Bylander et al. 1991] assumes the existence of a function
determining the observable effects of a set of hypotheses, and is based on inverting
such function. Given a set of hypotheses H and a set of observations O, the domain
knowledge is represented by a function e that takes as an argument a set of hypotheses
and gives as a result the corresponding set of observations. Thus, for every subset of
the hypotheses H  ⊆ H, their effects are known to be e(H  ). In this case, abduction
finds a set H  ⊆ H such that O ⊆ e(H  ), that is, it finds a set of hypotheses H  whose
effects e(H  ) include all observations in O. A common assumption is that the effects


of
 the hypotheses are independent, that is, for every H ⊆ H, it holds that e(H ) =
e({h}).
If
this
condition
is
met,
abduction
can
be
seen
as
a
form
of
set-covering.
h∈H 
No spatial reasoning is done here.
Comparison with facility location. There are several important ways in which GAPs differ

from facility location problems.
— Although it is possible to specify a distance-based cost function, in a GAP problem,
the distances between observations and partners are constraints (α and β in this
paper) whereas facility location problems usually attempt to minimize the distance
between producers and consumers.
— In this article, GAP problems have a minimum distance between observations and
partners that must be exceeded. In many respects, this requirement makes GAP
problems more difficult than facility location and other computational geometry
problems as the set of possible partners that cover a given observation is a nonconvex ring. Further, the feasibility function (feas) adds non-uniform holes to such
a ring. Maass [1986] addresses the complexity of non-convex covering and highlights issues with problems such as this.
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:23

— The feasibility predicate, feas is not part of a facility location problem. This gives us
the ability to restrict certain locations that can be partners.
— In general, the relation between observations and partners can be viewed to be a
set of constraints. In this paper, we only used α, β,and feas. However, in the future,
we could add additional constraints. Further, as our formalism represents space
as a set of discrete points (also not typically done with facility location), we can
easily specify certain properties of these points to apply such constraints (such as
feas).
Comparison with k-means clustering. A well-known and studied problem in clustering
location is the k-means problem [MacQueen 1967]. This problem can be expressed as
follows:
k-means:
INPUT: Coordinates on a plane C and natural number k
OUTPUT: k disjoint sets of C, C1 , . . . , Ck such that for each Ci, all the mean Euclidean
distance among all c ∈ Ci is minimized.

Clustering problems group points into clusters, associating each cluster with a center. At first glance, one may think that the points are equivalent to observations and
the “centers are equivalent to partners. However, this is not so. Most versions of the
clustering problem seek only to arrange points in groups, with “centers” being a side
effect of the algorithm. Geospatial abduction problem seeks to find partners that support observations and places constraints on the location of the partners; this is a key
difference from “centers” in clustering problems. Clustering algorithms cannot handle
the generality of our feasibility predicate or the (α, β) constraints.
In addition to these obvious differences, we experimentally compared an implementation of k-means with GREEDY-KSEP-OPT2 on the Sadr City data. Even when we
ignore the obvious value of α, β and the feasibility predicate, GREEDY-KSEP-OPT2
outperforms the SimpleKMeans solver in WEKA version 3.7.0 [WEKA 2009]. Note that
the exclusion of these parameters makes GREEDY-KSEP-OPT2 perform worse than it
performs with these parameters; yet, it performed better than k-means in terms of
accuracy. Our experiment was setup as follows.
— We used the same area for the Sadr City tests, as the α value was 0 in these tests
and there were virtually no non-feasible points near the observations. This allowed
us to use WEKA’s k-means implementation “out-of-the-box” as we did not have to
implement any extra infrastructure to deal with feasibility and α = 0.
— We set k = 6, the number of partners consistently found by GREEDY-KSEP-OPT2.
Normally, we would rather have the algorithm determine this size. Note that supplying the algorithm with a size already determined by GREEDY-KSEP-OPT2 (and,
also the smallest size of any explanation for Sadr City we found in our trials) gives
an advantage to k-means. Hence, we did not compare solution sizes.
— We clustered the observations with k-means and considered the “center” of each
cluster the cache location for the cluster.
— We did not compare timing results, as we ran WEKA in its GUI environment.
We ran 500 iterations of the SimpleKMeans and worked with the average centers
for the clusters as reported by WEKA. Multiple runs of the 500 iterations yielded the
same centers.
Average Distance Using WEKA, we obtained an average accuracy of 0.38 km, which is
worse than GREEDY-KSEP-OPT2 (average over 100 trials, 0.28 km).
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:24

P. Shakarian et al.

Worst-Case Distance WEKA’s SimpleKMeans returned 2 of the 6 points with a distance
of greater than 600 meters from a cache site. Without the “tie-breaking” heuristic,
GREEDY-KSEP-OPT2 never reported a prediction over 600 meters from a cache site
(all reported partners over 100 trials). With the heuristic, GREEDY-KSEP-OPT2 never
reported a prediction over 500 meters from a cache site.
Best-Case Distance The closest partners ever returned by GREEDY-KSEP-OPT2
(either with our without the heuristic) were 200 m away from an actual cache site (on
average, the closest partner per explanation was 220 m away). WEKA’s SimpleKMeans
did return two partners less than 200 m - each only 100 m away from an actual cache
site.
These results suggest that k-means may not be the optimal method for GAP
problems. Further, it does not support feasibility and α. The results do hold some
promise for some variants of cost-based spatial explanation problems that require a k
input from one of our greedy-approaches. However, even in this case, there would be
modification required of the k-means algorithm to support feasibility and α.
Comparison with Constrained clustering. Constrained clustering Wagstaff et al. [2001]
studied clustering where, in addition to the points to be clustered, there are constraints
that either force two points in the same cluster (must-link) or force two points to be
in different clusters (cannot-link). Later work on constrained clustering has focused
on distance constraints between elements of C or distance constraints between clusters [Davidson and Ravi 2005]. Much of the work in this area is summarized in Basu
et al. [2008].
At first glance, it may appear that spatial abduction can be expressed as a cannotlink constrained clustering problem as follows: For each o, o  ∈ O if 	 ∃ p ∈ S s.t.
d(o, p) ∈ [α, β], d(o  , p) ∈ [α, β], and feas( p), then create a cannot-link constraint for
o, o  .
However, such a mapping cannot be guaranteed to provide a correct result. For example, take o 1 , o 2 , o 3 and p12 , p23 , p13 . Suppose o 1 and o 2 share just partner p12 , o 2
and o 3 share just partner p23 and o 1 , o 3 share just partner p13 . This is entirely possible
given the generality of feas. In such a case, all three observations could be incorrectly
grouped into a single cluster, although it is obvious there is no single partner that
supports all of them. Hence, such a mapping would not be trivial. Further, most clustering algorithms are not seeking to constructively find centers that are constrained.
We leave the study of constrained clustering to solve GAP problems (i.e., an adaption
of the k-means algorithm) to future work. However, it is also worth noting that solving
constrained clustering problems given cannot-link constraints is NP-complete, so the
application of clustering techniques to this problem does not imply a more tractable
version of geospatial abduction, but rather an alternative heuristic.
8. CONCLUSIONS

There are a wide variety of problems where we can make geo-located observations “on
the ground” and where we want to infer a partner location. In this paper, we have
presented four examples of such problems: one dealing with serial killers, another
dealing with wildlife studies, and a third (perhaps more fun) application dealing with
finding sunken ships. A fourth real-world application we have looked at is that of
finding weapons caches associated with Improvised Explosive Device (IED) attacks in
Iraq where we were able to use real world, open source data. It is clear that many
other applications exist as well. For example, a bizarre (but real world) combination
ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:25

of two of our examples involves frequent attacks by man-eating leopards on children
in certain parts of greater Bombay in India. This situation is analogous to the serial
killer scenario where the leopard is the serial killer. We want to find the leopard’s
favorite “hang outs”, capture it, and solve the problem.
In this paper, we have made an attempt to formally define a class of geospatial
abduction problems (GAPs for short). We specifically made the following contributions.
— We developed formal mathematical definitions of geospatial abduction problems,
including several variants of the above problems. We conducted a detailed analysis
of the complexity of these problems.
— We developed exact algorithms for many of the problems, including a straightforward enumeration approach (NAIVE-KSEP-EXACT), by showing and leveraging
reductions to both the set-covering and dominating set problems, and by articulating these geospatial abduction problems via integer linear programs.
— As the complexity of most of the problems we have studied is NP-hard, we developed
two greedy approximation schemes for the k-SEP problem (other than set-covering)
and illustrated a scheme to quickly find a solution using randomized approaches to
the dominating set problem.
— We have implemented these algorithms and conducted experimental comparisons
of the reduction to set-covering and two other greedy approaches; GREEDY-KSEPOPT1 and GREEDY-KSEP-OPT2. Both of these algorithms outperformed the setcovering reduction in an experiment on the Understanding War Special Groups
dataset. We also implemented a “tie-breaker” heuristic that further improved the
accuracy of the algorithms.
— We have also developed approximation schemes using relaxations of the linearinteger program for k-SEP and the cost-based variant WT-SEP.
There are many interesting directions for future work. For example, spatial abduction in dimensions greater than two might be explored. A probabilistic variant might
replace the feasibility predicate with a probability distribution function, or express the
relationship between observations and partners as a PDF based on distance rather
than rely on α, β. Also, the use of randomization in the approximation algorithms may
improve results for both the greedy and linear programming approaches presented in
this article.
One aspect to explore in future work is the relationship between observations and
partners. k-SEP and its cost based variants only rely on α, β. However, many applications may have other constraints. Perhaps there is a direction associated with each
observation (as in identifying where an artillery round originated from), which would
limit the locations of the partner. Another possibility is to add geographic constraints.
Perhaps the observation cannot have a partner across a body of water, or beyond the
edge of a cliff.
ELECTRONIC APPENDIX

The electronic appendix for this article can be accessed in the ACM Digital Library.
REFERENCES
A LPAYDIN, E. 2010. Introduction to Machine Learning, 2nd Ed. MIT Press.
B ASU, S., D AVIDSON, I., AND WAGSTAFF , K. 2008. Constrained Clustering: Advances in Algorithms, Theory,
and Applications. Chapman & Hall/CRC.
B RANTINGHAM , P. AND B RANTINGHAM , P. 2008. Crime pattern theory. In Enviromental Criminology and
Crime Analysis, R. Wortley and L. Mazerolle, Eds., 78–93.
B YLANDER , T., A LLEMANG, D., T ANNER , M. C., AND J OSEPHSON, J. R. 1991. The computational complexity of abduction. Artif. Intell. 49, 1-3, 25–60.

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

7:26

P. Shakarian et al.

C ONSOLE , L., P ORTINALE , L., AND T HESEIDER D UPR É , D. 1991. Focussing abductive diagnosis. Arti.
Intelli. Comm. 4, 2–3, 88–97.
C ONSOLE , L., S APINO, M. L., AND T HESEIDER D UPR É , D. 1995. The role of abduction in database view
updating. J. Intell. Inform. Syst. 4, 3, 261.
C ORMEN, T. H., L EISERSON, C. E., R IVEST, R. L., AND S TEIN, C. 2001. Introduction to Algorithms, Second
ed. MIT Press.
D AVIDSON, I. AND R AVI , S. S. 2005. Clustering with constraints: Feasibility issues and the k-means algorithm. In Proceedings of the SIAM Data Mining Conference (SDM).
DO L AGO P EREIRA , S. AND DE B ARROS, L. N. 2004. Planning with abduction: A logical framework to
explore extensions to classical planning. In Lecture Notes in Computer Science Advances in Artificial
Intelligence.
E ITER , T. AND G OTTLOB, G. 1995. The complexity of logic-based abduction. J. ACM 42, 1, 3–42.
F REDMAN, M. L. AND T ARJAN, R. E. 1987. Fibonacci heaps and their uses in improved network optimization algorithms. J. ACM 34, 3, 596–615.
F REEDMAN, D., P URVES, R., AND P ISANI , R. 2007. Statistics, 4th Ed. W.W. Norton and Co.
G AREY, M. R. AND J OHNSON, D. S. 1979. Computers and Intractability; A Guide to the Theory of NPCompleteness. W. H. Freeman & Co., New York, NY.
H OCHBAUM , D. S. 1982. Approximation Algorithms for the set covering and vertex cover problems. SIAM
J. Comput. 11, 3, 555–556.
J IA , L., R AJARAMAN, R., AND S UEL , T. 2002. An efficient distributed algorithm for constructing small
dominating sets. Distrib. Comput. 15, 4, 193–205.
J OHNSON, D. 1982. The NP-completeness column: An ongoing guide. J. Algorithms 3, 2, 182–195.
K AKAS, A. C. AND M ANCARELLA , P. 1990. Database updates through abduction. In Proceedings of the
International Conference on Very Large Databases (VLDB).
K ARP, R. 1972. Reducibility among combinatorial problems. In Complexity of Computer Computations, R. E.
Miller and J. W. Thatcher Eds. 85–103.
K UHN, F. AND WATTENHOFER , R. 2003. Constant-time distributed dominating set approximation. In Proceedings of the 22nd ACM Symposium on the Principles of Distributed Computing (PODC). 25–32.
K UIPERS, B. 1996. A hierarchy of qualitative representations for space. In Working Papers of the 10th International Workshop on Qualitative Reasoning about Physical Systems.
L U, J. J., N ERODE , A., AND S UBRAHMANIAN, V. 1996. Hybrid knowledge bases. IEEE Trans. Knowl. Data
Engin. 8, 5, 773–785.
L UND, C. AND YANNAKAKIS, M. 1994. On the hardness of approximating minimization problems. J.
ACM 41, 5, 960–981.
M AASS, W. 1986. On the complexity of nonconvex covering. SIAM J. Comput. 15, 2, 453–467.
M AC Q UEEN, J. B. 1967. Some methods for classification and analysis of multivariate observations. In Proceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability. L. M. L. Cam and
J. Neyman, Eds. Vol. 1. University of California Press, 281–297.
PAGNUCCO, M. 1996. The role of abductive reasoning within the process of belief revision. Ph.D. thesis,
Basser Department of Computer Science, University of Sydney, Australia.
PAPADIMITRIOU, C. H. 1981. Worst-case and probabilistic analysis of a geometric location problem. SIAM
J. Comput. 10, 3, 542–557.
PASCHOS, V. T. 1997. A survey of approximately optimal solutions to some covering and packing problems.
ACM Comput. Surv. 29, 2, 171–209.
P EIRCE , C. S. 1955. Philosophical Writings of Peirce, (selected and edited with an introduction by Justus
Buchler.). Dover Publications, New York,.
P ENG, Y. AND R EGGIA , J. A. 1986. Plausibility of Diagnostic Hypotheses. In Proceedings of the 5th National
Conference on AI (AAAI). 140–145.
R EGGIA , J. A. AND P ENG, Y. 1990. Abductive Inference Models for Diagnostic Problem-Solving. SpringerVerlag, Berlin, Germany.
R OSSMO, D. K. AND R OMBOUTS, S. 2008. Geographic profiling. In Enviromental Criminology and Crime
Analysis, R. Wortley and L. Mazerolle, Eds., 136–149.
S ANTOS, P. AND S HANAHAN, M. 2002. Hypothesising object relations from image transitions. In Proceedings
of the European Conference on Artificial Intelligence (ECAI).
S HAKARIAN, P., S UBRAHMANIAN, V., AND S APINO, M. L. 2009. SCARE: A Case Study with Baghdad. In
Proceedings of the 3rd International Conference on Computational Cultural Dynamics (ICCCD). AAAI.

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

GAPs: Geospatial Abduction Problems

7:27

S HANAHAN, M. 1996. Noise and the common sense informatic situation. In Proceedings of the National
Conference on Artifical Intelligence AAAI. 1098.
US A RMY. 1994. Intelligence Preparation of the Battlefiled (US Army Field Manual). FM 34-130 Ed.
VAZIRANI , V. V. 2004. Approximation Algorithms. Springer.
WAGSTAFF , K., C ARDIE , C., R OGERS, S., AND S CHR ÖDL , S. 2001. Constrained k-means clustering with
background knowledge. In Proceedings of the 18th International Conference on Machine Learning
(ICML). Morgan Kaufmann Publishers Inc., San Francisco, CA, 577–584.
WEKA. 2009. WEKA 3 Data Mining, http://www.cs.waikato.ac.nz/ml/weka/.
Received March 2010; revised August 2010; accepted August 2010

ACM Transactions on Intelligent Systems and Technology, Vol. 3, No. 1, Article 7, Publication date: October 2011.

A Network-Based Approach for Identifying Cancer Causing
Pathogens
Joseph Hannigan

Suzanne J. Matthews

Department of Electrical Engineering &
Computer Science
United States Military Academy

Department of Electrical Engineering &
Computer Science
United States Military Academy

Joseph.Hannigan@usma.edu
John K. Wickiser

Suzanne.Matthews@usma.edu
Paulo Shakarian

Department of Chemistry and Life Science
United States Military Academy

Department of Electrical Engineering &
Computer Science
United States Military Academy

John.Wickiser@usma.edu
ABSTRACT
We present a new method to identify malignant cancercausing pathogens by analyzing their interactions with the
host protein interaction network. We introduce two new
measurements, core score and moment score that is based
on topological characteristics of the network of host proteins
that interact with the pathogen. We applied these measurement to a data set consisting of the interactions of 135
pathogens and a human protein-interaction network. We
show a strong linear relationship (R2 = 0.90) between the
core score and the probability that a pathogen leads to malignant cancer in humans and demonstrate, using a decision
tree classifier, that both measurements can be used to correctly identify pathogens that lead to malignant cancer in
humans with an accuracy of 97%.

Categories and Subject Descriptors
J.3 [Life and Medical Sciences]: Biology and genetics;
G.2.2 [Graph Theory]: Network problems; H.2.8 [Database
Applications]: Data Mining

General Terms
Theory, Measurement, Experimentation

Keywords
Protein Interaction Networks, Network topology, Pathogens,
Cancer

1.

INTRODUCTION

Pathogens (such as viruses and other microbes) are estimated to cause 20% of all fatal cancers in humans [15].

This paper is authored by an employee(s) of the United States Government
and is in the public domain. Non-exclusive copying or redistribution is allowed, provided that the article citation is given and the authors and agency
are clearly identified as its source.
ACM SE ’14 March 28 - 29, 2014, Kennesaw, GA, USA. Copyright is held
by the owner/author(s). Publication rights licensed to ACM.
Copyright 2014 ACM ACM 978-1-4503-2923-1/14/03 ...$15.00
http://dx.doi.org/10.1145/2638404.2735459.

Paulo.Shakarian@usma.edu
In recent years, much work [1, 9] has been done to study
the role of viruses in causing tumors and malignant cancers.
Most studies involve inducing tumors in animal models, as
it is very difficult to observe viral tumor growth in human
hosts, given the long latency periods for expression.
However, animal models have been limited in their ability
to mimic the pathogenesis of cancer-causing viruses in humans [1]. There is great potential in leveraging information
gained from human-pathogen protein interaction networks
(PIN) for tracking the lethality of viruses. In silico detection of cancer causing pathogens can facilitate the process of
creating vaccines. If these diseases were prevented, it would
reduce cancer cases in developing and developed countries
by 26.3%, and 7.7% respectively [15].
Recent analyses of host-pathogen interaction suggest that
pathogens associate with proteins based on the topological
features of the host protein interaction network [13, 14]. We
hypothesize that pathogens interact best with host proteins
containing specific features that enable optimal virulence.
To test this hypothesis, we developed a new quantitative
measurement of pathogens, core score, which is based on the
topological characteristics of the proteins from the host organism. Based on a study of 135 pathogens interacting with
a human protein interaction network, we not only show that
this measurement has a strong linear relationship with the
probability that the pathogen is cancer-causing in humans
(R2 = 0.90), but also that it can successfully be used to classify pathogens as cancer-causing (with an accuracy of 97%).
Further, we introduce a second measurement, moment score,
that when considered together with the core score can correctly classify pathogens as directly cancer-causing (leading
to cancer in humans in a short time span without requiring
additional pathogenic interaction) with an accuracy of 97%.
Our experimental results support the hypothesis that many
pathogens may have evolved to achieve optimal virulence
by interacting with portions of the host protein network
thought to be critical for intra-cellular communication [10].
These results also suggest that the core score may be a useful
metric to rate the lethality of a pathogen.

2.

RELATED WORK

There have been many recent studies investigating the sig-

Cancer causing pathogens
Name
*Hepatitis B virus
*Hepatitis C virus
Human herpesvirus 4
*Human herpesvirus 5
Human herpesvirus 8
*Human immunodeficiency virus 1
Human papillomavirus type 18
Human papillomavirus type 16
Human papillomavirus type 31
Human papillomavirus type 5
Human papillomavirus type 58
Human T-lymphotropic virus 1

Pathogen

SC
9.075
45.170
15.430
19.153
1.403
61.449
9.520
23.194
1.209
15.431
0.154
9.408

Table 1: Cancer causing pathogens with core scores.
Pathogens that indirectly lead to cancer are denoted
with a star.
nificance of PINs in various organisms; this work has shown
that essential proteins can be determined by network structure [19], allowed for the modeling of protein interactions [6,
2], helped identify disease-causing proteins [5], and proved
useful in identifying proteins in an organism associated with
cancer [12].
Specifically related to this paper is the recent work examining the study of pathogenic interaction with host PINs
and the study of the topological characteristics of proteins
that interact with various pathogens [13, 11, 14, 17, 18]. All
of these previous studies have focused on identifying topological properties of nodes (or sets of nodes) in the host PIN
that are likely targets for pathogenic interaction. This work
differs from these previous studies in that we characterize
the pathogen through analysis of topological properties of
host proteins with which it interacts. Specifically, we are
concerned with identifying if a pathogen leads to malignant
cancer in humans.

3.

APPROACH

We utilize the data set of [14] which consists of a human
PIN which consists of 63, 099 host interactions (not including self-interactions) over 10, 057 proteins as well as 2, 099
pathogen-host interactions with 416 pathogen proteins belonging to 135 pathogens. Using the available literature, we
determined whether or not each pathogen leads to cancer in
humans. These are listed in Table 1. We present a list of
all supporting references for cancer-causing pathogens in the
supplement. Note that some of the pathogens listed, such
as HIV which are highly correlated with cancer, but either
have a long term dormancy period or there is no reported
evidence for direct causation. These are denoted with a star.
The remaining pathogens on the list can be thought of as
directly leading to cancer. In this study, we consider both
types of cancer-causing pathogens. All other pathogens either supported by literature as non-carcinogenic or which
lacked reports of carcinogenicity were considered not cancer
causing.
To characterize the pathogens by the topology of the targeted host proteins, we created two new measurements that
are introduced for the first time in this paper: core score (SC )
and moment score (SM ). These measures depend on the degree and shell number of the host proteins which with the

1
1

1

Host Protein
Network

2
2

3

2

4

2

1
3

1

4

4

3
2

1

4

1

4

3

3

1

Protein Node

1
1

1

1

1

Affected Protein Node
Shell number

Figure 1: Example network. The first number represents the shell number of the node. See the methods
section for a detailed explanation of shell decomposition.
pathogen interacts. The degree of a host protein is simply
the number of other interacting host proteins. An S-core of
a PIN is the maximum sub-graph where each protein is connected to at least S other proteins and the shell number of
a protein is largest value S such that the protein is included
in that S-core. The shell number can be easily determined
using shell decomposition, described in [16] and proceeds as
follows: remove nodes with less than or equal to degree 1 and
assign them a shell number of 1, recalculating degree every
time a node is removed. Repeat this process but for nodes
with less than or equal to degree 2, assigning them shell
number 2. Then this process is repeated for nodes with less
than or equal to degree 2, assigning them shell number 2.
This process is continued until all nodes have are removed
and have a shell number. For a given shell S, we define its
moment hkS i be the moment (average degree) of nodes in
that shell. Figure 1 shows an example shell protein network
with a pathogen interaction.
Hence, the core score and moment score are calculated as
follows: For a given pathogen P let Pinteract be the total
number of proteins in the host that P interacts with. For
given shell S let Pinteract (S) be the number of pathogen
interactions with shell S. For shell S, let size(S) be the size
(number of nodes in) shell S. Core score and moment score
are defined in equations 1 and 2 below:
X S · Pinteract (S )
(1)
SC =
size(S )
S
SM =

X hkS i · Pinteract (S )
size(S )
S

(2)

From Figure 1, SC is calculated for the sample pathogen.
Because the pathogenPinteracts with 3 different proteins
in the host network,
S Pinteract (S) = 3. size(1) = 13,
size(2) = 5, size(3) = 5, and size(4) = 5. Pinteract (1) = 0,
Pinteract (2) = 2, Pinteract (3) = 0, and Pinteract (4) = 1. The
summation yields SC = 1 .60 .
In other words, SC is the summation of the ratio of interactions a virus has with each shell of a host v.s. the total
interactions, weighted with the shell number itself. SM is
the same, except it is weighted with the moment of each

Type I Error(Rejected True)
Name
SC
Human herpesvirus 8
1.403
Human papillomavirus type 31 1.209
Human papillomavirus type 58 0.154
Type II Error(Failed to Reject False)
Name
SC
Vaccinia virus
14.447

1

R² = 0.9008
0.9

0.7
0.6

Core Score = 8.146

Pr (≥ Sc) (approximate)

0.8

0.5
0.4
0.3
0.2
0.1
0
0

2

4

6

8

10

12

14

16

SM
6.280
4.863
0.373
SM
108.04

Table 2: Results of decision tree analysis on indirect and directly cancer causing pathogens. Method
yielded 3 false negatives (Type I error) and 1 false
positive (Type II error).

Sc

Figure 2: Direct and Indirect Cancer Causing
Pathogens represented as the core score versus the
fraction of cancer causing pathogens that are greater
than or equal to the corresponding core score on the
x-axis. This graph omits the data points at the end
of the x axis where y = 1.

shell. Therefore, SM approaches SC from above as the network becomes more connected with fewer, higher shells. Our
intuition behind these measures is derived from our previous work in [17] where we showed that shells with higher
moments had a greater number of pathogenic interactions.
The Weka J-48 decision tree classifier [7] was used to
ascertain if our measures can be used to correctly classify
pathogens as being cancer causing or not. Weka is a commonly used software package for data mining analysis, and
the J-48 decision tree classifier is typically used for decision
tree analysis.

4.

RESULTS

Let P r(≥ SC ) denote the probability that a pathogen is
directly or indirectly cancer-causing in humans given that
its core score is greater than or equal to SC . We approximate this probability by taking the fraction of the pathogens
examined in this study that have a certain core score or
greater (using the observed core scores from the population of pathogens examined). We found a linear relationship between the core score and this probability (Figure 2,
R2 = 0.90). This strong correlation suggests that the core
score can be used to identify cancer causing pathogens. To
test this hypothesis, we used a decision tree to identify cancer causing pathogens based on this measure. We found,
based on our population, pathogens with a core score greater
than 8.416 were often correctly identified as cancer causing
(97% accuracy, 3 false negatives, 1 false positive).
Table 2 summarizes the incorrectly classified pathogens.
The false negatives were Human herpes virus 8 (HHV 8),
Human papillomavirus 31 (HPV 31), and Human papillomavirus 58 (HPV 58). These three false negative pathogens
have abnormally low core scores (1.403, 1.209, and 0.154
respectively). However, we note that infection with HHV
8 (also known as Kaposi’s Sarcoma virus, or KSV) while
known to directly cause tumorgenesis in humans, is reported
to be insufficient to produce disease alone [9]. Due to the
pathogen’s requirement for another virus such as HIV to
cause cancer, we hypothesize that the virus does not need

Type I Error(Rejected True)
Name
Human herpesvirus 8
Human papillomavirus type 31
Human papillomavirus type 58

SC
1.403
1.209
0.154

SM
6.280
4.863
0.373

Table 3: Results of decision tree analysis on indirect and directly cancer causing pathogens. Method
yielded 3 false negatives (Type I error) and 1 false
positive (Type II error).

to infiltrate the core of the host PIN in order to achieve optimal virulence. Further, HPV 58 has a strong geographic
component. For instance, it is highly prevalent in cervical
cancer of East Asian women but is rare in cancer among
North American women. Further exploration is needed to
establish a link between low core score and these two viruses.
As for Vaccinia, our sole false-positive, there may be some
similarities between its host interaction and that of a carcinogenic pathogen as Vaccinia has recently been noted to
interfere with cancer [3, 4, 8]. This may suggest that falsepositives found with this measurement may be used to repress cancer growth in certain cases - this is may be an
important direction for future work.
We then studied the problem of identifying pathogens that
only directly cause cancer. As stated earlier, we label a
pathogen as directly causing cancer if there was clear evidence in the literature establishing a direct link between
infection and development of cancer. These pathogens are
denoted with an star in Table 1. Using this more narrow definition of “cancer causing” we find that our linear relationship
between SC and P r(≥ SC ) is significantly weakened, noting
that this probability monotonically increases for core scores
under 9.075 and reverses after this point.
However, if we consider both core score and moment score
together, we can correctly identify pathogens that directly
cause cancer with a 97% accuracy based on the results of our
decision tree (Figure 3). Using this two-variable classifier,
we obtained no false positives and only three false negatives 3. We hypothesize this arises due to moment score
being associated with a virus’ ability to penetrate deep into
the core of a host. However, based on our previous findings [17] where we showed that the core proteins are often
under-targeted, we suspect that high penetration of the core
may cause apitosis, or programmed cell death. As most cancer causing viruses are known to have an ability to disable or
delay the host’s mechanism for apitosis, this could explain
the cut off for very high moment scores.

Cancer Causing

Acknowledgements

Not Cancer Causing

180

The authors are supported under by the Army Research
Office (project 2GDATXR042). The opinions in this paper
are those of the authors and do not necessarily reflect the
opinions of the funders, the U.S. Military Academy, or the
U.S. Army.

160

140

120

Sm

100

6.

80

Moment Score = 68.097

Core Score = 9.075

60

40

20

0
0

10

20

30

40

50

60

70

Sc

Figure 3: Direct Cancer Causing Pathogens: Moment Score vs. Core Score. Each data point represents a data point with a given core and moment
score. The legend specifies which pathogens are/are
not cancer causing. The box represents the area
that the decision tree determines as cancer causing.

Overall, our results suggest that the core and moment
scores of host-pathogen protein interactomes show promise
in helping facilitate the classification of unknown pathogens
as cancer causing. Our method could be used as a “precheck” prior to conducting more expensive wet lab testing,
and assist in the rapid identification of newly discovered
pathogens as being carcinogenic.

5.

CONCLUSIONS

In this paper, we characterized pathogens by networktopological characteristics of the host proteins they interact
with using two new measurements that we call the core score
and the moment socre. Using “ground truth” data based on
a literature review, we showed that these measurements can
be used to identify if the pathogens lead to malignant cancer
in humans with 97% accuracy. Further, the linear relationship we found between the core score and the probability of
a pathogen leading to cancer indicates that the techniques
presented here could be potentially used to measure the level
of carcinogenicity for a given pathogen.
One potential shortcoming of our results is that we relied
entirely on existing data. We note that many of these data
sources were derived from previous studies that focused on
cancer-causing pathogens, which may bias some our results.
An important direction for future research in this topic is to
create a new, less-biased dataset of pathogens and their host
interactions. That said, we feel this work is a useful “first
step” toward identifying cancer-causing pathogens based on
host protein network interaction.
There are other important avenues for future work as well.
These include how to best characterize these measurements
on networks with erroneous, missing or uncertain interaction, determining the relevance of the topological characteristics of the proteins in the pathogen, and exploring the
possibility of these measurements as useful predictors for
other types of diseases.

REFERENCES

[1] J. S. Butel. Viral carcinogenesis: revelation of
molecular mechanisms and etiology of human disease.
Carcinogenesis, 21(3):pp. 405–426, 2000.
[2] A. I. M. Consortium. Evidence for Network Evolution
in an Arabidopsis Interactome Map. Science,
333(6042):601–607, July 2011.
[3] S. Gholami, A. A. Marano, N. G. Chen, A. Frentzen,
C.-H. Chen, C. Eveno, E. Lou, L. Belin, A. A. Szalay,
and Y. Fong. Enhanced therapeutic effects of a novel
oncolytic and anti-angiogenic vaccinia virus against
triple-negative breast cancer. Journal of the American
College of Surgeons, 215(3), Sep. 2012.
[4] M. Gil, M. Seshadri, M. P. Komorowski, S. I. Abrams,
and D. Kozbor. Targeting cxcl12/cxcr4 signaling with
oncolytic virotherapy disrupts tumor vasculature and
inhibits breast cancer metastases. Proc Natl Acad Sci
U S A, 2013.
[5] K.-I. Goh, M. E. Cusick, D. Valle, B. Childs,
M. Vidal, and A.-L. Barabasi. The human disease
network. Proceedings of the National Academy of
Sciences, 104(21):8685–8690, 2007.
[6] M. W. Hahn and A. D. Kern. Comparative genomics
of centrality and essentiality in three eukaryotic
protein-interaction networks. 22(4):803–806, 2005.
[7] M. Hall, E. Frank, G. Holmes, B. Pfahringer,
P. Reutmann, and I. H. Witten. The WEKA data
mining software: An update. volume 11 of SIGKDD
Explorations, 2009.
[8] J. Heo, C. Breitbach, A. Moon, C. Kim, R. Patt,
M. Kim, Y. Lee, S. Oh, H. Woo, K. Parato,
J. Rintoul, T. Falls, T. Hickman, B. Rhee, J. Bell,
D. Kirn, and T. Hwang. Sequential therapy with
jx-594, a targeted oncolytic poxvirus, followed by
sorafenib in hepatocellular carcinoma: preclinical and
clinical demonstration of combination efficacy. Mol
Ther., 19(6):1170, Jun. 2011.
[9] R. T. Javier and J. S. Butel. The history of tumor
virology. Cancer Research, 68(7693), October 2008.
[10] M. Kitsak, L. K. Gallos, S. Havlin, F. Liljeros,
L. Muchnik, H. E. Stanley, and H. A. Makse.
Identification of influential spreaders in complex
networks. Nat Phys, 6(11):888–893, November 2010.
[11] T. Milenkovı́c, V. Memisević, A. Bonato, and
N. Przulj. Dominating biological networks. PLOS
One, 6(8), 2011.
[12] T. Milenkovı́c, V. Memisević, A. K. Genesan, and
N. Przulj. Systems-level cancer gene identification
from protein interaction network topology applied to
melanogenesis-related interaction networks. Journal of
the Royal Society Interface, 7(44):pp. 423–437, 2010.
[13] M. S. Mukhtar, A.-R. Carvunis, M. Dreze, P. Epple,
J. Steinbrenner, J. Moore, M. Tasan, M. Galli,
T. Hao, M. T. Nishimura, S. J. Pevzner, S. E.

[14]

[15]

[16]
[17]

[18]

[19]

Donovan, L. Ghamsari, B. Santhanam, V. Romero,
M. M. Poulin, F. Gebreab, B. J. Gutierrez, S. Tam,
D. Monachello, M. Boxem, C. J. Harbort,
N. McDonald, L. Gai, H. Chen, Y. He, E. U. E.
Consortium, J. Vandenhaute, F. P. Roth, D. E. Hill,
J. R. Ecker, M. Vidal, J. Beynon, P. Braun, and J. L.
Dangl. Independently Evolved Virulence Effectors
Converge onto Hubs in a Plant Immune System
Network. Science, 333(6042):596–601, July 2011.
V. Navratil, B. de Chassey, C. R. R. Combe, and
V. Lotteau. When the human viral infectome and
diseasome networks collide: towards a systems biology
platform for the aetiology of human diseases. BMC
systems biology, 5(1):13+, 2011.
D. M. Parkin. The global health burden of
infection-associated cancers in the year 2002.
International Journal of Cancer, 118(12):pp.
3030–3044, June 2006.
S. B. Seidman. Network structure and minimum
degree. Social Networks, 5(3):269 – 287, 1983.
P. Shakarian and J. K. Wickiser. Similar pathogen
targets in arabidopsis thaliana and homo sapiens
protein networks. PLoS ONE, 7, 09 2012.
R. W. Solava, R. P. Michaels, and T. Milenkovic.
Graphlet-based edge clustering reveals
pathogen-interacting proteins. Bioinformatics,
28(18):480–486, 2012.
H. Yu, D. Greenbaum, H. X. Lu, X. Zhu, and
M. Gerstein. Genomic analysis of essentiality within
protein networks. Trends Genet, 20(6):227–231, June
2004.

West Point Network Science Center
(Pre-Print Manuscript)

A Scalable Heuristic for Viral Marketing Under the
Tipping Model
Paulo Shakarian · Sean Eyre · Damon
Paulo

arXiv:1309.2963v1 [cs.SI] 11 Sep 2013

Sept. 2013

Abstract In a “tipping” model, each node in a social network, representing an
individual, adopts a property or behavior if a certain number of his incoming
neighbors currently exhibit the same. In viral marketing, a key problem is
to select an initial ”seed” set from the network such that the entire network
adopts any behavior given to the seed. Here we introduce a method for quickly
finding seed sets that scales to very large networks. Our approach finds a set
of nodes that guarantees spreading to the entire network under the tipping
model. After experimentally evaluating 31 real-world networks, we found that
our approach often finds seed sets that are several orders of magnitude smaller
than the population size and outperform nodal centrality measures in most
cases. In addition, our approach scales well - on a Friendster social network
consisting of 5.6 million nodes and 28 million edges we found a seed set in under
P. Shakarian
Network Science Center and
Dept. Electrical Engineering and Computer Science
U.S. Military Academy
West Point, NY 10996
Tel.: 845-938-5576
E-mail: paulo@shakarian.net
S. Eyre
Network Science Center and
Dept. Electrical Engineering and Computer Science
U.S. Military Academy
West Point, NY 10996
Tel.: 845-938-5576
E-mail: sean.k.eyre@gmail.com
Damon Paulo
Network Science Center and
Dept. Electrical Engineering and Computer Science
U.S. Military Academy
West Point, NY 10996
Tel.: 845-938-5576
E-mail: damon.paulo@usma.edu

2

Paulo Shakarian et al.

3.6 hours. Our experiments also indicate that our algorithm provides small
seed sets even if high-degree nodes are removed. Lastly, we find that highly
clustered local neighborhoods, together with dense network-wide community
structures, suppress a trend’s ability to spread under the tipping model.
Keywords social networks · viral marketing · tipping model

1 Introduction
A much studied model in network science, tipping[19, 30, 20] (a.k.a. deterministic linear threshold[21]) is often associated with “seed” or “target” set selection, [12] (a.k.a. the maximum influence problem). In this problem, we have
a social network in the form of a directed graph and thresholds for each individual. Based on this data, the desired output is the smallest possible set
of individuals (seed set) such that, if initially activated, the entire population will become activated (adopting the new property). This problem is NPComplete [21, 15] so approximation algorithms must be used. Though some
such algorithms have been proposed, [24, 12, 3, 13] none seem to scale to very
large data sets. Here, inspired by shell decomposition, [9, 22, 2] we present a
method guaranteed to find a set of nodes that causes the entire population to
activate - but is not necessarily of minimal size. We then evaluate the algorithm on 31 large, real-world, social networks and show that it often finds very
small seed sets (often several orders of magnitude smaller than the population
size). We also show that the size of a seed set is related to Louvain modularity
and average clustering coefficient. Therefore, we find that dense community
structure combined with tight-knit local neighborhoods inhibit the spreading
of activation under the tipping model. We also found that our algorithm outperforms the classic centrality measures and is robust against the removal of
high-degree nodes.
The rest of the paper is organized as follows. In Section 2, we provide
formal definitions of the tipping model. This is followed by the presentation
of our new algorithm in Section 3. We then describe our experimental results
in Section 4. Finally, we provide an overview of related work in Section 5.

2 Technical Preliminaries
Throughout this paper we assume the existence of a social network, G =
(V, E), where V is a set of vertices and E is a set of directed edges. We will
use the notation n and m for the cardinality of V and E respectively. For
a given node vi ∈ V , the set of incoming neighbors is ηiin , and the set of
outgoing neighbors is ηiout . The cardinalities of these sets (and hence the inout
and out-degrees of node vi ) are din
respectively. We now define a threshold
i , di
function that for each node returns the fraction of incoming neighbors that
must be activated for it to become activate as well.

A Scalable Heuristic for Viral Marketing Under the Tipping Model

3

Definition 1 (Threshold Function) We define the threshold function
as mapping from V to (0, 1]. Formally: θ : V → (0, 1].
For the number of neighbors that must be active, we will use the shorthand
ki . Hence, for each vi , ki = dθ(vi ) · din
i e. We now define an activation function
that, given an initial set of active nodes, returns a set of active nodes after one
time step.
Definition 2 (Activation Function) Given a threshold function, θ, an activation function Aθ maps subsets of V to subsets of V, where for some
V0 ⊆V,
Aθ (V 0 ) = V 0 ∪ {vi ∈ V s.t. |ηiin ∩ V 0 | ≥ ki }
(1)
We now define multiple applications of the activation function.
Definition 3 (Multiple Applications of the Activation Function) Given
a natural number i > 0, set V 0 ⊆ V , and threshold function, θ, we define the
multiple applications of the activation function, Aiθ (V 0 ), as follows:
(
Aiθ (V 0 ) =

Aθ (V 0 )
if i = 1
i−1
0
Aθ (Aθ (V )) otherwise

(2)

0
Clearly, when Aiθ (V 0 ) = Ai−1
θ (V ) the process has converged. Further, this
always converges in no more than n steps (as, prior to converging, a process
must, in each step, activate at least one new node). Based on this idea, we
define the function Γ which returns the set of all nodes activated upon the
convergence of the activation function.

Definition 4 (Γ Function) Let j be the least value such that Ajθ (V 0 ) =
Aj−1
(V 0 ). We define the function Γθ : 2V → 2V as follows.
θ
Γθ (V 0 ) = Ajθ (V 0 )

(3)

We now have all the pieces to introduce our problem - finding the minimal number of nodes that are initially active to ensure that the entire set V
becomes active.
Definition 5 (The MIN-SEED Problem) The MIN-SEED Problem is defined as follows: given a threshold function, θ, return V 0 ⊆ V s.t. Γθ (V 0 ) = V ,
and there does not exist V 00 ⊆ V where |V 00 | < |V 0 | and Γθ (V 00 ) = V .
The following theorem is from the literature [21, 15] and tells us that the
MIN-SEED problem is NP-complete.
Theorem 1 (Complexity of MIN-SEED [21, 15]) MIN-SEED in NPComplete.

4

Paulo Shakarian et al.

3 Algorithms
In this section, we introduce an integer program that solved the MIN-SEED
problem exactly and our new decomposition-based heuristic.

3.1 Exact Approach
Below we present SEED-IP, an integer program that if solved exactly, guarantees an exact solution to MIN-SEED (see Proposition 1). Though, in general,
solving an integer program is also NP-hard, suggesting that an exact solution will likely take exponential time, good approximation techniques such
as branch-and-bound exist and mature tools such as QSopt and CPLEX can
readily take and approximate solutions to integer programs.
Definition 6 (SEED-IP)
min
∀i, t ∈ {1, . . . , n},
∀i,
∀i, ∀t > 0,

P

i

xi,1 ,

w .r .t.

(4)

xi,t ∈ {0, 1}

(5)

xi,n = 1
xi,t ≤ xi,t−1 +

1
din
i θ(vi )

(6)
P

vj ∈ηiin

xj,t−1

(7)

Proposition 1 If V 0 is a solution to MIN-SEED, then setting ∀vi ∈ V 0 , xi,1 =
1 and ∀vi ∈
/ V 0 , xi,1 = 0 is a solution to SEED-IP.
If the vector [xi,t ] is a solution to SEED-IP, then {vi |xi,1 = 1} is a solution
to MIN-SEED.
Proof Claim 1: If V 0 is a solution to MIN-SEED, then setting ∀vi ∈ V 0 , xi,1 = 1
and ∀vi ∈
/ V 0 , xi,1 = 0 is a solution to SEED-IP.
Let [xi,t ] be a vector for SEED-IP created as per claim 1.
by way
PSuppose,
P
0
of contradiction (BWOC), there exists vector [x0i,t ] s.t.
x
<
i i,1
i xi,1 .
However, consider the set of nodes V 00 = {vi |x0i,1 = 1}. By Constraint 7 of
SEED-IP, we know that, for t > 1, that if x0i,t = 1, we have vi ∈ Atθ (V 00 ). Hence,
by P
ConstaintP
6 V 00 is a solution to MIN-SEED. This means that |V 00 | < |V 0 |
0
as i xi,1 < i xi,1 , which is a contradiction.
Claim 2: If the vector [xi,t ] is a solution to SEED-IP, then {vi |xi,1 = 1} is a
solution to MIN-SEED.
Suppose, BWOC, there exists set V 00 that is a solution to MIN-SEED s.t.
|V 00 | < |{vi |xi,1 = 1}|. Consider the vector [x0i,t ] where ∀i, x0i,0 = 1 iff vi ∈ V 00 .
By Constraint 7 of SEED-IP, we know that, for t > 1, that if vi ∈ Atθ (V 00 ), we
0
have x0i,t = 1. Hence, as Atθ (V 00 ) = V , know that
Constraint 6.
P [x0 i,t ] satisfies
P
00
Hence, as |V | < |{vi |xi,1 = 1}|, we know
x
<
x
i i,1
i i,1 , which is a
contradiction.
Proof of theorem: Follows directly form claims 1-2.
However, despite the availability of approximate solvers, SEED-IP requires
a quadratic number of variables and constraints (Proposition 2), which likely

A Scalable Heuristic for Viral Marketing Under the Tipping Model

5

will prevent this approach from scaling to very large datasets. As a result, in
the next section we introduce our heuristic approach.
Proposition 2 SEED-IP requires n2 variables and 2n2 constraints.

3.2 Heuristic
To deal with the intractability of the MIN-SEED problem, we design an algorithm that finds a non-trivial subset of nodes that causes the entire graph
to activate, but we do not guarantee that the resulting set will be of minimal
size. The algorithm is based on the idea of shell decomposition often cited in
physics literature [31, 9, 22, 2] but modified to ensure that the resulting set will
lead to all nodes being activated. The algorithm, TIP DECOMP is presented
in this section.
Algorithm 1 TIP DECOMP
Require: Threshold function, θ and directed social network G = (V, E)
Ensure: V 0
1:
2:
3:
4:
5:
6:
7:
8:
9:

For each vertex vi , compute ki .
For each vertex vi , disti = din
i − ki .
FLAG = TRUE.
while FLAG do
Let vi be the element of v where disti is minimal.
if disti = ∞ then
FLAG = FALSE.
else
Remove vi from G and for each vj in ηiout , if distj > 0, set distj = distj − 1.
Otherwise set distj = ∞.
10:
end if
11: end while
12: return All nodes left in G.

Intuitively, the algorithm proceeds as follows (Figure 1). Given network
G = (V, E) where each node vi has threshold ki = dθ(vi ) · din
i e, at each
iteration, pick the node for which din
−
k
is
the
least
but
positive
(or 0) and
i
i
remove it. Once there are no nodes for which din
−
k
is
positive
(or
0), the
i
i
algorithm outputs the remaining nodes in the network.
Now, we prove that the resulting set of nodes is guaranteed to cause all
nodes in the graph to activate under the tipping model. This proof follows
from the fact that any node removed is activated by the remaining nodes in
the network.
Theorem 2 If all nodes in V 0 ⊆ V returned by TIP DECOMP are initially
active, then every node in V will eventually be activated, too.
Proof Let w be the total number of nodes removed by TIP DECOMP, where
v1 is the last node removed and vw is the first node removed. We prove the

6

Paulo Shakarian et al.

Fig. 1 Example of our algorithm for a simple network depicted in box A. We use a threshold
value set to 50% of the node degree. Next to each node label (lower-case letter) is the value
din

i
for din
i − ki (where ki = d 2 e). In the first four iterations, nodes e, f, h, and i are removed
resulting in the network in box B. This is followed by the removal of node j resulting in
the network in box C. In the next two iterations, nodes a and b are removed (boxes D-E
respectively). Finally, node c is removed (box F). The nodes of the final network, consisting
of d and g, have negetive values for di − θi and become the output of the algorithm.

theorem by induction on w as follows. We use P (w) to denote the inductive
hypothesis which states that all nodes from v1 to vw are active. In the base
case, P (1) trivially holds as we are guaranteed that from set V 0 there are at
least k1 edges to v1 (or it would not be removed). For the inductive step,
assuming P (w) is true, when vw+1 was removed from the graph distw+1 ≥ 0
in
which means that din
w+1 ≥ kw+1 . All nodes in ηw+1 at the time when vw+1 was
removed are now active, so vw+1 will now be activated - which completes the
proof.
We also note that by using the appropriate data structure (we used a
binomial heap in our implementation), for a network of n nodes and m edges,
this algorithm can run in time O(m log n).
Proposition 3 The complexity of TIP DECOMP is O(m · log(n)).
Proof If we use a binomial heap as described in [14], we can create a heap
where we store each node and assign it a key value of disti for each node
vi . The creation of a heap takes constant time and inserting the n vertices

A Scalable Heuristic for Viral Marketing Under the Tipping Model

7

will take O(nlog(n)) time. We can also maintain a list data structure as well.
In the course of the while loop, all nodes will either be removed (as per the
algorithm), decreased in key-value no more than din
i or increased to infinity
(which we can implement as being removed and added to the list). P
Hence, the
in
number
of
decrease
key
or
removal
operations
is
bounded
by
n
+
i di . As
P in
i di = m (where m is the number of edges). As O(m·log(n)), the statement
follows.
4 Results
In this section we describe the results of our experimental evaluation. We
describe the datasets we used for the experiments in Section 4.1. We evaluate
the run-time of TIP DECOMP in Section 4.1.5. In Section 4.1.6, we evaluate
the size of the seed-set returned by the algorithm and we compare this to the
seed size returned by known centrality measures in Section 4.2. The speed of
the activiation process initiated with seed sets discovered by our algorithm is
described in Section 4.3. We then study how the removal of high-degree nodes
and community structure affect the results of the algorithm in Sections 4.4
and 4.4.1 respectively.
The algorithm TIP DECOMP was written using Python 2.6.6 in 200 lines
of code that leveraged the NetworkX library available from
http://networkx.lanl.gov/. The code used a binomial heap library written by
Björn B. Brandenburg available from http://www.cs.unc.edu/∼bbb/. The experiments were run on a computer equipped with an Intel X5677 Xeon Processor operating at 3.46 GHz with a 12 MB Cache running Red Hat Enterprise
Linux version 6.1 and equipped with 70 GB of physical memory. All statistics
presented in this section were calculated using R 2.13.1.
4.1 Datasets
In total, we examined 36 networks: nine academic collaboration networks,
three e-mail networks, and 24 networks extracted from social-media sites. The
sites included included general-purpose social-media (similar to Facebook or
MySpace) as well as special-purpose sites (i.e. focused on sharing of blogs,
photos, or video).
All datasets used in this paper were obtained from one of four sources:
the ASU Social Computing Data Repository, [35] the Stanford Network Analysis Project, [23] the University of Michigan, [26] and Universitat Rovira i
Virgili.[1] 31 of the networks considered were symmetric – i.e. if a directed
edge from vertex v to v 0 exists, there is also an edge from vertex v 0 to v. Tables 1 (A-C) show some of the pertinent qualities of the symmetric networks.
The networks are categorized by the results for the MIN-SEED experiments
(explained later in this section). Additionally, we also looked at several nonsymmetric (directed) networks and placed them in their own category. In what
follows, we provide their real-world context.

8

Paulo Shakarian et al.

4.1.1 Category A
– BlogCatalog is a social blog directory that allows users to share blogs
with friends. [35] The first two samples of this site, BlogCatalog1 and 2,
were taken in Jul. 2009 and June 2010 respectively. The third sample,
BlogCatalog3 was uploaded to ASU’s Social Computing Data Repository
in Aug. 2010.
– Buzznet is a social media network designed for sharing photographs, journals, and videos. [35] It was extracted in Nov. 2010.
– Douban is a Chinese social medial website designed to provide user reviews and recommendations. [35] It was extracted in Dec. 2010.
– Flickr is a social media website that allows users to share photographs. [35]
It was uploaded to ASU’s Social Computing Data Repository in Aug. 2010.
– Flixster is a social media website that allows users to share reviews and
other information about cinema. [35] It was extracted in Dec. 2010.
– FourSquare is a location-based social media site. [35] It was extracted in
Dec. 2010.
– Frienster is a general-purpose social-networking site. [35] It was extracted
in Nov. 2010.
– Last.Fm is a music-centered social media site. [35] It was extracted in
Dec. 2010.
– LiveJournal is a site designed to allow users to share their blogs. [35] It
was extracted in Jul. 2010.
– Livemocha is touted as the “world’s largest language community.” [35] It
was extracted in Dec. 2010.
– WikiTalk is a network of individuals who set and received messages while
editing WikiPedia pages. [23] It was extracted in Jan. 2008.
4.1.2 Category B
– Delicious is a social bookmarking site, designed to allow users to share
web bookmarks with their friends. [35] It was extracted in Dec. 2010.
– Digg is a social news website that allows users to share stories with
friends. [35] It was extracted in Dec. 2010.
– EU E-Mail is an e-mail network extracted from a large European Union
research institution. [23] It is based on e-mail traffic from Oct. 2003 to May
2005.
– Hyves is a popular general-purpose Dutch social networking site. [35] It
was extracted in Dec. 2010.
– Yelp is a social networking site that allows users to share product reviews. [35] It was extracted in Nov. 2010.
4.1.3 Category C
– CA-AstroPh is a an academic collaboration network for Astro Physics
from Jan. 1993 - Apr. 2003. [23]

A Scalable Heuristic for Viral Marketing Under the Tipping Model

9

– CA-CondMat is an academic collaboration network for Condense Matter Physics. Samples from 1999 (CondMat99), 2003 (CondMat03), and
2005 (CondMat05) were obtained from the University of Michigan. [26]
A second sample from 2003 (CondMat03a) was obtained from Stanford
University. [23]
– CA-GrQc is a an academic collaboration network for General Relativity
and Quantum Cosmology from Jan. 1993 - Apr. 2003. [23]
– CA-HepPh is a an academic collaboration network for High Energy Physics
- Phenomenology from Jan. 1993 - Apr. 2003. [23]
– CA-HepTh is a an academic collaboration network for High Energy Physics
- Theory from Jan. 1993 - Apr. 2003. [23]
– CA-NetSci is a an academic collaboration network for Network Science
from May 2006.
– Enron E-Mail is an e-mail network from the Enron corporation made
public by the Federal Energy Regulatory Commission during its investigation. [23]
– URV E-Mail is an e-mail network based on communications of members
of the University Rovira i Virgili (Tarragona). [1] It was extracted in 2003.
– YouTube is a video-sharing website that allows users to establish friendship links. [35] The first sample (YouTube1) was extracted in Dec. 2008.
The second sample (YouTube2) was uploaded to ASU’s Social Computing
Data Repository in Aug. 2010.
4.1.4 Non-Symmetric Networks
– Epinions is a consumer review website that allows members to establish
directed trust relationships. [23]
– WikiVote is a sample of Wikipedia users voting beahavior (who votes for
whom). [23]
– Slashdot formerly had a feature called “Slashdot Zoo” that allowed users
to tag each other as friend or foe. We looked at three samples based on
friendship relationships: one sample from 2008 (Slashdot1) and two from
2009 (Slashdot2-Slashdot3). [23]

4.1.5 Runtime
First, we examined the runtime of the algorithm (see Figure 2 and Table 3).
Our experiments aligned well with our time complexity result (Proposition 3).
For example, a network extracted from the Dutch social-media site Hyves consisting of 1.4 million nodes and 5.5 million directed edges was processed by our
algorithm in at most 12.2 minutes. The often-cited LiveJournal dataset consisting of 2.2 million nodes and 25.6 million directed edges was processed in no
more than 66 minutes - a short time to approximate an NP-hard combinatorial
problem on a large-sized input.

10

Paulo Shakarian et al.

Fig. 2 m ln n vs. runtime in seconds (log scale, m is number of edges, n is number of nodes).
The relationship is linear with R2 = 0.9015, p = 2.2 · 10−16 .

4.1.6 Seed Size
For each network, we performed 10 “integer” trials. In these trials, we set
θ(vi ) = min(din
i , k) where k was kept constant among all vertices for each
trial and set at an integer in the interval [1, 10]. We evaluated the ability of a
network to promote spreading under the tipping model based on the size of the
set of nodes returned by our algorithm (as a percentage of total nodes). For
purposes of discussion, we have grouped our networks into three categories
based on results (Figure 3 and Table 4). We have also included results for
symmetric networks (Figure 4 and Table 5). In general, online social networks
had the smallest seed sets - 13 networks of this type had an average seed set
size less than 2% of the population (these networks were all in Category A).
We also noticed, that for most networks, there was a linear realtion between
threshold value and seed size.
Category A can be thought of as social networks highly susceptible to
influence - as a very small fraction of initially activated individuals can lead
to activation of the entire population. All were extracted from social media

A Scalable Heuristic for Viral Marketing Under the Tipping Model

11

Fig. 3 Threshold value (assigned as an integer in the interval [1, 10]) vs. size of initial seed
set as returned by our algorithm in our three identified categories of networks (categories AC are depicted in panels A-C respectively). Average seed sizes were under 2% for Categorty
A, 2 − 10% for Category B and over 10% for Category C. The relationship, in general, was
linear for categories A and B and lograthimic for C. CA-NetSci had the largest Louvain
Modularity and clustering coefficient of all the networks. This likely explains why that
particular network seems to inhibit spreading.

12

Paulo Shakarian et al.

Fig. 4 Threshold value assigned as both an integer in the range [1, 10] (panel 1) as well as
a fraction of node degree (panel 2) for the non-symmetric networks.

websites. For some of the lower threshold levels, the size of the set of seed
nodes was particularly small. For a threshold of three, 11 of the Category A
networks produced seeds smaller than 0.5% of the total populationa. For a
threshold of four, nine networks met this criteria.
Networks in Category B are susceptible to influence with a relatively small
set of initial nodes - but not to the extent of those in Category A. They had an
average initial seed size greater than 2% but less than 10%. Members in this
group included two general purpose social media networks, two specialty social
media networks, and an e-mail network. Non-symmetric networks generally

A Scalable Heuristic for Viral Marketing Under the Tipping Model

13

perofrmed somewhat poorer than Category B networks (though in general,
not as poorly as those in Category C). The initial seed sizes for the nonsymmmetric networks ranged from 3% to 29%.
Category C consisted of networks that seemed to hamper diffusion in the
tipping model, having an average initial seed size greater than 10%. This
category included all of the academic collaboration networks, two of the email
networks, and two networks derived from friendship links on YouTube.
We also studied the effects on spreading when the threshold values were
assigned as a specific fraction of each node’s in-degree [20, 34], which results in
heterogeneous θi ’s across the network. We performed 12 trials for each network.
Thresholds for each trial were based on the product of in-degree and a fraction
in the interval [0.05, 0.60] (multiples of 0.05). The results (Figure 5 and Table 4;
for non-symmertic networks see Figure 4 and Table 5) were analogous to our
integer tests. We also compared the averages over these trials with M and C
and obtained similar results as with the other trials (Figure 14 B).

4.2 Comparison with Centrality Measures
We compared our results with six popular centrality measures: degree, betweenness, closeness, shell number, eigenvector, and PageRank. Here, we define degree centrality is simply the number of outgoing adjacent nodes. 1 The
intuition behind high betweenness centrality nodes is that they function as
“bottlenecks” as many paths in the network pass through them. Hence, betweenness is a medial centrality measure. Let σst be the number of shortest
paths between nodes s and t and σst (v) be the number of shortest paths between s and t containing node v. In [17], betweenness centrality for node v is
P
(v)
defined as s6=v6=t σst
σst . In most implementations, including the ones used
in this paper, the algorithm of [8] is used to calculate betweenness centrality.
Another common measure from the literature that we examined is closeness
[18]. Given node i, its closeness Cc (i) is the inverse of the average shortest
path length from node i to all other nodes in the graph. Intuitively, closeness
measures how “close” it is to all other nodes in a network. Formally, if we define the shortest path between nodes i to j as function dG (i, j), we can express
the average path length from i to all other nodes as
P
j∈V \i dG (i, j)
Li =
.
(8)
|V | − 1
Hence, the closeness of a node can be formally written as
Cc (i) =

1
|V | − 1
=P
.
Li
j∈V \i dG (i, j)

(9)

1 Note that in the symmetric networks we examined, our empirical results hold for the
number of incoming adjacent edges as well as the total number of adjacent edges.

14

Paulo Shakarian et al.

Fig. 5 Threshold value (assigned as a fraction of node in-degree as a multiple of 0.05 in
the interval [0.05, 0.60]) vs. size of initial seed set as returned by our algorithm in our three
identified categories of networks (categories A-C are depicted in panels A-C respectively,
categories are the same as in Figure 1). Average seed sizes were under 5% for Categorty A,
1 − 7% for Category B and over 3% for Category C. In general, the relationship between
threshold and initial seed size for networks in all categories was exponential.

A Scalable Heuristic for Viral Marketing Under the Tipping Model

15

The idea of shell number is based on a core to which a node lies in. A c-core of
a network is the subgraph in which every node is connected to the rest of the
network by at least c edges. A node is assigned a shell number based on the
maximal core that contains it. This value can be derived exactly using shell
decomposition [31]. The eigenvector centrality [6] of a node is assigned based on
the associated entry in the eigenvector of the adjacency matrix corresponding
to the largest real eigenvalue. The PageRank [28] for each node based on the
PageRank of its neighbors. An initial value for rank is considered for each node
and the relationship is then computed iteratively until convergence is reached.
Intuitively, PageRank can be thought of as the importance of a node based
on the importance of its neighbors. We note that shell number, eigenvector,
and PageRank are often associated with diffusion processes. A more complete
discussion of centrality measures can be found in [33].
We evaluated the performance of centrality measures in finding a seed set
by iteratively selecting the most central nodes with respect to a given measure until the Γθ of that set returns the set of all nodes. Due to the computational overhead of calculating these centrality measures and the repeated
re-evaluation of Γθ , we limited this comparison to only BlogCatalog3, CAHepTh, CA-NetSci, URV E-Mail, and Douban (no betweeness calcualted
for Douban). As with the experiments in the previous section, we studied
threshold settings based on an integer in the interval [1, 10] (see Figure 6) and
as a fraction of incoming neighbors in the interval [0.05, 0.60] (multiples of
0.05, see Figure 8). In general, selecting highly-central nodes is an inefficient
method for finding small seed sets.
In all but the lowest threshold settings, the use of centrality measures for
the integer-threshold trials proved to significantly underperformed when the
method presented in this paper - often returning seed-sets several orders of
magnitude larger and in many cases including the majority of nodes in the
network. Even for the centrality measures outperformed our method in these
trials, the reduction in seed set size was minimal (the greatest reduction in
seed set size experienced in a centrality-measure test over the algorithm of this
paper was 0.09%, while often producing seed sets orders of magnitude greater
than our method). This held even for the centrality measures associated with
diffusion (shell number, eigenvector, and PageRank).
Our tests using fractional-based thresholds tell a slightly different story.
While our method still generally outperformed the centrality measures for the
fractional tests, there were a few cases where the centrality measures fared
better. With BlogCatalog3 all of the centrality measures outperformed our
algorithm in the fraction-based experiments. For that dataset, centrality-based
algorithm consistently outperformed our method finding seed sets with less
members (by 3.13 − 3.29% of the population, on average). With URV-Email,
many trials that utilized a lower threshold setting outperformed our method,
but never finding a feed set with smaller by more than 8% of the total population. However, in the larger threshold settings, our method consistently
found smaller seeds. For a given centrality measure for this dataset, centrality
measures on average provided poorer results than our algorithm ranged - re-

16

Paulo Shakarian et al.

Fig. 6 The use of degree, betweenness and closeness to find seed-sets on select networks
when the threshold is set to an integer in the interval [1, 10]. For these trials, centrality
measure returned significantly larger (several orders of magnitude) larger seed sets than our
approach.

A Scalable Heuristic for Viral Marketing Under the Tipping Model

17

Fig. 7 The use of shell number, Eigenvector, and PageRank to find seed-sets on select
networks when the threshold is set to an integer in the interval [1, 10].

18

Paulo Shakarian et al.

turning seed sets which were, on average 10.22−67.14% (by overall population)
larger than that returned by our algorithm. Perhaps the most interesting result among the centrality measures were the PageRank fraction-based tests on
CA-NetSci, which is associated with the largest seed sets. PageRank found
seed sets that were, on average 14.45% smaller (by population) than our approach. Additionally, though centrality measures outperformed TIP DECOMP
for BlogCatalog3, this does not appear to hold for all social networks as
the seed sets returned using centrality measures for the Douban approaches at
least an order of magnitude increase over our method for nearly every fractional threshold setting for all centrality measures. Hence, we conclude that for
fraction-based thresholds, using centrality measures to find seed sets provides
inconsistent results, and when it fails, it tends to provide a large portion of
the network. A possibility for a practical algorithm that could combine both
methods would be to first run TIP DECOMP, returning some set V 0 . Then,
create set V 00 by selecting the most central nodes until either |V 0 | = |V 00 | or
Γθ (V 00 ) = V (whichever ensures the lower cardinality for V 00 . If |V 0 | = |V 00 |,
return V 0 , otherwise return V 00 . For such an approach, we would likely recommend using degree centrality due to its ease of computation and performance
in our experiments. However, we note that highly-central nodes often may not
be realistic targets for a viral-marketing campaign. For instance, it may be
cost-prohibitive to create a seed set consisting of major celebrities in order to
spread the use of a product. As such is a practical concern, we look at the performance of TIP DECOMP when high-degree nodes are removed in the next
section.

4.3 The Speed of the Activation Process and Sets of “Critical Mass”
An important aspect to consider in viral marketing is the speed of the activation process. We illustrate this speed for several networks under a threshold of
2 as well as a majority threshold (half of each nodes neighbors) in Figure 10.
Interestingly, we found that the size of the initial seed set was not indicative of the speed of spreading. For instance, in BlogCatalog3, a Category A
network (for which our algorithm found a very small seed set) the activation
process proceeded quickly when compared to the others examined. However,
this was also true for CA-NetSci, a Category C network (large seed set).
Conversely, the activation process in the Douban and CA-HepTh networks
(also Category A and C, respectively) proceeded more slowly than the rest.
Another interesting feature we learned in exploring the speed of the activation process was that in all of our experiments there was a single time
step where the number of activated nodes increased significantly more than
the other time periods - sometimes by several orders of magnitude (see Figure 11). We can think of such a set of activated nodes as when the population
reaches a “critical mass” which results in mass adoption in the next interval.
In many cases, such a critical mass is reached early - normally in the first few
time-steps.

A Scalable Heuristic for Viral Marketing Under the Tipping Model

19

100

Seed Size (Percentage of Nodes)

90
80
70
60

BlogCatalog3

Degree

50
40

Douban
CA-HepTh
CA-NetSci

30

URV E-Mail

20
10
0
0.05

0.15

0.25

0.35

0.45

0.55

Threshold Value

100

Seed Size (Percentage of Nodes)

90
80
70
60

Betweenness

50
40

BlogCatalog3
CA-HepTh
CA-NetSci

30

URV E-Mail

20
10
0
0.05

0.15

0.25

0.35

0.45

0.55

Threshold Value

100

Seed Size (Percentage of Nodes)

90
80
70
60

BlogCatalog3

50

Douban

40

CA-HepTh

Closeness

30
20

CA-NetSci
URV E-Mail

10
0
0.05

0.15

0.25

0.35

0.45

0.55

Threshold Value

Fig. 8 The use of degree, betweenness and closeness to find seed-sets on select networks
when the threshold is set to an fraction in the interval [0.05, 0.60] (multiples of 0.05).

20

Paulo Shakarian et al.

Fig. 9 The use of shell number, Eigenvector, and PageRank to find seed-sets on select
networks when the threshold is set to an fraction in the interval [0.05, 0.60] (multiples of
0.05).

A Scalable Heuristic for Viral Marketing Under the Tipping Model

21

100

1

Percent of Population Activated

90
80
70
60

BlogCatalog3

50

Douban

40

CA-HepTh
CA-NetSci

30

URV E-Mail

20
10
0
0

2

4

6

8

10

12

Time Period

100

80
Percent of Population Activated

BlogCatalog3

2

90

Douban

CA-HepTh
CA-NetSci

70

URV E-Mail

60
50

100

40
80
30
60

20

40

10

20

0

0

5

10
Time Period

15

20

0
0

25
100

30
200

Fig. 10 An examination of several of speed of activation initiated from the seed set using
a threshold of two (panel 1) and a majority threshold (panel 2).

Finding a subset of the population of “critical mass” may be an important
problem in its own right. Though the critical mass point will often be larger
than the seed set found by an algorithm in this paper, we can be assured
that in one time step of the model, the number of individuals reached (with
a certain number of signals from their neighbors) is substantially larger than
the investment. In practice, this could lead to quicker spreading of information
in an advertising campaign, for example. Further, our experiments indicate
that order-of-magnitude critical mass sets exist in several networks. We are
currently conducting further research on this topic.

22

Paulo Shakarian et al.

Fig. 11 Greatest Percent increase experienced in a single time step (the effect of reaching
“critical mass”) for integer-based and percentage-based thresholds (panel 1 and 2 respectively).

4.4 Effect of Removing High-Degree Nodes
In the last section we noted that high-degree nodes may not always be targetable in a viral marketing campaign (i.e. it may be cost prohibitive to include
them in a seed set). In this section, we explore the affect of removing highdegree nodes on the size of the seed-set returned by TIP DECOMP. This type
of node removal has also recently been studied in a different context in [5]. In
these trials, we studied all 31 networks and looked at two specific threshold

A Scalable Heuristic for Viral Marketing Under the Tipping Model

23

settings: an integer threshold of 2 (Figure 12) and a fractional threshold of 0.5
(Figure 13). We then studied the effect of removing up to 50% of the nodes in
order from greatest to least degree.
With an integer threshold of 2, networks in category A still retained a seedsize (as returned by TIP DECOMP) two orders of magnitude smaller than the
population size up to the removal of 10% of the top degree nodes, and for
many networks this was maintained to 50%. Networks in category B retained
seed sets an order of magnitude smaller than the population for up to 50% of
the nodes removed. For most networks in category C, the seed size remained
about a quarter of the population size up to 15% of the top degree nodes being
removed.
With a fractional threshold of 0.5, we noted that many networks in category
A actually had larger seed sets (as returned by TIP DECOMP) when more high
degree nodes are removed. Further, networks in categories A-B retained seed
sets of at least an order of magnitude smaller than the population in these
tests while most networks in category C retained sizes of about a quarter of
the population.
4.4.1 Seed Size as a Function of Community Structure
In this section, we view the results of our heuristic algorithm as a measurement
of how well a given network promotes spreading. Here, we use this measurement to gain insight into which structural aspects make a network more likely
to be “tipped.” We compared our results with two network-wide measures
characterizing community structure. First, clustering coefficient (C) is defined
for a node as the fraction of neighbor pairs that share an edge - making a
triangle. For the undirected case, we define this concept formally below.
Definition 7 (Clustering Coefficient) Let r be the number of edges between nodes with which vi has an edge and di be the degree of vi . The clus2r
.
tering coefficient, Ci =
di (di − 1)
Intuitively, a node with high Ci tends to have more pairs of friends that are
also mutual friends. We use the average clustering coefficient as a network-wide
measure of this local property.
Second, we consider modularity (M ) defined by Newman and Girvan. [27].
For a partition of a network, M is a real number in [−1, 1] that measures the
density of edges within partitions compared to the density of edges between
partitions. We present a formal definition for an undirected network below.
Definition 8 (Modularity [27]) Given partition C = {c1 , . . . , cq }, modularity,
1 XX
M=
wij − Pij
2m
i,j∈c
c∈C

where m is the number of undirected edges; wij = 1 if there is an edge between
ki kj
nodes i and j and wij = 0 otherwise; Pij = 2m

24

Paulo Shakarian et al.

Fig. 12 Size of the seed set returned by TIP DECOMP (as a fraction of the popualtion)
as a function of the percent of the highest degree nodes removed from the network with an
integer theshold of 2 for networks in categories A-C.

A Scalable Heuristic for Viral Marketing Under the Tipping Model

Seed Size (Percentage of Nodes)

12

25

A

10

BlogCatalog1
BlogCatalog2
BlogCatalog3
Buzznet

8

Douban

6

Flickr
Flixster

4

FourSquare
Friendster

2

Last.Fm
LiveJournal

0

Livemocha

0

10

20

30

40

50

WikiTalk

Percent of Nodes Removed

8

B

Seed Size (Percentage of Nodes)

7
6
5

Delicious

4

Digg
EU E-mail

3

Hyves
Yelp

2
1
0
0

10

20

30

40

50

Percent of Nodes Removed

35

Seed Size (Percentage of Nodes)

CA-AstroPh
CA-CondMat03

30

CA-CondMat03a

25

CA-CondMat05
CA-CondMat99

20

CA-GrQC
CA-HepPh

15

CA-HepTh
CA-NetSci

10

Enron E-Mail

C

5
0
0

10

20

30

40

URV E-Mail
YouTube1

50

YouTube2

Percent of Nodes Removed

Fig. 13 Size of the seed set returned by TIP DECOMP (as a fraction of the popualtion)
as a function of the percent of the highest degree nodes removed from the network with an
fractional theshold of 0.5 for networks in categories A-C.

26

Paulo Shakarian et al.

The modularity of an optimal network partition can be used to measure
the quality of its community structure. Though modularity-maximization is
NP-hard, the approximation algorithm of Blondel et al. [4] (a.k.a. the “Louvain
algorithm”) has been shown to produce near-optimal partitions.2 We call the
modularity associated with this algorithm the “Louvain modularity.” Unlike
the C, which describes local properties, M is descriptive of the community
level. For the 31 networks we considered, M and C appear uncorrelated (R2 =
0.0538, p = 0.2092).
We plotted the initial seed set size (S) (from our algorithm - averaged
over the 10 threshold settings) as a function of M and C (Figure 14a) and
uncovered a correlation (planar fit, R2 = 0.8666, p = 5.666·10−13 , see Figure 14
A). The majority of networks in Category C (less susceptible to spreading)
were characterized by relatively large M and C (Category C includes the top
nine networks w.r.t. C and top five w.r.t. M ). Hence, networks with dense,
segregated, and close-knit communities (large M and C) suppress spreading.
Likewise, those with low M and C tended to promote spreading. Also, we note
that there were networks that promoted spreading with dense and segregated
communities, yet were less clustered (i.e. Category A networks Friendster and
LiveJournal both have M ≥ 0.65 and C ≤ 0.13). Further, some networks
with a moderately large clustering coefficient were also in Category A (two
networks extracted from BlogCatalog had C ≥ 0.46) but had a relatively less
dense community structure (for those two networks M ≤ 0.33).

5 Related Work
Tipping models first became popular by the works of [19] and [30] where
it was presented primarily in a social context. Since then, several variants
have been introduced in the literature including the non-deterministic version
of [21] (described later in this section) and a generalized version of [20]. In
this paper we focused on the deterministic version. In [34], the authors look
at deterministic tipping where each node is activated upon a percentage of
neighbors being activated. Dryer and Roberts [15] introduce the MIN-SEED
problem, study its complexity, and describe several of its properties w.r.t.
certain special cases of graphs/networks. The hardness of approximation for
this problem is described in [12]. The work of [3] presents an algorithm for
target-set selection whose complexity is determined by the tree-width of the
graph - though it provides no experiments or evidence that the algorithm can
scale for large datasets. The recent work of [29] proves a non-trivial upper
bound on the smallest seed set.
Our algorithm is based on the idea of shell-decomposition that currently is
prevalent in physics literature. In this process, which was introduced in [31],
vertices (and their adjacent edges) are iteratively pruned from the network
until a network “core” is produced. In the most common case, for some value
2 Louvain modularity was computed using the implementation available from CRANS at
http://perso.crans.org/aynaud/communities/.

A Scalable Heuristic for Viral Marketing Under the Tipping Model

27

Fig. 14 (A) Louvain modularity (M ) and average clustering coefficient (C) vs. the average
seed size (S). The planar fit depicted is S = 43.374·M +33.794·C −24.940 with R2 = 0.8666,
p = 5.666 · 10−13 . (B) Same plot at (A) except the averages are over the 12 percentagebased threshold values. The planar fit depicted is S = 18.105 · M + 17.257 · C − 10.388 with
R2 = 0.816, p = 5.117 · 10−11 .

28

Paulo Shakarian et al.

k, nodes whose degree is less than k are pruned (in order of degree) until no
more nodes can be removed. This process was used to model the Internet in [9]
and find key spreaders under the SIR epidemic model in [22]. More recently, a
“heterogeneous” version of decomposition was introduced in [2] - in which each
node is pruned according to a certain parameter - and the process is studied
in that work based on a probability distribution of nodes with certain values
for this parameter.

5.1 Notes on Non-Deterministic Tipping
We also note that an alternate version of the model where the thresholds are
assigned randomly has inspired approximation schemes for the corresponding
version of the seed set problem.[21, 24, 13] Work in this area focused on finding
a seed set of a certain size that maximizes the expected number of adopters.
The main finding by Kempe et al., the classic work for this model, was to
prove that the expected number of adopters was submodular - which allowed
for a greedy approximation scheme. In this algorithm, at each iteration, the
node which allows for the greatest increase in the expected number of adopters
is selected. The approximation guarantee obtained (less than 0.63 of optimal)
is contingent upon an approximation guarantee for determining the expected
number of adopters - which was later proved to be #P -hard. [13] Recently,
some progress has been made toward finding a guarantee [7]. Further, the
simulation operation is often expensive - causing the overall time complexity
to be O(x · n2 ) where x is the number of runs per simulation and n is the
number of nodes (typically, x > n). In order to avoid simulation, various
heuristics have been proposed, but these typically rely on the computation
of geodesics - an O(n3 ) operation - which is also more expensive than our
approach.
Additionally, the approximation argument for the non-deterministic case
does not directly apply to the original (deterministic) model presented in
this paper. A simple counter-example shows that sub-modularity does not
hold here. Sub-modularity (diminishing returns) is the property leveraged by
Kempe et al. in their approximation result.

5.2 Note on an Upper Bound of the Initial Seed Set
Very recently, we were made aware of research by Daniel Reichman that proves
an upper bound on the minimal size of a seed set for the special case of
undirected networks with homogeneous threshold values. [29] The proof is
constructive and yields an algorithm that mirrors our approach (although
Reicshman’s algorithm applies only to that special case). We note that our
work and the work of Reichman were developed independently. We also note
that Reichman performs no experimental evaluation of the algorithm.

A Scalable Heuristic for Viral Marketing Under the Tipping Model

29

Given undirected network G where each node vi has degree di and the
threshold value for all nodes is k, P
Reichman proves that the size of the minimal seed set can be bounded by i min{1, dik+1 }. For our integer tests, we
compared our results to Reichman’s bound. Our seed sets were considerably
smaller - often by an order of magnitude or more. See Figure 15 for details.

6 Conclusion
As recent empirical work on tipping indicates that it can occur in real social
networks,[11, 36] our results are encouraging for viral marketers. Even if we
assume relatively large threshold values, small initial seed sizes can often be
found using our fast algorithm - even for large datasets. For example, with the
FourSquare online social network, under majority threshold (50% of incoming neighbors previously adopted), a viral marketeer could expect a 297-fold
return on investment. As results of this type seem to hold for many online
social networks, our algorithm seems to hold promise for those wishing to “go
viral.” An important open question to address in future work is if a similar
decomposition-based approach is viable for finding seed sets under other diffusion models, such as the independent cascade model [21] and evolutionary
graph theory [25] as well as probabilistic variants of the tipping model and
diffusion processes on multi-modal networks [32]. Exploring other models can
lead to the development of decomposition algorithms in domains where social
behavior is more dynamic such as cell-phone networks [16, 10].
Acknowledgements We would like to thank Gaylen Wong (USMA) for his technical support. Additionally, we would like to thank (in no particular order) Albert-László Barabási
(NEU), Sameet Sreenivasan (RPI), Boleslaw Szymanski (RPI), Patrick Roos (UMD), John
James (USMA), and Chris Arney (USMA) for their discussions relating to this work. Finally, we would also like to thank Megan Kearl, Javier Ivan Parra, and Reza Zafarani of
ASU for their help with some of the datasets. The authors are supported under by the
Army Research Office (project 2GDATXR042) and the Office of the Secretary of Defense
(project F1AF262025G001). The opinions in this paper are those of the authors and do not
necessarily reflect the opinions of the funders, the U.S. Military Academy, or the U.S. Army.

References
1. Arenas, A.: Network data sets (2012). URL http://deim.urv.cat/~aarenas/data/
welcome.htm
2. Baxter, G.J., Dorogovtsev, S.N., Goltsev, A.V., Mendes, J.F.F.: Heterogeneous k-core
versus bootstrap percolation on complex networks. Phys. Rev. E 83 (2011)
3. Ben-Zwi, O., Hermelin, D., Lokshtanov, D., Newman, I.: Treewidth governs the complexity of target set selection. Discrete Optimization 8(1), 87–96 (2011)
4. Blondel, V., Guillaume, J., Lambiotte, R., Lefebvre, E.: Fast unfolding of communities
in large networks. Journal of Statistical Mechanics: Theory and Experiment 2008,
P10,008 (2008)
5. Boldi, P., Rosa, M., Vigna, S.: Robustness of social and web graphs to node removal.
Social Network Analysis and Mining pp. 1–14 (2013). DOI 10.1007/s13278-013-0096-x.
URL http://dx.doi.org/10.1007/s13278-013-0096-x

30

Paulo Shakarian et al.

Fig. 15 Integer threshold values vs. the seed size divided by Reichman’s upper bound [29]
the three categories of networks (categories A-C are depicted in panels A-C respectively).
Note that in nearly every trial, our algorithm produced an initial seed set significantly
smaller than the bound - in many cases by an order of magnitude or more.

A Scalable Heuristic for Viral Marketing Under the Tipping Model

31

6. Bonacich, P.: Factoring and weighting approaches to status scores and clique identification. The Journal of Mathematical Sociology 2(1), 113–120 (1972). DOI
10.1080/0022250X.1972.9989806
7. Borgs, C., Brautbar, M., Chayes, J., Lucier, B.: Influence maximization in social networks: Towards an optimal algorithmic solution (2012)
8. Brandes, U.: A faster algorithm for betweenness centrality. Journal of Mathematical
Sociology 25(163) (2001)
9. Carmi, S., Havlin, S., Kirkpatrick, S., Shavitt, Y., Shir, E.: From the Cover: A model of
Internet topology using k-shell decomposition. PNAS 104(27), 11,150–11,154 (2007).
DOI 10.1073/pnas.0701175104
10. Catanese, S., Ferrara, E., Fiumara, G.: Forensic analysis of phone call networks. Social
Network Analysis and Mining 3(1), 15–33 (2013). DOI 10.1007/s13278-012-0060-1.
URL http://dx.doi.org/10.1007/s13278-012-0060-1
11. Centola, D.: The Spread of Behavior in an Online Social Network Experiment. Science
329(5996), 1194–1197 (2010). DOI 10.1126/science.1185231
12. Chen, N.: On the approximability of influence in social networks. SIAM J. Discret.
Math. 23, 1400–1415 (2009)
13. Chen, W., Wang, C., Wang, Y.: Scalable influence maximization for prevalent viral
marketing in large-scale social networks. In: Proceedings of the 16th ACM SIGKDD
international conference on Knowledge discovery and data mining, KDD ’10, pp. 1029–
1038. ACM, New York, NY, USA (2010)
14. Cormen, T.H., Leiserson, C.E., Rivest, R.L., Stein, C.: Introduction to Algorithms, second edn. MIT Press (2001). URL http://mitpress.mit.edu/catalog/item/default.
asp?tid=8570&#38;ttype=2
15. Dreyer, P., Roberts, F.: Irreversible -threshold processes: Graph-theoretical threshold
models of the spread of disease and of opinion. Discrete Applied Mathematics 157(7),
1615 – 1627 (2009). DOI 10.1016/j.dam.2008.09.012
16. Dyagilev, K., Mannor, S., Yom-Tov, E.: On information propagation in mobile call
networks. Social Network Analysis and Mining pp. 1–21 (2013). DOI 10.1007/
s13278-013-0100-5. URL http://dx.doi.org/10.1007/s13278-013-0100-5
17. Freeman, L.C.: A set of measures of centrality based on betweenness. Sociometry 40(1),
pp. 35–41 (1977). URL http://www.jstor.org/stable/3033543
18. Freeman, L.C.: Centrality in social networks conceptual clarification. Social Networks 1(3), 215 – 239 (1979). DOI 10.1016/0378-8733(78)90021-7. URL http:
//www.sciencedirect.com/science/article/pii/0378873378900217
19. Granovetter, M.: Threshold models of collective behavior. The American Journal of
Sociology (6), 1420–1443. DOI 10.2307/2778111
20. Jackson, M., Yariv, L.: Diffusion on social networks. In: Economie Publique, vol. 16,
pp. 69–82 (2005)
21. Kempe, D., Kleinberg, J., Tardos, E.: Maximizing the spread of influence through a
social network. In: KDD ’03: Proceedings of the ninth ACM SIGKDD international
conference on Knowledge discovery and data mining, pp. 137–146. ACM, New York,
NY, USA (2003). DOI http://doi.acm.org/10.1145/956750.956769
22. Kitsak, M., Gallos, L.K., Havlin, S., Liljeros, F., Muchnik, L., Stanley, H.E., Makse,
H.A.: Identification of influential spreaders in complex networks. Nat Phys (11), 888–
893. DOI 10.1038/nphys1746
23. Leskovec, J.: Stanford network analysis project (snap) (2012). URL http://snap.
stanford.edu/index.html
24. Leskovec, J., Krause, A., Guestrin, C., Faloutsos, C., VanBriesen, J., Glance, N.: Costeffective outbreak detection in networks. In: KDD ’07: Proceedings of the 13th ACM
SIGKDD international conference on Knowledge discovery and data mining, pp. 420–
429. ACM, New York, NY, USA (2007). DOI http://doi.acm.org/10.1145/1281192.
1281239
25. Lieberman, E., Hauert, C., Nowak, M.A.: Evolutionary dynamics on graphs. Nature
433(7023), 312–316 (2005). DOI 10.1038/nature03204. URL http://dx.doi.org/10.
1038/nature03204
26. Newman, M.: Network data (2011). URL http://www-personal.umich.edu/~mejn/
netdata/

32

Paulo Shakarian et al.

27. Newman, M.E.J., Girvan, M.: Finding and evaluating community structure in networks.
Phys. Rev. E 69(2), 026,113 (2004). DOI 10.1103/PhysRevE.69.026113
28. Page, L., Brin, S., Motwani, R., Winograd, T.: The pagerank citation ranking: Bringing
order to the web. In: Proceedings of the 7th International World Wide Web Conference,
pp. 161–172 (1998)
29. Reichman, D.: New bounds for contagious sets. Discrete Mathematics (in press) (0), –
(2012). DOI 10.1016/j.disc.2012.01.016
30. Schelling, T.C.: Micromotives and Macrobehavior. W.W. Norton and Co. (1978)
31. Seidman, S.B.: Network structure and minimum degree. Social Networks 5(3), 269 –
287 (1983). DOI 10.1016/0378-8733(83)90028-X
32. Shakarian, P., Subrahmanian, V., Sapino, M.L.: Using generalized annotated programs
to solve social network optimization problems. In: M. Hermenegildo, T. Schaub (eds.)
Technical Communications of the 26th International Conference on Logic Programming, Leibniz International Proceedings in Informatics (LIPIcs), vol. 7, pp. 182–
191. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik, Dagstuhl, Germany (2010).
DOI http://dx.doi.org/10.4230/LIPIcs.ICLP.2010.182. URL http://drops.dagstuhl.
de/opus/volltexte/2010/2596
33. Wasserman, S., Faust, K.: Social Network Analysis: Methods and Applications, 1 edn.
No. 8 in Structural analysis in the social sciences. Cambridge University Press (1994)
34. Watts, D.J., Dodds, P.S.: Influentials, networks, and public opinion formation. Journal
of Consumer Research 34(4), 441–458 (2007). URL http://www.journals.uchicago.
edu/doi/abs/10.1086/518527
35. Zafarani, R., Liu, H.: Social computing data repository at ASU (2009). URL http:
//socialcomputing.asu.edu
36. Zhang, L., Marbach, P.: Two is a crowd: Optimal trend adoption in social networks.
In: Proceedings of International Conference on Game Theory for Networks (GameNets)
(2011)

A Scalable Heuristic for Viral Marketing Under the Tipping Model

Table 1 Information on the networks in Categories A, B, and C.

33

34

Paulo Shakarian et al.

Table 2 Information on non-symmetric networks.

6.71 SNAP
14.57 SNAP
5.62 SNAP
5.64 SNAP
5.66 SNAP

Type

508837
103689
396378
422349
425072

Source

75879
7115
70491
74899
75144

Avg. Degree

# Edges

Epinions
Wiki-Vote
Slashdot1
Slashdot2
Slashdot3

# Nodes

Name

NON-SYMMERTRIC

SocMedia
SocMedia
SocMedia
SocMedia
SocMedia

A Scalable Heuristic for Viral Marketing Under the Tipping Model

0.03
0.04
0.03
0.06
0.02
0.00
0.02
0.01
0.00
0.05
0.00
0.02
9.73

Table 3 Runtime data on the datasets used in the experiments.

Avg. Runtime (Min.)

CA-AstroPh
CA-CondMat03
CA-CondMat03a
CA-CondMat05
CA-CondMat99
CA-GrQc
CA-HepPh
CA-HepTh
CA-NetSci
Enron E-Mail
URV E-Mail
YouTube1
YouTube2

Name

Delicious 2.33
Digg
9.32
EU E-Mail 0.51
Hyves
11.66
Yelp
2.85

NON-SYM

Avg. Runtime (Min.)

Avg. Runtime (Min.)

CAT C

Name

BlogCatalog1
0.44
BlogCatalog2
0.39
BlogCatalog3
0.03
Buzznet
0.64
Douban
0.24
Flickr
1.22
Flixster
49.61
FourSquare
4.48
Frienster
212.78
Last.Fm
12.53
LiveJournal
64.17
Livemocha
0.58
WikiTalk
33.47

Name

CAT B

Avg. Runtime (Min.)

Name

CAT A

35

Epinions
Wiki-Vote
Slashdot1
Slashdot2
Slashdot3

0.05
0.01
0.04
0.05
0.05

36

Paulo Shakarian et al.

Table 4 Regression analysis and network-wide measures for the networks in Categories A,
B, and C.

A Scalable Heuristic for Viral Marketing Under the Tipping Model

37

Table 5 Regression analysis and network-wide measures for the non-symmetric networks.

Proceedings of the Twenty-Third Innovative Applications of Artificial Intelligence Conference

Abductive Inference for Combat:
Using SCARE-S2 to Find High-Value Targets in Afghanistan
Paulo Shakarian

Margo K. Nagel, Brittany E. Schuetzle, V. S. Subrahmanian

U.S. Army
paulo.shakarian@us.army.mil

Dept. of Computer Science
University of Maryland, College Park, MD
mnagel@umd.edu, bschuetz@umiacs.umd.edu, vs@cs.umd.edu

cells (based on attack data), as well as these constraints (obtained from socio-cultural and terrain data), we wish to abductively infer where the HVTs can be found. This is clearly
an instance of a geospatial abduction problem originally introduced by the authors in (Shakarian, Subrahmanian, and
Sapino 2010) and later extended in (Shakarian and Subrahmanian 2010). We previously applied geospatial abduction
to ﬁnd small weapons hide-sites related to local attacks in
Baghdad in (Shakarian, Subrahmanian, and Sapino 2009).
However, the environment of Afghanistan provides several
challenges that we did not address in the other work. These
include the following:
1. In Afghanistan, the inﬂuence of multiple tribes affect relationships between areas on the ground. How do we account for this inﬂuence?
2. In the two provinces we considered in Afghanistan, the
terrain is extremely varied, unlike the more uniform urban
terrain of Baghdad. How do we account for this variance
in terrain?
3. Unlike our application to Baghdad (25 × 27 km area),
where we could easily discretize the space, our data-set
for Afghanistan includes two provinces covering a total
area 580 × 430 km, making discretizing of the space impractical. How do we best represent the space?
We note that using only attack data and socio-cultural information alone will most likely be insufﬁcient to pinpoint a
HVT. However, the real-world requirements imposed on the
insurgents by logistic and socio-cultural variables should allow a ground commander to signiﬁcantly reduce the searchspace for such targets. Intelligence professionals identify
“Named Areas of Interest” or NAIs - regions on the ground
where they think HVTs can be located. Then, other intelligence assets, such as unmanned aerial vehicles (UAVs) or
tactical human-intelligence (HUMINT) teams can be used
in the NAIs to pinpoint targets. (US Army 1994) In a large
area, such as a province of Afghanistan, UAVs or HUMINT
cannot be used effectively without ﬁrst determining good
NAIs. To address this problem ﬁr the speciﬁc case of
Afghanistan, we adapted the region-based abduction framework of (Shakarian and Subrahmanian 2010) to our scenario
by creating an entirely new piece of software for abductive inference called the SCARE-S2 (Spatio-Cultural Abductive Reasoning Engine System 2). SCARE-S2 abduc-

Abstract
Recently, geospatial abduction was introduced by the
authors in (Shakarian, Subrahmanian, and Sapino 2010)
as a way to infer unobserved geographic phenomena
from a set of known observations and constraints between the two. In this paper, we introduce the SCARES2 software tool which applies geospatial abduction
to the environment of Afghanistan. Unlike previous
work, where we looked for small weapon caches supporting local attacks, here we look for insurgent highvalue targets (HVT’s), supporting insurgent operations
in two provinces. These HVT’s include the locations
of insurgent leaders and major supply depots. Applying this method of inference to Afghanistan introduces
several practical issues not addressed in previous work.
Namely, we are conducting inference in a much larger
area (24, 940 sq km as compared to 675 sq km in previous work), on more varied terrain, and must consider
the inﬂuence of many local tribes. We address all of
these problems and evaluate our software on 6 months
of real-world counter-insurgency data. We show that we
are able to abduce regions of a relatively small area (on
average, under 100 sq km and each containing, on average, 4.8 villages) that are more dense with HVT’s (35×
more than the overall area considered).

Introduction
Insurgents operating in Afghanistan require a substantial
command-and-control (C2) and logistics support to conduct
successful attacks.1 Military analysts refer to elements that
provide C2 and logistics support for large number of insurgent cells as “high-value targets” (“HVTs”) as the elimination of these HVTs can have a signiﬁcant impact on insurgent operations. As a result, NATO and Afghan forces often
concentrate on ﬁnding these HVTs in an attempt to reduce
the level of violence in the country. The insurgents have a
limited number of these HVTs that are required to support
the activities of lower-level insurgent cells. Additionally,
terrain and cultural considerations place constraints on the
relationships between an HVT and the lower level insurgent
cell it supports. Knowing the locations of the lower-level
c 2011, Association for the Advancement of Artiﬁcial
Copyright 
Intelligence (www.aaai.org). All rights reserved.
1
Note that throughout this paper, ’attack’ refers to an attack
conducted by the insurgents against coalition forces.

1689

tively ﬁnds regions that can then later be used to cue other
intelligence assets to ﬁnd an HVT. Applying SCARE-S2
to our Afghanistan dataset produced regions with a significantly higher density of HVTs (by a factor of 35), where
half of the abduced ground regions (normally of an area
less than 100km2 ) would contain at least one HVT. Further,
each region produced by SCARE-S2 contained, on average,
4.8 villages - hence searching them is not resource-intensive
for many surveillance platforms. Due to the high density of
HVTs within the regions, we feel that they could be used for
NAIs and aide in combat operations.
This paper is organized as follows. First, we brieﬂy review the region-based abduction framework of (Shakarian
and Subrahmanian 2010) and present some extensions we
used to address our Afghanistan-speciﬁc problem. Then we
describe our dataset for Afghanistan. This is followed by
a description of our implementation along with our experimental results and discussion.

Region Explanation Problem (REP)
INPUT: Given a space S, distance interval [α, β], set O
of observations, set R of regions, and natural number
k ∈ [1, |O|].
OUTPUT: Set R ⊆ R, where |R | ≤ k and for each o ∈ O,
there is an r ∈ R s.t. r sub-(super-) explains o.
(Shakarian and Subrahmanian 2010), showed this decision problem to be strongly NP-complete, meaning that
the optimization version (that seeks to ﬁnd an explanation
of minimal cardinality) cannot be approximated by a fully
polynomial-time approximation algorithm unless P==NP.
However, the problem also reduces to an instance of setcover, which means that a solution can be obtained within
a reasonable approximation factor (1 − lg(f ), where f is
the maximum number of regions associated with any given
observation). We have included the algorithm, GREEDYREP-MC2 from that paper.4

Region-Based Geospatial Abduction

GREEDY-REP-MC2
INPUT: Set O of observations, set R of regions
OUTPUT: R ⊆ R


In this section, we brieﬂy review the framework of (Shakarian and Subrahmanian 2010) - which is not new material.
This is followed by our practical, Afghan-speciﬁc extensions
in the next section (which is new in this paper).
We assume the existence of a real-valued M × N space
S whose elements are pairs of real numbers from the set
[0, M ]×[0, N ]. An observation is any member of S. We use
O to denote an arbitrary, but ﬁxed, ﬁnite set of observations.
We assume there are real numbers α ≤ β such that for each
observation o , there exists a partner po (to be found) whose
distance from o is in the interval [α, β].2 Without loss of
generality, we also assume that all elements of O are over β
distance away from the edge of S.
Throughout this paper, we assume the existence of a
distance function d on S satisfying the usual properties of
such distance functions.3 We now deﬁne a region and how
they relate to the set of observations. Our intuition is simple
- a region explains an observation if that region contains a
partner point for that observation.

1. Let O =

r∈R

{Or }

2. For each observation o ∈ O, let GRPo = {Or ∈ O|o ∈ Or }
3. 
For each observation o ∈ O, let RELo = {o ∈ O|o ∈
Or } and let keyo = |RELo |
Or ∈GRPo
4. Let O = O, set R = ∅
5. While not O ≡ ∅ loop
(a) Let o be the element of O where keyo is minimal.
(b) Let the element Or be the member of GRPo s.t. |Or ∩ O |
is maximized.
(c) If there are more than one set Or that meet the criteria of
line 5b, pick the set w. the greatest cardinality.
(d) R = R ∪ r
(e) For each o ∈ Or ∩ O , do the following:
i. O = O − o
ii. For each o ∈ O ∩ RELo , keyo − −
6. Return R

Region/Region Explanation
• A region r is a subset of S such that for any two points
(x, y), (x , y  ) ∈ r, there is sequence a of line segments
from (x, y) to (x , y  ) s.t. no line segment lies outside r.

Adaptations for Afghanistan. There are two parts of the
formalism of region-based abduction that are generally deﬁned – the distance function (d) and the set of regions (R).
In the experiments of (Shakarian and Subrahmanian 2010),
we used a Euclidean distance function and we generated the
regions from the REGION-GEN algorithm of that paper,
which discretizes the entire space (hence, making it impractical for use here). Hence, we use d and R as a way to adapt
region-based abduction to our Afghanistan scenario and address each of the three concerns outlined in the introduction.
Our strategy is to build a special distance function, dafgh ,
and use this function and the set of observations, O, to generate R.

• A region r explains point o in S iff there exists a point
p ∈ r such that d(o, p) ∈ [α, β].
Note that regions can have any shape and may overlap.
Throughout this paper, we assume that checking if some
point o is explained by region r can be performed in
constant (i.e. O(1)) time. This is a reasonable assumption
for most regular shaped regions like circles, ellipses and
polygons.
2
(Shakarian, Subrahmanian, and Sapino 2010) describes methods to learn α, β automatically from historical data.
3
d(x, x) = 0; d(x, y) = d(y, x); d(x, y) + d(y, z) ≥ d(x, z).

4

Due to lack of space, we have omitted an example illustrating
how this algorithm works. We refer the reader to (Shakarian and
Subrahmanian 2010) for such examples.

1690

REGION-GEN-AFGH
INPUT: Space S, observations O, reals α, β
OUTPUT: Set of regions R

To address the ﬁrst concern, that of multiple tribes, assume we have a set of tribes, T = {t1 , . . . , tm }. Based on
our data set, we can assume we have the following function
tribes : S → 2T which takes a point in the space and returns
a set of tribes. Two points in the space, p1 , p2 , are triballyrelated iff tribes(p1 ) ∩ tribes(p2 ) ≡ ∅. When we create our
distance function, we will do so in a way to enforce this as
an additional criterion that there must be at least one tribe
that has a presence in the observation and partner location.
The idea here is that an HVT must have a tribal-relationship
with the lower-level cell conducting the attack, otherwise the
two groups may not have a conﬂuence of interest.
To address the second and third concerns, we appeal to
the idea that the road networks of Afghanistan binds parts of
this varied country together. Such sentiments are echoed in
other work such as (Conover 2010). So, for any two villages
on the road network (RN , an undirected graph where the
vertices are villages) of Afghanistan, we deﬁne the function
sp RN : S × S → 
 to return the shortest distance on the
Afghan road network between the two points. Using shortest
path on a road network is also useful as our attack and HVT
data were all geolocated by village. Hence, we put these
concepts together to create our new distance function, dafgh ,
deﬁned below.



dafgh (p, p ) =

sp RN (p, p )
∞

1. Let the road-network, RN = (V, E)
2. For each o ∈ O, ﬁnd the set Vo = {v ∈ V |dafgh (o, v) ∈ [α, β]



3. Let L = o∈O Vo . For each p ∈ L let Op be the set of observations that can be associated with it.
4. Partition L into subsets, denoted LO , where O ⊆ O and p ∈
LO iff Op ≡ O .
5. For each LO , create region r that is the minimum-enclosing
rectangle of all elements in LO . Add r to R.
6. Return set R.

Attack Data. We used a series of 203 attack events in
Afghanistan from the (National Counter-Terrorism Center
(NCTC) ). 103 of these events were from January-April
2010 and used to learn the [α, β] distance constraints, while
the remaining 100 attacks (May-June 2010) were used as
set O of observations. We actually divided the set of observations into 12 subsets, O1 ⊆ O2 ⊆ . . . ⊆ O12 , with each
subsequent set of observations containing 5 days more worth
of attacks than the previous (i.e. O1 was May 2-6 and O2
was May 2-11). All attacks in the WITS database were identiﬁed by village – corresponding with the AIMS information
described earlier.
HVT Data. We collected a total of 78 HVTs based on ofﬁcial reports from (International Security Assistance Force
(ISAF) Afghanistan ). These reports spanned JanuarySeptember 2010. We used the reports of January-April 2010
(27 HVTs) to learn the [α, β] distance constraints and the remainder for a ground-truth comparison (notice, this time interval is greater than that used for the set of observations, as
an associated HVT with an attack may not necessarily have
been located in the same time window described earlier).
As with the attack data, each HVT was geo-located by the
ISAF report with a village, which corresponded to the AIMS
information. We manually identiﬁed only certain weapons
caches and captured/killed enemy personnel as HVTs. Below we present our criteria in Figure 1 - it is based on the
combat experience of one of the authors.
Tribal Data. To create the tribes function, we used the
tribal data from (Naval Postgraduate School (NPS) ) that associated districts in Afghanistan with a set of tribes. All
together, there were 23 tribes reported by the NPS.
Distance Constraints. Using the simple algorithm FINDBOUNDS of (Shakarian, Subrahmanian, and Sapino 2010),
which essentially returns an upper and lower distance bound
on the shortest distance to an HVT given a set of attacks, determined the [α, β] bounds to be [0.0, 65.88] km based on the
historical attack and HVT data from January-April 2010.

iff tribes(p) ∩ tribes(p ) 	≡ ∅
otherwise

We use this function to generate regions via the algorithm
REGION-GEN-AFGH - presented for the ﬁrst time in this
paper. A practical improvement we introduced was in determining the set Vo for each observation. We ﬁrst determined
(Euc)
the set Vo
Vo computed with a Euclidean distance function on the interval [0, β] - as the Euclidean distance function
can be calculated much faster than shortest-path. From this
set, Vo is determined. It should be noted that the algorithm
runs with a complexity O(K · |O| · T (RN )) where K is a
constant bound on the number of partners distance β away
from a given observation and T (RN ) is the time complexity
to ﬁnd the shortest path between two points in RN . Another
practical extension we added was to the output of GREEDYREP-MC2. Any returned region over 1000 sq km was not
included in the output. Our intuition here is that a region
so large is not useful to an analyst attempting to cue other
intelligence assets.

Afghanistan Data Set
Our data-set consisted of HVTs and attack data from the
Afghan provinces of Hilmand and Kandahar from January
- June 2010 supported by tribal and road network information. Below we provide details of the data-set.
Provincial Data. All provincial data, including boundaries
of provinces and districts, road networks, and village locations were provided by (Afghanistan Information Management Services (AIMS) ). We considered the Hilmand
and Kandahar provinces, which consist of 29 districts. The
road-network (RN = (V, E)) is an undirected graph of
30, 304 vertices (1604 of which are identiﬁed as villages)
and 61, 064 edges.

Experimental Results
Setup. Our implementation of SCARE-S2, runs on a
Lenovo T400 ThinkPad laptop equipped with an Intel Core
2 Duo T9400 processor operating at 2.53 GHz and 4.0 GB
of RAM. The computer was running Windows Vista 64-

1691

Regions with HVT's

• Cache HVTs:

–
–
–
–
–

Average Area

Area of regions (km2)

Runtime (seconds)

250
200
150

100

9

20 24 31 32 36 58 69 72 91 100

Number of attacks considered

500
400
300
200

0
20

24

31

32

36

58

69

72

Number of attacks considered

HVT’s per km2

Number of Regions

Max Area

600

9

0.006

B

0.005

0.004
0.003
0.002
0.001

9

20 24 31 32 36 58 69 72 91 100

0
4

9

20

24

31

32

36

58

69

72

91 100

Number of attacks considered

Runtime Experiments. We examined runtime of the algorithm by running the algorithm on each of the 12 subsets
of observations described earlier. We observed two things:
that the relationship between runtime and number of attacks
was linear and that the runtime of REGION-GEN-AFGH
dominated the runtime of GREEDY-REP-MC2 (which was
negligible). This is primarily the result of the calculation of
the shortest path. As stated earlier, this relationship is linear,
so our result depicted in Figure 2 is unsurprising.
Area of Regions. As with (Shakarian and Subrahmanian
2010), we examine the average area of the regions. In general, smaller regions are preferred and as set O grows, the
regions should become smaller. In each of the 12 trials, there
was never more than one region over 200 sq km, and as set
O increased, the average area approach 100 sq km – this is
exactly what we are looking for. We plot the average and
maximum areas in Figure 2. Note that a few spikes in average area are directly related to spikes in maximum area from
a few outliers produced on some runs. Note that only a third
of our runs produced a region over 200 sq km. Although
even 100 sq km may seem like a large area, we must consider the density of villages - which is what we are attempting to locate. The overall density of villages for the entire
area considered was 0.0064.5 By the nature of how the regions are generated, they inherently have more villages. We
observed that when we considered the entire set of attacks,
no region contained more than 8 villages, with an average
village density of 4.8 villages per region. As such is the
case, we feel that the regions produced by SCARE-S2 will
be helpful in directing intelligence, surveillance, and reconnaissance (ISR) assets.
HVTs Enclosed by Regions. In Figure 3, we plot the number of regions returned by each run, as well as the number of
regions that enclose at least one HVT from the ground-truth
set. Although the number of regions increase with the number of attacks (from 1 to 6), the number of regions enclosing
an HVT also increase (from 0 to 3). While we should expect that solutions with more regions to enclose more HVTs,
we must also recall that the regions become smaller with
each run. Further, we also examined HVT density (number
of HVTs divided by total area of all regions), which also

700

4

2

0.007

Figure 3: Number of attacks vs. number of regions and HVT
density.

100
50

3

Number of attacks considered

800

300

4

4

Figure 1: HVT criteria.

350

5

0

– Reported listed individual as an insurgent “commander”
– Reported listed individual as an insurgent “subcommander”
– Reported listed individual as an insurgent “planner”

400

Overall Density

A

0.008

1

• Personnel HVTs:

4

Density of Regions
0.009

6

The cache contains 3x or more mortar rounds
The cache contains mortar tubes
The cache contains 3x or more rockets
The cache contains 10x or more grenades
The cache contains 5x or more RPG launchers
The cache contains 20x or more RPG rounds
The cache contains 15x or more AK-47’s (or other similar
riﬂes)
The cache contains 3x or more land-mines
The cache contains ”rooms” full of communications
equipment (or ”rooms” full of any type of equipment)
The cache contains a DsHK or any other anti-aircraft
weapon (including any number of Stinger missiles)
The cache contains 5x or more RPK machine guns (or
similar capable systems such as M60, M249, etc.)
The cache contains 5x or more sniper riﬂes (such as a Dragunov)

–
–
–
–
–
–
–

Total Number of Regions

7

91 100

Figure 2: Number of attacks vs. runtime (average over 10
trials) and average region area.

bit Business edition with Service Pack 1 installed. This
modest hardware setup was selected as deploying units to
Afghanistan are typically equipped with Windows-based
laptop systems. Isolated command posts, with limited connectivity to a network due to terrain restrictions may only
have access to this limited computation power.
We implemented SCARE in approximately 4000 lines of
Java code. Java Runtime Environment (JRE) Version 6 Update 14 was used. The software was developed with Eclipse
version 3.4.0. We used the JGraphT library version 0.81 to
implement the Fibonacci heap and the graph structure. Additionally, BBN OpenMap was used for some of the geospatial methods. We also added the capability to output KML
ﬁles so that the results could be viewed in Google Earth
- we used Google Earth 4.3.7284.3916 (beta) operating in
DirectX mode. Experimental results were also collected in
CSV-formatted spreadsheets.

5

In the newest version, SCARE-S2 also runs the geospatial abduction algorithm of (Shakarian, Subrahmanian, and Sapino 2010)
which abduces points (villages, in this case). Hence, the output
now not only included regions, but villages of interest as well which allows us to further reduce the search-space for HVTs.

1692

A

D

C

Region A
Report 2010-05-CA-052

Region B
Report 2010-07-CA-11

B

E

F

Region C
Report 2010-08-CA-161

Figure 4: Regions returned after considering attacks from
May-June 2010.

Figure 5: Close-up view of regions A-C with actual HVTs
plotted.

increased with each run (note we had two outliers, identiﬁed in Figure 3 as points A and B. In these two runs, the
software returned larger regions of size 719.68 sq km and
403.34 sq km that enclosed a large urban area where many
HVTs were found. Eliminating these regions from the solution would eliminate these artiﬁcial spikes in density). When
we considered the entire two months of observed attacks, the
HVT density in the regions was over 35 times greater than
the overall HVT density in the provinces. We remind the
reader that the the regions are meant to be used as Named
Areas of Interest (NAIs) for use by intelligence personnel.
These NAIs would then be used to cue other intelligence
assets (for example, a UAV or a HUMINT team) to conduct a more ﬁne-grained search (hence, avoiding a search
in a larger area). Therefore, despite only half the returned
SCARE regions containing NAIs, the small size of the regions, along with the high density of HVTs, make them invaluable for the intelligence process.
Discussion. We shall now consider our ﬁnal run of the algorithm, where we considered the entire set of 100 attacks from
May-June 2010. This run produced the most regions enclosing HVTs, the greatest HVT density (discounting spikes A
and B), and the smallest average region area.
This trial of the software produced 6 regions, labeled A-F,
shown in Figure 4. Half of them enclosed an HVT. However,
there were other ISAF reports that did not include village
information. We did not consider these additional reports in
any part of our experiments. However, all three regions returned by this experiment that did not enclose an HVT were
located in districts where an HVT was reported (with no village information). For region D, there were 11 such reports,
for region F, there were 4 such reports, and for district E
there were was one such report. Let us now consider the
HVTs found within regions A-C, depicted in Figure 5. Region A (with an area of 102.5 sq km) encloses the village
of Bahram in the Ghorak district of Kandahar. According to
ISAF PAO report 2010-05-CA-052, on May 5, 2010, a combined ISAF-Afghan force captured a Taliban commander in

this village, who was responsible for several improvised explosive device (IED) attacks as well as movement of foreign
ﬁghters in the country. He also had a cache that included
automatic riﬂes and heroin. Region B (with an area of 72.0
sq km) encloses the village of Makuan, in the Zhari district
of Kandahar. According to ISAF PAO report 2010-07-CA11, on July 18, 2010, a combined Afghan-ISAF force conducted a raid on a compound where a Taliban weapons facilitator was believed to reside. The unit received ﬁre from
insurgents, and returned ﬁre killing several of them. As they
approached the compound, they found several IED’s placed
to guard the facility. The compound was found to be a IED
factory and a bunker system that contained munitions. Region C (with an area of 71.0 sq km) encloses the village
Kharotan in the Nahri Sarraj district of Hilmand. ISAF PAO
report 2010-08-CA-161 describes how ISAF forces detained
the Taliban deputy-commander of the Lashkar Gah district
there on August 14, 2010.

Related Work and Conclusions
Recently, there has been some work dealing with analytical and computational methods for reducing the IED threat
in a counter-insurgency environment. (Marks 2009) uses
dynamic programming scheme to determine optimal path
on a network to conduct route-clearing operations. (Curtin
2009) explores the use of linear-referencing to associate IED
events to certain parts of a road network. In (Li et al.
2009), the authors introduce the PITS system for predicting IED events based on geographic features and other nongeographic event (such as time). (Benigni and Furrer 2008)
the authors look to quantify the IED threat of a given route
at speciﬁc times of day. We would like to point out that all of
this work deals with the either the prediction of IED attacks
or avoiding potential locations of IED attacks – not locating HVTs (enemy personnel or logistics sites). Additionally,
our search for HVTs is at a much larger scale – we are considering whole provinces of a very large area. Hence, the
neutralization of the HVTs associated with an area of this

1693

size has a greater effect on the battleﬁeld. To our knowledge, this paper introduces the ﬁrst computational method
for ﬁnding HVTs on the counter-insurgency battleﬁeld. As
stated above, this works build on the concept of geospatial abduction introduced in (Shakarian, Subrahmanian, and
Sapino 2009; 2010; Shakarian and Subrahmanian 2010).
However, none of these papers consider applying geospatial abduction to the Afghanistan scenario as presented here,
or the special considerations already discussed. Geospatial
abduction is a form of abductive inference, ﬁrst introduced
in (Peirce 1955). Two major existing theories of abduction
include logic-based abduction (Eiter and Gottlob 1995) and
set-covering abduction (Bylander et al. 1991). Geospatial
abduction is related to set-covering abduction (which has
been extensively explored in its application to medical diagnosis in (Peng and Reggia 1990)) as it reduces to an instance of set-cover. Some instances of other problems such
as facility location and clustering can actually be encoded
in a geospatial abduction, but a reduction in the opposite direction is not possible (see (Shakarian, Subrahmanian, and
Sapino 2010) for a detailed discussion on this comparison).
In this paper we introduced a piece of software called
“SCARE-S2” that applies geospatial abduction to the environment of Afghanistan. Unlike previous work, where we
looked for small weapon caches supporting local attacks,
here we looked for insurgent high-value targets (HVTs),
supporting insurgent operations in two provinces. These
HVTs included the locations of insurgent leaders and major supply depots. Applying this method of inference
to Afghanistan introduced several practical issues not addressed in previous work. Namely, we are conducting inference in a much larger area (24, 940 sq km as compared
to 675 sq km in previous work), on more varied terrain, and
must consider the inﬂuence of many local tribes. We address
all of these problems and evaluate our software on 6 months
of real-world counter-insurgency data. We show that we are
able to abduce regions of a relatively small area (on average, under 100 sq km, containing, in average, 4.8 villages)
that are more dense with HVTs (35× more than the overall
area considered). There are other possible uses of geospatial abduction, including counter-drug, police, and naturalist
uses. In our lab, we are also collecting data concerning illegal mining operations in Africa and are considering geospatial abduction as a possible tool to explore this international
problem. Some of these have been described as examples in
work such as (Shakarian, Subrahmanian, and Sapino 2010;
Shakarian and Subrahmanian 2010), but not explored from
an implementation standpoint. Such future studies would
highlight other practical issues to consider when applying
geospatial abduction to real-world problems, as was done in
this paper for the Afghan scenario. One such practical extension we are considering is the use social network data to
relate observations and partners (as we did in this work with
tribal data), which could aide in predictions.

FA95500610405 and ARO grants W911NF0910206 and
W911NF0910525.

References
Afghanistan Information Management Services (AIMS).
GIS / Mapping Services, http://http://www.aims.org.af/.
Benigni, M., and Furrer, R. 2008. Periodic spatio-temporal
improvised explosive device attack pattern analysis. Technical report, Golden, CO.
Bylander, T.; Allemang, D.; Tanner, M. C.; and Josephson,
J. R. 1991. The Computational Complexity of Abduction.
Conover, T. 2010. The Routes of Man: How Roads Are
Changing the World and the Way We Live Today. Knopf.
Curtin, K. 2009. Linear Referencing for Network Analysis
of IED. In AFCEA-GMU Symposium.
Eiter, T., and Gottlob, G. 1995. The complexity of logicbased abduction. J. ACM 42(1):3–42.
International Security Assistance Force (ISAF) Afghanistan.
Press
Releases,
http://www.isaf.nato.int/article/isafreleases/index.php.
Li, H.; Muoz-Avila, H.; Bramsen, D.; Hogg, C.; and Alonso,
R. 2009. Spatial event prediction by combining value function approximation and case-based reasoning. In McGinty,
L., and Wilson, D., eds., Case-Based Reasoning Research
and Development, volume 5650 of Lecture Notes in Computer Science. Springer Berlin / Heidelberg. 465–478.
Marks, C. 2009. Optimization-Based Routing and Scheduling of IED-Detection Assets in Contemporary Military Operations. Master’s thesis, Massachusetts Institute of Technology.
National Counter-Terrorism Center (NCTC). Worldwide Incident Tracking System (WITS), https://wits.nctc.gov/.
Naval Postgraduate School (NPS). Program for Culture and
Conﬂict Studies, http://www.nps.edu/programs/ccs/.
Peirce, C. S. 1955. Philosophical writings of Peirce, selected and edited with an introd. by Justus Buchler. Dover
Publications New York,.
Peng, Y., and Reggia, J. A. 1990. Abductive inference models for diagnostic problem-solving. New York, NY, USA:
Springer-Verlag New York, Inc.
Shakarian, P., and Subrahmanian, V. 2010. Region-based
Geospatial Abduction with Counter-IED Applications. In
Wiil, U. K., ed., Counterterrorism and Open Source Intelligence (to appear). Springer.
Shakarian, P.; Subrahmanian, V.; and Sapino, M. L. 2009.
SCARE: A Case Study with Baghdad. In Proceedings of the
Third International Conference on Computational Cultural
Dynamics. AAAI.
Shakarian, P.; Subrahmanian, V.; and Sapino, M. L. 2010.
Gaps: Geospatial abduction problems. ACM Transactions
on Intelligent Systems and Technology (to appear).
US Army. 1994. Intelligence Preparation of the Battleﬁled
(US Army Field Manual), FM 34-130 edition.

Acknowledgments
Paulo Shakarian is funded under the US Army ACS/West
Point Instructor (EECS) program.
Some of the authors of this paper were funded in part by AFOSR grant

1694

Noname manuscript No.
(will be inserted by the editor)

Toward Early and Order-of-Magnitude Cascade
Prediction in Social Networks
Ruocheng Guo · Elham Shaabani ·
Abhinav Bhatnagar · Paulo Shakarian

arXiv:1608.02646v1 [cs.SI] 8 Aug 2016

Received: date / Accepted: date

Abstract When a piece of information (microblog, photograph, video, link,
etc.) starts to spread in a social network, an important question arises: will it
spread to “viral” proportions – where “viral” can be defined as an order-ofmagnitude increase. However, several previous studies have established that
cascade size and frequency are related through a power-law - which leads to a
severe imbalance in this classification problem. In this paper, we devise a suite
of measurements based on “structural diversity” – the variety of social contexts (communities) in which individuals partaking in a given cascade engage.
We demonstrate these measures are able to distinguish viral from non-viral
cascades, despite the severe imbalance of the data for this problem. Further,
we leverage these measurements as features in a classification approach, successfully predicting microblogs that grow from 50 to 500 reposts with precision
of 0.69 and recall of 0.52 for the viral class - despite this class comprising under
2% of samples. This significantly outperforms our baseline approach as well
as the current state-of-the-art. We also show this approach also performs well
for identifying if cascades observed for 60 minutes will grow to 500 reposts as
well as demonstrate how we can tradeoff between precision and recall.
Keywords Cascade Prediction · Information Diffusion · Social Network
Analysis · Diffusion in Social Networks

U.S. provisional patent 62/201,517. A non-provisional patent is currently being filed.
Some of the authors of this paper are supported by by AFOSR Young Investigator Program
(YIP) grant FA9550-15-1-0159, ARO grant W911NF-15-1-0282, and the DoD Minerva program.
Ruocheng Guo, Elham Shaabani, Abhinav Bhatnagar, Paulo Shakarian
Arizona State University
E-mail: {rguosni, shaabani, abhatn, shak}@asu.edu

2

Ruocheng Guo et al.

1 Introduction
When a piece of information (microblog, photograph, video, link, etc.) starts
to spread in a social network, an important question arises: will it spread to
“viral” proportions – where “viral” is defined as a significant (i.e. order-ofmagnitude) increase in the number of individuals re-posting the information.
However, several previous studies (Bakshy et al, 2011; Cheng et al, 2014) have
established that cascade size and frequency are related through a power-law
- which leads to a severe imbalance in this classification problem. In this paper, we devise a suite of measurements based on “structural diversity” that
are associated with the growth of a viral cascade in a social network. Structural diversity refers to the variety of social contexts in which an individual
engages and is typically instantiated (for social networks) as the number of distinct communities represented in an individual’s local neighborhood (Ugander
et al, 2012; Zhang et al, 2013; Shakarian et al, 2014; Li et al, 2015). Previously, Ugander et al. identified a correlation between structural diversity and
influence (Ugander et al, 2012). We demonstrate these measures are able to
distinguish viral from non-viral cascades, despite the severe imbalance of the
data for this problem. Further, we leverage these measurements as features
in a classification approach, successfully predicting microblogs that grow to
500 reposts from 50 (size-based experiments) or the first-hour observations
(time-based experiments). The main contributions of the paper are as follows:
– We develop a suite of structural diversity-based measurements that are
indicative of cascade growth.
– We are able to identify cascades of 50 reposts that grow to 500 reposts
with a precision of 0.69 and recall of 0.52 for the viral class (200 out of
13,285 samples).
– We are able to identify cascades that have advanced for 60 minutes that
will reach 500 reposts with a precision of 0.65 and recall of 0.53 for the
viral class (200 out of 3,444 samples).
– We demonstrate how to trade-off between precision and recall for the
above-mentioned problems. For instance, to predict cascades that reach
500 nodes, we can obtain precision of 0.78 or recall of 0.71 at the expense
of the other.
– We demonstrate that our approach is stable for alternative definitions of
”viral” (i.e. microblogs that grow to sizes above or below 500 reposts).
We note that our results on the prediction of cascades rely solely upon the use
of our structural diversity based measures for features and limited temporal
features - hence the prediction is based on network topology alone (no content
information was utilized). We also achieved these results while maintaining the
imbalance of the dataset - where we leave the ratio of ’viral’ and ’non-viral’
samples as it is. This differs from some previous studies (i.e. (Jenders et al,
2013)) which balance the data before conducting classification experiments.
Further, we note that we obtained prediction of order-of-magnitude increases
in the size of the cascade - which also differs from other work (i.e. (Cheng

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

3

et al, 2014)) which focus on identifying cascades that double in size. The
remainder of the paper is organized as follows. In Section 2 we introduce
our notation and describe the dataset used in this paper. This is followed
by an introduction of our structural diversity measurements for cascades in
Section 3. Then we describe our experimental results where we examined both
the behavior of these measurements and the performance of classifiers built
using these measurements in Section 5. Finally, we discuss related work in
Section 6.

2 Technical Preliminaries
Here we introduce necessary notation and describe our social network data.
We represent a social network as G = (V, E) where V is the set of nodes and
E as a set of directed edges with sizes |V |, |E| respectively. The intuition behind edge (v, v 0 ) is that it is possible that v 0 repost a microblog from v since
v 0 did this previously. This intuition stems from how we create the edges in
our network: (v, v 0 ) is an edge if v 0 reposted from v once or more during a
specified time period (for our experiments, May 1 to July 31, 2011). We also
assume a partition over nodes that specifies a community structure. We assume that such a partition is static (based on the same time period from which
the edges were derived) and that the partition C consists of k communities:
{C1 , C2 , ..., Ck }, each is a set of nodes. There are many possible methods to
derive the communities (if user-reported communities are not available) - for
instance: the Louvain algorithm (Blondel et al, 2008), Infomap (Rosvall and
Bergstrom, 2008), Smart Local Move (SLM) (Waltman and van Eck, 2013)
and Label Propagation (Raghavan et al, 2007). Previous work such as (Weng
et al, 2014; Grabowicz et al, 2012) showed the effectiveness of communities
detected by these algorithms for different applications. In this paper, We utilize the Louvain algorithm, Infomap algorithm and SLM algorithm to identify
communities in the social network G due to their scalability for large social
network. For these algorithms, the number of communities is not an argument
as input but rather produced as part of the output of these algorithms. Note
that we require C to be a partition over nodes - hence we disallow for overlapping communities. This is consistent with the community structure derivations
from previous, related work (Ugander et al, 2012; Zhang et al, 2013; Shakarian et al, 2014; Li et al, 2015) which also required a partition over nodes such
as strongly connected components. As such, we leave the study of structural
diversity in the case of overlapping communities to future efforts.
Cascades. A cascade τ = (U, R) consists of all nodes (U ) who posted or reposted a certain original microblog and the reposting relationships between
them, treated as edges (R). Naturally, any cascade is a subgraph of the social
network G. In order to predict the final size, snapshots of a cascade can be
taken by different time since adoption of the seed adopter (denoted by t). Then
a snapshot of cascade τ introduces a subset τt = (Ut , Rt ) of τ . We refer to

4

Ruocheng Guo et al.

Ut as adopters. Moreover, we also call the out-neighbors of adopters in G but
not among the adopters as exposed users and denote them as NG (Ut ). For
each node v ∈ NG (Ut ), we define the adopters who exposes the cascade to v
as its exposers. For convenience, we also define function uea : v → u to return
the earliest adopter u among exposers of v ∈ NG (Ut ).
For size-based experiments, the time t for taking snapshot of a cascade
is decided by a given cascade size m. We use t(m) to denote the smallest
t such that |Ut |= m is true for a certain cascade. Accordingly, to get the
corresponding order number n of an adopter u ∈ Ut , we define function Index :
u → n where n ∈ [1, |Ut |]. To maintain a unique order of reposts, a very small
random number is added to each t(n) for all integers n ∈ [1, |Ut (m)|]. We have
not found this to be a significant issue in this dataset. For convenience and
simplicity, we use t to stand for both t(m) in size-based and t in time-based
experiments later.
For a given snapshot τt = (Ut , Rt ), then we want to divide the set NG (Ut )
into two sets, namely recently exposed users (Ft ) and past exposed users (Nt ).
Intuitively, this division is done based on how long it is since v ∈ NG (Ut ) is
true (when it is possible for v to make a repost) till the snapshot τt is taken.
Formally, given a node v ∈ NG (Ut ), we decide whether it is a recently or past
exposed user:
texpose (v) = t − t(Index(uea (v)))
(1)
As defined before, t(n) denotes the earliest time t when |Ut |= n is true.
Then the value of texpose (v) is the number of time periods since the earliest
adoption among its exposers till when the snapshot of cascade is taken.
A positive constant λ is set as a threshold on texpose (v) (we will discuss
how this constant is set in the last paragraph of 2), the recently exposed users
and past exposed users are defined as follows:
Ft = {v ∈ NG (Ut ) s.t. texpose (v) ≤ λ}

(2)

Nt = NG (Ut ) \ Ft

(3)

Sina Weibo Dataset. The dataset we used was provided by WISE 2012 Challenge1 . It included a sample of microblogs posted on Sina Weibo2 from 2009
to 2012. In this dataset, we are provided with time and user information for
each microblog and subsequent repost which enabled us to derive a corpus of
cascades. For every repost in this dataset, the reposting relationship is provided as uid: v 0 tab v which indicates this message is a reposted from user v by
v 0 . From this data, we derived our social network G = (V, E) that was created
from microblogs (including original posts and reposts) published during May
1, 2011 to July 31, 2011 (the 3-month period). For this network, the number
of active nodes in August (the time period we studied for cascade prediction)
is 5,910,608, while 5,664,625 of them at least have one out-neighbor. During
1
2

http://www.wise2012.cs.ucy.ac.cy/challenge.html
http://weibo.com

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

5

Table 1: Properties of the Social Network and Cascades
Network Properties
Vertices (Nodes)
Edges
Average degree
Average clustering coefficient
Connected components
Number
Average
Number
Average
Number
Average

of communities (Louvain)
size of communities (Louvain)
of communities (Infomap)
size of communities (Infomap)
of communities (SLM)
size of communities (SLM)

Cascade Properties
Number
Number
Number
Average

of cascades
of viral cascades
of active nodes in cascades
time to become viral

Value
17,996,803
52,472,547
5.83
0.107
4974
379,416
47.5
39,922
450.799
380,854
47.3
Value
2,113,405
208
5,910,608
18 (h)

the month of August, there were 22,182,704 microblogs. Of these, 9,323,294
are reposts. 2,252,368 different of original posts succeeded to make at least
one user repost, while 1,920,763 (86.6%) of them were written by authors who
at least published one microblog during the 3-month period mentioned before. For this dataset, although different from a power-law noted previoulsly
in (Bakshy et al, 2011; Cheng et al, 2014), the histogram of final cascade size
(see Figure 1a) still shows that only quite few cascades went ’viral’. Therefore, we could demonstrate that this dataset is more representative of cascade
behavior observed in real world than work like (Jenders et al, 2013) which
conducted biased sampling to artificially provide balanced classes.
We select the threshold constant λ as 30 minutes since vast majority of
all the reposts in May-July, 2011 occurred within 30 minutes since adoption
of the seed adopter (see Figure 1b). To justify this selection, knowing that
λ is a threshold on texpose (v) which is upper bounded by t, the proportion
of exposed users became adopter with texpose (v) ≤ 30(min) should be more
than that of those did the repost with t ≤ 30(min). This implies why it is
necessary to distinguish recently and past exposed users due to the significant
difference in probability to adopt. In Figure 1c, we show distribution of how
long it takes for viral cascades to reach 500 nodes - note that the average value
here is approximately 18 hours (which is significantly greater than what we
study in our time-based classification problem).

Ruocheng Guo et al.

Frequency

6

107
106
105
104
103
102
101
100 0

200 400 600 800 1000 1200 1400
Final Size of Cascades

(a) The histogram of cascade size for August, 2011

cumulative probability

10 0
10 -1
10 -2
10 -3
-4
1010
0
10 1
10 4
10 5
10 2
10 3
time since the adoption of the seed adopter (minutes)

(b) CDF of adoption time since adoption of the seed adopter (minutes) for May-July, 2011

Frequency

10 2

10 1

10 0 0 200 400 600 800 1000 1200 1400
Time taken to become viral (>500) in minutes
(c) Histogram of time (minutes) ’viral’ cascades took to reach size of 500.

Fig. 1: Network Dataset Statistics

3 Structural Diversity Measurements in Real Information Cascades
Found by (Ugander et al, 2012), an individual is more likely to be infected
by a ‘social contagion’ if his/her ‘infected’ in-neighbors are distributed over
more connected components of social network users. For example, as shown

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

7

in Figure 2, although the man on the left has more infected in-neighbors, the
woman on the right is more likely to be infected by the social contagion. As
in-neighbors of her are showing higher structural diversity (from two communities). Translated into the terminologies introduced in this paper, they showed
that an exposed user is more likely to become an adopter with exposers of
high structural diversity. If this effect is aggregated over all the exposed users
of a cascade, the significance to measure the relationship between structural
diversity of adopters would be revealed. Moreover, we also extend our experiments to measure that of exposed users. Instead of connected components, we
consider structural diversity described by communities. In this section we introduce a suite of various structural diversity measurements. We study these
measurements as cascades progress in Section 4 and then leverage them as
features for our classification problem in Section 5. We introduce these measurements as follows.
Number of communities. For a given set of node S ∈ {Ut , Ft , Nt } we can
retrieve the associated communities C(S) by the partition of the social network
C(G). Formally:
C(S) = {Ci ∈ C(V ) s.t. S ∩ Ci 6= ∅}
where C(V ) is the partition of the social network G, introduced in Section 2. We
measure the number of communities represented by |C(S)| for S ∈ {Ut , Ft , Nt }.
Gini impurity. For S ∈ {Ut , Ft , Nt } in a cascade τt , the gini impurity IG (S)
proposed by (Breiman et al, 1984) for splitting samples in decision tree, intuitively, is a scalar describing how much the distribution of nodes in S over
communities in C(S) differs from the uniform distribution. Here the uni|S|
for all Ci ∈ C(S).
form distribution stands for the situation where |Ci |= |C(S)|
To show the extreme values, IG (S) ≈ 1 means the nodes are uniformly distributed over a large quantity of communities while IG (S) ≈ 0 implies most of
the nodes in S are from the few ’dominant’ communities. Formally, we define
gini impurity as follows:
IG (S) = 1 −

X

(

Ci ∈C(S)

|Ci | 2
)
|S|

(4)

We study the gini impurity IG (S) for S ∈ {Ut , Ft , Nt } for each cascade. We
note that the impurity of the adopter set IG (Ut ) behaves similar to the entropy
of this set (a measurement introduced in (Weng et al, 2014)). However, as we
will see in the next two sections, we found that the impurity of the recently
exposed users is a more discriminating feature.
Overlap. For {Sa , Sb } ⊂ {Ut , Ft , Nt }, the overlap (O(Sa , Sb )) is simply the
number of shared communities between the sets of nodes Sa and Sb . Formally:
O(Sa , Sb ) = |C(Sa ) ∩ C(Sb )|

(5)

8

Ruocheng Guo et al.

Fig. 2: An example for structural diversity: Although the man on the left has
more infected in-neighbors, the woman on the right is more likely to be infected
by the social contagion. As in-neighbors of her are showing higher structural
diversity (from two communities).

The intuition behind overlap stems directly from the original structural diversity results of the related work (Ugander et al, 2012) - for instance a large
overlap value O(Ut , Ft ) is likely to indicate that the local neighborhoods of
many of the recently exposed users will exhibit high structural diversity hence increasing the probability to become adopters in the future.
Baseline measures. In addition to the aforementioned structural diversity measurements, we also examine two baseline measurements dealing with time and
size.
Average time to adoption. ThePaverage time to adoption for adopters in the
m
1
cascade snapshot of size m: m
i=1 t(m).
Number of nodes. The cardinality of adopters, recently and past exposed users
|Ut |,|Ft |,|Nt |.

4 Structural Diversity Measurement Study
Here we examine the behavior of the various structural diversity measurements
as viral and non-viral cascades progress. In this section, we define a cascade as
viral if the number of reposts eventually reaches a threshold (denoted T H) of
500 (in the next section we will explore various values for T H). Only the distributions of feature values computed based on Louvain algorithm are exhibited
in this section as it provides best results in both size-based and time-based classification tasks (See Section 5). All the measurements are computed by cascade

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

9

Table 2: Number of samples analyzed in different stages
m
10
30
50
100
200

Samples
98,832
26,733
13,285
4,722
1,324

Viral Samples (%)
0.2%
0.7%
1.5%
4.2%
15%

t (min)
40
60
100
150
300

Samples
2,234
3,444
5,767
8,349
15,350

Viral Samples (%)
7%
5%
3%
2%
1%

snapshots with five populations of nodes with m = {10, 30, 50, 100, 200} (or
t(m) accordingly) and five values of time since adoption of the seed adopter
with t = {40, 60, 100, 150, 300}. Table 2 shows the number of samples our
analysis covers in both classes for each value of m and t. For each time t we
perform analysis on measurements for those cascade snapshots with no less
than 5 adopters at the time so that the enough information can be provided
from Ut ,Ft and Nt for the prediction task. For each size m, we consider the
cascades with |Ut |= m adopters at the corresponding time t(m), t(m) can
vary for different cascades. Hence, cascades with final size less than m are
ignored in our analysis. This leads to that the number of non-viral cascades
decreases as m increases. We examined a total of 24 measurements discussed
in the previous section (12 for size-based and 12 for time-based analysis, listed
as Am and At respectively in Table 3). For each measurement, for each m and
t describing the diffusion process, we attempted to identify statistically significant difference between viral and non-viral classes. For this, we performed
KS tests for each pair of measurements. In every test, p ≤ 10−13 , so the null
hypothesis is rejected for all cases, which means each pair of the distributions
are significantly different. We choose KS test over T test and Chi-square test
as it is sensitive to both the location and shape of the distribution as well as
it does not require each distribution to cover all possible values of the other.
As notations of the box plots in the following subsections, A and M denotes
mean and median for each box plot respectively.

4.1 Size Progression
Average time to adoption. As a baseline measurement, we study the average
time to adoption for each m of the cascade process (Figure 3). As expected,
viral cascades exhibit shorter average time since adoption of the seed adopter
till each later adoption. While we note that significant differences are present
- especially in the early stages of the cascade, the whiskers of the non-viral
class indicate a significant proportion of non-viral cascades that exhibit rapid

10

Ruocheng Guo et al.

adoption. We believe this is likely due to the fact that certain cascades may
have very high appeal to specialized communities.
Number of communities. Figure 4 displays how the number of communities
|C(S)| increases over m = {10, 30, 50, 100, 200} for the sets S = {Ut , Ft }. We
note that |C(Ut )| (the communities represented in the set of adopters) was
shown to be a useful feature in (Weng et al, 2014) for tasks where the target
class had fewer reposts than in this study. Here, we note that while statistically
significant differences exist, the average and median values at each of the
examined stages are generally similar. On the other hand, the communities
represented by the set of rencently exposed users (Ft ) shows viral cascades
have stronger capability to keep set of rencently exposed users with many
communities than non-viral ones. We also noted that the median of |C(Nt )|
shows viral cascades start with smaller |C(Nt )|. However, it increases faster in
viral cascades as nodes in rencently exposed users become past exposed users
(not pictured) as m increases.
Gini impurity. Cascades in both classes tend to accumulate diversity in the
process of collecting more adopters - and we have also noted that a related
entropy measure (studied in (Weng et al, 2014)) performed similarly. We also
observed that viral cascades can show larger gini impurity in recently exposed
users measured by IG (Ft ) in early stages (m = {10, 30, 50}). However, perhaps
most striking, non-viral cascades gain more uniformly distributed nodes over
communities in non-adopters, shown by IG (Nt ) (Figure 5). We believe that this
is due to non-viral cascades likely have an appeal limited to a relatively small
number of communities - hence those not adopting the trend may represent a
distribution of nodes over communities which is more different from a uniform
distribution.
Overlap. We found that overlap grows with the number of adopters in the
three types of overlap considered. For O(Ut , Ft ), viral cascades start with a
larger initial value and keep leading non-viral ones in the diffusion process of
first 200 nodes (Figure 6). We consider that viral cascades also take advantage
of the densely linked communities to help them become viral. However, in the
case of O(Ut , Nt ) and O(Ft , Nt ), viral cascades begin with lower value but
grow much faster than non-viral cascades.
4.2 Time Progression
Number of adopters. As a baseline measurement, we study the number of
adopters at regular time intervals and, as expected, found a clear difference
between the two classes. Figure 7 shows how |Ut | changes over 40, 60, 100,
150 and 300 minutes. Although there is an obvious difference in early stages
(40-60 minutes) between the two distributions, we will see in the next section
that this alone does not provide adequate performance for our prediction task
(see Section 5).

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

Average Time(103 )

1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0 10

30

50 100 200

Number of Adopters

M: 15.3 49.7 78.4 168 301
A: 40.9 86.9 129 215 347

1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0 10

Average Time(103 )

M: 865 853 804 754 765
A: 780 790 770 753 759

11

(a) Non-viral cascades

30

50 100 200

Number of Adopters

(b) Viral cascades

Fig. 3: Average time (minutes in 103 ) since adoption of the seed adopter to
each later adoption

Number of Adopters

M: 8.0 17.0 23.0 34.0 46.5
A: 8.1 17.3 23.5 34.0 46.5
70
60
50
40
30
20
10
0 10
30 50 100 200

Number of Communities

Number of Communities

M: 8.0 18.0 25.0 35.0 48.0
A: 7.7 17.5 24.0 34.9 47.6
70
60
50
40
30
20
10
0 10
30 50 100 200

Number of Adopters

(a) Number of communities amongst (b) Number of communities amongst
adopters (|C(Ut )|) for non-viral cascades
adopters (|C(Ut )|) for viral cascades

Number of Adopters

M: 21.0 30.0 30.0 33.5 42.5
A: 24.3 41.7 44.4 78.7 88.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0 10
30 50 100 200

Number of Communities(102 )

Number of Communities(102 )

M: 7.0 15.0 20.0 27.0 33.0
A: 25.7 39.6 53.2 88.5 111
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0 10
30 50 100 200

Number of Adopters

(c) Number of communities amongst recently (d) Number of communities amongst recently
exposed users (|C(Ft )|) for non-viral cascades exposed users (|C(Ft )|) for viral cascades

Fig. 4: Number of communities for m = {10, 30, 50, 100, 200}

Number of communities. Figure 8 shows how |C(S)| for S ∈ {Ut , Ft , Nt }
changes over time. The value of |C(S)| increases over time for Ut and Nt
but decreases for Ft . Here, the differences are somewhat more pronounced
than for the size-progression measurements (compare with Figure 4). Viral
cascades are more likely to have more communities in any one of Ut , Ft , Nt
than non-viral ones. For adopters and non-adopters, |C(Ut )| and |C(Nt )| value
of viral cascades increases faster than that of non-viral ones over time. While
for recently exposed users, |C(Ft )| of non-viral cascades decreases more than
viral ones in the same amount of time.

12

Ruocheng Guo et al.

Gini

1.0
0.8
0.6
0.4
0.2
0.0 10

M: 0.9 0.9 0.9 0.9 0.9
A: 0.8 0.9 0.9 0.9 0.9

1.0
0.8
0.6
0.4
0.2
0.0 10

Gini

M: 0.7 0.8 0.9 0.9 0.9
A: 0.7 0.8 0.8 0.8 0.9

30

50 100 200

Number of Adopters

30

50 100 200

Number of Adopters

(a) Gini impurity of recently exposed users (b) Gini impurity of recently exposed users
(IG (Ft )) for non-viral cascades
(IG (Ft )) for viral cascades

Number of Adopters

M: 0.0 0.9 0.9 0.9 0.9
A: 0.4 0.8 0.9 0.9 0.9
1.0
0.8
0.6
0.4
0.2
0.0 10
30 50 100 200

Gini

Gini

M: 0.8 0.9 0.9 0.9 0.9
A: 0.8 0.9 0.9 0.9 0.9
1.0
0.8
0.6
0.4
0.2
0.0 10
30 50 100 200

Number of Adopters

(c) Gini impurity of past exposed users (d) Gini impurity of past exposed users
(IG (Nt )) for non-viral cascades
(IG (Nt )) for viral cascades

Fig. 5: Gini impurity for m = {10, 30, 50, 100, 200}
Gini impurity. It takes less than λ = 30 minutes for a considerable portion
of viral cascades to reach size m = 30. This explains the difference between
size-based and time-based gini impurity values in initial-stage cascades (compare Figure 5 and Figure 9). In terms of size-based gini impurity of the nonadopters (IG (Nt )), the values of viral cascades are smaller than those of nonviral cascades when m is small. However, when t is small, larger gini impurity
(IG (Nt )) amongst non-adopters are shown in viral cascades. Furthermore, as
m increases, although no significant difference is shown by the median and
average of IG (Nt ), Figure 5 shows non-viral cascades are more likely to have
a value smaller than the lower whisker to become outliers.
Overlap. By definition, overlap is the number of shared communities between
two sets of nodes. We found that overlap O(Ut , Ft ), O(Ut , Nt ) and O(Ut , Nt )
manifest obvious difference between viral and non-viral cascades by values and
trend over time. For instance, in Figure 10, we see growth of O(Ut , Ft ) for the
viral cascades compared to the non-viral class. In fact, over time, this value
decreases for non-viral cascades as the set of recently exposed users fades away
for non-viral cascades with time.

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

M: 3.0 9.0 12.0 19.0 26.0
A: 3.7 8.7 12.3 18.5 25.2

M: 7.0 13.0 17.0 22.5 31.0
A: 6.7 12.7 16.5 22.2 29.5

60
50
40
30
20
10
0 10

Overlap

Overlap

60
50
40
30
20
10
0 10

13

30

50 100 200

Number of Adopters

30

50 100 200

Number of Adopters

(a) Overlap of adopters and recently exposed (b) Overlap of adopters and recently exposed
users (O(Ut , Ft )) for non-viral cascades
users (O(Ut , Ft )) for viral cascades

M: 0.0 14.0 22.0 32.0 45.0
A: 2.4 13.3 21.1 32.2 45.0
70
60
50
40
30
20
10
0 10
30 50 100 200

Overlap

Overlap

M: 6.0 16.0 23.0 34.0 46.0
A: 5.9 15.6 22.3 33.3 46.1
70
60
50
40
30
20
10
0 10
30 50 100 200

Number of Adopters

Number of Adopters

(c) Overlap of adopters and past exposed (d) Overlap of adopters and past exposed
users (O(Ut , Nt )) for non-viral cascades
users (O(Ut , Nt )) for viral cascades

M: 0.0 14.5 21.5 28.0 38.0
A: 2.5 16.0 23.5 30.0 38.1
70
60
50
40
30
20
10
0 10
30 50 100 200

Overlap

Overlap

M: 3.0 11.0 16.0 23.0 30.0
A: 4.5 12.1 17.1 24.8 31.9
70
60
50
40
30
20
10
0 10
30 50 100 200

Number of Adopters

Number of Adopters

(e) Overlap of recently and past exposed (f) Overlap of recently and past exposed
users (O(Ft , Nt )) for non-viral cascades
users (O(Ft , Nt )) for viral cascades

Fig. 6: Overlap for m = {10, 30, 50, 100, 200}
9.0
15.3

300

Time Since the Original Post

M: 16.0 22.0 34.0 50.0
A: 22.2 31.4 49.7 71.9
3.0
2.5
2.0
1.5
1.0
0.5
0.0 40 60 100 150

Number of Nodes(102 )

Number of Nodes(102 )

M: 7.0 7.0 8.0 9.0
A: 9.5 10.4 11.8 13.1
3.0
2.5
2.0
1.5
1.0
0.5
0.0 40 60 100 150

109
139

300

Time Since the Original Post

(a) Number of adopters (|Ut |) for non-viral (b) Number of adopters (|Ut |) for viral cascascades
cades

Fig. 7: Number of adopters for t ∈ {40, 60, 100, 150, 300} (min)

Ruocheng Guo et al.

M: 6.0 6.0 6.0 7.0
A: 7.0 7.4 8.0 8.6

7.0
9.3

60 100 150

300

80
70
60
50
40
30
20
10
0 40

Time Since the Original Post

M: 12.0 14.0 19.0 24.0
A: 12.7 15.7 20.3 24.9
80
70
60
50
40
30
20
10
0 40 60 100 150

Number of Communities

Number of Communities

14

34.0
35.2

300

Time Since the Original Post

(a) Number of communities amongst (b) Number of communities amongst
adopters (|C(Ut )|) for non-viral cascades
adopters (|C(Ut )|) for viral cascades

0.0
15.2

300

Time Since the Original Post

M: 29.5 28.5 27.0 26.0
A: 66.7 44.5 57.4 46.3
100
80
60
40
20
0 40 60 100 150

Number of Communities

Number of Communities

M: 15.0 11.0 7.0 3.0
A: 79.8 61.0 49.3 35.8
100
80
60
40
20
0 40 60 100 150

25.0
38.2

300

Time Since the Original Post

2.0

M: 4.0 11.0 17.0 20.0
A: 22.1 43.5 73.4 105

23.0
140

1.5
1.0

0.5

M: 14.0 27.0 48.0 61.5
A: 22.1 63.1 95.1 146
2.0

Number of Communities(102 )

Number of Communities(102 )

(c) Number of communities amongst recently (d) Number of communities amongst recently
exposed users (|C(Ft )|), non-viral cascades
exposed users (|C(Ft )|) for viral cascades

92.5
261

1.5
1.0

0.5

0.0 40

60 100 150

300

Time Since the Original Post

0.0 40

60 100 150

300

Time Since the Original Post

(e) Number of communities amongst past ex- (f) Number of communities amongst past exposed users (|C(Nt )|) for non-viral cascades posed users (|C(Nt )|) for viral cascades

Fig. 8: Number of communities for t = {40, 60, 100, 150, 300} (min)

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

0.0
0.3

60 100 150

300

Gini

1.0
0.8
0.6
0.4
0.2
0.0 40

M: 0.9 0.9 0.9 0.9
A: 0.9 0.8 0.8 0.8

0.9
0.8

60 100 150

300

1.0
0.8
0.6
0.4
0.2
0.0 40

Gini

M: 0.8 0.8 0.7 0.5
A: 0.8 0.7 0.6 0.4

15

Time Since the Original Post

Time Since the Original Post

(a) Gini impurity of recently exposed users (b) Gini impurity of recently exposed users
(IG (Ft )) for non-viral cascades
(IG (Ft )) for viral cascades

M: 0.8 0.9 0.9 0.9
A: 0.7 0.8 0.9 0.9
1.0
0.8
0.6
0.4
0.2
0.0 40 60 100 150

0.9
0.9

Gini

0.9
0.8

Gini

M: 0.6 0.8 0.8 0.9
A: 0.5 0.7 0.8 0.8
1.0
0.8
0.6
0.4
0.2
0.0 40 60 100 150

300

Time Since the Original Post

300

Time Since the Original Post

(c) Gini impurity of past exposed users (d) Gini impurity of past exposed users
(IG (Nt )) for non-viral cascades
(IG (Nt )) for viral cascades

Fig. 9: Gini impurity for t = {40, 60, 100, 150, 300} (min)
M: 10.0 11.0 13.0 14.0
A: 11.5 12.6 14.4 15.8
60
50
40
30
20
10
0 40 60 100 150

18.0
19.2

Overlap

0.0
1.9

Overlap

M: 5.0 4.0 3.0 2.0
A: 5.7 4.8 3.8 2.9
60
50
40
30
20
10
0 40 60 100 150

300

Time Since the Original Post

300

Time Since the Original Post

(a) Overlap of adopters and recently exposed (b) Overlap of adopters and recently exposed
users (O(Ut , Ft )) for non-viral cascades
users (O(Ut , Ft )) for viral cascades

Fig. 10: Overlap for t = {40, 60, 100, 150, 300} (min)

16

Ruocheng Guo et al.

5 Classification Experiments
Here we examine our experiments for predicting whether a cascade becomes
viral - when the number of adopters exceeds a size threshold (T H = 500)
given that either the cascade has 50 adopters (m = 50) or has progressed for
an hour (t = 60). We shall refer to these as size-based and time-based prediction problems. Based on the distribution of final size of cascades in this dataset
(see Figure 1a), as shown in Table 2, this binary classification task deals with
two heavily imbalanced classes. Hence, we report performance measurements
(precision, recall and F1 score) for only the minority (viral) class. Throughout
the course of our experiments, we found that varying threshold (slightly modifying the definition of “viral”) for only the training set allows for a trade-off
between precision and recall. We study the trend of performance metrics in
two cases:
– The threshold for test set is maintained as T Hts = 500 while the training
threshold is varied T Htr ∈ {300, 400, 500, 600, 700}.
– The two thresholds are kept as the same T H while we modify this value
T H ∈ {300, 400, 500, 600, 700}.
Table 3 shows the groups of features used in our prediction tasks. The
features introduced in this paper are groups Am (size-based) and At (timebased). We compare our features (Group Am , At ) with the community features
extracted in (Weng et al, 2014) (Group Bm ,Bt ) and nodal features of the seed
adopter (Group Cm and Ct ). Here nodal measures of the seed adopter refer
to k-shell number, out-degree, in-degree, pagerank and eigenvector, which are
computed based on the social network G. In previous work (Pei et al, 2014), kshell number of the seed adopter node is shown to be correlated to the average
size of cascades. However, cascades from the seed adopter nodes with the same
k-shell number can end up with quite different size (Shakarian et al, 2015). As
baseline methods, average time to adoption (group Dm ) is applied to the sizebased experiment while cascade size at time t (group Dt ) is evaluated for timebased prediction. We extracted each group of community-based features (Am ,
At , Bm , Bt ) with all the three community detection algorithms mentioned
in Section 2: Louvain, Infomap and SLM. Therefore, for both size-based and
time-based prediction, there are 8 groups of features. Among them, Bm and
Bt were the best performing feature set in the paper (Weng et al, 2014) for a
comparable task.3
Additionally, we study the average size of correctly classified viral cascades
and the other viral samples using features in groups Am and At . We also investigate the significance and performance of individual and certain combinations
of features introduced in this paper.
3 This was their highest-performing set of features for predicting cascades that grew from
50 to 367 and 100 to 417 reposts. We also included the baseline feature in this set as we
found it improved the effectiveness of this approach.

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

17

Table 3: Features for prediction tasks (size-based and time-based): Am , Bm ,
At and Bt are computed based on three community detection algorithms (Louvain, Infomap and SLM)
Name

Feature(s) over size

Name

Feature(s) over time

Am

|C(Ft )|,|C(Nt )|,
IG (Ut ),IG (Ft ),IG (Nt ),
O(Ut , Ft ),O(U
t , Nt ),O(Ft , Nt ),
1 Pm
|Ft |,|Nt |, m
i=1 t(i)
where t stands for t(m) with
m ∈ {30, 50}

At

|C(Ft )|,|C(Nt )|,
IG (Ut ),IG (Ft ),IG (Nt ),
O(Ut , Ft ),O(Ut , Nt ),O(Ft , Nt ),
|Ut |,|Ft |,|Nt |
for time t ∈ {40, 60}(min)

Bm

Community Features Mentioned P
in (Weng et al, 2014)
m
1
and m
i=1 t(i), m = 50

Bt

Community Features Mentioned in (Weng et al, 2014)
and |Ut |, t = 60(min)

Cm

Nodal
1 Pm

Ct

Nodal Features and |Ut |, t =
60(min)

Dt

|Ut |, t = 60(min)

Dm

m
1
m

i=1

Pm

i=1

Features
t(i), m = 50
t(i), m = 50

and

5.1 Cascade Prediction Results
We split cascades into training set and testing set using ten-fold cross-validation.
All classification experiments are repeated for 10 times to ensure the results
do not take any advantage of randomness in picking training and testing sets.
First we carried out the prediction tasks with fixed thresholds for both training
and testing T Htr = 500, T Hts = 500. Then we modify the training threshold
T Htr ∈ {300, 400, 500, 600, 700} to show how this achieves a tradeoff between
precision and recall. The difference in average final size between correctly
classified viral cascades and incorrectly classified ones is also monitored over
T Htr ∈ {300, 400, 500, 600, 700} to show the potential to predict exact number of adopters by features in Am and At . Furthermore, we modify threshold
of both training and testing sets T H ∈ {300, 400, 500, 600, 700} to show the
robustness of our features on related classification problems. We used the oversampling method SMOTE (Chawla et al, 2002) with random forest classifier to
generate synthetic samples for the viral class. Other, lesser-performing classifiers were also examined (including SVM, MLP, and other ensemble methods)
and are not reported here. All results shown in this section is a sample mean
produced by repeated experiments (10 times) under each combination of variables. Error bars represent one standard deviation.
Size-based prediction. We studied cascades of size 50 that reached 500 for this
task. There are 13,285 cascades that can reach the size m = 50 while only 200
out of them reached the size of 500. Maintaining the threshold T H = 500,
Figure 11 shows random forest classifier trained with features in group Am
can outperform the other groups with any of the three community detection algorithms. The tradeoff between precision and recall can be achieved by
changing the training threshold T Htr while maintaining the testing thresh-

18

Ruocheng Guo et al.

Classification Results: TH = 500

0.7
0.6
0.5
0.4

Louvain Am
Infomap Am
SLM Am
Louvain Bm
Infomap Bm
SLM Bm
Cm
Dm

0.3
0.2
0.1
0.0

Precision

Recall

F1 Score

Fig. 11: Classification results based on groups of features (Am ,Bm ,Cm ,Dm )
extracted with three community detection algorithms (Louvain, Infomap and
SLM) when m = 50 for fixed T Htr = 500, T Hts = 500. Error bars represent
one standard deviation.

old T Hts = 500 (see Figure 12). We also note that the average final size of
viral cascades correctly classified by the classifier increases with the training threshold. With threshold T H ∈ {300, 400, 500, 600, 700} on both training
and testing samples, the features introduced in this paper (Am ) consistently
outperform those previously introduced (Bm ) – see Figure 13. The fact that
features in Bm are not able to maintain their predictability over different T H
can be explained as that they only count the number of users on recently exposed users instead of taking the community structure of them or the decay of
probability to repost over time into consideration. As shown in Figure 12a, 12c
and 12e, while the trends relating to this tradeoff are similar among the various community detection algorithms, the Louvain algorithm led to superior
performance for precision and F1. Infomap and SLM generally outperformed
Louvain in terms of recall for both feature sets. We also note that our features
outperform those of Weng et al. regardless of the testing/training thresholds
and the selected community finding algorithm.
Time-based prediction. As shown in Table 2, there are 3,444 cascades in our
dataset reached the size of m = 5 within 60 (min) with only 5% from the
minority class. When the threshold is kept as T H = 500 for both training
set and testing set, we obtain the results shown in Figure 14 again showing
that the features introduced in this paper (At ) outperform the other feature
sets in terms of recall, precision and F1 score, no matter which community
detection algorithm is used. By modifying threshold for training samples only,
two phenomenon are discovered. First, a tradeoff between precision and recall
can be manipulated by controlling the training threshold (T Htr ). This is shown
in Figure 15a, 15c, 15e. Second, as shown in Figure 15b, 15d, 15f, with T Htr
increasing, the average final size of correctly classified viral cascades also grows.
Furthermore, we modify the threshold for training and testing sets together

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

1.0

precision
recall

f1 score

Size (103 )

1.2
0.8
0.6
0.4
0.2

1.4
1.3
1.2
1.1
1.0
0.9
0.8
0.7

300 400 500 600 700
Training Threshold

19

correct
incorrect
mean

300 400 500 600 700
Training Threshold

(b) Average final size of viral cascades (cor(a) Precision, recall, and F1 score for different rectly classified, mean and incorrectly classitraining thresholds, using Louvain algorithm. fied), using Louvain algorithm.

1.0

1.2
precision
recall

1.1

f1 score

Size (103 )

1.2
0.8
0.6
0.4

1.0

correct
incorrect
mean

0.9
0.8
0.7

0.2

300 400 500 600 700
Training Threshold

300 400 500 600 700
Training Threshold

(d) Average final size of viral cascades (cor(c) Precision, recall, and F1 score for different rectly classified, mean and incorrectly classitraining thresholds, using Infomap algorithm. fied), using Infomap algorithm.

1.0

1.2
precision
recall

1.1

f1 score

Size (103 )

1.2
0.8
0.6
0.4

1.0

correct
incorrect
mean

0.9
0.8
0.7

0.2
300 400 500 600 700
Training Threshold

300 400 500 600 700
Training Threshold

(f) Average final size of viral cascades (cor(e) Precision, recall, and F1 score for different rectly classified, mean and incorrectly classitraining thresholds, using SLM algorithm.
fied), using SLM algorithm.

Fig. 12: Prediction results when T Htr = {300, 400, 500, 600, 700} for
Am (Louvain, Infomap and SLM). Error bars represent one standard deviation.

20

Ruocheng Guo et al.

0.8
0.7
0.6
0.5
0.4
0.3
precision
f1 score
0.2
recall
0.1 300 400 500 600 700
Training/Testing Threshold

0.8
precision
f1 score
recall
0.7
0.6
0.5
0.4
0.3
0.2
0.1 300 400 500 600 700
Training/Testing Threshold

(a) Classification results for features in group (b) Classification results for features in group
Am (Louvain)
Bm (Louvain)

0.8
precision
f1 score
recall
0.7
0.6
0.5
0.4
0.3
0.2
0.1 300 400 500 600 700
Training/Testing Threshold

0.8
precision
f1 score
recall
0.7
0.6
0.5
0.4
0.3
0.2
0.1 300 400 500 600 700
Training/Testing Threshold

(c) Classification results for features in group (d) Classification results for features in group
Am (Infomap)
Bm (Infomap)

0.8
precision
f1 score
recall
0.7
0.6
0.5
0.4
0.3
0.2
0.1 300 400 500 600 700
Training/Testing Threshold

0.8
precision
f1 score
recall
0.7
0.6
0.5
0.4
0.3
0.2
0.1 300 400 500 600 700
Training/Testing Threshold

(e) Classification results for features in group (f) Classification results for features in group
Am (SLM)
Bm (SLM)

Fig. 13: Prediction results based on groups of features extracted for m =
50 when T H = {300, 400, 500, 600, 700}. Error bars represent one standard
deviation.

to show the reliability of features in group At is better than ones in Bt (See
Figure 16). Here, we noted similar trends with regard to both feature sets and
community finding algorithms as found in the size-based tests.

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

Classification Results: TH = 500

0.7
0.6
0.5
0.4

21

Louvain At
Infomap At
SLM At
Louvain Bt
Infomap Bt
SLM Bt
Ct
Dt

0.3
0.2
0.1
0.0

Precision

Recall

F1 Score

Fig. 14: Classification results based on groups of features (At ,Bt ,Ct ,Dt ) extracted with three community detection algorithms (Louvain, Infomap and
SLM) when t = 60 for fixed T Htr = 500, T Hts = 500. Error bars represent
one standard deviation.

5.2 Feature Investigation

Here we investigate the importance of each feature in Am (Louvain) and Am
(Louvain) as communities detected by Louvain algorithm achieves the best
classification results out of the three. With T Htr = 500 and T Hts = 500, we
trained 200 randomized logistic regressions models (100 for Am and 100 for
At ) - with each assigning weights to the features in those sets. We then categorized the features with weight larger than 0.01 (on average) into groups such
as overlap, gini impurity, etc. Then, we performed classification on the basis
of single feature group or combination of such groups. The average weights
assigned are shown in Table 4 while classification results (by random forest
with SMOTE) are depicted in Figure 17 for groups and combinations of them.
As shown, overlaps can make significant contribution to the prediction tasks.
Intuitively, communication between two sets of nodes is more likely to happen
in their shared communities - which is consistent with the results of (Ugander
et al, 2012). This implies that the larger overlap value, the more likely one set
would repost from the otherFor example, we can infer that viral cascades tend
to have larger O(Ut , Ft ) value therefore adopters in them have larger chance to
motivate the recently exposed users to repost than non-viral cascades. Figure 6
and Figure 10 provide evidence of this phenomenon.

22

Ruocheng Guo et al.

1.2
1.0

precision
recall

f1 score

Size (103 )

0.8
0.6
0.4
0.2

1.4
1.3
1.2
1.1
1.0
0.9
0.8
0.7

300 400 500 600 700
Training Threshold

correct
incorrect
mean

300 400 500 600 700
Training Threshold

(b) Average final size of viral cascades (cor(a) Precision, recall, and F1 score for different
rectly classified, mean and incorrectly classitraining thresholds, using Louvain algorithm.
fied), using Louvain algorithm.

1.2
1.0

1.2
precision
recall

f1 score

Size (103 )

0.8

1.1

0.6
0.4

1.0

correct
incorrect
mean

0.9
0.8
0.7

0.2

300 400 500 600 700
Training Threshold

300 400 500 600 700
Training Threshold

(d) Average final size of viral cascades (cor(c) Precision, recall, and F1 score for different
rectly classified, mean and incorrectly classitraining thresholds, using Infomap algorithm.
fied), using Infomap algorithm.

1.2
1.0

1.2
precision
recall

f1 score

Size (103 )

0.8

1.1

0.6
0.4

1.0

correct
incorrect
mean

0.9
0.8
0.7

0.2
300 400 500 600 700
Training Threshold

300 400 500 600 700
Training Threshold

(f) Average final size of viral cascades (cor(e) Precision, recall, and F1 score for different
rectly classified, mean and incorrectly classitraining thresholds, using SLM algorithm.
fied), using SLM algorithm.

Fig. 15: Prediction results when T Htr ∈ {300, 400, 500, 600, 700} for At (Louvain, Infomap and SLM). Error bars represent one standard deviation.

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

0.8
0.7
0.6
0.5
0.4
0.3
precision
f1 score
0.2
recall
0.1 300 400 500 600 700
Training/Testing Threshold

23

0.8
precision
f1 score
recall
0.7
0.6
0.5
0.4
0.3
0.2
0.1 300 400 500 600 700
Training/Testing Threshold

(a) Classification results for features in group (b) Classification results for features in group
At (Louvain)
Bt (Louvain)

0.8
precision
f1 score
recall
0.7
0.6
0.5
0.4
0.3
0.2
0.1 300 400 500 600 700
Training/Testing Threshold

0.8
precision
f1 score
recall
0.7
0.6
0.5
0.4
0.3
0.2
0.1 300 400 500 600 700
Training/Testing Threshold

(c) Classification results for features in group (d) Classification results for features in group
At (Infomap)
Bt (Infomap)

0.8
precision
f1 score
recall
0.7
0.6
0.5
0.4
0.3
0.2
0.1 300 400 500 600 700
Training/Testing Threshold

0.8
precision
f1 score
recall
0.7
0.6
0.5
0.4
0.3
0.2
0.1 300 400 500 600 700
Training/Testing Threshold

(e) Classification results for features in group (f) Classification results for features in group
At (SLM)
Bt (SLM)

Fig. 16: Prediction results based on groups of features extracted for t =
60(min) for T H ∈ {300, 400, 500, 600, 700}. Error bars represent one standard
deviation.
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0 Precision

ol
at
gini
ol+at

Recall

gini+at
ol+gini
ol+at+gini

F1 Score

(a) Classification results for subsets of
Am (Louvain): ol means overlap, gini means
gini impurity,P
at represents average time to
50
1
adoption ( 50
i=1 t(i)).

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0 Precision

ol
cs
gini
ol+cs

Recall

gini+cs
ol+gini
ol+cs+gini

F1 Score

(b) Classification results for subsets of
At (Louvain): ol means overlap, gini means
gini impurity, cs represents number of
adopters (|U60 |).

Fig. 17: Classification results (random forest with SMOTE) based on subsets
of features from Am and At (by Louvain algorithm)

24

Ruocheng Guo et al.

Group Name

Features(Am (Louvain))

Weights

Features(At (Louvain))

Weights

IG (Ft(50) )

0.020

IG (U60 )

0.039

IG (Nt(50) )

0.021

IG (U40 )

0.049

IG (Nt(30) )

0.521

IG (F40 )

0.331

O(Ut(30) , Ft(30) )

0.503

O(U60 , F60 )

0.500

O(Ut(30) , Nt(30) )

0.037

O(U60 , N60 )

0.538

O(Ft(30) , Nt(30) )

0.227

O(F60 , N60 )

0.409

O(Ut(50) , Ft(50) )

0.500

O(U40 , F40 )

0.628

O(Ft(50) , Nt(50) )

0.257

O(U40 , N40 )

0.509

O(F40 , N40 )

0.288

|U60 |

0.072

Gini Impurity

Overlap

Baseline

1
50

P50

i=1

t(i)

1.0

Table 4: Weights of features assigned by randomized logistic regression models

6 Related Work
Early works about popularity prediction with data driven approach simplified
the problem of cascade prediction as modeling one step information propagation Galuba et al (2010); Bian et al (2014); Zhang et al (2013) or as predicting
the near term popularity Gupta et al (2012). As the real pioneer of cascade
prediction, the work (Bakshy et al, 2011) devised a regression model for this
task and was one of the first attempts to explore this problem. They noted
that the severe imbalance of the data due to a power-law relationship between
cascade size and frequency (which we also observed) hindered the creation of
useful model - they obtained an R2 value of only 0.3 for their regression model.
The later work of (Jenders et al, 2013) also studies the problem, again taking a machine learning approach and identify several useful features to obtain
relatively high precision and recall. However, in their evaluation, they artificially balance the dataset - they ensure that each fold had equal amounts of
viral and non-viral tweets. The work of (Cheng et al, 2014) predicts “viral”
cascades with high precision and recall, but defines “viral” as cascades that
can double in size (which also has the effect of balancing the classes in the
dataset). The very recent work of (Weng et al, 2014) also looks at predicting viral cascades and does leverage some community-based features, some of
which are also inspired by structural diversity - though their structural diversity features are more limited than in this study - we perform a comparison
with their structural diversity method (see previous section). In a nutshell,
there are two main points differing our work from the ones mentioned in this
section: (1). the method proposed by this paper does not need the content of
microblogs or the underlying topology based on friendship relationships (2).
this method is able to provide a reliable performance in prediction of order-of-

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

25

magnitude increase of cascade size. In a conference version of this paper (Guo
et al, 2015) we described the basics of tis approach. However that work did not
include time-based results, examination of various underlying community finding algorithms and how each sub-group of features performs in independent
classification experiments.
In addition to the work on cascades, there is much related work on structural diversity. This concept was first studied in (Ugander et al, 2012) and
later explored in the work of (Zhang et al, 2013; Shakarian et al, 2014; Li
et al, 2015; Bao et al, 2013a,b; Huang et al, 2013). However, these papers
leverage structural diversity for a variety of other social network applications
including the creation of new diffusion models, the study of peer influence,
identifying influential nodes, and ranking communities. Finally, we note that
the popular work on diffusion in the areas of computer science (Kempe et al,
2003), physics (Gallos et al, 2010), and biology (Lieberman et al, 2005) have
led to a ground swell of research on this topic over the past decade, please see
(Shakarian et al, 2015) for a review of major results.

7 Conclusion
In this paper, we explored the effect of structural diversity on a diffusion
process which allowed us to predict viral cascades. Moving forward, we look to
integrate our structural-diversity approach with content information (which
we believe will further increase performance) as well as study how to best
operationalize this method in a system to detect viral cascades in near-real
time.

8 Acknowledgment
Some of the authors of this paper are supported by by AFOSR Young Investigator Program (YIP) grant FA9550-15-1-0159, ARO grant W911NF-15-10282, and the DoD Minerva program. Portions this work were also disclosed
in U.S. provisional patent 62/201,517. A non-provisional patent is currently
being filed.

References
Alstott J, Bullmore E, Plenz D (2014) powerlaw: a python package for analysis
of heavy-tailed distributions
Bakshy E, Hofman JM, Mason WA, Watts DJ (2011) Everyone’s an Influencer: Quantifying Influence on Twitter. In: Proceedings of the Fourth
ACM International Conference on Web Search and Data Mining, ACM, New
York, NY, USA, WSDM ’11, pp 65–74, DOI 10.1145/1935826.1935845, URL
http://dx.doi.org/10.1145/1935826.1935845

26

Ruocheng Guo et al.

Bao P, Shen HW, Chen W, Cheng XQ (2013a) Cumulative effect in information diffusion: empirical study on a microblogging network. PloS one
8(10):e76,027
Bao Q, Cheung WK, Zhang Y (2013b) Incorporating structural diversity of
neighbors in a diffusion model for social networks. In: Web Intelligence (WI)
and Intelligent Agent Technologies (IAT), 2013 IEEE/WIC/ACM International Joint Conferences on, IEEE, vol 1, pp 431–438
Bian J, Yang Y, Chua TS (2014) Predicting trending messages and diffusion
participants in microblogging network. In: Proceedings of the 37th international ACM SIGIR conference on Research & development in information
retrieval, ACM, pp 537–546
Blondel VD, Guillaume JL, Lambiotte R, Lefebvre E (2008) Fast unfolding
of communities in large networks. Journal of Statistical Mechanics: Theory
and Experiment 2008(10):P10,008
Breiman L, Friedman J, Stone CJ, Olshen RA (1984) Classification and regression trees. CRC press
Chawla NV, Bowyer KW, Hall LO, Kegelmeyer WP (2002) Smote: synthetic
minority over-sampling technique. Journal of artificial intelligence research
16(1):321–357
Cheng J, Adamic L, Dow PA, Kleinberg JM, Leskovec J (2014) Can cascades
be predicted? In: Proceedings of the 23rd international conference on World
wide web, International World Wide Web Conferences Steering Committee,
pp 925–936
Gallos L, Havlin S, Kitsak M, Liljeros F, Makse H, Muchnik L, Stanley H
(2010) Identification of influential spreaders in complex networks. Nature
Physics 6(11):888–893
Galuba W, Aberer K, Chakraborty D, Despotovic Z, Kellerer W (2010) Outtweeting the twitterers-predicting information cascades in microblogs. In:
Proceedings of the 3rd conference on Online social networks, vol 39, p 3âAS3
Grabowicz PA, Ramasco JJ, Moro E, Pujol JM, Eguiluz VM, et al (2012)
Social features of online networks: The strength of intermediary ties in online
social media. PloS one 7(1):e29,358
Guo R, Shaabani E, Bhatnagar A, Shakarian P (2015) Toward order-ofmagnitude cascade prediction. In: Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining
2015, ACM, pp 1610–1613
Gupta M, Gao J, Zhai C, Han J (2012) Predicting future popularity trend of
events in microblogging platforms. Proceedings of the American Society for
Information Science and Technology 49(1):1–10
Huang X, Cheng H, Li RH, Qin L, Yu JX (2013) Top-k structural diversity
search in large networks. Proceedings of the VLDB Endowment 6(13):1618–
1629
Jenders M, Kasneci G, Naumann F (2013) Analyzing and predicting viral
tweets. In: Proceedings of the 22Nd International Conference on World Wide
Web Companion, International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, WWW ’13 Compan-

Toward Early and Order-of-Magnitude Cascade Prediction in Social Networks

27

ion, pp 657–664, URL http://dl.acm.org/citation.cfm?id=2487788.2488017
Kempe D, Kleinberg J, Tardos E (2003) Maximizing the spread of influence
through a social network. In: Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM,
New York, NY, USA, KDD ’03, pp 137–146, DOI 10.1145/956750.956769,
URL http://doi.acm.org/10.1145/956750.956769
Li RH, Qin L, Yu JX, Mao R (2015) Influential community search in large
networks. Proceedings of the VLDB Endowment 8(5)
Lieberman E, Hauert C, Nowak MA (2005) Evolutionary dynamics on graphs.
Nature 433(7023):312–316, DOI 10.1038/nature03204
Pei S, Muchnik L, Andrade Jr JS, Zheng Z, Makse HA (2014) Searching for
superspreaders of information in real-world social media. Scientific reports
4
Raghavan UN, Albert R, Kumara S (2007) Near linear time algorithm to
detect community structures in large-scale networks. Physical Review E
76(3):036,106
Rosvall M, Bergstrom CT (2008) Maps of random walks on complex networks
reveal community structure. Proceedings of the National Academy of Sciences 105(4):1118–1123
Shakarian P, Gerdes L, Lei H (2014) Circle-based tipping cascades in social
networks. In: WSDM Workshop on Diffusion Networks and Cascade Analytics
Shakarian P, Bhatnagar A, Aleali A, Guo R, Shaabani E (2015) Diffusion in
Social Networks. Springer (in press)
Ugander J, Backstrom L, Marlow C, Kleinberg J (2012) Structural diversity in social contagion. Proceedings of the National Academy of Sciences
109(16):5962–5966
Waltman L, van Eck NJ (2013) A smart local moving algorithm for large-scale
modularity-based community detection. The European Physical Journal B
86(11):1–14
Weng L, Menczer F, Ahn YY (2014) Predicting successful memes using network and community structure. In: Eighth International AAAI Conference
on Weblogs and Social Media
Zhang J, Liu B, Tang J, Chen T, Li J (2013) Social influence locality for modeling retweeting behaviors. In: Proceedings of the Twenty-Third international
joint conference on Artificial Intelligence, AAAI Press, pp 2761–2767

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Cyber Attacks and Public Embarrassment:
A Survey of Some Notable Hacks
Jana Shakarian, Paulo Shakarian, and Andrew Ruef
We hear it all too often in the media: an organization is attacked, its data, often containing personally
identifying information, is made public, and a hacking group emerges to claim credit. In this excerpt, we
discuss how such groups operate and describe the details of a few major cyber-attacks of this sort in the
wider context of how they occurred. We feel that understanding how such groups have operated in the
past will give organizations ideas of how to defend against them in the future.

Hacking Group Modus Operandi: the Case of Anonymous
"I think what is, important about Anonymous is that it
works, I don't know how it works but it works"
Australian Anon quoted in NineMSN, 05/08/20081

A video, mostly published on YouTube, announcing a new campaign kicked off many projects in
the past.

2

Additionally, every “operation” (“AnonOp”) is declared beforehand on Twitter

(@YourAnonNews, @Anon_Central), tumblr (youranonnews.tumblr.com) and first-hand Anonymous
websites, such as anonnews.org and whyweprotest.net. Other commonly used outlets are Pastebin, Pirate
Bay3 and Facebook (Anonymous News Network).4 Internet Relay Chats (IRC) and image boards, Internet
forums, as well as wikis serve the purpose of online communication and coordination.i These as well as
the partyvan.info 5 hosted raid boards and IRCs as well as those run by AnonOps (anonops.ru,

Especially 4chan, 711 chan, Encyclopedia Dramatica, IRC channels, YouTube, and (supported) blogs
(e.g. anonops.blogspot.com (by invitation only), Legion News Network and AnonNews.org as news outlets,
whyweprotest.net (Anonymous supported website originally in support of operation Chanology, but
expanded to service the organization of protest initiatives and campaigns, grass root activism), and
Anonywebz.com (Anonymous tool network), social networking services like Twitter and Facebook are
used to organize real world protest
i

1

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

anonops.net) are apparently used to garner support for ideas from individual Anons. The websites of
collaborating hacktivist groups, too, may explain the mission and extend the opportunity to participate to
the visitor.6 One chan user might post a call to arms where s/he perceives something is wrong or has
potential of being fun. If enough other users agree a date is set on which the operation is launched.7 If the
initial recruiting process was unsuccessful, nothing will happen. Factors that might motivate an
Anonymous-attack (i.e. further the recruitment process to an individual idea) are the lulz-potential i ,
perceived arrogance of the potential target, and perceived Internet censorship or other ethical or moral
challenges.8 The latter may be secondary or even afterthought for the mere justification of the hacks for
the public eye and the decisive moment is the actual possibility to achieve the desired results (although
the ensuing real world consequences may not necessarily have been anticipated fully).9
The most often employed tactic in Anonymous & Co.’s campaigns is the distributed denial of
service attack (DDoS). As with the some of the other DDoS attacks discussed in previous chapters, the
DDoS attacks of Anonymous rely on DDoS tool provided to the hacktivist participants. These tools were
somewhat more advanced than the software used by Russian hacktivists in the Georgia cyber campaign
(chapter 3), but unlike the “voluntary botnet” used by pro-Israel supporters against Hamas (chapter 4)
they do not allow a central C&C total control over the user’s computer. The creation of such tools allows
Anons to participate with virtually no hacking skills – while still contributing their computing resources.
The most widely known software of this sort in use by Anonymous includes the Low Orbit Ion Cannon
(LOIC) and the RefRef web script10. The latter of which was meant to replace the former in September
2011 since LOIC retains the IP-address of the senders, which lead to numerous arrests of Anons.11 The
RefRef web script is a command-line based Java site which exploits SQL and Javascript vulnerabilities in

i

According to Adrian Crenshaw (“Crude Inconsistent Threat”) this is what appears to draw the most
supporters

2

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

order to exhaust the server supporting the website.i The Low Orbit Ion Cannon is a legitimate tool to
stress-test a web-application by sending a large amount of requests to the webpage to see, if it can handle
it (“bandwidth raep”). It was written in C#, is available in three versions (manual, server-controlled, and
in JavaScript) and can be found on any major open source code repository. Individual users download the
application and opt their computer to become part of the botnet which is employed in Anonymous’
DDoS-attacks; one form of membership is thus the mere contribution of computing power to
Anonymous’ resources. LOIC also features a connection to an IRC channel in order to coordinate the load
of packets send from the individual computers. Unbeknownst to a large number of participants in illegal
DDoS-attacks may be the fact that LOIC does not encrypt or hide the IP-addresses of the senders. The
target computer’s website logs all IP-addresses of incoming requests which in turn can be traced back to a
single computer. 12
Another prevalent Anonymous tactics requiring somewhat more hacking skills, but less
computing resources is the SQL injection, which exploits weaknesses in the database of a website –
previously described in chapter 3. In its attack on HB Gary Federal and its head, Aaron Barr, a handful of
Anonymous and affiliated hackers gathered compromising documents and emails this way. Captured data
usually is “dumped”, i.e. published on Pastebin or most recently on Anonpaste. More rarely, the obtained
data is used for In Real Life (IRL) pranks – the staging of real world events such as unwanted pizza
delivery or using social engineering to have a SWAT team called to the respective residence
(“swatting”).13 Other ends through the mean of SQL injection include the defacement of websites, in
which the original content is substituted by pictures or messages of the intruders or the hijacking and/ or
redirection of the target website. In the latter cases the website would either cease to be under the control
of its original authors or redirect to another site as selected by the hacker(s).

i The tool exploits the fact that most web sites save the .js file of an incoming request on their own server, since the
request is still working the packets bounce back and forth on the target server, exhausting its resources (THN,
07/07/2011)

3

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Targeting Governments, Corporations, and Individuals: Notable Hacks on Anonymous
Anonymous meanwhile is featured in the media almost every week with either claiming or being
found responsible for cyber-attacks against selected targets. It would not make any sense to recap a
chronology of Anonymous’ attacks as the resulting long list would probably have a lot of holes: the media
coverage of Anonymous- acts depends either on largesse or popularity of the target.
Habbo Hotel Raids
Long before Anons engaged in hacks for which the collective know is famous and feared for,
4chan’s Ur-Anonymous raided their targets. Protesting against Habbo’s ban on African-American avatars
and accusing Habbo’s social moderators of racism the virtual game made a great target for raids. Habbo
Hotel raids began in mid-2005 in which avatars looking like a wealthy African-American in business suit
(to some reminiscent of the Samuel Jackson’s Pulp Fiction character Jules) obstruct entry to the pool.
This hack already signifies two important motifs for the collective action of the Anonymous we know
today: perceived discrimination as well as the humungous lulz potential.14

4

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Figure: During the Habbo hotel raid, members of 4chan protested against the ban on
African-American avatars by creating avatars of African-American businessmen who blocked
access to the pool. Source: KnowYourMeme15

“Pool’s closed” became a catch-phrase for the Habbo raids that resulted in 4chan exercising
otherwise rare censorship and moderation. A year later Habbo -raids culminated in an unprecedented
organized raid across four countries (UK, USA, Germany, and Australia) that resulted in the site being
knocked offline. The Habbo-raids are also a precedent for the counterproductive actions that bring about
what (at least part of) the momentary Anonymous force set out to prevent in the first place and which will
form the core of the criticism of Anonymous years later: In the aftermath of the summer 2006 attacks
Habbo Hotel administrators programmed the automatic ban of African-American avatars with afro and
suit.16

Internet Vigilantism
In December of 2007 in an act of Internet vigilantism17 Anonymous hackers aided the arrest of
Canadian Chris Forcand by impersonating teenage girlsi.18 He would subsequently be brought to court on
charges related to pedophilia. 19 In summer 2012, Anonymous followed up on this initiative against
pedophiles in launching the Twitter hashtag “#TwitterPedoRing” to invite pedophiles on the
communication network to join. Week later 190 offenders were arrested by the U.S. Immigrations and
Customs Enforcement, though no reference to Anonymous was made. In August 2012 the Anonymous
Twitter account, @YourAnonNews, asked its 615,000 subscribers to report the account “@many501611”
spam who had published pornographic pictures of young boys. 20 Other,

instances in which the

i

The online threads from the perspective of the anonymous collective of b/tards are saved on 4chan’s archive
here: http://4chanarchive.org/brchive/dspl_thread.php5?thread_id=42828652&x=brb%20church%20%20chris%20forcand

5

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

propagation of evidence of perceived injustice through the Internet resulted in real-life consequences for
the perpetrator include a South Korean girl who refused to clean up after her dog on a subway and whose
subsequent harassment brought her on the brink of suicide, the tactless Zhang Ya, whose inhuman
remarks on the suffering of the victims of the Sichuan earthquake in 2008 eventually got her arrested,
American pioneer spammer, Alan Ralsky, receiving mailbox spam in truck loads, the New York City cop,
Patrick Pogan, who attacked an unsuspecting cyclist and would have gotten away with it, if it was not for
the video of the incident being spread all over the Internet.21 Internet vigilantism is neither an invention of
4chan nor the Anonymous collective nor constrained to North America.i

Project Chanology
Anonymous first real-world protest brought thousands donning Guy Fawkes masks onto the
streets in numerous cities and countries to protest against the Church of Scientology. Churches
experienced real-world pranks, like harassing phone calls, black faxes (in order to waste ink)22, pizzas and
taxis they did not order23 as well as letters with what turned out to be harmless white powder24. Project
Chanology was sparked by the leak of an insider video of an interview with actor Tom Cruise talking
about his life in the sect.25 The subsequent forceful attempts by the Church to retract the video were
perceived as a metaphorical example for the general restrictiveness the organization is often criticized for.
The initial momentum that kicked of immense headaches for the Church of Scientology was an
anonymous post on 4chan/b: “it is time to do something great”.26,27 In January 2008 self-confessed Anons
originating from image boards like 4chan, Partyvan.org, and 711chan amongst others officially launched
“Project Chanology” by posting a video on YouTube entitled “Message to Scientology”. 28 Besides the
real-world protests, Anons rendered the official website of the Church of Scientology inaccessible by way

i

Clay Shirky authored an insightful book (“Here Comes Everybody – The Power of Organizing Without
Organization”) on online group action, which argues that it does not only take new forms of technology, but also
new forms of behavior.

6

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

of DDoS-attacks and captured and published literature for which adherents normally have to pay.29, 30 In
the course of three weeks, Project Chanology encouraged over 8,000 harassing phone calls, 3.6 malicious
emails, 141 million hits against the church web sites, 10 acts of vandalism, 22 bomb threats, and 8 death
threats.31 The Internet activists employed online tools like JMeter and Gigaloader in DDoS-attacks and
the exploit of computer security vulnerabilities like Cross-site Scripting.32 Botnets and the Low Orbit Ion
Cannon (LOIC) had their debut as Anonymous’ tools in Project Chanology.33, 34 Scientology responded
with attempts to obtain restraining orders for their premises and identify the Anons who organized local
protests. One of the exposed, Gareth A. Cales of Los Angeles reported legal threats and general
harassment by Scientology members. 35 His account also includes details on the organization of the
protests associated with Project Chanology. Mark Bunker and other critics of the Church of Scientology
released a video encouraging the protests to remain legal and were surprised that Anons appeared to heed
the advice. 36 Four years later, in February 2012, still some protesters wearing Guy Fawkes masks
beleaguer Scientology churches.37 The two-pronged approach showed effect: The resounding response to
the Project Chanology not only made the organizers aware of the possibilities of the online organization
of a social movement, but it also appears to have refined Anonymous’ character. While the majority of
the Anonymous collective prior was interested in the lulz-potential of an undertaking38, with the protest
against an enigmatic organization known for its attempts to censor public information about itself, many
Anons appear to be spurred by the perceived righteousness of this quest. 39

Arab Spring
Anonymous targeted government websites of countries in North Africa and the Arabian Peninsula
as well as Asia Minor that found themselves engulfed in civil uprisings in 2011 – the Western world
would call it hopefully “Arab Spring”. Anons used their computers and knowledge to support the
protesters on the ground, whose governments in many cases had resolved to deny them access to social
media or the Internet altogether. For each country, Anonymous launched a new “operation”. Starting with
7

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)
“Operation Tunisia” and “Operation Egypt” affiliates of the collective and sympathizers took down the
governments’ computers with DDoS-attacks.40

Figure: 2011, Anonymous consequently took up the fight with the Syrian government after it
clamped down violently on public protesters.Source: PLF, Operation Syria41

The PLF’s Commander X boasted in a chat-interview that his organization kicked off Tunisia’s
“Jasmine Revolution” by stealing compromising information on the government and leaking it to
WikiLeaks.42,43 Other media outlets stress the dire living conditions in Tunisia, amongst others the high
unemployment and inflation as well as the lack of political freedom as causes taken to Tunisian streets
after the self-immolation of Mohamed Bouazizi on December 17, 2010. 44,45 The press acknowledged
Anonymous’ support of the protesters on the ground by taking down at least eight government websites
with DDoS-attacks (including websites of the president, prime minister, the ministries of foreign affairs
and industry, as well as the stock exchange)46 and defacing some of them47. Anonymous also provides
means and knowledge to activists on the ground to conceal their online identity in order to prevent
prosecution and coordinate their activities with the events on the ground.48 As Commander X stated in
regard to their participation in various episodes of the “Arab Spring”, besides the admittedly mostly
negative attention Anonymous and its collaborators earn with each campaign, the goals are to deny the
targets (here: governments) lines of communication and to “encourage the protesters on the ground”.49
8

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

The initial motivation to join in the uprising for one Anon was the Internet censorship as exercised by the
Tunisian government.50 Subsequently a host of Anons identified with the struggles of the revolutionaries
in the respective countries and sought to alleviate their plight by doing whatever they could to provide
them with avenues for information exchange51 while at the same time denying them to their opponents.
The Tunisian governments attempt to identify political activists by phishing online for their social
networking or email accounts 52 was countered by a subdivision of Anonymous, the Internetfeds. A
greasemonkey script made available to the Tunisian protestors would override the governments’
spyware.53 They also translated and distributed information on how to conceal IP-addresses and other
techniques to obscure individual identities in French and Arabic.54 Anonymous’ involvement did not stop
with the ouster of Zine el Abidine Ben Ali. The new Tunisian Anons proceeded to use online tools to
fight alongside the new moderate Tunisian government against the pressure it experienced from Islamist
fringe groups. 55 To circumvent Internet censorship in Egypt, Anonymous aided in the restoration of
proxies and mirrors in order to guarantee information flow to benefit the revolutionaries.56 The Egyptian
authorities had blocked twitter.com and other social media apparently in order to aggravate
communication between protestors.57 Anons targeted websites of the Egyptian government and ministries
with DDoS-attacks.58 In both operations the trickster-natured among the Anons still found pleasure in
real-world pranks, like flooding the respective embassies with unwarranted pizza-orders. 59 In August
2011, Anonymous consequently took up the fight with the Syrian government after it clamped down
violently on public protesters. The website of the Syrian Ministry of Defense was defaced with an
encouraging message to the Syrian people.60
Besides the above mentioned, the governments of Yemen61,62, Algeria63, Zimbabwe64, and Italy65
also drew the ire of the online collective, which targeted associated websites with more or less extensive
DDoS-attacks.66 The predecessor to these diverse operations associated with the “Arab Spring” could

9

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)
perhaps be found in Anonymous’ engagement in Iran’s post-election crises in 2009. Back then Anons
intercepted the propagation of hit lists depicting protestors distributed by pro-government groups.67

HBGary Federal and Aaron Barr
The InternetFeds, an AnonOps spin-off of skilled black hat hackers engaged in what appears to be
a “personal” vendetta on Aaron Barr, HBGary’s CEO, who had claimed to have identified key actors after
infiltrating Anonymous.68 After mocking Barr online and obtaining all his passwords via SQL injection
the hackers were amused to have him “watch” how they hijacked his email and all Internet social media
and stole data from internal company emails he had sent to his coworkers.69 DDoS attacks brought down
hggary.com and hbgaryfederal.com.70 The latter was breached using SQL injection, which exploited a
security flaw in the custom-made content management system (CMS) the company had employed.71 So
called rainbow tables appeared to have immensely alleviated the quest to garner the hashed passwords of
Aaron Barr and COO Ted Vera.72 Barr had apparently re-used one password over and over, “kibafo33”,
which allowed access to other company email-inboxes since Barr enjoyed administrator rights. 73
Ultimately this led to compromising HBGary’s founder, Greg Hoglund’s rootkit.com website by way of
hijacking his email account. The hackers then impersonated Hoglund in an email-conversation with an
associate in order to obtain the last bits of information necessary to gain control over rootkit.com. 74
Besides defacing the website, the intruders also resolved to publish the user database. 75 Ted Vera’s
repeatedly used password enabled the hackers to access the support server that hosted the shell accounts
of many HBGary employees and which enabled them to upgrade Vera’s personal account through the
exploitation of a personal escalation vulnerability, which gave the hackers full access to HBGary’s
system.76 Gigabytes of data were now immediately at the hand of the intruders. More than sixty thousand
company emails were published on the Pirate Bay file-sharing site.77 Another case apparently motivated
by revenge was the hack into Sony’s online Playstation store and the DDoS-attack against the Playstation
10

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)
website. 78 Sony had sued PS3-hacker George Hotz (aka “GeoHot”), who had become famous for
unlocking various iPhone versions79 before he managed to gain administrator-rights to the entire system
memory and the processor of the PS3 system in early 2011. 80 An abrupt settlement in the case was
reached in April 2011 with neither side disclosing the full terms, but on the part of the phreaker/hacker
was the deletion of all his information on the PS3-hack from the Internet.81 Hotz was subsequently hired
by Facebook, but found himself just months later with Lady Gaga’s start-up social networking site,
Backplane.82

Straightforward Operations
Anonymous’ goals become apparent when looking at those campaigns that aim at institutions that
are either held responsible or perceived to embody the objectionable with DDoS-attacks. In some cases
sensitive material is published after the successful intrusion of hackers into the target’s system. A
prominent example is the charge under which attacks against copyright companies were launched. The
effort was later extended to also aim at companies that ceased business relation with the whistle-blower,
WikiLeaks, after the publishing of sensitive U.S. diplomatic cables (Operation Payback). 83 In this
instance, Anonymous officially became a supporter of WikiLeaks, its co-founder, Julian Assange as well
as Bradley Manning, a U.S. soldier who had leaked confidential information on America’s military
campaign in Iraq.
The term “anti-security” refers to a movement conceived in the late 1990s to counteract the
cyber-security industry’s tactic of provocatively exploiting vulnerabilities in order to increase sales 84 .
Apparently, Anonymous joined by LulzSec85 takes the viewpoint that governments employ similar tactics
to justify legislation that monitors Internet behavior and allows censorship and surveillance (Operation
AntiSec). In its quest to safeguard online privacy, the hacktivists encouraged the defacement of
government websites and leaking of data obtained through breaches into the systems government
11

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

organization, banks and other institutions deemed to profit from infringements on user privacy. 86 Other
digital rights-related reasons for hacks under the AntiSec banner are racial profiling, copyright laws and
the War on Drugs87. The attack against the British SOCA presented the debut of AntiSec, followed by the
publication of material from the Cyberterrorism Defence Initiative Sentinel program88, and the release of
private information apparently obtained through SQL-injection from sources related to the governments
of Brazil, Zimbabwe, and Tunisia. So far Anonymous attacked U.S. defense contractor Booz Allen
Hamilton, U.S. Central Command, U.S. Special Operations Command, U.S. Marine Corps, and the U.S.
Air Force in a spree dubbed “Military Meltdown Monday”.89 The December 2011 Stratfor-hack where
subscribers’ credit card information and emails were stolen and later published on WikiLeaks was also
perpetrated by the LulzSec member(s) now working under the Anonymous banner90.
Other campaigns launched under the Anonymous banner include Operation Vendetta91 launched
after a wave of arrests of alleged Anonymous-affiliated hackers in March 2012 to help Anons escape the
authorities. This campaign is the second one to date that entails a major real-world component in that it
aims to set up safe-houses and an “underground railroad”92 to lead sought-after hackers to countries which
don’t have extradition treaties with the prosecuting authorities. A popular hacktivist who apparently
benefitted from this operation is Christopher Doyon aka Commander X, whose People’s Liberation Front
had joined forces with Anonymous in this campaign again. After having been arrested in Santa Cruz,
California, as the “homeless hacker”93 who protested against a recent county ban on outdoor sleeping by
launching DDoS-attacks94, Doyon reportedly found an interim sanctuary in Canada95.

Software for the Legion: Anonymous Products
In early 2012 Anons engaged in the creation of software. Partially in protest to existing
applications, such as the social music platform, AnonTune, and partially in the quest of opening new

12

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

avenues beyond hacking as in the launch of its operating system, Anonymous OS live. Besides the filesharing site, AnonPaste, the collective also launched a WikiLeaks-like site in an attempt to control and
deepen the public impact of their hacking activity96. Both platforms were meant to serve as data dumps.
AnonTune
In April 2012 Anonymous launched a social music platform that provides streaming songs from
third party users (e.g. YouTube) for users to compile into playlists and share. Initiated by online
discussions the ambitions of an individual, who created and uploaded a prototype, generated the technical
support necessary to render AnonTune capable of handling large requests aside from the user interface 97.
It is planned that AnonTune will grant its users anonymity, shielding them from prosecution and
copyright law suits while offering a service better organized and less expensive than similar platforms. 98
Upon its launch AnonTune will be a project borne purely of the Internet. Once more, the creators of this
online forum must not have ever been in personal physical contact and may even be spread out over
different continents.

AnonPaste
After the operators of PasteBin, hitherto Anonymous’ favorite forum to publish captured data,
was found to be compromised, Anonymous affiliates associated with Operation Anti-Sec together with
the People’s Liberation Front launched its own data-sharing website, AnonPastei, in April 2012.99 Jeroen
Vader, owner of PasteBin, announced an increase in censorship of the site100. He further admitted that at
times he shares his logs -a register of the IP-addresses of users - with law enforcement agencies, which

i

Anonpaste.org, last accessed 05/12/2012 – no entries

13

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

drew immediate recognition on the part of Anonymous, which introduced its new website with the
following comment:
"As a recent leak of private emails show clearly, Pastebin is not only willing to
give up IP addresses to governments – but apparently has already given many
IPs to at least one private security firm. And these leaked emails also revealed a
distinct animosity towards Anonymous”
(RT.com 23 Apr 2012)

AnonPaste allows the user to determine when the post is to be deleted at a time increment of his
or her choosing. The creators of this new haven for captured data promote a secure forum without
advertisements, censorship or connection logs, and which retains only encrypted data.101 AnonPaste was
registered in the New Zealand –administered Tokelau (.tk) which allows everybody to register a free
domain. It relies solely on donations as advertisements are not featured.102

When WikiLeaks sought to verify the data captured during the intrusion into the intelligence
company, Stratfor in December 2011, part of Anonymous was frustrated with the slow release of their
bounty and launched Par:AnoIA (Potentially Alarming Research: Anonymous Intelligence Agency). It
also appears to be an attempt at solving a problem high-volume websites are struggling with everywhere:
the sensible organization of humungous amounts of data.103 The Anons who run the page say their sole
task is to present the data others from the Anonymous collective have hacked in a usable format. 104 At the
time of writing neither AnonPaste nor Par:AnoIA were workable websites.

Anonymous-OS 0.1/ Live

The Ubuntu 11.10 -based operating system released for “education purposes”105, Anonymous OS
Live allegedly performed security checks on websites testing for password-security and simulating
DDoS-attacks.106 As default search engine it used DuckDuckGo and it came with a host of pre-installed
applications, which included Tor, Slowloris and AnonymousHOIC. 107 In its initial news release The

14

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Hacker News warned that a genuine source of the operating system is not apparent and that it could be
“backdoored” by law enforcement or affiliated hackers. 108 Accompanying the software a Tumblr and
About page provided news and updates and the disclaimer that the user - not the developers - is
responsible for any illegal use of the operating system.109, 110

Figure: Screen-shot of the Anonymous Operating System - essentially a Linux distribution. Source:
Softpedia, 03/16/2012111

In the four days following its release the operating software was downloaded over twenty-six
thousand times and enjoyed user ratings of 62%.112 The free application was quickly marred by doubts
about its true origin and the website hosting its free download, SourceForge, eventually closed the project
site and removed the downloads from its server.113 Official Twitter accounts, AnonOps, YourAnonNews,
and AnonNewsSec, warned it was “wrapped in Trojans”114 while its creators denied it was spyware.115, 116

In July 2012 an effort to represent itself in the media world without the bias other news outlets117
are accused of carrying took forms in “AnonPR” (anonpr.net, complete with newsletter subscription) and

15

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)
“Anonymous Analytics” (anonanalytics.com, featuring “research” and a mirror of media reports on
Anonymous).

Chapter Summary
This chapter represents the attempt to outline what the hitherto most notorious hacker collective,
Anonymous, might look like on a whiteboard. Publically available hints towards its structure had been
followed and explored: the possible initial “directorate” recruited from an idealist veteran hacking group
as well as the better known online seedbed, a mingling place for contempt and counterculture. Whatever
the beginnings, Anonymous is driven by a set of motivations largely shared by those whose actions are
most visible: freedom of information and the right to online privacy. There are a certain number of online
arenas which are used to decide upon, plan and organize a hack – mostly using SQL-injection or a related,
basic hacker skill that grants access to target systems. Personal, confidential and otherwise compromising
data is later dumped on one or more popular file-sharing sites mainly to give evidence of the intrusion.
Mostly after capturing sensitive data, but not requiring this more or less clandestine step a DDoS-attack is
used to render the target website inaccessible. In some cases website defacement prominently displayed
the reason and goals of Anonymous’ interference. Over its history the collective experienced dedicated
functional spin-offs (e.g. LulzSec) or ideological derivatives who sought to be more “pure” (e.g. MalSec)
whose history and demise is antidote as well as defining element of Anonymous’ structure. The political
hacktivists also encountered like-minded collaborators (e.g. PLF), who probably helped emphasize this
facet of the collective. Finally, this chapter sought to display representative motivations, modi operandi,
and tools through the brief description of select hacks. In the wake of Anonymous’ refocusing or just the
skilled public relation work of a few Anons, the chapter concludes with examples for the nascent stage of

16

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

products: a music portal, two dumping sites and a highly controversial, quickly retracted operating
system.
Anonymous might be more the history of hacking exploits than a social structure, but in the role
of Sabu alone it contradicts its claims of being a legion of countless “everybodies.” Sabu organized,
motivated and lead many of the highly popularized hacks in 2011. His absence after the March 2012
arrests was noticeable and it forced LulzSec to reinvent itself. The global wave of arrests in 2011 and
especially those in early 2012118 are perceived by some as crippling for the Anonymous collective 119,
which can only be the case for an organization that is hierarchically structured. Detentions can have
effects on the activity-level of a group only, if the arrested individuals were crucial in the organization of
the activities. Whether there is or was a handful of people conceiving and directing the politically aware
and active Anonymous, the collective appears to be much more than a loosely-knit organization now. The
collective action presented in its every hack represents an enormous challenge not only to the reader who
seeks to wrap her head around this virtual phenomenon, but also to the social scientist. Initially selfproclaimed members of the collective without any real-world connection to fellow hacktivists, political
Anons may form real local groups with regular meetings and faces, real names. In the virtual meeting
spaces (user) name recognition still applies and allows for virtual groups and Anonymous-spin offs to be
formed. But the numerical majority of the collective remains elusive with many different levels of
possible engagement ranging from sympathizers to participants in DDoS-attacks. The world-spanning
virtual social network, which conceives, decides, plans, and organizes hacking exploits is what and who
Anonymous really is: a number of IRC-channels, blogs and message boards accessed from (at least)
several hundred thousand devices all around the globe. 4chan might have been its cradle, but so far it
seems Anonymous has risen beyond this tactless, seedy playground with its bored opportunists, tricksters
and hustlers.

17

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

So far it seems the political activists have by and large conquered the movement, though it cannot
completely abandon its trickster nature. The Janus-faced character of the collective is reflected in its every
aspect from activity, to the motivation and the understanding of itself is due to the myriad of individuals
who have used the Anonymous platform for very different reasons. In a handful of interviews some selfproclaimed Anons try to fixate an image for the collective, but due to the elusiveness of its membership it
will be difficult to instill and maintain. The political hactivists the Anonymous collective depend on its
favorable depiction in the media since the nature of its preferred modus operandi, the employment of the
low-orbit ion cannon in DDoS-attacks, hinges on a large number of volunteers. The advance in new
alleyways with the launches of the Anonymous operating system, the music sharing website as well as the
data dump sites, albeit with different levels of success, help diversify the collective, but are also evidence
of the lack of guidelines for members, that could serve as identity markers.

Suggested Further Reading
Parmy Olson’s 2012 book We Are Anonymous – Inside the Hacker World of LulzSec, Anonymous,
and the Global Cyber Insurgency, is a very readable synergy of documentary and novel that explores
aspects of the Anonymous collective by following the exploits of a fictitious hacker. Some of Olson’s
story is mirrored in insider Cole Stryker’s account of the legendary 4chan message board in Epic Win for
Anonymous – How 4chan’s Army Conquered the Web (2011).
For a more, general perspective on how the Internet has changed social movements, we recommend
Clay Shirky’s 2008 Here Comes Everybody- The Power of Organizing Without Organizations. Finally,
one of the best known early computer espionage stories is Clifford Stoll’s classic The Cuckoo’s Egg –
Tracking a Spy Through the Maze of Computer Espionage, which provides a first-hand account of the
KGB-hack. This was later made into a television documentary entitled The KGB, the Computer, and Me.

18

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

NineMSN, 05/08/2008, “The Internet Pranksters who Started a War”, URL:
http://news.ninemsn.com.au/article.aspx?id=459214
1

2 Baltimore City Paper, 21 Jan 2008, “Serious Business”, URL:
http://www2.citypaper.com/columns/story.asp?id=15543)

3 IT World, 13 Feb 2011, “That new Facebook Friend Might Just Be a Spy”, URL:
http://www.itworld.com/internet/136830/that-new-facebook-friend-might-just-be-a-spy

4 Times of India, 11 Feb 2012, “Anonymous hacks CIA website”, URL:
http://articles.timesofindia.indiatimes.com/2012-02-11/security/31049746_1_cia-site-cia-websiteanonymous

Irongeek (Adrian Crenshaw), undated, “Crude, Inconsistent Threat: Understanding Anonymous”, URL:
http://www.irongeek.com/i.php?page=security/understanding-anonymous
5

6

Peoples Liberation Front, Public Campaigns, URL: http://peoplesliberationfront.net/campaigns.html

RFE/ RL, 3 Mar 2012, “What Is ‘Anonymous’ And How Does It Operate”, URL:
http://www.rferl.org/content/explainer_what_is_anonymous_and_how_does_it_operate/24500381.html
7

Irongeek (Adrian Crenshaw), undated, “Crude, Inconsistent Threat: Understanding Anonymous”, URL:
http://www.irongeek.com/i.php?page=security/understanding-anonymous
8

9 Cognitive Dissidents (Josh Corman, Brian Martin), 29 Dec. 2011, “’Building a Better Anonymous’ Series,
Part II: Fact vs Fiction”, URL: http://blog.cognitivedissidents.com/2011/12/29/building-a-betteranonymous-series-part-2/

10 ZDNet, 17 Feb 2012, “Anonymous Launches ‘Operation Global Blackout’, aims to DDoS the Root
Internet server”, URL: http://www.zdnet.com/blog/security/anonymous-launches-operation-globalblackout-aims-to-ddos-the-root-internet-servers/10387

11 The Hacker News, 7 July 2011, “#RefRef – Denial of Service (DDoS) Tool Developed by Anonymous”,
URL: http://thehackernews.com/2011/07/refref-denial-of-service-ddos-tool.html (last accessed
02/21/2012)

Information Week, 12 Dec 2010, “WikiLeaks Supporters Download Botnet Tool 50,000 Times”, URL:
http://www.informationweek.com/news/security/attacks/228800161
12

19

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Irongeek (Adrian Crenshaw), undated, “Crude, Inconsistent Threat: Understanding Anonymous”, URL:
http://www.irongeek.com/i.php?page=security/understanding-anonymous
13

14

Knowyourmemes, April 2012, “Pool’s Closed”, URL: http://knowyourmeme.com/memes/pools-closed

15

Knowyourmemes, April 2012, “Pool’s Closed”, URL: http://knowyourmeme.com/memes/pools-closed

16

Knowyourmemes, April 2012, “Pool’s Closed”, URL: http://knowyourmeme.com/memes/pools-closed

17 Knowyourmemes, May 2012, “Internet Vigilantism”, URL:
http://knowyourmeme.com/memes/subcultures/internet-vigilantism

18 Cracked, 23 March 2009, “Eight Awesome Cases of Internet Vigilantism”, URL:
http://www.cracked.com/article_17170_8-awesome-cases-internet-vigilantism_p2.html#ixzz1RZFPycz6

IB Times, 24 Oct. 2007, “Anonymous Takes on Child Pornography Sites”, URL:
http://www.ibtimes.com/articles/236744/20111024/anonymous-operation-darknet-childpornography.htm
19

Mashable, 9 Aug 2012, “Anonymous Shuts Down Alleged Twitter Pedophile”, URL:
http://mashable.com/2012/08/09/anonymous-twitter-pedophile/
20

Cracked, 23 March 2009, “Eight Awesome Cases of Internet Vigilantism”, URL:
http://www.cracked.com/article_17170_8-awesome-cases-internet-vigilantism_p2.html#ixzz1RZFPycz6
21

22 FoxNews, 25 Jan. 2008, “Hackers Declare War On Scientology”, URL:
http://www.foxnews.com/story/0,2933,325586,00.html

23 WirtschaftsWoche (German language magazine), 23 July 2012, “Wie Anonymous Scientology in die
Knie Zwang”, URL: http://www.wiwo.de/technologie/digitale-welt/hackernetzwerk-wie-anonymousscientology-in-die-knie-zwang/6908658.html (excerpt of Parmy Olson’s 2012 book on Anonymous)

24 The Guardian, 3 Feb. 2008, “Hackers Declare War On Scientologists Amid Claim of Heavy-Handed
Cruise Control”, URL: http://www.guardian.co.uk/technology/2008/feb/04/news

L.A. Weekly, 4 Feb 2009, “My Date with Anonymous: A Rare Interview with the Elusive Internet
Troublemakers”, URL: http://www.laweekly.com/2009-02-05/columns/my-date-with-anonymous-a-rareinterview-with-the-illusive-internet-troublemakers/
25

20

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Jacobson, Jeff, undated, “We Are Legion: Anonymous And The War On Scientology”, URL:
http://www.lisamcpherson.org/pc.htm
26

27 WirtschaftsWoche (German language magazine), 23 July 2012, “Wie Anonymous Scientology in die
Knie Zwang”, URL: http://www.wiwo.de/technologie/digitale-welt/hackernetzwerk-wie-anonymousscientology-in-die-knie-zwang/6908658.html (excerpt of Parmy Olson’s 2012 book on Anonymous)

28 KnowYourMemes, Feb. 2012, “Project Chanology”, URL:
http://knowyourmeme.com/memes/events/project-chanology

29 Jacobson, Jeff, undated, “We Are Legion: Anonymous And The War On Scientology”, URL:
http://www.lisamcpherson.org/pc.htm

National Post, 26 Jan. 2008, “Online Group Declares War on Scientology”, URL:
http://web.archive.org/web/20080128145858/http://www.nationalpost.com/news/canada/story.html?id=
261308
30

Jacobson, Jeff, undated, “We Are Legion: Anonymous And The War On Scientology”, URL:
http://www.lisamcpherson.org/pc.htm
31

WirtschaftsWoche (German language magazine), 23 July 2012, “Wie Anonymous Scientology in die
Knie Zwang”, URL: http://www.wiwo.de/technologie/digitale-welt/hackernetzwerk-wie-anonymousscientology-in-die-knie-zwang/6908658.html (excerpt of Parmy Olson’s 2012 book on Anonymous)
32

33 WirtschaftsWoche (German language magazine), 23 July 2012, “Wie Anonymous Scientology in die
Knie Zwang”, URL: http://www.wiwo.de/technologie/digitale-welt/hackernetzwerk-wie-anonymousscientology-in-die-knie-zwang/6908658.html (excerpt of Parmy Olson’s 2012 book on Anonymous)

34 CNet, 25 Jan. 2008, “Technical Aspects of the DDoS Attacks Upon the Church of Scientology”, URL:
http://news.cnet.com/8301-10789_3-9858552-57.html

35 LAist, 23 March 2008, “Church of Scientology Strikes Back – Anonymous Responds”, URL:
http://laist.com/2008/03/23/church_of_scien.php

L.A. Weekly, 17 March 2008, “’Anonymous’ vs. Scientology: Group Targets ‘Church’ Headquarters”,
URL: http://www.laweekly.com/2008-03-20/news/8220-anonymous-8221-vs-scientology/2/
36

Mancunian Matters, 13 July 2012, “Manchester Anonymous to Hold Anti-Scientology Protest Following
Cruise-Holmes Split”, URL: http://mancunianmatters.co.uk/content/13074409-manchester-anonymoushold-anti-scientology-protest-following-cruise-holmes-split
37

21

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

NineMSN, 8 May 2008, “The Internet Pranksters Who Started A War”, URL:
http://news.ninemsn.com.au/article.aspx?id=459214
38

39 WirtschaftsWoche (German language magazine), 23 July 2012, “Wie Anonymous Scientology in die
Knie Zwang”, URL: http://www.wiwo.de/technologie/digitale-welt/hackernetzwerk-wie-anonymousscientology-in-die-knie-zwang/6908658.html (excerpt of Parmy Olson’s 2012 book on Anonymous)

40 Atlantic Wire, 28 Dec. 2011, “The Hacks That Mattered in the Year of the Hack”, URL:
http://www.theatlanticwire.com/technology/2011/12/hacks-mattered-year-hack/46731/

41 Peoples Liberation Front, Public Campaigns, “Operation Syria”, URL:
http://peoplesliberationfront.net/campaigns.html

IT World, 18 Feb 2011, “A Conversation with Commander X”, URL:
http://www.itworld.com/internet/137590/conversation-commander-x?page=0%2C0
42

Al Arabiya, 15 Jan 2011, “Wikileaks Might Have Triggered Tunis’ Revolution”, URL:
http://www.alarabiya.net/articles/2011/01/15/133592.html
43

Al Jazeera, 26 Jan 2011, “How Tunisia’s Revolution began”, URL:
http://www.aljazeera.com/indepth/features/2011/01/2011126121815985483.html
44

BBC News, 5 Jan 2011, “Tunisia Suicide Protester Mohamed Bouazizi Dies”, URL:
http://www.bbc.co.uk/news/world-africa-12120228
45

46 Al Jazeera, 6 Jan 2011, “Tunisia’s Bitter Cyberwar”, URL:
http://www.aljazeera.com/indepth/features/2011/01/20111614145839362.html

47 Gawker, 3 Jan. 2011, “Anonymous Attacks Tunisian Government over WikiLeaks Censorship”, URL:
http://gawker.com/5723104/anonymous-attacks-tunisian-government-over-wikileaks-censorship

48 Al Jazeera, 6 Jan 2011, “Tunisia’s Bitter Cyberwar”, URL:
http://www.aljazeera.com/indepth/features/2011/01/20111614145839362.html

IT World, 18 Feb 2011, ”A Conversation with Commander X”, URL:
http://www.itworld.com/internet/137590/conversation-commander-x?page=0%2C0
49

Al Jazeera, 6 Jan 2011, “Tunisia’s Bitter Cyberwar”, URL:
http://www.aljazeera.com/indepth/features/2011/01/20111614145839362.html
50

22

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Al Jazeera, 19 May 2011, “Anonymous and The Arab Uprisings”, URL:
http://www.aljazeera.com/news/middleeast/2011/05/201151917634659824.html
51

52 Al Jazeera, 6 Jan 2011, “Tunisia’s Bitter Cyberwar”, URL:
http://www.aljazeera.com/indepth/features/2011/01/20111614145839362.html

53 Internetfeds, 6 Jan. 2011, “Remove Tunisian Government Phishing Scripts”, URL:
http://userscripts.org/scripts/show/94122

54 Al Jazeera, 19 May 2011, “Anonymous and The Arab Uprisings”, URL:
http://www.aljazeera.com/news/middleeast/2011/05/201151917634659824.html

Agence France Press (AFP), 17 March 2012, “’Anonymous’ Group Hacks Tunisian Islamist Sites”, URL:
http://www.google.com/hostednews/afp/article/ALeqM5hwgwVBJdpJa0Jm1LsoCpW0HnophQ?docId=CNG.
a7aa7a5a7dd45ef26c7fad8a1c0a0dfe.401
55

Al Jazeera, 19 May 2011, “Anonymous and The Arab Uprisings”, URL:
http://www.aljazeera.com/news/middleeast/2011/05/201151917634659824.html
56

Naked Security, 26 Jan. 2011, “Egypt versus the Internet – Anonymous Hackers Launch DDoS-Attack”,
URL: http://nakedsecurity.sophos.com/2011/01/26/egypt-versus-the-internet-anonymous-hackers-launchddos-attack/
57

58 Naked Security, 26 Jan. 2011, “Egypt versus the Internet – Anonymous Hackers Launch DDoS-Attack”,
URL: http://nakedsecurity.sophos.com/2011/01/26/egypt-versus-the-internet-anonymous-hackers-launchddos-attack/

59Al Jazeera, 19 May 2011, “Anonymous and The Arab Uprisings”, URL:
http://www.aljazeera.com/news/middleeast/2011/05/201151917634659824.html

60 Huffington Post, 8 Aug. 2011, “Syrian Ministry of Defense Website Hacked by Anonymous”, URL:
http://www.huffingtonpost.com/2011/08/08/syria-ministry-of-defense-hacked-anonymous_n_920733.html

Gawker, 2 Feb. 2011, “Anonymous Hackerse Attack Yemeni Government”, URL:
http://gawker.com/5750513/anonymous-hackers-already-taking-down-yemeni-websites
61

Softpedia, 17 July 2012, “Anonymous Hackers Publish Details of Yemen’s Internet Filtering Systems”,
URL: http://news.softpedia.com/news/Anonymous-Hackers-Publish-Details-of-Yemen-s-Internet-FilteringSystems-281745.shtml
62

23

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

The Hacker News, 11 Feb. 2011, “Operation Algeria, Part 2 by Anonymous Hackers Released”, URL:
http://thehackernews.com/2011/02/operation-algeria-part-2-by-anonymous.html
63

64 Naked Security, 31 Dec. 2010, “Pro-WikiLeaks Hackers Attack Zimbabwe Government Websites”, URL:
http://nakedsecurity.sophos.com/2010/12/31/pro-wikileaks-hackers-attack-zimbabwe-governmentwebsites/

65 The Hacker News, 10 Feb. 2011, “Operation Italy Press Release: Anonymous Hackers Will Soon Strike
Again”, URL: http://thehackernews.com/2011/02/operation-italy-press-release-anonymous.html

66 Daily Caller, 26 Feb. 2011, “Who is Anonymous? A Look At the Hacktivists Aiding Revolution in the
Middle East”, URL: http://dailycaller.com/2011/02/26/who-is-anonymous-a-look-at-the-hacktivists-aidingrevolution-in-the-middle-east/2/

Al Jazeera, 19 May 2011, “Anonymous and The Arab Uprisings”, URL:
http://www.aljazeera.com/news/middleeast/2011/05/201151917634659824.html
67

Ars Technica, 15 Feb 2011, “Anonymous Speaks: The Inside Story of the HBGary Hack”, URL:
http://arstechnica.com/tech-policy/2011/02/anonymous-speaks-the-inside-story-of-the-hbgary-hack/
68

Olson, Parmy, 2012, “We Are Anonymous – Inside the Hacker World of LulzSec, Anonymous, And the
Global Cyber Insurgency”, Little Brown, pp.17
69

70 eSecurity, 8 Feb. 2011, “Anonymous Hackers Target HB Gary”, URL:
http://www.esecurityplanet.com/headlines/article.php/3923906/Anonymous-Hackers-Target-HBGary.htm

71 Ars Technica, 15 Feb 2011, “Anonymous Speaks: The Inside Story of the HBGary Hack”, URL:
http://arstechnica.com/tech-policy/2011/02/anonymous-speaks-the-inside-story-of-the-hbgary-hack/

72 Ars Technica, 15 Feb 2011, “Anonymous Speaks: The Inside Story of the HBGary Hack”, URL:
http://arstechnica.com/tech-policy/2011/02/anonymous-speaks-the-inside-story-of-the-hbgary-hack/

73 Olson, Parmy, 2012, “We Are Anonymous – Inside the Hacker World of LulzSec, Anonymous, And the
Global Cyber Insurgency”, Little Brown, p. 20

Ars Technica, 15 Feb 2011, “Anonymous Speaks: The Inside Story of the HBGary Hack”, URL:
http://arstechnica.com/tech-policy/2011/02/anonymous-speaks-the-inside-story-of-the-hbgary-hack/
74

75

Ibid.

24

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Ars Technica, 15 Feb 2011, “Anonymous Speaks: The Inside Story of the HBGary Hack”, URL:
http://arstechnica.com/tech-policy/2011/02/anonymous-speaks-the-inside-story-of-the-hbgary-hack/
76

77 eSecurity, 8 Feb. 2011, “Anonymous Hackers Target HB Gary”, URL:
http://www.esecurityplanet.com/headlines/article.php/3923906/Anonymous-Hackers-Target-HBGary.htm

78
Ars Technica, 4 Apr. 2011, “’Anonymous’ Attacks Sony to Protest PS3 Hacker Law Suit”, URL:
http://arstechnica.com/tech-policy/2011/04/anonymous-attacks-sony-to-protest-ps3-hacker-lawsuit/

79

New Yorker, 7 May 2012, “Machine Politics – Annals of Technology”, URL:
http://www.newyorker.com/reporting/2012/05/07/120507fa_fact_kushner

80

Ps3News, undated, “PS3 Is Hacked By George Hotz – Hello Hypervisor, I’m GeoHot!”, URL:
http://www.ps3news.com/PS3-Hacks/ps3-is-hacked-by-george-hotz-hello-hypervisor-im-geohot/

81

Technologizer, 11 Apr. 2011, “Sony And George Hotz Settle PS3 Hacking Lawsuit”, URL:
http://technologizer.com/2011/04/11/sony-george-hotz-settle-ps3-hacking-lawsuit/

82

BusinessInsider, 24 Jan. 2012, “Famous iPhone Hacker George Hotz Has Left Facebook”, URL:
http://articles.businessinsider.com/2012-01-24/tech/30658124_1_george-hotz-location-data-iphone
Olson, Parmy, 2012, “We Are Anonymous – Inside the Hacker World of LulzSec, Anonymous, And the
Global Cyber Insurgency”, Little Brown, pp. 423f
83

Know Your Meme, 1 March 2012, “Operation Antisec”, URL:
http://knowyourmeme.com/memes/events/operation-antisec
84

PCMagazine, 20 June 2011, “LulzSec, Anonymous Team Up for ‘Operation Anti-Security”, URL:
http://www.pcmag.com/article2/0,2817,2387264,00.asp
85

86 PCMagazine, 20 June 2011, “LulzSec, Anonymous Team Up for ‘Operation Anti-Security”, URL:
http://www.pcmag.com/article2/0,2817,2387264,00.asp

87 Know Your Meme, 1 March 2012, “Operation Antisec”, URL:
http://knowyourmeme.com/memes/events/operation-antisec

88 ITProPortal, 27 June 2011, “Anonymous Puts US Counter Terrorist Program Online”, URL:
http://www.itproportal.com/2011/06/27/anonymous-puts-us-counter-terrorist-program-online/

25

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Know Your Meme, 1 March 2012, “Operation Antisec”, URL:
http://knowyourmeme.com/memes/events/operation-antisec
89

90 The Telegraph, 7 March 2012, “FBI Charges Alleged Anonymous Hackers After Supergrass Claims”,
URL: http://www.telegraph.co.uk/technology/news/9127004/FBI-charges-alleged-Anonymous-hackersafter-supergrass-claims.html

91 Peoples Liberation Front, Public Campaigns, undated, “Operation Vendetta”, URL:
http://www.peoplesliberationfront.net/campaignsArchive1.html, last accessed 08/12/2012

92 TPM, 8 March 2012, “Occupy Lawyer Stuck With $35K Bill After ‘Homeless Hacker’ Jumps Bail”, URL:
http://idealab.talkingpointsmemo.com/2012/03/occupy-lawyer-stuck-with-35k-bill-after-homeless-hackerjumps-bail.php

TPM, 27 Oct. 2011, “’Homeless Hacker’ Christopher Doyon, AKA ‘Commander X’, Joins Up With Occupy
Movement”, URL: http://idealab.talkingpointsmemo.com/2011/10/homeless-hacker-christopher-doyonaka-commander-x-joins-up-with-occupy-movement.php
93

CBS News, 23 Sep. 2011, “Feds: Homeless Hacker ‘Commander X’ Arrested”, URL:
http://www.cbsnews.com/8301-31727_162-20110912-10391695.html
94

The Montreal Gazette, 12 May 2012, “Christopher Doyon, One of the Brains Behind Anonymous”, URL:
http://www.montrealgazette.com/technology/Christopher+Doyon+brains+behind+Anonymous/6612381/s
tory.html
95

96
Wired, 13 July 2012, “Par:AnoIA: Anonymous Launches WikiLeaks-esque Site for Data Dumps”, URL:
http://www.wired.com/threatlevel/2012/07/paranoia-anonymous/all/

97 Wired, 19 Apr 2012, “Anontune: The New Social Music Platform From Anonymous”, URL:
http://www.wired.com/underwire/2012/04/anontune-anonymous/

98 RT.com, 23 Apr 2012, “Anonymous Unveils Data-Sharing Websites Amidst Privacy Concerns”, URL:
http://rt.com/usa/news/anonymous-pastebin-new-internet-605/

99 RT.com, 23 Apr 2012, “Anonymous Unveils Data-Sharing Websites Amidst Privacy Concerns”, URL:
http://rt.com/usa/news/anonymous-pastebin-new-internet-605/

100 RT.com, 23 Apr 2012, “Anonymous Unveils Data-Sharing Websites Amidst Privacy Concerns”, URL:
http://rt.com/usa/news/anonymous-pastebin-new-internet-605/

26

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Information Week, 19 April 2012, “Anonymous Builds New Haven for Stolen Data”, URL:
http://www.informationweek.com/news/security/vulnerabilities/232900590
101

102

PC Magazine, 19 Apr. 2012, “With PasteBin ‘Compromised’, Anonymous Launches AnonPaste”, URL:
http://www.pcmag.com/article2/0,2817,2403283,00.asp

103

Wired, 13 July 2012, “Par:AnoIA: Anonymous Launches WikiLeaks-esque Site for Data Dumps”, URL:
http://www.wired.com/threatlevel/2012/07/paranoia-anonymous/all/

104

Wired, 13 July 2012, “Par:AnoIA: Anonymous Launches WikiLeaks-esque Site for Data Dumps”, URL:
http://www.wired.com/threatlevel/2012/07/paranoia-anonymous/all/
CNet, 15 March 2012, “Anonymous OS: Worth The Risk?”, URL: http://news.cnet.com/8301-13506_357397895-17/anonymous-os-worth-the-risk/
105

Mobiledia, 16 March 2012, “Hackers’ OS? Joke’s On You”, URL:
http://www.mobiledia.com/news/133380.html
106

The Next Web (TNW), undated, “Anonymous Has Just Released Its Own Operating System:
Anonymous OS”, URL: http://thenextweb.com/insider/2012/03/14/anonymous-has-just-released-its-ownoperating-system-anonymous-os/
107

108 The Hacker News, 15 March 2012, “Anonymous-OS 0.1: Anonymous Hackers Released Their Own
Operating System”, URL: http://thehackernews.com/2012/03/anonymous-os-01-anonymous-hackers.html

109 CNet, 15 March 2012, “Anonymous OS: Worth The Risk?”, URL: http://news.cnet.com/8301-13506_357397895-17/anonymous-os-worth-the-risk/

The Next Web (TNW), undated, “Anonymous Has Just Released Its Own Operating System:
Anonymous OS”, URL: http://thenextweb.com/insider/2012/03/14/anonymous-has-just-released-its-ownoperating-system-anonymous-os/
110

Softpedia, 16 March 2012, “SourceForge Closes Anonymous-OS Live CD Project”, URL:
http://news.softpedia.com/newsImage/SourceForge-Closes-Anonymous-OS-Live-CD-Project-2.jpg/
111

The Next Web, undated, “Anonymous Claims That The Operating System, ‘Anonymous-OS’ Is Fake”,
URL: http://thenextweb.com/insider/2012/03/15/anonymous-claims-that-the-operating-systemanonymous-os-is-fake/
112

27

Excerpt from Introduction to Cyber-Warfare: A Multidisciplinary Approach
(Shakarian, Shakarian, and Ruef)

Softpedia, 16 March 2012, “SourceForge Closes Anonymous-OS Live CD Project”, URL:
http://news.softpedia.com/news/SourceForge-Closes-Anonymous-OS-Live-CD-Project-258944.shtml
113

114 The Next Web, undated, “Anonymous Claims That The Operating System, ‘Anonymous-OS’ Is Fake”,
URL: http://thenextweb.com/insider/2012/03/15/anonymous-claims-that-the-operating-systemanonymous-os-is-fake/

115 Mobiledia, 16 March 2012, “Hackers’ OS? Joke’s On You”, URL:
http://www.mobiledia.com/news/133380.html

116 The Next Web, undated, “Anonymous Claims That The Operating System, ‘Anonymous-OS’ Is Fake”,
URL: http://thenextweb.com/insider/2012/03/15/anonymous-claims-that-the-operating-systemanonymous-os-is-fake/

117

ZDNet, 16 July 2012, “Fluid Structure, Leadership Keep Anonymous’ Threat Alive”, URL:
http://www.zdnet.com/fluid-structure-leadership-keep-anonymous-threat-alive-7000000957/
Radio Free Europe, 3 Mar 2012, “What Is Anonymous And How Does It Operate?”, URL:
http://www.rferl.org/content/explainer_what_is_anonymous_and_how_does_it_operate/24500381.html
118

Mobiledia, 24 Apr. 2012, “A Rising War Between Hackers”, URL:
http://www.mobiledia.com/news/139185.html
119

28

Large Social Networks can be Targeted for Viral
Marketing with Small Seed Sets
Paulo Shakarian and Damon Paulo

arXiv:1205.4431v2 [cs.SI] 15 Mar 2013

Network Science Center and
Department of Electrical Engineering and Computer Science
United States Military Academy
West Point, New York 10996
Email: paulo[at]shakarian.net, damon.paulo[at]usma.edu

Abstract—In a “tipping” model, each node in a social network,
representing an individual, adopts a behavior if a certain number
of his incoming neighbors previously held that property. A key
problem for viral marketers is to determine an initial “seed”
set in a network such that if given a property then the entire
network adopts the behavior. Here we introduce a method for
quickly finding seed sets that scales to very large networks. Our
approach finds a set of nodes that guarantees spreading to the
entire network under the tipping model. After experimentally
evaluating 31 real-world networks, we found that our approach
often finds such sets that are several orders of magnitude smaller
than the population size. Our approach also scales well - on a
Friendster social network consisting of 5.6 million nodes and
28 million edges we found a seed sets in under 3.6 hours. We
also find that highly clustered local neighborhoods and dense
network-wide community structure together suppress the ability
of a trend to spread under the tipping model.

I. I NTRODUCTION
A much studied model in network science, tipping [10],
[11], [20] (a.k.a. deterministic linear threshold [12]) is often
associated with “seed” or “target” set selection, [7] (a.k.a.
the maximum influence problem). In this problem we have a
social network in the form of a directed graph and thresholds
for each individual. Based on this data, the desired output is
the smallest possible set of individuals such that, if initially
activated, the entire population will adopt the new behavior (a
seed set). This problem is NP-Complete [9], [12]. Although
approximation algorithms have been proposed, [3], [7], [8],
[15] none seem to scale to very large data sets. Here, inspired
by shell decomposition, [2], [5], [13] we present a method
guaranteed to find a set of nodes that causes the entire population to activate - but is not necessarily of minimal size. We then
evaluate the algorithm on 31 large real-world social networks
and show that it often finds very small seed sets (often several
orders of magnitude smaller than the population size). We also
show that the size of a seed set is related to Louvain modularity
and average clustering coefficient. Therefore, we find that
dense community structure and tight-knit local neighborhoods
together inhibit the spreading of trends under the tipping
model.
The rest of the paper is organized as follows. In Section II,
we provide formal definitions of the tipping model. This
is followed by the presentation of our new algorithm in
Section III. We then describe our experimental results in

Section IV. Finally, we provide an overview of related work
in Section V.
II. T ECHNICAL P RELIMINARIES
Throughout this paper we assume the existence of a social
network, G = (V, E), where V is a set of vertices and E is a
set of directed edges. We will use the notation n and m for the
cardinality of V and E respectively. For a given node vi ∈ V ,
the set of incoming neighbors is ηiin , and the set of outgoing
neighbors is ηiout . The cardinalities of these sets (and hence
out
the in and out degrees of node vi ) are din
respectively.
i , di
We now define a threshold function that for each node returns
the fraction of incoming neighbors that must be activated for
it to become activate as well.
Definition 1 (Threshold Function): We define the threshold function as mapping from V to (0, 1]. Formally: θ : V →
(0, 1].
For the number of neighbors that must be active, we will
use the shorthand ki . Hence, for each vi , ki = dθ(vi ) · din
i e.
We now define an activation function that, given an initial set
of active nodes, returns a set of active nodes after one time
step.
Definition 2 (Activation Function): Given a threshold function, θ, an activation function Aθ maps subsets of V to
subsets of V, where for some V 0 ⊆ V ,
Aθ (V 0 ) = V 0 ∪ {vi ∈ V s.t. |ηiin ∩ V 0 | ≥ ki }

(1)

We now define multiple applications of the activation function.
Definition 3 (Multiple Applications of the Activation Function):
Given a natural number i > 0, set V 0 ⊆ V , and threshold
function, θ, we define the multiple applications of the
activation function, Aiθ (V 0 ), as follows:
(
Aθ (V 0 )
if i = 1
Aiθ (V 0 ) =
(2)
i−1
0
Aθ (Aθ (V )) otherwise
0
Clearly, when Aiθ (V 0 ) = Ai−1
θ (V ) the process has converged. Further, this occurs in no more than n steps (as, in
each step, at least one new node must be activated). Based
on this idea, we define the function Γ which returns the set
of all nodes activated upon the convergence of the activation
function.

Definition 4 (Γ Function): Let j be the least value such that
Ajθ (V 0 ) = Aj−1
(V 0 ). We define the function Γθ : 2V → 2V
θ
as follows.
Γθ (V 0 ) = Ajθ (V 0 )
(3)
We now have all the pieces to introduce our problem finding the minimal number of nodes that are initially active
to ensure that the entire set V becomes active.
Definition 5 (The MIN-SEED Problem): The MIN-SEED
Problem is defined as follows: given a threshold function, θ,
return V 0 ⊆ V s.t. Γθ (V 0 ) = V , and there does not exist
V 00 ⊆ V where |V 00 | < |V 0 | and Γθ (V 00 ) = V .
The following theorem is from the literature [9], [12] and
tells us that the MIN-SEED problem is NP-complete.
Theorem 1 (Complexity of MIN-SEED [9], [12]): MINSEED in NP-Complete.
III. A LGORITHM
To deal with the intractability of the MIN-SEED problem,
we design an algorithm that finds a non-trivial subset of nodes
that causes the entire graph to activate, but we do not guarantee
that the resulting set will be of minimal size. The algorithm
is based on the idea of shell decomposition often cited in
physics literature [2], [5], [13], [21] but modified to ensure
that the resulting set will lead to all nodes being activated.
The algorithm, TIP DECOMP is presented in this section.
Algorithm 1 TIP DECOMP
Require: Threshold function, θ and directed social network
G = (V, E)
Ensure: V 0
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:

For each vertex vi , compute ki .
For each vertex vi , disti = din
i − ki .
FLAG = TRUE.
while FLAG do
Let vi be the element of v where disti is minimal.
if disti = ∞ then
FLAG = FALSE.
else
Remove vi from G and for each vj in ηiout , if distj >
0, set distj = distj − 1. Otherwise set distj = ∞.
end if
end while
return All nodes left in G.

Intuitively, the algorithm proceeds as follows (Figure 1).
Given network G = (V, E) where each node vi has threshold
ki = dθ(vi ) · din
i e, at each iteration, pick the node for which
din
−
k
is
the
least but positive (or 0) and remove it. Once
i
i
there are no nodes for which din
i − ki is positive (or 0), the
algorithm outputs the remaining nodes in the network.
Now, we prove that the resulting set of nodes is guaranteed
to cause all nodes in the graph to activate under the tipping
model. This proof follows from the fact that any node removed
is activated by the remaining nodes in the network.

A

b:1
a:1

j:0
c:2

g:1

d:1

C

b:1
a:1

j:1

c:2

e:0

B

h:0

i:0

g:0

d:-1

f:0

D

b:1
a:1
c:2
d:-1

E

b:0

g:-1
d:-1

g:-1
d:-1

c:1
g:-1

c:0

F

g:-2
d:-2

Remove g,j

Remove b

Remove a
Fig. 1. Example of our algorithm for a simple
network depicted in box A.
We use a threshold value set to 50% of the node degree. Next to each node
din

i
label (lower-case letter) is the value for din
i − ki (where ki = d 2 e). In the
first four iterations, nodes e, f, h, and i are removed resulting in the network
in box B. This is followed by the removal of node j resulting in the network
in box C. In the next two iterations, nodes a and b are removed (boxes DE respectively). Finally, node c is removed (box F). The nodes of the final
network, consisting of d and g, have negetive values for di − θi and become
the output of the algorithm.

Theorem 2: If all nodes in V 0
⊆
V returned by
TIP DECOMP are initially active, then every node in V will
eventually be activated, too.
Proof: Let w be the total number of nodes removed by
TIP DECOMP, where v1 is the last node removed and vw is
the first node removed. We prove the theorem by induction on
w as follows. We use P (w) to denote the inductive hypothesis
which states that all nodes from v1 to vw are active. In the
base case, P (1) trivially holds as we are guaranteed that from
set V 0 there are at least k1 edges to v1 (or it would not be
removed). For the inductive step, assuming P (w) is true, when
vw+1 was removed from the graph distw+1 ≥ 0 which means
in
that din
w+1 ≥ kw+1 . All nodes in ηw+1 at the time when vw+1
was removed are now active, so vw+1 will now be activated which completes the proof.
We also note that by using the appropriate data structure (we
used a binomial heap in our implementation), for a network
of n nodes and m edges, this algorithm can run in time
O(m log n).
Proposition 1: The complexity of TIP DECOMP is O(m·
log(n)).
IV. R ESULTS
All experiments were run on a computer equipped with an
Intel X5677 Xeon Processor operating at 3.46 GHz with a
12 MB Cache. The machine was running Red Hat Enterprise
Linux version 6.1 and equipped with 70 GB of physical
memory. TIP DECOMP was written using Python 2.6.6 in
200 lines of code that leveraged the NetworkX library available
from http://networkx.lanl.gov/. The code used a binomial
heap library written by Björn B. Brandenburg available from

Remove e,f,

http://www.cs.unc.edu/∼bbb/. All statistics presented in this
section were calculated using R 2.13.1.
•

A. Datasets
In total, we examined 31 networks: nine academic collaboration networks, three e-mail networks, and 19 networks
extracted from social-media sites. The sites included included
general-purpose social-media (similar to Facebook or MySpace) as well as special-purpose sites (i.e. focused on sharing
of blogs, photos, or video).
All datasets used in this paper were obtained from one of
four sources: the ASU Social Computing Data Repository, [23]
the Stanford Network Analysis Project, [14] the University
of Michigan, [17] and Universitat Rovira i Virgili. [1] All
networks considered were symmetric – i.e. if a directed edge
from vertex v to v 0 exists, there is also an edge from vertex v 0
to v. Tables I (A-C) show some of the pertinent qualities of
these networks. The networks are categorized by the results
(explained later in this section). In what follows, we provide
their real-world context.

•

•
•

D. Category C
•
•

B. Category A
•

•

•

•

•

•
•
•
•
•
•

BlogCatalog is a social blog directory that allows users
to share blogs with friends. [23] The first two samples of
this site, BlogCatalog1 and 2, were taken in Jul. 2009 and
June 2010 respectively. The third sample, BlogCatalog3
was uploaded to ASU’s Social Computing Data Repository in Aug. 2010.
Buzznet is a social media network designed for sharing
photographs, journals, and videos. [23] It was extracted
in Nov. 2010.
Douban is a Chinese social medial website designed to
provide user reviews and recommendations. [23] It was
extracted in Dec. 2010.
Flickr is a social media website that allows users to
share photographs. [23] It was uploaded to ASU’s Social
Computing Data Repository in Aug. 2010.
Flixster is a social media website that allows users to
share reviews and other information about cinema. [23]
It was extracted in Dec. 2010.
FourSquare is a location-based social media site. [23] It
was extracted in Dec. 2010.
Frienster is a general-purpose social-networking
site. [23] It was extracted in Nov. 2010.
Last.Fm is a music-centered social media site. [23] It
was extracted in Dec. 2010.
LiveJournal is a site designed to allow users to share
their blogs. [23] It was extracted in Jul. 2010.
Livemocha is touted as the “world’s largest language
community.” [23] It was extracted in Dec. 2010.
WikiTalk is a network of individuals who set and received messages while editing WikiPedia pages. [14] It
was extracted in Jan. 2008.

C. Category B
•

Delicious is a social bookmarking site, designed to allow

users to share web bookmarks with their friends. [23] It
was extracted in Dec. 2010.
Digg is a social news website that allows users to share
stories with friends. [23] It was extracted in Dec. 2010.
EU E-Mail is an e-mail network extracted from a large
European Union research institution. [14] It is based on
e-mail traffic from Oct. 2003 to May 2005.
Hyves is a popular general-purpose Dutch social networking site. [23] It was extracted in Dec. 2010.
Yelp is a social networking site that allows users to share
product reviews. [23] It was extracted in Nov. 2010.

•

•

•

•
•

•

•

CA-AstroPh is a an academic collaboration network for
Astro Physics from Jan. 1993 - Apr. 2003. [14]
CA-CondMat is an academic collaboration network for
Condense Matter Physics. Samples from 1999 (CondMat99), 2003 (CondMat03), and 2005 (CondMat05) were
obtained from the University of Michigan. [17] A second
sample from 2003 (CondMat03a) was obtained from
Stanford University. [14]
CA-GrQc is a an academic collaboration network for
General Relativity and Quantum Cosmology from Jan.
1993 - Apr. 2003. [14]
CA-HepPh is a an academic collaboration network for
High Energy Physics - Phenomenology from Jan. 1993 Apr. 2003. [14]
CA-HepTh is a an academic collaboration network for
High Energy Physics - Theory from Jan. 1993 - Apr.
2003. [14]
CA-NetSci is a an academic collaboration network for
Network Science from May 2006.
Enron E-Mail is an e-mail network from the Enron corporation made public by the Federal Energy Regulatory
Commission during its investigation. [14]
URV E-Mail is an e-mail network based on communications of members of the University Rovira i Virgili
(Tarragona). [1] It was extracted in 2003.
YouTube is a video-sharing website that allows users
to establish friendship links. [23] The first sample
(YouTube1) was extracted in Dec. 2008. The second
sample (YouTube2) was uploaded to ASU’s Social Computing Data Repository in Aug. 2010.

E. Runtime
First, we examined the runtime of the algorithm (see Figure 2). Our experiments aligned well with our time complexity
result (Proposition 1). For example, a network extracted from
the Dutch social-media site Hyves consisting of 1.4 million
nodes and 5.5 million directed edges was processed by our
algorithm in at most 12.2 minutes. The often-cited LiveJournal
dataset consisting of 2.2 million nodes and 25.6 million
directed edges was processed in no more than 66 minutes
- a short time for an NP-hard combinatorial problem on a
large-sized input.

23.58 ASU
17.05 ASU
32.39 ASU
27.31 ASU
2.11 ASU
73.28 ASU
3.14 ASU
5.03 ASU
2.47 ASU
3.79 ASU
5.72 ASU
21.07 ASU
1.95 SNAP

Type

Source

5000

SocMedia
SocMedia
SocMedia
SocMedia
SocMedia
SocMedia
SocMedia
SocMedia
SocMedia
SocMedia
SocMedia
SocMedia
SocMedia

Runtime (seconds, log scale)

CATEGORY A
BlogCatalog1
88,784 4,186,390
BlogCatalog2
97,884 3,337,294
BlogCatalog3
10,312
667,966
Buzznet
101,163 5,526,132
Douban
154,908
654,324
Flickr
80,513 11,799,764
Flixster
2,523,386 15,837,602
FourSquare
639,014 6,429,972
Frienster
5,689,498 28,135,774
Last.Fm
1,191,812 9,038,680
LiveJournal
2,238,731 25,632,368
Livemocha
104,103 4,386,166
WikiTalk
2,394,385 9,319,130
CATEGORY B
Delicious
536,408 2,732,272
Digg
771,231 11,814,826
EU E-Mail
265,214
728,962
Hyves
1,402,673 5,554,838
Yelp
487,401 4,686,962
CATEGORY C
CA-AstroPh
18,772
396,100
CA-CondMat03
30,460
240,058
CA-CondMat03a
23,133
186,878
CA-CondMat05
39,577
351,384
CA-CondMat99
16,264
95,188
CA-GrQc
5,242
28,968
CA-HepPh
12,008
236,978
CA-HepTh
9,877
51,946
CA-NetSci
1,463
5,486
Enron E-Mail
36,692
367,662
URV E-Mail
1,133
10,902
YouTube1
13,723
153,530
YouTube2
1,138,499 5,980,886

Avg. Degree

# Edges

# Nodes

Name

50000

500

50

5

0.5

0.05
1.20E+04

1.20E+05

1.20E+06

1.20E+07

m ln (n) (m = # of edges, n= # of nodes, log scale)

2.55 ASU
7.66 ASU
1.37 SNAP
1.98 ASU
4.81 ASU

SocMedia
SocMedia
E-Mail
SocMedia
SocMedia

10.55 SNAP
3.94 UMICH
4.04 SNAP
4.44 UMICH
2.93 UMICH
2.76 SNAP
9.87 SNAP
2.63 SNAP
1.87 UMICH
5.01 SNAP
4.81 URV
5.59 ASU
2.63 ASU

Collab
Collab
Collab
Collab
Collab
Collab
Collab
Collab
Collab
E-Mail
E-Mail
SocMedia
SocMedia

TABLE I
I NFORMATION ON THE NETWORKS IN C ATEGORIES A, B, AND C.

F. Seed Size
For each network, we performed 10 “integer” trials. In
these trials, we set θ(vi ) = min(din
i , k) where k was kept
constant among all vertices for each trial and set at an integer
in the interval [1, 10]. We evaluated the ability of a network
to promote spreading under the tipping model based on the
size of the set of nodes returned by our algorithm (as a
percentage of total nodes). For purposes of discussion, we have
grouped our networks into three categories based on results
(Figure 3 and Table II). In general, online social networks had
the smallest seed sets - 13 networks of this type had an average
seed set size less than 2% of the population. We also noticed,
that for most networks, there was a linear realtion between
threshold value and seed size.

Fig. 2. m ln n vs. runtime in seconds (log scale, m is number of edges,
n is number of nodes). The relationship is linear with R2 = 0.9015, p =
2.2 · 10−16 .

Category A can be thought of as social networks highly
susceptible to influence - as a very small fraction of individuals
initially having a behavior can lead to adoption by the entire
population. In our ten trials, the average seed size was under
2% for each of these 13 networks. All were extracted from
social media websites. For some of the lower threshold levels,
the size of the set of seed nodes was particularly small. For a
threshold of three we had 11 of the Category A networks with
a seed size less than 0.5% of the population. For a threshold
of four, we had nine networks meeting that criteria.
Networks in Category B are susceptible to influence with a
relatively small set of initial nodes - but not to the extent
of those in Category A. They had an average initial seed
size greater than 2% but less than 10%. Members in this
group included two general purpose social media networks,
two specialty social media networks, and an e-mail network.
Category C consisted of networks that seemed to hamper
diffusion in the tipping model, having an average initial seed
size greater than 10%. This category included all of the
academic collaboration networks, two of the email networks,
and two networks derived from friendship links on YouTube.
G. Seed Size as a Function of Community Structure
In this section, we view the results of our heuristic algorithm
as a measurement of how well a given network promotes
spreading. Here, we use this measurement to gain insight into
which structural aspects make a network more likely to be
“tipped.” We compared our results with two network-wide
measures characterizing community structure. First, clustering
coefficient (C) is defined for a node as the fraction of neighbor
pairs that share an edge - making a triangle. For the undirected
case, we define this concept formally below.

3.5

A

Seed Size (Percentage of Nodes)

3

BlogCatalog1
BlogCatalog2
BlogCatalog3

2.5

Buzznet
Douban

2

Flickr

1.5

Flixster
FourSquare

1

Friendster
Last.Fm

0.5

LiveJournal
Livemocha

0
1

2

3

4

5

6

7

8

9

WikiTalk

10

Threshold Value

Seed Size (Percentage of Nodes)

14

B

12
10

Delicious

8

Digg
EU E-mail

6

Hyves

4

Yelp

2
0
1

2

3

4

5

6

7

8

9

10

Threshold Value

Seed Size (Percentage of Nodes)

60

C

50

CA-AstroPh
CA-CondMat03
CA-CondMat03a
CA-CondMat05

40

CA-CondMat99
CA-GrQC

30

CA-HepPh
CA-HepTh

20

CA-NetSci
Enron E-Mail

10

URV E-Mail
YouTube1

0
1

3

5

7

9

YouTube2

Threshold Value

Fig. 3. Threshold value (assigned as an integer in the interval [1, 10]) vs. size
of initial seed set as returned by our algorithm in our three identified categories
of networks (categories A-C are depicted in panels A-C respectively). Average
seed sizes were under 2% for Categorty A, 2 − 10% for Category B and over
10% for Category C. The relationship, in general, was linear for categories A
and B and lograthimic for C. CA-NetSci had the largest Louvain Modularity
and clustering coefficient of all the networks. This likely explains why that
particular network seems to inhibit spreading.

Definition 6 (Clustering Coefficient): Let r be the number
of edges between nodes with which vi has an edge and di be
2r
the degree of vi . The clustering coefficient, Ci =
.
di (di − 1)
Intuitively, a node with high Ci tends to have more pairs
of friends that are also mutual friends. We use the average
clustering coefficient as a network-wide measure of this local
property.
Second, we consider modularity (M ) defined by Newman
and Girvan. [16]. For a partition of a network, M is a real
number in [−1, 1] that measures the density of edges within

partitions compared to the density of edges between partitions.
We present a formal definition for an undirected network
below.
Definition 7 (Modularity [16]): Modularity,
di dj
1 P
]δ(ci , cj ), where m is the
M =
i,j∈V [1 −
2m
2m
number of undirected edges, di is node degree, ci is the
community to which vi belongs and δ(x, y) = 1 if x = y and
0 otherwise.
The modularity of an optimal network partition can be used
to measure the quality of its community structure. Though
modularity-maximization is NP-hard, the approximation algorithm of Blondel et al. [4] (a.k.a. the “Louvain algorithm”)
has been shown to produce near-optimal partitions.1 We call
the modularity associated with this algorithm the “Louvain
modularity.” Unlike the C, which describes local properties,
M is descriptive of the community level. For the 31 networks
we considered, M and C appear uncorrelated (R2 = 0.0538,
p = 0.2092).
We plotted the initial seed set size (S) (from our algorithm
- averaged over the 10 threshold settings) as a function of
M and C (Figure 4a) and uncovered a correlation (planar fit,
R2 = 0.8666, p = 5.666·10−13 , see Figure 4 A). The majority
of networks in Category C (less susceptible to spreading)
were characterized by relatively large M and C (Category
C includes the top nine networks w.r.t. C and top five w.r.t.
M ). Hence, networks with dense, segregated, and close-knit
communities (large M and C) suppress spreading. Likewise,
those with low M and C tended to promote spreading. Also,
we note that there were networks that promoted spreading with
dense and segregated communities, yet were less clustered (i.e.
Category A networks Friendster and LiveJournal both have
M ≥ 0.65 and C ≤ 0.13). Further, some networks with a
moderately large clustering coefficient were also in Category
A (two networks extracted from BlogCatalog had C ≥ 0.46)
but had a relatively less dense community structure (for those
two networks M ≤ 0.33).
We also studied the effects on spreading when the threshold
values would be assigned as a certain fraction of the node’s
in-degree. [11], [22] This results in heterogeneous θi ’s for the
nodes. We performed 12 trials for each network. Thresholds
for each trial were based on the product of in-degree and a
fraction in the interval [0.05, 0.60] (multiples of 0.05). The
results (Figure 5 and Table II) were analogous to our integer
tests. We also compared the averages over these trials with
M and C and obtained similar results as with the other trials
(Figure 4 B).
V. R ELATED W ORK
Tipping models first became popular by the works of
[10] and [20] where it was presented primarily in a social
context. Since then, several variants have been introduced in
the literature including the non-deterministic version of [12]
(described later in this section) and a generalized version of
1 Louvain modularity was computed using the implementation available
from CRANS at http://perso.crans.org/aynaud/communities/.

12

A

A

Average Seed Size (Percent of Nodes)

Seed Size (Percentage of Nodes)

10

BlogCatalog1
BlogCatalog2
BlogCatalog3

8

Buzznet
Douban

6

Flickr
Flixster
FourSquare

4

Friendster
Last.Fm

2

LiveJournal
Livemocha

0

WikiTalk

0.05

0.15

0.25

0.35

0.45

0.55

Threshold Value

12

B

Louvain Modularity

Average Seed Size (Percent of Nodes)

B

Seed Size (Percentage of Nodes)

10

8
Delicious

6

Digg
EU E-mail
Hyves

4

Yelp

2

0
0.06

0.16

0.26

0.36

0.46

0.56

Threshold Value (Fraction of Neighbors)

50

C

Louvain Modularity

Seed Size (Percentage of Nodes)

45
40

CA-AstroPh
CA-CondMat03
CA-CondMat03a

35

CA-CondMat05

30

CA-CondMat99

25

CA-GrQC

20

CA-HepPh
CA-HepTh

15

CA-NetSci

10

Enron E-Mail
URV E-Mail

5

YouTube1

0
0.05

0.15

0.25

0.35

0.45

0.55

YouTube2

Threshold Value (Fraction of Neighbors)

Fig. 4. (A) Louvain modularity (M ) and average clustering coefficient (C)
vs. the average seed size (S). The planar fit depicted is S = 43.374 · M +
33.794 · C − 24.940 with R2 = 0.8666, p = 5.666 · 10−13 . (B) Same
plot at (A) except the averages are over the 12 percentage-based threshold
values. The planar fit depicted is S = 18.105 · M + 17.257 · C − 10.388
with R2 = 0.816, p = 5.117 · 10−11 .

[11]. In this paper we focused on the deterministic version. In
[22], the authors look at deterministic tipping where each node
is activated upon a percentage of neighbors being activated.
Dryer and Roberts [9] introduce the MIN-SEED problem,
study its complexity, and describe several of its properties
w.r.t. certain special cases of graphs/networks. The hardness
of approximation for this problem is described in [7]. The
work of [3] presents an algorithm for target-set selection
whose complexity is determined by the tree-width of the
graph - though it provides no experiments or evidence that
the algorithm can scale for large datasets. The recent work of
[18] prove a non-trivial upper bound on the smallest seed set.

Fig. 5. Threshold value (assigned as a fraction of node in-degree as a multiple
of 0.05 in the interval [0.05, 0.60]) vs. size of initial seed set as returned by
our algorithm in our three identified categories of networks (categories A-C
are depicted in panels A-C respectively, categories are the same as in Figure
1). Average seed sizes were under 5% for Categorty A, 1 − 7% for Category
B and over 3% for Category C. In general, the relationship between threshold
and initial seed size for networks in all categories was exponential.

Our algorithm is based on the idea of shell-decomposition
that currently is prevalent in physics literature. In this process,
which was introduced in [21], vertices (and their adjacent
edges) are iteratively pruned from the network until a network
“core” is produced. In the most common case, for some value
k, nodes whose degree is less than k are pruned (in order of
degree) until no more nodes can be removed. This process
was used to model the Internet in [5] and find key spreaders
under the SIR epidemic model in [13]. More recently, a
“heterogeneous” version of decomposition was introduced in
[2] - in which each node is pruned according to a certain

p-value (exp. fit for Deg. tests)

0.63
0.65
0.63
0.65
0.64
0.53
0.61
0.47
0.69
0.50
0.22
0.14
0.08

R^2 (exp. fit for Deg. tests)

CA-AstroPh
CA-CondMat03
CA-CondMat03a
CA-CondMat05
CA-CondMat99
CA-GrQc
CA-HepPh
CA-HepTh
CA-NetSci
Enron E-Mail
URV E-Mail
YouTube1
YouTube2

CATEGORY A
0.73 0.97 1.4E-07
0.01 0.86 1.1E-04
0.29 0.89 3.9E-05
0.40 0.83 2.7E-04
1.54 0.99 3.2E-09
0.69 0.95 1.2E-06
1.14 1.00 1.1E-11
0.07 0.27 1.2E-01
0.21 0.95 1.2E-06
1.31 0.97 1.2E-07
1.12 0.97 1.4E-07
1.04 0.89 3.6E-05
0.90 0.98 8.0E-08
CATEGORY B
0.75 8.27 0.98 2.9E-08
0.53 4.64 0.98 2.0E-08
0.79 6.66 0.81 3.8E-04
0.77 4.90 0.97 1.5E-07
0.62 7.07 0.99 2.2E-10
CATEGORY C
0.63 14.31 1.00 6.3E-11
0.76 27.80 0.98 7.8E-08
0.73 26.52 0.98 2.3E-08
0.73 25.59 0.98 2.8E-08
0.85 34.71 0.95 1.3E-06
0.86 35.09 0.92 1.2E-05
0.66 21.35 0.98 1.8E-08
0.77 30.63 0.95 1.3E-06
0.96 50.69 0.82 3.0E-04
0.62 18.15 0.95 1.3E-06
0.57 13.17 0.97 1.5E-07
0.67 11.21 0.98 4.8E-08
0.72 16.06 0.87 7.9E-05

Deg.-based Avg. Seed Size (%)

0.03
0.09
0.07
0.04
0.11

p-value (linear fit for Int. tests)

Delicious
Digg
EU E-Mail
Hyves
Yelp

R^2 (linear fit for Int. tests)

Louv. Mod.

0.32
0.33
0.24
0.31
0.60
0.52
0.60
0.40
0.76
0.58
0.65
0.35
0.58

Int.-based Avg. Seed Size (%)

Clust. Coeff.

0.35
0.49
0.46
0.23
0.02
0.17
0.08
0.11
0.05
0.07
0.13
0.05
0.05

Name

BlogCatalog1
BlogCatalog2
BlogCatalog3
Buzznet
Douban
Flickr
Flixster
FourSquare
Frienster
Last.Fm
LiveJournal
Livemocha
WikiTalk

1.01
0.69
3.62
1.78
1.73
3.11
0.98
0.44
0.42
0.93
1.09
2.31
0.37

0.90
0.90
0.96
0.93
0.84
0.89
0.89
0.51
0.86
0.79
0.79
0.90
0.82

2.15E-06
2.25E-06
1.42E-08
4.99E-07
2.76E-05
3.89E-06
5.06E-06
9.50E-03
1.38E-05
1.19E-04
1.22E-04
2.99E-06
5.56E-05

2.87
1.10
6.48
2.10
1.44

0.86
0.73
0.95
0.79
0.70

1.5E-05
3.8E-04
5.8E-08
1.2E-04
7.2E-04

8.53
12.45
11.62
11.26
15.48
16.86
10.59
12.47
29.22
7.64
5.54
4.24
3.73

0.89
0.92
0.91
0.91
0.93
0.92
0.91
0.89
0.93
0.90
0.87
0.86
0.79

3.4E-06
8.7E-07
1.2E-06
1.6E-06
3.0E-07
8.1E-07
1.2E-06
4.1E-06
5.5E-07
2.5E-06
9.8E-06
1.3E-05
1.2E-04

TABLE II
R EGRESSION ANALYSIS AND NETWORK - WIDE MEASURES FOR THE
NETWORKS IN C ATEGORIES A, B, AND C.

iteration, the node which allows for the greatest increase in the
expected number of adopters is selected. The approximation
guarantee obtained (less than 0.63 of optimal) is contingent
upon an approximation guarantee for determining the expected
number of adopters - which was later proved to be #P hard. [8] Though finding a such a guarantee is still an open
question, work on counting-complexity problems such as that
of Dan Roth [19] indicate that a non-trivial approximation ratio
is unlikely. Further, the simulation operation is often expensive
- causing the overall time complexity to be O(x · n2 ) where x
is the number of runs per simulation and n is the number of
nodes (typically, x > n). In order to avoid simulation, various
heuristics have been proposed, but these typically rely on the
computation of geodesics - an O(n3 ) operation - which is also
more expensive than our approach.
Additionally, the approximation argument for the nondeterministic case does not directly apply to the original (deterministic) model presented in this paper. A simple counterexample shows that sub-modularity does not hold here. Submodularity (diminishing returns) is the property leveraged by
Kempe et al. in their approximation result.
B. Note on an Upper Bound of the Initial Seed Set
Very recently, we were made aware of research by Daniel
Reichman that proves an upper bound on the minimal size of
a seed set for the special case of undirected networks with
homogeneous threshold values. [18] The proof is constructive
and yields an algorithm that mirrors our approach (although
Reicshman’s algorithm applies only to that special case). We
note that our work and the work of Reichman were developed independently. We also note that Reichman performs no
experimental evaluation of the algorithm.
Given undirected network G where each node vi has degree
di and the threshold value for all nodes is k, Reichman proves
that
P the size kof the minimal seed set can be bounded by
i min{1, di +1 }. For our integer tests, we compared our
results to Reichman’s bound. Our seed sets were considerably
smaller - often by an order of magnitude or more. See Figure 6
for details.
VI. C ONCLUSION

parameter - and the process is studied in that work based on
a probability distribution of nodes with certain values for this
parameter.
A. Notes on Non-Deterministic Tipping
We also note that an alternate version of the model where
the thresholds are assigned randomly has inspired approximation schemes for the corresponding version of the seed
set problem. [8], [12], [15] Work in this area focused on
finding a seed set of a certain size that maximizes of the
expected number of adopters. The main finding by Kempe
et al., the classic work for this model, was to prove that the
expected number of adopters was submodular - which allowed
for a greedy approximation scheme. In this algorithm, at each

As recent empirical work on tipping indicates that it can
occur in real social networks, [6], [24] our results are encouraging for viral marketers. Even if we assume relatively
large threshold values, small initial seed sizes can often be
found using our fast algorithm - even for large datasets. For
example, with the FourSquare online social network, under
majority threshold (50% of incoming neighbors previously
adopted), a viral marketeer could expect a 297-fold return on
investment. As results of this type seem to hold for many
online social networks, our algorithm seems to hold promise
for those wishing to “go viral.”
ACKNOWLEDGMENTS
We would like to thank Gaylen Wong (USMA) for his technical support. Additionally, we would like to thank (in no par-

Seed Size Over Upper Bound

R EFERENCES

A

0.05

BlogCatalog1
BlogCatalog2
BlogCatalog3

0.04

Buzznet
Douban

0.03

Flickr
Flixster

0.02

FourSquare
Friendster
Last.Fm

0.01

LiveJournal
Livemocha

0
1

2

3

4

5

6

7

8

9

WikiTalk

10

Threshold Value

0.16

B

Seed Size Over Upper Bound

0.14
0.12
0.1

Delicious
Digg

0.08

EU E-mail

0.06

Hyves
Yelp

0.04
0.02
0
1

2

3

4

5

6

7

8

9

10

Threshold Value

0.7

C

0.6

CA-AstroPh

Seed Size Over Upper Bound

CA-CondMat03

0.5

CA-CondMat03a
CA-CondMat05

0.4

CA-CondMat99
CA-GrQC

0.3

CA-HepPh
CA-HepTh.txt
CA-NetSci

0.2

Enron E-Mail
URV E-Mail

0.1

YouTube1
YouTube2

0
1

3

5

7

9

Threshold Value

Fig. 6. Integer threshold values vs. the seed size divided by Reichman’s upper
bound [18] the three categories of networks (categories A-C are depicted
in panels A-C respectively). Note that in nearly every trial, our algorithm
produced an initial seed set significantly smaller than the bound - in many
cases by an order of magnitude or more.

ticular order) Albert-László Barabási (NEU), Sameet Sreenivasan (RPI), Boleslaw Szymanski (RPI), John James (USMA),
and Chris Arney (USMA) for their discussions relating to this
work. Finally, we would also like to thank Megan Kearl, Javier
Ivan Parra, and Reza Zafarani of ASU for their help with
some of the datasets. The authors are supported under by the
Army Research Office (project 2GDATXR042) and the Office
of the Secretary of Defense (project F1AF262025G001). The
opinions in this paper are those of the authors and do not necessarily reflect the opinions of the funders, the U.S. Military
Academy, or the U.S. Army.

[1] A. Arenas, “Network data sets,” 2012. [Online]. Available: http:
//deim.urv.cat/∼aarenas/data/welcome.htm
[2] G. J. Baxter, S. N. Dorogovtsev, A. V. Goltsev, and J. F. F. Mendes, “Heterogeneous k-core versus bootstrap percolation on complex networks,”
Phys. Rev. E, vol. 83, May 2011.
[3] O. Ben-Zwi, D. Hermelin, D. Lokshtanov, and I. Newman, “Treewidth
governs the complexity of target set selection,” Discrete Optimization,
vol. 8, no. 1, pp. 87–96, 2011.
[4] V. Blondel, J. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast unfolding
of communities in large networks,” Journal of Statistical Mechanics:
Theory and Experiment, vol. 2008, p. P10008, 2008.
[5] S. Carmi, S. Havlin, S. Kirkpatrick, Y. Shavitt, and E. Shir, “From
the Cover: A model of Internet topology using k-shell decomposition,”
PNAS, vol. 104, no. 27, pp. 11 150–11 154, 2007.
[6] D. Centola, “The Spread of Behavior in an Online Social Network
Experiment,” Science, vol. 329, no. 5996, pp. 1194–1197, Sep. 2010.
[7] N. Chen, “On the approximability of influence in social networks,” SIAM
J. Discret. Math., vol. 23, pp. 1400–1415, September 2009.
[8] W. Chen, C. Wang, and Y. Wang, “Scalable influence maximization for
prevalent viral marketing in large-scale social networks,” in Proceedings
of the 16th ACM SIGKDD international conference on Knowledge
discovery and data mining, ser. KDD ’10. New York, NY, USA: ACM,
2010, pp. 1029–1038.
[9] P. Dreyer and F. Roberts, “Irreversible -threshold processes: Graphtheoretical threshold models of the spread of disease and of opinion,”
Discrete Applied Mathematics, vol. 157, no. 7, pp. 1615 – 1627, 2009.
[10] M. Granovetter, “Threshold models of collective behavior,” The American Journal of Sociology, no. 6, pp. 1420–1443.
[11] M. Jackson and L. Yariv, “Diffusion on social networks,” in Economie
Publique, vol. 16, no. 1, 2005, pp. 69–82.
[12] D. Kempe, J. Kleinberg, and E. Tardos, “Maximizing the spread of
influence through a social network,” in KDD ’03: Proceedings of the
ninth ACM SIGKDD international conference on Knowledge discovery
and data mining. New York, NY, USA: ACM, 2003, pp. 137–146.
[13] M. Kitsak, L. K. Gallos, S. Havlin, F. Liljeros, L. Muchnik, H. E.
Stanley, and H. A. Makse, “Identification of influential spreaders in
complex networks,” Nat Phys, no. 11, pp. 888–893, Nov.
[14] J. Leskovec, “Stanford network analysis project (snap),” 2012. [Online].
Available: http://snap.stanford.edu/index.html
[15] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, J. VanBriesen, and
N. Glance, “Cost-effective outbreak detection in networks,” in KDD
’07: Proceedings of the 13th ACM SIGKDD international conference on
Knowledge discovery and data mining. New York, NY, USA: ACM,
2007, pp. 420–429.
[16] M. E. J. Newman and M. Girvan, “Finding and evaluating community
structure in networks,” Phys. Rev. E, vol. 69, no. 2, p. 026113, Feb 2004.
[17] M. Newman, “Network data,” 2011. [Online]. Available: http:
//www-personal.umich.edu/∼mejn/netdata/
[18] D. Reichman, “New bounds for contagious sets,” Discrete Mathematics
(in press), no. 0, pp. –, 2012. [Online]. Available: http://www.
sciencedirect.com/science/article/pii/S0012365X12000301
[19] D. Roth, “On the hardness of approximate reasoning,” Artificial Intelligence, vol. 82, pp. 273–302, 1996.
[20] T. C. Schelling, Micromotives and Macrobehavior. W.W. Norton and
Co., 1978.
[21] S. B. Seidman, “Network structure and minimum degree,” Social
Networks, vol. 5, no. 3, pp. 269 – 287, 1983. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/037887338390028X
[22] D. J. Watts and P. S. Dodds, “Influentials, networks, and public opinion
formation,” Journal of Consumer Research, vol. 34, no. 4, pp. 441–458,
2007. [Online]. Available: http://www.journals.uchicago.edu/doi/abs/10.
1086/518527
[23] R. Zafarani and H. Liu, “Social computing data repository at ASU,”
2009. [Online]. Available: http://socialcomputing.asu.edu
[24] M. P. Zhang, L., “Two is a crowd: Optimal trend adoption in social
networks,” in Proceedings of International Conference on Game Theory
for Networks (GameNets), 2011.

I

INTRODUCTION

arXiv:1211.0709v1 [cs.SI] 4 Nov 2012

Shaping Operations to Attack Robust Terror Networks
Devon Callahan, Paulo Shakarian
Network Science Center and
Dept. of Electrical Engineering and Computer Science
United States Military Academy
West Point, NY 10996
Email: devon.callahan[at]usma.edu,
paulo[at]shakarian.net
November 6, 2012

Abstract
Security organizations often attempt to disrupt terror or insurgent
networks by targeting “high value targets” (HVT’s). However,
there have been numerous examples that illustrate how such networks are able to quickly re-generate leadership after such an operation. Here, we introduce the notion of a shaping operation in
which the terrorist network is first targeted for the purpose of reducing its leadership re-generation ability before targeting HVT’s. We
look to conduct shaping by maximizing the network-wide degree
centrality through node removal. We formally define this problem and prove solving it is NP-Complete. We introduce a mixed
integer-linear program that solves this problem exactly as well as a
greedy heuristic for more practical use. We implement the greedy
heuristic and found in examining five real-world terrorist networks
that removing only 12% of nodes can increase the network-wide
centrality between 17% and 45%. We also show our algorithm can
scale to large social networks of 1, 133 nodes and 5, 541 edges on
commodity hardware.

I

Jeffrey Nielsen, Anthony N. Johnson
Network Science Center and
Dept. of Mathematical Science
United States Military Academy
West Point, NY 10996
Email: jeffrey.nielsen[at]usma.edu,
anthony.johnson[at]usma.edu

Introduction

Terrorist and insurgent networks are known for their ability to regenerate leadership after targeted attacks. For example, the infamous Al Qaeda in Iraq terrorist leader Abu Musab al-Zarqawi was
killed on June 8th, 2006 1 only to be replaced with Abu Ayyub alMasri about a week later. 2 Here, we introduce the notion of a shaping operation in which the terrorist network is first targeted for the
purpose of reducing its leadership re-generation ability. Such shaping operations would then be followed by normal attacks against
high value targets – however the network would be less likely to
recover due to the initial shaping operations. In this paper, we look
to shape such networks by increasing network-wide centrality, first
1 http://www.nytimes.com/2006/06/08/world/middleeast/08cnd-iraq.html?
2 http://articles.cnn.com/2006-06-15/world/iraq.main

r=1
1 al-zarqawi-al-qaeda-

leader-zawahiri? s=PM:WORLD

1

introduced in [1]. Intuitively, this measure provides insight into
the criticality of high-degree nodes. Hence, a network with a low
network-wide centrality is a more decentralized organization and
likely to regenerate leadership. In the shaping operations introduced in this paper, we seek to target nodes that will maximize this
measure - making follow-on attacks against leadership more effective. Previous work has primarily dealt with the problem of leadership regeneration by focusing on individuals likely to emerge as
new leaders [2]. However, targeting or obtaining information about
certain individuals may not always be possible. Hence, in this paper, we target nodes that affect the reduce the network’s ability
regenerate leadership as a whole.
The main contributions of this paper is the introduction of a formal problem we call FRAGILITY (Section II) which seeks to find
a set of nodes whose removal would maximize the network-wide
centrality. We also included in the problem a “no strike list” - nodes
in the network that cannot be targeted for various reasons. This is
because real-world targeting of terrorist or insurgent networks often includes restrictions against certain individuals. We also prove
that this problem is NP-complete (and the associated optimization
problem is NP-hard) which means that an efficient algorithm to
solve it optimally is currently unknown. We then provide two algorithms for solving this problem (Section III). Our first algorithm
is an integer program that ensures an exact solution and, though
intractable by our complexity result, may be amenable to an integer program solver. Then we introduce a greedy heuristic that
we show experimentally (in Section IV) to provide good results
in practice (as we demonstrate on six different real-world terrorist
networks) and scales to networks of 1, 133 nodes and 5, 541 edges.
In examining five real-world terrorist networks, we found that successful targetting operations against only 12% (or less) of nodes
can increase the network-wide centrality between 17% and 45%.
Additionally, we discuss related work further in Section V.
We would like to note that the targeting of individuals in a terrorist or insurgent network does not necessarily mean to that they
should be killed. In fact, for “shaping operations” as the ones described in this paper, the killing of certain individuals in the net-

II

TECHNICAL PRELIMINARIES AND COMPUTATIONAL COMPLEXITY

work may be counter-productive. This is due to the fact that the
capture of individuals who are likely emergent leaders may provide further intelligence on the organization in question.

II Technical Preliminaries and Computational Complexity
We assume that an undirected social network is represented by the
graph G = (V, E). Additionally, we assume a “no strike” set,
S ⊆ V . Intuitively, these are nodes in a terrorist/insurgent network that cannot be targeted. This set is a key part of our framework, as real-world targeting of terrorist and/or insurgents in a terrorist/insurgent network is often accompanied by real-world constraints. For example, consider the following:
• We may know an individual’s relationships in the terrorist/insurgent network, but may not have enough information
(i.e. where he or she may reside, enough evidence, etc.) to
actually target him or her.
• The potential target may be politically sensitive.
• The potential target may have fled the country or area of
operations but still maintains his or her role in the terrorist/insurgent network through electronic communication.
• The potential “target” may actually be a source of intelligence
and/or part of an ongoing counter-intelligence operation (i.e.
as described in [3]).
Throughout this paper we will also use the following notation.
The symbols NG , MG will denote the sizes of V, E respectively.
For each i ∈ V , we will use di to denote the degree of that node
(the number of individuals he/she is connected to) and ηi to denote
the set of neighbors andSwe extend this notation for subsets of V
(for V 0 ⊆ V, η(V 0 ) = i∈V 0 ηi ). We will use the notation κi to
denote all edges in E that are adjacent to node i and the notation
d∗G to denote the maximum degree of the network. Given some
subset V 0 ⊆ V , we will use the notation G(V 0 ) to denote the subgraph of G induced by V 0 . We describe an example network in
Example II.1.

Figure 1: Sample network (Gsam ) for Example II.1.
Definition II.1 (Network-Wide Degree Centrality [1]) The degree centrality of a network G, denoted CG is defined as:
P ∗
i dG − di
CG =
(1)
(NG − 1)(NG − 2)
We note that there are other types of network-wide centrality (i.e.
network-wide betweenness, closeness, etc.). We leave the consideration of these alternate definitions of network-wide centrality to
future
P work. Freeman [1] shows that for a star network, the quantity i d∗G −di equals (NG −1)(NG −2) - and this is the maximum
possible value for this quantity. Hence, the value for CG can be at
most 1. As this equation is clearly always positive, network-wide
degree centrality is a scalar in [0, 1]. Turning back to Example II.1,
we can compute CGsam = 0.38 - which seems to indicate that in
this particular terrorist/insurgent network that, after leadership is
targeted, there is a cadre of second-tier individuals who can eventually take control of the organization. Throughout this paper, we
find it useful to manipulate Equation 1 as follows.
CG

=

NG d∗G − 2MG
(NG − 1)(NG − 2)

(2)

We notice that the centrality of a network really depends on
three
things: number of nodes, number of edges, and the highest
Example II.1 Consider network Gsam in Figure 1. Nodes a and b
degree
of any node in the network. We leverage this re-arranged
may be leaders of a strategic cell that provides guidance to attack
equation
in many of our proofs. Further, we will use the function
cells (nodes c-f and g-j). Note that no members in the attack cells
f
ragile
: V → < to denote the level of network-wide of the
G
are linked to each other. Also note that if node a is the leader, and
graph
after
some set of nodes is removed. Hence, f ragileG (V 0 ) =
targeted, he could easily be replaced by b.
CG(V −V 0 ) . We note that this function has some interesting characteristics. For example, for some subset V 0 ⊂ V and element
A Network-Wide Degree Centrality
i ∈ V − V 0 , it is possible that f ragileG (V 0 ) > f ragile(V 0 ∪ {i})
We now introduce the notion of network-wide degree centrality as or f ragileG (V 0 ) < f ragile(V 0 ∪ {i}), hence f ragileG is not
per [1]. The key intuition of this paper is to use this centrality as a necessarily monotonic or anti-monotonic in this sense. Further,
measure of the network’s ability to re-generate leadership.
given some additional element j ∈ V − V 0 , it is possible that
f ragileG (V 0 ∪ {j}) − f ragileG (V 0 ) > f ragileG (V 0 ∪ {i, j}) −
2

B

III

Problems and Complexity Results

f ragileG (V 0 ∪ {j}) or f ragileG (V 0 ∪ {j}) − f ragileG (V 0 ) <
f ragileG (V 0 ∪ {i, j}) − f ragileG (V 0 ∪ {j}). Hence, f ragileG
is not necessarily sub- or super- modular either. Consider Example II.2.
Example II.2 Consider the network Gsam in Figure 1.
Here, f ragileGsam (∅) = 0.33, f ragileGsam ({a}) =
f ragileGsam ({b}) = 0.57, f ragileGsam ({c}) = 0.30, and
f ragileGsam ({a, b}) = 0.0. The fact that f ragileGsam ({c} <
f ragileGsam (∅) and f ragileGsam ({a} > f ragileGsam (∅)
illustrate that f ragileGsam is not necessarily monotonic or
anti-monotonic. Now let us consider the incremental increase of
adding an additional element. Adding a to ∅ causes f ragileGsam
to increase by 0.24 while adding a to {b} ⊃ ∅ causes f ragileGsam
to decrease by 0.57 - implying sub-modularity. However, adding
c to ∅ causes f ragileGsam to decrease by 0.03 while adding
c to set {a, b} ⊃ ∅ causes f ragileGsam to increase by 0.1 (as
f ragileGsam ({a, b, c} = 0.1) - implying super-modularity. Hence,
f ragileGsam is not necessarily sub- or super- modular.

B

Problems and Complexity Results

We now have all the pieces to introduce our problems of interest.
We include decision and optimization versions.
F RAGILIT Y (k, x, G, S):
INPUT: Natural number k, real number x, network G = (V, E),
and no-strike set S
OUTPUT: “Yes” if there exists set V 0 ⊆ V − S s.t. |V 0 | ≤ k and
f ragileG (V 0 ) > x – “no” otherwise.
F RAGILIT Y OP T (k, G, S):
INPUT: Natural number k, network G = (V, E), and no-strike set
S
OUTPUT: Set V 0 ⊆ V − S s.t. |V 0 | ≤ k s.t. 6 ∃V 00 ⊆ V − S s.t.
|V 00 | ≤ k and f ragileG (V 00 ) > f ragileG (V 0 ).
As our problems seek to find sets of nodes, rather than individual ones, it raises the question of “how difficult are these problems.” We prove that F RAGILIT Y is NP-Complete - meaning an efficient algorithm to solve it optimally is currently unknown. Following directly from this result is the NP-hardness of
F RAGILIT Y OP T . Below we state and prove this result.
Theorem 1 (Complexity of F RAGILIT Y ) F RAGILIT Y
NP-Complete.

ALGORITHMS

or j (or both) are in V ∗ . This problem is well-known to be NPhard. First we create a new network G = (V, E) which consists of graph G∗ but with NG∗ + 2 additional nodes which form
a star that is disconnected from the rest of the network. All of
the new nodes are put in the no-strike set S (part of the input
of F RAGILIT Y ). Clearly, the center of this star is always the
most central node in the graph, no matter what is removed from set
V − S. This allows us to treat d∗G as a constant equal to NG + 1.
Also note that with this construction, for both problems, if a solution exists of less than size k, there also exists a solution of exactly size k. Further, we note that for any subset of V whose removal does not affect the overall maximal degree of the network
(which is any node outside the set S - hence in some corresponding subset of V ∗ in the graph of the dominating set problem), when
some set V 0 (of size k) is removed from V , the network-wide degree centrality for the resulting graph can Sbe expressed as follows:
(N −k)(N +1)−2(M −|
0 κ |)
f ragileG (V 0 ) = G (NGG−k−1)(NGG−k−2)i∈V i .
The proof of correctness of the embedding rests on proving that a
“yes” answer is returned for the vertex cover problem iff
G −k)(NG +1)−2NG∗ −2
F RAGILIT Y (k, (N(N
, G, S) = “yes”.
G −k−1)(NG −k−2)
First, suppose by way of contradiction (BWOC) there is a “yes”
answer to the V C problem and a “no” answer to the corresponding
F RAGILIT Y problem. Let V ∗∗ be the set of nodes that cause
a “yes” answer to V C. If we remove the corresponding nodes
from G, there are NG∗ + 1 edges left in that network. Hence, as
this is a set of size k (thus, meeting the cardinality requirement of
G −k)(NG +1)−2NG∗ −4
F RAGILIT Y then f ragileG (V ∗∗ ) = (N(N
G −k−1)(NG −k−2)
which would cause a “yes” answer for F RAGILIT Y – hence a
contradiction.
Going the other direction, suppose BWOC there is a “yes” answer
to the F RAGILIT Y problem and a “no” answer to the corresponding V C problem. Let V 0 be the nodes in the solution to
F RAGILIT Y . Clearly, this set is of size k and by how we set
up the no-strike list (S), there are corresponding nodes in G∗∗ . As
these nodes cause a “yes” answer to F RAGILIT Y , they result in
the removal of MG∗ number of edges in G. By the construction,
none of these edges are adjacent to nodes in S. Hence, there are
corresponding edges in G∗ . As this is also the number of edges
in G∗ , then this set is also a vertex cover - hence a contradiction.
Hence, as we have shown membership in NP and that this problem
is at least as hard as the dominating set problem (resulting in NP
hardness), the statement of the theorem follows.

is Corollary 1 (Hardness of F RAGILIT Y OP T )
F RAGILIT Y OP T is NP-hard

Proof. Follows directly from Theorem 1.
Proof. Membership in NP is trivial, consider a set V 0 of size k, –
clearly we can calculate f ragileG (V 0 ) in polynomial time.
Next we consider the vertex-cover (V C) problem and show that it III Algorithms
can be embedded into an instance of F RAGILIT Y . In the V C
problem, the input consists of undirected graph G∗ = (V ∗ , E ∗ ) Now with the problems and their complexity identified, we proand natural number k. The output is “yes” iff there is a set ceed to develop algorithms to solve them. First, we develop an
V ∗∗ ⊆ V ∗ of size at most k s.t. for all (i, j) ∈ E ∗ , either i integer program that, if solved exactly, will produce an optimal
3

A

III

Integer Program

solution. We note that solving a general integer program is also
NP-hard. Hence, an exact solution will likely take exponential
time. However, good approximation techniques such as branchand-bound exist and mature tools such as QSopt and CPLEX can
readily take and approximate solutions to integer programs. We
follow our integer program formulation with a greedy heuristic.
Though we cannot guarantee that the greedy heuristic provides an
optimal solution, it often provides a natural approach to approximating many NP-hard optimization problems.

A

Integer Program

Our first algorithm is presented in the form of an integer program.
The idea is that certain variables in the integer program correspond
with the nodes in the original network that can be set to either 0
or 1. An objective function, which mirrors the f ragile function
is then maximized. When this function is maximized, all nodes
associated with a 1 variable are picked as the solution.
Definition III.1 (F RAGILIT Y IP ) For each i ∈ V , create
variables Xi , Zi . For each undirected edge ij ∈ E, create three
variables: Yij , Qij , Qji . Note that the edge is considered in only
“one direction” for the Y variables and both directions for the Q
variables. We define the F RAGILIT Y IP integer program as
follows:
max

P
P
P
(NG − i Xi ) ij Qij −2 ij Yij
P
P
(NG −1− i Xi )(NG −2− i Xi )

S
Proof. (1.) Suppose, BWOC, Xi =1 i is not an optimal
S solution
to F RAGILIT Y OP T . Then there is some V 0 6= Xi =1 i that
is. Suppose ∀i ∈ S, X = 1 and ∀i ∈
/ S, X = 0. Clearly, by the
definition of a solution to F RAGILIT Y OP T , constraints 3,11
and 12 are all met. Constraints 5 and 6 set variables associated
with edges adjacent to nodes not in V 0 to 1. Hence, the quantity
P
ij Yij is equal to the number of edges in the network. The Y
edge variables (both of them for each edge) are also set in a similar
manner. Constraints 4,10 ensures that onlyPone setPof such edge
variables are set to 1. Hence, the quantity i Xi ) ij Qij is the
degree of one node in the network. As this quantity is present in the
∗
objective function
P and non-negative, it corresponds to the dG . As0
we note that i Xi is equal to the number of nodes in G when V
is removed, we see that this function is f ragileG . As this quantity
is maximized, we have a contradiction.
(2.) Suppose, BWOC, ∀i ∈ S, X = 1 and ∀i ∈
/ S, X = 0 is
not an optimal solution to F RAGILIT Y IP . Using the same
line of reasoning as above, we see that the objective function of
F RAGILIT Y IP is the same as f ragileG , which also gives us
a contradiction.
Note that this integer program does not have a linear objective function. However, this can be accommodated for by instead
solving k different integer programs and taking the solution from
whichever one returns the greatest value for the objective function
(that is greater than the initial network-wide degree centrality, of
course). In this case, each integer program is identified with a natural number i ∈ {1, . . . , k} and the ith integer program has the
following objective function:

Subject to:
max
P

Xi ≤ k
Pi
i Zi = 1

(3)

∀ij ∈ E

Yij ≤ 1 − Xi

(5)

∀ij ∈ E

Yij ≤ 1 − Xj

(6)

(4)

∀ij ∈ E

Qij ≤ Yij

(7)

∀ij ∈ E

Qij ≤ Yji

(8)

∀ij ∈ E

Qij ≤ Zi

(9)

∀i ∈ V

Zi ∈ {0, 1}

(10)

Xi = 0

(11)

Xi ∈ {0, 1}

(12)

∀i ∈ S
∀i ∈ V − S

Next we prove how many variables and constraints
F RAGILIT Y IP requires as well as prove that it provides
a correct solution to F RAGILIT Y OP T .
Proposition III.1 F RAGILIT Y IP has 2NG + 3MG variables
and 2 + 2NG + 5MG constraints.
Proposition III.2 (1.)
Given Sthe vector X returned by
F RAGILIT Y IP , the set
Xi =1 i is a solution to
F RAGILIT Y OP T .
(2.)Given a solution V 0 to F RAGILIT Y OP T , ∀i ∈ S, X = 1
and ∀i ∈
/ S, X = 0 will maximize F RAGILIT Y IP .
4

ALGORITHMS

P
P
(NG −i) ij Qij −2 ij Yij
(NG −1−i)(NG −2−i)

As well as constraint 3 as follows:
P
i Xi ≤ i

(13)

(14)

Notice that now the quantities (NG − i) and (NG − 1 − i)(NG −
2 − i) can be treated as constants, making the objective function
linear. However, for networks with a heterogeneous degree distribution where NG >> k, it is likely that only the integer program
for the case where i = k is needed as removing any node with
edges that is unconnected to a maximal degree node will result in
an increase in network-wide degree centrality.
Again, we stress that F RAGILIT Y IP provides an exact solution. As integer-programming is also NP-hard, solving these
constraints is likely intractable unless P = N P . However, techniques such as branch-and-bound and mature solvers such as QSopt
and CPLEX can provide good approximate solutions to such constraints. Even if the integer program must be linear, we can use the
techniques described above to solve k smaller integer programs or
obtaining an approximation by treating the terms involving the total
number of nodes in the resulting graph (in the objective function)
as constants. Additionally, a relaxation of the above constraints
where Zi and Xi variables lie in the interval [0, 1] is solvable in
polynomial time and would provide a lower-bound on the solution to the problem (although this would likely be a loose bound in
many cases).

B

IV

A Greedy Heuristic

B

IMPLEMENTATION AND EXPERIMENTS

A Greedy Heuristic

Example III.1 Following from Examples II.1-II.2 using the terThe integer program introduced in the last section can be lever- rorist/insurgent network Gsam from Figure 1, suppose a user wants
aged by an integer-program solver for an approximate solution to to identify 3 nodes that will cause the network to become “as fragile
F RAGILIT Y OP T . However, it likely will not scale well to ex- as possible” and is able to target any node. Hence, he would like
tremely large networks. Therefore, we introduce a greedy heuristic to solve F RAGILE OP T (3, Gsam , ∅) and decides to do so usto find an approximate solution. The ideas is to iteratively pick the ing GREEDY F RAGILE. Initially, f ragileGsam (∅) = 0.33.
node in the network that provides the greatest increase in f ragile In the first iteration, it selects and removes node a, increasing
the fragility (f ragileGsam ({a}) = 0.57). In the next itera- and does not cause a decrease.
tion, it selects node j, giving us f ragileGsam ({a, j}) = 0.57.
Algorithm 1 GREEDY FRAGILE
Finally, in the third iteration, it picks node c. This results in
Require: Network G = (V, E), no-strike set S ⊆ V , cardinality f ragileGsam ({a, j, c}) = 0.6. The algorithm then terminates.
constraint k
Ensure: Subset V 0
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:

V0 =∅
f lag = T RU E
while |V 0 | ≤ k and f lag do
curBest = null, curBestScore = 0, haveV alidScore =
F ALSE
for i ∈ V − (V 0 ∪ S) do
curScore = f ragileG (V 0 ∪ {i}) − f ragileG (V 0 )
if curScore ≥ curBestScore then
curBest = i
curBestScore = curScore
haveV alidScore = T RU E
end if
end for
if haveV alidScore = F ALSE then
f lag = F ALSE
else
V 0 = V 0 ∪ {curBest}
end if
end while
return V 0 .

IV

Implementation and Experiments

All experiments were run on a computer equipped with an Intel
Core 2 Duo CPU T9550 processor operating at 2.66 GHz (only
one core was used). The machine was running Microsoft Windows
7 (32 bit) and equipped with 4.0 GB of physical memory. We implemented the GREEDY FRAGILE algorithm using Python 2.6 in
under 30 lines of code that leveraged the NetworkX library available from http://networkx.lanl.gov/.
We compared the results of the GREEDY FRAGILE to three
other more traditional approaches to targeting that rely on centrality measures from the literature. Specifically, we look at the top
closeness and betweenness nodes in the network. Given node i,
its closeness is the inverse of the average shortest path length from
node i to all other nodes in the graph. Betweenness, on the other
hand, is defined as the number of shortest paths between node pairs
that pass through i. Formal definitions of both of these measures
can be found in [4].

A

Datasets

We studied the effects of our algorithm on five different datasets.
The network Tanzania [5] is a social network of the individuals
involved with the Al Qaeda bombing of the U.S. embassy in Dar
Proposition III.3 If GREEDY F RAGILE returns a non- es Salaam in 1998. It was collected from newspaper accounts by
empty solution (V 0 ), then |V 0 | ≤ k and f ragileG (V 0 ) > subject matter experts in the field. The remainder networks, GenTerrorNw1-GenTerrorNw4 are terrorist networks generated from
f ragileG (∅).
real-world classified datasets[6, 7]. The Tanzania and the GenTerProof. As the algorithm terminates its main loop once the cardi- rorNw1-GenTerrorNw4 datasets used in our analysis were multinality of the solution reaches k and as in each iteration, the variable modal networks, meaning they contain multiple node classes such
as Agents, Resources, Locations, etc. The presence of the different
curBestScore is initialized as zero, the statement follows.
node classes generate multiple or meta networks, which, in their
2
Proposition III.4 GREEDY F RAGILE runs in O(kNG
) original state, do not provide the single-mode Agent by Agent nettime.
work needed to test our algorithms. Johnson and McCulloh [8]
demonstrated a mathematical technique to convert meta networks
Proof. We note that f ragile is computed in O(NG ) time as it into single-mode networks without losing critical information. Usmust update the node with the maximum degree. As the outer loop ing this methodology, we were able to derive distant relationships
of the algorithm iterates at most k times and the inner loop iterates between nodes as a series of basic matrix algebra operations on all
NG times, the statement follows.
five networks. The result is an agent based social network of potenThough our guarantees on GREEDY F RAGILE are limited, tial terrorist. Characteristics of the transformed networks of agent
we show that it performs well experimentally in the next section.
node class only can be found in Table 1.
The following two propositions describe characteristics of the
output and run-time of GREEDY F RAGILE, respectively.

5

B

IV

Increasing the Fragility of Networks

Table 1: Network Datasets
Name
Tanzania
GenTerrorNw1
GenTerrorNw2
GenTerrorNw3
GenTerrorNw4
URV E-Mail
CA-NetSci

B

Nodes
17
57
102
105
135
1, 133
1, 463

Edges
29
162
388
590
556
5, 541
2, 743

Density
0.213
0.102
0.0753
0.108
0.0615
0.00864
0.00256

Avg. Degree
3.412
5.684
7.608
11.238
8.237
9.781
3.750

Increasing the Fragility of Networks

IMPLEMENTATION AND EXPERIMENTS

centralize. We display these results graphically in Figures 3-7.
Notice that GREEDY FRAGILE consistently causes an increase
in the network-wide degree centrality. An analysis of variance
(ANOVA) reveals that there is a significant difference in the performance among our algorithm and the centrality measures with
respect to increase or decrease in network-wide degree centrality
(p-value less than 2.2 · 10−16 , calculated with R version 2.13). Additionally, pairwise analysis conducted using Tukey’s Honest Significant Difference (HSD) test indicates that the results of our algorithm differ significantly from any of the three centrality measures with a probability approaching 1.0 (95% confidence, calculated with R version 2.13). Typically, the ratio of percent increase
in fragility to the percent of removed nodes is typically 2 : 1 or
greater.

In our experiments, we showed that our algorithm was able to significantly increase the network-wide degree centrality by removing nodes - hence increasing the f ragile function with respect to
a given network. In each of the five real-world terrorist networks
that we examined, removal of only 12% of nodes can increase the
network-wide centrality between 17% and 45% (see Figures 3-7).
In Figure 2 we show a visualization of how the Tanzania network
becomes more “star-like” with subsequent removal of nodes by the
greedy algorithm.

Figure 3: Percent of nodes removed vs. percent increase in fragility
for the Tanzania network using GREEDY FRAGILE, top degree,
top closeness, and top betweenness. The scale of the x-axis is positioned at 0%.

C
Figure 2: Visualization of the Tanzania network after nodes removed by GREEDY FRAGILE. Panel A shows the original network. Panel B shows the network after 3 nodes are removed, panel
C shows the network after 5 nodes are removed, and panel D shows
the network after 9 nodes are removed. Notice that the network
becomes more “star-like” after subsequent node removals. In our
experiment, after GREEDY FRAGILE removed 11 of the nodes
in the network, it took the topology of a star.

Runtime

We also evaluated the run-time of the GREEDY FRAGILE algorithm. With the largest terror network considered (GenTerrorNw4),
we achieved short runtime (under 7 seconds) on standard commodity hardware (see Figure 8). Hence, in terms of runtime, our
algorithm is practical for use by a real-world analyst. As predicted in our time complexity result, we found that the runtime
of GREEDY FRAGILE increases with the number of nodes removed. We note that the implementations of top degree, closeness,
and betweenness calculate those measures for the entire network at
once - hence increasing the number of nodes to remove does not
affect their runtime.

For comparison, we also looked at the removal of high degree,
closeness, and betweenness nodes. Removal of high-degree, closeness, or betweenness nodes tended to increase the network-wide
D Experiments on Large Data-Sets
centrality. In other words, traditional efforts of targeting leadership without first conducting shaping operations may actually To study the scalability of GREEDY FRAGILE, we also employed
increase the organization’s ability to regenerate leadership - as it on two large social networks. Note that these datasets are not
such targeting operations effectively cause an organization to de- terrorist or insurgent networks. However, the larger size of these
6

V

RELATED WORK

Figure 4: Percent of nodes removed vs. percent increase in fragility
for the GenTerrorNet1 network using GREEDY FRAGILE, top
degree, top closeness, and top betweenness. The scale of the x-axis
is positioned at 0%.

Figure 5: Percent of nodes removed vs. percent increase in fragility
for the GenTerrorNw2 network using GREEDY FRAGILE, top
degree, top closeness, and top betweenness. The scale of the x-axis
is positioned at 0%.

datasets is meant to illustrate how well our approach scales. For
these experiments, we used an e-mail network from University
Rovira i Virgili (URV E-Mail) [9] and a Network Science collaboration network (CA-NetSci) from [10] (see Table 1). In Figure 9 we show the percentage of nodes removed vs. the percent
increase in fragility. We note that 2 : 1 ratio of percent increase in
fragility to the percent of removed nodes appears to be maintained
even in these large datasets. In Figure 10 we show the runtime for
GREEDY FRAGILE on the two large networks. We note that the
behavior of runtime vs. number of nodes removed resembles that
of the GenTerrorNw4 network from the previous section. Also of
interest is that the algorithm was able to handle networks of over a
thousand nodes in about 20 minutes on commodity hardware.

connectivity in the network. Additionally, fragmentation of a network may result in the splintering of an organization into smaller,
but more radical and deadly organizations. This happens because
in some cases, it may be desirable to keep certain terrorist or insurgent leaders in place to restrain certain, more radical elements
of their organization. Such splinter was observed for the insurgent
organization Jaysh al-Mahdi in Iraq [16]. Further, these techniques
do not specifically address the issue of emerging leaders. Hence, if
they were to be used for counter-terrorism or counter-insurgency,
they would likely still benefit from a shaping operation to reduce
organization’s ability to regenerate leadership.
There has been some previous work on identifying emerging
leaders in terrorist networks. Although such an approach could
be useful in identifying certain leaders, it does not account the organizations ability as a whole to regenerate leadership. In [2], the
topic of cognitive demand is studied. The cognitive load of an individual deals with their ability to handle multiple demands on their
time and work on complex tasks. Typically, this can be obtained
by studying networks where the nodes may represent more than individual people - but tasks, events, and responsibilities. However,
it may often be the case that this type of information is often limited or non-existent in many situations. Additionally, as discussed
throughout this paper, the targeting of individual nodes may often
not be possible for various reasons. Hence, our framework, that focuses on the network’s ability to regenerate leadership as opposed
to finding individual emerging leaders may be more useful as we
can restrict the available nodes in our search using the “no strike
list.” By removing these nodes from targeting consideration - but
by still considering their structural role - our framework allows a
security force to reduce the regenerative ability of a terror network
by “working around” individuals that may not be targeted.
In more recent work [17] looks at the problem of removing leadership nodes from a terrorist or criminal network in a manner that

V Related Work
Various aspects of the resiliency of terrorist networks have been
previously explored in the literature. For instance, [11] studies the
ability such network to facilitate communication while maintaining secrecy while [12] studies how such networks are resilient to
cascades. However, to our knowledge, the network-wide degree
centrality in such networks - and how to increase this property has not been previously studied.
There has been much work dealing with the removal of nodes
from a network to maximize fragmentation [13, 14, 15] where the
nodes removed are mean to either increase fragmentation of the
network or reduce the size of the largest connected component.
While this work has many applications, it is important to note that
there are special considerations of terrorist and insurgent networks
that we must account for in a targeting strategy. For instance, if
conducting a counter-intelligence operation while targeting, as in
the case of [3], it may be desirable to preserve some amount of
7

REFERENCES

Figure 6: Percent of nodes removed vs. percent increase in fragility
for the GenTerrorNw3 network using GREEDY FRAGILE, top
degree, top closeness, and top betweenness. The scale of the x-axis
is positioned at 0%.

accounts for new links created in the aftermath of an operation.
Additionally, [18] look at identifying leaders in covert terrorist network who attempt to minimize their communication due to the
clandestine nature of their operations. They do this by introducing a new centrality measure called “covertness centrality.” Both
of these approaches are complementary to ours as they focus on
the leadership of the terrorist or insurgent group - as this approach
focuses on the networks ability to re-generate leadership. A more
complete integration of this approach leadership targeting method
such as these (i.e. using a network-wide version of covertness centrality) is an obvious direction for future work.

VI

Figure 7: Percent of nodes removed vs. percent increase in fragility
for the GenTerrorNw4 network using GREEDY FRAGILE, top
degree, top closeness, and top betweenness. The scale of the x-axis
is positioned at 0%.

Acknowledgements
We would like to thank Jon Bentley and Charles Weko for their
feedback on an earlier version of this paper.
Some of the authors are supported under by the Army Research
Office (project 2GDATXR042). The opinions in this paper are
those of the authors and do not necessarily reflect the opinions of
the funders, the U.S. Military Academy, or the U.S. Army.

References
[1] L. Freeman, “Centrality in social networks conceptual clarification,” Social networks, vol. 1, no. 3, pp. 215–239, 1979.
I, A, II.1, A

Conclusions

In this paper we described how to target nodes in a terrorist or insurgent network as part of a shaping operation designed to reduce the
organization’s ability to regenerate leadership. Our key intuition
was to increase the network-wide degree centrality which would
likely have the effect of eliminating emerging leaders as maximizing this quantity would intuitively increase the organization’s reliance on a single leader. In this paper, we found that though identifying a set of nodes to maximize this network-wide degree centrality is NP-hard, our greedy approach proved to be a viable heuristic for this problem, increasing this quantity between 17% − 45%
in our experiments. Future work could include an examination of
other types of network-wide centrality – for instance network-wide
closeness centrality – instead of network-wide degree centrality.
Another aspect that we are considering in ongoing research is determining the effectiveness of the shaping strategy when we have
observed only part of the terrorist or insurgent organization – as is
often the case as such networks are created from intelligence data.
8

[2] K. Carley, “Estimating Vulnerabilities in Large Covert Networks,” Carnegie Mellon University, Tech. Report, 2004. I,
V
[3] O. Deforest and D. Chanoff, Slow Burn: The Rise and Bitter Fall of American Intelligence in Vietnam. Simon and
Schuster, 1990. II, V
[4] S. Wasserman and K. Faust, Social Network Analysis: Methods and Applications, 1st ed., ser. Structural analysis in the
social sciences. Cambridge University Press, 1994, no. 8.
IV
[5] I.-C. Moon, “Destabilization of adversarial organizations
with strategic interventions,” Ph.D. dissertation, Carnegie
Mellon University, Pittsburgh, PA, USA, Jun. 2008. A
[6] K. M. Carley, “FICTA data,” Center for Computational
Analysis of Social and Organizational Systems, 2009. A

REFERENCES

REFERENCES

Figure 8: Number of nodes removed vs. runtime for the Gen- Figure 10: Number of nodes removed vs. runtime for the URV
TerrorNw4 network using GREEDY FRAGILE, top degree, top E-Mail and CA-NetSci networks using GREEDY FRAGILE.
closeness, and top betweenness.
[11] R. Lindelauf, P. Borm, and H. Hamers, “The influence of
secrecy on the communication structure of covert networks,”
Social Networks, vol. 31, no. 2, pp. 126 – 137, 2009. V
[12] A. Gutfraind, “Optimizing topological cascade resilience
based on the structure of terrorist networks,” PLoS ONE,
vol. 5, no. 11, p. e13448, 11 2010. V
[13] R. Albert, H. Jeong, and A. Barabási, “Error and attack tolerance of complex networks,” Nature, vol. 406, pp. 378–382,
2000. V
[14] S. Borgatti, “Identifying sets of key players in a social network,” Computational and Mathematical Organization Theory, vol. 12, no. 1, 2006. V
Figure 9: Percent of nodes removed vs. percent increase in
fragility for the URV E-Mail and CA-NetSci networks using
GREEDY FRAGILE.
[7] Dynamic Network Analysis (DNA) and ORA. San Francisco, CA: 2nd International Conference on Cross-Cultural
Decision Making: Focus 2012, Jul. 2012. A
[8] A. N. Johnson and I. A. McCulloh, Advanced Network Analysis and Targeting (ANAT), 1st ed., Joint Training Counter
IED Operational Integration Center, Washington D.C., Jan.
2009. A
[9] A. Arenas, “Network data sets,” 2012. [Online]. Available:
http://deim.urv.cat/˜aarenas/data/
welcome.htm D
[10] M. Newman, “Network data,” 2011. [Online]. Available: http://www-personal.umich.edu/˜mejn/
netdata/ D
9

[15] A. Arulselvan, C. Commander, L. Elefteriadou, and P. M.
Pardalos, “Detecting critical nodes in sparse graphs,” Computers and Operations Research, vol. 36, 2009. V
[16] M. Cochrane, “The Fragmentation of the Sadrist Movement,” The Institute for the Study of War, Iraq Report 12,
Jan. 2009. V
[17] R. Petersen, C. Rhodes, and U. Wiil, “Node removal in
criminal networks,” in Intelligence and Security Informatics Conference (EISIC), 2011 European, Sep. 2011, pp. 360
–365. V
[18] M. Ovelgonne, C. Kang, A. Sawant, and V. Subrahmanian,
“Covertness centrality in networks,” in Proc. 2012 Intl. Symposium on Foundations of Open Source Intelligence and Security Informatics, Aug. 2012. V

