The performance of action recognition in video sequences depends significantly on the representation of actions and the similarity measurement between the representations. In this paper, we combine two kinds of features extracted from the spatio-temporal interest points with context-aware kernels for action recognition. For the action representation, local cuboid features extracted around interest points are very popular using a Bag of Visual Words (BOVW) model. Such representations, however, ignore potentially valuable information about the global spatio-temporal distribution of interest points. We propose a new global feature to capture the detailed geometrical distribution of interest points. It is calculated by using the 3D  R  transform which is defined as an extended 3D discrete Radon transform, followed by the application of a two-directional two-dimensional principal component analysis. For the similarity measurement, we model a video set as an optimized probabilistic hypergraph and propose a context-aware kernel to measure high order relationships among videos. The context-aware kernel is more robust to the noise and outliers in the data than the traditional context-free kernel which just considers the pairwise relationships between videos. The hyperedges of the hypergraph are constructed based on a learnt Mahalanobis distance metric. Any disturbing information from other classes is excluded from each hyperedge. Finally, a multiple kernel learning algorithm is designed by integrating the  l2l2  norm regularization into a linear SVM classifier to fuse the  R  feature and the BOVW representation for action recognition. Experimental results on several datasets demonstrate the effectiveness of the proposed approach for action recognition.
Although several methods have been developed for protein-protein interaction (PPI) prediction, each method has a specialised emphasis, and it is often necessary to use multiple methods to avoid a high false-negative rate. We here describe a method that is based on binding profiles and only requires protein sequence as an input. We also developed an online platform, the PPI Prediction Platform (PPIPP), to predict PPI networks (PPINs). PPIPP, which is freely accessible at http://ppipp.songbx.me, provides two main functions: PPI prediction, which uses the binding profile method, domain-motif interactions from structural topology, and PPIN-based detection of functionally similar proteins within species. PPIPP offers a web-based interface to facilitate PPIN predictions and a high-performance server to overcome the problems of user access and large-scale computation. The wheat proteome was used to evaluate the performance of this platform.
In many Web image retrieval applications, adapting the retrieval results according to some model of the user is a desired feature as the returned images can be made specifically relevant to a user’s needs. Making retrieval user-adaptive faces several practical challenges, including the ambiguity of user query, the lack of user-adaptive training data, and lack of proper mechanisms for supporting adaptive learning. To address some of these challenges, we propose a hybrid learning strategy that fuses knowledge from both pointwise and pairwise training data into one framework for attribute-based, user-adaptive image retrieval. An online learning algorithm is developed for updating the ranking performance based on user feedback. The framework is also derived into a kernel form allowing easy application of kernel techniques. We use both synthetic and real-world datasets to evaluate the performance of the proposed algorithm. Comparison with other state-of-the-art approaches suggests that our method achieves obvious performance gains over ranking and zero-shot learning. Further, our online learning algorithm was found to be able to deliver much better performance than batch learning, given the same elapsed running time.
The objective of this study was to improve individual tree crown delineation by fully exploiting the crown information exhibited in multi-wavelength LiDAR data. The data used in this study were obtained by an Optech's Titan instrument with three wavelengths: 532 nm, 1064 nm, and 1550 nm. Methods were developed to employ both spectral and structural information of tree crowns to separate crowns from other cover types and from each other. The methods were tested using a data set obtained over a study area in Toronto, Ontario, Canada. Preliminary results show that with both the canopy height model and intensities corresponding to the three wavelength, trees were distinguished from other cover types with a high accuracy and trees were separated from each other with a reasonable accuracy (based on visual observation).
With the advent of progressive format display and broadcast technologies, video deinterlacing has become an important video-processing technique. Numerous approaches exist in the literature to accomplish deinterlacing. While most earlier methods were simple linear filtering-based approaches, the emergence of faster computing technologies and even dedicated video-processing hardware in display units has allowed higher quality but also more computationally intense deinterlacing algorithms to become practical. Most modern approaches analyze motion and content in video to select different deinterlacing methods for various spatiotemporal regions. We introduce a family of deinterlacers that employs spectral residue to choose between and weight control grid interpolation based spatial and temporal deinterlacing methods. The proposed approaches perform better than the prior state-of-the-art based on peak signal-to-noise ratio, other visual quality metrics, and simple perception-based subjective evaluations conducted by human viewers. We further study the advantages of using soft and hard decision thresholds on the visual performance.
Employing correlation among images for improved reconstruction in compressive sensing is a conceptually attractive idea, although developing efficient modeling strategies and reconstruction algorithms are often the key to achieve any potential benefit. This paper presents a novel modeling strategy and an efficient reconstruction algorithm for processing a set of correlated images, jointly taking into consideration inter-image correlation, intra-image correlation and inter-channel correlation. The approach starts with joint modeling of the entire image set in the gradient domain, which supports simultaneous representation of local smoothness, nonlocal self-similarity of every single image, and inter-image correlation. Then an efficient algorithm is proposed to solve the joint formulation, using a Split-Bregman-based technique. Furthermore, to support color image reconstruction, the proposed algorithm is extended by using the concept of group sparsity to explore inter-channel correlation. The effectiveness of the proposed approach is demonstrated with extensive experiments on both grayscale and color image sets. Results are also compared with recently proposed compressive sensing recovery algorithms.
