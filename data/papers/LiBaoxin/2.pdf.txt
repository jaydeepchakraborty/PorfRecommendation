IEEE SIGNAL PROCESSING LETTERS, VOL. 23, NO. 4, APRIL 2016

449

Compressive Sensing Reconstruction of Correlated Images Using Joint Regularization
Kan Chang, Pak Lun Kevin Ding, and Baoxin Li, Senior Member, IEEE
Abstract--This letter proposes a novel compressive sensing reconstruction method for correlated images by using joint regularization, where a compensation-based adaptive total variation (CATV) regularization and a multi-image nonlocal low-rank (MNLR) regularization are included. In CATV, local weights are assigned to the residual values in the gradient domain so as to constrain the regularization strength at each pixel. In MNLR, the search of similar patches goes across different images so that both self-similarity and inter-image similarity are explored. Afterward, an efficient algorithm is proposed to solve the joint formulation, using a Split-Bregman-based technique. The effectiveness of the proposed approach is demonstrated with experiments on both multiview images and video sequences. Index Terms--Compressive sensing, motion estimation/disparity estimation (ME/DE), nonlocal low-rank regularization (NLR), total variation.

prior knowledge for regularizing the solution to the following minimization problem: ^ i = argmin (ui ) u
ui

s.t. yi = i ui

(2)

I. I NTRODUCTION

T

HIS LETTER focuses on the compressive sensing (CS) reconstruction of a set of correlated images, each of which is independently acquired by the CS technique [1], [2]. The correlated images could be multiview images which represent a scene from different view points, or a series of video frames which are taken at different time points. More specifically, the CS measurement of the original ith image is acquired by y i = i u i (1)

where ui  RN stands for the original ith image, yi  RM is the measurement of the ith image, and i  RM ×N is the measurement matrix. Usually, M << N , and we call M/N the subrate of CS. To reconstruct the underlying images from such an underdetermined system, one common way is to employ image
Manuscript received December 13, 2015; revised February 03, 2016; accepted February 04, 2016. Date of publication February 11, 2016; date of current version March 03, 2016. This work was supported by the Natural Science Foundation of China under Grants 61401108 and 61261023, and the Natural Science Foundation of Guangxi under Grant 2013GXNSFBA019272. The work of B. Li was supported by the Natural Science Foundation under Grants 1135616 and 0845469. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Deanna Needell. K. Chang is with the School of Computer and Electronic Information, the Guangxi Key Laboratory of Multimedia Communications and Network Technology (Cultivating Base), and the Key Laboratory of Multimedia Communications and Information Processing, Guangxi University, Nanning 530004, China (e-mail: changkan0@gmail.com). P. L. Kevin Ding and B. Li are with the Department of Computer Science and Engineering, Arizona State University, Tempe, AZ 85287 USA (e-mail: kevinding@asu.edu; baoxin.li@asu.edu). Color versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org. Digital Object Identifier 10.1109/LSP.2016.2527680

where  is the regularization term denoting image prior. Different types of intra-image-based regularization have been investigated, including total variation (TV) minimization [3], nonlocal low-rank regularization (NLR) [4], nonlocal meansbased regularization [5], autoregressive model [6], dictionary learning-based sparse representation [7], etc. Besides intra-image prior information, inter-imagestructured sparsity also needs to be explored for correlated images. The most direct way to do this is to require a joint sparsity of the whole image set, such as [8]­[11]. However, such methods are sensitive to motion or disparity. Improvement may be obtained by using the neighboring images to help reconstruct the current one, such as [12]­[20]. In [21], correlation between a pair of images was directly estimated in the compressed domain so as to reduce the computational complexity. The main contributions of this letter are listed as follows. First, we propose a compensation-based adaptive TV regularization approach, where the reliability of each compensated pixel is considered. Second, we extend the existing NLR from single-image pattern to multiple-image pattern. Note that different from the similar model in [22], we additionally use optical flow (OF) fields to guide the central points of search windows. Finally, we jointly incorporate these two types of regularization into a minimization problem and design an optimization algorithm for CS reconstruction of correlated images. Experiments show that our proposed algorithm is capable of achieving significantly better reconstruction than several state-of-the-art methods. To facilitate evaluation and further exploration of the proposed algorithm, we will publish the source code on the third author's webpage.1 II. P ROPOSED J OINT R EGULARIZATION A. Compensation-Based Adaptive TV Regularization To explore inter-image correlation, we can utilize disparity estimation/disparity compensation (DE/DC) for multiview images or motion estimation/motion compensation (ME/MC) for video sequences. As have been proved in [17]­[20], requiring small prediction error in the gradient domain is able to get satisfactory results. In [17], the compensation-based TV (CTV) regularization term was written as CTV (ui ) = D(ui - si )
1 [Online].

1

(3)

Available: http://www.public.asu.edu/~bli24/

1070-9908 © 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

450

IEEE SIGNAL PROCESSING LETTERS, VOL. 23, NO. 4, APRIL 2016

T T where D = [DT h , Dv ] with Dh , Dv denoting the horizontal and vertical finite difference operators, respectively, and

si =

1 (Fi-1 ui-1 + Bi+1 ui+1 ) 2

(4)

with Fi-1 and Bi+1 standing for the forward and backward compensation operators by using the optical flow fields of the (i - 1)th and (i + 1)th images, respectively. We only used the closest images to build the compensated results because: 1) usually a further distance between two images leads to a less accurate compensated image and 2) the computational complexity of estimating the OF fields is high. Unfortunately, such an si is not always reliable on images with fine details, multiview images with large disparity, or video sequences with complex motion. Therefore, simply minimizing the regularization term (3) may sometimes deteriorate the quality of reconstructed images. Considering the reliability at each pixel in si , we propose to add local weights to the residual values in the gradient domain, leading to a compensation-based adaptive TV (CATV) regularization CATV (ui ) = Wi (D(ui - si ))
1

Fig. 1. Example of intra-image and inter-image search. OF fields are used to guide the central points of search windows in adjacent images. The sizes of search windows in different images are the same.

Xj . It is reasonable to expect the formed matrix Xj has a lowrank property (in practice, Xj is only approximately low rank due to noises and artifacts [4]). Hence for the ith image, NLR is calculated as NLR (ui ) =
j

1 ^ Rj ui - L j 2

2 F

+ Rank(Lj )

(10)

(5)

is the where Wi denotes the vector of local weights, and Hadamard product. If an unreliable predicted value occurs at a pixel position in si , a small weight should be assigned to it. To appropriately build Wi , a good spatial information indicator is needed. Here, the second derivative-based indicator called difference curvature [23] is utilized. It is a pixel-based indicator which can effectively discriminate edges from flat regions or noises. For the mth pixel, it is defined as Cm = ||e | - |e || e = e = e2 x exx + 2ex ey exy + 2 e2 x + ey e2 y eyy (6) (7) (8)

^ j stands for extracting similar patches for the j th exemwhere R ^ j ui ;  is a tradeoff parameter; The plar patch, i.e., Xj = R newly introduced low-rank matrix Lj is close to Xj . For correlated images, just exploring nonlocal low-rank property inside an image is not enough. Therefore, we propose to extend (10) to a new multi-image nonlocal low-rank (MNLR) regularization, which is written as
MNLR (U) =
i j

1 ~ Ri,j U - Li,j 2

2 F

+ Rank(Li,j )

(11)

2 e2 y exx + 2ex ey exy + ex eyy 2 e2 x + ey

where ex and ey represent the first-order gradients of the pixel along x (horizontal) and y (vertical) directions, respectively; exx , eyy , and exy are the second-order gradients of the pixel. With Cm , the mth local weight in Wi is computed as wm = 1 1 + Cm (9)

where  is the contrast factor. It should be noted that our Wi is designed for residual in the gradient domain, which is different from other works such as [24] and [25] (i.e., Cm is computed on (ui - si ) instead of ui ). In practice, since the original images are not available, the previously reconstructed images are needed to calculate Wi . B. Multi-Image Nonlocal Low-Rank Regularization NLR [4] is an efficient tool for describing single image characteristics. To apply it, a target image is first divided into overlapped patches with size Sp × Sp . As a similarity metric, the l2 differences between the j th exemplar patch and the candidate patches within a search window are computed. After that, Np similar patches are found and grouped into a matrix

T T T where U = [uT 1 , u2 , . . . , un ] , and n is the number of corre^ j in (10), for the j th exemplar lated images. Different from R ~ i,j extracts its similar patches patch in the ith image, operator R from the (i - 1)th, ith, and (i + 1)th images. To find similar patches in three neighboring images, both intra-image and inter-image searches are needed. Fig. 1 illustrates how the search works. Recall that we have obtained OF fields when calculating si in (4). Thus, here they can be reused to guide the central points of search windows in the (i - 1)th and (i + 1)th images. More specifically, given a central point of a window in the ith image, we locate its motion/disparity vectors in the OF fields and use these vectors to find where this point is in the adjacent images. This procedure helps to find the most similar patches, especially in cases where large disparity or motion occurs among neighboring images. Note that higher quality of reconstruction can be achieved if the search goes across more images. However, doing so would cause heavier computational burden. Through experiments, we found that searching in three continuous images has achieved significant improvement over single-image NLR [4]. In addition, we only have the OF fields for each pair of adjacent images, which means the guidance for the central points of search windows is not available in further images.

III. O PTIMIZATION A LGORITHM FOR CS R ECONSTRUCTION U SING J OINT R EGULARIZATION Since CATV and MNLR impose different prior knowledge within correlated images, jointly considering them can get satisfactory results. By doing so, the minimization problem for reconstructing a set of correlated images becomes

CHANG et al.: CS RECONSTRUCTION OF CORRELATED IMAGES USING JOINT REGULARIZATION

451

TABLE I M EAN PSNR S ( D B) C OMPARISON FOR M ULTIVIEW I MAGES R ECONSTRUCTION

Since rank-minimization problem is NP-hard, here, we have replaced Rank(Li,j ) in (11) with L(Li,j , ), which is a log det(·) surrogate function [26] and L(Li,j , ) = log det Li,j LT i,j
1/ 2

+ I

(13)

TABLE II M EAN PSNR S ( D B) C OMPARISON FOR V IDEO S EQUENCES R ECONSTRUCTION

where  is a small constant and I denotes the identity matrix. We use log det(·) here because it can better approximate rank than the widely used nuclear norm [4]. To efficiently solve problem (12), we introduce a new ~ (U - CU). Then, our joint variable d and let d = D regularization-driven Split-Bregman iteration [27] can be written as   Lk+1 = argmin{Li,j } i j (L(Li,j , )   i,j    k 2 ~  +1  2 Ri,j U - Li,j F )     Uk+1 = argmin Y - HU 2  2 U     +1 2  ~ + i j ( Ri,j U - Lk F) i,j (14) k k  ~ (U - CU) - b 2  + d - D  2     k+1 ~  dk+1 = argmind  - bk 2  2 2 d - D ( I - C) U     ~  + W d 1      k+1 k k+1 k+1 k+1
b ~ (U =b +D - CU )-d

where  is a tradeoff parameter. When considering the "L" subproblem, we treat every Li,j separately, and the solution can be written as [4]
+1 k T Lk i,j = Q( -  diag(g ))+ V

(15)

where QVT is the singular value decomposition (SVD) of ~ i,j Uk , and thin SVD is applied in our implementation. g k = R l k k 1/(l + ) ,  l denotes the lth singular value of Lk i,j , and (x)+ = max(x, 0). When solving the "U" subproblem, we use CUk to approximate CUk+1 and get the closed-form solution as follows:  -1
Uk+1 = HT H +  ~T ~ ~T ~ R i,j Ri,j +  D D
i j




i j k+1  ~T . R i,j Li,j

^ , {L ^ i,j }} = argmin 1 Y - HU {U U,{Li,j } 2 ~ + W +
i j

2 2

k ~ T (dk + DCU ~  D - bk ) + HT Y + 

(16)
2 F

~ (U - CU) D

1

1 ~ Ri,j U - Li,j 2

+ L(Li,j , )

(12)

To compute (16), conjugate gradient (CG) method is used. When dealing with the "d" subproblem, closed-form solution by the shrinkage formula [28] is given as ~ (I - C)Uk+1 + bk , W ~ / ). dk+1 = shrink(D With a vector x and a threshold Ts , we have shrink(x, Ts ) = max(|x| - Ts , 0) sgn(x). (18) (17)

T T where ,  , and  are tradeoff parameters, Y = [y1 , y2 , T T T T ~ = [W , W , . . . , . . . , yn ] , H = diag(1 , 2 , . . . , n ), W 1 2 T T ~ ] D = diag(D, D, . . . , D), and Wn   0 B2 0 ··· 0 0 B3 /2 ··· 0  F1 /2  .  . . . .   .. .. .. . C= . . . .  0 0 Bn /2 · · · Fn-2 /2 0 0 ··· 0 Fn-1

Note that the max operator here is implemented for each spatial index independently. Our algorithm, named joint regularization-based compressive sensing reconstruction (JR-CSR), is summarized as

452

IEEE SIGNAL PROCESSING LETTERS, VOL. 23, NO. 4, APRIL 2016

Fig. 2. Visual quality comparison for the ninth frame in City (subrate = 0.20). From left to right: DC-TV, DC-JTV, NLR-CS, JM-RCI, JR-CSR. TABLE III AVERAGE CPU T IME ( S ) FOR R ECONSTRUCTING O NE F RAME IN Foreman

Algorithm 1. JR-CSR ~ 0 , H, Y, ,  , ,  Input: U Outer loop for t = 0, 1, . . . , T ~ i,j }. ~ t to update C and {R Use U ~ = [1, 1, . . . 1]T Else Update W ~ by (9) If t  T0 W 0 ~ ( I - C) U ~ t , b0 = 0, U0 = U ~t Set d = D Inner loop for k = 0, 1, . . . , K +1 Update each Lk i,j by (15). Update Uk+1 by using CG method to solve (16). Update dk+1 via (17). ~ (Uk+1 - CUk+1 ) - dk+1 bk+1 = bk + D t+1 k+1 ~ Set U =U If Uk+1 - Uk 2 / Uk+1 2 < 10-4 Break End for End for ^ =U ~ T +1 return U ~ t and Uk denote the results in the outer loop Algorithm 1. U and the results in the inner loop, respectively. To get an accu~ , and {R ~ i,j } are updated several times in the rate result, C, W ~ is fixed. This outer loop. Note that in the first T0 iterations, W was found empirically to be able to improve the convergence while leading to a better result. The inner loop will stop if the relative change of U is smaller than a predefined threshold, or the maximum number of iterations is reached. IV. E XPERIMENTAL R ESULTS This section evaluates the performance of JR-CSR. All experiments were performed in MATLAB 2013b on a Lenovo computer with Intel(R) Core(TM) i7-4790 processor, 8.00G memory. Structurally random matrices (SRM) [29] were used as i , and we had the measurement yi = i ui . To generate ~ 0 , TVAL3 [30] software2 was utilized for each image. To U construct C, OF implementation3 of [31] was used. In this OF implementation, successive over-relaxation (SOR) was applied to solve the linear system resulting from the energy functional of [32], where the assumptions of brightness constancy, gradient constancy, and piecewise smooth flow field were combined. T , K , and T0 were set to 15, 25, and 5, respectively.  in (9) was set to 0.8, patch size Sp × Sp for MNLR was 6 × 6, and the number of similar patches Np was 45. ,  , , and  were tuned according to each subrate. The test datasets included four multiview image sets [half size Monopoly (MP), Tsukuba (TK), Venus and Art] from
2 [Online]. 3 [Online].

the middlebury multiview database4 and four video sequences [352 × 288 Foreman (FM), Football (FB), City, and Bus]. We tested the first five views of each multiview image set and the first 20 frames of each video sequence. Only grayscale images were considered. Four state-of-the-art algorithms were compared, including NLR-CS [4], JM-RCI [17], DC-JTV [20], and DC-TV [19]. For fair comparison, TVAL3 [30] was applied to obtain the initial results for all competing algorithms. The average peak signal-to-noise ratio (PSNR) results of each multiview image set and each video sequence are given in Tables I and II, respectively. One can see that JR-CSR beats all the benchmark methods in all cases. For example, in Table I at a subrate of 0.10, JR-CSR gets 3.05 dB PSNR improvement over the second best method, i.e., NLR-CS. For visual quality comparison, please see Fig. 2. The average running times for reconstructing one frame in Foreman are listed in Table III. We can find that JR-CSR is the slowest algorithm. The main computational burdens are introduced by iteratively updating {Li,j }, U, and C. For each Li,j , 2 Np r), where r is the rank the complexity of thin SVD is O(Sp ~ of Ri,j U. To update U and C, CG and SOR are used to solve the related linear systems, respectively. Given a linear system Ax = z, assume that Nn is the number of nonzero entries in matrix A, and Nc is the condition number of A. To get the  vector x, the complexity of one iteration of CG is O(Nn Nc ), while O(Nn ) is required for one iteration of SOR. To speed up JR-CSR, parallelization techniques may be the best choice. Other solutions, such as updating C in JR-CSR only once, removing either CATV or MNLR from (12), etc., would lead to different levels of quality loss. V. C ONCLUSION In this letter, we proposed two types of regularization, including CATV and MNLR, for CS reconstruction of correlated image sets. After incorporating the two regularization terms into the minimization problem, we designed an optimization algorithm called JR-CSR. Through experiments, we found that JR-CSR is able to deliver the best performance among all the tested methods, which demonstrates the effectiveness of the proposed joint regularization.
4 [Online].

Available: http://www.caam.rice.edu/~optimization/L1/TVAL3/ Available: http://people.csail.mit.edu/celiu/OpticalFlow/

Available: http://vision.middlebury.edu/stereo/data

CHANG et al.: CS RECONSTRUCTION OF CORRELATED IMAGES USING JOINT REGULARIZATION

453

R EFERENCES
[1] D. L. Donoho, "Compressed sensing," IEEE Trans. Inf. Theory, vol. 52, no. 4, pp. 1289­1306, Apr. 2006. [2] E. J. Candès, J. Romberg, and T. Tao, "Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information," IEEE Trans. Inf. Theory, vol. 52, no. 2, pp. 489­509, Feb. 2006. [3] L. Rudin, S. Osher, and E. Fatemi, "Nonlinear total variation based noise removal algorithms," Phys. D: Nonlinear Phenom., vol. 60, no. 1, pp. 259­268, 1992. [4] W. Dong, G. Shi, X. Li, Y. Ma, and F. Huang, "Comressive sensing via nonlocal low-rank regularization," IEEE Trans. Image Process., vol. 23, no. 8, pp. 3618­3612, Aug. 2014. [5] J. Zhang, S. Liu, D. Zhao, R. Xiong, and S. Ma, "Improved total variation based image compressive sensing recovery by nonlocal regularization," in Proc. IEEE Int. Symp. Circuits Syst. (ISCAS), 2013, pp. 2836­2839. [6] X. Wu, W. Dong, X. Zhang, and G. Shi, "Model-assisted adaptive recovery of compressed sensing with imaging applications," IEEE Trans. Image Process., vol. 21, no. 2, pp. 451­458, Feb. 2012. [7] W. Dong, G. Shi, X. Li, L. Zhang, and X. Wu, "Image reconstruction with locally adaptive sparsity and nonlocal robust regularization," Signal Process.: Image Commun., vol. 27, pp. 1109­1122, 2012. [8] J. Ma, G. Plonka, and M. Y. Hussaini, "Compressive video sampling with approximate message passing decoding," IEEE Trans. Circuits Syst. Video Technol., vol. 22, no. 9, pp. 1354­1364, Sep. 2012. [9] C. Li, H. Jiang, W. Paul, and Y. Zhang, "A new compressive video sensing framework for mobile broadcast," IEEE Trans. Broadcast., vol. 59, no. 1, pp. 197­205, Mar. 2013. [10] M. Hosseini and K. N. Plataniotis, "High-accuracy total variation with application to compressed video sensing," IEEE Trans. Image Process., vol. 23, no. 9, pp. 3869­3884, Sep. 2014. [11] P. Nagesh and B. Li, "A compressive sensing approach for expressioninvariant face recognition," in Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR), 2009, pp. 1518­1525. [12] T. T. Do, Y. Chen, D. T. Nguyen, N. Nguyen, L. Gan, and T. D. Tran, "Distributed compressed video sensing," in Proc. Int. Conf. Image Process. (ICIP), 2009, pp. 1393­1396. [13] J. Nebot, Y. Ma, and T. Huang, "Distributed video coding using compressive sampling," in Proc. Picture Coding Symp. (PCS), 2009, pp. 1­4. [14] L. W. Kang and C. S. Lu, "Distributed compressive video sensing," in Proc. Int. Conf. Acoust. Speech Signal Process. (ICASSP), 2009, pp. 1169­1172. [15] V. Thirumalai and P. Frossard, "Distributed representation of geometrically correlated images with compressed linear measurements," IEEE Trans. Image Process., vol. 21, no. 7, pp. 3206­3218, Jul. 2012. [16] Y. Liu, M. Li, and A. Dimitris, "Motion-aware decoding of compressedsensed video," IEEE Trans. Circuits Syst. Video Technol., vol. 23, no. 3, pp. 438­444, Mar. 2013.

[17] K. Chang and B. Li, "Joint modeling and reconstruction of a compressively-sensed set of correlated images," J. Visual Commun. Image Represent., vol. 33, pp. 286­300, 2015. [18] K. Chang, T. Qin, W. Xu, and Z. Tang, "Reconstruction of multi-view compressed imaging using weighted total variation," Multimedia Syst., vol. 20, no. 4, pp. 363­378, 2014. [19] M. Trocan, E. W. Tramel, J. E. Fowler, and B. Pesquet, "Compressedsensing recovery of multiview image and video sequences using signal prediction," Multimedia Tools Appl., vol. 72, no. 1, pp. 95­121, 2014. [20] Y. Liu, C. Zhang, and J. Kim, "Disparity-compensated total-variation minimization for compressed-sensed multiview image reconstruction," in Proc. IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), 2015, pp. 1458­1462. [21] V. Thirumalai and P. Frossard, "Correlation estimation from compressed images," J. Visual Commun. Image Represent., vol. 24, no. 6, pp. 649­ 660, 2013. [22] H. Yoon, K. S. Kim, D. Kim, Y. Bresler, and J. C. Ye, "Motion adaptive patch-based low-rank approach for compressed sensing cardiac cine MRI," IEEE Trans. Med. Imag., vol. 33, no. 11, pp. 2069­2085, Nov. 2014. [23] Q. Chen, P. Montesinos, Q. Sun, P. Heng, and D. Xia, "Adaptive total variation denoising based on difference curvature," Image Vis. Comput., vol. 28, no. 3, pp. 298­306, 2010. [24] W. Dong, X. Yang, and G. Shi, "Compressive sensing via reweighted TV and nonlocal sparsity regularisation," Electron. Lett., vol. 49, no. 3, pp. 184­186, 2013. [25] E. J. Candès, M. B. Wakin, and S. P. Boyd, "Enhancing sparsity by reweighted l1 minimization," J. Fourier Anal. Appl., vol. 14, no. 5, pp. 877­905, 2008. [26] M. Fazel, H. Hindi, and S. P. Boyd, "Log-det heuristic for matrix rank minimization with applications to hankel and euclidean distance matrices," in Proc. Amer. Control Conf., 2003, pp. 2156­2162. [27] T. Goldstein and S. Osher, "The split bregman method for l1 regularized problems," SIAM J. Imag. Sci., vol. 2, no. 2, pp. 323­343, 2009. [28] E. T. Hale, W. Yin, and Y. Zhang, "Fixed-point continuation for l1minimization: Methodology and convergence," SIAM J. Optim., vol. 19, no. 3, pp. 1107­1130, 2008. [29] T. T. Do, L. Gan, N. H. Nguyen, and T. D. Tran, "Fast and efficient compressive sensing using structurally random matrices," IEEE Trans. Signal Process., vol. 60, no. 1, pp. 139­154, Jan. 2012. [30] C. Li, W. Yin, H. Jiang, and Y. Zhang, "An efficient augmented lagrangian method with applications to total variation minimization," Comput. Optim. Appl., vol. 56, no. 3, pp. 507­530, 2013. [31] C. Liu, "Beyond pixels: Exploring new representations and applications for motion analysis," Ph.D. dissertation, Department of Electrical Engineering and Computer Science, Massachusetts Inst. Technol., Cambridge, MA, USA, 2009. [32] T. Brox, A. Bruhn, N. Papenberg, and J. Weickert, "High accuracy optical flow estimation based on a theory for warping," in Proc. Eur. Conf. Comput. Vis. (ECCV), 2004, pp. 25­36.

