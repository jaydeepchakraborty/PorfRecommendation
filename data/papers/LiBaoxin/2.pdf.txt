IEEE SIGNAL PROCESSING LETTERS, VOL. 23, NO. 4, APRIL 2016

449

Compressive Sensing Reconstruction of Correlated
Images Using Joint Regularization
Kan Chang, Pak Lun Kevin Ding, and Baoxin Li, Senior Member, IEEE
Abstractâ€”This letter proposes a novel compressive sensing
reconstruction method for correlated images by using joint regularization, where a compensation-based adaptive total variation (CATV) regularization and a multi-image nonlocal low-rank
(MNLR) regularization are included. In CATV, local weights are
assigned to the residual values in the gradient domain so as to
constrain the regularization strength at each pixel. In MNLR, the
search of similar patches goes across different images so that both
self-similarity and inter-image similarity are explored. Afterward,
an efficient algorithm is proposed to solve the joint formulation,
using a Split-Bregman-based technique. The effectiveness of the
proposed approach is demonstrated with experiments on both
multiview images and video sequences.
Index
Termsâ€”Compressive
sensing,
motion
estimation/disparity
estimation
(ME/DE),
nonlocal
low-rank
regularization (NLR), total variation.

I. I NTRODUCTION

T

HIS LETTER focuses on the compressive sensing (CS)
reconstruction of a set of correlated images, each of which
is independently acquired by the CS technique [1], [2]. The correlated images could be multiview images which represent a
scene from different view points, or a series of video frames
which are taken at different time points. More specifically, the
CS measurement of the original ith image is acquired by
y i = Î¦i u i

(1)

where ui âˆˆ RN stands for the original ith image, yi âˆˆ RM
is the measurement of the ith image, and Î¦i âˆˆ RM Ã—N is the
measurement matrix. Usually, M << N , and we call M/N the
subrate of CS.
To reconstruct the underlying images from such an underdetermined system, one common way is to employ image
Manuscript received December 13, 2015; revised February 03, 2016;
accepted February 04, 2016. Date of publication February 11, 2016; date of
current version March 03, 2016. This work was supported by the Natural
Science Foundation of China under Grants 61401108 and 61261023, and the
Natural Science Foundation of Guangxi under Grant 2013GXNSFBA019272.
The work of B. Li was supported by the Natural Science Foundation under
Grants 1135616 and 0845469. The associate editor coordinating the review of
this manuscript and approving it for publication was Prof. Deanna Needell.
K. Chang is with the School of Computer and Electronic Information,
the Guangxi Key Laboratory of Multimedia Communications and Network
Technology (Cultivating Base), and the Key Laboratory of Multimedia
Communications and Information Processing, Guangxi University, Nanning
530004, China (e-mail: changkan0@gmail.com).
P. L. Kevin Ding and B. Li are with the Department of Computer Science
and Engineering, Arizona State University, Tempe, AZ 85287 USA (e-mail:
kevinding@asu.edu; baoxin.li@asu.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/LSP.2016.2527680

prior knowledge for regularizing the solution to the following
minimization problem:
uÌ‚i = argmin Î¨(ui )
ui

s.t. yi = Î¦i ui

(2)

where Î¨ is the regularization term denoting image prior.
Different types of intra-image-based regularization have been
investigated, including total variation (TV) minimization [3],
nonlocal low-rank regularization (NLR) [4], nonlocal meansbased regularization [5], autoregressive model [6], dictionary
learning-based sparse representation [7], etc.
Besides intra-image prior information, inter-imagestructured sparsity also needs to be explored for correlated
images. The most direct way to do this is to require a joint
sparsity of the whole image set, such as [8]â€“[11]. However,
such methods are sensitive to motion or disparity. Improvement
may be obtained by using the neighboring images to help
reconstruct the current one, such as [12]â€“[20]. In [21], correlation between a pair of images was directly estimated in
the compressed domain so as to reduce the computational
complexity.
The main contributions of this letter are listed as follows.
First, we propose a compensation-based adaptive TV regularization approach, where the reliability of each compensated
pixel is considered. Second, we extend the existing NLR from
single-image pattern to multiple-image pattern. Note that different from the similar model in [22], we additionally use optical
flow (OF) fields to guide the central points of search windows.
Finally, we jointly incorporate these two types of regularization
into a minimization problem and design an optimization algorithm for CS reconstruction of correlated images. Experiments
show that our proposed algorithm is capable of achieving
significantly better reconstruction than several state-of-the-art
methods. To facilitate evaluation and further exploration of the
proposed algorithm, we will publish the source code on the
third authorâ€™s webpage.1
II. P ROPOSED J OINT R EGULARIZATION
A. Compensation-Based Adaptive TV Regularization
To explore inter-image correlation, we can utilize disparity estimation/disparity compensation (DE/DC) for multiview
images or motion estimation/motion compensation (ME/MC)
for video sequences. As have been proved in [17]â€“[20], requiring small prediction error in the gradient domain is able to get
satisfactory results. In [17], the compensation-based TV (CTV)
regularization term was written as
Î¨CTV (ui ) = D(ui âˆ’ si )1
1 [Online].

Available: http://www.public.asu.edu/~bli24/

1070-9908 Â© 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

(3)

450

IEEE SIGNAL PROCESSING LETTERS, VOL. 23, NO. 4, APRIL 2016

where D = [DTh , DTv ]T with Dh , Dv denoting the horizontal
and vertical finite difference operators, respectively, and
si =

1
(Fiâˆ’1 uiâˆ’1 + Bi+1 ui+1 )
2

(4)

with Fiâˆ’1 and Bi+1 standing for the forward and backward
compensation operators by using the optical flow fields of the
(i âˆ’ 1)th and (i + 1)th images, respectively. We only used
the closest images to build the compensated results because:
1) usually a further distance between two images leads to a
less accurate compensated image and 2) the computational
complexity of estimating the OF fields is high.
Unfortunately, such an si is not always reliable on images
with fine details, multiview images with large disparity, or video
sequences with complex motion. Therefore, simply minimizing
the regularization term (3) may sometimes deteriorate the quality of reconstructed images. Considering the reliability at each
pixel in si , we propose to add local weights to the residual values in the gradient domain, leading to a compensation-based
adaptive TV (CATV) regularization
Î¨CATV (ui ) = Wi  (D(ui âˆ’ si ))1

(5)

where Wi denotes the vector of local weights, and  is the
Hadamard product. If an unreliable predicted value occurs at a
pixel position in si , a small weight should be assigned to it.
To appropriately build Wi , a good spatial information indicator is needed. Here, the second derivative-based indicator called
difference curvature [23] is utilized. It is a pixel-based indicator which can effectively discriminate edges from flat regions
or noises. For the mth pixel, it is defined as
Cm = ||eÎ·Î· | âˆ’ |e ||
eÎ·Î· =
e =

e2x exx

+ 2ex ey exy +
e2x + e2y

(6)
e2y eyy

e2y exx + 2ex ey exy + e2x eyy
e2x + e2y

(7)
(8)

where ex and ey represent the first-order gradients of the pixel
along x (horizontal) and y (vertical) directions, respectively;
exx , eyy , and exy are the second-order gradients of the pixel.
With Cm , the mth local weight in Wi is computed as
wm =

1
1 + Î¸Cm

(9)

where Î¸ is the contrast factor.
It should be noted that our Wi is designed for residual in
the gradient domain, which is different from other works such
as [24] and [25] (i.e., Cm is computed on (ui âˆ’ si ) instead of
ui ). In practice, since the original images are not available, the
previously reconstructed images are needed to calculate Wi .

Fig. 1. Example of intra-image and inter-image search. OF fields are used to
guide the central points of search windows in adjacent images. The sizes of
search windows in different images are the same.

Xj . It is reasonable to expect the formed matrix Xj has a lowrank property (in practice, Xj is only approximately low rank
due to noises and artifacts [4]). Hence for the ith image, NLR
is calculated as

 1
2
RÌ‚j ui âˆ’ Lj F + Î»Rank(Lj )
(10)
Î¨NLR (ui ) =
2
j
where RÌ‚j stands for extracting similar patches for the jth exemplar patch, i.e., Xj = RÌ‚j ui ; Î» is a tradeoff parameter; The
newly introduced low-rank matrix Lj is close to Xj .
For correlated images, just exploring nonlocal low-rank
property inside an image is not enough. Therefore, we propose
to extend (10) to a new multi-image nonlocal low-rank (MNLR)
regularization, which is written as
Î¨MNLR (U) =

1
i

j

2

RÌƒi,j U âˆ’ Li,j 2F + Î»Rank(Li,j )



(11)

where U = [uT1 , uT2 , . . . , uTn ]T , and n is the number of correlated images. Different from RÌ‚j in (10), for the jth exemplar
patch in the ith image, operator RÌƒi,j extracts its similar patches
from the (i âˆ’ 1)th, ith, and (i + 1)th images.
To find similar patches in three neighboring images, both
intra-image and inter-image searches are needed. Fig. 1 illustrates how the search works. Recall that we have obtained OF
fields when calculating si in (4). Thus, here they can be reused
to guide the central points of search windows in the (i âˆ’ 1)th
and (i + 1)th images. More specifically, given a central point of
a window in the ith image, we locate its motion/disparity vectors in the OF fields and use these vectors to find where this
point is in the adjacent images. This procedure helps to find the
most similar patches, especially in cases where large disparity
or motion occurs among neighboring images.
Note that higher quality of reconstruction can be achieved if
the search goes across more images. However, doing so would
cause heavier computational burden. Through experiments, we
found that searching in three continuous images has achieved
significant improvement over single-image NLR [4]. In addition, we only have the OF fields for each pair of adjacent
images, which means the guidance for the central points of
search windows is not available in further images.

B. Multi-Image Nonlocal Low-Rank Regularization
NLR [4] is an efficient tool for describing single image
characteristics. To apply it, a target image is first divided into
overlapped patches with size Sp Ã— Sp . As a similarity metric, the l2 differences between the jth exemplar patch and the
candidate patches within a search window are computed. After
that, Np similar patches are found and grouped into a matrix

III. O PTIMIZATION A LGORITHM FOR CS
R ECONSTRUCTION U SING J OINT R EGULARIZATION
Since CATV and MNLR impose different prior knowledge
within correlated images, jointly considering them can get satisfactory results. By doing so, the minimization problem for
reconstructing a set of correlated images becomes

CHANG et al.: CS RECONSTRUCTION OF CORRELATED IMAGES USING JOINT REGULARIZATION

TABLE I
M EAN PSNR S ( D B) C OMPARISON FOR M ULTIVIEW I MAGES
R ECONSTRUCTION

TABLE II
M EAN PSNR S ( D B) C OMPARISON FOR V IDEO S EQUENCES
R ECONSTRUCTION

451

Since rank-minimization problem is NP-hard, here, we
have replaced Rank(Li,j ) in (11) with L(Li,j , Îµ), which is a
log det(Â·) surrogate function [26] and


1/2
+ ÎµI
(13)
L(Li,j , Îµ) = log det Li,j LTi,j
where Îµ is a small constant and I denotes the identity matrix.
We use log det(Â·) here because it can better approximate rank
than the widely used nuclear norm [4].
To efficiently solve problem (12), we introduce a new
variable d and let d = DÌƒ(U âˆ’ CU). Then, our joint
regularization-driven Split-Bregman iteration [27] can be
written as

âŽ§
 
âŽª
Lk+1
= argmin{Li,j } i j (Î»L(Li,j , Îµ)
âŽª
i,j
âŽª
âŽª
âŽª
âŽª
âŽª
+ 12 RÌƒi,j Uk âˆ’ Li,j 2F )
âŽª
âŽª
âŽª
âŽª
âŽª
âŽª
Uk+1 = argminU Y âˆ’ HU22
âŽª
âŽª
âŽª
âŽª
 
âŽª
2
âŽ¨
+Î² i j (RÌƒi,j U âˆ’ Lk+1
i,j F )
(14)
âŽª
âŽª
+Î³dk âˆ’ DÌƒ(U âˆ’ CU) âˆ’ bk 22
âŽª
âŽª
âŽª
âŽª
âŽª
âŽª
dk+1 = argmind Î³2 d âˆ’ DÌƒ(I âˆ’ C)Uk+1 âˆ’ bk 22
âŽª
âŽª
âŽª
âŽª
âŽª
âŽª
+Î±WÌƒ  d1
âŽª
âŽª
âŽª
âŽª
âŽ© k+1
k
k+1
k+1
k+1
b

= b + DÌƒ(U

âˆ’ CU

)âˆ’d

where Î³ is a tradeoff parameter.
When considering the â€œLâ€ subproblem, we treat every Li,j
separately, and the solution can be written as [4]
k
T
Lk+1
i,j = Q(Î£ âˆ’ Î» diag(g ))+ V

(15)

where QÎ£VT is the singular value decomposition (SVD) of
RÌƒi,j Uk , and thin SVD is applied in our implementation. glk =
1/(Ïƒlk + Îµ), Ïƒlk denotes the lth singular value of Lki,j , and
(x)+ = max(x, 0).
When solving the â€œUâ€ subproblem, we use CUk to approximate CUk+1 and get the closed-form solution as follows:
âŽ›
âŽžâˆ’1


T âŽ 
Uk+1 = âŽHT H + Î²
RÌƒT
i,j RÌƒi,j + Î³ DÌƒ DÌƒ
âŽ›

1
{UÌ‚, {LÌ‚i,j }} = argmin Y âˆ’ HU22
U,{Li,j } 2
+ Î±WÌƒ  DÌƒ(U âˆ’ CU)1

  1
RÌƒi,j U âˆ’ Li,j 2F + Î»L(Li,j , Îµ) (12)
+Î²
2
i
j
where Î±, Î², and Î» are tradeoff parameters, Y = [y1T , y2T ,
. . . , ynT ]T , H = diag(Î¦1 , Î¦2 , . . . , Î¦n ), WÌƒ = [W1T , W2T , . . . ,
WnT ]T DÌƒ = diag(D, D, . . . , D), and
âŽ¡
âŽ¤
0
B2
0
Â·Â·Â·
0
0
B3 /2
Â·Â·Â·
0 âŽ¥
âŽ¢F1 /2
âŽ¢ .
.. âŽ¥
.
.
.
âŽ¢
âŽ¥
..
..
..
C = âŽ¢ ..
. âŽ¥.
âŽ£ 0
0
Bn /2âŽ¦
Â· Â· Â· Fnâˆ’2 /2
0
0
Â·Â·Â·
0
Fnâˆ’1

i

j

âŽÎ³ DÌƒT (dk + DÌƒCUk âˆ’ bk ) + HT Y + Î²


i

j

âŽž
k+1 âŽ 
.
RÌƒT
i,j Li,j

(16)
To compute (16), conjugate gradient (CG) method is used.
When dealing with the â€œdâ€ subproblem, closed-form solution by the shrinkage formula [28] is given as
dk+1 = shrink(DÌƒ(I âˆ’ C)Uk+1 + bk , Î±WÌƒ/Î³).

(17)

With a vector x and a threshold Ts , we have
shrink(x, Ts ) = max(|x| âˆ’ Ts , 0)  sgn(x).

(18)

Note that the max operator here is implemented for each
spatial index independently.
Our algorithm, named joint regularization-based compressive sensing reconstruction (JR-CSR), is summarized as

452

IEEE SIGNAL PROCESSING LETTERS, VOL. 23, NO. 4, APRIL 2016

Fig. 2. Visual quality comparison for the ninth frame in City (subrate = 0.20). From left to right: DC-TV, DC-JTV, NLR-CS, JM-RCI, JR-CSR.

Algorithm 1. JR-CSR
Input: UÌƒ0 , H, Y, Î±, Î², Î», Î³
Outer loop for t = 0, 1, . . . , T
Use UÌƒt to update C and {RÌƒi,j }.
If t â‰¤ T0 WÌƒ = [1, 1, . . . 1]T Else Update WÌƒ by (9)
Set d0 = DÌƒ(I âˆ’ C)UÌƒt , b0 = 0, U0 = UÌƒt
Inner loop for k = 0, 1, . . . , K
Update each Lk+1
i,j by (15).
k+1
Update U
by using CG method to solve (16).
Update dk+1 via (17).
bk+1 = bk + DÌƒ(Uk+1 âˆ’ CUk+1 ) âˆ’ dk+1
Set UÌƒt+1 = Uk+1
If Uk+1 âˆ’ Uk 2 /Uk+1 2 < 10âˆ’4 Break
End for
End for
return UÌ‚ = UÌƒT +1
Algorithm 1. UÌƒt and Uk denote the results in the outer loop
and the results in the inner loop, respectively. To get an accurate result, C, WÌƒ, and {RÌƒi,j } are updated several times in the
outer loop. Note that in the first T0 iterations, WÌƒ is fixed. This
was found empirically to be able to improve the convergence
while leading to a better result. The inner loop will stop if the
relative change of U is smaller than a predefined threshold, or
the maximum number of iterations is reached.
IV. E XPERIMENTAL R ESULTS
This section evaluates the performance of JR-CSR. All
experiments were performed in MATLAB 2013b on a Lenovo
computer with Intel(R) Core(TM) i7-4790 processor, 8.00G
memory. Structurally random matrices (SRM) [29] were used
as Î¦i , and we had the measurement yi = Î¦i ui . To generate
UÌƒ0 , TVAL3 [30] software2 was utilized for each image. To
construct C, OF implementation3 of [31] was used. In this OF
implementation, successive over-relaxation (SOR) was applied
to solve the linear system resulting from the energy functional
of [32], where the assumptions of brightness constancy, gradient constancy, and piecewise smooth flow field were combined.
T , K, and T0 were set to 15, 25, and 5, respectively. Î¸ in (9)
was set to 0.8, patch size Sp Ã— Sp for MNLR was 6 Ã— 6, and
the number of similar patches Np was 45. Î±, Î², Î», and Î³ were
tuned according to each subrate.
The test datasets included four multiview image sets [half
size Monopoly (MP), Tsukuba (TK), Venus and Art] from
2 [Online].
3 [Online].

Available: http://www.caam.rice.edu/~optimization/L1/TVAL3/
Available: http://people.csail.mit.edu/celiu/OpticalFlow/

TABLE III
AVERAGE CPU T IME ( S ) FOR R ECONSTRUCTING O NE F RAME IN Foreman

the middlebury multiview database4 and four video sequences
[352 Ã— 288 Foreman (FM), Football (FB), City, and Bus]. We
tested the first five views of each multiview image set and the
first 20 frames of each video sequence. Only grayscale images
were considered. Four state-of-the-art algorithms were compared, including NLR-CS [4], JM-RCI [17], DC-JTV [20], and
DC-TV [19]. For fair comparison, TVAL3 [30] was applied to
obtain the initial results for all competing algorithms.
The average peak signal-to-noise ratio (PSNR) results of
each multiview image set and each video sequence are given
in Tables I and II, respectively. One can see that JR-CSR beats
all the benchmark methods in all cases. For example, in Table I
at a subrate of 0.10, JR-CSR gets 3.05 dB PSNR improvement
over the second best method, i.e., NLR-CS. For visual quality
comparison, please see Fig. 2.
The average running times for reconstructing one frame in
Foreman are listed in Table III. We can find that JR-CSR is the
slowest algorithm. The main computational burdens are introduced by iteratively updating {Li,j }, U, and C. For each Li,j ,
the complexity of thin SVD is O(Sp2 Np r), where r is the rank
of RÌƒi,j U. To update U and C, CG and SOR are used to solve
the related linear systems, respectively. Given a linear system
Ax = z, assume that Nn is the number of nonzero entries in
matrix A, and Nc is the condition number of A. To get the
âˆš vector x, the complexity of one iteration of CG is O(Nn Nc ),
while O(Nn ) is required for one iteration of SOR. To speed
up JR-CSR, parallelization techniques may be the best choice.
Other solutions, such as updating C in JR-CSR only once,
removing either CATV or MNLR from (12), etc., would lead
to different levels of quality loss.
V. C ONCLUSION
In this letter, we proposed two types of regularization, including CATV and MNLR, for CS reconstruction of correlated
image sets. After incorporating the two regularization terms
into the minimization problem, we designed an optimization
algorithm called JR-CSR. Through experiments, we found that
JR-CSR is able to deliver the best performance among all the
tested methods, which demonstrates the effectiveness of the
proposed joint regularization.
4 [Online].

Available: http://vision.middlebury.edu/stereo/data

CHANG et al.: CS RECONSTRUCTION OF CORRELATED IMAGES USING JOINT REGULARIZATION

R EFERENCES
[1] D. L. Donoho, â€œCompressed sensing,â€ IEEE Trans. Inf. Theory, vol. 52,
no. 4, pp. 1289â€“1306, Apr. 2006.
[2] E. J. CandÃ¨s, J. Romberg, and T. Tao, â€œRobust uncertainty principles:
Exact signal reconstruction from highly incomplete frequency information,â€ IEEE Trans. Inf. Theory, vol. 52, no. 2, pp. 489â€“509, Feb.
2006.
[3] L. Rudin, S. Osher, and E. Fatemi, â€œNonlinear total variation based
noise removal algorithms,â€ Phys. D: Nonlinear Phenom., vol. 60, no. 1,
pp. 259â€“268, 1992.
[4] W. Dong, G. Shi, X. Li, Y. Ma, and F. Huang, â€œComressive sensing via
nonlocal low-rank regularization,â€ IEEE Trans. Image Process., vol. 23,
no. 8, pp. 3618â€“3612, Aug. 2014.
[5] J. Zhang, S. Liu, D. Zhao, R. Xiong, and S. Ma, â€œImproved total variation
based image compressive sensing recovery by nonlocal regularization,â€
in Proc. IEEE Int. Symp. Circuits Syst. (ISCAS), 2013, pp. 2836â€“2839.
[6] X. Wu, W. Dong, X. Zhang, and G. Shi, â€œModel-assisted adaptive recovery of compressed sensing with imaging applications,â€ IEEE Trans.
Image Process., vol. 21, no. 2, pp. 451â€“458, Feb. 2012.
[7] W. Dong, G. Shi, X. Li, L. Zhang, and X. Wu, â€œImage reconstruction
with locally adaptive sparsity and nonlocal robust regularization,â€ Signal
Process.: Image Commun., vol. 27, pp. 1109â€“1122, 2012.
[8] J. Ma, G. Plonka, and M. Y. Hussaini, â€œCompressive video sampling
with approximate message passing decoding,â€ IEEE Trans. Circuits Syst.
Video Technol., vol. 22, no. 9, pp. 1354â€“1364, Sep. 2012.
[9] C. Li, H. Jiang, W. Paul, and Y. Zhang, â€œA new compressive video sensing
framework for mobile broadcast,â€ IEEE Trans. Broadcast., vol. 59, no. 1,
pp. 197â€“205, Mar. 2013.
[10] M. Hosseini and K. N. Plataniotis, â€œHigh-accuracy total variation with
application to compressed video sensing,â€ IEEE Trans. Image Process.,
vol. 23, no. 9, pp. 3869â€“3884, Sep. 2014.
[11] P. Nagesh and B. Li, â€œA compressive sensing approach for expressioninvariant face recognition,â€ in Proc. IEEE Int. Conf. Comput. Vis. Pattern
Recognit. (CVPR), 2009, pp. 1518â€“1525.
[12] T. T. Do, Y. Chen, D. T. Nguyen, N. Nguyen, L. Gan, and T. D. Tran,
â€œDistributed compressed video sensing,â€ in Proc. Int. Conf. Image
Process. (ICIP), 2009, pp. 1393â€“1396.
[13] J. Nebot, Y. Ma, and T. Huang, â€œDistributed video coding using compressive sampling,â€ in Proc. Picture Coding Symp. (PCS), 2009, pp. 1â€“4.
[14] L. W. Kang and C. S. Lu, â€œDistributed compressive video sensing,â€
in Proc. Int. Conf. Acoust. Speech Signal Process. (ICASSP), 2009,
pp. 1169â€“1172.
[15] V. Thirumalai and P. Frossard, â€œDistributed representation of geometrically correlated images with compressed linear measurements,â€ IEEE
Trans. Image Process., vol. 21, no. 7, pp. 3206â€“3218, Jul. 2012.
[16] Y. Liu, M. Li, and A. Dimitris, â€œMotion-aware decoding of compressedsensed video,â€ IEEE Trans. Circuits Syst. Video Technol., vol. 23, no. 3,
pp. 438â€“444, Mar. 2013.

453

[17] K. Chang and B. Li, â€œJoint modeling and reconstruction of a
compressively-sensed set of correlated images,â€ J. Visual Commun.
Image Represent., vol. 33, pp. 286â€“300, 2015.
[18] K. Chang, T. Qin, W. Xu, and Z. Tang, â€œReconstruction of multi-view
compressed imaging using weighted total variation,â€ Multimedia Syst.,
vol. 20, no. 4, pp. 363â€“378, 2014.
[19] M. Trocan, E. W. Tramel, J. E. Fowler, and B. Pesquet, â€œCompressedsensing recovery of multiview image and video sequences using signal
prediction,â€ Multimedia Tools Appl., vol. 72, no. 1, pp. 95â€“121, 2014.
[20] Y. Liu, C. Zhang, and J. Kim, â€œDisparity-compensated total-variation
minimization for compressed-sensed multiview image reconstruction,â€ in
Proc. IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), 2015,
pp. 1458â€“1462.
[21] V. Thirumalai and P. Frossard, â€œCorrelation estimation from compressed
images,â€ J. Visual Commun. Image Represent., vol. 24, no. 6, pp. 649â€“
660, 2013.
[22] H. Yoon, K. S. Kim, D. Kim, Y. Bresler, and J. C. Ye, â€œMotion adaptive patch-based low-rank approach for compressed sensing cardiac cine
MRI,â€ IEEE Trans. Med. Imag., vol. 33, no. 11, pp. 2069â€“2085, Nov.
2014.
[23] Q. Chen, P. Montesinos, Q. Sun, P. Heng, and D. Xia, â€œAdaptive total
variation denoising based on difference curvature,â€ Image Vis. Comput.,
vol. 28, no. 3, pp. 298â€“306, 2010.
[24] W. Dong, X. Yang, and G. Shi, â€œCompressive sensing via reweighted
TV and nonlocal sparsity regularisation,â€ Electron. Lett., vol. 49, no. 3,
pp. 184â€“186, 2013.
[25] E. J. CandÃ¨s, M. B. Wakin, and S. P. Boyd, â€œEnhancing sparsity by
reweighted l1 minimization,â€ J. Fourier Anal. Appl., vol. 14, no. 5,
pp. 877â€“905, 2008.
[26] M. Fazel, H. Hindi, and S. P. Boyd, â€œLog-det heuristic for matrix
rank minimization with applications to hankel and euclidean distance
matrices,â€ in Proc. Amer. Control Conf., 2003, pp. 2156â€“2162.
[27] T. Goldstein and S. Osher, â€œThe split bregman method for l1 regularized
problems,â€ SIAM J. Imag. Sci., vol. 2, no. 2, pp. 323â€“343, 2009.
[28] E. T. Hale, W. Yin, and Y. Zhang, â€œFixed-point continuation for l1minimization: Methodology and convergence,â€ SIAM J. Optim., vol. 19,
no. 3, pp. 1107â€“1130, 2008.
[29] T. T. Do, L. Gan, N. H. Nguyen, and T. D. Tran, â€œFast and efficient compressive sensing using structurally random matrices,â€ IEEE Trans. Signal
Process., vol. 60, no. 1, pp. 139â€“154, Jan. 2012.
[30] C. Li, W. Yin, H. Jiang, and Y. Zhang, â€œAn efficient augmented lagrangian
method with applications to total variation minimization,â€ Comput.
Optim. Appl., vol. 56, no. 3, pp. 507â€“530, 2013.
[31] C. Liu, â€œBeyond pixels: Exploring new representations and applications for motion analysis,â€ Ph.D. dissertation, Department of Electrical
Engineering and Computer Science, Massachusetts Inst. Technol.,
Cambridge, MA, USA, 2009.
[32] T. Brox, A. Bruhn, N. Papenberg, and J. Weickert, â€œHigh accuracy optical flow estimation based on a theory for warping,â€ in Proc. Eur. Conf.
Comput. Vis. (ECCV), 2004, pp. 25â€“36.

