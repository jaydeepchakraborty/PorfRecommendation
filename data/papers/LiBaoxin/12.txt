In this paper, we propose a real-time system using vehicle back-up camera to alert for potential back-up collisions. We developed a highly efficient algorithm, combining segmenting pedestrians and vehicles from moving background using local optical flow value, and a scale adaptive method using Deformable Part Model to detect objects at different distances. To test out algorithm, we created our own vehicle back-up dataset that contains rich scenes recorded from a back-up camera on moving/stationary vehicles with unique and challenging scenarios such as frequent occlusion with cluttered and moving background, and we made this dataset available to public for other researchers. Experiments on the dataset shows that our algorithm achieves high accuracy in near real-time, and it is about 10 times faster than the comparable state-of-the-art algorithm.
Personalized and content-adaptive image enhancement can find many applications in the age of social media and mobile computing. This paper presents a relative-learning-based approach, which, unlike previous methods, does not require matching original and enhanced images for training. This allows the use of massive online photo collections to train a ranking model for improved enhancement. We first propose a multi-level ranking model, which is learned from only relatively-labeled inputs that are automatically crawled. Then we design a novel parameter sampling scheme under this model to generate the desired enhancement parameters for a new image. For evaluation, we first verify the effectiveness and the generalization abilities of our approach, using images that have been enhanced/labeled by experts. Then we carry out subjective tests, which show that users prefer images enhanced by our approach over other existing methods.
Video-based coaching systems have seen increasing adoption in various applications including dance, sports, and surgery training. Most existing systems are either passive (for data capture only) or barely active (with limited automated feedback to a trainee). In this paper, we present a video-based skill coaching system for simulation-based surgical training by exploring a newly proposed problem of instructive video retrieval. By introducing attribute learning into video for high-level skill understanding, we aim at providing automated feedback and providing an instructive video, to which the trainees can refer for performance improvement. This is achieved by ensuring the feedback is weakness-specific, skill-superior and content-similar. A suite of techniques was integrated to build the coaching system with these features. In particular, algorithms were developed for action segmentation, video attribute learning, and attribute-based video retrieval. Experiments with realistic surgical videos demonstrate the feasibility of the proposed method and suggest areas for further improvement.
Color demosaicking is used to reconstruct full color images from incomplete color filter array samples captured by cameras with a single sensor array. In reconstructing natural-looking images, one key challenge is to model and respect the statistics of natural images. This paper presents a novel modeling strategy and an efficient color demosaicking algorithm. The approach starts with joint modeling of the color images, which supports simultaneous representation of inter-channel correlation and structural information in an image. The inter-channel correlation is explored by measuring the channel difference signals in the gradient domain, while the structural information is explored by nonlocal low-rank regularization. An efficient algorithm is then proposed to solve the joint formulation, by dividing the minimization problem into two sub-problems and solving them iteratively. The effectiveness of the proposed approach is demonstrated with extensive experiments on both noiseless and noisy datasets, with comparison with existing state-of-the-arts color demosaicking methods.
In this proposal, we study the problem of understanding human sentiments from large scale collection of Internet images based on both image features and contextual social network information (such as friend comments and user description). Despite the great strides in analyzing user sentiment based on text information, the analysis of sentiment behind the image content has largely been ignored. Thus, we extend the significant advances in text-based sentiment prediction tasks to the higher level challenge of predicting the underlying sentiments behind the images. We show that neither visual features nor the textual features are by themselves sufficient for accurate sentiment labeling. Thus, we provide a way of using both of them, and formulate sentiment prediction problem in two scenarios: supervised and unsupervised. We develop an optimization algorithm for finding a local-optima solution under the proposed framework. With experiments on two large-scale datasets, we show that the proposed method improves significantly over existing state-of-the-art methods. In the future, we are going to incorporating more information on the social network and explore sentiment on signed social network.
In this paper, we propose a real-time system using vehicle back-up camera to alert for potential back-up collisions. We developed a highly efficient algorithm, combining segmenting pedestrians and vehicles from moving background using local optical flow value, and a scale adaptive method using Deformable Part Model to detect objects at different distances. To test out algorithm, we created our own vehicle back-up dataset that contains rich scenes recorded from a back-up camera on moving/stationary vehicles with unique and challenging scenarios such as frequent occlusion with cluttered and moving background, and we made this dataset available to public for other researchers. Experiments on the dataset shows that our algorithm achieves high accuracy in near real-time, and it is about 10 times faster than the comparable state-of-the-art algorithm.
