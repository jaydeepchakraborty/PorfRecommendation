LR-PPR: Locality-Sensitive, Re-use Promoting,
Approximate Personalized PageRank Computation
Jung Hyun Kim

K. Sel√ßuk Candan

Maria Luisa Sapino

Arizona State University
Tempe, AZ 85287, USA

Arizona State University
Tempe, AZ 85287, USA

University of Torino
I-10149 Torino, Italy

jkim294@asu.edu

candan@asu.edu

mlsapino@di.unito.it
G

ABSTRACT
Personalized PageRank (PPR) based measures of node proximity
have been shown to be highly effective in many prediction and recommendation applications. The use of personalized PageRank for
large graphs, however, is difficult due to its high computation cost.
In this paper, we propose a Locality-sensitive, Re-use promoting,
approximate personalized PageRank (LR-PPR) algorithm for efficiently computing the PPR values relying on the localities of the
given seed nodes on the graph: (a) The LR-PPR algorithm is locality sensitive in the sense that it reduces the computational cost
of the PPR computation process by focusing on the local neighborhoods of the seed nodes. (b) LR-PPR is re-use promoting in that
instead of performing a monolithic computation for the given seed
node set using the entire graph, LR-PPR divides the work into localities of the seeds and caches the intermediary results obtained
during the computation. These cached results are then reused for
future queries sharing seed nodes. Experiment results for different
data sets and under different scenarios show that LR-PPR algorithm
is highly-efficient and accurate.

Categories and Subject Descriptors
H.3 [Information Storage and Retrieval]: Miscellaneous

Keywords
Personalized PageRank; Locality-Sensitivity; Reuse-Promotion

1.

INTRODUCTION

Node distance/proximity measures are commonly used for quantifying how nearby or otherwise related to two or more nodes on
a graph are. Path-length based definitions [17] are useful when the
relatedness can be captured solely based on the properties of the
nodes and edges on the shortest path (based on some definition of
path-length). Random-walk based definitions, such as hitting distance [16] and personalized page rank (PPR) score [4, 13, 21] of
‚àó
This work is supported by NSF Grant 1043583 ‚ÄúMiNC: NSDL
Middleware for Network- and Context-aware Recommendations‚Äù.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CIKM‚Äô13, Oct. 27‚ÄìNov. 1, 2013, San Francisco, CA, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2263-8/13/10 ...$15.00.
http://dx.doi.org/10.1145/2505515.2505651.

‚àó

v1

b
v2

d
c
a

v3

Figure 1: Key questions: Given a graph, G, and a seed set of
nodes S = {v1 , v2 , v3 } in G, can we rank the remaining nodes
in the graph regarding their relationships to the set S? Which
of the nodes a through d is the most interesting given the seed
set of nodes v1 through v3 ?
node relatedness, on the other hand, also take into account the density of the edges: unlike in path-based definitions, random walkbased definitions of relatedness also consider how tightly connected
two nodes are and argue that nodes that have many paths between
them can be considered more related. Random-walk based techniques encode the structure of the network in the form a transition matrix of a stochastic process from which the node relationships can be inferred. When it exists, the convergence probability of a node n gives the ratio of the time spent at that node in a
sufficiently long random walk and, therefore, neatly captures the
connectivity of the node n in the graph. Therefore, many web
search and recommendation algorithms, such as PageRank [5],
rely on random-walks to identify significant nodes in the graph:
let us consider a weighted, directed graph G(V, E), where the
weight
j ‚àà E is denoted as wj (‚â• 0) and where
 of the edge e
= 1.0. The PageRank score of the node
w
j
ej ‚ààoutedge(vi )
vi ‚àà V is the stationary distribution of a random walk on G, where
at each step with probability 1‚àíŒ≤, the random walk moves along an
outgoing edge of the current node with a probability proportional
to the edge weights and with probability Œ≤, the walk jumps to a
random node in V . In other words, if we denote all the PageRank
scores of the nodes in V with a vector œÄ , then
œÄ = (1 ‚àí Œ≤)TG √ó œÄ + Œ≤j,
where TG denotes the transition matrix corresponding to the graph
G (and the underlying edge weights) and j is a teleportation vector
where all entries are V1  .

1.1 Proximity and PageRank
An early attempt to contextualize the PageRank scores is the
topic sensitive PageRank [12] approach which adjusts the PageRank scores of the nodes by assigning the teleportation probabilities in vector j in a way that reflects the graph nodes‚Äô degrees of

G
G1

G

incoming bnd. node
of G1

G1

G2

v1

G2

v2

a shared
node
v1
v3

outgoing bnd. node
of G1

Figure 2: Locality-sensitivity: Computation of PPR should focus on the neighborhoods (localities) of the seeds
G
G1

G
G1

G2

v1

G7

v1
v7

v2

v6

v3

Figure 4: Incoming and outgoing boundary nodes/edges and a
node shared between two localities
‚Ä¢ locality sensitive in the sense that it reduces the computational cost of the PPR computation process and improve accuracy by focusing on the neighborhoods of the seed nodes
(Figure 2); and

v9

G6

G3

G9

(a) PPR query 1

v2

G3

(b) PPR query 2

‚Ä¢ re-use promoting in that it enables caching and re-use of significant portions of the intermediary work for the individual
seed nodes in future queries (Figure 3).

Figure 3: Re-use promotion: Two PPR queries sharing a seed
node (v1 ) should also share relevant work
match to the search topic. [6, 7] were among the first works which
recognized that random-walks can also be used for measuring the
degree of association, relatedness, or proximity of the graph nodes
to a given seed node set, S ‚äÜ V (Figure 1). An alternative to
this approach is to modify (as in topic sensitive PageRank [12]) the
teleportation vector, j: instead of jumping to a random node in V
with probability Œ≤, the random walk jumps to one of the nodes in
the seed set, S, given by the user. More specifically, if we denote
the personalized PageRank scores of the nodes in V with a vector
 then
œÜ,
 = (1 ‚àí Œ≤)TG √ó œÜ
 + Œ≤s,
œÜ
1
where s is a re-seeding vector, such that if vi ‚àà S, then s[i] = S
and s[i] = 0, otherwise. One key advantage of this approach over
modifying the transition matrix as in [6] is that the term Œ≤ can be
used to directly control the degree of seeding (or personalization)
of the PPR score. However, the use of personalized PageRank for
large graphs is difficult due to the high cost of solving for the vec given Œ≤, transition matrix TG , and the seeding vector s.
tor œÜ,
 is to solve the above equation for œÜ
 matheOne way to obtain œÜ
matically. Alternatively, PowerIteration methods [14] simulate the
dissemination of probability mass by repeatedly applying the tran 0 until a convergence crisition process to an initial distribution œÜ
terion is satisfied. For large data sets, both of these processes are
prohibitively expensive. Recent advances on personalized PageRank includes top-k and approximate personalized PageRank algorithms [1, 3, 8, 10, 11, 20, 22] and parallelized implementations on
MapReduce or Pregel based batch data processing systems [2, 15].
The FastRWR algorithm presented in [22] for example partitions
the graph into subgraphs and indexes partial intermediary solutions.
Unfortunately, for large data sets, FastRWR requires large number
of partitions to ensure that the intermediary metadata (which requires dense matrix representation) fits into the available memory
and this negatively impacts execution time and accuracy.

1.2 Contributions of this Paper
In this paper, we argue that we can improve both scalability and
accuracy through a Locality-sensitive, Re-use promoting, approximate personalized PageRank (LR-PPR) algorithm: LR-PPR is

In the following section, we first formally introduce the problem
and then present our solution for locality-sensitive, re-use promoting, approximate personalized PageRank computations. We evaluate LR-PPR for different data sets and under different scenarios in
Section 3. We conclude in Section 4.

2. PROPOSED APPROACH
Let G = (V, E) be a directed graph. For the simplicity of the
discussion, without any loss of generality, let us assume that G is
unweighted1 . Let us be given a set S ‚äÜ V of seed nodes (Figure 1)
and a personalization parameter, Œ≤. Let GS = {Gh (Vh , Eh ) | 1 ‚â§
h ‚â§ K} be K = S subgraphs of G, such that
‚Ä¢ for each vi ‚àà S, there exists a corresponding Gi ‚àà GS such
that vi ‚àà Vi and
‚Ä¢ for all Gh ‚àà GS , Gh   G.
We first formalize the locality-sensitivity goal (Figure 2):
Desideratum 1: Locality-Sensitivity. Our goal is to compute an
 apx , using GS instead of G, such that
approximate PPR vector, œÜ
 apx ‚àº œÜ,
 where œÜ
 represents the true PPR scores of the nodes in
œÜ
V relative to S: i.e.,
 = (1 ‚àí Œ≤)TG √ó œÜ
 + Œ≤s,
 apx ‚àº œÜ
œÜ
where TG is the transition matrix corresponding to G and s is the
re-seeding vector corresponding to the seed nodes in S.
We next formalize the re-use promotion goal (Figure 3):
Desideratum 2: Reuse-Promotion. Let S1 and S2 be two sets of
seed nodes and let vi be a node such that vi ‚àà S1 ‚à© S2 . Let also the
 apx,1 corresponding to S1 have already
approximate PPR vector, œÜ
been computed using GS1 and let us assume that the approximate
 apx,2 corresponding to S2 is being requested. The
PPR vector, œÜ
part of the work performed when processing Gi ‚àà GS1 (corresponding to vi ) should not need to be re-performed when process apx,2 using GS .
ing Gi ‚àà GS , when computing œÜ
2

2.1

2

Combined Locality and its Boundary

Unlike existing approximate PPR algorithms [1, 3, 8, 10, 11, 20,
22], LR-PPR is location sensitive. Therefore, given the set, S, of
1

Extending the proposed algorithms to weighted graphs is trivial.

G1
v1

GK

G3

G2
v2

v3

‚éõ

vK

‚éú 0V2 √óV1 
‚éú
...
‚éú
‚éù0
VK √óV1 
01√óV1 

A node shared by multiple seed locality graphs

Figure 5: An equivalence set consists of the copies of a node
shared across multiple seed locality graphs
seed nodes and the corresponding localities, GS , the computation
focuses on the combined locality G+ (V + , E + ) ‚äÜ G, where


Vl and E + =
El .
V+ =
1‚â§l‚â§K

1‚â§l‚â§K

Given a combined locality, G+ , we can also define its external
graph, G‚àí (V ‚àí , E ‚àí ), as the set of nodes and edges of G that
are outside of G+ and boundary nodes and edges. As shown in
Figure 4, we refer to vi ‚àà Vl as an outgoing boundary node of
Gl if there is an outgoing edge ei,j = [vi ‚Üí vj ] ‚àà E, where
vj ‚àà
/ Vl ; the edge ej is also referred to as an outgoing boundary
edge of Gl . The set of all outgoing boundary nodes of Gl is denoted as Voutbound,l and the set of all outgoing boundary edges of
Gl is denoted as Eoutbound,l. Note that Voutbound,l ‚äÜ Vl , whereas
Eoutbound,l ‚à© El = ‚àÖ.
We also define incoming boundary nodes (Vinbound,l ) and incoming boundary edges (Einbound,l ) similarly to the outgoing
boundary nodes and edges of Gl , but considering inbound edges
to these subgraphs. More specifically, Einbound,l consists of edges
of the form [vi ‚Üí vj ] ‚àà E, where vj ‚àà Vl and vi ‚àà
/ Vl .

2.2 Localized Transition Matrix
Since LR-PPR focuses on the combined locality, G+ , the next
step is to combine the transition matrices of the individual localities
into a combined transition matrix. To produce accurate approximations, this localized transition matrix, however, should nevertheless
take the external graph, G‚àí , and the boundaries between G‚àí and
G+ , into account.

2.2.1 Transition Matrices of Individual Localities
Let v(l,i) (1 ‚â§ l ‚â§ K) denote a re-indexing of vertices in Vl .
If v(l,i) ‚àà Vl and vc ‚àà V s.t. v(l,i) = vc , we say that v(l,i) is a
member of an equivalence set, Vc (Figure 5). Intuitively, the equivalence sets capture the common parts across the localities of the
individual seed nodes. Given Gl (Vl , El ) ‚äÜ G and an appropriate
re-indexing, we define the corresponding local transition matrix,
Ml , as a Vl  √ó Vl  matrix, where


‚Ä¢ ei,j = [v(l,i) ‚Üí v(l,j) ] ‚àà El ‚Üí Ml [j, i] = 0 and


‚Ä¢ ‚àÉei,j = [v(l,i) ‚Üí v(l,j) ] ‚àà El ‚Üí Ml [j, i] =

1
,
out(v(l,i) )

where out(v(l,i) ) is the number of outgoing edges of vi .

2.2.2 Localization of the Transition Matrix
Given the local transition matrices, M1 through MK , we localize the transition matrix of G by approximating it as
Mapx = Mbd + M0 ,
where Mbd is a block-diagonal matrix of the form

M1

0V1 √óV2 
M2
...
0VK √óV2 
01√óV2 

. . . 0V1 √óVK 
. . . 0V2 √óVK 
...
...
...
MK
...
01√óVK 

‚éû
0V1 √ó1
0V2 √ó1 ‚éü
‚éü
... ‚éü,
0VK √ó1 ‚é†
MK+1

where MK+1 is equal to the 1 √ó 1 matrix 01√ó1 . Intuitively,
Mbd combines the K subgraphs into one transition matrix, without
considering common nodes/edges or incoming/outgoing boundary
edges and ignoring all outgoing and incoming edges. All the external nodes in G‚àí are accounted by a single node represented by the
1 √ó 1 matrix MK+1 .
A key advantage of Mbd is that it is block-diagonal and, hence,
there are efficient ways to process it. However, this block-diagonal
matrix, Mbd , cannot accurately represent the graph G as it ignores
potential overlaps among the individual localities and ignores all
the nodes and edges outside of G+ . We therefore need a compensation matrix to
‚Ä¢ make sure that nodes and edges shared between the localities
are not double counted during PPR computation and
‚Ä¢ take into account the topology of the graph external to both
localities G1 through GK .

2.2.3 Compensation Matrix, M 0
Let t be (V1  + V2  + . . . + VK  + 1). The compensation
matrix, M0 , is a t √ó t matrix accounting for the boundary edges
of the seed localities as well as the nodes/edges in G‚àí . M0 also
ensures that the common nodes in V1 through VK are not double
counted during PPR calculations. M0 is constructed as follows:
Row/column indexing: Let vl,i be a vertex in Vl . We introduce a
row/column indexing function, ind(), defined as follows:
‚éõ
‚éû

ind(l, i) = ‚éù
Vh ‚é† + i
1‚â§h<l

Intuitively the indexing function, ind(), maps the relevant nodes in
the graph to their positions in the M0 matrix.
Compensation for the common nodes: Let el,i,j be an edge
[v(l,i) ‚Üí v(l,j) ] ‚àà El and let v(l,j) be a member of the equivalence set Vc for some vc ‚àà V . Then, if Vc  > 1
1
c ‚àí1
√ó out(G,v
and
‚Ä¢ M0 [ind(l, j), ind(l, i)] = ‚àí VV
c
l,i )
‚Ä¢ ‚àÄv(h,k) ‚àà Vc s.t. v(h,k) = v(l,j) , we have
M0 [ind(h, k), ind(l, i)] = ‚àí

1
1
√ó
,
Vc 
out(G, vl,i )

where out(G, v) is the outdegree of node v in G. Intuitively, the
compensation matrix re-routes a portion of the transitions going
towards a shared node in a given locality Vl to the copies in other
seed localities. This prevents the transitions to and from the shared
node from being mis-counted.
Compensation for outgoing boundary edges: The compensation matrix needs to account also for outgoing boundary edges that
are not accounted for by the neighborhood transition matrices M1
through MK :
‚Ä¢ Accounting for boundary edges from nodes in Vl to nodes in
Vh : ‚àÄ[v(l,i) ‚Üí v(h,j) ] ‚àà Eoutbound,l
‚Äì M0 [ind(h, j), ind(l, i)] =

1
out(v(l,i) )

‚Ä¢ Accounting for boundary edges from nodes in Vl to graph
nodes that are in V ‚àí :
if ‚àÉ[v(l,i) ‚Üí v] ‚àà Eoutbound,l s.t. v ‚àà V ‚àí

‚Äì M0 [t, ind(l, i)] =

bnd(v(l,i) )
,
out(v(l,i) )

where bnd(v(l,i) ) is

the number of edges of the form [v(l,i) ‚Üí v] ‚àà
Eoutbound,l where v ‚àà V ‚àí
else M0 [t, ind(l, i)] = 0
The compensation matrix records all outgoing edges, whether they
cross into another locality or they are into external nodes in G‚àí . If
a node has more than one outgoing edge into the nodes in G‚àí , all
such edges are captured using one single compensation edge which
aggregates all the corresponding transition probabilities.
Compensation for incoming boundary edges (from G‚àí ): Similarly to the outgoing boundary edges, the compensation matrix
needs also to account for incoming boundary edges that are not
accounted for by the neighborhood transition matrices M1 through
MK . Since incoming edges from other localities have been accounted for in the previous step, here we only need to consider
incoming boundary edges (from G‚àí ). Following the formulation
in [23], we account for incoming edges where the source is external to G+ and the destination is a vertex v(l,i) in Vl by inserting
an edge from the dummy node to v(l,i) with a weight that considers the outdegrees of all external source nodes; i.e., ‚àÄv(l,i) s.t.
‚àÉ[vk ‚Üí v(l,i) ] ‚àà Einbound,l where vk ‚àà V ‚àí and v(l,i) is in the
equivalence set Vc for a vc ‚àà V , M0 [ind(l, i), t] is equal to

1
([vk ‚Üív(l,i) ]‚ààEinbound,l )‚àß(vk ‚ààV ‚àí ) out(G,vk )
1
,
Vc 
V ‚àí 
where out(G, v) is the outdegree of node v in G.
Compensation for the edges in G‚àí : We account for edges that
are entirely in G‚àí by creating a self-loop that represents the sum of
outdegree flow between all external nodes averaged by the number
of external nodes; i.e.,

out(G‚àí ,v)
M0 [t, t] =

v‚ààV ‚àí

out(G,v)

V ‚àí 

,

where out(G‚àí , v) and out(G, v) are the outdegrees of node v in
G‚àí and G, respectively.
Completion: For any matrix position p, q not considered above, no
compensation is necessary; i.e., M0 [p, q] = 0.

2.3 L-PPR: Locality Sensitive PPR
Once the block-diagonal local transition matrix, Mbd , and the
compensation matrix, M0 , are obtained, the next step is to obtain
the PPR scores of the nodes in V + . This can be performed using
any fast PPR computation algorithm discussed in Section 1.1.
Note that the overall transition matrix Mapx = Mbd + M0 is
approximate in the sense that all the nodes external to G+ are clustered into a single node, represented by the last row and column of
the matrix. Otherwise, the combined matrix Mapx accurately represents the nodes and edges in the ‚Äúmerged localities graph‚Äù combining the seed localities, G1 through GK . As we see in Section 3,
this leads to highly accurate PPR scores with better scalability than
existing techniques.

the nodes in V + . In particular, we rely on the following result due
to [22], which itself relies on the Sherman-Morisson lemma [18]:
Let C = A + USV. Let also (I ‚àí cA)‚àí1 = Q‚àí1 . Then,
the equation
r = (1 ‚àí c)(I ‚àí cA)‚àí1e
has the solution
r = (1 ‚àí c)(Q‚àí1e + cQ‚àí1 UŒõVQ‚àí1e),
where
Œõ = (S‚àí1 ‚àí cVQ‚àí1 U)‚àí1 .
If A is a block diagonal matrix consisting of k blocks, A1
through Ak , then Q‚àí1 is also a block diagonal matrix con‚àí1
sisting of k corresponding blocks, Q‚àí1
1 through Qk , where
‚àí1
‚àí1
Qi = (I ‚àí cAi ) .
We use the above observation to efficiently obtain PPR scores by
setting c = (1 ‚àí Œ≤), C = Mapx , A = Mbd , and USV = M0 .
In particular, we divide the PPR computation into two steps: a
locality-sensitive and re-usable step involving the computation of
the Q‚àí1 term using the local transition matrices and a run-time
computation step involving the compensation matrix.

2.4.1 Locality-sensitive and Re-usable Q ‚àí1
bd
Local transition matrices, M1 through MK corresponding to the
seeds v1 through vK are constant (unless the graph itself evolves
‚àí1
is computed
over time). Therefore, if Q‚àí1
h = (I ‚àí (1 ‚àí Œ≤)Mh )
and cached once, it can be reused for obtaining Q‚àí1
bd , which is a
‚àí1
block diagonal matrix consisting of Q‚àí1
1 through QK+1 (as before,
‚àí1
the last block, QK+1 , is simply equal to 11√ó1 ):
‚éû
‚éõ
Q‚àí1
0V1 √óV2  . . . 0V1 √óVK  0V1 √ó1
1
‚àí1
‚éú 0V √óV 
Q2
. . . 0V2 √óVK  0V2 √ó1 ‚éü
2
1
‚éü
‚éú
‚éú
.
.
.
.
.
.
.
..
...
... ‚éü
‚éü,
‚éú
‚àí1
‚é†
‚éù0V √óV1  0V √óV2  . . .
Q
0
V
√ó1
K
K
K
K
‚àí1
01√óV1 
01√óV2 
...
01√óVK 
QK+1

2.4.2 Computation of the LR-PPR Scores
In order to be able to use the above formulation for obtaining the
PPR scores of the nodes in V + , in the query time, we need to decompose the compensation matrix, M0 , into U0 S0 V0 . While obtaining a precise decomposition in run-time would be prohibitively
expensive, since M0 is sparse and since we are looking for an approximation of the PPR scores, we can obtain a fairly accurate lowrank approximation of M0 efficiently [22]:
M0  UÃÉ0 SÃÉ0 VÃÉ0 .
 apx , which contains
Given this decomposition, the result vector œÜ
the (approximate) PPR scores of the nodes in V + , is computed as


 apx = Œ≤ Q‚àí1s + (1 ‚àí Œ≤)Q‚àí1 UÃÉ0 ŒõVÃÉ0 Q‚àí1 s ,
œÜ
bd
bd
bd
where

2.4 LR-PPR: Locality Sensitive and Reuse
Promoting PPR

‚àí1

‚àí1
Œõ = SÃÉ‚àí1
.
0 ‚àí (1 ‚àí Œ≤)VÃÉ0 Qbd UÃÉ0

Our goal is not only to leverage locality-sensitivity as in L-PPR,
but also to boost sub-result re-use. Remember that, as discussed
above, the localized transition matrix Mapx is equal to Mbd + M0
where (by construction) Mbd is a block-diagonal matrix, whereas
M0 (which accounts for shared, boundary, and external nodes) is
relatively sparse. We next use these two properties of the decomposition of Mapx to efficiently compute approximate PPR scores of

Note that the compensation matrix M0 is query specific and,
thus, the work done for the last step cannot be reused across queries.
However, as we experimentally verify in Section 3, the last step
is relatively cheap and the earlier(costlier) steps involve re-usable
work. Thus, caching and re-use through LR-PPR enables significant savings in execution time. We discuss the overall complexity
and the opportunities for re-use next.

2.5 Complexity and Re-use

3.

EXPERIMENTAL EVALUATION

In this section, we present results of experiments assessing
the efficiency and effectiveness of the Locality-Sensitive, Re-use
Promoting Approximate Personalized PageRank (LR-PPR) algorithm. Table 1 provides overviews of the three data sets (from
http : //snap.stanford.edu/data/) considered in the experiments. We considered graphs with different sizes and edge densities. We also varied numbers of seeds and the distances between the
seeds (thereby varying the overlaps among seed localities). We also
considered seed neighborhoods (or localities) of different sizes.
Experiments were carried out using a 4-core Intel Core i5-2400,
3.10GHz, machine with 8GB memory and 64-bit Windows 7 Enterprise. Codes were executed using Matlab 7.11.0(2010b). All
experiments were run 10 times and averages are reported.

3.1 Alternative Approaches
Global PPR: This is the default approach where the entire graph is
used for PPR computation. We compute the PPR scores by solving
the equation presented in Section 1.1.
FastRWR: This is an approximation algorithm, referred to as
NB_LIN in [22]. The algorithm reduces query execution times by
partitioning the graph into subgraphs and preprocessing each partition. The pre-computed files are stored on disk and loaded to the
memory during the query stage. To be fair to FastRWR, we selected
the number of partitions in a way that minimizes its execution time
and memory and maximizes its quality.
L-PPR: This is our locality sensitive algorithm, where instead of
using the whole graph, we use the localized graph created by combining the locality nodes and edges as described in Section 2.2.
Once the localized transition matrix is created, the PPR scores are
computed by solving the equation presented in Section 1.1.
LR-PPR: This is the locality sensitive and re-use promoting algorithm proposed described in detail in Section 2.4.
The restart probability, Œ≤, is set to 0.15 for all approaches.

3.2 Evaluation Measures
Efficiency: This is the amount of time taken to load the relevant
(cached) data from the disk plus the time needed to carry out the
operations to obtain the PPR scores.

&%

	"

Analysis of LR-PPR points to the following advantages: First of
all, computation is done using only local nodes and edges. Secondly, most of the results of the expensive sub-tasks can be cached
and re-used. Moreover, costly matrix inversions are limited to the
smaller matrices representing localities and small matrices of size
r √ó r. Various subtasks
have complexity proportional to V + 2 ,

where V +  = 1‚â§l‚â§K Vl . While in theory the locality Vl can
be arbitrarily large, in practice we select localities with a bounded
number of nodes; i.e., ‚àÄ1‚â§l‚â§K , Vl  ‚â§ L for some L  V .
As described above LR-PPR algorithm supports caching and reuse of some of the intermediary work. The process results in local transition matrices, each of which can be cached in O(El )
space (where El is the number edges in the locality) assuming a
sparse representation. The algorithm also involves a matrix inversion, which results in a dense matrix; as a result, caching the
inverted matrix takes O(Vl 2 ) space (where Vl is the number of
vertices in the locality). If the locality is size-constrained, this leads
to constant space usage of O(L2 ), where L is the maximum number of nodes in the locality. If the inverted matrix of a locality is
cached, then the local transition matrix does not need to be maintained further. For cache replacement, any frequency-based or predictive cache-replacement policy can be used.

1	"

()!
%..%..
%.'

%.-%.,
%-,

%.*%.*

%--
%-+

%,(
%*'

%*

%%

%-'
%,*

%'.

*

&%

'*
1

*%

,*

  

Figure 6: Accuracies of L-PPR, LR-PPR, and FastRWR
against the Global PPR for different numbers of target nodes
Accuracy: For different algorithm pairs, we report the Spearman‚Äôs
rank correlation

(xi ‚àí xÃÑ)(yi ‚àí yÃÑ)
 i
,

2
2
i (xi ‚àí xÃÑ)
i (yi ‚àí yÃÑ)
which measures the agreement between two rankings (nodes with
the same score are assigned the average of their positions in the
ranking). Here, x and y are rankings by two algorithms and xÃÑ and yÃÑ
are average ranks. To compute the rank coefficient, a portion of the
highest ranked nodes in the merged graph according to x are considered. As default, we considered 10% highest ranked nodes; but
we also varied the target percentage (5%, 10%, 25%, 50%, 75%) to
observe how the accuracy varies with result size.
Memory: We also report the amount of data read from the cache.

3.3 Results and Discussions
Table 2 presents experimental results for FastRWR, L-PPR, and
LR-PPR. First of all, all three algorithms are much faster than
Global PPR. As expected, in small data sets (Epinions and Slashdot) FastRWR works faster than L-PPR and LR-PPR, though in
many cases, it requires more memory. In large data sets, however,
L-PPR and LR-PPR significantly outperform FastRWR in terms of
query processing efficiency and run-time memory requirement.
In terms of accuracy, the proposed locality sensitive techniques,
L-PPR and LR-PPR, constantly outperform FastRWR. This is because, FastRWR tries to approximate the whole graph, whereas
the proposed algorithms focus on the relevant localities. FastRWR requires large number of partitions to ensure that the intermediary metadata (which requires dense matrix representation) fits
into memory and this negatively impacts accuracy. Our localitysensitive algorithms, L-PPR and LR-PPR, avoid this and provide
high accuracy with low memory consumption, especially in large
graphs, like WikiTalk.
Figure 6 confirms that the accuracies of L-PPR and LR-PPR
both stay high as we consider larger numbers of top ranked network nodes for accuracy assessment, whereas the accuracy of FastRWR suffers significantly when we consider larger portions of the
merged locality graph.
Figure 7 studies the execution time behavior for L-PPR, LRPPR, and FastRWR for different number of seed nodes. As the
figure shows, the time cost increases for both L-PPR and LR-PPR
algorithms as the number of seeds increases. But, the cost of LRPPR (which leverages re-use) increases much slower than the cost
of L-PPR and both remain significantly cheaper than FastRWR.

Table 1: Data sets
Data Set

Overall Graph Characteristics
# nodes
# edges
‚àº76K
‚àº500K
‚àº82K
‚àº870K
‚àº2.4M
‚àº5M

Epinions
SlashDot
WikiTalk

Locality Graph Characteristics
# nodes per neighborhood
# edges per neighborhood
from ‚àº200 to ‚àº2000
from ‚àº10K to ‚àº75K
from ‚àº700 to ‚àº5000
from ‚àº10K to ‚àº75K
from ‚àº700 to ‚àº6000
from ‚àº10K to ‚àº75K

# seeds
2-3
2-3
2-8

Seeds
seed distances (hops)
3-4
3-4
3-4

Table 2: Summary of the results for different configurations (in all scenarios, individual seed localities have ‚àº75K edges)
Seeds
Data set
Epinions
‚àº76K nodes
‚àº500K edges
SlashDot
‚àº82K nodes
‚àº870K edges
WikiTalk
‚àº2.4M nodes
‚àº5M edges

#
seeds
2
2
3
3
2
2
3
3
2
2
3
3

Merged Network

Dist
(#hops)
3
4
3
4
3
4
3
4
3
4
3
4

Avg
# nodes
‚àº2.2K
‚àº3.0K
‚àº2.7K
‚àº3.5K
‚àº5.9K
‚àº5.7K
‚àº7.1K
‚àº7.2K
‚àº5.7K
‚àº5.8K
‚àº6.3K
‚àº6.7K

Execution Time (sec.)

Avg
# edges
‚àº90K
‚àº99K
‚àº108K
‚àº120K
‚àº117K
‚àº125K
‚àº141K
‚àº159K
‚àº102K
‚àº100K
‚àº101K
‚àº103K

	#

"*+((*
!
',)

',+

',*

',)

Global
PPR
27.81
27.58
27.30
27.90
21.79
21.85
21.74
22.93
681.08
693.44
701.34
706.26

	 	!







&- &*


(&

*&

)&
'(

&-







#
 




',


	

Figure 7: Execution times of L-PPR, LR-PPR, and FastRWR
for different numbers of seed nodes

4.

CONCLUSIONS

In this paper, we presented a Locality-sensitive, Re-use promoting, approximate Personalized PageRank (LR-PPR) algorithm for
efficiently computing the PPR values relying on the localities of
the seed nodes on the graph. Instead of performing a monolithic
computation for the given seed node set using the entire graph, LRPPR divides the work into localities of the seeds and caches the intermediary results obtained during the computation. These cached
results can then be reused for future queries sharing seed nodes.
Experiments showed that the proposed LR-PPR approach provides
significant gains in execution time relative to existing approximate
PPR computation techniques, where the PPR scores are computed
from scratch using the whole network. LR-PPR also outperforms
L-PPR, where the PPR scores are computed in a locality-sensitive
manner, but without significant re-use.

5.

REFERENCES
[1] K. Avrachenkov, N. Litvak, D. Nemirovsky, E. Smirnova, and M.
Sokol. Quick Detection of Top-k Personalized PageRank Lists.
WAW‚Äô11, 2011.
[2] B.Bahmani, K.Chakrabarti, and D. Xin. Fast personalized
PageRank on MapReduce. In SIGMOD‚Äô11. 973-984. 2011.
[3] B.Bahmani, A.Chowdhury, and A.Goel. Fast incremental and
personalized PageRank. PVLDB. 4, 3, 173-184, 2010.
[4] A. Balmin, V. Hristidis, and Y.Papakonstantinou. ObjectRank:
Authority-based keyword search in databases. VLDB, 2004.

Fast
RWR
0.21
0.22
0.21
0.22
0.35
0.35
0.36
0.38
16.28
16.22
16.32
16.34

LPPR
0.37
0.51
0.58
0.76
0.70
0.78
1.12
1.39
0.75
0.73
0.75
0.78

LRPPR
0.14
0.20
0.26
0.36
0.53
0.42
0.95
0.83
0.37
0.37
0.37
0.36

Top-10%
Spearman‚Äôs
Correl. (vs. Global PPR)
Fast
LLRRWR
PPR
PPR
0.963
0.997
0.990
0.960
0.998
0.990
0.967
0.998
0.990
0.967
0.997
0.991
0.955
0.973
0.990
0.943
0.965
0.983
0.957
0.971
0.990
0.958
0.976
0.986
0.868
0.958
0.944
0.870
0.930
0.909
0.877
0.937
0.902
0.869
0.976
0.967

Memory usage(MB)
Fast
RWR
178.3

302.1

1429.0

LPPR
2.9
3.1
4.6
4.7
5.0
4.9
7.6
7.2
15.5
16.2
24.0
28.7

LRPPR
36.3
55.2
57.6
77.7
228.1
172.8
325.9
256.0
114.5
120.7
211.6
197.5

[5] S. Brin and L. Page. "The anatomy of a large-scale hypertextual
Web search engine". Computer Networks and ISDN Systems 30:
107-117, 1998.
[6] K. S. Candan and W.-S. Li. Using random walks for mining web
document associations. In PAKDD, pp. 294-305, 2000.
[7] K. S. Candan and W.-S. Li. Reasoning for Web document
associations and its applications in site map construction. Data
Knowl. Eng. 43(2), 2002.
[8] K. Csalogany, D.Fogaras, B. Racz, and T. Sarlos. Towards Scaling
Fully Personalized PageRank: Algorithms, Lower Bounds, and
Experiments Internet Math. 2,3, 333-358, 2005.
[9] F. Fouss, A. Pirotte, J. Renders, and M. Saerens. Random-walk
computation of similarities between nodes of a graph with
application to collaborative recommendation. TKDE, 2007.
[10] Y. Fujiwara, M. Nakatsuji, M. Onizuka, and M. Kitsuregawa. Fast
and exact top-k search for random walk with restart. PVLDB. 5, 5,
442-453. 2012.
[11] M. Gupta, A. Pathak, and S. Chakrabarti. Fast algorithms for Top-k
Personalized PageRank Queries. In WWW‚Äô08. 1225-1226. 2008.
[12] T.H. Haveliwala. Topic-sensitive PageRank. WWW‚Äô02. 517-526.
2002.
[13] G. Jeh and J. Widom. Scaling personalized web search. Stanford
University Technical Report. 2002.
[14] S.D. Kamvar, T.H. Haveliwala, C.D. Manning, and G.H. Golub.
Extrapolation methods for accelerating PageRank computations.
In WWW‚Äô03 261-270. 2003.
[15] G. Malewicz, et al. Pregel: a system for large-scale graph
processing. SIGMOD‚Äô10, 2010.
[16] Q. Mei, D. Zhou, and K. Church. Query suggestion using hitting
time, CIKM‚Äô08, 2008.
[17] C. Palmer, P. Gibbons, and C. Faloutsos. Anf: a fast and scalable
tool for data mining in massive graphs. KDD‚Äô02, 2002.
[18] W. Piegorsch and G. E. Casella. Inverting a sum of matrices. In
SIAM Review, 1990.
[19] P. Sarkar, A.W. Moore, and A. Prakash. Fast incremental
proximity search in large graphs. ICML‚Äô08, 2008.
[20] H. H. Song, et al. Scalable proximity estimation and link
prediction in online social networks. In Internet Measurement
Conference, pp. 322‚Äì335. 2009.
[21] H. Tong, C. Faloutsos, and Y. Koren. Fast direction-aware
proximity for graph mining. KDD, pp. 747‚Äì756, 2007.
[22] H. Tong, C. Faloutsos, and J.-Y. Pan. Fast Random Walk with
Restart and Its Applications. In ICDM‚Äô06. 613-622. 2006.
[23] Y. Wu and L. Raschid, ApproxRank: Estimating Rank for a
Subgraph, ICDE‚Äô09, 54-65, 2009.

