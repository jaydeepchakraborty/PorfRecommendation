From: AAAI-00 Proceedings. Copyright ¬© 2000, AAAI (www.aaai.org). All rights reserved.

Maintainability: a weaker stabilizability like notion for high level control
Mutsumi Nakamura
Department of CSE
University of Texas at Arlington
Arlington, TX 76019, USA
nakamura@cse.uta.edu

Chitta Baral
Department of CSE
Arizona State University
Tempe, AZ 85287, USA
chitta@asu.edu

Abstract
The goal of most agents is not just to reach a goal state, but
rather also (or alternatively) to put restrictions on its trajectory, in terms of states it must avoid and goals that it must
‚Äòmaintain‚Äô. This is analogous to the notions of ‚Äòsafety‚Äô and
‚Äòstability‚Äô in the discrete event systems and temporal logic
community.
In this paper we argue that the notion of ‚Äòstability‚Äô is too
strong for formulating ‚Äòmaintenance‚Äô goals of an agent ‚Äì in
particular, reactive and software agents, and give examples of
such agents. We present a weaker notion of ‚Äòmaintainability‚Äô
and show that our agents which do not satisfy the stability criteria, do satisfy the weaker criteria. We give algorithms to test
maintainability, and also to generate control for maintainability. We then develop the notion of ‚Äòsupportability‚Äô that generalizes both ‚Äòmaintainability‚Äô and ‚Äòstabilizability, develop an
automata theory that distinguishes between exogenous and
control actions, and develop a temporal logic based on it.

Motivation and Introduction
Stability has undergone extensive investigations in the control theory community (Passino & Burgess 1998), both for
continuous systems (e.g. Lyapunov stability and asymptotic
stability) and Discrete Event Dynamic Systems (DEDS)
(Ramadge & Wonham 1987b; 1987a; Ozveren, Willsky, &
Antsaklis 1991). All these notions can be summarized as in
(Passino & Burgess 1998):
We say that a system is stable if when it begins in a
good state and is perturbed into any other state it will
always return to a good state.
The appropriate stability notion in a particular case depends
on how the notions ‚Äúsystem‚Äù, ‚Äúbegins‚Äù, ‚Äústate‚Äù, ‚Äúgood‚Äù, and
‚Äúperturbed‚Äù are defined, For DEDS the mainstream definition can be found in (Ozveren, Willsky, & Antsaklis 1991),
and that definition is the one we use in this paper. They also
mention that relation between stability and the notions of
safety, fairness, livelock, deadlock are well studied. In this
paper we present a related notion which we call maintainability, and argue its importance, particularly for high level
control of agents.



Copyright c 2000, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.

Marcus BjaÃàreland
Department of Comp and Info Sc
LinkoÃàping University
S-581 83 Linkoping, Sweden
marbj@ida.liu.se

Intuitively, we can view stabilizability as a hard constraint
of the system while maintainability is a softer constraint. In
both maintainability and stabilizability our goal is that the
system should be among a given set of states E as much
as possible. In stabilizability, we want a control such that
regardless of where the system is now and what exogenous
actions may happen, the system will reach one of the states
in E within a finite number of transitions and keep visiting it infinitely often after that. In maintainability, we have
a weaker requirement where the system reaches a state in
E within a finite number of transitions, provided it is not
interfered with during those transitions. Thus in maintainability, we admit that if there is continuous interference (by
exogenous actions) we can not get to E in a finite number
of transition. Such a system will not satisfy the condition of
stabilizability, but may satisfy the condition of maintainability.
Many practical closed-loop systems are not stabilizable, but
they still serve a purpose and we believe that such systems purpose can be specified by using the weaker notion
of maintainability. An example of such a system is an active
database system (Widom & Ceri 1996) where ‚Äòconsistency‚Äô
of data is ‚Äòmaintained‚Äô using active rules (also referred to
as triggers). In such a database system, external updates
are made to the database through Insert, Delete and Update
commands. But the direct result of the updates may take
the database to an inconsistent state where ‚Äòintegrity constraints‚Äô of the database may be violated. In that case, the
active part of the database triggers rules that result in additional changes to the database to bring it back to a consistent
state. Now suppose E is the set of consistent states of a
database. We can not capture the correctness of the triggers
by directly using the notions of ‚Äòstability‚Äô. That is because,
if there is a continuous stream of external updates with no
time in between for getting back to consistency, then there is
no guarantee that the database will reach a state in E within
a finite number of transitions. But we can have a different
notion of correctness of triggers, where the triggers are correct if given a window of non-interference (from external
updates) the triggers will ultimately make the database consistent. In fact that is what happens in a database system
where external updates are blocked until the triggers bring
back the database to a consistent state.

Another example is a mobile robot (Brooks 1986; Maes
1991) which is asked to ‚Äòmaintain‚Äô a state where there are
no obstacles in its front. Here, if there is a belligerent adversary that keeps on putting an obstacle in front of the robot,
then the robot can not get to a state with no obstacle in its
front. But often we will be satisfied if the robot avoids obstacle in its front when it is not continually harassed. Of
course, we would rather have the robot take a path that does
not have such an adversary, but in the absence of such a path,
it would be acceptable if it takes an available path and ‚Äòmaintains‚Äô states where there are no obstacle in front.
Other examples include agents that perform tasks based on
commands. Here, the correctness of the agent‚Äôs behavior
can be formalized as ‚Äòmaintaining‚Äô states where there are no
commands in the queue. We can not use the notion of stability because if there is a continuous stream of commands,
then there is no guarantee that the agent would get to a state
with no commands in its queue within a finite number of
transitions.
The rest of the paper is structured as follows. We first formally define the notion of stability and stabilizability. We
then introduce the notion of maintainability and compare it
with the notion of stabilizability. Next we show that the correctness of an active database can be formalized as maintainability of consistent states. We then present algorithms
to verify maintainability, and to construct controls to make a
system maintain a set of states. Finally, we develop a general
notion called supportability and show that stabilizability and
maintainability are special cases of it.

Alternatively, A is stable w.r.t. E if, for any state x 62 E ,
every infinite trajectory starting with x will lead to E in a
finite number of steps.
Definition 0.4 R(A; x) denotes the set of states that can be
reached from x in a system A.

A state x is said to be alive if d(y ) 6= ;, for all y 2 R(A; x).
(I.e., we can not reach a state y from x, where no action is
possible.)
We say A

2

Stabilizability
We now consider control and exogenous actions. The set of
control actions U is a subset of , that can be performed by
the (controlling) agent. A particular control K is a function
from X to U . The set of exogenous actions that can occur in
a state (and that are beyond the control of the agent) is given
by a function e from X to 2 , such that e(x)  d(x).

Definition 0.5 Let A = (X; ; f; d) be a system. In presence of e, U , and K , we define AK 1 , the closed loop system of A as the four-tuple (X; ; f; dK ), where dK (x) =
(d(X ) \ fK (x)g) [ e(x).
2.
Definition 0.6 Given a system A, a function e, and a set of
states E , we say S  X is stabilizable with respect to E if
there exists a control law2 K such that for all x in S , x is
alive and stable with respect to E in the closed loop system
Ak . If S = X , we say A is stabilizable with respect to E .

2

Reviewing stability and stabilizability
In this section we review the notions of stability and stabilizability adapted from the definitions in (Ozveren, Willsky,
& Antsaklis 1991).

Stability and aliveness

Definition 0.1 A system A is a 4-tuple (X; ; f; d), where
X is a finite set of states,  is a finite set of actions, d is a
function from X to 2 listing what actions may occur (or
are executable) in what state, and f is a non-deterministic
2
transition function from X and  to 2X .
Definition 0.2 A trajectory is an alternating sequence of
states and actions, and could be either a finite trajectory that
starts and ends with a state or an infinite trajectory.
A trajectory x0 ; a1 ; x1 ; a2 ; : : : ; xk ; ak+1 ; xk+1 (: : :) is said
to be consistent with a system A if:

 xk+1 2 f (xk ; ak+1 ), and
 ak+1 2 d(xk ).
2
Definition 0.3 Given a system A and a set of states E , a
state x is said to be stable in A w.r.t. E if all trajectories
consistent with A and starting from x go through a state in
E in a finite number of transitions and they visit E infinitely
often afterwards.
We say A = (X; ; f; d) is a stable system if all states in X
are stable in A w.r.t. E .
2

= (X; ; f; d) is alive if all states in X are alive.

Maintainability
Our intuition behind maintainability is that we would like
our system to ‚Äòmaintain‚Äô a formula (or a set of states where
the formula is satisfied) in presence of exogenous actions.
By ‚Äòmaintain‚Äô we mean a weaker requirement than the temporal operator always (2) where 2f means that f should
be true in all the states in the trajectory. The weaker requirement is that our system needs to get to a desired state within
a finite number of transitions provided it is not interfered in
between by exogenous actions. The question then is what
role the exogenous actions play.
Our definition of maintainability has parameters as a set of
initial states S , that the system may be initially in, a set of
desired state E , that we want to maintain, a system A and
a control law K . Our goal is to formulate when the control
law K maintains E assuming that the system is initially in
one of the states in S . We account for the exogenous actions
by defining the notion ‚Äì Closure(S; A) ‚Äì of a closure of
S with respect to A. This closure is the set of states that
the system may get into starting from S . Then we define
maintainability by requiring that the control law be such that
A more appropriate terminology would be AK;e . We use
to remain consistent with the usage in (Ozveren, Willsky, &
Antsaklis 1991).
2
It is also referred to as ‚Äòfeedback law‚Äô, ‚Äòfeedback control‚Äô or
‚Äòstate feedback‚Äô in the literature.

A

1

K

if the system is in any state in the closure and is given a
window of non-interference from exogenous actions then it
gets into a desired state.
Now a question might be that suppose the above condition
of maintainability is satisfied, and while the control law is
leading the system towards a desired state an exogenous action happens and takes the system off that path. What then?
The answer is that the state that the system will reach after
the exogenous action will be a state from the closure. Thus,
if the system is then left alone (without interference from
exogenous actions) it will be again on its way to a desired
state. So in our notion of maintainability, the control is always taking the system towards a desired state, and after any
disturbance from an exogenous action, the control again puts
the system on a path to a desired state.
We now formally define the notions of closure and maintainability.
Definition 0.7 Let A = (X; ; f; d) be a system and S
be a set of states. By Closure(S; A) we refer to the set
2
x2S R(A; x).

S

Definition 0.8 Given a system A = (X; ; f; d), a set of
control actions U  , a specification of exogenous actions e, and a set of states E , we say a set of states S is
k-maintainable with respect to E if there exists a feedback
control K such that from each state x in Closure(S; AK ),
we will get to a state in E with at most k transitions, where
each action (behind the transitions) is dictated by the control
K.
If there exists an integer n such that S is n-maintainable with
respect to E , we say S is maintainable with respect to E .
If S

= X , then we say A is maintainable with respect to E .
2

We now show that while stabilizability guarantees maintainability, the opposite is not true.
Proposition 0.1 Given a system A, if a set of states S is
stabilizable with respect to a set of states E , then S is maintainable with respect to E .
2

Proof : Suppose that a set S  X and S is stabilizable with
respect to E . Then there exists a control law K such that for
each x 2 S , x is alive and is stable with respect E .
Claim: There is a trajectory from each state x in S to a state
in E with a finite transitions.
Case 1. Suppose x 2 S . Then x is stable, therefore we can
get from x to a state in E with a finite number of transitions
dictated by K , say nx transitions.
Case 2. Suppose x 2 Closure(S; A)nS . Then there exists y 2 S such that there is a trajectory T from y which
goes through x. Since y 2 S , y is stabilizable. Thus
all trajectories consistent with A and starting from y go
through a state in E in a finite number of transitions and
they visit E infinitely often afterwards. Therefore any trajectory from y which goes through x will visit E infinitely.
Thus there must be a sub trajectory T 0 from x to a state in
E which is contained in the trajectory T from y to a state
in E through x. Through this trajectory T 0 , we can reach

from x to a state in E in a finite number of transitions dictated by K , say nx . Note that the maximum possible cardinality of Closure(S; A) is the cardinality of X . Thus it
is finite. Let n be maxfnx jx 2 Closure(S; A)g. Since
Closure(S; A) is finite, n exists (n < 1) and from all
states in Closure(S; A) we can reach a state in E within
n transitions dictated by K . Hence S is n-maintainable with
respect to E and thus S is maintainable with respect to E . 2
But the converse of the above proposition is not true. I.e.
Maintainability does not necessarily imply stabilizability.
We now show an example of a system which is maintainable but is not stabilizable.

P

Consider a system A = (X; ; f; d) with the following:
X = fs1 ; s2 ; s3 ; s4 ; s5 g,
= fa1; a2 ; a3 ; a4 ; a5 g fe1 ; e2g;

P

S

d(s1 ) = fa1g, d(s2 ) = fa2; e1 ; e2 g, d(s3 ) = fa3 g,
d(s4 ) = fa4 g, d(s5 ) = fa5 g
f (s1 ; a1 ) = fs2g, f (s2 ; a2 ) = fs4 g, f (s2 ; e1 ) = fs3 g,
f (s2 ; e2) = fs2 g, f (s3 ; a3 ) = fs4 g, f (s4 ; a4 ) = fs5 g,
f (s5 ; a5 ) = fs4g
Given E = fs4 ; s5 g, this system is maintainable, but is not
stabilizable. With the control law K , where K (si ) = ai ,
with at most 3 transitions, we can reach from any state in X
to a state in E , therefore it is maintainable. But if we consider all trajectories, at the state s2 , the exogenous action e2
can keep interfering and we might never reach from the state
s2 to a state in E . Therefore it is not stabilizable. 2
Maintainability in an active database
In this section we show how the notion of ‚Äòmaintainability‚Äô
is useful in defining the correctness of an active database.
Consider an active database with the following aspects:
 Relational Schema:

Employee(Emp#; Name; Salary; Dept#)
Dept(Dept#; Mgr#)
 Goal of the active database: Maintain Integrity constraints. I.e., Maintain the database in states where
(i) If (e; n; s; d) is a tuple in Employee then there
must be a tuple (d0 ; m0 ) in Dept such that d = d0 ;
and
(ii) If (d; m) is a tuple in Dept, then there must be
a tuple (e0 ; n0 ; s0 ; d0 ) in Employee such that d = d0
and m = e0
(In addition we may have other constraints ‚Äì which we
do not focus here ‚Äì such as each department has a single manager and each employee works in a single department.)
 Exogenous actions are of the kind: Delete (E; N; S; D)
from Employee. (The direct effect of this action is the
deletion of the tuple.)

 Triggers are of the kind:

1. For any Delete (e; n; s; d) from Employee, if (d; e) is
a tuple in Dept, delete that tuple from Dept and delete
all tuples of the form (e0 ; n0 ; s0 ; d0 ) from Employee,
where d = d0 .

To formulate the correctness of such an active database, we
can treat the triggers as control laws, as was done initially
in (Ceri & Widom 1990). The overall system operates in a
way that whenever an exogenous action occurs if it modifies
the database such that integrity constraints are violated, the
triggers (control laws) kick in and force additional changes
to the database such that it reaches a state where the integrity
constraints are satisfied. This can be formulated as maintenance of the integrity constraints.
Now, if there were a continuous stream of exogenous actions (whose direct effects were immediately reflected in the
database) then there is no guarantee that the database would
reach a state satisfying the integrity constraints within a finite number of transitions. Hence, we can not formulate this
as stabilizability.
Another important aspect of maintainability is that in reactive software systems like this, if we know that our system is k-maintainable, and each transition takes say at most
t time units, then we can implement a transaction mechanism that will regulate the number of exogenous actions al1 . This will also be useful in
lowed per unit time to be k
t
web-based transaction softwares where exogenous actions
are external interactions and the internal service mechanism
is modeled as control laws. On the other hand, given a requirement that we must allow m requests (exogenous actions) per unit time, we can work backwards to determine
the value of k , and then find a control to make the system
k-maintainable. In general, since in high level controls we
may have the opportunity to limit (say through a transaction
mechanism) the exogenous actions, we think ‚Äòmaintainability‚Äô is an important notion for high level control.

Algorithms
In this section we give two simple algorithms to verify maintainability, and to generate control for maintainability. We
will further analyze them in the full paper.

Testing maintainability

Input: A system A = (X; ; f; d), a set of states E , a set of
states S , and a control K .

Output: To find out if S is maintainable with respect to E ,
using the control K .
Algorithm:
Step 1: Compute Closure(S; AK ).
Step 2: For each
quence

x in Closure(S; AK ) compute the se-

x0 ; x1 ; : : : ; xk ; xk+1 ; : : : ; xjX j , where x0 = x, and xk+1 =
xk if xk 2 E , and xk+1 = f (xk ; K (xk )) otherwise.

Step 3: If for all x, fx0 ; : : : ; xjX j g \ E 6= ; then S is maintainable with respect to E , using the control K ; Otherwise it
is not maintainable with respect to E , using the control K .

Generating control for maintainability of a set of
states
Input: A system A
set of states S .

= (X; ; f; d), a set of states E , and a

Output: Find a control K such that S is maintainable with
respect to E , using the control K .
Algorithm:
Step 0: Sin

:= S , Sout = ;.
Step 1: While Sin 6= Sout Do.
Pick an x from Sin n Sout . Find a shortest path (or a minimal
cost path) from x to a state in E using only control actions.
If no such path exists then EXIT and return(FAIL).
Let a be the first action of that path.
Assign K (x) = a.
Sout := Sout [ fxg
Sin := Sin [ ff (x; a)g [ fx : x 2
e(X )g.
Step 2: If Sin

f (x; b); for some b 2

= Sout , return(Sout; K ).

Proposition 0.2 If the above algorithm terminates by returning S 0 and K , then: (i) S 0 = Closure(S; AK ), and (ii)
S is maintainable with respect to E , using the control K . 2
One important aspect of the above algorithm and its proof
of correctness is the requirement of picking the first action
of a shortest path or a minimal cost path. Picking the first
action of a minimal path (as normally used in the notions of
minimal plans) will not be sufficient as that may lead to cycles and the system may never reach its goal. An algorithm
based on a minimal path will have to be more complicated
so as to avoid this. On the other hand, our use of shortest
path allows us to easily enhance the control when additional
states are added to S . We then only need to consider the new
states in the closure, find shortest paths from each of these
states (say x), and have the first action as the value of K (x).
Thus our algorithm is useful in incrementally broadening the
control when the set of initial states S is broadened.
At this point we would like to point out the relation between
our work here and some research on reactive and situated
agents (Kaelbling & Rosenschein 1991). In (Kaelbling &
Rosenschein 1991), they say that in a control rule ‚Äòif c then
a‚Äô, the action a, must be the action that leads to the goal from
any situation that satisfies the condition c. The above algorithm interprets the notion of ‚Äòleading to‚Äô as the first action
of a minimal cost plan.

Supportability: a notion that generalizes
stabilizability and maintainability
In this section we generalize the notion of maintainability
and show that the notion of stabilizability is a special case

of this generalization. Our generalization is based on the
intuition that perhaps, we can allow a limited number of
exogenous actions during our so called ‚Äòwindow of noninterference‚Äô and still be able to get back to a state in E .
We refer to this general notion as supportability.
Definition 0.9 Given a system A = (X; ; f; d), a set of
agents action U  , a specification of exogenous actions
e, and a set of states E , we say a set of states S is (k,l)supportable (l  k ) with respect to E if there exists a control
law K such that for each state x in Closure(S; AK ), all
trajectories ‚Äì consistent with AK ‚Äì from x whose next k
transitions contain at most l transitions due to exogenous
actions and the rest is dictated by the control K , reach a
state in E by the k -th transition.
2
Proposition 0.3 (k; 0)-supportable is equivalent to k maintainable. (A set of states S is (k; 0)-supportable with
respect to a set of states E if and only if S is k -maintainable
with respect to E .)
Proposition 0.4 A set of states S is stabilizable iff S is
alive and there exists an integer m such that S is (m,m)supportable with respect to E .

An automata and a temporal logic for
‚Äòmaintainability‚Äô and ‚Äòsupportability‚Äô
The notion of a system defined earlier does not distinguish
between exogenous action and control action. They are both
part of . In this section we first define the notion of a 2system where we distinguish between exogenous and control actions. Using the notion of a two system we define the
notion of ‚Äòmaintained‚Äô which is analogous to the notion of
being ‚Äòstable‚Äô and related it to our earlier notion of maintainability. We then use the notion of 2-systems to define
a temporal logic that makes the distinction between transitions due to exogenous action and transitions due to control
actions.
Definition 0.10
A 2-system A is a 5-tuple (X; a ; e ; f; d), where X is a
finite set of states, a is a finite set of control actions, e
is a finite set of control events, d is a function from X to
2a [e listing what actions and events may occur (or are
executable) in what state, and f is a transition function from
X and a [ e to 2X .
2
The notion of a trajectory with respect to a 2-system remains
the same as with respect to a system, which we earlier defined in Definition 0.2.
Definition 0.11 Given a 2-system A and a set of
states E , a state x is said to be k-maintained in A
w.r.t.
E if for all trajectories of the form x =
x0 ; a1 ; x1 ; a2 ; : : : ; aj ; xj ; aj+1 ; : : : that is consistent with A
and for all i such that fai+1 ; : : : ; ai+k g  a , we have that
fxi+1 ; : : : ; xi+k g \ E =
6 ;.
A 2-system A = (X; a ; e ; f; d) is k-maintained with respect to E if all its states are k-maintained.

A 2-system A = (X; a ; e ; f; d) is maintained with respect to E if there exists a positive integer n such that it is
n-maintained with respect to E .
2

Proposition 0.5 A state x is k-maintainable in a system
A = (X; a [ e ; f; d) with respect to E iff there exists
a control law K such that x is k-maintained with respect to
E in the 2-system AK = (X; a ; e ; f; dK ), where dK is
as defined earlier in Definition 0.5.

A temporal language with respect to 2-systems
In the past, temporal logic has been used to specify and verify the behavior of reactive systems (Manna & Pnueli 1992;
Clarke, Emerson, & Sistla 1986; Kabanza, Barbeau, & StDenis 1997). Most of these temporal logics do not (perhaps
with the exception of one description in (Singh 1994)) distinguish between transitions due to control actions and due
to exogenous actions. Hence, they are too strong to be able
to characterize the correctness of reactive software systems
such as an active database system. In this section we propose a temporal language that makes a distinction between
transitions due to control actions and exogenous actions and
is able to characterize correctness of reactive software systems such as an active database system. We plan to elaborate
on this in the full paper.
Some of the important future temporal operators as discussed in (Manna & Pnueli 1992) are: Next (), Always
(2), Eventually (), and Until (U ). There meaning with respect a trajectory  = x0 ; a1 ; x1 ; : : : ; xj ; aj +1 ; xj +1 ; : : : is
defined as follows:

 (; j ) j= p iff p is true in xj .

 (; j ) j= p iff (; j + 1) j= p

 (; j ) j= 2p iff (; k ) j= p, for all k  j .

 (; j ) j= p iff (; k ) j= p, for some k  j .
 (; j ) j= p U q iff there exists k 
and for all i, j  i < k , (; i) j= p.

j such that (; k) j= q

It is easy to see that none of the above temporal operators
consider the action type (whether exogenous or control action) behind the transitions. We now introduce some temporal operators that do consider the action type behind the
transitions.

 (; j ) j= k p iff
fai+1 ; : : : ; ai+k g 
r  k.

i  j is the smallest index such that
a and (; i + r) j= p, for some 1 

 (; j ) j= 2k p iff for all i  j if fai+1 ; : : : ; ai+k g 
then (; i + r) j= p for some 1  r  k .

a

 (; j ) j= k;l p iff i  j is the smallest index such that
jfai+1 ; : : : ; ai+k g \ e j  l and (; i + r) j= p for some
1  r  k.
 (; j ) j= 2k;l p iff for all i  j if
jfai+1 ; : : : ; ai+k g \ e j  l then (; i + r) j=
1  r  k.

p for some

We can describe the intuitive meaning behind the above
formal definitions as follows: Intuitively, (; j ) j= 2k p
means that starting from xj , within or after any k consecutive transitions due to control actions p holds. Similarly,
(; j ) j= 2k;l p means that starting from xj , within or after
any k transitions with at most l exogenous actions p holds.

Proposition 0.6 (i) (; j ) j= 2k p iff (; j ) j= 2k;0 p.
(ii) (; j ) j= k p iff (; j ) j= k;0 p.

(iii) Let Ep be the set of states, where a formula p holds. S
is (k; l)-supportable w.r.t. Ep iff for all trajectories  whose
x0 2 S , and for all j , (; j ) j= 2k;l p.
2

Corollary 0.7 1. Let Ep be the set of states, where a formula p holds. S is k maintainable w.r.t. Ep iff for all trajectories  whose x0 2 S , and for all j , (; j ) j= 2k p.
2. Let Ep be the set of states, where a formula p holds. S
is stabilizable w.r.t. Ep iff S is alive and there exists an m
such that for all trajectories  whose x0 2 S , and for all j ,
(; j ) j= 2m;m p.

Conclusion and related work
In this paper we formalized the notion of ‚Äòmaintenance‚Äô often mentioned (Baral & Son 1998) in the context of robots
and agents, as a property of a discrete event dynamic system (DEDS) and compared it with the notion of ‚Äòstability‚Äô
and ‚Äòstabilizability‚Äô that are most popular in DEDS. We argued why ‚Äòmaintainability‚Äô may be a more preferred notion
for certain systems and discussed active database systems
as an example. We then gave simple algorithms for testing
maintainability and generating control for maintainability.
We then developed the notion of ‚Äòsupportability‚Äô that generalizes both ‚Äòmaintainability‚Äô and ‚Äòstabilizability. Finally, we
developed an automata theory that distinguishes between exogenous and control actions, and developed a temporal logic
based on it. Our basic formulation of ‚Äòmaintainability‚Äô is related to the work in (Baral & Son 1998).
Among the other related works, there has been some work
on defining stability of continuous systems in the presence
of discontinuities and disturbances; for example (Sontag
1999). In the planning literature there has been some work
on planning for temporal goals (Bacchus & Kabanza 1998;
Weld & Etzioni 1994) where goals are expressed as temporal formulas. But they use the traditional temporal operators which by themselves can not express our notion of
‚Äòmaintenance‚Äô. Another related notion is planning from the
current situation in a dynamic domain (Baral, Gelfond, &
Provetti 1997) and execution monitoring (DeGiacomo, Reiter, & Soutchanski 1998). In both these notions ‚Äòmaintenance‚Äô is achieved by monitoring (or observing) the world
for discrepancies and making new plans to recover. Finally, the notion of ‚Äòself-stabilization‚Äô (Dijkstra 1974) in distributed and fault-tolerant computing seems to be similar to
our notion of ‚Äòmaintenance‚Äô and we plan to compare and
contrast them in the sequel.

References
Bacchus, F., and Kabanza, F. 1998. Planning for temporally extended goals. Annals of Math and AI 22:5‚Äì27.
Baral, C., and Son, T. 1998. Relating theories of actions
and reactive control. Electronic transactions on Artificial
Intelligence 2(3-4).

Baral, C.; Gelfond, M.; and Provetti, A. 1997. Representing Actions: Laws, Observations and Hypothesis. Journal
of Logic Programming 31(1-3):201‚Äì243.
Brooks, R. 1986. A robust layered control system for a
mobile robot. IEEE journal of robotics and automation
14‚Äì23.
Ceri, S., and Widom, J. 1990. Deriving production rules
for constraint maintainance. In VLDB 90. 566‚Äì577.
Clarke, E.; Emerson, E.; and Sistla, A. 1986. Automatic
verification of finite-state concurrent systems using temporal logic specifications. ACM Transactions on Programming Languages and Systems 8(2):244‚Äì263.
DeGiacomo, G.; Reiter, R.; and Soutchanski, M. 1998. Execution monitoring of high-level robot programs. In Proc.
of KR 98, 453‚Äì464.
Dijkstra, E. W. 1974. Self-stabilizing systems in spite of
distributed control. CACM 17(11):843‚Äì644.
Kabanza, F.; Barbeau, M.; and St-Denis, R. 1997. Planning control rules for reactive agents. Artificial Intelligence
5(1):67‚Äì113.
Kaelbling, L., and Rosenschein, S. 1991. Action and planning in embedded agents. In Maes, P., ed., Designing Autonomous Agents. MIT Press. 35‚Äì48.
Maes, P., ed. 1991. Designing Autonomous Agents.
MIT/Elsevier.
Manna, Z., and Pnueli, A. 1992. The temporal logic of
reactive and concurrent systems: specification. Springer
Verlag.
Ozveren, O.; Willsky, A.; and Antsaklis, P. 1991. Stability and stabilizability of discrete event dynamic systems.
JACM 38(3):730‚Äì752.
Passino, K., and Burgess, K. 1998. Stability Analysis of
Discrete Event Systems. Adaptive and Learning Systems
for Signal Processing, Communications, and Control. New
York: John Wiley and Sons, Inc.
Ramadge, P., and Wonham, W. 1987a. Modular feedback
logic for discrete event systems. SIAM Journal of Control
and Optimization 25(5):1202‚Äì1217.
Ramadge, P., and Wonham, W. 1987b. Supervisory control of a class of discrete event process. SIAM Journal of
Control and Optimization 25(1):206‚Äì230.
Singh, M. 1994. Multiagent systems - a theoretical
framework for intentions, know-how, and communications.
Springer-Verlag.
Sontag, E. 1999. Stability and stabilization: Discontinuities and the effect of disturbances. In Clarke, F., and Stern,
R., eds., Proc. NATO advanced study institute, July/Aug
1998. Kluwer. 551‚Äì598.
Weld, D., and Etzioni, O. 1994. The first law of robotics (a
call to arms). In AAAI, 1042‚Äì1047.
Widom, J., and Ceri, S., eds. 1996. Active Database Systems - Triggers and Rules for advanced database processing. Morgan Kaufmann.

ON HARDWARE SUPPORT FOR INTERVAL COMPUTATIONS AND FOR SOFT COMPUTING: THEOREMS
Hung T. Nguyen, Vladik Kreinovich, Member, IEEE, Vyacheslav Nesterov, and Mutsumi Nakamura

Abstract. This paper provides a rationale for providing hardware supported functions of
more than two variables for processing incomplete knowledge and fuzzy knowledge. The result is in contrast to Kolmogorov's theorem in numerical (non-fuzzy) case.

1. INTRODUCTION
In this paper, we show that for interval computations and for processing fuzzy data (i.e., for soft computing), it is desirable to have hardware supported operations with more than two operands. Before we formulate the problem and go into technical details, we would like to emphasize the importance of this problem by brie y describing in Subsection 1.1 the practical origin (and practical necessity) of interval computations and soft computing.

1.1. Estimating accuracy of the results of data processing: crisp and fuzzy cases
values of the physical quantities. For example, in order to decide whether to approve the scheduled launch of a Space Shuttle, we must know the characteristics of the Shuttle (to make sure that all its systems work), and weather conditions around the launch site during the launch time. Some of these characteristics can be measured directly: e.g., characteristics of the Shuttle's electric systems can be measured by testers. Some of the desired characteristics can be estimated by experts: e.g., some experts meteorologists can provide us with reasonably good short-time weather predictions for a given area. Hung T. Nguyen is with the Department of Mathematical Sciences, New Mexico State University, Las Cruces, NM 88003, USA, email hunguyen@nmsu.edu Vladik Kreinovich is with the Department of Computer Science Department, University of Texas at El Paso, El Paso, TX 79968, USA, email vladik@cs.utep.edu Vyacheslav Nesterov is with the Institute of New Technologies, P. O. Box 52, St. Petersburg 256, 195256 Russia, email nest@into.nit.spb.su Mutsumi Nakamura is with the Department of Mathematics, University of Texas at Austin, Austin, TX 78712, USA, email mutsumin@math.utexas.edu 1

Data processing: why? To make decisions, we must have some information about the

In some cases, however, it is very di cult (or even impossible) to measure the characteristic y that we are interested in, and there are no experts who can predict the values of these characteristics. For example, it is very di cult to directly measure the temperature inside the jet chamber (because this temperature is extremely high); if we are planning a mission to a new planet, it is simply impossible to directly measure the characteristics of the new environment before the mission actually gets there, and often, no expert can help. If we are interested in the value of such a characteristic y, and we cannot estimate y directly (either by measurement, or by using experts), then a natural idea is to estimate y indirectly, i.e.: to estimate some other (easier to estimate) quantities x1 ; :::; xn that are related to y, and then to compute the estimate y ~ for y based on the estimates x ~1 ; ::; x ~n for x1 ; :::; xn. This process is called data processing, and this is what super-computers are doing most of the time: from measured characteristics x ~i of observed collisions in the accelerators, they reconstruct the (directly unobservable) properties of the elementary particles; from the results x ~i of geophysical measurements, computers predict the amount y of oil (or other mineral) in a given area, etc. In this paper, we will assume that we already know what characteristics xi to measure, and how to reconstruct y from xi . In other words, we will assume that we know an algorithm f (x1; :::; xn) that transforms the values of xi into an estimate for y. This algorithm is not necessarily simple: e.g., in geophysics, it may involve solving a complicated non-linear integral equation (\inverse problem"); in elementary particle physics, it may involve solving a system of non-linear operator quantum equations, etc. we know the algorithm f means that if we know the exact values of the variables x1 ; :::; xn, we can then apply the algorithm f and compute the exact value of y. In reality, however, we only know some estimates x ~i for xi that are obtained either by measurements or by an expert estimation. Measurements are never 100% precise; expert estimates are not absolutely precise either. As a result, the available values x ~i di er from the actual (unknown) values xi ; therefore, the estimate y ~ = f (~ x1; :::; x ~n) that we obtain by processing the available data may di er from the desired value y = f (x1; :::; xn).

The result of data processing is never absolutely accurate. The assumption that

In real-life applications, we must know the accuracy of the result of data processing. For practical purposes, it is important to know how di erent the result y ~ of data
processing can be from the actual value y. 2

For example, if we want to decide whether a particular well is worth drilling, and the estimate for the amount of oil is y ~ = 100 mln. tons, then before we start drilling, we would like to know whether this is, say, 100 1, in which case, we should probably start drilling, or it is 100 100 (maybe 100, maybe 0, maybe 200), in which case we would rather undertake further (and more accurate) measurements. In this paper, we consider the problem of nding this accuracy. both measurement results and expert estimates are present, let us consider the simplest case, where there is no expert knowledge, and all the data come from the measurements. In traditional measurement theory (see, e.g., 8,47,35]), it is usually assumed that we know the probabilities of di erent values of a measurement error. These values can be obtained if we calibrate the measuring instrument, i.e.: we use the calibrated instrument in conjunction with a much more accurate one (called a standard) in several measurements; for each measurement, we compute a di erence e(k) = x ~(k) ? x(k) between the results of these two instruments, and use this di erence as an estimate of the error of the measurement performed by the calibrated instrument; reconstruct the error probability distribution from the recorded sample errors e(1) , ..., e(N ) . For the situations in which we know the probabilities of di erent errors, there exist numerous methods that compute statistical characteristics of the resulting error. In many real-life situations, however, the values of the probabilities are not known: in advanced measurements (in radio-astronomy, in elementary particle physics, etc), we are using measuring instruments that have the highest accuracy possible, so, there is simply no \more accurate" measuring instrument that we can for calibrating; in manufacturing applications, we can potentially calibrate all the sensors that we use, but this calibration would cost much more than the sensors themselves, so it is usually not done. In these situations, the manufacturer of the measuring instrument provides us with the guaranteed accuracy , i.e., with a guaranteed upper bound of the error x = x ~ ? x (e.g., \error cannot exceed 0.1"). If our measurement results is x ~, then the possible values of x=x ~ ? x form an interval x ~? ;x ~ + ]. Since we are dealing with intervals, the entire area is called interval computations (see, e.g., 29,11,10,18,14]). 3

Simplest case: measurements only. Before we start analyzing the general case, where

The set of possible values of an error is not necessarily an interval. For example, suppose that we are measuring the current inside the computer, and we know that the error cannot exceed a certain value . If we know nothing else about the error, then we may conclude that the error belongs to the interval ? ; ]. However, we may know that the error is caused by the in uence of a nearby magnetic memory element, which can be in two possible states (corresponding to \0" and \1"). In this case, the error is either positive, or negative (depending on the state), but never 0; actually, the error can never be smaller than some value . In this case, the set X of possible values of the error is not an interval, but a union of two intervals: X = ? ; ? ] ; ]. There can be more complicated cases, in which the error can be described by more complicated (crisp) sets X of possible values. In this case, our problem takes the following form:
We know: an algorithm f that transform n real numbers x1; :::; xn into a real number y = f (x1; :::; xn); sets X1 R, ..., Xn R that contain the actual values of xi ; We must compute: The set Y of possible values of y:

Y = ff (x1; :::; xn) j x1 2 X1; :::; xn 2 Xng
This set Y is usually denoted by f (X1; :::; Xn).

(1:1)

A measuring instrument can measure several di erent quantities x1; :::; xn at a time. In this case, in addition to the information about the possible errors of each measurement, the manufacturer can guarantee that certain combinations of errors are impossible: e.g., it can happen that x1 attains its largest possible value , and it can happen that x2 attains its largest possible value , but they can never attain these extreme values at the 2 (this situation happens, e.g., same time, because of the restriction that x2 1 + x2 2 if we measure geographical coordinates of a point). Such an information can be described by a set X Rn of all the tuples that the manufacturer believes can be possible values of errors ( x1; :::; xn). In this case, the problem takes the following form:

4

We know: an algorithm f that transform n real numbers x1; :::; xn into a real number y = f (x1; :::; xn); a set X Rn that contains the actual value of ~ x = (x1; ::; xn); We must compute: The set Y of possible values of y:

Y = ff (x1; :::; xn) j (x1; :::; xn) 2 X g
This set Y is usually denoted by f (X ).

(1:2)

The previous formulation is a particular case of this one if we take X = X1 ::: Xn. General case: processing data that includes expert knowledge as well. In many cases, in addition to measurements results, we have expert's knowledge about the variables x1 ; :::; xn. For example, in order to make a decision on what doze of radiation to assign to a patient, we must know not only the characteristics that are measurable (like blood count, tumor size, etc), but the characteristics that can only be estimated by an expert (e.g., the granularity of a tumor can be \small" or \medium"). We want to process this informal information automatically, therefore, we must be able to represent it in the computer. A word like \medium-size" does not describe one particular value; it can correspond to several di erent values; some of them are more reasonably described as \medium-size", some values can be in principle described as such, but only occasionally. To describe the meaning of each word, we ascribe to every real number x a value (x) 2 0; 1] that describe to what extent it is reasonable to assume that x is, say, medium-size (1 means that it is absolutely reasonable, 0 that it is not reasonable at all). The resulting function is called a membership function, or a fuzzy set. In some cases, the expert's informal statement describes not one variable, but several of them. For example, if we say that a point with coordinates x1 ; x2 is close to 0, this means that both x1 and x2 are close to 0. Such knowledge can be represented by a function from R2 to 0,1]. This membership function is called a fuzzy subset of R2. If we have such information about xi , and we want to estimate y, we get the following problem: We know: a function f of n variables; a fuzzy set X Rn that describes our knowledge about ~ x = (x1 ; :::; xn). We want: to describe the resulting knowledge about y in terms of a fuzzy set Y . This problem was formulated, e.g., in 1,46,39], and it has appeared in many practical cases, including: 5

testing jet engines 22,20,21]; seismic analysis 3,4]; image processing 19,20,21], etc.

The desired description of the set Y is known as extension principle. This principle was proposed by Zadeh in his pioneer paper 53] (see also 54] and 5]), and it is based on the following idea: A real number y ~ is a reasonable value of y if and only if there exist values x ~1; :::x ~n for which x ~1 is a possible values of x1 , x ~2 is a possible value of x2 , ..., and f (~ x1; :::; x ~n) = y ~. If we follow the traditional fuzzy set theory and interpret \and" as min, and \there exists" as sup, then we arrive at the following formula:

x); f (~ x; y)); Y (y ) = supn (min( X (~ ~ x2R
where f is a characteristic function of the graph of the function f (i.e., (~ x; y) = 1 if f (~ x) = y, and 0 otherwise). Due to this formula, values ~ x for which f (~ x) 6= y, do not in uence on Y (y). Therefore, this formula can be rewritten as follows:

x): Y (y ) = sup X (~ ~ x:f (~ x)=y

(1:3)

This formula is called the extension principle, and the resulting fuzzy set Y is denoted by f (X ). If instead of X , we have n separate fuzzy sets X1 ; :::; Xn that describe our knowledge about x1 ; :::; xn, then similar arguments lead to a formula
Y (y ) = sup min( X1 (x1 ); :::; Xn (xn )): ~ x:f (~ x)=y

(1:4)

The resulting fuzzy set Y is denoted by f (X1; :::; Xn).
Comments. 1. In particular, if we take elementary arithmetic operations (+; ; ?, etc) as f , we get the de nition of arithmetic operations with fuzzy operands X1; :::; Xn.

2. The statement that we have just formalized contains two logical terms: \and" and \there exists". So, to formalize it, we must formalize what these two logical terms mean. 6

\There exists" can be viewed as an in nite \or": namely, \there exist x ~1 ; :::; x ~n with a certain property" means that this property is either true for, say, (0:0; :::; 0:0), or for (1:1; 0:2; :::; 2:3), or for any of in nitely many tuples of n real numbers. Therefore, to get an interpretation of \there exists", we must choose an appropriate fuzzy interpretation f_(a; b) of _ and apply the resulting _?operation f_ in nitely many times (i.e., apply it to N tuples and then take N ! 1). In fuzzy logic, many di erent _?operations have been proposed (e.g., f_(a; b) = a + b ? a b); these operations are also called t?conorms. A usual (and natural) restriction on a t?conorm f_ comes from the fact that for every two statement A and B , our degree of belief in A _ B must be at least as big as the degree of belief in each of these statements A and B . If we denote the degree of belief in A by t(A), then this condition turns into f_(t(A); t(B )) t(A) and f_ (t(A); t(B )) t(B ). In other words, for every a and b, f_(a; b) max(a; b). If we choose one of the known t?conorms for which f_(a; b) > max(a; b) (e.g., if we choose f_ (a; b) = a + b ? ab), then, the more times we apply f_ , the larger the resulting degree of belief, and in the limit, we get 1. For example, for f_ (a; b) = a + b ? ab = 1 ? (1 ? a) (1 ? b), disjunction of N formulas with the same degree of belief a 2 (0; 1) leads to f_(a; : : :; a) = 1 ? (1 ? a)N , and this expression ! 1 as N ! 1. (Here, f_(a; b; :::; c) stands for f_(:::(f_(a; b); :::); c), i.e., it means that we apply the _?operation N times.) A similar result can be proven for any (strict or non-strict) Archimedean t?conorm (see, e.g., 16,34]). Hence, for such operations, we will have Y (y) = 1 for all y, which makes no sense. Therefore, when we de ne operations with fuzzy operands, the only meaningful interpretation of \there exists" is through the _?operation f_ (a; b) = max(a; b), for which for every property A(x), the degree of belief in \there exists x such that A(x)" is equal to the \maximum" (or, to use the precise mathematical term, supremum) of all the degrees of belief t(A(x)) for all x. As far as an &?operation is concerned, we can use an arbitrary function f& : 0; 1] 0; 1] ! 0; 1] that extends a usual & operation de ned for binary values (with 0 as false as 1 as true), i.e., an arbitrary function f& for which f& (0; 0) = f& (0; 1) = f& (1; 0) = 0 and f& (1; 1) = 1. For such interpretation of \and" and \there exists", formula (2) takes the following form: (1:4a) Y (y ) = sup f& ( X1 (x1 ); :::; X (xn ));
~ x:f (~ x)=y
n

7

where f& (a; b; :::; c) stands for f& (:::(f&(a; b); :::); c) (i.e., it means that we apply the &?operation several times). Our results will be true for an arbitrary choice of an &?operation.

1.2. How is the problem of estimating accuracy of the results of data processing solved now? In general, the problem is computationally intractable even for crisp sets (even for intervals). It has been proven that even for the case when the sets Xi are crisp (and
are intervals), and the algorithm f is actually a polynomial, the problem of computing the set Y exactly is computationally intractable (NP-hard) 9]. This result does not mean, of course, that the problem of computing Y is not practically solvable. The sets Xi describe the inaccuracy of the measuring devices, or the inaccuracy of an expert. These inaccuracies are never known precisely, therefore, it would be quite su cient to have an approximate description of Y . Several methods are known for that:

Case when estimates are pretty accurate: linearization technique. If the esti-

In this case, for interval Xi = x ~i ? i ; x ~i + i ], we have Y Xlin = flin (X1; :::; Xn) = y ~? ;y ~ + ], where = jf;1j 1 + ::: + jf;nj n (see, e.g., 35]).

mates x ~i for xi are pretty accurate, then we can neglect the terms that are quadratic (or of higher order) in xi = x ~i ? xi , and thus, for given estimates x ~i , describe y = f (x1; :::; xn) = f (~ x1 ? x1 ; :::; x ~n ? xn ) by the following approximate formula: y flin = y ~ ? f;1 x1 ? ::: ? f;n xn ; where by f;i , we denoted the partial derivative of f w.r.t. xi : @f (~ x1; :::; x ~n): f;i = @x
i

Another case when we can estimate Y is when the function f is monotonic in each + of the variables; in this case, if, e.g., f is monotonically increasing, and Xi = x? i ; xi ], we + ? + have Y = f (x? 1 ; :::; xn ); f (x1 ; :::; xn )]. For these two cases (small errors or monotonic f ), there also exist e cient techniques for fuzzy data processing 4,51].

Expert estimates are rarely very accurate, so, other methods are needed. Mea8

surements typically lead to accurate estimates of xi , so, if all the estimates come from

measurements, we can usually apply linearization techniques. Expert estimates, on the other hand, are rarely very accurate. So, if we have expert estimates, we usually cannot neglect the squares of the errors, and therefore, we need other methods for estimating the error of the result of data processing. For this case, the following idea has been proposed by R. Moore 27,28] (see also 29,11,10,14]). No matter what high-level language we use to describe an algorithm f , inside a computer, this algorithm is translated into a sequence of elementary operations (usually, +, ?, , :, etc). For example, a function f (x1; x2; x3) = (x1 + x2 )2 + 2 x3 is computed as follows (we will enumerate all the input and intermediate values by r1 ; r2, ...): rst, we have r1 = x1, r2 = x2 , and r3 = x3 ; then, we start computing further values: we apply + and get r4 = r1 + r2 = x1 + x2 ; 2 (so, r5 = (x1 + x2 )2 ). we apply the square operation and get r5 = r4 we take r6 = 2; we compute r7 = r6 r3 ; nally, we compute r8 = r5 + r7 ; this is the desired value y. The idea is to repeat the same sequence of operations, but with intervals instead of numbers. Elementary operations g are usually monotonic, so, we can explicitly compute g(X1; :::; Xn) + ? + for intervals Xi : e.g., for addition g(x1; x2) = x1 + x2 , we have g( x? 1 ; x1 ]; x2 ; x2 ]) = ? + + x? 1 + x2 ; x1 + x2 ]. For example, if we start with the intervals R1 = X1 = 0; 1], R2 = X2 = 0; 1], and R3 = X3 = 1; 2], we get the following sequence of computations: we apply + and get R4 = R1 + R2 = 0; 1] + 0; 1] = 0; 2]; 2 = 0; 4]; we apply the square operation and get R5 = R4 take R6 = 2; 2]; compute R7 = R6 R3 = 2; 2] 1; 2] = 2; 4]; ~ = R8 = R5 + R7 = 0; 4] + 2; 4] = 2; 8]; this is the desired nally, we compute Y estimate for Y . ~ contains the desired It has been proven that for intervals Xi , the resulting estimate Y interval Y . A similar procedure can be used for fuzzy processing: here, we implement elementary operations g using extension principle. computations do not always lead to the exact value of Y ; even for intervals Xi , the result 9

These new methods do not always lead to accurate results. The results of these

depends on the exact order of the operations performed to compute f . For example, we can compute f (x1; x2) = x1 x2 by simply multiplying the two numbers, or we can compute the same product by using a more complicated formula x1 x2 = (1=4) (x1 + x2 )2 ? (x1 ? x2 )2 ]. ~ = 1; 4] that coincides If X1 = X2 = 1; 2], then the rst algorithm leads to the estimate Y with the desired interval Y = f (X1; X2). However, the second algorithm leads to a di erent result: indeed, this algorithm can be represented as a following sequence of computations: r3 := r1 + r2. 2. r4 := r3 r5 := r1 ? r2. 2. r6 := r5 r7 := r4 ? r6. r8 := 4. r9 := r7 =r8. So, for Xi = 1; 2], we get R3 = 2; 4], R4 = 4; 16], R5 = ?1; 1], R6 = 0; 1], R7 = 3; 16], ~ = R9 = 0:75; 4] 6= Y = 1; 4]. The resulting interval Y ~ contains extra R7 = 4; 4], and Y points 0:75; 1).

bers, data processing algorithm that computes f (x1; :::; xn) can be quite complicated and time-consuming. When we analyze accuracy of data processing, we must go from operations with numbers to operations with intervals, crisp sets, or fuzzy sets. For example, when we go from precise numbers to fuzzy sets, then instead of processing n numbers according to the known algorithm f , we have to solve complicated optimization problems to nd Y (y). This increases computation time drastically: for example, in a crisp case, to compute a sum of two numbers x1 + x2 , we must process these two numbers xi only; all it takes is one arithmetic operation. To compute a sum of two fuzzy operands, instead of processing two numbers, we must take as input the values X1 (x1 ) and X2 (x2 ) that correspond to di erent xi . Just because of the necessity to process such a long input, these computations are inevitably long. How to speed up fuzzy computations? One known way to speed up computations in general is to design a hardware support for them. This idea worked perfectly well, e.g., for oating point operations that had initially been implemented in software. So, it is desirable to design hardware support for interval and fuzzy computations as well. 10

1.3. Going from numbers to intervals and fuzzy sets drastically increases computation time, so hardware support is in order Hardware support is necessary. We have already mentioned that even for real num-

bring a speed-up, and is, therefore, a great idea. However, the very fact that we have a hardware support of several basic operations with intervals, crisp sets, and/or with fuzzy sets, does not necessarily mean that we have improved the quality of the result (we are thankful to the anonymous referee who helped us clarify this point). As we have shown in Subsection 1.2, if we start with an expression (1=4) (x1 + x2)2 ? (x1 ? x2)2 ] and simply substitute interval operations instead of operations with numbers, we will get an overestimation irrespective on whether we implement these operations in software or in hardware. The only way to get the exact estimate is to transform this expression into an equivalent one x1 x2 for which interval computations give the exact estimate. An even more striking example is a function of one variable de ned as f (x1) = x1 ? x1 . This function is, of course, identically equal to 0, so, for every interval X1, we should get f (X1) = f0g. However, if we take X1 = 0; 1], and apply interval subtraction, we will get X1 ? X1 = 0; 1] ? 0; 1] = ?1; 1]. Whether we are implementing interval subtractions in hardware or in software, we get an overestimation. Again, the only way to get the exact estimate is take into the consideration that the two terms in the original expression cancel each other, and thus, to transform the original expression x1 ? x1 into an equivalent one 0. So, in addition to hardware, we need some appropriate symbolic reasoning engine (of the type implemented in Macsyma or in Mathematica) that would transform the original expression into an equivalent one that will lead to the precise (or at least to a more accurate) estimate.
At present, designing such an engine is a more urgent and more potentially rewarding task than working on hardware. Currently, computers only allow unary and binary operations. So, what this engine will do is, given a function, transform it into a sequence of unary and binary operations. The perfect engine will output a transformation that leads to the best possible estimate (e.g., to the interval with the smallest possible overestimation). However, this \the best" does not necessarily mean that we will have no overestimation at all: As we will see later, for some functions of three and more variables, no matter how we transform these functions into a sequence of unary and binary operations, interval computations will always lead to an overestimation. This overestimation result is true not only for the existing computers, where only elementary arithmetic operations are hardware supported; this result (as we will show) is true for any computer that hardware supports

A word of warning: Hardware support is not su cient. Hardware support does

11

only unary and binary operations. So, for such functions, the only way to avoid overestimation is to implement operations with three or more interval (corr., fuzzy) operands in hardware. For the resulting new computer, the computation scheme will include not only standard unary and binary operations, but some new operations (with interval or fuzzy operands) as well. Again, the very fact that we have added these new operations does not automatically mean that we will achieve the exact estimate: before we apply interval computations, we must transform the original computation scheme (that may be overestimating) into a new (equivalent) scheme with no overestimation. So, we will again need an appropriate symbolic reasoning engine for the new computer. Summarizing, we can say that achieving precise interval and fuzzy computations is a threestep task: First, we must design a symbolic reasoning engine based on the existing hardware supported operations (namely, elementary arithmetic operations). This engine must transform the original expression (in terms of these elementary operations) for which interval and fuzzy computations overestimate into an equivalent expression that leads to more precise result Y . Second, we must select operations with three or more interval or fuzzy operands that need to be hardware supported in order to get precise results. Third, for these new operations included, we must design a new symbolic reasoning engine that will transform every algorithm into a sequence of elementary operations (arithmetic or new ones) for which interval (fuzzy) computations will lead to the precise result. The rst task { the design of the original engine is, in e ect, being currently done in interval computations community (see, e.g., 10] and 14]). In the present paper, we consider the second task: the choice of the hardware operations to be hardware supported. We give only a partial answer to this task. As soon as this problem will be solved, the need will come for the third task: designing a new symbolic reasoning engine for the new computer.

Hardware support of interval and fuzzy operations: a little bit of history. The

existing hardware support of interval operations is described in 23,36,37], and references therein. Usually, the supported operations are arithmetic operations, and the scalar (dot) product a1 b1 + ::: + an bn . The rst hardware implementation of operations with fuzzy sets has been developed by Yamakawa. For the current state of research, see, e.g., 49,50]; for applications, see, 12

e.g., 43] and 52]. This rst implementation included several chips. The rst single-chip hardware implementation of fuzzy operations have been proposed in 45] (for more recent results, see, e.g., 44] and 48]). Parallel hardware implementation has been proposed and described in 2]; see also 38] and 42]. These implementations, however, are mainly oriented towards fuzzy control problems (and not fuzzy data processing). is impossible to implement in hardware fuzzy operations that correspond to all possible functions f (x1; :::; xn). So, it is necessary to choose.

What interval and fuzzy operations should we support for data processing? It
The natural idea is to describe all functions f that are hardware supported on the existing computers, and to support the corresponding operations with fuzzy sets. Since usually, only unary and binary operations are hardware supported, we will thus have hardware implementation only of operations of one and two operands.

What we are planning to do. In this paper, we show that for intervals and for fuzzy sets,

an implementation of only unary and binary operations is not su cient in the following sense: for some functions f and for some intervals (fuzzy sets) Xi , no matter how we represent the function f as a composition of unary and binary operations, if we then ~ will be di erent from the apply the above-described methodology, the resulting estimate Y desired value Y = f (X1; :::; Xn). Therefore, if we want fuzzy data processing to be precise, operations with three or more fuzzy operands should also be implemented in hardware. Some crisp operations with three or more crisp operands are already hardware supported: e.g., many computers contain a math co-processor that, among other things, hardware supports matrix operations, i.e., operations whose operands include an entire matrix (i.e., lots of numerical operands). For example, it is possible, given two arrays a1 ; :::; an and b1; :::; bn, to compute their dot (scalar) product a1 b1 + a2 b2 + ::: + an bn by using a single operation of a math co-processor. For crisp numbers, the main purpose of using such operations is to speed up computations: in principle, we can use operations with two operands (in this case, addition and multiplication) and compute the same expression in several steps. We are planning to show that in interval and fuzzy case, if we restrict ourselves to unary and binary operations only, then not only computations will slow down, but for some functions f , and for some intervals (fuzzy sets) Xi , we will not get the desired value f (X1; :::; Xn) at all. 13

1.4. Structure of the paper
In Section 2, we will give some general de nitions. In Section 3, we will consider the simplest case when inputs are intervals, and when all operations that are hardware supported are smooth (di erentiable) functions. For this case, we will prove that operations with one or two variables are not su cient. The fact that functions are di erentiable makes it possible not only to prove the negative results but also to describe the smallest possible order of the error that can be caused by such computations (linear, quadratic, etc). We also give a list of operations that need to be hardware supported so that we will be able to compute Y with a better accuracy: this list consists of arithmetic operations and a weighted scalar product. In Section 4, these results will be generalized from crisp intervals to fuzzy sets. In Section 5 and 6, we show that even if we allow operations that are not di erentiable, still operations with one or two operands will not be su cient. In Section 7, we discuss the relation between these results and Kolmogorov's theorem (well known in mathematics) that every continuous function of three or more real variables can be represented as a composition of real-valued functions of one and two variables. For reader's convenience, all the proofs are placed in Section 8.

14

2. GENERAL DEFINITIONS
In this Section, we give general de nitions that will be used in the following text.

2.1. Computation scheme
In this subsection, we will formalize the description of a general computation process (presented in Subsection 1.2) into a formal de nition, and show (on an example) how this formalization is related to the original description.

De nition 2.1. By a computation scheme S with n initial values, and with operations
with one or two operands (or, for short, simply a computation scheme), we mean a nite sequence (Sn+1; Sn+2 ; :::; SN ) of expressions Si (called steps). Each step Si is an expression of one of the following three types: ri := ci , where ci is a real number; ri := fi (rj ), where fi is a function of one variable (not necessarily everywhere de ned), and j < i; ri := fi (rj ; rk ), where fi is a function of two variables (not necessarily everywhere de ned), j < i, and k < i. If S is a computation scheme with n initial values, and x1; :::; xn are n real numbers, we say that the result of applying S to xi is y, if rN = y, where the sequence ri is de ned as follows: if i n, then ri = xi : if i > n, then depending on the type of the rule Si , we de ne ri as follows: if the rule if ri := ci , then ri = ci ; if the rule is ri := fi (rj ), then ri = fi (rj ); if the rule is ri := fi (rj ; rk ), then ri = fi (rj ; rk ).

certain value of ri . This value will be denoted by ri (x1; :::; xn).

Denotation. For some x1; :::; xn, and for each i N , this De nition provides us with a

Comment. We have already mentioned that inside a computer, every algorithm is translated into a sequence of elementary operations. Since in the majority of computers, all elementary operations correspond to functions of one or two variables, an arbitrary algorithm computing y = f (x1; :::; xn) can be thus represented as a computation scheme. For example, how in the above-given representation of the function f (x1; x2; x3) = (x1 + x2 )2 +2 x3, we have:

15

r4 = r1 + r2 (here, f4 = +, j = 1, k = 2); 2 (here, f5 (x) = x2 , j = 4); r 5 = r4 r6 = 2 (here, we have a function of 0 variables, that computes a constant 2); r 7 = r6 r3 ; r 8 = r5 + r7 .

De nition 2.2. Let K Rn, and let f be a function from K to R. We say that a computation scheme S computes f if for every (x1; :::; xn) 2 K , the value that S computes
(is de ned and) is equal to f (x1; :::; xn).

2.2. Applying computation scheme to crisp sets (in particular, to intervals)
In this subsection, we will describe how a computation scheme can be applied to crisp sets; in particular, we will describe how it can be applied to intervals.

Xn R be (crisp) sets. Then, the result f (X1; :::; Xn) of applying f to the sets X1 ; :::; Xn is de ned by the formula (1.1). If instead of the sets Xi, we have a (crisp) set X Rn, then the result f (X ) of applying f to X is de ned by the formula (1.2).

De nition 2.3. Let f (x1; :::; xn) be a function of n real variables, and let X1 R, ...,

X1; :::; Xn is Y if RN = Y , where the sequence of (crisp) sets R1; :::; RN is de ned as
follows: if i n, then Ri = Xi ; if i > n, then, depending of the type of the rule Si , Ri is de ned as follows: if Si is ri := ci , then Ri = fci g; if the rule is ri := fi (rj ), then Ri = fi (Rj ); if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).

De nition 2.4. Assume that S is a computation scheme with n input values, and that Xq R, ..., Xn R are (crisp) subsets of R. We say that the result of applying S to

16

De nition 2.5. Assume that S is a computation scheme with n input values, and that X is a (crisp) subset of Rn. We say that the result of applying S to X is Y if RN = Y ,

where the sequence of (crisp) sets R1 ; :::; RN is de ned as follows: if i n, then Ri = i (X ), where i is a projection on i?th component (i.e., i (~ x) = xi ); if i > n, then, depending of the type of the rule Si , Ri is de ned as follows: if Si is ri := ci , then Ri = fci g; if the rule is ri := fi (rj ), then Ri = fi (Rj ); if the rule is ri := fi(rj ; rk ), where j n and k n, then we take Ri = f ( jk (X )), where jk is a projection to j ?th and k?th components (i.e., jk (x1 ; :::; xj ; :::; xk ; :::; xn) = (xj ; xk )); if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).
Comment. The main di erence between these two de nitions is that when we have a set X Rn , and we want to compute the set fi (X ) of possible values of fi (x1 ; :::; xn), we must take into consideration the fact that not all values (x1 ; :::; xn) with xi 2 i (X ) are possible.

2.3. Applying computation scheme to fuzzy sets

In the previous subsection, we described the result of applying a computation scheme to crisp sets. Let us now describe what a computation scheme will do if we apply it to fuzzy sets.

Xn R be fuzzy sets. Then, the result f (X1; :::; Xn) of applying f to the sets X1; :::; Xn is de ned by the formula (1.4a). If instead of the fuzzy sets Xi , we have a fuzzy set X Rn, then the result f (X ) of applying f to X is de ned by the formula (1.3).

De nition 2.6. Let f (x1; :::; xn) be a function of n real variables, and let X1 R, ...,

De nition 2.7. Assume that S is a computation scheme with n input values, and that X1 R, ..., Xn R are fuzzy subsets of R. We say that the result of applying S to
follows: if i n, then Ri = Xi ; if i > n, then, depending of the type of the rule Si , Ri is de ned as follows: if Si is ri := ci , then Ri = fci g (a crisp set); if the rule is ri := fi (rj ), then Ri = fi (Rj ); if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ). 17

X1; :::; Xn is Y if RN = Y , where the sequence of fuzzy sets R1 ; :::; RN is de ned as

De nition 2.8. Assume that S is a computation scheme with n input values, and that X is a fuzzy subset of Rn . We say that the result of applying S to X is Y if RN = Y ,

where the sequence of fuzzy sets R1; :::; RN is de ned as follows: if i n, then Ri = i (X ), where i is a projection on i?th component (i.e., i (~ x) = xi ); if i > n, then, depending of the type of the rule Si , Ri is de ned as follows: if Si is ri := ci , then Ri = fci g (a crisp set); if the rule is ri := fi (rj ), then Ri = fi (Rj ); if the rule is ri := fi(rj ; rk ), where j n and k n, then we take Ri = f ( jk (X )), where jk is a projection to j ?th and k?th components (i.e., jk (x1 ; :::; xj ; :::; xk ; :::; xn) = (xj ; xk )); if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).

3. SIMPLEST CASE: SMOOTH OPERATIONS, INTERVAL UNCERTAINTY; HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS IS NOT SUFFICIENT; WEIGHTED SCALAR PRODUCT MUST ALSO BE SUPPORTED

In this section, we will consider the simplest case when inputs are intervals, and when all operations that are hardware supported are smooth (di erentiable) functions. For this case, we will prove that hardware operations with one or two variables are not su cient. The fact that functions are di erentiable makes it possible not only to prove the negative results but also to describe the smallest possible order of the error that can be caused by such computations (linear, quadratic, etc). We will also give a list of operations that need to be hardware supported so that we will be able to compute Y with a better accuracy: this list consists of arithmetic operations and a weighted scalar product.

De nition 3.1.

We say that a computation scheme S is continuous if all the function fi are continuous. We say that a function f is smooth if it is de ned on an open set, is three times di erentiable, and all its third order derivatives are continuous. We say that a computation scheme S is smooth if all the function fi are smooth.

3.1. The main (negative) result: unary and binary operations are not su cient

In this subsection, we will describe our rst negative result: that for smooth operations on intervals, hardware unary and binary operations are not su cient. 18

De nition 3.2. Assume that a smooth computation scheme S computes a smooth function f de ned on an open set K Rn. We say that S is precise for intervals if for all intervals X1; :::; Xn for which X1 ::: Xn K , the result of applying S to X1 ; :::; Xn
coincides with f (X1; :::; Xn). For example, a 1-step computation scheme that computes f (x1; x2) = x1 x2 by multiplying x1 and x2 is precise for intervals, while the computation scheme based on the expression (1=4) (x1 + x2 )2 ? (x1 ? x2 )2] is not. It can be proven that the above-given computation scheme for f (x1; x2; x3) = (x1 + x2 )2 +2 x3 is precise for intervals. As we have already mentioned, for one and the same function, some computation scheme are precise, and some others are not. The question is: for a give function f , is there any computation scheme that is precise?
putations are precise, if there exists a smooth computation scheme that computes f and that is precise for intervals. If such a smooth computation scheme does not exist, then we say that for this function f , smooth interval computations cannot be always precise.

De nition 3.3. We say that for a smooth function f : Rn ! R, smooth interval com-

We will show that for many reasonable smooth functions, smooth interval computations cannot be always precise. To formulate our result, we will need a few denotations and de nitions.

Denotations.

By f;i, we will denote i?th partial derivative of a function f . By f;ij , we will denote the second partial derivative

@ 2f : f;ij = @x @x
i j

De nition 3.4.

A point ~ s is called a stationary point of a function f if f;i (~ s) = 0 for all i. A stationary point ~ s of a function f is called non-degenerate if the following two conditions are satis ed: at this point ~ s, all components of the Hessian matrix f;ij (~ s) are di erent from 0; at this point ~ s, the determinant of the Hessian matrix is di erent from 0.

Comment. Almost all matrices satisfy these two properties (in the sense that the set of symmetric matrices for which they are not true forms a subspace of co-dimension 1 in the n(n + 1)=2?dimensional set of all matrices). So, we can say that almost all smooth functions with a stationary point have a non-degenerate stationary point.

19

THEOREM 3.1. If a smooth function f (x1; :::; xn), n 3, has a non-degenerate stationary point, then for this function f , smooth interval computations cannot be always precise.

Reformulation of this result in more informal (and hopefully, more understandable) terms. In view of the previous comment, this result means that for almost
all smooth functions with a stationary point, smooth interval computations cannot be always precise.

Our result and known mathematical results. The very fact that there exist smooth
functions for which smooth interval computations are not always precise is not surprising: indeed, it is known (see, e.g., a survey 26]), that there exists a smooth function of three variables that cannot be represented as a composition of smooth functions of one or two variables. For such functions, a smooth computation scheme cannot be precise even for real numbers, and of course, it is not precise for intervals, because every real number xi can be viewed as a (degenerate) interval xi ; xi]. Our negative result is much broader than that: namely: Functions that cannot be represented as a composition of smooth unary and binary operations can be viewed rather as an exception: e.g., every polynomial can de nitely be represented as such a composition. For smooth interval computations, we have shown that (in some reasonable sense) almost all functions (to be more precise, almost all functions with a stationary point) cannot be represented as compositions of smooth unary and binary interval operations. This result includes functions f (x1; :::; xn) like quadratic polynomials, that can be represented as a composition for numerical xi .

What does this theorem tell us about the choice of operations for hardware implementation. With respect to hardware support, Theorem 3.1 says the following:
suppose that we have chosen a list of operations that we intend to implement in hardware (both as operations with numbers and as operations with intervals). On the resulting computer, every algorithm f (x1; :::; xn) will thus be represented as a composition of the hardware supported operations fi . If we want to compute the interval f (X1; :::; Xn), we will apply the same sequence of operations as in computing f (x1; :::; xn), but with intervals instead of numbers (i.e., we will apply the computation scheme S that computes f to intervals X1; :::; Xn). For some computation schemes, e.g., for

x1 x2 = (1=4) (x1 + x2)2 ? (x1 ? x2)2 ];
20

we may get an overestimate of f (X1; :::; Xn); for some others, hopefully, we will get a precise estimate. In view of the previously mentioned result, for some smooth functions, no smooth computation scheme will return the precise interval f (X1; :::; Xn). We would like to choose a set of hardware supported operations in such a way that for each smooth function that has smooth computation schemes, at least one of these schemes will be precise for intervals (i.e., the above-described method will give exactly f (X1; :::; Xn)). Theorem 3.1 tell us that we cannot achieve this goal if we only support unary and binary operations; so, we must also implement some operations with three or more operands in hardware.

3.2. Second negative result: if we only use unary and binary operations, we cannot even compute the main term correctly
According to Theorem 3.1, if a smooth function f (x1; :::; xn) has a non-degenerate stationary point, and if we are only using unary and binary operations, then it is impossible to always compute f (X1; :::; Xn) precisely for intervals Xi. So, if a computation scheme S ~ of applying S to some intervals X1; :::; Xn will be di erent computes f , then the result Y from the desired interval Y = f (X1; :::; Xn). How di erent can it be? Since we consider smooth functions, we can try to describe this di erence in terms of the order: is it linear ( rst order), quadratic (second order), cubic (third order), etc, in i ? It could be that the di erence is, say, of fth order w.r.t. errors i , and therefore, for practical purposes (this di erence being much smaller than the interval itself) we could ~ as a good approximation for Y . Alas, the reality is not so safely neglect it, and treat Y good: it turns out that smooth interval computations (with unary and binary operations) do not even give a correct main term for Y . To describe this result in mathematical terms, let us rst describe the asymptotic of Y :

PROPOSITION 3.1. Let f (x1; :::; xn) be a smooth function. Then, the lower f ? and upper f + bounds of the interval f ( x1 ? 1 ; x1 + 1 ]; :::; xn ? n ; xn + n ]) satisfy the property f = f (x1; :::; xn) (jf;1(~ x)j 1 + ::: + jf;n (~ x)j n ) + O( 2 i ). De nition 3.5. Assume that S is a smooth computation scheme for a smooth function f (x1; :::; xn). We say that S always computes the main error term correctly if for every ~ x,
the di erence between the actual endpoints of the interval Y = f ( x1 ? 1; x1 + 1 ]; :::; xn ? n ; xn + n ]) and the values computed by applying S to intervals Xi = xi ? i ; xi + i ] is O( 2 i ). 21

Comment. In other words, we allow smooth interval computations not to be precise in the sense that their result can di er in terms that are quadratic (or of higher order) in i , but we require that the main term in i be computed precisely. THEOREM 3.2. If a smooth function f (x1; :::; xn), n 3, has a non-degenerate stationary point, then for this function f , smooth interval computations cannot always compute the main error term correctly.

3.3. Third negative result: if we only use unary and binary operations, we cannot even be locally asymptotically correct

An even stronger negative result can be proved. Namely, in our de nition of what it means to compute the main term correctly, we required that the main term should be computed exactly. In general, the fact that a function is several times di erentiable, means that we can approximate it by its Taylor polynomial. For example, if f is twice di erentiable, then in the neighborhood of a point (s1; :::; sn), we can approximate the function f (x1; :::; xn) P by a linear function: f (x1; :::; xn) = f (s1; :::; sn) + f;i (s1; :::; sn)(xi ? si ) + O((xi ? si )2 ). If the function is analytical, these Taylor polynomials actually converge to the function f . So, if by using smooth interval computations, we cannot compute the main term precisely, then maybe, we can at least compute correctly the rst few terms in the expansion of the main term? I.e., e.g., we may be able to compute the main term with the accuracy of O((xi ? si )2) terms? Alas, even this, we cannot compute, as the following result shows. De nition 3.6. Let f (~ x) be a smooth function, ~ s = (s1; :::; sn) is a point in Rn, and S is a smooth computation scheme for f . We say that S is locally asymptotically correct (in computing the main error term) in the neighborhood of ~ s, if the di erence between the actual endpoints of the interval f ( x1 ? 1 ; x1 + 1 ]; :::; xn ? n ; xn + n ]) and the values 2 computed by applying S to the intervals Xi = xi ? i ; xi + i ] is O( 2 i )+ O( i (xj ? sj ) ). THEOREM 3.3. If a smooth function f (x1; :::; xn), n 3, has a non-degenerate stationary point, then for this function f , there exists a point ~ s such that no matter what smooth computation scheme S we choose to compute f , the resulting smooth interval computations are not locally asymptotically correct in the neighborhood of ~ s.

3.4. Positive result: if we add weighted scalar product, smooth interval computations become locally asymptotically correct

Indeed, assume that in our de nition of a computation scheme, we allow, in addition to unary and binary operations, weighted scalar product, i.e., an operation a1 ; :::; an; b1; :::; bn ! w1 a1 b1 + ::: + wn an bn ; (3:1) 22

where n is an arbitrary positive integer, and wi are arbitrary real numbers (called weights). Before we give a formal de nition, we must make one comment. In operations with real numbers, if we can implement a binary operation f (x1; x2), then we can automatically implement the function g(x) = f (x; x) that is obtained by applying f to two equal values: namely, to implement g, we can simply apply f to two equal values. For interval operations, this idea does not always lead to an implementation of g. As an example, we can take subtraction f (x1; x2) = x1 ? x2. For subtraction, + ? + g(x) = f (x; x) = x ? x = 0; the corresponding interval operation is f ( x? 1 ; x1 ]; x2 ; x2 ]) = + + ? ? + ? + x? 1 ? x2 ; x1 ? x2 ]. If we apply this operation to x1 ; x1 ] = x2 ; x2 ] = 0; 1], we get f ( 0; 1]; 0; 1]) = ?1; 1]. This result is di erent from the desired g( 0; 1]) = f0g. Because of this comment, when we describe a computation scheme that involves a certain interval operation f , we must speci cally include interval analogues of all functions that can be obtained from f by applying it to equal values of the variables. As a result, for weighted scalar product, we arrive at the following de nition:

De nition 3.7.

Let a function f (x1; :::; xi?1; xi ; xi+1; :::; xj?1; xj ; xj+1; :::; xn) be given. We say that a function g(x1; :::; xj?1; xj+1; :::; xn) = f (x1; :::; xi?1; xi; xi+1 ; :::; xj?1; xi; xj+1 ; :::; xn) with n ? 1 variables is a simpli ed version of a function f ; transition from f to g will be called a simpli cation. We say that a function g is a version of a function f if g can be obtained from f by a sequence of simpli cations. By a weighted scalar product, we mean an operation (3.1). By a computation scheme with weighted scalar products, we mean a sequence S of expressions each of which is either a function of zero, one, or two variables (like in De nition 2.1), or an application of a weighted scalar product or of one of its versions.

Example. If we use weighted scalar product and its versions, we can simplify the computation of the above-given expression (x1 + x2 )2 + 2 x3 as follows: we still have ri = xi for i = 1; 2; 3; and then: r4 = r2 + r3 (this is a binary operation); r5 = 2; 2 + r5 r3 ; here, to the values r4 , r5 , and r6 , we apply a function f6 (y1 ; y2 ; y3 ) = r 6 = r4 2 + y2 y3 obtained by simplifying a weighted scalar product: f6 (y1 ; y2 ; y3) = y1 f (y1; y1; y2; y3), where f (y1; y4; y2; y3) = y1 y4 + y2 y3 is a weighted scalar product with both weights equal to 1.

23

For such computation schemes, we can repeat de nitions 2.2 (what it means that a scheme computes a function f ), 2.3 (how to apply a scheme to intervals), and 3.6 (what it means to be locally asymptotically correct). Now, we can formulate our positive result:

THEOREM 3.4. For every smooth function f (x1; :::; xn), n 3, and for every point ~ s in its domain, there exists a computation scheme S with weighted scalar products for
which the resulting smooth interval computations are locally asymptotically correct in the neighborhood of ~ s. Comments. Good news: the result is applicable not only to intervals, but to arbitrary crisp sets as well. From the proof of this theorem, one can easily see that the designed computation scheme is locally asymptotically correct not only for intervals Xi = xi ? i ; xi + i ], but also for arbitrary crisp sets Xi xi ? i ; xi + i ]. Not so good news: We know what operations we need to implement in hardware, but we do not yet know how to implement them all. Theorem 3.4 says that if we hardware support all weighted scalar products, then smooth interval computation becomes locally asymptotically correct. A word of warning: this result does not mean that we can immediately implement all these operations and make computations (asymptotically) precise, because we do not yet know how to implement all the necessary operations. Indeed, according to De nition 3.7, we need separate versions of a function to deal with each simpli cation obtained when two or more arguments to the function represent the same variable. For a function with n arguments, this will require n! hardware implementations of the function. When n is large, n! is so unrealistically large that it is practically impossible to have n! di erent hardware devices that compute n! different simpli cations. So, to implement all these simpli cations, we need a exible implementation that will change when some of the arguments represent the same variable. At present, we do not know how to design such a exible implementation. This implementation issue is an interesting open problem.

4. SMOOTH OPERATIONS, INDEPENDENT FUZZY SETS X1; :::; Xn: HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS IS NOT SUFFICIENT; WEIGHTED SCALAR PRODUCT MUST ALSO BE SUPPORTED
In the previous section, we proved that unary and binary operations are not su cient to support arbitrary smooth operations on intervals. In this section, we will show that, 24

similarly, unary and binary operations are not su cient to describe smooth operations on (independent) fuzzy sets.

coincides with f (X1; :::; Xn).

De nition 4.1. Assume that a smooth computation scheme S computes a function f de ned on an open set K Rn. We say that S is precise for independent fuzzy sets if for all fuzzy sets X1 ; :::; Xn for which X1 ::: Xn K , the result of applying S to X1 ; :::; Xn

are precise for independent fuzzy sets, if there exists a smooth computation scheme that computes f and that is precise for fuzzy sets. If such a smooth computation scheme does not exist, then we say that for this function f , smooth computations cannot be always precise for independent fuzzy sets.

De nition 4.2. We say that for a smooth function f : Rn ! R, smooth computations

THEOREM 4.1. If a smooth function f (x1; :::; xn), n 3, has a non-degenerate sta-

tionary point, then for this function f , smooth computations cannot be always precise for independent fuzzy sets. Comments. Theorem 4.1 follows directly from Theorem 3.1: indeed, if a smooth computation scheme is precise for arbitrary independent fuzzy sets, then, in particular, it must be precise for crisp intervals, and this (according to Theorem 3.1) is impossible. Similarly, Theorems 3.2 and 3.3 show that smooth fuzzy computations with only unary and binary operations cannot even describe the main term in f (X1; :::; Xn) correctly. In many reasonable cases, extension principle that de nes Y = f (X1; :::; Xn) for fuzzy sets X1; :::; Xn can be reformulated in terms of their (crisp) ?cuts Xi ( ) = fxj X (x) g: namely, Y ( ) = f (X1( ); ::; Xn( )) (see 33]; for counterexamples, see 33] and 7]). So, if we add weighted scalar product to the list of hardware supported operations, then, due to Theorem 3.4, we will be able to get all ?cuts Y ( ) locally asymptotically correctly, and in this sense, we will be able to compute the fuzzy set Y itself with the same accuracy.
i

5. GENERIC (NOT NECESSARY SMOOTH) OPERATIONS, CRISP SETS: HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS IS NOT SUFFICIENT
Let us now consider the general case of operations that are not necessarily smooth, and of the information that is not necessarily representable by independent sets X1 ; :::; Xn. 25

De nition 5.1. Assume that a computation scheme S computes a function f de ned on a set K Rn. We say that S is precise for all (crisp) sets if for every (crisp) set X K , the result of applying S to X coincides with f (X ).
Comment. We are going to prove that if our list of elementary operations includes only operations with one and two operands, and a function f of three and more variables is (in some reasonable sense) non-degenerate, then no computation scheme is applicable to fuzzy processing (i.e., none of them will provide the exact fuzzy result). Let us describe what we mean by non-degenerate.

De nition 5.2. Let K Rn , n 3. We say that a function f : K ! R is degenerate
if K can be subdivided into nitely many subsets Ki so that on each subset, f coincides with some function of one or two variables (i.e., on which f (x1; :::; xn) = g(xj ; xk ) for some j and k and for some function g). A function that is not degenerate will be called non-degenerate.

Comment. As an example of a degenerate function, we can take f (x1; :::; xn) = max(x1 ; :::; xn). For this function, K = Rn can be subdivided into the subsets Ki in which xi is greater than or equal to all other values, and on each Ki , f (x1; :::; xn) = xi (i.e., is equal to a function of one variable).

The following two results show that many functions of three or more variables are non-degenerate:

PROPOSITION 5.1. If a function f (x1; :::; xn) of three or more variables is de ned
on a domain K , and on some subset M K with a non-empty interior, f is strictly monotonic in each variable, then f is non-degenerate. Comment. To describe non-degenerate functions, we need to recall a notion of a real analytic function: this means a function that can be represented as a sum of its Taylor series. All known elementary functions (arithmetic operations, sin, cos, exp, ln, etc) and their compositions are real analytic functions. It turns out that a real analytical function is non-degenerate if and only if it actually depends on all of its variables:

PROPOSITION 5.2. If f (x1; : : :; xn) is a real analytic function of n 3 variables, and
f is not equal to a function of < n variables, then the function f is non-degenerate (in the
sense of De nition 5.2).

26

Examples. A function f (x1; x2; x3) = sin(x1 + exp(x2 x3)) is non-degenerate, because it actually depends on each of its variables. In contrast, a function f (x1; x2; x3) = x1 x2 is degenerate, because it does not depend on the variable x3 at all and is thus equal to the function of two variables. computation scheme that computes f is precise for all crisp sets.

THEOREM 5.1. If a function f of three and more variables is non-degenerate, then no

Comment. This result is based on our De nition 2.1, in which we assumed that all elementary operations are operations with one or two (set-valued) operands. Thus, in case of incomplete knowledge, when we have sets of possible values of the variables, operations with one and two operands are not su cient. This suggests that for this case, we need to implement hardware operations with 3 or more operands.

6. GENERIC (NOT NECESSARY SMOOTH) OPERATIONS, FUZZY SETS: HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS IS NOT SUFFICIENT
In the previous section, we proved that unary and binary operations are not su cient to support generic (not necessarily smooth) operations on crisp sets. In this section, we will show that, similarly, unary and binary operations are not su cient to describe generic operations on fuzzy sets.

computation scheme that computes f is precise for all fuzzy sets.

De nition 6.1. Assume that a computation scheme S computes a function f de ned on a set K Rn. We say that S is precise for all fuzzy sets if for every fuzzy subset X K , the result of applying S to X coincides with f (X ). THEOREM 6.1. If a function f of three and more variables is non-degenerate, then no
Comments. Since crisp sets are a particular case of fuzzy sets, this theorem is a corollary of Theorem 5.1 (just like Theorem 4.1. is a corollary of Theorem 3.1). This result is based on our De nition 2.1, in which we assumed that all elementary operations are operations with one or two (fuzzy) operands. Thus, for soft computing, operations with one and two operands are not su cient. This suggests that for soft computing, we need to implement hardware operations with 3 or more operands.

27

7. OUR RESULTS AND KOLMOGOROV'S THEOREM 7.1 What is Kolmogorov's theorem: in brief
The fact that every continuous function of three and more variables can be represented as a composition of functions of one or two variables (and can be thus computed by an appropriate computation scheme) has been rst proved by Kolmogorov 15] as a solution to the famous Hilbert's problem: one of 22 problems that Hilbert has proposed in 1900 as a challenge to the XX century mathematics 13]. Kolmogorov's result was later improved in 40,41], and turned out to be applicable to theoretical and practical aspects of computation (see, e.g., 6,12,24,25,31,30]).

7.2. In some reasonable sense, Kolmogorov's theorem may not be extended to interval and fuzzy computations
Our negative theorems (3.1{3.3, 4.1, 5.1, and 6.1) show that Kolmogorov's theorem might not be possible to extend to interval or fuzzy cases: there are functions that cannot be represented as a composition of operations with one or two interval (resp. fuzzy) operands.

7.3. In some other sense (less computationally straightforward) we can extend Kolmogorov's theorem to intervals
The above results are about the following: we have a function; we describe its computations step-by-step, and substitute operations with intervals instead of operations with numbers. In 32], the following result have been proven: if we do not follow the algorithm f step-by-step, i.e., if we do not require that interval operations follow the ow of numerical computations, then Kolmogorov's theorem is true: namely, an arbitrary interval function can be represented as a composition of functions of one and two variables. The proof is rather simple: suppose that we have an interval-valued function f (x1 ; :::; xn) = + ? + f ? (x1 ; :::); f +(x1 ; :::)] of n interval variables x1 = x? 1 ; x1 ]; :::; xn = xn ; xn ] . This means ? + + that we have two functions f ? and f + of 2n real variables x? 1 ; :::; xn ; x1 ; :::; xm. Each of these functions can be (due to Kolmogorov's theorem) represented as a composition of functions of one and two variables. So, we can do the following: rst, apply the interval functions ? and > that transform an interval x? ; x+] into x? ; x? ] and, correspondingly, x+ ; x+]. follow the operations from Kolmogorov's theorem with these degenerate intervals, and get the numerical-valued functions f ?; f ?] and f +; f +] as the desired composition; apply a combination operation comb( a; a]; b; b]) = a; b] to f ?; f ? ] and f +; f +] and get the desired interval f = f ?; f +]. 28

With respect to hardware operations it means that in principle, we can restrict ourselves to unary and binary operations only, but in this case, to compute the interval f (X1; :::; Xn), we will not be able to simply follow the algorithm f step-by-step: for each f , we will have to design a new method of interval (and therefore, for fuzzy) data processing.
Comment. An important open question: the result from 32] (described in this section) is proven for intervals; what happens in the fuzzy case?

8. PROOFS Proof of Proposition 3.1 Since the function f is smooth, if xi are such that j xi j

i , then

f (x1 + 1; :::; xn + xn ) = flin + O( 2 i );
where we denoted flin = f (x1; :::; xn) + x1 f;1 + ::: + xn f;n. The maximum of flin is attained when each of the component terms xi f;i attains the largest value for xi 2 ? i ; i ]: for f;i > 0, the maximum is attained when xi = i , and for f;i < 0, the maximum is attained when xi = ? i . In both cases, the maximum of i?th term is equal to jf;ij i . Therefore, the maximum of flin is equal to f (x1; :::; xn) + jf;1j 1 + ::: + jf;nj n . ? Hence, the maximum f + of f is equal to this expression plus O( 2 i ). The result for f is proved similarly. Q.E.D.

Proof of Theorems 3.1{3.3
Theorems 3.1 and 3.2 follow from Theorem 3.3, so it is su cient to prove Theorem 3.3. We will prove that the statement of this theorem is true for the non-degenerate stationary point ~ s. This will be proven by reduction to a contradiction. Namely, let us assume that there exist a smooth function with a non-degenerate stationary point ~ s and a computation scheme S for which smooth interval computations are locally asymptotically correct in the neighborhood of ~ s. Each such scheme S can be characterized by an integer: namely, by the total number of computation steps. Among such schemes, there exists a scheme with the smallest possible value of this integer. Let us denote this scheme by S , the function that is computed by this scheme by f (x1; :::; xn), and the stationary point for this function by ~ s = (s1; ::; sn). First, let us describe what type of expression we can get after each step of the smooth computation scheme. 29

De nition 8.1. By a generalized linear function of n variables x1; :::; xn, we mean a linear combination of functions 1, x1, ..., xn , and absolute values ja1x1 + ::: + an xn j of

homogeneous linear functions a1x1 + ::: + an xn . Example. A function 1 + x1 + x2 + j2x1 ? x2j + jx + 3j is a generalized linear function. LEMMA 1. For every smooth computation scheme S that computes a function f (x1; :::; xn), and for every point ~ s 2 Rn , the endpoints f~ of the result of smooth interval computations can be represented as X f~ (x ? s ; :::; x ? s ) + O( 2) + O((x ? s )2 ) f (x1; :::; xn) i 1 1 n n i i i j i

in a smooth computation scheme. Induction base. If a smooth computation scheme has not steps at all, this means that the function that we are computing simply coincides with one of the input variables. For an input variable xi , each endpoint xi of the interval xi ? i ; xi + i ] is already represented ~i = 1, and f~j = 0 for j 6= i. in the desired form with f Induction step. Assume now that we have proved this result for all smooth computation schemes of length k, and we want to prove it for smooth computation schemes of length k +1. Let S be any smooth computation scheme of length k +1. By de nition of a smooth computation scheme, the nal result of S is obtained in the last ((k + 1)?st) step by applying a smooth function of one or two variables to the results of previous computations. These results of previous computations are thus computable by computation schemes of length k. Therefore, for these results, due to the induction assumption, the result can be represented in the desired form. Let us use these forms to describe the result of applying (k + 1)?st step. To prove it, we will consider two possible cases: The rst case if when the last step of S consists of applying a smooth function of one variable. The second case if when the last step of S consists of applying a smooth function of two variables. In the rst case, f (x1; :::; xn) = F (r(x1; :::; xn)), and the result of applying smooth interval computations to r is already known to be expressible in the form
2 r(x1; :::; xn) ? l + O( 2 i ) + O((xi ? si ) 2 j ); r(x1; :::; xn) + l + O( 2 i ) + O((xi ? si )
j )];

Proof of Lemma 1. We will prove this lemma using induction over the number of steps

~i . for some generalized linear functions f

30

where l = r ~1 1 + ::: + r ~n n is a linear expression in i , with coe cients r ~i that are generalized linear function in xi ? si . Similarly to the proof of Proposition 3.1, we can prove that applying F results in an interval y?; y+], where

y = F (r(x1; :::; xn)) jF 0 (r(x1; :::; xn))j l + O((xi ? si )2

j ):

To prove the desired result, let us rst approximate jF 0 (r(x1; :::; xn))j by a generalized linear function. To do that, we can rst approximate the composition F 0 (r(x1; :::; xn)) by a generalized linear function. This part is easy: Since both F 0 and r are smooth functions, we conclude that F 0 (r(x1; :::; xn)) is also a smooth function, and therefore, it can be represented as a0 + a1 (x1 ? s1) + ::: + an(xn ? sn ) + O((xi ? si )2). If a0 = 0, then the absolute value of this function can be represented as

ja1(x1 ? s1) + ::: + an (xn ? sn )j + O((xi ? si)2 );
i.e., as a generalized linear function plus O(:::). P P If a0 6= 0, then a0 + ai (xi ?si ) = a0 (1+ (ai =a0)(xi ?si )). The absolute value of the product can be represented as the product of the absolute values. When xi ! si , then P(ai=a0)(xi ?si) ! 0, hence P(ai=a0)(xi ?si) > ?1, and so, j1+P(ai=a0)(xi ?si)j = P 1+ (ai =a0)(xi ? si )+ O((xi ? si )2). Therefore, ja0 + a1 (x1 ? s1)+ ::: + an(xn ? sn )j = ja0j(1 + P(ai =a0)(xi ? si)) + O((xi ? si )2) is a linear (and thus, generalized linear) function of xi ? si . In both cases, we represent jF 0(r(x1; :::; xn))j as a sum of the generalized linear function g ~ and an O((xi ? si)2 ) term. Therefore, the product jF 0 (r(x1; :::; xn)))j l = jF 0 (r(x1; :::; xn)))j r ~1 1 + ::: + jF 0(r(x1; :::; xn)))j r ~n n can be represented as

g ~ r ~1

~ r ~n 1 + ::: + g

n + O((xi ? si )2 j ):

For every i, the coe cient g ~ r ~i at i is a product of two generalized linear functions. By de nition, each generalized linear function is a sum of a constant (maybe 0), and a homogeneous rst order part (i.e., terms ai xi and ja1x1 + ::: + an xn j). The product g ~r ~i of two generalized linear functions g ~ and r ~i is thus a product of two sums and can, therefore, be represented as a sum of four terms: a product of two constants, which is a constant; a product of a constant term of g ~ and a homogeneous rst order part of r ~i , which is a generalized linear function; a product of a constant term of r ~i and a homogeneous rst order part of g ~, which is also a generalized linear function; 31

a product of a homogeneous rst order parts of g ~ and r ~i , which is O((xi ? si)2 ). The sum f~i of the rst three products is generalized linear function; the fourth term lead ~i i + O((xi ? si )2 j ) for to the term O((xi ? si )2 i ) in g ~ r ~i i. Therefore, g ~ r ~i i = f ~i . So, jF 0 (r(x1; :::; xn))j l = L + O((xi ? si )2 j ), where a generalized linear function f L = f~1 1 + ::: + f~n n , f~i are generalized linear, and therefore, the resulting interval is indeed equal to the desired expression f (x1; :::; xn) ? L + O(:::); f (x1; :::; xn) + L + O(:::)]. The second case can be described in a similar manner. In this case, instead of f = F (r), we have f (x1; :::; xn) = F (r(x1; :::; xn); t(x1; :::; xn)) for some functions r and t that have been computed on the previous steps. The resulting proof is similar. The lemma is proved. Q.E.D.

LEMMA 2. Let S be a smooth computation scheme that computes a function f (x1; :::; xn), and let ~ s 2 Rn. Then, jf;ij f~i + O((xi ? si)2 ), where f~i are generalized linear functions
that appear (as coe cients at i ) in the description of the result of applying smooth interval computations.

actual interval of values of f . Due to Lemma 1, the endpoints of the resulting interval are f (f~1 1 + ::: + f~n n )+ O(:::), and due to the Proposition, the endpoints of the interval of values of f are f (jf;1j 1 + ::: + jf;n j n )+ O(:::). The fact that the rst interval contains the second one means, in particular, that the width of the rst interval is than the width of the second interval, i.e., that f~1 1 + ::: + f~n n jf;1j 1 + ::: + jf;n j n + O(:::). If we x i, choose i = 1 for this i, and j = 0 for all j 6= i, we get the desired inequality. Q.E.D.

Proof of Lemma 2. For interval computations, the resulting interval always contains the

LEMMA 3. Let S be a smooth computation scheme that computes a function f (x1; :::; xn), and let ~ s 2 Rn . Then, the following statements are equivalent to each other: for S , smooth interval computations are locally asymptotically correct in the neighborhood of ~ s; ~ jf;i j = fi + O((xi ? si )2), where f~i are generalized linear functions that appear (as coe cients at i ) in the description of the result of applying smooth interval computations.

Q.E.D.

Proof of Lemma 3. This result immediately follows from Lemma 1 and Proposition 3.1.

Proof of Theorem 3.3 itself. Let us now prove Theorem 3.3 itself. By de nition, each step of a smooth computation scheme S that does not assign a constant value to a variable
32

(i.e., that is not of the type Ri = fci g), consists of applying a function of one or two variables either to initial data xi , or to the values computed on one of the previous steps. The last step of the scheme S cannot be of the form Ri = fci g since otherwise the function would have no non-degenerate stationary point. Therefore, the last step of the scheme S can consists of applying either: a function of one variable, or a function of two variables. Let us prove the theorem for these two cases. First case: the last step consists of applying a function of one variable. Let us rst show that this last step cannot consist of applying a smooth function of one variable. We will prove this statement by reduction to a contradiction. Assume that the last step of S does consist in applying a smooth function of one variable F to the result r(x1 ; :::; xn) of some previous step. In this case, f (x1; :::; xn) = F (r(x1; :::; xn)). Let us prove that r(~ x) has a non-degenerate stationary point (at the same ~ s), and that for this function r, smooth interval computations are locally asymptotically correct in the neighborhood of ~ s. Indeed, we know that ~ s is a stationary point for f , i.e., that f;i (s1; :::; sn) = 0. Since f (x1; :::; xn) = F (r(x1; :::; xn)), we have f;i (s1; :::; sn) = F 0 (r(s1; :::; sn)) r;i (s1; :::; sn). Similarly, f;ij (~ s) = F 00 (r(~ s))r;i(~ s)r;j (~ s)+ F 0 (r(~ s)) r;ij (~ s). Since f;i(~ s) = 0, we can conclude that either F 0 (r(~ s)) = 0, or r;i (~ s) = 0. In the rst case, f;ij = F 00 (~ s)r;i r;j , and the determinant of the Hessian at ~ s is 0, which contradicts to our assumption that ~ s is a nondegenerate point. Therefore, F 0 (~ s) 6= 0, and r;i (~ s) = 0, and ~ s is a stationary point of the function r(x1; :::; xn). Since F 0 (r(~ s)) 6= 0 and r;i (~ s) = 0, from f;ij (~ s) = F 00(r(~ s))r;i (~ s)r;j (~ s)+ F 0 (r(~ s)) r;ij (~ s), we can conclude that f;ij (~ s) = F 0 (r(~ s)) r;ij (~ s), and r;ij (~ s) = C f;ij (~ s), where C = 0 1=F (r(~ s)). Since ~ s is a non-degenerate stationary point of f , we have f;ij 6= 0, hence r;ij (~ s) = C f;ij (~ s) 6= 0. Similarly, from det jf;ij j 6= 0, we conclude that det jr;ij j 6= 0. So, ~ s is a non-degenerate stationary point for the function r. Let us now show that for the smooth computation scheme that leads to r, smooth interval computations are locally asymptotically correct in the neighborhood of ~ s. Indeed, let r ~i be the generalized linear functions that appear (as coe cients at i ) in the description of the result of applying smooth interval computations to r. This means that after we reach r, the resulting interval is equal to r (~ r1 1 + ::: + r ~n n ) + O(:::). Due to Proposition 3.1, after applying the function F to this interval, we get F (r) jF 0 (r(x1; :::; xn))j(~ r1 1 + ::: + r ~n n ) + O(:::): 33

Now, since F 0 (r) is a smooth function, we get

F 0 (r(x1; :::; xn)) = F 0 (r(~ s)) +

X F 00(r(~ s))r (x ? s ) + O((x ? s )2 ):
;i i i i i

Since ~ s is a stationary point for r, we have r;i (~ s) = 0, and therefore, F 0 (r(x1; :::; xn)) = F 0 (r(~ s))+ O((xi ? si )2) and jF 0(r(x1; :::; xn))j = jF 0 (r(~ s))j + O((xi ? si )2). So, the result of applying smooth interval computations to S is equal to F (r) jF 0 (r(~ s))j(~ r1 1 +:::+~ rn n )+ O(:::). Since for f and S , smooth interval computations are locally asymptotically correct, we can (due to Lemma 3) conclude that for all i, jF 0 (r(~ s))j r ~i (~ x) = jf;i(~ x)j + O(:::). But, 0 since f (~ x) = F (r(~ x)), we have f;i (~ x) = F (r(~ x))r;i (~ x) and jf;i(~ x)j = jF 0 (r(~ x))j jr;i(~ x)j. We already know that jF 0(r(x1; :::; xn))j = jF 0(r(~ s))j + O((xi ? si )2). Therefore, jf;i (~ x)j = 0 jF (r(~ s))j jr;i(~ x)j + O(:::). So, from

jF 0 (r(~ s))j r ~i (~ x) = jf;i(~ x)j + O(:::) = jF 0 (r(~ s))j jr;i(~ x)j + O(:::);
we can conclude that r ~i (~ x) = jr;i (~ x)j + O(:::), and hence, due to Lemma 3, that for r, smooth interval computations are locally asymptotically correct. Since r is computed on a previous step of the smooth computation scheme S , the number of steps that lead to r is smaller than the number of computation steps in a scheme S , and this contradicts to our choice of S as the shortest smooth computation scheme that leads to a smooth non-degenerate function for which smooth interval computations are locally asymptotically correct. So, the last step of our smooth computation scheme S cannot consist of applying a function of one variable. complete our proof, let us show that the last step cannot consist of applying a function of two variables. Indeed, suppose that the last step consists of applying a smooth function F of two variables to two functions r(~ x) and t(~ x) that have been computed on a previous computation step. In this case, f;i = F;r r;i + F;t t;i , where by F;r and F;t, we denoted partial derivatives of F w.r.t. r and t.

Second case: the last step consists of applying a function of two variables. To

Let us rst show that for ~ s, both partial derivatives of F cannot be 0. Indeed, suppose that they are. For f = F (r; t), the Hessian matrix is equal to f;ij (~ x) = F;rr (~ x)r;ir;j + 2F;rt (~ x)r;i t;j + F;tt (~ x)t;i t;j + F;r (~ x)r;ij + F;t (~ x)t;ij . In particular, for ~ x=~ s, taking into consideration that F;r = F;t = 0, we conclude that f;ij (~ s) = F;rr (~ s)r;ir;j + 2F;rt (~ s)r;i t;j + F;tt (~ s)t;i t;j . If we choose vectors r;i (~ s) and t;i(~ s) as the rst two elements of the base, then the Hessian matrix will only have 11, 12, and 22 components. Therefore, the determinant 34

of the Hessian matrix f;ij (~ s) will be 0, which contradicts to our assumption that the stationary point ~ s is non-degenerate. This contradiction shows that the derivatives F;r (~ s) and F;t (~ s) cannot be both equal to 0. Hence, we only need to consider the following three subcases: F;r (r(~ s); t(~ s)) 6= 0 and F;t(r(~ s); t(~ s)) 6= 0. F;r (r(~ s); t(~ s)) 6= 0 and F;t(r(~ s); t(~ s)) = 0. F;r (r(~ s); t(~ s)) = 0 and F;t(r(~ s); t(~ s)) 6= 0. We will analyze these three subcases separately. from 0 at ~ s. Let us show that in this case, r;i (~ s) = t;i (~ s) = 0. Indeed, the interval that P corresponds to r is equal to r r ~i i + O(:::), and the interval that corresponds to t is P ~i i + O(:::). Due to Proposition 3.1, the interval that corresponds to f is equal to t t P f~i i +O(:::), where f~i(~ ~i(~ thus equal to f x) = jF;r (~ x)j r ~i(~ x)+jF;t(~ x)j t x)+O((xi ?si )2 ). Let us analyze this equality for ~ x=~ s. For this ~ x, the O term is equal to 0, so we have an ~i (~ ~i (~ exact equality f x) = jF;r (~ x)j r ~i (~ x) + jF;t(~ x)j t x). Since smooth interval computations are locally asymptotically correct for f , we have (due to Lemma 2) f~i = jf;ij + O((xi ? si )2 ). In particular, for ~ x=~ s, we have f~;i (~ s) = jf;i(~ x)j = 0. So, the left-hand side of the equality ~i(~ ~i are non-negative for all ~ is 0: 0 = jF;r (~ s)j r ~i(~ s)+ jF;t(~ s)j t s). The coe cients r ~i and t x. ~i (~ So, 0 is equal to the sum of two non-negative products (jF;r (~ s)j r ~i (~ s) and jF;t(~ s)j t s)). The only way for this to happen is when both products are equal to 0. Since F;r 6= 0 for ~ x=~ s, from jF;r (~ s)j r ~i (~ s) = 0, it follows that r;i(~ s) = 0. Similarly, we can conclude that t;i (~ s) = 0. Due to r;i (~ s) = t;i (~ s) = 0, we can (similarly to the case of f = F (r)) conclude that ~i(~ F (~ x) = F (~ s)+ O((xi ? si )2 ). Therefore, f~i (~ x) = jF;r (~ s)jr ~i (~ x)+ jF;t (~ s)jt x)+ O(:::). On the ~i = jf;ij + O(:::), where f;i (~ other hand, f x) = F;r (~ x)r;i(~ x)+ F;t (~ x)t;i (~ x), and due to F (~ x) = 2 F (~ s)+ O((xi ? si ) ), we can rewrite this equality as f;i (~ x) = F;r (~ s)r;i (~ x)+ F;t (~ s)t;i(~ x). So,

First subcase of the second case: both partial derivatives of F are di erent from 0 at ~ s. Let us rst consider the case when both partial derivatives of F are di erent

f~i = jf;ij + O(:::) = jF;r (~ s)r;i(~ x) + F;t (~ s)t;i(~ x)j + O(:::):
Since jp + qj jpj + jqj, we conclude that

f~i jF;r r;i + F;t t;ij + O(:::) jF;r j jr;i j + jF;tj jt;i j + O(:::):
~i + O(:::). Therefore, Due to Lemma 2, jr;ij r ~i + O(:::) and jt;i j t ~i + O(:::): f~i jF;r r;i + F;t t;ij + O(:::) jF;r j jr;ij + jF;tj jt;ij + O(:::) jF;r j r ~i + jF;t j t 35

But the right-hand side of this inequality is already known to be equal to f~i (~ x) (modulo quadratic terms). Therefore,

f~i jF;r r;i + F;t t;ij + O(:::) jF;r j jr;ij + jF;tj jt;ij + O(:::) f~i + O(::):
In this chain of inequalities the starting and the ending expressions coincide, and hence, they are all equalities. So,

jF;r r;i + F;t t;i j = jF;r j jr;i j + jF;t j jt;i j + O(:::):
The only case when jp + qj = jpj + jqj is when p and q are of the same sign. So, we can conclude that the linear parts of the expressions F;r (~ s) r;i (~ x) and F;t (~ s) t;i(~ x) are of the same sign. Clearly, the sign of the linear part of

f;i = F;r (~ s) r;i(~ x) + F;t(~ s) t;i(~ x) + O(:::)
will be of the same sign. This linear part is f;ij (~ s)(xj ? sj ). Similarly, we can express the linear parts of r;i and t;i . We know that the numbers F;r (~ s) and F;t (~ s) are di erent from 0. Let us assume that both numbers are positive (the cases when one of them is negative can be treated in a similar manner). In this case, if a linear term in f;i is positive, then the linear terms in r;i and t;i are also non-negative. In other words, if P P s)(xj ?sj ) 0. Turning to a limit, we can conclude that f s )(xj ? sj ) > 0, then f;ij (~ ;ij (~ P s)(xj ? sj ) 0, then P f;ij (~ P s)(xj ? sj ) 0, if f;ij (~ s )(xj ? sj ) 0. Similarly, if f;ij (~ P s)(xj ? sj ) 0. Therefore, if P f;ij (~ then f;ij (~ s)(xj ? sj ) = 0,P then we have both P f;ij (~ P s)(xj ?sj ) 0 and f;ij (~ s)(xj ?s s)(xj ?sj ) 0 j ) 0, hence, we have both r;ij (~ P P and r;ij (~ s)(xj ? sj ) 0, and thence, r;ij (~ s)(xj ? sj ) = 0. So, if f;ij (~ s)(xj ? sj ) = 0, then r;ij (~ s)(xj ? sj ) = 0. In geometric terms, the ~i with coordinates condition means that a vector xj ? sj is orthogonal to the vector f f;i1(~ s); :::; f;in(~ s). Similarly, the conclusion means that a vector xj ? sj is orthogonal to the vector ~ ri with coordinates r;ij (~ s). Since ~ s is a non-degenerate stationary point, the ~i is not zero, and therefore, vectors that are orthogonal to f ~i form a (hyper)plane. vector f A vector ~ ri is orthogonal to every vector from this (hyper)plane, and is, therefore, collinear ~i . This means that for every i, there exists a constant ci such that r;ij (~ with f s) = ci f;ij (~ s) for all i and j . The matrix of second derivatives is symmetric: r;ij = r;ji . Therefore, for every i and j , ci f;ij = cj f;ji. Since second derivatives of f;ij also form a symmetric matrix, we have 36

P

P

P

ci f;ij = cj f;ij . Due to the fact that ~ s is a non-degenerate stationary point for f , we conclude that f;ij = 6 0 and therefore, ci = cj for all i and j . Let us denote the common value of all ci by c. Then, r;ij (~ s) = cf;ij (~ s). Similarly, t;ij (~ s) = c0 f;ij (~ s). The coe cients c and c0 cannot be both equal to 0, because then, we would have f;ij (~ s) = F;r (~ s)rij (~ s) + F;t (~ s)t;ij (~ s) = 0. 0 So, either c = 6 0, or c = 6 0. If c = 6 0, then r;ij (~ s) = cf;ij (~ s) is a non-degenerate matrix with non-zero determinant and all elements non-zero. Therefore, r is a function that has a non-degenerate stationary point at ~ s, and that can be computed in fewer steps than f , which contradicts to our choice of f . Similarly, if c0 = 6 0, then t is a function that contradicts to our choice of f . In both cases, we get a contradiction.

Second and third subcases of the second case: only one partial derivative of F is di erent from 0 at ~ s. We have derived a contradiction for the case when both partial derivatives F;r (~ s) = 6 0 and F;t (~ s) = 6 0. To complete the proof of the theorem, we

must deduce a contradiction for the case when one of these partial derivatives is equal to 0. Without losing generality, we can assume that F;r (~ s) 6= 0 and F;t (~ s) = 0. ~i (~ In this subcase, from the equality f~i (~ x) = jF;r (~ x)j r ~i (~ x) + jF;t (~ x)j t x) (that can be proven exactly like in the rst subcase), we conclude that r;i (~ s) = 0. Since F;t (~ s) = 0, we can conclude that F;t (~ s) = aj (xj ?sj )+O((xi ?si )2 ). Therefore, only zeroth-order terms in t;i (~ x) need to be taken into consideration, and we have

P

f;i (~ x) =

Xf

s) ;ij (xj ? sj )+ O(:::) = F;r (~

Xr

s)(xj ? sj )+( ;ij (~

X a (x ? s ))t (~ s)+ O(:::):
j j j ;i

Similarly to the rst subcase, we can prove that the two linear components of this sum must be of the same sign as fi , and therefore, that r;ij = cf;ij and aj t;i = c0 f;ij . The coe cient c0 cannot be di erent from 0, because then, we would have f;ij = (1=c0)aj t;i, and det jf;ij j = 0,which contradicts to our assumption that the Hessian matrix f;ij is nondegenerate. Therefore, c0 = 0, and hence, c = 0 is impossible. Therefore, r;ij = (1=c)f;ij , and r is a function that has a non-degenerate stationary point at ~ s, and that can be computed in fewer steps than f , which contradicts to our choice of f . We have proven the result for the rst case, and for all subcases of the second case; therefore, the theorem is proven. Q.E.D.

Proof of Theorem 3.4
Since the function f is smooth, for every point ~ s, we have f (~ x) = fquadr(~ x)+ O((xi ? si )3 ), where X s)(x ? s ) + 1 X f (x ? s )(x ? s ): fquadr = f (~ s) + f;i(~ ;ij i i j j i i 2
i i;j

37

Therefore (similarly to the proof of Proposition 3.1), we can conclude that the di erence between the intervals f (X1; :::; Xn) and fquadr (X1; :::; Xn) is also O((xi ? si )3). The function fquadr is quadratic in xi , so, we can represent it as

fquadr(x1; :::; xn) = a0 +

Xa x + Xa
i i i i;j

ij xi xj

for some real numbers ai and aij . If we de ne a0i = ai for i = 0; 1; :::; n, then we can represent this expression as fquadr(x1 ; :::; xn) = g(x0; x1; :::; xn) for x0 = 1 and

g(x0; :::; xn) =

n X n X a i=0 j =0

ij xi xj :

The function g, in its turn, can be represented as a result of applying n simpli cations xi = yi , 1 i n, to a weighted scalar product
n X n X f (x ; x ; :::; x ; y ; y ; :::; y ) = a

0 1

n 0 1

n

i=0 j =0

ij xi yj

with weights aij . So, fquadr can be computed using a computation scheme S with weighted scalar products. Since the di erence between the intervals f (X1; :::; Xn) and fquadr(X1; :::; Xn) is O((xi ? si )3 ), we can conclude that smooth interval computations described by the scheme S are locally asymptotically correct for the original function f . Q.E.D.

Proof of Proposition 5.1
1. Let us prove this Proposition by reduction to a contradiction. Namely, assume that f : K ! R is strictly monotonic in each variable, and that f is degenerate. By de nition, this means that K can be represented as a union of nitely many sets K1 ; :::; Kp on each of which f is equal to a function of two of fewer variables. Let's deduce a contradiction from here. 2. Since the interior of M

K is non-empty, the set M contains a ball.

Inside the ball, we can place a cube a1; b1] a2; b2] ::: an ; bn]. Let's divide each side ai ; bi] of the cube into p + 1 equally distanced values of xi : ai , ai + (bi ? ai )=p, ai + 2 (bi ? ai)=p, ..., ai + p (bi ? ai )=p = bi . By combining these values for di erent i, we get (p + 1)n di erent points that all belong to the cube and therefore, to K . Let us denote the set of all these points by P . 38

3. Let us take one of the sets Ki , and let us estimate how many of the points from P belong to Ki . Since f is degenerate of Ki , it means that on Ki f is equal to a function of two or fewer variables. But f is a function of n 3 variables. So, this means, that for ~ x 2 Ki , f cannot depend on all the variables. Hence, it does not depend on one of the variables. Let us denote one of such variables by xj . The fact that for ~ x 2 Ki , f does not depend on xj , means that if we have two di erent points with di erent values of xj and equal values of all other coordinates, then the value of f for both point will be the same. 4. Formally, if ~ x = (x1; :::; xj?1; xj ; xj+1; :::; xn) 2 P where xj 6= 0, then f (~ x) = f (~ y). But on M , f is strictly monotonic in each variable. This means, in particular, that f is either strictly increasing in xj , or strictly decreasing in xj . In both cases, f (~ x) 6= f (~ y). This contradiction with f (~ x) = f (~ y) shows that no such pairs (~ x; ~ y) are possible. In other words, if we x the values of n ? 1 coordinates (all of them except for xj ), i.e., if we x the values x1; :::; xj?1; xj+1; :::; xn, then at most one point with these values of n ? 1 coordinates belongs to Ki . 5. For P , if we x the values of all the coordinates but one, then, we can choose p + 1 di erent values of xj and hence, have p + 1 di erent points from P K . At most one of them belongs to Ki. Therefore, Ki contains at most 1=(p + 1) part of all the points from P. 6. The same inequality is true for each of the sets Ki . So, totally, p sets K1, ..., Kp contain p=(p + 1) of all the points from P . Since p=(p + 1) < 1, it means that there are points from P (and hence from K ) that are not covered by any of the sets Ki . This contradicts to our assumption that f is degenerate and K = Ki . This contradiction shows that our assumption was false, and so f is not degenerate. Q.E.D.

M and

~ y = (x1 ; :::; xj?1; xj + xj ; xj+1; :::; xn) 2 M;

Proof of Proposition 5.2
Let us show that if a real analytic function f (x1; :::; xn) does not coincide with a function of less than n variables, then it is non-degenerate in the sense of De nition 5.2. Indeed, an arbitrary real analytic function g(x1; :::; xn) has the following property (similar to complex analytical functions): it is either identically equal to 0, or it is equal to 0 on a set of (Lebesgue) measure 0 (i.e., it is di erent from 0 on a set of full measure) (see, e.g., 17]). 39

Also, for an arbitrary real analytic function, each of its derivatives is also real analytic. In particular, the partial derivative @f=@x1 of the given function is real analytic. If it was identically equal to 0, then f would not depend on x1 at all. Therefore, according to the above-cited result, the set of points (x1 ; :::; xn) on which this derivative is equal to 0 is of Lebesgue measure 0. Similarly, for each i = 2; :::; n, the set of all points (x1 ; :::; xn), at which i?th partial derivative @f=@xi is equal to zero, is also of measure 0. Therefore, the union of these n sets, i.e., the set of all points on which at least one of the partial derivatives is di erent from 0, is also of measure 0 (as a union of measure-zero (0) sets). Therefore, there exists a point (x(0) 1 ; :::; xn ) that does not belong to this union. By de nition of the union it means that in this point, all n partial derivatives are di erent from 0. These derivatives are real analytic and therefore, continuous. Therefore, there exists (0) a spherical neighborhood M of this point (x(0) 1 ; :::; xn ) in which sign of each of the partial (0) derivatives coincides with its sign at the point (x(0) 1 ; :::; xn ). For those i for which this sign is positive (@f=@xi > 0), f is strictly increasing in xi . For those i for which this sign is negative (@f=@xi < 0), f is strictly decreasing in xi . So, for all points from a set M with a non-empty interior, the function f is strictly monotonic in each variable. Therefore, according to Proposition 5.1, this function f is non-degenerate. Q.E.D.

Proof of Theorem 5.1
1. Let us prove this theorem by reduction to a contradiction. Namely, we will assume that there exists a non-degenerate function f and a computation scheme S that computes f and that is precise for all (crisp) sets, and we will deduce a contradiction from this assumption. To deduce this contradiction, we will use the following observation: According to our de nitions, the phrase \S is precise for all (crisp) sets" means that for every (crisp) set X Rn , the result RN of applying S to X coincides with f (X ). In this proof, we will need the following two Lemmas:

LEMMA 4. Assume that a function f : K ! R (K Rn ) is computed by a composition scheme S , and X K . Let's denote by RN the result of applying S to X . Then, f (X )
RN .
tions (see, e.g., 29]), and is proved similarly: namely, using induction, one can then prove that for every i, ri (X ) Ri. For i = N , we get the desired result. Q.E.D. 40

Proof of Lemma 4. This Lemma is similar to the Main Theorem of Interval Computa-

is a composition of f and g (i.e., h(~ x) = f (g(~ x))). Then, for every (crisp) set X h(X ) = f (g(X )).

LEMMA 5. Assume that k is an integer, f : R ! R, g : Rk ! R, and h : Rk ! R

Rk ,

Proof of Lemma 5 follows directly from the de nitions. Q.E.D.
2. We will need the following auxiliary notion: by a complexity of a computation scheme S = (Sn+1 ; :::; SN ), we will understand the number N . We assumed that there exists a computation scheme that computes a non-degenerate function of n variables and that is precise for all (crisp) sets. Out of all computation schemes with this property, there exists a one with the smallest possible complexity N . Let's choose one of these \simplest" schemes. In the following text, this chosen scheme will be denoted by Ss (s stands for simplest). The corresponding function will be denoted by fs .
Comment. A computation scheme Ss consists of the rules of the type ri := ci , ri := fi (rj ), and ri := fi (rj ; rk ). In principle, the corresponding functions fi can be de ned everywhere. However, when we apply this computation scheme to compute the value of the function fs that is de ned on some set K , we will use only the values of fi for rj 2 ri (K ); or, for the function of two variables, only the values for (rj ; rk ) 2 Djk , where

Djk = f(a; b) j 9~ x (~ x 2 K & rj (~ x) = a & rk (~ x) = bg:
Therefore, to simplify our proofs, we will assume in the following text that fi is de ned only for these values. It is easy to check that if initially Ss computed fs and was precise for all (crisp) sets, then after such a restriction on fi it still has the same properties. 3. Depending on what the nal step SN of Ss is, we have the following ve possibilities: N n; N > n and rN := cN ; N > n and rN := fN (rj ), where j < N ; N > n and rN := fN (rj ; rk ), where j n and k n; N > n and rN := fN (rj ; rk ), where j > n or k > n. In the following ve subsections, we will prove that in all these ve cases, we have a contradiction with our initial assumption. 4. N

n.
41

In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = xN . So, fs depends only on one of its variables. Hence, fs is degenerate, which contradicts to the assumption that it is nondegenerate. 5. N > n and rN := cN . In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = cN does not depend on any variables at all. Therefore, it is degenerate. 6. N > n and rN := fN (rj ), where j < N . Let us prove (by considering all possible cases) that this case is impossible. Depending on the case, we will prove it either directly, or by \merging" the last step with one of the previous ones, and thus coming up with a new computation scheme that is simpler than the scheme Ss that is by de nition the simplest possible (so, we have a contradiction). 6.1. If j n, then rj = xj , and fs = fN (rj ) = fN (xj ) is a function of one variable (namely, xj ) and is thus degenerate, which contradicts to our choice of fs. 6.2. If j > n, and j ?th step is rj := cj , then fs = rN = fN (cj ) =const, i.e., fs is also degenerate. 6.3. If j > n, and j ?th step is rj := fj (rk ) for some k < j , then rN = fN (fj (rk )). In ~N (rk ), where by f~N , we denoted the composition of fN and fj . other words, rN = f 6.3.1. If k n, then fs is again a function of one variable xk (i.e., degenerate). 6.3.2. If k > n, then, we can replace the original computation scheme S with the ~ = (Sn+1 ; :::; Sk ; S ~N ), where by S ~N , we denoted the following simpli ed one: S ~N (rk ). Because of our formulas, this scheme computes following step: rN := f exactly the same function fs . The fact that this scheme computes the same function and is precise for all (crisp) sets, follows from Lemma 5. Since we deleted at least one step (Sj ), this new scheme has a smaller complexity that Ss . This contradicts to our choice of Ss as the computation scheme with the smallest possible complexity that computes a non-degenerate function of 3 or more variables and that is precise for all (crisp) sets. 6.4 If j > n, and j ?th step is rj := fj (rk ; rl ) for some k; l < j , then rN = fN (fj (rk ; rl)) = f~N (rk ; rl ), where by f~N , we denoted a composition f~N (a; b) = fN (fj (a; b)). In this case, we can also delete one step from the computation scheme and thus arrive at the contradiction. 42

7. N > n and rN := fN (rj ; rk ), where j n and k n. In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = fN (xj ; xk ). Hence, fs depends on only two of its variables, and is therefore degenerate. 8. N > n and rN := fN (rj ; rk ), where j > n or k > n. 8.1. We assumed that Ss computes fs , and that Ss is precise for all (crisp) sets. This means, in particular, that for each input set X K , RN = fs(X ). In particular, if we take arbitrary two elements ~ x 2 K and ~ y 2 K , then this equality must be true for a 2-point set X = f~ x; ~ yg. 8.2. For this choice of X , the right-hand side of the equality RN = fs (X ) (i.e., the set fs(X )) is easy to describe: it consists of two values fs (~ x) = fN (rj (~ x); rk (~ x)) and fs(~ y) = fN (rj (~ y); rk (~ y)). 8.3. Now, let's nd an element of the left-hand side. By de nition of RN , this set is equal to RN = fN (Rj ; Rk ). Due to Lemma 4, Rj rj (X ), and Rk rk (X ). Since rj (~ x) 2 rj (X ), we can thus conclude that rj (~ x) 2 Rj . Similarly, we can conclude that rk (~ y) 2 Rk . Therefore, fN (rj (~ x); rk (~ y)) 2 fN (Rj ; Rk ) = RN . Since RN = fs(X ), every element of RN must coincide with one of the two elements of fs (X ). In particular, for the above-discovered element, it means the following:
For every ~ x 2 K and ~ y 2 K , fN (rj (~ x); rk (~ y)) is either equal to fN (rj (~ x); rk (~ x)), or it is equal to fN (rj (~ y); rk (~ y)).

8.4. This statement enables us to make the following conclusion about the function fN (a; b):
If we can nd ~ x and ~ y such that a = rj (~ x) and b = rk (~ y), then either fN (a; b) = fN (a; rk (~ x)), or fN (a; b) = fN (rj (~ y); b).

8.5. For each a 2 rj (K ), there exists a vector ~ x for which rj (~ x) = a (it is possible that several such vectors exist). For di erent vectors ~ x, the value rk (~ x) may also be di erent. For each a, let us pick one of these values rk (~ x) and denote it by gkj (a). Similarly, for each b 2 rk (K ), we will pick a vector ~ x with the property that rk (~ x) = b, and denote the value rj (~ x) for thus picked ~ x by gjk (b). 8.6. Using these denotations, we can reformulate the statement from 8.4 as follows: 43

For every a 2 rj (K ) and b 2 rk (K ), either fN (a; b) = fN (a; gkj (a)), or fN (a; b) = fN (gjk (b); b).

If we denote h1 (a) = fN (a; gkj (a)) and h2 (b) = fN (gjk (b); b), then we can further simplify this conclusion: For every (a; b) 2 Djk , either fN (a; b) = h1 (a), or fN (a; b) = h2 (b). 8.7. In particular, this property is true if we choose an arbitrary ~ x 2 K and take a = rj (~ x) and b = rk (~ x). Let us denote by K1 the set of all ~ x 2 K for which fN (rj (~ x); rk (~ x)) = h1 (rj (~ x)), and by K2, the set of all values ~ x 2 K for which fN (rj (~ x); rk (~ x)) = h2 (rk (~ x)). Then, this property means that K = K1 K2. 8.8. Since the function f de ned on K is non-degenerate, its restriction to either K1 or K2 is also non-degenerate. Indeed, if it were not true, then we would be able to describe both K1 and K2 (and hence, their union) as the union of nitely many subsets on which fs is degenerate. On the other hand, we assumed that fs : K ! R is non-degenerate, which means that for K , such a representation is impossible. 8.9. Let us choose a set Ki (i.e., K1 or K2) for which the restriction of fs is non-degenerate. For this set, we can form the restriction of fs and Ss . For this restriction, we can take rN := h1 (rj ) (or rN := h2 (rk )) as a last step of the computation scheme (instead of the step rN := fN (rj ; rk )), and the resulting computation scheme will still compute the restriction of fs , and it will still precise for all (crisp) sets. If we were able to compute a non-degenerate function fs by another computation scheme S1 whose complexity is < N computation steps, then we would get a contradiction with our choice of N as the smallest possible complexity of a computation scheme that computes a non-degerenate function. Therefore, the resulting computation scheme is still the \simplest" in the sense that its complexity N is the smallest possible among all computation schemes that compute non-degenerate functions. So, we arrive at the situation where we have the \simplest" computation scheme, and the function at the last step is a function of one variable; we have already proved (in part 6 of this proof) that such situation leads to a contradiction. 9. So, in all ve cases, we arrive at a contradiction. Hence, our initial assumption is false, namely, the assumption that a non-degenerate function of 3 or more variables can 44

be computed by a computation scheme (with unary and binary operations only) that is precise for all (crisp) sets. Q.E.D.

CONCLUSIONS Theoretical. The main theoretical result of this paper is that functions of several interval
or fuzzy variables cannot always be computed precisely if we use only operations with one or two interval (resp. fuzzy) variables. Moreover, for smooth functions f , we show that even the main term in the result of fuzzy (interval) computations cannot always be computed correctly. The accuracy of interval and fuzzy data processing drastically improves if we add weighted scalar product to the list of elementary (hardware supported) operations. For numerical operands, scalar product is already hardware supported in modern computers: by math co-processors. There have been successful attempts to hardware support scalar product of interval operands. it is desirable to hardware support (weighted) scalar product of fuzzy operands as well (at least, some operations with three or more fuzzy operands). and No. EEC-9322370, by a Grant No. PF90{018 from the General Services Administration (GSA), administered by the Materials Research Institute and the Institute for Manufacturing and Materials Management, and by a NASA grant No. NAG 9-757. The authors are greatly thankful to Paul Kainen, Baker Kearfott, Vera Kurkova, and Reza Langari for valuable discussions, and to the anonymous referees for their extremely valuable suggestions and help.

Practical. Therefore, our main practical recommendation is that for fuzzy data processing,

Acknowledgments. This work was partially supported by NSF grants No. CDA-9015006

45

REFERENCES
1] O. Artbauer, \Application of interval, statistical, and fuzzy methods to the evaluation of measurements", Metrologia, 1988, Vol. 25, pp. 81{86. 2] H. Dhirf and D. Sarkar, \Fuzzy arithmetic on systolic arrays", Parallel Computing, 1993, Vol. 19, pp. 1283{1301. 3] W. M. Dong, W. L. Chiang, H. C. Shah, \Fuzzy information processing in seismic hazard analysis and decision making", International Journal of Soil Dynamics and Earthquake Engineering, 1987, Vol. 6, No. 4., pp. 220{226. 4] W. Dong and F. Wong, \Fuzzy weighted averages and implementation of the extension principle", Fuzzy Sets and Systems, 1987, Vol. 21, pp. 183{199. 5] D. Dubois and H. Prade. Fuzzy sets and systems: theory and applications, Academic Press, N.Y., London, 1980. 6] H. L. Frisch, C. Borzi, G. Ord, J. K. Percus, and G. O. Williams, \Approximate Representation of Functions of Several Variables in Terms of Functions of One Variable", Physical Review Letters, 1989, Vol. 63, No. 9, pp. 927{929. 7] R. Fuller and T. Keresztfalvi, \On generalization of Nguyen's theorem", Fuzzy Sets and Systems, 1990, Vol. 4, pp. 371{374. 8] W. A. Fuller, Measurement error models, J. Wiley & Sons, New York, 1987. 9] A. A. Gaganov, \Computational complexity of the range of the polynomial in several variables", Cybernetics, 1985, pp. 418{421. 10] R. Hammer, M. Hocks, U. Kulisch, D. Ratz, Numerical toolbox for veri ed computing. I. Basic numerical problems, Springer Verlag, Heidelberg, N.Y., 1993. 11] E. R. Hansen, Global optimization using interval analysis, Marcel Dekker, N.Y., 1992. 12] R. Hecht-Nielsen, \Kolmogorov's Mapping Neural Network Existence Theorem", IEEE International Conference on Neural Networks, San Diego, SOS Printing, 1987, Vol. 2, pp. 11{14. 13] D. Hilbert, \Mathematical Problems, lecture delivered before the International Congress of Mathematics in Paris in 1900", translated in Bull. Amer. Math, Soc., 1902, Vol. 8, pp. 437{479. 14] R. B. Kearfott and V. Kreinovich (eds.), Applications of Interval Computations, Kluwer, Dordrecht, 1996. 15] A. N. Kolmogorov, \On the Representation of Continuous Functions of Several Variables by Superposition of Continuous Functions of One Variable and Addition", Dokl. Akad. Nauk SSSR, 1957, Vol. 114, pp. 369{373. 16] G. Klir and B. Yuan, Fuzzy sets and fuzzy logic: theory and applications, Prentice 46

17]

18] 19]

20]

21] 22]

23] 24] 25] 26] 27]

Hall, Upper Saddle River, NJ, 1995. V. Kreinovich, \On the problem of recovering the ?function in non-relativistic quantum mechanics", Teoreticheskaya i Mathematicheskaya Fizika, 1976, Vol. 28, No. 1, pp. 56{64 (in Russian); English translation: Theoretical and Mathematical Physics, 1976, Vol. 8, No. 7, pp. 56{64. V. Kreinovich (ed.), Reliable Computing, 1995, Supplement (Extended Abstracts of APIC'95: International Workshop on Applications of Interval Computations, El Paso, TX, Febr. 23{25, 1995). V. Kreinovich, Ching-Chuang Chang, L. Reznik, G. N. Solopchenko, \Inverse problems: fuzzy representation of uncertainty generates a regularization", Proceedings of NAFIPS'92: North American Fuzzy Information Processing Society Conference, Puerto Vallarta, Mexico, December 15{17, 1992, NASA Johnson Space Center, Houston, TX, 1992, Vol. II, pp. 418{426. V. Kreinovich, C. Quintana, L. Reznik, Gaussian membership functions are most adequate in representing uncertainty in measurements, In: Proceedings of NAFIPS'92: North American Fuzzy Information Processing Society Conference, Puerto Vallarta, Mexico, December 15{17, 1992, NASA Johnson Space Center, Houston, TX, 1992, Vol. II, pp. 618{624. V. Kreinovich et al, What non-linearity to choose? Mathematical foundations of fuzzy control, Proceedings of the 1992 International Conference on Fuzzy Systems and Intelligent Control, Louisville, KY, 1992, pp. 349{412. V. Kreinovich and L. K. Reznik, \Methods and models of formalizing a priori information (on the example of processing measurements results)", In: Analysis and Formalization of Computer Experiments, Proceedings of the Mendeleev Metrology Institute, 1986, pp.37{41 (in Russian). U. Kulisch, G. Bohlender, \Features of a hardware implementation of an optimal arithmetic", In: U. Kulisch, W. L. Miranker (eds), A new approach to scienti c computation, Academic Press, Orlando, FL, 1983, pp. 269{290. V. Kurkova, \Kolmogorov's Theorem Is Relevant", Neural Computation, 1991, Vol. 3, pp. 617{622. V. Kurkova, \Kolmogorov's Theorem and Multilayer Neural Networks", Neural Networks, 1992, Vol. 5, pp. 501{506. G. G. Lorentz, \The 13-th problem of Hilbert", in: F. E. Browder (ed.), Mathematical Developments Arizing from Hilbert's Problems, American Math. Society, Providence, RI, 1976, Part 2, pp. 419{430. R. E. Moore, Automatic error analysis in digital computation, Lockheed Missiles and 47

28] 29] 30] 31] 32] 33] 34] 35] 36] 37]

38] 39] 40] 41] 42] 43]

Space Co. Technical Report LMSD-48421, Palo Alto, CA, 1959. R. E. Moore, C. T. Yang, Interval analysis, Lockheed Missiles and Space Co. Technical Report LMSD-285875, Palo Alto, CA, 1959. R. E. Moore, Methods and applications of interval analysis, SIAM, Philadelphia, 1979. M. Nakamura, R. Mines, V. Kreinovich, \Guaranteed Intervals for Kolmogorov's Theorem (and Their Possible Relation to Neural Networks)", Interval Computations, 1993, No. 3, pp. 183{199. M. Ness, \Approximative versions of Kolmogorov's superposition theorem, proved constructively", J. Comput. Appl. Math., 1993. V. M. Nesterov, \Interval analogues of Hilbert's 13th problem", In: Abstracts of the Int'l Conference Interval'94, St. Petersburg, Russia, March 7{10, 1994, 185{186. H. T. Nguyen, \A note on the extension principle for fuzzy sets", J. Math. Anal. and Appl., 1978, Vol. 64, pp. 359{380. H. T. Nguyen and E. A. Walker, A First Course in Fuzzy Logic, CRC Press, Boca Raton, Florida, 1996 (to appear). S. Rabinovich, Measurement errors: theory and practice, American Institute of Physics, N.Y., 1993. M. J. Schulte and E. E. Swartzlander, Jr., \Parallel Hardware Designs for Correctly Rounded Elementary Functions", Interval Computations, 1993, No. 4, pp. 65{88. M. J. Schulte and E. E. Swartzlander, Jr., \Design and applications for variableprecision, interval arithmetic coprocessors", In: V. Kreinovich (ed.), Reliable Computing, 1995, Supplement (Extended Abstracts of APIC'95: International Workshop on Applications of Interval Computations, El Paso, TX, Febr. 23{25, 1995), pp. 166{172. S. M. Shah and R. Horvath, A hardware digital fuzzy inference engine using standard integrated circuits, Information Sciences, 1994, Vol. 1, pp. 1{7. G. N. Solopchenko, \Formal metrological components of measuring systems", Measurement, 1994, Vol. 13, pp. 1{12. D. A. Sprecher, \On the Structure of Continuous Functions of Several Variables", Transactions Amer. Math. Soc., 1965, Vol. 115, No. 3, pp. 340{355. D. A. Sprecher, \An Improvement in the Superposition Theorem of Kolmogorov", Journal of Mathematical Analysis and Applications, 1972, Vol. 38, pp. 208{213. H. Surmann et al., \What kind of hardware is necessary for a fuzzy rule based system?", In: Proceedings of the FUZZ-IEEE'94 International Conference, Orlando, FL, July 1994, Vol. 1, pp. 274{278. M. Takahashi, E. Sanchez, R. Bartolin, J. P. Aurrand-Lions, E. Akaiwa, T. Yamakawa, 48

44] 45] 46] 47] 48] 49] 50] 51] 52] 53] 54]

and J. R. Monties, \Biomedical applications of fuzzy logic controllers", In: Intl. Conference on Fuzzy Logic and Neural Networks, Iizuka, Fukuoka, Japan, 1990, pp. 553{ 556. M. Togai and S. Chiu, \A fuzzy accelerator and a programming environment for realtime fuzzy control", In: Second IFSA Congress, Tokyo, Japan, 1987, pp. 147{151. M. Togai and H. Watanabe, \Expert systems on a chip: an engine for real-time approximate reasoning", IEEE Experts Systems Magazine, 1986, No. 1, pp. 55{62. M. J. Tretter, \Interval analysis isn`t fuzzy is it?", Abstracts for an International Conference on Numerical Analysis with Automatic Result Veri cation: Mathematics, Application and Software, February 25 { March 1, 1993, Lafayette, LA, 1993, p. 104. H. M. Wadsworth, Jr. (editor), Handbook of statistical methods for engineers and scientists, McGraw-Hill Publishing Co., N.Y., 1990. H. Watanabe and W. Detlo , \Recon gurable fuzzy logic processor: a full custom digital VLSI", In: Intl. Workshop on Fuzzy Systems Applications, Iizuka, Japan, 1988, pp. 49{50. T. Yamakawa, \Fuzzy microprocessors { rule chip and defuzzi er chip", In: Intl. Workshop on Fuzzy Systems Applications, Iizuka, Japan, 1988, pp. 51{52. T. Yamakawa, \Intrinsic fuzzy electronic circuits for sixth generation computer", In: M. M. Gupta and T. Yamakawa (eds.), Fuzzy Computing, Elsevier, 1988, pp. 157{181. H. Q. Yang, H. Yao, and J. D. Jones, \Calculating functions of fuzzy numbers", Fuzzy Sets and Systems, 1993, Vol. 55, pp. 273{283. Y. Yoshikawa, T. Deguchi, and T. Yamakawa, \Exclusive fuzzy hardware systems for the appraisal of orthodentic results", In: Intl. Conference on Fuzzy Logic and Neural Networks, Iizuka, Fukuoka, Japan, 1990, pp. 939{942. L. A. Zadeh, \Fuzzy sets", Information and control, 1965, Vol. 8, pp. 338{353. L. A. Zadeh, Outline of a new approach to the analysis of complex systems and decision processes, IEEE Transactions on Systems, Man and Cybernetics, 1973, Vol. 3, pp. 28{44.

49
The author has requested enhancement of the downloaded file. All in-text references underlined in blue are linked to publications on ResearchGate.

Invariance, Maintenance and other declarative objectives of triggers { a formal characterization of active databases
Department of CSE Department of CSE University of Texas at Arlington Arizona State University Arlington, TX 76019, USA Tempe, AZ 85287, USA nakamura@cse.uta.edu chitta@asu.edu

Mutsumi Nakamura

Chitta Baral

1 Introduction and Motivation

In this paper we take steps towards a systematic design of active features in an active database. We propose having declarative speci cations that specify the objective of an active database and formulate the correctness of triggers with respect to such speci cations. In the process we distinguish between the notions of `invariance' and `maintenance' and propose four di erent classes of speci cation constraints. We also propose three di erent types of triggers with distinct purposes and show through the analysis of an example from the literature, the correspondence between these trigger types and the speci cation classes. Finally, we brie y introduce the notion of k-maintenance that is important from the perspective of a reactive (active database) system.

Abstract

Many commercial database systems (such as Oracle, Sybase, IBM's DB2-V2, etc.) and the database standard SQL3 incorporate active features { namely constraints (also referred to as integrity constraints) and triggers. Due to these active features explicit update requests to the database may have several consequences from the request being refused (as it may violate `integrity constraints'), to the request being ful lled with slight changes (as modi ed through `before triggers'), to additional changes triggered by cascade deletes and inserts used in the processing of some constraints and/or ring of `after triggers'. Although originally, integrity constraints were thought of as declarative constraints about database states and de ned which database states were valid and which were not, with the presence of cascade operations in the SQL3 constraints and the use of after triggers to maintain the integrity of the data, there is currently little tradition (except in CF97] and few other cases) of using or following standard software engineering practices of separating speci cation from implementation when designing and developing active databases. This means that 1

often active database developers do not even specify what the purpose of the active features of their database are. Thus there is no way to verify the correctness of the active features. We believe this is one of the reasons why many companies balk at using the active features of a database. Our goal in this paper is to take steps towards developing a systematic approach to the design of active databases. In the process we will develop several language constructs that can be used in specifying the purpose of an active database; formulate the correctness of the procedural triggers with respect to declarative speci cations; and develop guidelines that match the procedural aspects with the declarative aspects. One major hindrance in this pursuit has been the multitude of syntax and semantics (and their complexity) associated with the various di erent implementation of active rules WC96, Pat98] and the complexity of their semantics. In this paper we will follow the SQL3 standard (and the DB2-V2 implementation) to some extent and make certain simpli cations. The basic goal of the active features of a database is to constrain the evolution of the database. Based on analyzing a large class of active database examples, we have identi ed four kind of constraints: state invariance constraints; state maintenance constraints (or quiescent state constraints); trajectory invariance constraints; and trajectory maintenance constraints. In the above constraints there are two dimensions: (i) state vs trajectory (ii) invariance vs maintenance. Intuitively, in state constraints we are concerned about the integrity about particular states, while the trajectory constraints focus on the trajectory of evolution of the database. On the other hand, invariance constraints worry about all states of the database, while the maintenance constraints focus only on the quiescent states. De nition 1 (State Constraints) ADA93] A state constraint s on a database scheme R, is a function that associates with each database r of R a boolean value s (r). A database r of R is said to satisfy s if s (r) is true and is said to violate s if s (r) is false. In the former case, it is also said that s holds in r. A database r is said to satisfy a set of state constraints if it satis es each element of the set. 2 De nition 2 (Trajectory Constraints) A trajectory constraint t on a database scheme R, is a function that associates with each database sequence of R a boolean value t ( ). A database sequence of R is said to satisfy t if t ( ) is true and is said to violate t if t ( ) is false. In the former case, it is also said that t holds in . A database sequence is said to satisfy a set of trajectory constraints if it satis es each element of the set. 2 Often static integrity constraints are expressed through sentences in propositional logic or rst-order predicate calculus while we need temporal operators to express trajectory constraints. We further discuss this in Section 3. 2

1.1 The declarative notions

1.2 The procedural features of an active database

In SQL3 (and DB2-V2) the active features are: Constraints; Before triggers; and After triggers. The constraints in DB2-V2 are of the kinds: NOT NULL constraints, column defaults, unique indexes, check constraints, primary key constraints, and foreign key constraints. Among these, the NOT NULL constraints, unique indexes, check constraints, primary key constraints and some of the foreign key constraints (with NO ACTION or RESTRICT in the action part) refuse updates that violate the constraints. These correspond to the state invariance constraints mentioned in the previous section. On the other hand column default constraints and the foreign key constraints with CASCADE or SET NULL in the action part accept the updates but make additional changes. The former correspond to the state invariance constraints, while the later correspond to the state maintenance constraints. The before triggers act on the update request directly (instead of the updated database) and modify it if necessary while the after triggers are triggered by the update request and can either refuse the update (through a rollback) or force additional changes. Here, the former can implement state and trajectory invariance constraints, while the later can implement any of the four types of constraints. From the above analysis, it seems that certain speci cations such as a state maintenance constraint can be implemented in multiple ways, through a DB2V2 constraint or through after triggers. But the trigger processing architecture treats DB2-V2 constraints very di erently from after triggers. Thus it becomes very di cult to formulate and verify the correctness of the DB2-V2 (or SQL3) active features with respect to speci cations mentioned in Section 1.1. We propose a di erent class of active features that are close to the SQL3 features, but that are distinct in terms of their goals. Our class consists of three kind of procedural features (triggers): refusal triggers, wrapper triggers, and maintenance triggers. Intuitively, the refusal triggers when triggered refuse the update that caused the triggering. Thus refusal triggers can express not only after triggers with refuse actions, but also NOT NULL constraints, unique indexes, check constraints, primary key constraints, and foreign key constraints with NO ACTION or RESTRICT in the action part. The wrapper triggers, wrap the update request by additional changes and thus can express both before triggers and column default constraints. The maintenance triggers1 trigger additional updates and thus can express both after triggers with similar purpose, and foreign key constraints with CASCADE or SET NULL in the action part.

1 In Section 4 we will further divide maintenance triggers to two classes: short-term and long-term. This becomes necessary when we need to worry about reactive response to update requests.

3

Our division of the triggers into the above three classes makes them distinct in terms of what they set out to achieve. This is di erent from the active features in DB2-V2 and SQL3 where there is overlapping of goals making it di cult in designing active databases and formulating their correctness.

2 Actions, Events and Triggers

In this section we describe the necessary mechanism for reasoning about actions and events which we will then use to formulate correctness of triggers with respect to declarative speci cations. Intuitively, an action when executed in a world changes the state of the world. In databases, an action can take several meanings; from the basic insert, delete and update actions to SQL update statements. In this paper by an action we will usually refer to an uninterruptable transaction. To specify the e ects of an action on a database we borrow constructs from the speci cation language A GL93] and our earlier work in BL96, BLT97]. In the following by a uent we will mean a database fact, and by a uent literal we will mean either a database fact or its negation. E ects of actions are speci ed through e ect axioms of the following form:

2.1 Actions and e ects

state. A word of caution is needed regarding the safeness Ull88] of variables in the causal law . The preconditions p1 (X1 ); : : : ; pn (Xn ) will be evaluated as regular queries in the database and a(X ) is an action that could be invoked by a user or an active rule. Thus, variables appearing in Y or in any negated uent in the preconditions must also appear in one of the positive uents in the precondition. If there are variables in X that do not appear in any of the positive uents in the preconditions these arguments must be ground at the time of the invocation of the action, otherwise there will be an error in the execution. Moreover, the variables are schema variables, and intuitively an e ect axiom with variables represents the set of ground e ect axioms where the variables are replaced by ground terms in the domain. Two e ect axioms with preconditions p1 ; : : : ; pn and q1 ; : : : ; qm respectively are said to be contradictory if they describe the e ect of the same action a on complementary f s, and fp1; : : : ; pn g \ fq1 ; : : : ; qm g = ; A state is a set of uent names. Given a uent name f and a state , we say that f holds in if f 2 ; :f holds in if f 62 . A transition function is a 4

a(X ) causes f (Y ) if p1 (X1 ); : : : ; pn (Xn ) (2.1) where a(X ) is an action and f (Y ); p1 (X1 ); : : : ; pn (Xn ) are uent literals (n 0). p1 (X1 ); : : : ; pn (Xn ) are called preconditions. The intuitive meaning of (2.1) is that in any state of the active database execution in which p1 (X1 ); : : : ; pn(Xn ) are true, the execution of the action a(X ) causes f (Y ) to be true in the resulting

mapping of the set of pairs (a; ), where a is an action name and is a state, into the set of states. A collection of e ect axioms (EA) for various actions in our world { with no contradictory e ect axioms in them, de ne a transition function from the set of actions and the set of database states to the set of database states. For every action a and every state ,
0 ) n 00 ; (a; ) = ( where 0 ( 00 ) is the set of uent names f such that EA includes an e ect proposition describing the e ect of action a on f (respectively, :f ) whose preconditions hold in . We now show how the e ect of simple actions such as insert, delete and update can be speci ed using e ect axioms.

insert(R(t)) causes R(t) delete(R(t)) causes :R(t) update(R(t); R(t0)) causes R(t0 ) if R(t) update(R(t); R(t0)) causes :R(t) if R(t)

(2.2) (2.3) (2.4) (2.5)

We now show how we can specify the e ect of actions corresponding to more complex transactions:

Example 1 Consider another transaction a2 from Cha96]:

UPDATE parts SET qonorder = qonhand, qonhand = qonorder WHERE partno = `P207'; Its e ects can be described in our language through the following e ect propositions: a2 causes parts(P 207; Descr; qonhand; qonorder) if parts(P 207; Descr; qonorder; qonhand) a2 causes :parts(P 207; Descr; qonhand; qonorder) if parts(P 207; Descr; qonhand; qonorder) 2

To reason about the e ect of a sequence of actions on a database , we need to extend the function , to allow sequence of actions as its rst parameter. This extension is de ned as follows: ( ]; ) = , and ( ja]; ) = (a; ( ; )). 5

2.2 Events and ECA rules

Triggers (or active rules) in active databases are normally WC96] represented as a triple consisting of events, conditions and actions. In most active database architectures, the sequence of actions that have been executed since the last evaluation point are evaluated to decide on what events have taken place. These events together with the valuation of the condition with respect to the current database state determine whether a particular ECA active rule should be triggered or not. Di erent active databases allow di erent event sets and have di erent ways of evaluating the events. In the simplest case, the events can be the set of inserts and deletes explicitly performed by the last action. On the other hand, in Starburst Wid96] events are de ned in terms of the net e ects of a sequence of transitions. To allow the exibility of de ning a set of events and computing them from a sequence of actions we use the notion of event de nitions from BLT97]. An event de nition proposition is an expression of the form:

where e(X ); e1 (Y1 ); : : : ; em (Ym ) are event literals2 and q1 (Z1 ); : : : ; qn (Zn ) are uent literals. This proposition says that the execution of the action a(W ) ordered in a state in which each of the uent literals qi (Zi ) is true and each of the event literals ej (Yj ) is true generates the event literal e(X ) if the event literal is positive, or removes the event from the set of current events if the event literal e(X ) is negative. If the execution is ordered in a state in which some of the qi (Zi ) or ej (Yj ) does not hold then (2.6) has no e ect. Each of the (schema) variables appearing in X or in a negated event or uent literals, has to appear either in W or in a positive event/ uent literal. The default assumption is that the event persists from one state to another, with two possible exceptions: either the event is consumed by an active rule (see below), or the event is removed by an action based on the speci cation of an event de nition. For example, if we have an expression :e1 after a1 , the execution of the action a1 will cause the event e1 not to be present in the resulting state. Hence, the meaning of \an event is true in a given state" is: the event was induced (i.e. generated) in some state prior to the given one and the event persisted, or the event was induced by an execution of an action in the previous state.

e(X ) after a(W ) if e1(Y1 ); : : : ; em (Ym ); q1 (Z1 ); : : : ; qn (Zn )

(2.6)

Example 2 (Events in Starburst) In Starburst net e ects (or events) are
expressed in words through the following conditions: If a tuple is inserted and then updated, it is considered an insertion of the updated tuple.
2

Like uent literals, an event literal is an event or its negation.

6

If a tuple is updated and then deleted, it is considered as a deletion of the original tuple. If a tuple is updated more than once, it is considered as an update from the original value to the newest value. If a tuple is inserted and then deleted, it is not considered in the net e ect at all. These four premises can be encoded through event de nitions as follows:

e del(G) :e upd(G; F ) e upd(G; I ) :e upd(G; H ) :e add(G)

:e add(G)

e add(H )

after upd(G; H ) if e add(G) after upd(G; H ) if e add(G) after del(F ) if e upd(G; F ) after del(F ) if e upd(G; F ) after upd(H; I ) if e upd(G; H ) after upd(H; I ) if e upd(G; H ) after del(G) if e add(G)

(2.7)

In the above example, at the rst glance it appears that our notation is more verbose than the original rules. For each of the rst three rules we needed two event de nition propositions. This is because we assume that events have inertia. This assumption actually cuts down in writing individual event de nition propositions encoding the persistence of each event due to actions that do not a ect it. For example we do not need to explicitly write:

e add(H ) after del(G) if e add(H ); H 6= G
We characterize events using the function whose input is a set of events, a state, and an action and the output is a set of events. More formally, let E + (E; ; a) = f e : there is an event de nition proposition of the form e after a if e1 ; : : : em; q1 ; : : : ; qn where e1 ; : : : ; em hold in E and q1 ; : : : ; qn hold in g; and let E ? (E; ; a) = f e : there is an event de nition proposition of the form :e after a if e1 ; : : : em ; q1 ; : : : ; qn where e1 ; : : : ; em hold in E and q1 ; : : : ; qn hold in g. (E; ; a) is then de ned as follows: (E; ; a) = (E E + (E; ; a)) n E ? (E; ; a) To be able to compute events with respect to a sequence of actions we extend as follows: (E; ; ]) = E , and (E; ; ja]) = ( (E; ; ); ( ; ); a). 7

As mentioned in Section 1.2, we have three kinds of triggers: wrapper triggers, refusal triggers and maintenance triggers. We represent each of them through ECA rules but distinguish them by the action part. In wrapper triggers the action part is a wrapping function ! which maps an action sequence and a database state to an action sequence. Intuitively, for a single action a, by !(a; ) = a0 we mean that a0 is the action obtained by wrapping a with ! in state . In refusal triggers the action part is the special action REFUSE and in maintenance triggers the action part could be an arbitrary sequence of actions. Thus an ECA rule is a triple he; c; i, where e is an event in our language, c is a temporal formula about the database history, and is either a wrapping function, the special action REFUSE, or a sequence of actions. Often we will represent a single action as the ECA rule h;; True; ai. In this subsection our goal is to give a formal characterization of the evolution of a database due to a sequence of actions in presence of a set of ECA rules. In our characterization we strive to keep a balance between not making the semantics too complicated and at not losing expressibility. We now give an intuitive description of our characterization. Intuitively, after the action sequence (with necessary modi cations due to wrapper triggers) is executed the set of events corresponding to that sequence of actions are evaluated. Then the ECA rules that match with the events are identi ed. We assume (as in many implemented systems Cha96]) that there is a total ordering among the ECA rules with the condition that refusal triggers have higher priority than maintenance triggers. Using this total ordering a priority list of the identi ed ECA rules is created. Then the condition parts of the ECA rules in the priority list are evaluated in the order of their priority and if the condition evaluates to be true, the action part is executed. Since the action part may trigger additional ECA rules, an important concern is how these ECA rules are assimilated into the already existing prioritized list of ECA rules. Two straightforward approaches are to view the list as a stack where newly triggered ECA rules are pushed onto the top of the stack, or to view the list as a queue where newly triggered ECA rules are put at the end of the queue. In both cases, among the newly added rules, the wrapper triggers have the highest priority, the refusal triggers have the second highest priority and the maintenance triggers have the lowest priority. So after the execution of the action part of the currently considered ECA rule, the newly triggered ECA rules are put into the priority list and the evaluation of the ECA rules in the modi ed list are again done based on their priority. This loop of executing the action part of the currently chosen ECA rule, updating the list of ECA rules, and evaluating the list to nd the next ECA rule, continues until the list is empty. During the execution when faced with a trigger whose action part is REFUSE, the database is rolled back. We now formally de ne the function ( ; ; List), where is a database state, is a sequence of actions and List is a prioritized list of ECA rules that are 8

2.3 Characterizing database evolution due to ECA rules

yet to be processed, and the output of the function is a sequence of database states. Once we de ne this function, the evolution of a database state due to an action sequence , can then be expressed by ( ; ; ]). (For lack of space we only consider the simple case where there are no triggers with REFUSE in their action part.)

De nition 3 Evolution due to actions and triggers]
1. ( ; ; List) = if is a state, is an empty sequence, and List = ]. 2. ( ; ; List) is an empty list if is unde ned. 3. ( ; ; List) = if (a) 0 = (!( ); ), where ! is the composition of the wrapping functions of the before triggers triggered by the events in (;; ; ). (If there are no before triggers triggered by the events in (;; ; ) then ! is the identity function; i.e., 8 :!( ) = ). (b) List1 is the list obtained by adding the new ECA rules triggered by the events in (;; ; !( )) to List and adjusting the priorities, (c) eca is the ECA rule with the highest priority in the priority list List1, (d) 0 is the action part in eca, (e) List2 = List1 n fecag, and (f) ( 0 ; 0 ; List2) = . 2 Because of the second condition above, when (!( ); ) is unde ned we obtain as an empty list, and then ( ; ; List) is a sequence of length one with as the only element. Rollbacks can be accounted for by having an additional parameter in which stores the initial state, where the database should be rolled back to when a trigger with REFUSE in its action part is triggered.

Our next step is to formally de ne when a set of ECA rules are correct with respect to invariant and maintenance constraints. For state maintenance constraints, intuitively, the correctness means that the ECA rules force the database to evolve in such a way that the nal state that is reached is a state where all the state maintenance constraints are satis ed. For state invariant constraints, intuitively, the correctness means that the ECA rules force the database to evolve in such a way that the state invariance constraints are satis ed in all states of the trajectory. Since our ultimate goal is to be able to use this de nition to verify the correctness, we add another dimension to the de nition: the class of exogenous actions that we consider; where exogenous actions are the actions that outside users are 9

2.4 Correctness of ECA rules

allowed to execute on the database. It should be noted that the action part of the ECA rules may have actions other than the exogenous actions. We now formally de ne correctness with respect to state invariant and maintenance constraints. state maintenance constraints, A be a set of exogenous actions, and T be a set of ECA rules. We say T is correct with respect to ?si ?sm and A, if for all database states where the constraints in ?si and ?sm hold, and for all action sequences consisting of exogenous actions from A, all the states in the sequence ( ; ; ]) satisfy the constraints in ?si ; and the last state of the evolution given by ( ; ; ]) satis es the constraints in ?sm . 2 To expand the De nition 4 to de ne correctness with respect to trajectory constraints we need to consider a larger evolution window where the database evolves through several exogenous requests each consisting of a sequence of (exogenous) actions. For this we use the notation to denote the last state of the evolution given by ( ; ; ]). We use the notation ( 1 ; 2 ) to denote the last state of the evolution given by ( 1 ; 2 ; ]), and similarly de ne ( 1 ;:::; i ) . state maintenance constraints, ?ti be a set of trajectory invariant constraints, ?tm be a set of trajectory maintenance constraints, A be a set of exogenous actions, and T be a set of ECA rules. We say T is correct with respect to ?si ?sm ?ti ?tm and A, if for all database states where the constraints in ?si and ?sm hold, and for all action sequences 1 ; : : : ; n consisting of exogenous actions from A, all the states in the sequences ( ; 1 ; ]), ( 1 ; 2 ; ]), . . . , ( ( 1 ;:::; n?1 ) ; n ; ]) satisfy the constraints in ?si ; all the states 1 ; : : : ; ( 1 ;:::; n ) satisfy the constraints in ?sm ; the trajectory obtained by concatenating ( ; 1 ; ]) with ( 1 ; 2 ; ]), . . . , ( ( 1 ;:::; n?1 ) ; n ; ]) satisfy the constraints in ?ti ; and the trajectory ; 1 ; : : : ; ( 1 ;:::; n ) satis es the constraints in ?tm . 2 Example 3 Consider the relational Schema: Employee(Emp#; Name; Salary; Dept#) Dept(Dept#; Mgr#) We have two state maintenance constraints: (i) If (e; n; s; d) is a tuple in Employee then there must be a tuple (d0 ; m0 ) in 10

De nition 4 Let ?si be a set of state invariant constraints, ?sm be a set of

De nition 5 Let ?si be a set of state invariant constraints, ?sm be a set of

The set of maintenance triggers that can be shown to be correct with respect to the above maintenance constraints and exogenous actions consists of the following trigger. For any Delete (e; n; s; d) from Employee, if (d; e) is a tuple in Dept, delete that tuple from Dept and delete all tuples of the form (e0 ; n0 ; s0 ; d0 ) from Employee, where d = d0 . 2 We can now make the formal claim that the above maintenance triggers are correct with respect to the above mentioned state maintenance constraints and exogenous actions.

Dept such that d = d0 . (ii) If (d; m) is a tuple in Dept, then there must be a tuple (e0 ; n0 ; s0 ; d0 ) in Employee such that d = d0 and m = e0 The only allowable exogenous action is del(Employee(E; N; S; D)).

3 Elaborating on our abstractions

In Section 1.1 we de ned state constraints and trajectory constraints as boolean functions on database states and sequences of database states respectively. Our next concern is how to represent such functions parsimoniously. One approach is to use logical constructs. In this section we introduce several language constructs that we proposed to use in specifying state and trajectory constraints and show their use through examples. We start with a description of the mail order business active database from Cha96]. To save space and to make it readable without knowing the syntax of triggers in DB2-V2, we describe the triggers of this active database in words, and not in the syntax of DB2-V2. The ve tables that are mentioned in the database in Cha96] and their attributes are: Cust(C#, Cname, Caddr, Baldue, Creditlmt) Suppl(S#, Sname, Saddr, Amtowed) Inv(It#, Iname, S#, Qonhand, Unitsalpr, Qonorder, Unitorderpr, Orderthreshold, Minorder) Purch(Orddate, Ordtime, S#, It#, Qordered, Dtrecvd, Qrcvd, Unitpr) Sales(Sldate, Sltime, C#, It#, Qsold, Unitpr, Totalsale) Due to lack of space we only consider two of the eight triggers given in Cha96], and identify the state and trajectory constraints corresponding to these triggers. (PT1: a wrapper trigger) When inserting into the Purch table modify the tuples (to be inserted) 11

3.1 The tables

3.2 A subset of the triggers

so that for any It#, the values for S# and Unitpr are the values for S# and Unitorderpr for that It# in the Inv table. (Note that because of the constraints associated with the Purch table that allow Orddate and Ordtime to get the current date and time by default, It# and Qordered are the only pieces of information required to do insertions into the Purch table.) (PT2 { a maintenance trigger) After inserting an order for an It# to Purch, update the Inv table by increasing the Qonorder (in the tuple with that It#) by Qordered. We rst list the constraints in a high level language that we developed and then explain the meaning of the constructs in this language. (C1) ForAll It#: Inv:S # = Purch:S # is invariant (C2) ForAll It#: Inv:Unitorderpr = Purch:Unitpr is invariant (C3) newtuple Purch requires Orddate = Currentdate and Ordtime = Currenttime (C4) ForAll It#: Purch:Sum(Qordered) ? Purch:Sum(Qrcvd) = Inv:Qonorder is maintained Among the above constraints, the rst two are state invariant constraints, the second is a trajectory invariant constraint, and the third is a state maintenance constraint. These constraints can be speci ed in rst-order logic with temporal and aggregate constructs. We specify them using such constructs below with the assumption that all free variables are universally quanti ed and all the existentially quanti ed variables are denoted by underscores \ ". (C1') (Inv(It#; ; S1 ; ; ; ; ; ; ) ^ Purch( ; ; S2 ; It#; ; ; ; )) ) (S1 = S2 ) (C2') (Inv(It#; ; ; ; ; ; UOP1 ; ; ) ^ Purch( ; ; ; It#; ; ; ; UP2 )) ) (UOP1 = UP2 ) (C3') (:Purch(OD; OT; S #; It#; ; ; ; )^ nexttime (Purch(OD; OT; S #; It#; ; ; ; ))) ) nexttime (OD = date ^ OT = time) (C4.1') R1 (It#; Sum Qord) = It# GSum Qordered(Purch) (C4.2') R2 (It#; Sum Qrcvd) = It# GSum Qrcvd(Purch) (C4') (quiescent ^ R1 (It#; Sum Qord) ^ R2 (It#; Sum Qrcvd) ^ Inv(It#; ; ; ; ; Qonorder; ; ; )) ) (Sum Qord?Sum Qrcvd = Qonorder) 12

3.2.1 The corresponding constraints

The rst order formulas (C1') and (C2') are low level representations of the state invariant constraints (C1) and (C2) respectively. The temporal formula (C3') is a low level representation of the trajectory invariant constraints (C3) and the temporal operator nexttime in (C3') has the usual FTL (future temporal logic) CT95] meaning. Next we have the formulas (C4.1'), (C4.2') containing grouping aggregation expressions using the notation3 from the text book SKS96], and (C4') which are a low level representation of the state maintenance constraint (C4). Note the di erence between (C4') and (C1'-C2'). Since the former is a maintenance constraint, we use the proposition quiescent in the left hand side of the implication, meaning that the implication only holds in quiescent states. On the other hand the implications in (C1'-C2') must hold in all states.

Proposition 1 Let DB be the schema declaration in Section 3.1, and the only allowable exogenous action is `Insert into Purch with Dtrecvd and Qrcvd as null, and Qordered as a positive value'. Then in the context of DB the set of triggers fPT1,PT2g, is correct w.r.t. the set of constraints fC1, C2, C3, C4g, and the above mentioned exogenous action. 2

4 Interrupting exogenous updates
So far we have (implicitly) assumed that if new exogenous update requests come in when the active database system is in the midst of processing ECA rules due to a previous exogenous update, the new requests are kept in hold until the processing (due to the previous update) comes to an end. Such an assumption is perhaps acceptable when the exogenous updates are not that frequent and/or trigger processing is not that time consuming, and there is no guaranteed quality of service requirement. With the popularity of e-commerce where updates to the database would often be due to e-transactions over the web, companies may require a guaranteed quality of service requirement. In particular, they may require immediate response to requests. In such a case, it may be a good idea to partition maintenance triggers to two kinds short term and long term, with the idea that in order to give reactive response to new update requests, processing of long term maintenance triggers may be postponed in favor of processing the new update request.
3 In this notation the general form is: G1 ;G2 ;:::;Gn GF1 A1 ;F2 A2 ;:::;Fm Am (E ), where E is any relational-algebra expression, G1 ; : : : ; Gn constitute a list of attributes on which to group, each Fi is an aggregate function, and each Ai is an attribute name. The meaning of the operation is de ned as follows. The tuples in the result of expression E are partitioned into groups such that: (i) All tuples in a group have the same values for G1 ; : : : ; Gn . (ii) Tuples in di erent groups have di erent values for G1 ; : : : ; Gn . The groups now can be identi ed by the values of the attributes G1 ; : : : ; Gn of the relation, and for each group (g1 ; : : : ; gn ), the result has a tuple (g1 ; : : : ; gn ; a1 ; : : : ; am ) where, for each i, ai is the result of applying the aggregate function Fi on the multi-set of values for the attribute Ai in the group.

13

The formulation of correctness in such a case becomes tricky, and we have made a small start in that direction. In this we only consider condition-action triggers, and consider all triggers to be long term. Before we get to our de nition of correctness in such cases, we have the following notation. Let T be a set of condition-action triggers, and be a database state. By T ( ) we denote the action of the trigger which has the highest priority among the triggers whose conditions are satis ed in . We also have the following additional notations: 0 0 T ( ) = T ( ) and T = . k+1 ( ) = T ( k+1 ) and k+1 = ( K ( ); k ).

De nition 6 (k-maintenance) Let T be a set of condition-action triggers, ?

T

T

T

T

T

be a set of long term maintenance constraints, S be a set of states, and A be a set of allowable exogenous actions. By Closure(S; T; A) we denote the smallest set of states that is a superset of S and that satis es the properties that if 2 S , then for an exogenous action a from A, (a; ) 2 S , and ( T ( ); )) 2 S . We say T k-maintains the maintenance constraints ? from S and A, if for each 0;:::; T k satis es ?. state in S , the sequence T 2

5 Conclusion and future work

Intuitively, the notion of k-maintenance means that the active database system will get back to consistency (with respect to ?) if it is given a window of opportunity of processing k triggers without any outside interference in terms of new update requests. An important aspect of such a notion of k-maintainability is that in reactive (active database) systems, if we know that our system is k-maintainable, and each transition takes say t time units, then we can implement a transaction mechanism that will regulate the number of exogenous actions allowed per unit time to be k 1 t . On the other hand, given a requirement that we must allow m requests (exogenous actions) per unit time, we can work backwards to determine the value of k, and then nd a set of triggers to make the system k-maintainable.

In this paper we have taken several steps towards the systematic design of active features in an active database. The main steps that we have taken are identifying a few constructs for speci cation, classifying triggers into distinct classes based on their purpose, linking the trigger classes with the speci cation classes, formulating correctness of triggers with respect to a given speci cation, elaborating our formulation through examples and brie y introducing the notion of k-maintainability. Due to space limitations we were not able to detail our formulation (especially, the prioritization used in de ning and the di erentiation between row and statement triggers) and show the design methodology with respect to a large 14

example. In the full version we will show how our formulation in this paper can be used in systematically developing the triggers for the complete example in Cha96], starting from a speci cation which is not given in Cha96]. Our main future work will be to develop composition methods and theorems so that given sets of triggers T1 and T2 that are correct with respect to speci cations S1 and S2 respectively, we can construct triggers that are correct with respect to S1 S2 . We also plan to identify additional speci cation constructs with matching trigger sub-classes, and further elaborate on our notion of k-maintainability.

References
ADA93] P. Atzeni and V. De Antonellis. Relational database theory. The Benjamin/Cummings publishing company, 1993. BL96] C. Baral and J. Lobo. Formal characterization of active databases. In Proc. of International Workshop on Logic in Databases { LID'96 (LNCS 1154), pages 175{195, 1996. BLT97] C. Baral, J. Lobo, and G. Trajcevski. Formal characterization of active databases: Part II. In DOOD 97, 1997. CF97] S. Ceri and P. Fraternali. Designing database applications with objects and rules { the IDEA methodology. Addison-Wesley, 1997. Cha96] D. Chamberlin. Using the new DB2: IBM's Object-relational database system. Morgan Kaufmann, 1996. CT95] J. Chomicki and D. Toman. Implementing temporal integrity constraints using an active dbms. IEEE transactions on knowledge and data engineering, 1995. GL93] M. Gelfond and V. Lifschitz. Representing actions and change by logic programs. Journal of Logic Programming, 17(2,3,4):301{323, 1993. Pat98] N. Paton. Active rules in database systems. Springer-Verlag, 1998. SKS96] A. Silberschatz, H. Korth, and S. Sudershan. Database System Concepts. McGraw Hill, 3rd edition, 1996. Ull88] J. Ullman. Principles of Database and Knowledge-base Systems, volume I. Computer Science Press, 1988. WC96] J. Widom and S Ceri, editors. Active Database Systems - Triggers and Rules for advanced database processing. Morgan Kaufmann, 1996. Wid96] J. Widom. The Starbust rule system. In J. Widom and S Ceri, editors, Active Database Systems, pages 87{110. Morgan Kaufmann, 1996.

15

ON HARDWARE SUPPORT FOR INTERVAL COMPUTATIONS
AND FOR SOFT COMPUTING: THEOREMS
Hung T. Nguyen, Vladik Kreinovich, Member, IEEE, Vyacheslav Nesterov,
and Mutsumi Nakamura

Abstract. This paper provides a rationale for providing hardware supported functions of
more than two variables for processing incomplete knowledge and fuzzy knowledge. The
result is in contrast to Kolmogorov's theorem in numerical (non-fuzzy) case.

1. INTRODUCTION
In this paper, we show that for interval computations and for processing fuzzy data (i.e.,
for soft computing), it is desirable to have hardware supported operations with more than
two operands.
Before we formulate the problem and go into technical details, we would like to emphasize the importance of this problem by briey describing in Subsection 1.1 the practical
origin (and practical necessity) of interval computations and soft computing.

1.1. Estimating accuracy of the results of data processing:
crisp and fuzzy cases
Data processing: why? To make decisions, we must have some information about the

values of the physical quantities. For example, in order to decide whether to approve
the scheduled launch of a Space Shuttle, we must know the characteristics of the Shuttle
(to make sure that all its systems work), and weather conditions around the launch site
during the launch time. Some of these characteristics can be measured directly: e.g.,
characteristics of the Shuttle's electric systems can be measured by testers. Some of the
desired characteristics can be estimated by experts: e.g., some experts meteorologists can
provide us with reasonably good short-time weather predictions for a given area.
Hung T. Nguyen is with the Department of Mathematical Sciences, New Mexico
State University, Las Cruces, NM 88003, USA, email hunguyen@nmsu.edu
Vladik Kreinovich is with the Department of Computer Science Department, University of Texas at El Paso, El Paso, TX 79968, USA, email vladik@cs.utep.edu
Vyacheslav Nesterov is with the Institute of New Technologies, P. O. Box 52, St.
Petersburg 256, 195256 Russia, email nest@into.nit.spb.su
Mutsumi Nakamura is with the Department of Mathematics, University of Texas at
Austin, Austin, TX 78712, USA, email mutsumin@math.utexas.edu
1

In some cases, however, it is very dicult (or even impossible) to measure the characteristic y that we are interested in, and there are no experts who can predict the values of
these characteristics. For example, it is very dicult to directly measure the temperature
inside the jet chamber (because this temperature is extremely high); if we are planning a
mission to a new planet, it is simply impossible to directly measure the characteristics of
the new environment before the mission actually gets there, and often, no expert can help.
If we are interested in the value of such a characteristic y, and we cannot estimate y
directly (either by measurement, or by using experts), then a natural idea is to estimate y
indirectly, i.e.:
 to estimate some other (easier to estimate) quantities x1 ; :::; xn that are related to y,
and then
 to compute the estimate y~ for y based on the estimates x~1 ; ::; x~n for x1 ; :::; xn.
This process is called data processing, and this is what super-computers are doing most of
the time: from measured characteristics x~i of observed collisions in the accelerators, they
reconstruct the (directly unobservable) properties of the elementary particles; from the
results x~i of geophysical measurements, computers predict the amount y of oil (or other
mineral) in a given area, etc.
In this paper, we will assume that we already know what characteristics xi to measure,
and how to reconstruct y from xi . In other words, we will assume that we know an algorithm
f (x1; :::; xn) that transforms the values of xi into an estimate for y. This algorithm is
not necessarily simple: e.g., in geophysics, it may involve solving a complicated non-linear
integral equation (\inverse problem"); in elementary particle physics, it may involve solving
a system of non-linear operator quantum equations, etc.

The result of data processing is never absolutely accurate. The assumption that

we know the algorithm f means that if we know the exact values of the variables x1 ; :::; xn,
we can then apply the algorithm f and compute the exact value of y. In reality, however, we only know some estimates x~i for xi that are obtained either by measurements
or by an expert estimation. Measurements are never 100% precise; expert estimates are
not absolutely precise either. As a result, the available values x~i dier from the actual
(unknown) values xi ; therefore, the estimate y~ = f (~x1; :::; x~n) that we obtain by processing
the available data may dier from the desired value y = f (x1; :::; xn).

In real-life applications, we must know the accuracy of the result of data processing. For practical purposes, it is important to know how dierent the result y~ of data
processing can be from the actual value y.

2

For example, if we want to decide whether a particular well is worth drilling, and the
estimate for the amount of oil is y~ = 100 mln. tons, then before we start drilling, we
would like to know whether this is, say, 100  1, in which case, we should probably start
drilling, or it is 100  100 (maybe 100, maybe 0, maybe 200), in which case we would rather
undertake further (and more accurate) measurements.
In this paper, we consider the problem of nding this accuracy.

Simplest case: measurements only. Before we start analyzing the general case, where

both measurement results and expert estimates are present, let us consider the simplest
case, where there is no expert knowledge, and all the data come from the measurements.
In traditional measurement theory (see, e.g., [8,47,35]), it is usually assumed that we know
the probabilities of dierent values of a measurement error. These values can be obtained
if we calibrate the measuring instrument, i.e.:
 we use the calibrated instrument in conjunction with a much more accurate one (called
a standard) in several measurements;
 for each measurement, we compute a dierence e(k) = x~(k) ? x(k) between the results
of these two instruments, and use this dierence as an estimate of the error of the
measurement performed by the calibrated instrument;
 reconstruct the error probability distribution from the recorded sample errors e(1) , ...,
e(N ) .
For the situations in which we know the probabilities of dierent errors, there exist numerous methods that compute statistical characteristics of the resulting error.
In many real-life situations, however, the values of the probabilities are not known:
 in advanced measurements (in radio-astronomy, in elementary particle physics, etc),
we are using measuring instruments that have the highest accuracy possible, so, there
is simply no \more accurate" measuring instrument that we can for calibrating;
 in manufacturing applications, we can potentially calibrate all the sensors that we
use, but this calibration would cost much more than the sensors themselves, so it is
usually not done.
In these situations, the manufacturer of the measuring instrument provides us with the
guaranteed accuracy , i.e., with a guaranteed upper bound of the error x = x~ ? x (e.g.,
\error cannot exceed 0.1"). If our measurement results is x~, then the possible values of
x = x~ ? x form an interval [~x ? ; x~ + ]. Since we are dealing with intervals, the entire
area is called interval computations (see, e.g., [29,11,10,18,14]).
3

The set of possible values of an error is not necessarily an interval. For example,
suppose that we are measuring the current inside the computer, and we know that the
error cannot exceed a certain value . If we know nothing else about the error, then we
may conclude that the error belongs to the interval [?; ]. However, we may know that
the error is caused by the inuence of a nearby magnetic memory element, which can be
in two possible states (corresponding to \0" and \1"). In this case, the error is either
positive, or negative (depending on the state), but never 0; actually, the error can never
be smaller than some value . In this case, the set X of possible values of the error is
not an interval, but a union of two intervals: X = [?; ?] [ [; ]. There can be more
complicated cases, in which the error can be described by more complicated (crisp) sets X
of possible values.
In this case, our problem takes the following form:
We know:
 an algorithm f that transform n real numbers x1; :::; xn into a real number y =
f (x1; :::; xn);
 sets X1  R, ..., Xn  R that contain the actual values of xi ;
We must compute: The set Y of possible values of y:

Y = ff (x1; :::; xn) j x1 2 X1; :::; xn 2 Xng

(1:1)

This set Y is usually denoted by f (X1; :::; Xn).
A measuring instrument can measure several dierent quantities x1; :::; xn at a time.
In this case, in addition to the information about the possible errors of each measurement,
the manufacturer can guarantee that certain combinations of errors are impossible: e.g.,
it can happen that x1 attains its largest possible value , and it can happen that x2
attains its largest possible value , but they can never attain these extreme values at the
same time, because of the restriction that x21 + x22  2 (this situation happens, e.g.,
if we measure geographical coordinates of a point). Such an information can be described
by a set X  Rn of all the tuples that the manufacturer believes can be possible values of
errors (x1; :::; xn). In this case, the problem takes the following form:

4

We know:
 an algorithm f that transform n real numbers x1; :::; xn into a real number y =
f (x1; :::; xn);
 a set X  Rn that contains the actual value of ~x = (x1; ::; xn);
We must compute: The set Y of possible values of y:

Y = ff (x1; :::; xn) j (x1; :::; xn) 2 X g

(1:2)

This set Y is usually denoted by f (X ).
The previous formulation is a particular case of this one if we take X = X1  :::  Xn.

General case: processing data that includes expert knowledge as well. In many

cases, in addition to measurements results, we have expert's knowledge about the variables
x1 ; :::; xn. For example, in order to make a decision on what doze of radiation to assign to
a patient, we must know not only the characteristics that are measurable (like blood count,
tumor size, etc), but the characteristics that can only be estimated by an expert (e.g., the
granularity of a tumor can be \small" or \medium"). We want to process this informal
information automatically, therefore, we must be able to represent it in the computer.
A word like \medium-size" does not describe one particular value; it can correspond to
several dierent values; some of them are more reasonably described as \medium-size",
some values can be in principle described as such, but only occasionally. To describe the
meaning of each word, we ascribe to every real number x a value (x) 2 [0; 1] that describe
to what extent it is reasonable to assume that x is, say, medium-size (1 means that it is
absolutely reasonable, 0 that it is not reasonable at all). The resulting function is called a
membership function, or a fuzzy set.
In some cases, the expert's informal statement describes not one variable, but several
of them. For example, if we say that a point with coordinates x1 ; x2 is close to 0, this
means that both x1 and x2 are close to 0. Such knowledge can be represented by a function
from R2 to [0,1]. This membership function is called a fuzzy subset of R2. If we have such
information about xi , and we want to estimate y, we get the following problem:
We know:
 a function f of n variables;
 a fuzzy set X  Rn that describes our knowledge about ~x = (x1 ; :::; xn).
We want: to describe the resulting knowledge about y in terms of a fuzzy set Y .
This problem was formulated, e.g., in [1,46,39], and it has appeared in many practical
cases, including:
5

 testing jet engines [22,20,21];
 seismic analysis [3,4];
 image processing [19,20,21],
etc.

The desired description of the set Y is known as extension principle. This principle was
proposed by Zadeh in his pioneer paper [53] (see also [54] and [5]), and it is based on the
following idea:
A real number y~ is a reasonable value of y if and only if
there exist values x~1; :::x~n for which
x~1 is a possible values of x1 , x~2 is a possible value of x2 , ..., and f (~x1; :::; x~n) = y~.
If we follow the traditional fuzzy set theory and interpret \and" as min, and \there
exists" as sup, then we arrive at the following formula:

Y (y) = sup (min(X (~x); f (~x; y));
~x2Rn

where f is a characteristic function of the graph of the function f (i.e., (~x; y) = 1 if
f (~x) = y, and 0 otherwise). Due to this formula, values ~x for which f (~x) 6= y, do not
inuence on Y (y). Therefore, this formula can be rewritten as follows:

Y (y) = sup X (~x):

(1:3)

~x:f (~x)=y

This formula is called the extension principle, and the resulting fuzzy set Y is denoted by
f (X ).
If instead of X , we have n separate fuzzy sets X1 ; :::; Xn that describe our knowledge
about x1 ; :::; xn, then similar arguments lead to a formula

Y (y) = sup min(X1 (x1); :::; X (xn)):
~x:f (~x)=y

n

(1:4)

The resulting fuzzy set Y is denoted by f (X1; :::; Xn).
Comments.
1. In particular, if we take elementary arithmetic operations (+; ; ?, etc) as f , we get
the denition of arithmetic operations with fuzzy operands X1; :::; Xn.

2. The statement that we have just formalized contains two logical terms: \and" and
\there exists". So, to formalize it, we must formalize what these two logical terms mean.
6

\There exists" can be viewed as an innite \or": namely, \there exist x~1 ; :::; x~n with
a certain property" means that this property is either true for, say, (0:0; :::; 0:0), or for
(1:1; 0:2; :::; 2:3), or for any of innitely many tuples of n real numbers. Therefore, to get
an interpretation of \there exists", we must choose an appropriate fuzzy interpretation
f_(a; b) of _ and apply the resulting _?operation f_ innitely many times (i.e., apply it
to N tuples and then take N ! 1).
In fuzzy logic, many dierent _?operations have been proposed (e.g., f_(a; b) =
a + b ? a  b); these operations are also called t?conorms. A usual (and natural) restriction
on a t?conorm f_ comes from the fact that for every two statement A and B , our degree
of belief in A _ B must be at least as big as the degree of belief in each of these statements
A and B . If we denote the degree of belief in A by t(A), then this condition turns into
f_(t(A); t(B ))  t(A) and f_ (t(A); t(B ))  t(B ). In other words, for every a and b,
f_(a; b)  max(a; b).
If we choose one of the known t?conorms for which f_(a; b) > max(a; b) (e.g., if we
choose f_ (a; b) = a + b ? ab), then, the more times we apply f_ , the larger the resulting
degree of belief, and in the limit, we get 1. For example, for f_ (a; b) = a + b ? ab =
1 ? (1 ? a)  (1 ? b), disjunction of N formulas with the same degree of belief a 2 (0; 1) leads
to f_(a; : : :; a) = 1 ? (1 ? a)N , and this expression ! 1 as N ! 1. (Here, f_(a; b; :::; c)
stands for f_(:::(f_(a; b); :::); c), i.e., it means that we apply the _?operation N times.)
A similar result can be proven for any (strict or non-strict) Archimedean t?conorm (see,
e.g., [16,34]). Hence, for such operations, we will have Y (y) = 1 for all y, which makes
no sense.
Therefore, when we dene operations with fuzzy operands, the only meaningful interpretation of \there exists" is through the _?operation f_ (a; b) = max(a; b), for which for
every property A(x), the degree of belief in \there exists x such that A(x)" is equal to the
\maximum" (or, to use the precise mathematical term, supremum) of all the degrees of
belief t(A(x)) for all x.
As far as an &?operation is concerned, we can use an arbitrary function f& : [0; 1] 
[0; 1] ! [0; 1] that extends a usual & operation dened for binary values (with 0 as false
as 1 as true), i.e., an arbitrary function f& for which f& (0; 0) = f& (0; 1) = f& (1; 0) = 0
and f& (1; 1) = 1.
For such interpretation of \and" and \there exists", formula (2) takes the following
form:
Y (y) = sup f& (X1 (x1); :::; X (xn ));
(1:4a)
~x:f (~x)=y

n

7

where f& (a; b; :::; c) stands for f& (:::(f&(a; b); :::); c) (i.e., it means that we apply the
&?operation several times).
Our results will be true for an arbitrary choice of an &?operation.

1.2. How is the problem of
estimating accuracy of the results of data processing
solved now?
In general, the problem is computationally intractable even for crisp sets (even
for intervals). It has been proven that even for the case when the sets Xi are crisp (and
are intervals), and the algorithm f is actually a polynomial, the problem of computing the
set Y exactly is computationally intractable (NP-hard) [9].

This result does not mean, of course, that the problem of computing Y is not practically solvable. The sets Xi describe the inaccuracy of the measuring devices, or the
inaccuracy of an expert. These inaccuracies are never known precisely, therefore, it would
be quite sucient to have an approximate description of Y . Several methods are known
for that:

Case when estimates are pretty accurate: linearization technique. If the esti-

mates x~i for xi are pretty accurate, then we can neglect the terms that are quadratic
(or of higher order) in xi = x~i ? xi , and thus, for given estimates x~i , describe
y = f (x1; :::; xn) = f (~x1 ? x1 ; :::; x~n ? xn ) by the following approximate formula:
y  flin = y~ ? f;1x1 ? ::: ? f;nxn ; where by f;i , we denoted the partial derivative of f
w.r.t. xi :
@f (~x ; :::; x~ ):
f;i = @x
1
n
i

In this case, for interval Xi = [~xi ? i ; x~i + i ], we have Y  Xlin = flin (X1; :::; Xn) =
[~y ? ; y~ + ], where  = jf;1j1 + ::: + jf;njn (see, e.g., [35]).

Another case when we can estimate Y is when the function f is monotonic in each
of the variables; in this case, if, e.g., f is monotonically increasing, and Xi = [x?i ; x+i ], we
have Y = [f (x?1 ; :::; x?n ); f (x+1; :::; x+n )].
For these two cases (small errors or monotonic f ), there also exist ecient techniques
for fuzzy data processing [4,51].

Expert estimates are rarely very accurate, so, other methods are needed. Mea-

surements typically lead to accurate estimates of xi , so, if all the estimates come from
8

measurements, we can usually apply linearization techniques. Expert estimates, on the
other hand, are rarely very accurate. So, if we have expert estimates, we usually cannot
neglect the squares of the errors, and therefore, we need other methods for estimating the
error of the result of data processing. For this case, the following idea has been proposed
by R. Moore [27,28] (see also [29,11,10,14]). No matter what high-level language we use
to describe an algorithm f , inside a computer, this algorithm is translated into a sequence
of elementary operations (usually, +, ?, , :, etc).
For example, a function f (x1; x2; x3) = (x1 + x2 )2 + 2  x3 is computed as follows (we will
enumerate all the input and intermediate values by r1 ; r2, ...): rst, we have r1 = x1,
r2 = x2 , and r3 = x3 ; then, we start computing further values:
 we apply + and get r4 = r1 + r2 = x1 + x2 ;
 we apply the square operation and get r5 = r42 (so, r5 = (x1 + x2 )2).
 we take r6 = 2;
 we compute r7 = r6  r3 ;
 nally, we compute r8 = r5 + r7 ; this is the desired value y.
The idea is to repeat the same sequence of operations, but with intervals instead of numbers.
Elementary operations g are usually monotonic, so, we can explicitly compute g(X1; :::; Xn)
for intervals Xi : e.g., for addition g(x1; x2) = x1 + x2 , we have g([x?1 ; x+1]; [x?2 ; x+2]) =
[x?1 + x?2 ; x+1 + x+2 ].
For example, if we start with the intervals R1 = X1 = [0; 1], R2 = X2 = [0; 1], and
R3 = X3 = [1; 2], we get the following sequence of computations:
 we apply + and get R4 = R1 + R2 = [0; 1] + [0; 1] = [0; 2];
 we apply the square operation and get R5 = R42 = [0; 4];
 take R6 = [2; 2];
 compute R7 = R6  R3 = [2; 2]  [1; 2] = [2; 4];
 nally, we compute Y~ = R8 = R5 + R7 = [0; 4] + [2; 4] = [2; 8]; this is the desired
estimate for Y .
It has been proven that for intervals Xi , the resulting estimate Y~ contains the desired
interval Y .
A similar procedure can be used for fuzzy processing: here, we implement elementary
operations g using extension principle.

These new methods do not always lead to accurate results. The results of these

computations do not always lead to the exact value of Y ; even for intervals Xi , the result
9

depends on the exact order of the operations performed to compute f . For example, we can
compute f (x1; x2) = x1  x2 by simply multiplying the two numbers, or we can compute the
same product by using a more complicated formula x1  x2 = (1=4)  [(x1 + x2 )2 ? (x1 ? x2 )2 ].
If X1 = X2 = [1; 2], then the rst algorithm leads to the estimate Y~ = [1; 4] that coincides
with the desired interval Y = f (X1; X2). However, the second algorithm leads to a dierent
result: indeed, this algorithm can be represented as a following sequence of computations:
 r3 := r1 + r2.
 r4 := r32 .
 r5 := r1 ? r2.
 r6 := r52 .
 r7 := r4 ? r6.
 r8 := 4.
 r9 := r7 =r8.
So, for Xi = [1; 2], we get R3 = [2; 4], R4 = [4; 16], R5 = [?1; 1], R6 = [0; 1], R7 = [3; 16],
R7 = [4; 4], and Y~ = R9 = [0:75; 4] 6= Y = [1; 4]. The resulting interval Y~ contains extra
points [0:75; 1).

1.3. Going from numbers to intervals and fuzzy sets
drastically increases computation time,
so hardware support is in order
Hardware support is necessary. We have already mentioned that even for real num-

bers, data processing algorithm that computes f (x1; :::; xn) can be quite complicated and
time-consuming. When we analyze accuracy of data processing, we must go from operations with numbers to operations with intervals, crisp sets, or fuzzy sets. For example,
when we go from precise numbers to fuzzy sets, then instead of processing n numbers
according to the known algorithm f , we have to solve complicated optimization problems
to nd Y (y). This increases computation time drastically: for example, in a crisp case,
to compute a sum of two numbers x1 + x2 , we must process these two numbers xi only;
all it takes is one arithmetic operation. To compute a sum of two fuzzy operands, instead
of processing two numbers, we must take as input the values X1 (x1 ) and X2 (x2 ) that
correspond to dierent xi . Just because of the necessity to process such a long input, these
computations are inevitably long. How to speed up fuzzy computations?
One known way to speed up computations in general is to design a hardware support
for them. This idea worked perfectly well, e.g., for oating point operations that had
initially been implemented in software. So, it is desirable to design hardware support for
interval and fuzzy computations as well.
10

A word of warning: Hardware support is not sucient. Hardware support does

bring a speed-up, and is, therefore, a great idea. However, the very fact that we have a
hardware support of several basic operations with intervals, crisp sets, and/or with fuzzy
sets, does not necessarily mean that we have improved the quality of the result (we are
thankful to the anonymous referee who helped us clarify this point).
As we have shown in Subsection 1.2, if we start with an expression
(1=4)  [(x1 + x2)2 ? (x1 ? x2)2 ]
and simply substitute interval operations instead of operations with numbers, we will get
an overestimation irrespective on whether we implement these operations in software or in
hardware. The only way to get the exact estimate is to transform this expression into an
equivalent one x1  x2 for which interval computations give the exact estimate.
An even more striking example is a function of one variable dened as f (x1) = x1 ? x1 .
This function is, of course, identically equal to 0, so, for every interval X1, we should get
f (X1) = f0g. However, if we take X1 = [0; 1], and apply interval subtraction, we will get
X1 ? X1 = [0; 1] ? [0; 1] = [?1; 1]. Whether we are implementing interval subtractions in
hardware or in software, we get an overestimation. Again, the only way to get the exact
estimate is take into the consideration that the two terms in the original expression cancel
each other, and thus, to transform the original expression x1 ? x1 into an equivalent one
0.
So, in addition to hardware, we need some appropriate symbolic reasoning engine (of
the type implemented in Macsyma or in Mathematica) that would transform the original
expression into an equivalent one that will lead to the precise (or at least to a more
accurate) estimate.
At present, designing such an engine is a more urgent and more potentially rewarding
task than working on hardware. Currently, computers only allow unary and binary operations. So, what this engine will do is, given a function, transform it into a sequence of
unary and binary operations. The perfect engine will output a transformation that leads to
the best possible estimate (e.g., to the interval with the smallest possible overestimation).
However, this \the best" does not necessarily mean that we will have no overestimation
at all: As we will see later, for some functions of three and more variables, no matter
how we transform these functions into a sequence of unary and binary operations, interval
computations will always lead to an overestimation. This overestimation result is true not
only for the existing computers, where only elementary arithmetic operations are hardware
supported; this result (as we will show) is true for any computer that hardware supports

11

only unary and binary operations. So, for such functions, the only way to avoid overestimation is to implement operations with three or more interval (corr., fuzzy) operands in
hardware.
For the resulting new computer, the computation scheme will include not only standard unary and binary operations, but some new operations (with interval or fuzzy
operands) as well. Again, the very fact that we have added these new operations does
not automatically mean that we will achieve the exact estimate: before we apply interval
computations, we must transform the original computation scheme (that may be overestimating) into a new (equivalent) scheme with no overestimation. So, we will again need
an appropriate symbolic reasoning engine for the new computer.
Summarizing, we can say that achieving precise interval and fuzzy computations is a threestep task:
 First, we must design a symbolic reasoning engine based on the existing hardware
supported operations (namely, elementary arithmetic operations). This engine must
transform the original expression (in terms of these elementary operations) for which
interval and fuzzy computations overestimate into an equivalent expression that leads
to more precise result Y .
 Second, we must select operations with three or more interval or fuzzy operands that
need to be hardware supported in order to get precise results.
 Third, for these new operations included, we must design a new symbolic reasoning
engine that will transform every algorithm into a sequence of elementary operations
(arithmetic or new ones) for which interval (fuzzy) computations will lead to the
precise result.
The rst task { the design of the original engine is, in eect, being currently done in interval
computations community (see, e.g., [10] and [14]). In the present paper, we consider the
second task: the choice of the hardware operations to be hardware supported. We give
only a partial answer to this task. As soon as this problem will be solved, the need will
come for the third task: designing a new symbolic reasoning engine for the new computer.

Hardware support of interval and fuzzy operations: a little bit of history. The

existing hardware support of interval operations is described in [23,36,37], and references
therein. Usually, the supported operations are arithmetic operations, and the scalar (dot)
product a1  b1 + ::: + an  bn .
The rst hardware implementation of operations with fuzzy sets has been developed
by Yamakawa. For the current state of research, see, e.g., [49,50]; for applications, see,
12

e.g., [43] and [52]. This rst implementation included several chips. The rst single-chip
hardware implementation of fuzzy operations have been proposed in [45] (for more recent
results, see, e.g., [44] and [48]). Parallel hardware implementation has been proposed
and described in [2]; see also [38] and [42]. These implementations, however, are mainly
oriented towards fuzzy control problems (and not fuzzy data processing).

What interval and fuzzy operations should we support for data processing? It

is impossible to implement in hardware fuzzy operations that correspond to all possible
functions f (x1; :::; xn). So, it is necessary to choose.

The natural idea is to describe all functions f that are hardware supported on the
existing computers, and to support the corresponding operations with fuzzy sets. Since
usually, only unary and binary operations are hardware supported, we will thus have
hardware implementation only of operations of one and two operands.

What we are planning to do. In this paper, we show that for intervals and for fuzzy sets,

an implementation of only unary and binary operations is not sucient in the following
sense: for some functions f and for some intervals (fuzzy sets) Xi , no matter how we
represent the function f as a composition of unary and binary operations, if we then
apply the above-described methodology, the resulting estimate Y~ will be dierent from the
desired value Y = f (X1; :::; Xn). Therefore, if we want fuzzy data processing to be precise,
operations with three or more fuzzy operands should also be implemented in hardware.
Some crisp operations with three or more crisp operands are already hardware supported: e.g., many computers contain a math co-processor that, among other things, hardware supports matrix operations, i.e., operations whose operands include an entire matrix
(i.e., lots of numerical operands). For example, it is possible, given two arrays a1 ; :::; an
and b1; :::; bn, to compute their dot (scalar) product a1  b1 + a2  b2 + ::: + an  bn by using
a single operation of a math co-processor. For crisp numbers, the main purpose of using
such operations is to speed up computations: in principle, we can use operations with two
operands (in this case, addition and multiplication) and compute the same expression in
several steps.
We are planning to show that in interval and fuzzy case, if we restrict ourselves to
unary and binary operations only, then not only computations will slow down, but for
some functions f , and for some intervals (fuzzy sets) Xi , we will not get the desired value
f (X1; :::; Xn) at all.
13

1.4. Structure of the paper
In Section 2, we will give some general denitions. In Section 3, we will consider the simplest case when inputs are intervals, and when all operations that are hardware supported
are smooth (dierentiable) functions. For this case, we will prove that operations with
one or two variables are not sucient. The fact that functions are dierentiable makes it
possible not only to prove the negative results but also to describe the smallest possible
order of the error that can be caused by such computations (linear, quadratic, etc). We
also give a list of operations that need to be hardware supported so that we will be able
to compute Y with a better accuracy: this list consists of arithmetic operations and a
weighted scalar product. In Section 4, these results will be generalized from crisp intervals
to fuzzy sets. In Section 5 and 6, we show that even if we allow operations that are not
dierentiable, still operations with one or two operands will not be sucient. In Section
7, we discuss the relation between these results and Kolmogorov's theorem (well known in
mathematics) that every continuous function of three or more real variables can be represented as a composition of real-valued functions of one and two variables. For reader's
convenience, all the proofs are placed in Section 8.

14

2. GENERAL DEFINITIONS
In this Section, we give general denitions that will be used in the following text.

2.1. Computation scheme
In this subsection, we will formalize the description of a general computation process
(presented in Subsection 1.2) into a formal denition, and show (on an example) how this
formalization is related to the original description.

Denition 2.1. By a computation scheme S with n initial values, and with operations
with one or two operands (or, for short, simply a computation scheme), we mean a nite
sequence (Sn+1; Sn+2 ; :::; SN ) of expressions Si (called steps). Each step Si is an expression
of one of the following three types:
 ri := ci , where ci is a real number;
 ri := fi (rj ), where fi is a function of one variable (not necessarily everywhere dened),
and j < i;
 ri := fi (rj ; rk ), where fi is a function of two variables (not necessarily everywhere
dened), j < i, and k < i.
If S is a computation scheme with n initial values, and x1; :::; xn are n real numbers, we
say that the result of applying S to xi is y, if rN = y, where the sequence ri is dened as
follows:
 if i  n, then ri = xi :
 if i > n, then depending on the type of the rule Si , we dene ri as follows:
 if the rule if ri := ci , then ri = ci ;
 if the rule is ri := fi (rj ), then ri = fi (rj );
 if the rule is ri := fi (rj ; rk ), then ri = fi (rj ; rk ).

Denotation. For some x1; :::; xn, and for each i  N , this Denition provides us with a

certain value of ri . This value will be denoted by ri (x1; :::; xn).

Comment. We have already mentioned that inside a computer, every algorithm is translated into a sequence of elementary operations. Since in the majority of computers, all elementary operations correspond to functions of one or two variables, an arbitrary algorithm
computing y = f (x1; :::; xn) can be thus represented as a computation scheme. For example, how in the above-given representation of the function f (x1; x2; x3) = (x1 + x2 )2 +2  x3,
we have:

15

 r4 = r1 + r2 (here, f4 = +, j = 1, k = 2);
 r5 = r42 (here, f5(x) = x2, j = 4);
 r6 = 2 (here, we have a function of 0 variables, that computes a constant 2);
 r 7 = r6  r3 ;
 r 8 = r5 + r7 .
Denition 2.2. Let K  Rn, and let f be a function from K to R. We say that a
computation scheme S computes f if for every (x1; :::; xn) 2 K , the value that S computes
(is dened and) is equal to f (x1; :::; xn).
2.2. Applying computation scheme to crisp sets
(in particular, to intervals)
In this subsection, we will describe how a computation scheme can be applied to crisp sets;
in particular, we will describe how it can be applied to intervals.

Denition 2.3. Let f (x1; :::; xn) be a function of n real variables, and let X1  R, ...,
Xn  R be (crisp) sets. Then, the result f (X1; :::; Xn) of applying f to the sets X1 ; :::; Xn
is dened by the formula (1.1). If instead of the sets Xi, we have a (crisp) set X  Rn,
then the result f (X ) of applying f to X is dened by the formula (1.2).

Denition 2.4. Assume that S is a computation scheme with n input values, and that
Xq  R, ..., Xn  R are (crisp) subsets of R. We say that the result of applying S to

X1; :::; Xn is Y if RN = Y , where the sequence of (crisp) sets R1; :::; RN is dened as
follows:
 if i  n, then Ri = Xi ;
 if i > n, then, depending of the type of the rule Si , Ri is dened as follows:
 if Si is ri := ci , then Ri = fci g;
 if the rule is ri := fi (rj ), then Ri = fi (Rj );
 if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).

16

Denition 2.5. Assume that S is a computation scheme with n input values, and that
X is a (crisp) subset of Rn. We say that the result of applying S to X is Y if RN = Y ,

where the sequence of (crisp) sets R1 ; :::; RN is dened as follows:
 if i  n, then Ri = i (X ), where i is a projection on i?th component (i.e., i (~x) =
xi );
 if i > n, then, depending of the type of the rule Si , Ri is dened as follows:
 if Si is ri := ci , then Ri = fci g;
 if the rule is ri := fi (rj ), then Ri = fi (Rj );
 if the rule is ri := fi(rj ; rk ), where j  n and k  n, then we take
Ri = f (jk (X )), where jk is a projection to j ?th and k?th components (i.e.,
jk (x1 ; :::; xj ; :::; xk ; :::; xn) = (xj ; xk ));
 if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).
Comment. The main dierence between these two denitions is that when we have a set
X  Rn , and we want to compute the set fi (X ) of possible values of fi (x1 ; :::; xn), we
must take into consideration the fact that not all values (x1 ; :::; xn) with xi 2 i (X ) are
possible.

2.3. Applying computation scheme to fuzzy sets

In the previous subsection, we described the result of applying a computation scheme to
crisp sets. Let us now describe what a computation scheme will do if we apply it to fuzzy
sets.

Denition 2.6. Let f (x1; :::; xn) be a function of n real variables, and let X1  R, ...,
Xn  R be fuzzy sets. Then, the result f (X1; :::; Xn) of applying f to the sets X1; :::; Xn is
dened by the formula (1.4a). If instead of the fuzzy sets Xi , we have a fuzzy set X  Rn,

then the result f (X ) of applying f to X is dened by the formula (1.3).

Denition 2.7. Assume that S is a computation scheme with n input values, and that
X1  R, ..., Xn  R are fuzzy subsets of R. We say that the result of applying S to

X1; :::; Xn is Y if RN = Y , where the sequence of fuzzy sets R1 ; :::; RN is dened as
follows:
 if i  n, then Ri = Xi ;
 if i > n, then, depending of the type of the rule Si , Ri is dened as follows:
 if Si is ri := ci , then Ri = fci g (a crisp set);
 if the rule is ri := fi (rj ), then Ri = fi (Rj );
 if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).
17

Denition 2.8. Assume that S is a computation scheme with n input values, and that
X is a fuzzy subset of Rn . We say that the result of applying S to X is Y if RN = Y ,

where the sequence of fuzzy sets R1; :::; RN is dened as follows:
 if i  n, then Ri = i (X ), where i is a projection on i?th component (i.e., i (~x) =
xi );
 if i > n, then, depending of the type of the rule Si , Ri is dened as follows:
 if Si is ri := ci , then Ri = fci g (a crisp set);
 if the rule is ri := fi (rj ), then Ri = fi (Rj );
 if the rule is ri := fi(rj ; rk ), where j  n and k  n, then we take
Ri = f (jk (X )), where jk is a projection to j ?th and k?th components (i.e.,
jk (x1 ; :::; xj ; :::; xk ; :::; xn) = (xj ; xk ));
 if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).

3. SIMPLEST CASE:
SMOOTH OPERATIONS, INTERVAL UNCERTAINTY;
HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS
IS NOT SUFFICIENT;
WEIGHTED SCALAR PRODUCT MUST ALSO BE SUPPORTED

In this section, we will consider the simplest case when inputs are intervals, and when
all operations that are hardware supported are smooth (dierentiable) functions. For this
case, we will prove that hardware operations with one or two variables are not sucient.
The fact that functions are dierentiable makes it possible not only to prove the
negative results but also to describe the smallest possible order of the error that can be
caused by such computations (linear, quadratic, etc). We will also give a list of operations
that need to be hardware supported so that we will be able to compute Y with a better
accuracy: this list consists of arithmetic operations and a weighted scalar product.

Denition 3.1.
 We say that a computation scheme S is continuous if all the function fi are continuous.
 We say that a function f is smooth if it is dened on an open set, is three times
dierentiable, and all its third order derivatives are continuous.
 We say that a computation scheme S is smooth if all the function fi are smooth.

3.1. The main (negative) result:
unary and binary operations are not sucient

In this subsection, we will describe our rst negative result: that for smooth operations on
intervals, hardware unary and binary operations are not sucient.
18

Denition 3.2. Assume that a smooth computation scheme S computes a smooth function f dened on an open set K  Rn. We say that S is precise for intervals if for all
intervals X1; :::; Xn for which X1  :::  Xn  K , the result of applying S to X1 ; :::; Xn
coincides with f (X1; :::; Xn).

For example, a 1-step computation scheme that computes f (x1; x2) = x1  x2 by
multiplying x1 and x2 is precise for intervals, while the computation scheme based on the
expression (1=4)  [(x1 + x2 )2 ? (x1 ? x2 )2] is not. It can be proven that the above-given
computation scheme for f (x1; x2; x3) = (x1 + x2 )2 +2  x3 is precise for intervals. As we have
already mentioned, for one and the same function, some computation scheme are precise,
and some others are not. The question is: for a give function f , is there any computation
scheme that is precise?

Denition 3.3. We say that for a smooth function f : Rn ! R, smooth interval com-

putations are precise, if there exists a smooth computation scheme that computes f and
that is precise for intervals. If such a smooth computation scheme does not exist, then we
say that for this function f , smooth interval computations cannot be always precise.

We will show that for many reasonable smooth functions, smooth interval computations cannot be always precise. To formulate our result, we will need a few denotations
and denitions.

Denotations.
 By f;i, we will denote i?th partial derivative of a function f .
 By f;ij , we will denote the second partial derivative
2f
:
f;ij = @x@ @x
i

j

Denition 3.4.
 A point ~s is called a stationary point of a function f if f;i (~s) = 0 for all i.
 A stationary point ~s of a function f is called non-degenerate if the following two

conditions are satised:
 at this point ~s, all components of the Hessian matrix f;ij (~s) are dierent from 0;
 at this point ~s, the determinant of the Hessian matrix is dierent from 0.

Comment. Almost all matrices satisfy these two properties (in the sense that the set of
symmetric matrices for which they are not true forms a subspace of co-dimension 1 in
the n(n + 1)=2?dimensional set of all matrices). So, we can say that almost all smooth
functions with a stationary point have a non-degenerate stationary point.

19

THEOREM 3.1. If a smooth function f (x1; :::; xn), n  3, has a non-degenerate stationary point, then for this function f , smooth interval computations cannot be always
precise.

Reformulation of this result in more informal (and hopefully, more understandable) terms. In view of the previous comment, this result means that for almost
all smooth functions with a stationary point, smooth interval computations cannot be always precise.

Our result and known mathematical results. The very fact that there exist smooth
functions for which smooth interval computations are not always precise is not surprising:
indeed, it is known (see, e.g., a survey [26]), that there exists a smooth function of three
variables that cannot be represented as a composition of smooth functions of one or two
variables. For such functions, a smooth computation scheme cannot be precise even for
real numbers, and of course, it is not precise for intervals, because every real number xi
can be viewed as a (degenerate) interval [xi ; xi]. Our negative result is much broader than
that: namely:
 Functions that cannot be represented as a composition of smooth unary and binary
operations can be viewed rather as an exception: e.g., every polynomial can denitely
be represented as such a composition.
 For smooth interval computations, we have shown that (in some reasonable sense)
almost all functions (to be more precise, almost all functions with a stationary point)
cannot be represented as compositions of smooth unary and binary interval operations.
This result includes functions f (x1; :::; xn) like quadratic polynomials, that can be
represented as a composition for numerical xi .

What does this theorem tell us about the choice of operations for hardware
implementation. With respect to hardware support, Theorem 3.1 says the following:
suppose that we have chosen a list of operations that we intend to implement in hardware
(both as operations with numbers and as operations with intervals). On the resulting
computer, every algorithm f (x1; :::; xn) will thus be represented as a composition of the
hardware supported operations fi . If we want to compute the interval f (X1; :::; Xn),
we will apply the same sequence of operations as in computing f (x1; :::; xn), but with
intervals instead of numbers (i.e., we will apply the computation scheme S that computes
f to intervals X1; :::; Xn). For some computation schemes, e.g., for

x1  x2 = (1=4)  [(x1 + x2)2 ? (x1 ? x2)2 ];
20

we may get an overestimate of f (X1; :::; Xn); for some others, hopefully, we will get a
precise estimate. In view of the previously mentioned result, for some smooth functions,
no smooth computation scheme will return the precise interval f (X1; :::; Xn).
We would like to choose a set of hardware supported operations in such a way that
for each smooth function that has smooth computation schemes, at least one of these
schemes will be precise for intervals (i.e., the above-described method will give exactly
f (X1; :::; Xn)). Theorem 3.1 tell us that we cannot achieve this goal if we only support
unary and binary operations; so, we must also implement some operations with three or
more operands in hardware.

3.2. Second negative result: if we only use unary and binary operations,
we cannot even compute the main term correctly
According to Theorem 3.1, if a smooth function f (x1; :::; xn) has a non-degenerate stationary point, and if we are only using unary and binary operations, then it is impossible to
always compute f (X1; :::; Xn) precisely for intervals Xi. So, if a computation scheme S
computes f , then the result Y~ of applying S to some intervals X1; :::; Xn will be dierent
from the desired interval Y = f (X1; :::; Xn). How dierent can it be?
Since we consider smooth functions, we can try to describe this dierence in terms of
the order: is it linear (rst order), quadratic (second order), cubic (third order), etc, in
i ? It could be that the dierence is, say, of fth order w.r.t. errors i , and therefore,
for practical purposes (this dierence being much smaller than the interval itself) we could
safely neglect it, and treat Y~ as a good approximation for Y . Alas, the reality is not so
good: it turns out that smooth interval computations (with unary and binary operations)
do not even give a correct main term for Y .
To describe this result in mathematical terms, let us rst describe the asymptotic of Y :

PROPOSITION 3.1. Let f (x1; :::; xn) be a smooth function. Then, the lower f ? and
upper f + bounds of the interval f ([x1 ? 1 ; x1 + 1 ]; :::; [xn ? n ; xn + n ]) satisfy the
property f  = f (x1; :::; xn)  (jf;1(~x)j1 + ::: + jf;n (~x)jn ) + O(2i ).
Denition 3.5. Assume that S is a smooth computation scheme for a smooth function
f (x1; :::; xn). We say that S always computes the main error term correctly if for every ~x,
the dierence between the actual endpoints of the interval
Y = f ([x1 ? 1; x1 + 1 ]; :::; [xn ? n ; xn + n ])
and the values computed by applying S to intervals Xi = [xi ? i ; xi + i ] is O(2i ).
21

Comment. In other words, we allow smooth interval computations not to be precise in the
sense that their result can dier in terms that are quadratic (or of higher order) in i , but
we require that the main term in i be computed precisely.
THEOREM 3.2. If a smooth function f (x1; :::; xn), n  3, has a non-degenerate stationary point, then for this function f , smooth interval computations cannot always compute
the main error term correctly.

3.3. Third negative result:
if we only use unary and binary operations,
we cannot even be locally asymptotically correct

An even stronger negative result can be proved. Namely, in our denition of what it means
to compute the main term correctly, we required that the main term should be computed
exactly. In general, the fact that a function is several times dierentiable, means that we
can approximate it by its Taylor polynomial. For example, if f is twice dierentiable, then
in the neighborhood of a point (s1; :::; sn), we can approximate the function f (x1; :::; xn)
P
by a linear function: f (x1; :::; xn) = f (s1; :::; sn) + f;i (s1; :::; sn)(xi ? si ) + O((xi ? si )2 ).
If the function is analytical, these Taylor polynomials actually converge to the function f .
So, if by using smooth interval computations, we cannot compute the main term precisely,
then maybe, we can at least compute correctly the rst few terms in the expansion of the
main term? I.e., e.g., we may be able to compute the main term with the accuracy of
O((xi ? si )2) terms? Alas, even this, we cannot compute, as the following result shows.
Denition 3.6. Let f (~x) be a smooth function, ~s = (s1; :::; sn) is a point in Rn, and
S is a smooth computation scheme for f . We say that S is locally asymptotically correct
(in computing the main error term) in the neighborhood of ~s, if the dierence between the
actual endpoints of the interval f ([x1 ? 1 ; x1 +1 ]; :::; [xn ? n ; xn +n ]) and the values
computed by applying S to the intervals Xi = [xi ? i ; xi +i ] is O(2i )+ O(i  (xj ? sj )2 ).
THEOREM 3.3. If a smooth function f (x1; :::; xn), n  3, has a non-degenerate stationary point, then for this function f , there exists a point ~s such that no matter what smooth
computation scheme S we choose to compute f , the resulting smooth interval computations
are not locally asymptotically correct in the neighborhood of ~s.

3.4. Positive result: if we add weighted scalar product,
smooth interval computations become locally asymptotically correct

Indeed, assume that in our denition of a computation scheme, we allow, in addition to
unary and binary operations, weighted scalar product, i.e., an operation
a1 ; :::; an; b1; :::; bn ! w1  a1  b1 + ::: + wn  an  bn ;
(3:1)
22

where n is an arbitrary positive integer, and wi are arbitrary real numbers (called weights).
Before we give a formal denition, we must make one comment.
In operations with real numbers, if we can implement a binary operation f (x1; x2),
then we can automatically implement the function g(x) = f (x; x) that is obtained by
applying f to two equal values: namely, to implement g, we can simply apply f to two
equal values. For interval operations, this idea does not always lead to an implementation
of g. As an example, we can take subtraction f (x1; x2) = x1 ? x2. For subtraction,
g(x) = f (x; x) = x ? x = 0; the corresponding interval operation is f ([x?1 ; x+1]; [x?2 ; x+2]) =
[x?1 ? x+2 ; x+1 ? x?2 ]. If we apply this operation to [x?1 ; x+1 ] = [x?2 ; x+2] = [0; 1], we get
f ([0; 1]; [0; 1]) = [?1; 1]. This result is dierent from the desired g([0; 1]) = f0g. Because
of this comment, when we describe a computation scheme that involves a certain interval
operation f , we must specically include interval analogues of all functions that can be
obtained from f by applying it to equal values of the variables. As a result, for weighted
scalar product, we arrive at the following denition:

Denition 3.7.
 Let a function f (x1; :::; xi?1; xi ; xi+1; :::; xj?1; xj ; xj+1; :::; xn) be given. We say that a

function g(x1; :::; xj?1; xj+1; :::; xn) = f (x1; :::; xi?1; xi; xi+1 ; :::; xj?1; xi; xj+1 ; :::; xn)
with n ? 1 variables is a simplied version of a function f ; transition from f to g will
be called a simplication.
 We say that a function g is a version of a function f if g can be obtained from f by
a sequence of simplications.
 By a weighted scalar product, we mean an operation (3.1).
 By a computation scheme with weighted scalar products, we mean a sequence S of
expressions each of which is either a function of zero, one, or two variables (like in
Denition 2.1), or an application of a weighted scalar product or of one of its versions.

Example. If we use weighted scalar product and its versions, we can simplify the computation of the above-given expression (x1 + x2 )2 + 2  x3 as follows: we still have ri = xi for
i = 1; 2; 3; and then:
 r4 = r2 + r3 (this is a binary operation);
 r5 = 2;
 r6 = r42 + r5  r3; here, to the values r4 , r5 , and r6 , we apply a function f6(y1; y2; y3) =
y12 + y2  y3 obtained by simplifying a weighted scalar product: f6 (y1; y2; y3) =
f  (y1; y1; y2; y3), where f (y1; y4; y2; y3) = y1  y4 + y2  y3 is a weighted scalar product
with both weights equal to 1.

23

For such computation schemes, we can repeat denitions 2.2 (what it means that a scheme
computes a function f ), 2.3 (how to apply a scheme to intervals), and 3.6 (what it means
to be locally asymptotically correct). Now, we can formulate our positive result:

THEOREM 3.4. For every smooth function f (x1; :::; xn), n  3, and for every point
~s in its domain, there exists a computation scheme S with weighted scalar products for
which the resulting smooth interval computations are locally asymptotically correct in the
neighborhood of ~s.

Comments.
 Good news: the result is applicable not only to intervals, but to arbitrary crisp sets as
well. From the proof of this theorem, one can easily see that the designed computation
scheme is locally asymptotically correct not only for intervals Xi = [xi ? i ; xi + i ],
but also for arbitrary crisp sets Xi  [xi ? i ; xi + i ].

 Not so good news: We know what operations we need to implement in hardware, but

we do not yet know how to implement them all. Theorem 3.4 says that if we hardware
support all weighted scalar products, then smooth interval computation becomes locally asymptotically correct. A word of warning: this result does not mean that we can
immediately implement all these operations and make computations (asymptotically)
precise, because we do not yet know how to implement all the necessary operations.
Indeed, according to Denition 3.7, we need separate versions of a function to deal
with each simplication obtained when two or more arguments to the function represent the same variable. For a function with n arguments, this will require n! hardware
implementations of the function. When n is large, n! is so unrealistically large that
it is practically impossible to have n! dierent hardware devices that compute n! different simplications. So, to implement all these simplications, we need a exible
implementation that will change when some of the arguments represent the same variable. At present, we do not know how to design such a exible implementation. This
implementation issue is an interesting open problem.

4. SMOOTH OPERATIONS, INDEPENDENT FUZZY SETS X1; :::; Xn:
HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS
IS NOT SUFFICIENT;
WEIGHTED SCALAR PRODUCT MUST ALSO BE SUPPORTED
In the previous section, we proved that unary and binary operations are not sucient
to support arbitrary smooth operations on intervals. In this section, we will show that,
24

similarly, unary and binary operations are not sucient to describe smooth operations on
(independent) fuzzy sets.

Denition 4.1. Assume that a smooth computation scheme S computes a function f
dened on an open set K  Rn. We say that S is precise for independent fuzzy sets if for
all fuzzy sets X1 ; :::; Xn for which X1  :::  Xn  K , the result of applying S to X1 ; :::; Xn

coincides with f (X1; :::; Xn).

Denition 4.2. We say that for a smooth function f : Rn ! R, smooth computations

are precise for independent fuzzy sets, if there exists a smooth computation scheme that
computes f and that is precise for fuzzy sets. If such a smooth computation scheme does
not exist, then we say that for this function f , smooth computations cannot be always
precise for independent fuzzy sets.

THEOREM 4.1. If a smooth function f (x1; :::; xn), n  3, has a non-degenerate sta-

tionary point, then for this function f , smooth computations cannot be always precise for
independent fuzzy sets.
Comments.
 Theorem 4.1 follows directly from Theorem 3.1: indeed, if a smooth computation
scheme is precise for arbitrary independent fuzzy sets, then, in particular, it must be
precise for crisp intervals, and this (according to Theorem 3.1) is impossible.
 Similarly, Theorems 3.2 and 3.3 show that smooth fuzzy computations with only unary
and binary operations cannot even describe the main term in f (X1; :::; Xn) correctly.
 In many reasonable cases, extension principle that denes Y = f (X1; :::; Xn) for
fuzzy sets X1; :::; Xn can be reformulated in terms of their (crisp) ?cuts Xi () =
fxjX (x)  g: namely, Y () = f (X1(); ::; Xn()) (see [33]; for counterexamples,
see [33] and [7]). So, if we add weighted scalar product to the list of hardware supported operations, then, due to Theorem 3.4, we will be able to get all ?cuts Y ()
locally asymptotically correctly, and in this sense, we will be able to compute the
fuzzy set Y itself with the same accuracy.
i

5. GENERIC (NOT NECESSARY SMOOTH) OPERATIONS, CRISP SETS:
HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS
IS NOT SUFFICIENT
Let us now consider the general case of operations that are not necessarily smooth, and of
the information that is not necessarily representable by independent sets X1 ; :::; Xn.
25

Denition 5.1. Assume that a computation scheme S computes a function f dened on
a set K  Rn. We say that S is precise for all (crisp) sets if for every (crisp) set X  K ,
the result of applying S to X coincides with f (X ).
Comment. We are going to prove that if our list of elementary operations includes only
operations with one and two operands, and a function f of three and more variables is
(in some reasonable sense) non-degenerate, then no computation scheme is applicable to
fuzzy processing (i.e., none of them will provide the exact fuzzy result). Let us describe
what we mean by non-degenerate.

Denition 5.2. Let K  Rn , n  3. We say that a function f : K ! R is degenerate
if K can be subdivided into nitely many subsets Ki so that on each subset, f coincides
with some function of one or two variables (i.e., on which f (x1; :::; xn) = g(xj ; xk ) for
some j and k and for some function g). A function that is not degenerate will be called
non-degenerate.

Comment. As an example of a degenerate function, we can take f (x1; :::; xn) =
max(x1 ; :::; xn). For this function, K = Rn can be subdivided into the subsets Ki in
which xi is greater than or equal to all other values, and on each Ki , f (x1; :::; xn) = xi
(i.e., is equal to a function of one variable).

The following two results show that many functions of three or more variables are
non-degenerate:

PROPOSITION 5.1. If a function f (x1; :::; xn) of three or more variables is dened
on a domain K , and on some subset M  K with a non-empty interior, f is strictly
monotonic in each variable, then f is non-degenerate.

Comment. To describe non-degenerate functions, we need to recall a notion of a real
analytic function: this means a function that can be represented as a sum of its Taylor
series. All known elementary functions (arithmetic operations, sin, cos, exp, ln, etc) and
their compositions are real analytic functions. It turns out that a real analytical function
is non-degenerate if and only if it actually depends on all of its variables:

PROPOSITION 5.2. If f (x1; : : :; xn) is a real analytic function of n  3 variables, and
f is not equal to a function of < n variables, then the function f is non-degenerate (in the
sense of Denition 5.2).

26

Examples.
 A function f (x1; x2; x3) = sin(x1 + exp(x2  x3)) is non-degenerate, because it actually
depends on each of its variables.
 In contrast, a function f (x1; x2; x3) = x1  x2 is degenerate, because it does not depend
on the variable x3 at all and is thus equal to the function of two variables.

THEOREM 5.1. If a function f of three and more variables is non-degenerate, then no

computation scheme that computes f is precise for all crisp sets.

Comment. This result is based on our Denition 2.1, in which we assumed that all elementary operations are operations with one or two (set-valued) operands. Thus, in case
of incomplete knowledge, when we have sets of possible values of the variables, operations
with one and two operands are not sucient. This suggests that for this case, we need to
implement hardware operations with 3 or more operands.

6. GENERIC (NOT NECESSARY SMOOTH) OPERATIONS, FUZZY SETS:
HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS
IS NOT SUFFICIENT
In the previous section, we proved that unary and binary operations are not sucient to
support generic (not necessarily smooth) operations on crisp sets. In this section, we will
show that, similarly, unary and binary operations are not sucient to describe generic
operations on fuzzy sets.

Denition 6.1. Assume that a computation scheme S computes a function f dened on
a set K  Rn. We say that S is precise for all fuzzy sets if for every fuzzy subset X  K ,
the result of applying S to X coincides with f (X ).
THEOREM 6.1. If a function f of three and more variables is non-degenerate, then no

computation scheme that computes f is precise for all fuzzy sets.

Comments.
 Since crisp sets are a particular case of fuzzy sets, this theorem is a corollary of
Theorem 5.1 (just like Theorem 4.1. is a corollary of Theorem 3.1).
 This result is based on our Denition 2.1, in which we assumed that all elementary
operations are operations with one or two (fuzzy) operands. Thus, for soft computing,
operations with one and two operands are not sucient. This suggests that for soft
computing, we need to implement hardware operations with 3 or more operands.

27

7. OUR RESULTS AND KOLMOGOROV'S THEOREM
7.1 What is Kolmogorov's theorem: in brief
The fact that every continuous function of three and more variables can be represented
as a composition of functions of one or two variables (and can be thus computed by an
appropriate computation scheme) has been rst proved by Kolmogorov [15] as a solution
to the famous Hilbert's problem: one of 22 problems that Hilbert has proposed in 1900 as a
challenge to the XX century mathematics [13]. Kolmogorov's result was later improved in
[40,41], and turned out to be applicable to theoretical and practical aspects of computation
(see, e.g., [6,12,24,25,31,30]).

7.2. In some reasonable sense, Kolmogorov's theorem
may not be extended to interval and fuzzy computations
Our negative theorems (3.1{3.3, 4.1, 5.1, and 6.1) show that Kolmogorov's theorem might
not be possible to extend to interval or fuzzy cases: there are functions that cannot be
represented as a composition of operations with one or two interval (resp. fuzzy) operands.

7.3. In some other sense (less computationally straightforward)
we can extend Kolmogorov's theorem to intervals
The above results are about the following: we have a function; we describe its computations
step-by-step, and substitute operations with intervals instead of operations with numbers.
In [32], the following result have been proven: if we do not follow the algorithm
f step-by-step, i.e., if we do not require that interval operations follow the ow of numerical computations, then Kolmogorov's theorem is true: namely, an arbitrary interval
function can be represented as a composition of functions of one and two variables. The
proof is rather simple: suppose that we have an interval-valued function f (x1 ; :::; xn) =
[f ? (x1 ; :::); f +(x1 ; :::)] of n interval variables x1 = [x?1 ; x+1]; :::; xn = [x?n ; x+n ] . This means
that we have two functions f ? and f + of 2n real variables x?1 ; :::; x?n ; x+1 ; :::; x+m. Each
of these functions can be (due to Kolmogorov's theorem) represented as a composition of
functions of one and two variables. So, we can do the following:
 rst, apply the interval functions ? and > that transform an interval [x? ; x+] into
[x? ; x? ] and, correspondingly, [x+ ; x+].
 follow the operations from Kolmogorov's theorem with these degenerate intervals, and
get the numerical-valued functions [f ?; f ?] and [f +; f +] as the desired composition;
 apply a combination operation comb([a; a]; [b; b]) = [a; b] to [f ?; f ? ] and [f +; f +] and
get the desired interval f = [f ?; f +].
28

With respect to hardware operations it means that in principle, we can restrict ourselves to
unary and binary operations only, but in this case, to compute the interval f (X1; :::; Xn),
we will not be able to simply follow the algorithm f step-by-step: for each f , we will have
to design a new method of interval (and therefore, for fuzzy) data processing.
Comment. An important open question:
 the result from [32] (described in this section) is proven for intervals;
 what happens in the fuzzy case?

8. PROOFS
Proof of Proposition 3.1
Since the function f is smooth, if xi are such that jxi j  i , then
f (x1 + 1; :::; xn + xn ) = flin + O(2i );
where we denoted flin = f (x1; :::; xn) + x1  f;1 + ::: + xn  f;n. The maximum of
flin is attained when each of the component terms xi  f;i attains the largest value for
xi 2 [?i ; i ]: for f;i > 0, the maximum is attained when xi = i , and for f;i < 0, the
maximum is attained when xi = ?i . In both cases, the maximum of i?th term is equal
to jf;iji . Therefore, the maximum of flin is equal to f (x1; :::; xn) + jf;1j1 + ::: + jf;njn .
Hence, the maximum f + of f is equal to this expression plus O(2i ). The result for f ? is
proved similarly. Q.E.D.

Proof of Theorems 3.1{3.3
Theorems 3.1 and 3.2 follow from Theorem 3.3, so it is sucient to prove Theorem 3.3.
We will prove that the statement of this theorem is true for the non-degenerate stationary
point ~s. This will be proven by reduction to a contradiction. Namely, let us assume that
there exist a smooth function with a non-degenerate stationary point ~s and a computation
scheme S for which smooth interval computations are locally asymptotically correct in the
neighborhood of ~s. Each such scheme S can be characterized by an integer: namely, by
the total number of computation steps. Among such schemes, there exists a scheme with
the smallest possible value of this integer. Let us denote this scheme by S , the function
that is computed by this scheme by f (x1; :::; xn), and the stationary point for this function
by ~s = (s1; ::; sn).
First, let us describe what type of expression we can get after each step of the smooth
computation scheme.
29

Denition 8.1. By a generalized linear function of n variables x1; :::; xn, we mean a
linear combination of functions 1, x1, ..., xn , and absolute values ja1x1 + ::: + an xn j of

homogeneous linear functions a1x1 + ::: + an xn .
Example. A function 1 + x1 + x2 + j2x1 ? x2j + jx + 3j is a generalized linear function.
LEMMA 1. For every smooth computation scheme S that computes a function
f (x1; :::; xn), and for every point ~s 2 Rn , the endpoints f~ of the result of smooth interval computations can be represented as
X
f (x1; :::; xn)  f~i (x1 ? s1; :::; xn ? sn)i + O(2i ) + O((xi ? si )2j )
for some generalized linear functions f~i .

Proof of Lemma 1. We will prove this lemma using induction over the number of steps

in a smooth computation scheme.
Induction base. If a smooth computation scheme has not steps at all, this means that the
function that we are computing simply coincides with one of the input variables. For an
input variable xi , each endpoint xi of the interval [xi ? i ; xi + i ] is already represented
in the desired form with f~i = 1, and f~j = 0 for j 6= i.
Induction step. Assume now that we have proved this result for all smooth computation
schemes of length  k, and we want to prove it for smooth computation schemes of length
k +1. Let S be any smooth computation scheme of length k +1. By denition of a smooth
computation scheme, the nal result of S is obtained in the last ((k + 1)?st) step by
applying a smooth function of one or two variables to the results of previous computations.
These results of previous computations are thus computable by computation schemes of
length  k. Therefore, for these results, due to the induction assumption, the result can be
represented in the desired form. Let us use these forms to describe the result of applying
(k + 1)?st step.
To prove it, we will consider two possible cases:
 The rst case if when the last step of S consists of applying a smooth function of one
variable.
 The second case if when the last step of S consists of applying a smooth function of
two variables.
In the rst case, f (x1; :::; xn) = F (r(x1; :::; xn)), and the result of applying smooth interval
computations to r is already known to be expressible in the form
[r(x1; :::; xn) ? l + O(2i ) + O((xi ? si )2  j ); r(x1; :::; xn) + l + O(2i ) + O((xi ? si )2  j )];
30

where l = r~1 1 + ::: + r~n n is a linear expression in i , with coecients r~i that are
generalized linear function in xi ? si . Similarly to the proof of Proposition 3.1, we can
prove that applying F results in an interval [y?; y+], where

y = F (r(x1; :::; xn))  jF 0 (r(x1; :::; xn))j  l + O((xi ? si )2  j ):
To prove the desired result, let us rst approximate jF 0 (r(x1; :::; xn))j by a generalized
linear function. To do that, we can rst approximate the composition F 0 (r(x1; :::; xn))
by a generalized linear function. This part is easy: Since both F 0 and r are smooth
functions, we conclude that F 0 (r(x1; :::; xn)) is also a smooth function, and therefore, it
can be represented as a0 + a1 (x1 ? s1) + ::: + an(xn ? sn ) + O((xi ? si )2).
 If a0 = 0, then the absolute value of this function can be represented as

ja1(x1 ? s1) + ::: + an (xn ? sn )j + O((xi ? si)2 );
i.e., as a generalized linear function plus O(:::).
 If a0 6= 0, then a0 +P ai (xi ?si ) = a0 (1+P(ai =a0)(xi ?si )). The absolute value of the
product can be represented as the product of the absolute values. When xi ! si , then
P(ai=a0)(xi ?si) ! 0, hence P(ai=a0)(xi ?si) > ?1, and so, j1+P(ai=a0)(xi ?si)j =
P
1+ (ai =a0)(xi ? si )+ O((xi ? si )2). Therefore, ja0 + a1 (x1 ? s1)+ ::: + an(xn ? sn )j =
ja0j(1 + P(ai =a0)(xi ? si)) + O((xi ? si )2) is a linear (and thus, generalized linear)
function of xi ? si .
In both cases, we represent jF 0(r(x1; :::; xn))j as a sum of the generalized linear function g~ and an O((xi ? si)2 ) term. Therefore, the product jF 0 (r(x1; :::; xn)))j  l =
jF 0 (r(x1; :::; xn)))j  r~1 1 + ::: + jF 0(r(x1; :::; xn)))j  r~n n can be represented as

g~  r~1  1 + ::: + g~  r~n  n + O((xi ? si )2j ):
For every i, the coecient g~  r~i at i is a product of two generalized linear functions.
By denition, each generalized linear function is a sum of a constant (maybe 0), and a
homogeneous rst order part (i.e., terms ai xi and ja1x1 + ::: + an xn j). The product g~  r~i of
two generalized linear functions g~ and r~i is thus a product of two sums and can, therefore,
be represented as a sum of four terms:
 a product of two constants, which is a constant;
 a product of a constant term of g~ and a homogeneous rst order part of r~i , which is
a generalized linear function;
 a product of a constant term of r~i and a homogeneous rst order part of g~, which is
also a generalized linear function;
31

 a product of a homogeneous rst order parts of g~ and r~i , which is O((xi ? si)2 ).
The sum f~i of the rst three products is generalized linear function; the fourth term lead
to the term O((xi ? si )2 i ) in g~  r~i  i. Therefore, g~  r~i i = f~i i + O((xi ? si )2  j ) for
a generalized linear function f~i . So, jF 0 (r(x1; :::; xn))j  l = L + O((xi ? si )2  j ), where
L = f~11 + ::: + f~n n , f~i are generalized linear, and therefore, the resulting interval is
indeed equal to the desired expression [f (x1; :::; xn) ? L + O(:::); f (x1; :::; xn) + L + O(:::)].
The second case can be described in a similar manner. In this case, instead of f =
F (r), we have f (x1; :::; xn) = F (r(x1; :::; xn); t(x1; :::; xn)) for some functions r and t that
have been computed on the previous steps. The resulting proof is similar. The lemma is
proved. Q.E.D.

LEMMA 2. Let S be a smooth computation scheme that computes a function f (x1; :::; xn),
and let ~s 2 Rn. Then, jf;ij  f~i + O((xi ? si)2 ), where f~i are generalized linear functions
that appear (as coecients at i ) in the description of the result of applying smooth interval
computations.

Proof of Lemma 2. For interval computations, the resulting interval always contains the

actual interval of values of f . Due to Lemma 1, the endpoints of the resulting interval are
f  (f~1 1 + ::: + f~n n )+ O(:::), and due to the Proposition, the endpoints of the interval of
values of f are f  (jf;1j1 + ::: + jf;n jn )+ O(:::). The fact that the rst interval contains
the second one means, in particular, that the width of the rst interval is  than the width
of the second interval, i.e., that f~1 1 + ::: + f~n n  jf;1j1 + ::: + jf;n jn + O(:::). If
we x i, choose i = 1 for this i, and j = 0 for all j 6= i, we get the desired inequality.
Q.E.D.

LEMMA 3. Let S be a smooth computation scheme that computes a function f (x1; :::; xn),
and let ~s 2 Rn . Then, the following statements are equivalent to each other:
 for S , smooth interval computations are locally asymptotically correct in the neighborhood of ~s;
 jf;i j = f~i + O((xi ? si )2), where f~i are generalized linear functions that appear (as
coecients at i ) in the description of the result of applying smooth interval computations.

Proof of Lemma 3. This result immediately follows from Lemma 1 and Proposition 3.1.

Q.E.D.

Proof of Theorem 3.3 itself. Let us now prove Theorem 3.3 itself. By denition, each
step of a smooth computation scheme S that does not assign a constant value to a variable
32

(i.e., that is not of the type Ri = fci g), consists of applying a function of one or two
variables either to initial data xi , or to the values computed on one of the previous steps.
The last step of the scheme S cannot be of the form Ri = fci g since otherwise the
function would have no non-degenerate stationary point. Therefore, the last step of the
scheme S can consists of applying either:
 a function of one variable, or
 a function of two variables.
Let us prove the theorem for these two cases.
First case: the last step consists of applying a function of one variable. Let us
rst show that this last step cannot consist of applying a smooth function of one variable.
We will prove this statement by reduction to a contradiction. Assume that the last step of
S does consist in applying a smooth function of one variable F to the result r(x1 ; :::; xn)
of some previous step. In this case, f (x1; :::; xn) = F (r(x1; :::; xn)). Let us prove that r(~x)
has a non-degenerate stationary point (at the same ~s), and that for this function r, smooth
interval computations are locally asymptotically correct in the neighborhood of ~s.
Indeed, we know that ~s is a stationary point for f , i.e., that f;i (s1; :::; sn) = 0. Since
f (x1; :::; xn) = F (r(x1; :::; xn)), we have f;i (s1; :::; sn) = F 0 (r(s1; :::; sn))  r;i (s1; :::; sn).
Similarly, f;ij (~s) = F 00 (r(~s))r;i(~s)r;j (~s)+ F 0 (r(~s))  r;ij (~s). Since f;i(~s) = 0, we can conclude
that either F 0 (r(~s)) = 0, or r;i (~s) = 0. In the rst case, f;ij = F 00 (~s)r;i r;j , and the
determinant of the Hessian at ~s is 0, which contradicts to our assumption that ~s is a nondegenerate point. Therefore, F 0 (~s) 6= 0, and r;i (~s) = 0, and ~s is a stationary point of the
function r(x1; :::; xn).
Since F 0 (r(~s)) 6= 0 and r;i (~s) = 0, from f;ij (~s) = F 00(r(~s))r;i (~s)r;j (~s)+ F 0 (r(~s))  r;ij (~s),
we can conclude that f;ij (~s) = F 0 (r(~s))  r;ij (~s), and r;ij (~s) = C  f;ij (~s), where C =
1=F 0(r(~s)). Since ~s is a non-degenerate stationary point of f , we have f;ij 6= 0, hence
r;ij (~s) = C  f;ij (~s) 6= 0. Similarly, from det jf;ij j 6= 0, we conclude that det jr;ij j 6= 0. So,
~s is a non-degenerate stationary point for the function r.
Let us now show that for the smooth computation scheme that leads to r, smooth
interval computations are locally asymptotically correct in the neighborhood of ~s. Indeed,
let r~i be the generalized linear functions that appear (as coecients at i ) in the description of the result of applying smooth interval computations to r. This means that after
we reach r, the resulting interval is equal to r  (~r11 + ::: + r~n n ) + O(:::). Due to
Proposition 3.1, after applying the function F to this interval, we get
F (r)  jF 0 (r(x1; :::; xn))j(~r11 + ::: + r~n n ) + O(:::):
33

Now, since F 0 (r) is a smooth function, we get

F 0 (r(x1; :::; xn)) = F 0 (r(~s)) +

X F 00(r(~s))r (x ? s ) + O((x ? s )2):
;i i

i

i

i

Since ~s is a stationary point for r, we have r;i (~s) = 0, and therefore, F 0 (r(x1; :::; xn)) =
F 0 (r(~s))+ O((xi ? si )2) and jF 0(r(x1; :::; xn))j = jF 0 (r(~s))j + O((xi ? si )2). So, the result of
applying smooth interval computations to S is equal to F (r)jF 0 (r(~s))j(~r11 +:::+~rn n )+
O(:::). Since for f and S , smooth interval computations are locally asymptotically correct,
we can (due to Lemma 3) conclude that for all i, jF 0 (r(~s))j  r~i (~x) = jf;i(~x)j + O(:::). But,
since f (~x) = F (r(~x)), we have f;i (~x) = F 0 (r(~x))r;i (~x) and jf;i(~x)j = jF 0 (r(~x))j  jr;i(~x)j.
We already know that jF 0(r(x1; :::; xn))j = jF 0(r(~s))j + O((xi ? si )2). Therefore, jf;i (~x)j =
jF 0 (r(~s))j  jr;i(~x)j + O(:::). So, from

jF 0 (r(~s))j  r~i (~x) = jf;i(~x)j + O(:::) = jF 0 (r(~s))j  jr;i(~x)j + O(:::);
we can conclude that r~i (~x) = jr;i (~x)j + O(:::), and hence, due to Lemma 3, that for r,
smooth interval computations are locally asymptotically correct.
Since r is computed on a previous step of the smooth computation scheme S , the
number of steps that lead to r is smaller than the number of computation steps in a scheme
S , and this contradicts to our choice of S as the shortest smooth computation scheme that
leads to a smooth non-degenerate function for which smooth interval computations are
locally asymptotically correct. So, the last step of our smooth computation scheme S
cannot consist of applying a function of one variable.

Second case: the last step consists of applying a function of two variables. To

complete our proof, let us show that the last step cannot consist of applying a function of
two variables. Indeed, suppose that the last step consists of applying a smooth function
F of two variables to two functions r(~x) and t(~x) that have been computed on a previous
computation step. In this case, f;i = F;r  r;i + F;t  t;i , where by F;r and F;t, we denoted
partial derivatives of F w.r.t. r and t.

Let us rst show that for ~s, both partial derivatives of F cannot be 0. Indeed, suppose
that they are. For f = F (r; t), the Hessian matrix is equal to f;ij (~x) = F;rr (~x)r;ir;j +
2F;rt (~x)r;i t;j + F;tt (~x)t;i t;j + F;r (~x)r;ij + F;t (~x)t;ij . In particular, for ~x = ~s, taking into
consideration that F;r = F;t = 0, we conclude that f;ij (~s) = F;rr (~s)r;ir;j + 2F;rt (~s)r;i t;j +
F;tt (~s)t;i t;j . If we choose vectors r;i (~s) and t;i(~s) as the rst two elements of the base, then
the Hessian matrix will only have 11, 12, and 22 components. Therefore, the determinant
34

of the Hessian matrix f;ij (~s) will be 0, which contradicts to our assumption that the
stationary point ~s is non-degenerate. This contradiction shows that the derivatives F;r (~s)
and F;t (~s) cannot be both equal to 0. Hence, we only need to consider the following three
subcases:
 F;r (r(~s); t(~s)) 6= 0 and F;t(r(~s); t(~s)) 6= 0.
 F;r (r(~s); t(~s)) 6= 0 and F;t(r(~s); t(~s)) = 0.
 F;r (r(~s); t(~s)) = 0 and F;t(r(~s); t(~s)) 6= 0.
We will analyze these three subcases separately.

First subcase of the second case: both partial derivatives of F are dierent
from 0 at ~s. Let us rst consider the case when both partial derivatives of F are dierent

from 0 at ~s. Let us show that in this case, r;i (~s) = t;i (~s) = 0. Indeed, the interval that
P
corresponds to r is equal to r  r~i i + O(:::), and the interval that corresponds to t is
P
equal to t  t~i i + O(:::). Due to Proposition 3.1, the interval that corresponds to f is
P
thus equal to f  f~i i +O(:::), where f~i (~x) = jF;r (~x)jr~i(~x)+jF;t(~x)jt~i(~x)+O((xi ?si )2 ).
Let us analyze this equality for ~x = ~s. For this ~x, the O term is equal to 0, so we have an
exact equality f~i (~x) = jF;r (~x)j  r~i (~x) + jF;t(~x)j  t~i (~x). Since smooth interval computations
are locally asymptotically correct for f , we have (due to Lemma 2) f~i = jf;ij + O((xi ? si )2 ).
In particular, for ~x = ~s, we have f~;i (~s) = jf;i(~x)j = 0. So, the left-hand side of the equality
is 0: 0 = jF;r (~s)j r~i(~s)+ jF;t(~s)j t~i(~s). The coecients r~i and t~i are non-negative for all ~x.
So, 0 is equal to the sum of two non-negative products (jF;r (~s)j  r~i (~s) and jF;t(~s)j  t~i (~s)).
The only way for this to happen is when both products are equal to 0. Since F;r 6= 0 for
~x = ~s, from jF;r (~s)j  r~i (~s) = 0, it follows that r;i(~s) = 0. Similarly, we can conclude that
t;i (~s) = 0.
Due to r;i (~s) = t;i (~s) = 0, we can (similarly to the case of f = F (r)) conclude that
F (~x) = F (~s)+ O((xi ? si )2 ). Therefore, f~i (~x) = jF;r (~s)jr~i (~x)+ jF;t (~s)jt~i(~x)+ O(:::). On the
other hand, f~i = jf;ij + O(:::), where f;i (~x) = F;r (~x)r;i(~x)+ F;t (~x)t;i (~x), and due to F (~x) =
F (~s)+ O((xi ? si )2), we can rewrite this equality as f;i (~x) = F;r (~s)r;i (~x)+ F;t (~s)t;i(~x). So,

f~i = jf;ij + O(:::) = jF;r (~s)r;i(~x) + F;t (~s)t;i(~x)j + O(:::):
Since jp + qj  jpj + jqj, we conclude that

f~i  jF;r  r;i + F;t  t;ij + O(:::)  jF;r j  jr;i j + jF;tj  jt;i j + O(:::):
Due to Lemma 2, jr;ij  r~i + O(:::) and jt;i j  t~i + O(:::). Therefore,

f~i  jF;r  r;i + F;t  t;ij + O(:::)  jF;r jjr;ij + jF;tjjt;ij + O(:::)  jF;r j r~i + jF;t j t~i + O(:::):
35

But the right-hand side of this inequality is already known to be equal to f~i (~x) (modulo
quadratic terms). Therefore,

f~i  jF;r  r;i + F;t  t;ij + O(:::)  jF;r j  jr;ij + jF;tj  jt;ij + O(:::)  f~i + O(::):
In this chain of inequalities the starting and the ending expressions coincide, and hence,
they are all equalities. So,

jF;r  r;i + F;t  t;i j = jF;r j  jr;i j + jF;t j  jt;i j + O(:::):
The only case when jp + qj = jpj + jqj is when p and q are of the same sign. So, we can
conclude that the linear parts of the expressions F;r (~s)  r;i (~x) and F;t (~s)  t;i(~x) are of the
same sign. Clearly, the sign of the linear part of

f;i = F;r (~s)  r;i(~x) + F;t(~s)  t;i(~x) + O(:::)

P

will be of the same sign. This linear part is f;ij (~s)(xj ? sj ). Similarly, we can express
the linear parts of r;i and t;i . We know that the numbers F;r (~s) and F;t (~s) are dierent
from 0. Let us assume that both numbers are positive (the cases when one of them
is negative can be treated in a similar manner). In this case, if a linear term in f;i
then the linear terms in r;i and t;i are also non-negative. In other words, if
Pis positive,
P
f
;ij (~s)(xj ? sj ) > 0, then f;ij (~s)(xj ? sj )  0. Turning to a limit, we can conclude that
P
P
P
if f;ij (~s)(xj ? sj )  0, then f;ij (~s)(xj ? sj )  0. Similarly, if f;ij (~s)(xj ? sj )  0,
P
P
then f;ij (~s)(xj ? sj )  0. Therefore, if f;ij (~s)(xj ? sj ) = 0, then we have both
P f;ij (~s)(xj ?sj )  0 and P f;ij (~s)(xj ?sj )  0, hence, we have both P r;ij (~s)(xj ?sj )  0
P
P
and r;ij (~s)(xj ? sj )  0, and thence, r;ij (~s)(xj ? sj ) = 0.

P

P

So, if f;ij (~s)(xj ? sj ) = 0, then r;ij (~s)(xj ? sj ) = 0. In geometric terms, the
condition means that a vector xj ? sj is orthogonal to the vector f~i with coordinates
f;i1(~s); :::; f;in(~s). Similarly, the conclusion means that a vector xj ? sj is orthogonal to
the vector ~ri with coordinates r;ij (~s). Since ~s is a non-degenerate stationary point, the
vector f~i is not zero, and therefore, vectors that are orthogonal to f~i form a (hyper)plane.
A vector ~ri is orthogonal to every vector from this (hyper)plane, and is, therefore, collinear
with f~i . This means that for every i, there exists a constant ci such that r;ij (~s) = ci f;ij (~s)
for all i and j .
The matrix of second derivatives is symmetric: r;ij = r;ji . Therefore, for every i and
j , ci f;ij = cj f;ji. Since second derivatives of f;ij also form a symmetric matrix, we have
36

ci f;ij = cj f;ij . Due to the fact that ~s is a non-degenerate stationary point for f , we conclude
that f;ij =
6 0 and therefore, ci = cj for all i and j . Let us denote the common value of all ci
by c. Then, r;ij (~s) = cf;ij (~s). Similarly, t;ij (~s) = c0 f;ij (~s). The coecients c and c0 cannot
be both equal to 0, because then, we would have f;ij (~s) = F;r (~s)rij (~s) + F;t (~s)t;ij (~s) = 0.
So, either c =
6 0, or c0 =
6 0. If c =6 0, then r;ij (~s) = cf;ij (~s) is a non-degenerate matrix
with non-zero determinant and all elements non-zero. Therefore, r is a function that has
a non-degenerate stationary point at ~s, and that can be computed in fewer steps than
f , which contradicts to our choice of f . Similarly, if c0 =
6 0, then t is a function that
contradicts to our choice of f . In both cases, we get a contradiction.

Second and third subcases of the second case: only one partial derivative of
F is dierent from 0 at ~s. We have derived a contradiction for the case when both
partial derivatives F;r (~s) =
6 0 and F;t (~s) =
6 0. To complete the proof of the theorem, we

must deduce a contradiction for the case when one of these partial derivatives is equal to
0. Without losing generality, we can assume that F;r (~s) 6= 0 and F;t (~s) = 0.
In this subcase, from the equality f~i (~x) = jF;r (~x)j  r~i (~x) + jF;t (~x)j  t~i (~x) (that can be
proven exactly like in the rst subcase), we conclude that r;i (~s) = 0.

P

Since F;t (~s) = 0, we can conclude that F;t (~s) = aj (xj ?sj )+O((xi ?si )2 ). Therefore,
only zeroth-order terms in t;i (~x) need to be taken into consideration, and we have

f;i (~x) =

Xf

;ij (xj ? sj )+ O(:::) = F;r (~s)

Xr

;ij (~s)(xj ? sj )+(

X a (x ? s ))t (~s)+ O(:::):
j j

j

;i

Similarly to the rst subcase, we can prove that the two linear components of this sum
must be of the same sign as fi , and therefore, that r;ij = cf;ij and aj t;i = c0 f;ij . The
coecient c0 cannot be dierent from 0, because then, we would have f;ij = (1=c0)aj t;i,
and det jf;ij j = 0,which contradicts to our assumption that the Hessian matrix f;ij is nondegenerate. Therefore, c0 = 0, and hence, c = 0 is impossible. Therefore, r;ij = (1=c)f;ij ,
and r is a function that has a non-degenerate stationary point at ~s, and that can be
computed in fewer steps than f , which contradicts to our choice of f .
We have proven the result for the rst case, and for all subcases of the second case;
therefore, the theorem is proven. Q.E.D.

Proof of Theorem 3.4
Since the function f is smooth, for every point ~s, we have f (~x) = fquadr(~x)+ O((xi ? si )3 ),
where
X
X
fquadr = f (~s) + f;i(~s)(xi ? si ) + 21 f;ij (xi ? si )(xj ? sj ):
i;j

i

37

Therefore (similarly to the proof of Proposition 3.1), we can conclude that the dierence
between the intervals f (X1; :::; Xn) and fquadr (X1; :::; Xn) is also O((xi ? si )3). The function fquadr is quadratic in xi , so, we can represent it as

fquadr(x1; :::; xn) = a0 +

Xa x + Xa
i

i i

i;j

ij xi xj

for some real numbers ai and aij . If we dene a0i = ai for i = 0; 1; :::; n, then we can
represent this expression as fquadr(x1 ; :::; xn) = g(x0; x1; :::; xn) for x0 = 1 and

g(x0; :::; xn) =

Xn Xn a
i=0 j =0

ij xi xj :

The function g, in its turn, can be represented as a result of applying n simplications
xi = yi , 1  i  n, to a weighted scalar product

f (x0; x1; :::; xn; y0; y1; :::; yn) =

Xn Xn a
i=0 j =0

ij xi yj

with weights aij .
So, fquadr can be computed using a computation scheme S with weighted scalar products. Since the dierence between the intervals f (X1; :::; Xn) and fquadr(X1; :::; Xn) is
O((xi ? si )3 ), we can conclude that smooth interval computations described by the scheme
S are locally asymptotically correct for the original function f . Q.E.D.

Proof of Proposition 5.1
1. Let us prove this Proposition by reduction to a contradiction. Namely, assume that
f : K ! R is strictly monotonic in each variable, and that f is degenerate. By denition,
this means that K can be represented as a union of nitely many sets K1 ; :::; Kp on each
of which f is equal to a function of two of fewer variables. Let's deduce a contradiction
from here.
2. Since the interior of M  K is non-empty, the set M contains a ball.
Inside the ball, we can place a cube [a1; b1]  [a2; b2]  :::  [an ; bn]. Let's divide each
side [ai ; bi] of the cube into p + 1 equally distanced values of xi : ai , ai + (bi ? ai )=p,
ai + 2  (bi ? ai)=p, ..., ai + p  (bi ? ai )=p = bi . By combining these values for dierent i,
we get (p + 1)n dierent points that all belong to the cube and therefore, to K . Let us
denote the set of all these points by P .
38

3. Let us take one of the sets Ki , and let us estimate how many of the points from P
belong to Ki . Since f is degenerate of Ki , it means that on Ki f is equal to a function
of two or fewer variables. But f is a function of n  3 variables. So, this means, that for
~x 2 Ki , f cannot depend on all the variables. Hence, it does not depend on one of the
variables. Let us denote one of such variables by xj . The fact that for ~x 2 Ki , f does not
depend on xj , means that if we have two dierent points with dierent values of xj and
equal values of all other coordinates, then the value of f for both point will be the same.
4. Formally, if ~x = (x1; :::; xj?1; xj ; xj+1; :::; xn) 2 P  M and

~y = (x1 ; :::; xj?1; xj + xj ; xj+1; :::; xn) 2 M;
where xj 6= 0, then f (~x) = f (~y).
But on M , f is strictly monotonic in each variable. This means, in particular, that f
is either strictly increasing in xj , or strictly decreasing in xj . In both cases, f (~x) 6= f (~y).
This contradiction with f (~x) = f (~y) shows that no such pairs (~x; ~y) are possible. In other
words, if we x the values of n ? 1 coordinates (all of them except for xj ), i.e., if we
x the values x1; :::; xj?1; xj+1; :::; xn, then at most one point with these values of n ? 1
coordinates belongs to Ki .
5. For P , if we x the values of all the coordinates but one, then, we can choose p + 1
dierent values of xj and hence, have p + 1 dierent points from P  K . At most one of
them belongs to Ki. Therefore, Ki contains at most 1=(p + 1) part of all the points from
P.
6. The same inequality is true for each of the sets Ki . So, totally, p sets K1, ..., Kp contain
 p=(p + 1) of all the points from P . Since p=(p + 1) < 1, it means that there are points
from P (and hence from K ) that are not covered by any of the sets Ki . This contradicts
to our assumption that f is degenerate and K = [Ki .
This contradiction shows that our assumption was false, and so f is not degenerate.
Q.E.D.

Proof of Proposition 5.2
Let us show that if a real analytic function f (x1; :::; xn) does not coincide with a function
of less than n variables, then it is non-degenerate in the sense of Denition 5.2. Indeed, an
arbitrary real analytic function g(x1; :::; xn) has the following property (similar to complex
analytical functions): it is either identically equal to 0, or it is equal to 0 on a set of
(Lebesgue) measure 0 (i.e., it is dierent from 0 on a set of full measure) (see, e.g., [17]).
39

Also, for an arbitrary real analytic function, each of its derivatives is also real analytic.
In particular, the partial derivative @f=@x1 of the given function is real analytic. If it was
identically equal to 0, then f would not depend on x1 at all. Therefore, according to the
above-cited result, the set of points (x1 ; :::; xn) on which this derivative is equal to 0 is of
Lebesgue measure 0. Similarly, for each i = 2; :::; n, the set of all points (x1 ; :::; xn), at
which i?th partial derivative @f=@xi is equal to zero, is also of measure 0.
Therefore, the union of these n sets, i.e., the set of all points on which at least one of
the partial derivatives is dierent from 0, is also of measure 0 (as a union of measure-zero
(0)
sets). Therefore, there exists a point (x(0)
1 ; :::; xn ) that does not belong to this union. By
denition of the union it means that in this point, all n partial derivatives are dierent
from 0.
These derivatives are real analytic and therefore, continuous. Therefore, there exists
(0)
a spherical neighborhood M of this point (x(0)
1 ; :::; xn ) in which sign of each of the partial
(0)
derivatives coincides with its sign at the point (x(0)
1 ; :::; xn ). For those i for which this
sign is positive (@f=@xi > 0), f is strictly increasing in xi . For those i for which this sign
is negative (@f=@xi < 0), f is strictly decreasing in xi . So, for all points from a set M
with a non-empty interior, the function f is strictly monotonic in each variable. Therefore,
according to Proposition 5.1, this function f is non-degenerate. Q.E.D.

Proof of Theorem 5.1
1. Let us prove this theorem by reduction to a contradiction. Namely, we will assume that
there exists a non-degenerate function f and a computation scheme S that computes f and
that is precise for all (crisp) sets, and we will deduce a contradiction from this assumption.
To deduce this contradiction, we will use the following observation: According to our
denitions, the phrase \S is precise for all (crisp) sets" means that for every (crisp) set
X  Rn , the result RN of applying S to X coincides with f (X ).
In this proof, we will need the following two Lemmas:

LEMMA 4. Assume that a function f : K ! R (K  Rn ) is computed by a composition
scheme S , and X  K . Let's denote by RN the result of applying S to X . Then, f (X ) 
RN .

Proof of Lemma 4. This Lemma is similar to the Main Theorem of Interval Computa-

tions (see, e.g., [29]), and is proved similarly: namely, using induction, one can then prove
that for every i, ri (X )  Ri. For i = N , we get the desired result. Q.E.D.
40

LEMMA 5. Assume that k is an integer, f : R ! R, g : Rk ! R, and h : Rk ! R
is a composition of f and g (i.e., h(~x) = f (g(~x))). Then, for every (crisp) set X  Rk ,

h(X ) = f (g(X )).

Proof of Lemma 5 follows directly from the denitions. Q.E.D.
2. We will need the following auxiliary notion: by a complexity of a computation scheme
S = (Sn+1 ; :::; SN ), we will understand the number N .
We assumed that there exists a computation scheme that computes a non-degenerate
function of n variables and that is precise for all (crisp) sets. Out of all computation
schemes with this property, there exists a one with the smallest possible complexity N .
Let's choose one of these \simplest" schemes. In the following text, this chosen scheme
will be denoted by Ss (s stands for simplest). The corresponding function will be denoted
by fs .
Comment. A computation scheme Ss consists of the rules of the type ri := ci , ri := fi (rj ),
and ri := fi (rj ; rk ). In principle, the corresponding functions fi can be dened everywhere.
However, when we apply this computation scheme to compute the value of the function fs
that is dened on some set K , we will use only the values of fi for rj 2 ri (K ); or, for the
function of two variables, only the values for (rj ; rk ) 2 Djk , where

Djk = f(a; b) j 9~x (~x 2 K & rj (~x) = a & rk (~x) = bg:
Therefore, to simplify our proofs, we will assume in the following text that fi is dened
only for these values.
It is easy to check that if initially Ss computed fs and was precise for all (crisp) sets,
then after such a restriction on fi it still has the same properties.
3. Depending on what the nal step SN of Ss is, we have the following ve possibilities:
 N  n;
 N > n and rN := cN ;
 N > n and rN := fN (rj ), where j < N ;
 N > n and rN := fN (rj ; rk ), where j  n and k  n;
 N > n and rN := fN (rj ; rk ), where j > n or k > n.
In the following ve subsections, we will prove that in all these ve cases, we have a
contradiction with our initial assumption.
4. N  n.
41

In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = xN . So, fs depends only on one of its
variables. Hence, fs is degenerate, which contradicts to the assumption that it is nondegenerate.
5. N > n and rN := cN .
In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = cN does not depend on any variables at
all. Therefore, it is degenerate.
6. N > n and rN := fN (rj ), where j < N .
Let us prove (by considering all possible cases) that this case is impossible. Depending
on the case, we will prove it either directly, or by \merging" the last step with one of the
previous ones, and thus coming up with a new computation scheme that is simpler than
the scheme Ss that is by denition the simplest possible (so, we have a contradiction).
6.1. If j  n, then rj = xj , and fs = fN (rj ) = fN (xj ) is a function of one variable (namely,
xj ) and is thus degenerate, which contradicts to our choice of fs.
6.2. If j > n, and j ?th step is rj := cj , then fs = rN = fN (cj ) =const, i.e., fs is also
degenerate.
6.3. If j > n, and j ?th step is rj := fj (rk ) for some k < j , then rN = fN (fj (rk )). In
other words, rN = f~N (rk ), where by f~N , we denoted the composition of fN and fj .
6.3.1. If k  n, then fs is again a function of one variable xk (i.e., degenerate).
6.3.2. If k > n, then, we can replace the original computation scheme S with the
following simplied one: S~ = (Sn+1 ; :::; Sk ; S~N ), where by S~N , we denoted the
following step: rN := f~N (rk ). Because of our formulas, this scheme computes
exactly the same function fs . The fact that this scheme computes the same
function and is precise for all (crisp) sets, follows from Lemma 5.
Since we deleted at least one step (Sj ), this new scheme has a smaller complexity
that Ss . This contradicts to our choice of Ss as the computation scheme with
the smallest possible complexity that computes a non-degenerate function of 3 or
more variables and that is precise for all (crisp) sets.
6.4 If j > n, and j ?th step is rj := fj (rk ; rl ) for some k; l < j , then rN = fN (fj (rk ; rl)) =
f~N (rk ; rl ), where by f~N , we denoted a composition f~N (a; b) = fN (fj (a; b)). In this
case, we can also delete one step from the computation scheme and thus arrive at the
contradiction.
42

7. N > n and rN := fN (rj ; rk ), where j  n and k  n.
In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = fN (xj ; xk ). Hence, fs depends on only
two of its variables, and is therefore degenerate.
8. N > n and rN := fN (rj ; rk ), where j > n or k > n.
8.1. We assumed that Ss computes fs , and that Ss is precise for all (crisp) sets. This
means, in particular, that for each input set X  K , RN = fs(X ). In particular, if we
take arbitrary two elements ~x 2 K and ~y 2 K , then this equality must be true for a 2-point
set X = f~x; ~yg.
8.2. For this choice of X , the right-hand side of the equality RN = fs (X ) (i.e., the
set fs(X )) is easy to describe: it consists of two values fs (~x) = fN (rj (~x); rk (~x)) and
fs(~y) = fN (rj (~y); rk (~y)).
8.3. Now, let's nd an element of the left-hand side. By denition of RN , this set is
equal to RN = fN (Rj ; Rk ). Due to Lemma 4, Rj  rj (X ), and Rk  rk (X ). Since
rj (~x) 2 rj (X ), we can thus conclude that rj (~x) 2 Rj . Similarly, we can conclude that
rk (~y) 2 Rk . Therefore, fN (rj (~x); rk (~y)) 2 fN (Rj ; Rk ) = RN .
Since RN = fs(X ), every element of RN must coincide with one of the two elements
of fs (X ). In particular, for the above-discovered element, it means the following:
For every ~x 2 K and ~y 2 K , fN (rj (~x); rk (~y)) is either equal to fN (rj (~x); rk (~x)), or it is
equal to fN (rj (~y); rk (~y)).

8.4. This statement enables us to make the following conclusion about the function
fN (a; b):
If we can nd ~x and ~y such that a = rj (~x) and b = rk (~y), then either fN (a; b) =
fN (a; rk (~x)), or fN (a; b) = fN (rj (~y); b).

8.5. For each a 2 rj (K ), there exists a vector ~x for which rj (~x) = a (it is possible that
several such vectors exist). For dierent vectors ~x, the value rk (~x) may also be dierent.
For each a, let us pick one of these values rk (~x) and denote it by gkj (a).
Similarly, for each b 2 rk (K ), we will pick a vector ~x with the property that rk (~x) = b,
and denote the value rj (~x) for thus picked ~x by gjk (b).
8.6. Using these denotations, we can reformulate the statement from 8.4 as follows:
43

For every a 2 rj (K ) and b 2 rk (K ), either fN (a; b) = fN (a; gkj (a)), or fN (a; b) =
fN (gjk (b); b).

If we denote h1 (a) = fN (a; gkj (a)) and h2 (b) = fN (gjk (b); b), then we can further
simplify this conclusion:
For every (a; b) 2 Djk , either fN (a; b) = h1 (a), or fN (a; b) = h2 (b).
8.7. In particular, this property is true if we choose an arbitrary ~x 2 K and take a = rj (~x)
and b = rk (~x).
Let us denote by K1 the set of all ~x 2 K for which fN (rj (~x); rk (~x)) = h1 (rj (~x)), and
by K2, the set of all values ~x 2 K for which fN (rj (~x); rk (~x)) = h2 (rk (~x)). Then, this
property means that K = K1 [ K2.
8.8. Since the function f dened on K is non-degenerate, its restriction to either K1 or
K2 is also non-degenerate.
Indeed, if it were not true, then we would be able to describe both K1 and K2 (and
hence, their union) as the union of nitely many subsets on which fs is degenerate. On
the other hand, we assumed that fs : K ! R is non-degenerate, which means that for K ,
such a representation is impossible.
8.9. Let us choose a set Ki (i.e., K1 or K2) for which the restriction of fs is non-degenerate.
For this set, we can form the restriction of fs and Ss . For this restriction, we can take
rN := h1 (rj ) (or rN := h2 (rk )) as a last step of the computation scheme (instead of the step
rN := fN (rj ; rk )), and the resulting computation scheme will still compute the restriction
of fs , and it will still precise for all (crisp) sets.
If we were able to compute a non-degenerate function fs by another computation
scheme S1 whose complexity is < N computation steps, then we would get a contradiction with our choice of N as the smallest possible complexity of a computation scheme
that computes a non-degerenate function. Therefore, the resulting computation scheme is
still the \simplest" in the sense that its complexity N is the smallest possible among all
computation schemes that compute non-degenerate functions.
So, we arrive at the situation where we have the \simplest" computation scheme, and
the function at the last step is a function of one variable; we have already proved (in part
6 of this proof) that such situation leads to a contradiction.
9. So, in all ve cases, we arrive at a contradiction. Hence, our initial assumption is
false, namely, the assumption that a non-degenerate function of 3 or more variables can
44

be computed by a computation scheme (with unary and binary operations only) that is
precise for all (crisp) sets. Q.E.D.

CONCLUSIONS
Theoretical. The main theoretical result of this paper is that functions of several interval

or fuzzy variables cannot always be computed precisely if we use only operations with one or
two interval (resp. fuzzy) variables. Moreover, for smooth functions f , we show that even
the main term in the result of fuzzy (interval) computations cannot always be computed
correctly. The accuracy of interval and fuzzy data processing drastically improves if we
add weighted scalar product to the list of elementary (hardware supported) operations.
For numerical operands, scalar product is already hardware supported in modern
computers: by math co-processors. There have been successful attempts to hardware
support scalar product of interval operands.

Practical. Therefore, our main practical recommendation is that for fuzzy data processing,

it is desirable to hardware support (weighted) scalar product of fuzzy operands as well (at
least, some operations with three or more fuzzy operands).

Acknowledgments. This work was partially supported by NSF grants No. CDA-9015006

and No. EEC-9322370, by a Grant No. PF90{018 from the General Services Administration (GSA), administered by the Materials Research Institute and the Institute for
Manufacturing and Materials Management, and by a NASA grant No. NAG 9-757. The
authors are greatly thankful to Paul Kainen, Baker Kearfott, Vera Kurkova, and Reza Langari for valuable discussions, and to the anonymous referees for their extremely valuable
suggestions and help.

45

REFERENCES
[1] O. Artbauer, \Application of interval, statistical, and fuzzy methods to the evaluation
of measurements", Metrologia, 1988, Vol. 25, pp. 81{86.
[2] H. Dhirf and D. Sarkar, \Fuzzy arithmetic on systolic arrays", Parallel Computing,
1993, Vol. 19, pp. 1283{1301.
[3] W. M. Dong, W. L. Chiang, H. C. Shah, \Fuzzy information processing in seismic
hazard analysis and decision making", International Journal of Soil Dynamics and
Earthquake Engineering, 1987, Vol. 6, No. 4., pp. 220{226.
[4] W. Dong and F. Wong, \Fuzzy weighted averages and implementation of the extension
principle", Fuzzy Sets and Systems, 1987, Vol. 21, pp. 183{199.
[5] D. Dubois and H. Prade. Fuzzy sets and systems: theory and applications, Academic
Press, N.Y., London, 1980.
[6] H. L. Frisch, C. Borzi, G. Ord, J. K. Percus, and G. O. Williams, \Approximate Representation of Functions of Several Variables in Terms of Functions of One Variable",
Physical Review Letters, 1989, Vol. 63, No. 9, pp. 927{929.
[7] R. Fuller and T. Keresztfalvi, \On generalization of Nguyen's theorem", Fuzzy Sets
and Systems, 1990, Vol. 4, pp. 371{374.
[8] W. A. Fuller, Measurement error models, J. Wiley & Sons, New York, 1987.
[9] A. A. Gaganov, \Computational complexity of the range of the polynomial in several
variables", Cybernetics, 1985, pp. 418{421.
[10] R. Hammer, M. Hocks, U. Kulisch, D. Ratz, Numerical toolbox for veried computing.
I. Basic numerical problems, Springer Verlag, Heidelberg, N.Y., 1993.
[11] E. R. Hansen, Global optimization using interval analysis, Marcel Dekker, N.Y., 1992.
[12] R. Hecht-Nielsen, \Kolmogorov's Mapping Neural Network Existence Theorem",
IEEE International Conference on Neural Networks, San Diego, SOS Printing, 1987,
Vol. 2, pp. 11{14.
[13] D. Hilbert, \Mathematical Problems, lecture delivered before the International
Congress of Mathematics in Paris in 1900", translated in Bull. Amer. Math, Soc.,
1902, Vol. 8, pp. 437{479.
[14] R. B. Kearfott and V. Kreinovich (eds.), Applications of Interval Computations,
Kluwer, Dordrecht, 1996.
[15] A. N. Kolmogorov, \On the Representation of Continuous Functions of Several Variables by Superposition of Continuous Functions of One Variable and Addition", Dokl.
Akad. Nauk SSSR, 1957, Vol. 114, pp. 369{373.
[16] G. Klir and B. Yuan, Fuzzy sets and fuzzy logic: theory and applications, Prentice
46

[17]

[18]
[19]

[20]

[21]
[22]

[23]
[24]
[25]
[26]
[27]

Hall, Upper Saddle River, NJ, 1995.
V. Kreinovich, \On the problem of recovering the ?function in non-relativistic quantum mechanics", Teoreticheskaya i Mathematicheskaya Fizika, 1976, Vol. 28, No. 1,
pp. 56{64 (in Russian); English translation: Theoretical and Mathematical Physics,
1976, Vol. 8, No. 7, pp. 56{64.
V. Kreinovich (ed.), Reliable Computing, 1995, Supplement (Extended Abstracts of
APIC'95: International Workshop on Applications of Interval Computations, El Paso,
TX, Febr. 23{25, 1995).
V. Kreinovich, Ching-Chuang Chang, L. Reznik, G. N. Solopchenko, \Inverse problems: fuzzy representation of uncertainty generates a regularization", Proceedings
of NAFIPS'92: North American Fuzzy Information Processing Society Conference,
Puerto Vallarta, Mexico, December 15{17, 1992, NASA Johnson Space Center, Houston, TX, 1992, Vol. II, pp. 418{426.
V. Kreinovich, C. Quintana, L. Reznik, Gaussian membership functions are most
adequate in representing uncertainty in measurements, In: Proceedings of NAFIPS'92:
North American Fuzzy Information Processing Society Conference, Puerto Vallarta,
Mexico, December 15{17, 1992, NASA Johnson Space Center, Houston, TX, 1992,
Vol. II, pp. 618{624.
V. Kreinovich et al, What non-linearity to choose? Mathematical foundations of fuzzy
control, Proceedings of the 1992 International Conference on Fuzzy Systems and Intelligent Control, Louisville, KY, 1992, pp. 349{412.
V. Kreinovich and L. K. Reznik, \Methods and models of formalizing a priori information (on the example of processing measurements results)", In: Analysis and
Formalization of Computer Experiments, Proceedings of the Mendeleev Metrology Institute, 1986, pp.37{41 (in Russian).
U. Kulisch, G. Bohlender, \Features of a hardware implementation of an optimal
arithmetic", In: U. Kulisch, W. L. Miranker (eds), A new approach to scientic computation, Academic Press, Orlando, FL, 1983, pp. 269{290.
V. Kurkova, \Kolmogorov's Theorem Is Relevant", Neural Computation, 1991, Vol.
3, pp. 617{622.
V. Kurkova, \Kolmogorov's Theorem and Multilayer Neural Networks", Neural Networks, 1992, Vol. 5, pp. 501{506.
G. G. Lorentz, \The 13-th problem of Hilbert", in: F. E. Browder (ed.), Mathematical
Developments Arizing from Hilbert's Problems, American Math. Society, Providence,
RI, 1976, Part 2, pp. 419{430.
R. E. Moore, Automatic error analysis in digital computation, Lockheed Missiles and
47

[28]
[29]
[30]
[31]
[32]
[33]
[34]
[35]
[36]
[37]

[38]
[39]
[40]
[41]
[42]
[43]

Space Co. Technical Report LMSD-48421, Palo Alto, CA, 1959.
R. E. Moore, C. T. Yang, Interval analysis, Lockheed Missiles and Space Co. Technical
Report LMSD-285875, Palo Alto, CA, 1959.
R. E. Moore, Methods and applications of interval analysis, SIAM, Philadelphia, 1979.
M. Nakamura, R. Mines, V. Kreinovich, \Guaranteed Intervals for Kolmogorov's Theorem (and Their Possible Relation to Neural Networks)", Interval Computations, 1993,
No. 3, pp. 183{199.
M. Ness, \Approximative versions of Kolmogorov's superposition theorem, proved
constructively", J. Comput. Appl. Math., 1993.
V. M. Nesterov, \Interval analogues of Hilbert's 13th problem", In: Abstracts of the
Int'l Conference Interval'94, St. Petersburg, Russia, March 7{10, 1994, 185{186.
H. T. Nguyen, \A note on the extension principle for fuzzy sets", J. Math. Anal. and
Appl., 1978, Vol. 64, pp. 359{380.
H. T. Nguyen and E. A. Walker, A First Course in Fuzzy Logic, CRC Press, Boca
Raton, Florida, 1996 (to appear).
S. Rabinovich, Measurement errors: theory and practice, American Institute of
Physics, N.Y., 1993.
M. J. Schulte and E. E. Swartzlander, Jr., \Parallel Hardware Designs for Correctly
Rounded Elementary Functions", Interval Computations, 1993, No. 4, pp. 65{88.
M. J. Schulte and E. E. Swartzlander, Jr., \Design and applications for variableprecision, interval arithmetic coprocessors", In: V. Kreinovich (ed.), Reliable Computing, 1995, Supplement (Extended Abstracts of APIC'95: International Workshop
on Applications of Interval Computations, El Paso, TX, Febr. 23{25, 1995), pp.
166{172.
S. M. Shah and R. Horvath, A hardware digital fuzzy inference engine using standard
integrated circuits, Information Sciences, 1994, Vol. 1, pp. 1{7.
G. N. Solopchenko, \Formal metrological components of measuring systems", Measurement, 1994, Vol. 13, pp. 1{12.
D. A. Sprecher, \On the Structure of Continuous Functions of Several Variables",
Transactions Amer. Math. Soc., 1965, Vol. 115, No. 3, pp. 340{355.
D. A. Sprecher, \An Improvement in the Superposition Theorem of Kolmogorov",
Journal of Mathematical Analysis and Applications, 1972, Vol. 38, pp. 208{213.
H. Surmann et al., \What kind of hardware is necessary for a fuzzy rule based system?", In: Proceedings of the FUZZ-IEEE'94 International Conference, Orlando, FL,
July 1994, Vol. 1, pp. 274{278.
M. Takahashi, E. Sanchez, R. Bartolin, J. P. Aurrand-Lions, E. Akaiwa, T. Yamakawa,
48

[44]
[45]
[46]
[47]
[48]
[49]
[50]
[51]
[52]
[53]
[54]

and J. R. Monties, \Biomedical applications of fuzzy logic controllers", In: Intl. Conference on Fuzzy Logic and Neural Networks, Iizuka, Fukuoka, Japan, 1990, pp. 553{
556.
M. Togai and S. Chiu, \A fuzzy accelerator and a programming environment for realtime fuzzy control", In: Second IFSA Congress, Tokyo, Japan, 1987, pp. 147{151.
M. Togai and H. Watanabe, \Expert systems on a chip: an engine for real-time
approximate reasoning", IEEE Experts Systems Magazine, 1986, No. 1, pp. 55{62.
M. J. Tretter, \Interval analysis isn`t fuzzy is it?", Abstracts for an International
Conference on Numerical Analysis with Automatic Result Verication: Mathematics,
Application and Software, February 25 { March 1, 1993, Lafayette, LA, 1993, p. 104.
H. M. Wadsworth, Jr. (editor), Handbook of statistical methods for engineers and
scientists, McGraw-Hill Publishing Co., N.Y., 1990.
H. Watanabe and W. Detlo, \Recongurable fuzzy logic processor: a full custom
digital VLSI", In: Intl. Workshop on Fuzzy Systems Applications, Iizuka, Japan,
1988, pp. 49{50.
T. Yamakawa, \Fuzzy microprocessors { rule chip and defuzzier chip", In: Intl.
Workshop on Fuzzy Systems Applications, Iizuka, Japan, 1988, pp. 51{52.
T. Yamakawa, \Intrinsic fuzzy electronic circuits for sixth generation computer", In:
M. M. Gupta and T. Yamakawa (eds.), Fuzzy Computing, Elsevier, 1988, pp. 157{181.
H. Q. Yang, H. Yao, and J. D. Jones, \Calculating functions of fuzzy numbers", Fuzzy
Sets and Systems, 1993, Vol. 55, pp. 273{283.
Y. Yoshikawa, T. Deguchi, and T. Yamakawa, \Exclusive fuzzy hardware systems for
the appraisal of orthodentic results", In: Intl. Conference on Fuzzy Logic and Neural
Networks, Iizuka, Fukuoka, Japan, 1990, pp. 939{942.
L. A. Zadeh, \Fuzzy sets", Information and control, 1965, Vol. 8, pp. 338{353.
L. A. Zadeh, Outline of a new approach to the analysis of complex systems and decision
processes, IEEE Transactions on Systems, Man and Cybernetics, 1973, Vol. 3, pp.
28{44.

49
The author has requested enhancement of the downloaded file. All in-text references underlined in blue are linked to publications on ResearchGate.

From: AAAI-00 Proceedings. Copyright ¬© 2000, AAAI (www.aaai.org). All rights reserved.

Maintainability: a weaker stabilizability like notion for high level control
Mutsumi Nakamura
Department of CSE
University of Texas at Arlington
Arlington, TX 76019, USA
nakamura@cse.uta.edu

Chitta Baral
Department of CSE
Arizona State University
Tempe, AZ 85287, USA
chitta@asu.edu

Abstract
The goal of most agents is not just to reach a goal state, but
rather also (or alternatively) to put restrictions on its trajectory, in terms of states it must avoid and goals that it must
‚Äòmaintain‚Äô. This is analogous to the notions of ‚Äòsafety‚Äô and
‚Äòstability‚Äô in the discrete event systems and temporal logic
community.
In this paper we argue that the notion of ‚Äòstability‚Äô is too
strong for formulating ‚Äòmaintenance‚Äô goals of an agent ‚Äì in
particular, reactive and software agents, and give examples of
such agents. We present a weaker notion of ‚Äòmaintainability‚Äô
and show that our agents which do not satisfy the stability criteria, do satisfy the weaker criteria. We give algorithms to test
maintainability, and also to generate control for maintainability. We then develop the notion of ‚Äòsupportability‚Äô that generalizes both ‚Äòmaintainability‚Äô and ‚Äòstabilizability, develop an
automata theory that distinguishes between exogenous and
control actions, and develop a temporal logic based on it.

Motivation and Introduction
Stability has undergone extensive investigations in the control theory community (Passino & Burgess 1998), both for
continuous systems (e.g. Lyapunov stability and asymptotic
stability) and Discrete Event Dynamic Systems (DEDS)
(Ramadge & Wonham 1987b; 1987a; Ozveren, Willsky, &
Antsaklis 1991). All these notions can be summarized as in
(Passino & Burgess 1998):
We say that a system is stable if when it begins in a
good state and is perturbed into any other state it will
always return to a good state.
The appropriate stability notion in a particular case depends
on how the notions ‚Äúsystem‚Äù, ‚Äúbegins‚Äù, ‚Äústate‚Äù, ‚Äúgood‚Äù, and
‚Äúperturbed‚Äù are defined, For DEDS the mainstream definition can be found in (Ozveren, Willsky, & Antsaklis 1991),
and that definition is the one we use in this paper. They also
mention that relation between stability and the notions of
safety, fairness, livelock, deadlock are well studied. In this
paper we present a related notion which we call maintainability, and argue its importance, particularly for high level
control of agents.



Copyright c 2000, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.

Marcus BjaÃàreland
Department of Comp and Info Sc
LinkoÃàping University
S-581 83 Linkoping, Sweden
marbj@ida.liu.se

Intuitively, we can view stabilizability as a hard constraint
of the system while maintainability is a softer constraint. In
both maintainability and stabilizability our goal is that the
system should be among a given set of states E as much
as possible. In stabilizability, we want a control such that
regardless of where the system is now and what exogenous
actions may happen, the system will reach one of the states
in E within a finite number of transitions and keep visiting it infinitely often after that. In maintainability, we have
a weaker requirement where the system reaches a state in
E within a finite number of transitions, provided it is not
interfered with during those transitions. Thus in maintainability, we admit that if there is continuous interference (by
exogenous actions) we can not get to E in a finite number
of transition. Such a system will not satisfy the condition of
stabilizability, but may satisfy the condition of maintainability.
Many practical closed-loop systems are not stabilizable, but
they still serve a purpose and we believe that such systems purpose can be specified by using the weaker notion
of maintainability. An example of such a system is an active
database system (Widom & Ceri 1996) where ‚Äòconsistency‚Äô
of data is ‚Äòmaintained‚Äô using active rules (also referred to
as triggers). In such a database system, external updates
are made to the database through Insert, Delete and Update
commands. But the direct result of the updates may take
the database to an inconsistent state where ‚Äòintegrity constraints‚Äô of the database may be violated. In that case, the
active part of the database triggers rules that result in additional changes to the database to bring it back to a consistent
state. Now suppose E is the set of consistent states of a
database. We can not capture the correctness of the triggers
by directly using the notions of ‚Äòstability‚Äô. That is because,
if there is a continuous stream of external updates with no
time in between for getting back to consistency, then there is
no guarantee that the database will reach a state in E within
a finite number of transitions. But we can have a different
notion of correctness of triggers, where the triggers are correct if given a window of non-interference (from external
updates) the triggers will ultimately make the database consistent. In fact that is what happens in a database system
where external updates are blocked until the triggers bring
back the database to a consistent state.

Another example is a mobile robot (Brooks 1986; Maes
1991) which is asked to ‚Äòmaintain‚Äô a state where there are
no obstacles in its front. Here, if there is a belligerent adversary that keeps on putting an obstacle in front of the robot,
then the robot can not get to a state with no obstacle in its
front. But often we will be satisfied if the robot avoids obstacle in its front when it is not continually harassed. Of
course, we would rather have the robot take a path that does
not have such an adversary, but in the absence of such a path,
it would be acceptable if it takes an available path and ‚Äòmaintains‚Äô states where there are no obstacle in front.
Other examples include agents that perform tasks based on
commands. Here, the correctness of the agent‚Äôs behavior
can be formalized as ‚Äòmaintaining‚Äô states where there are no
commands in the queue. We can not use the notion of stability because if there is a continuous stream of commands,
then there is no guarantee that the agent would get to a state
with no commands in its queue within a finite number of
transitions.
The rest of the paper is structured as follows. We first formally define the notion of stability and stabilizability. We
then introduce the notion of maintainability and compare it
with the notion of stabilizability. Next we show that the correctness of an active database can be formalized as maintainability of consistent states. We then present algorithms
to verify maintainability, and to construct controls to make a
system maintain a set of states. Finally, we develop a general
notion called supportability and show that stabilizability and
maintainability are special cases of it.

Alternatively, A is stable w.r.t. E if, for any state x 62 E ,
every infinite trajectory starting with x will lead to E in a
finite number of steps.
Definition 0.4 R(A; x) denotes the set of states that can be
reached from x in a system A.

A state x is said to be alive if d(y ) 6= ;, for all y 2 R(A; x).
(I.e., we can not reach a state y from x, where no action is
possible.)
We say A

2

Stabilizability
We now consider control and exogenous actions. The set of
control actions U is a subset of , that can be performed by
the (controlling) agent. A particular control K is a function
from X to U . The set of exogenous actions that can occur in
a state (and that are beyond the control of the agent) is given
by a function e from X to 2 , such that e(x)  d(x).

Definition 0.5 Let A = (X; ; f; d) be a system. In presence of e, U , and K , we define AK 1 , the closed loop system of A as the four-tuple (X; ; f; dK ), where dK (x) =
(d(X ) \ fK (x)g) [ e(x).
2.
Definition 0.6 Given a system A, a function e, and a set of
states E , we say S  X is stabilizable with respect to E if
there exists a control law2 K such that for all x in S , x is
alive and stable with respect to E in the closed loop system
Ak . If S = X , we say A is stabilizable with respect to E .

2

Reviewing stability and stabilizability
In this section we review the notions of stability and stabilizability adapted from the definitions in (Ozveren, Willsky,
& Antsaklis 1991).

Stability and aliveness

Definition 0.1 A system A is a 4-tuple (X; ; f; d), where
X is a finite set of states,  is a finite set of actions, d is a
function from X to 2 listing what actions may occur (or
are executable) in what state, and f is a non-deterministic
2
transition function from X and  to 2X .
Definition 0.2 A trajectory is an alternating sequence of
states and actions, and could be either a finite trajectory that
starts and ends with a state or an infinite trajectory.
A trajectory x0 ; a1 ; x1 ; a2 ; : : : ; xk ; ak+1 ; xk+1 (: : :) is said
to be consistent with a system A if:

 xk+1 2 f (xk ; ak+1 ), and
 ak+1 2 d(xk ).
2
Definition 0.3 Given a system A and a set of states E , a
state x is said to be stable in A w.r.t. E if all trajectories
consistent with A and starting from x go through a state in
E in a finite number of transitions and they visit E infinitely
often afterwards.
We say A = (X; ; f; d) is a stable system if all states in X
are stable in A w.r.t. E .
2

= (X; ; f; d) is alive if all states in X are alive.

Maintainability
Our intuition behind maintainability is that we would like
our system to ‚Äòmaintain‚Äô a formula (or a set of states where
the formula is satisfied) in presence of exogenous actions.
By ‚Äòmaintain‚Äô we mean a weaker requirement than the temporal operator always (2) where 2f means that f should
be true in all the states in the trajectory. The weaker requirement is that our system needs to get to a desired state within
a finite number of transitions provided it is not interfered in
between by exogenous actions. The question then is what
role the exogenous actions play.
Our definition of maintainability has parameters as a set of
initial states S , that the system may be initially in, a set of
desired state E , that we want to maintain, a system A and
a control law K . Our goal is to formulate when the control
law K maintains E assuming that the system is initially in
one of the states in S . We account for the exogenous actions
by defining the notion ‚Äì Closure(S; A) ‚Äì of a closure of
S with respect to A. This closure is the set of states that
the system may get into starting from S . Then we define
maintainability by requiring that the control law be such that
A more appropriate terminology would be AK;e . We use
to remain consistent with the usage in (Ozveren, Willsky, &
Antsaklis 1991).
2
It is also referred to as ‚Äòfeedback law‚Äô, ‚Äòfeedback control‚Äô or
‚Äòstate feedback‚Äô in the literature.

A

1

K

if the system is in any state in the closure and is given a
window of non-interference from exogenous actions then it
gets into a desired state.
Now a question might be that suppose the above condition
of maintainability is satisfied, and while the control law is
leading the system towards a desired state an exogenous action happens and takes the system off that path. What then?
The answer is that the state that the system will reach after
the exogenous action will be a state from the closure. Thus,
if the system is then left alone (without interference from
exogenous actions) it will be again on its way to a desired
state. So in our notion of maintainability, the control is always taking the system towards a desired state, and after any
disturbance from an exogenous action, the control again puts
the system on a path to a desired state.
We now formally define the notions of closure and maintainability.
Definition 0.7 Let A = (X; ; f; d) be a system and S
be a set of states. By Closure(S; A) we refer to the set
2
x2S R(A; x).

S

Definition 0.8 Given a system A = (X; ; f; d), a set of
control actions U  , a specification of exogenous actions e, and a set of states E , we say a set of states S is
k-maintainable with respect to E if there exists a feedback
control K such that from each state x in Closure(S; AK ),
we will get to a state in E with at most k transitions, where
each action (behind the transitions) is dictated by the control
K.
If there exists an integer n such that S is n-maintainable with
respect to E , we say S is maintainable with respect to E .
If S

= X , then we say A is maintainable with respect to E .
2

We now show that while stabilizability guarantees maintainability, the opposite is not true.
Proposition 0.1 Given a system A, if a set of states S is
stabilizable with respect to a set of states E , then S is maintainable with respect to E .
2

Proof : Suppose that a set S  X and S is stabilizable with
respect to E . Then there exists a control law K such that for
each x 2 S , x is alive and is stable with respect E .
Claim: There is a trajectory from each state x in S to a state
in E with a finite transitions.
Case 1. Suppose x 2 S . Then x is stable, therefore we can
get from x to a state in E with a finite number of transitions
dictated by K , say nx transitions.
Case 2. Suppose x 2 Closure(S; A)nS . Then there exists y 2 S such that there is a trajectory T from y which
goes through x. Since y 2 S , y is stabilizable. Thus
all trajectories consistent with A and starting from y go
through a state in E in a finite number of transitions and
they visit E infinitely often afterwards. Therefore any trajectory from y which goes through x will visit E infinitely.
Thus there must be a sub trajectory T 0 from x to a state in
E which is contained in the trajectory T from y to a state
in E through x. Through this trajectory T 0 , we can reach

from x to a state in E in a finite number of transitions dictated by K , say nx . Note that the maximum possible cardinality of Closure(S; A) is the cardinality of X . Thus it
is finite. Let n be maxfnx jx 2 Closure(S; A)g. Since
Closure(S; A) is finite, n exists (n < 1) and from all
states in Closure(S; A) we can reach a state in E within
n transitions dictated by K . Hence S is n-maintainable with
respect to E and thus S is maintainable with respect to E . 2
But the converse of the above proposition is not true. I.e.
Maintainability does not necessarily imply stabilizability.
We now show an example of a system which is maintainable but is not stabilizable.

P

Consider a system A = (X; ; f; d) with the following:
X = fs1 ; s2 ; s3 ; s4 ; s5 g,
= fa1; a2 ; a3 ; a4 ; a5 g fe1 ; e2g;

P

S

d(s1 ) = fa1g, d(s2 ) = fa2; e1 ; e2 g, d(s3 ) = fa3 g,
d(s4 ) = fa4 g, d(s5 ) = fa5 g
f (s1 ; a1 ) = fs2g, f (s2 ; a2 ) = fs4 g, f (s2 ; e1 ) = fs3 g,
f (s2 ; e2) = fs2 g, f (s3 ; a3 ) = fs4 g, f (s4 ; a4 ) = fs5 g,
f (s5 ; a5 ) = fs4g
Given E = fs4 ; s5 g, this system is maintainable, but is not
stabilizable. With the control law K , where K (si ) = ai ,
with at most 3 transitions, we can reach from any state in X
to a state in E , therefore it is maintainable. But if we consider all trajectories, at the state s2 , the exogenous action e2
can keep interfering and we might never reach from the state
s2 to a state in E . Therefore it is not stabilizable. 2
Maintainability in an active database
In this section we show how the notion of ‚Äòmaintainability‚Äô
is useful in defining the correctness of an active database.
Consider an active database with the following aspects:
 Relational Schema:

Employee(Emp#; Name; Salary; Dept#)
Dept(Dept#; Mgr#)
 Goal of the active database: Maintain Integrity constraints. I.e., Maintain the database in states where
(i) If (e; n; s; d) is a tuple in Employee then there
must be a tuple (d0 ; m0 ) in Dept such that d = d0 ;
and
(ii) If (d; m) is a tuple in Dept, then there must be
a tuple (e0 ; n0 ; s0 ; d0 ) in Employee such that d = d0
and m = e0
(In addition we may have other constraints ‚Äì which we
do not focus here ‚Äì such as each department has a single manager and each employee works in a single department.)
 Exogenous actions are of the kind: Delete (E; N; S; D)
from Employee. (The direct effect of this action is the
deletion of the tuple.)

 Triggers are of the kind:

1. For any Delete (e; n; s; d) from Employee, if (d; e) is
a tuple in Dept, delete that tuple from Dept and delete
all tuples of the form (e0 ; n0 ; s0 ; d0 ) from Employee,
where d = d0 .

To formulate the correctness of such an active database, we
can treat the triggers as control laws, as was done initially
in (Ceri & Widom 1990). The overall system operates in a
way that whenever an exogenous action occurs if it modifies
the database such that integrity constraints are violated, the
triggers (control laws) kick in and force additional changes
to the database such that it reaches a state where the integrity
constraints are satisfied. This can be formulated as maintenance of the integrity constraints.
Now, if there were a continuous stream of exogenous actions (whose direct effects were immediately reflected in the
database) then there is no guarantee that the database would
reach a state satisfying the integrity constraints within a finite number of transitions. Hence, we can not formulate this
as stabilizability.
Another important aspect of maintainability is that in reactive software systems like this, if we know that our system is k-maintainable, and each transition takes say at most
t time units, then we can implement a transaction mechanism that will regulate the number of exogenous actions al1 . This will also be useful in
lowed per unit time to be k
t
web-based transaction softwares where exogenous actions
are external interactions and the internal service mechanism
is modeled as control laws. On the other hand, given a requirement that we must allow m requests (exogenous actions) per unit time, we can work backwards to determine
the value of k , and then find a control to make the system
k-maintainable. In general, since in high level controls we
may have the opportunity to limit (say through a transaction
mechanism) the exogenous actions, we think ‚Äòmaintainability‚Äô is an important notion for high level control.

Algorithms
In this section we give two simple algorithms to verify maintainability, and to generate control for maintainability. We
will further analyze them in the full paper.

Testing maintainability

Input: A system A = (X; ; f; d), a set of states E , a set of
states S , and a control K .

Output: To find out if S is maintainable with respect to E ,
using the control K .
Algorithm:
Step 1: Compute Closure(S; AK ).
Step 2: For each
quence

x in Closure(S; AK ) compute the se-

x0 ; x1 ; : : : ; xk ; xk+1 ; : : : ; xjX j , where x0 = x, and xk+1 =
xk if xk 2 E , and xk+1 = f (xk ; K (xk )) otherwise.

Step 3: If for all x, fx0 ; : : : ; xjX j g \ E 6= ; then S is maintainable with respect to E , using the control K ; Otherwise it
is not maintainable with respect to E , using the control K .

Generating control for maintainability of a set of
states
Input: A system A
set of states S .

= (X; ; f; d), a set of states E , and a

Output: Find a control K such that S is maintainable with
respect to E , using the control K .
Algorithm:
Step 0: Sin

:= S , Sout = ;.
Step 1: While Sin 6= Sout Do.
Pick an x from Sin n Sout . Find a shortest path (or a minimal
cost path) from x to a state in E using only control actions.
If no such path exists then EXIT and return(FAIL).
Let a be the first action of that path.
Assign K (x) = a.
Sout := Sout [ fxg
Sin := Sin [ ff (x; a)g [ fx : x 2
e(X )g.
Step 2: If Sin

f (x; b); for some b 2

= Sout , return(Sout; K ).

Proposition 0.2 If the above algorithm terminates by returning S 0 and K , then: (i) S 0 = Closure(S; AK ), and (ii)
S is maintainable with respect to E , using the control K . 2
One important aspect of the above algorithm and its proof
of correctness is the requirement of picking the first action
of a shortest path or a minimal cost path. Picking the first
action of a minimal path (as normally used in the notions of
minimal plans) will not be sufficient as that may lead to cycles and the system may never reach its goal. An algorithm
based on a minimal path will have to be more complicated
so as to avoid this. On the other hand, our use of shortest
path allows us to easily enhance the control when additional
states are added to S . We then only need to consider the new
states in the closure, find shortest paths from each of these
states (say x), and have the first action as the value of K (x).
Thus our algorithm is useful in incrementally broadening the
control when the set of initial states S is broadened.
At this point we would like to point out the relation between
our work here and some research on reactive and situated
agents (Kaelbling & Rosenschein 1991). In (Kaelbling &
Rosenschein 1991), they say that in a control rule ‚Äòif c then
a‚Äô, the action a, must be the action that leads to the goal from
any situation that satisfies the condition c. The above algorithm interprets the notion of ‚Äòleading to‚Äô as the first action
of a minimal cost plan.

Supportability: a notion that generalizes
stabilizability and maintainability
In this section we generalize the notion of maintainability
and show that the notion of stabilizability is a special case

of this generalization. Our generalization is based on the
intuition that perhaps, we can allow a limited number of
exogenous actions during our so called ‚Äòwindow of noninterference‚Äô and still be able to get back to a state in E .
We refer to this general notion as supportability.
Definition 0.9 Given a system A = (X; ; f; d), a set of
agents action U  , a specification of exogenous actions
e, and a set of states E , we say a set of states S is (k,l)supportable (l  k ) with respect to E if there exists a control
law K such that for each state x in Closure(S; AK ), all
trajectories ‚Äì consistent with AK ‚Äì from x whose next k
transitions contain at most l transitions due to exogenous
actions and the rest is dictated by the control K , reach a
state in E by the k -th transition.
2
Proposition 0.3 (k; 0)-supportable is equivalent to k maintainable. (A set of states S is (k; 0)-supportable with
respect to a set of states E if and only if S is k -maintainable
with respect to E .)
Proposition 0.4 A set of states S is stabilizable iff S is
alive and there exists an integer m such that S is (m,m)supportable with respect to E .

An automata and a temporal logic for
‚Äòmaintainability‚Äô and ‚Äòsupportability‚Äô
The notion of a system defined earlier does not distinguish
between exogenous action and control action. They are both
part of . In this section we first define the notion of a 2system where we distinguish between exogenous and control actions. Using the notion of a two system we define the
notion of ‚Äòmaintained‚Äô which is analogous to the notion of
being ‚Äòstable‚Äô and related it to our earlier notion of maintainability. We then use the notion of 2-systems to define
a temporal logic that makes the distinction between transitions due to exogenous action and transitions due to control
actions.
Definition 0.10
A 2-system A is a 5-tuple (X; a ; e ; f; d), where X is a
finite set of states, a is a finite set of control actions, e
is a finite set of control events, d is a function from X to
2a [e listing what actions and events may occur (or are
executable) in what state, and f is a transition function from
X and a [ e to 2X .
2
The notion of a trajectory with respect to a 2-system remains
the same as with respect to a system, which we earlier defined in Definition 0.2.
Definition 0.11 Given a 2-system A and a set of
states E , a state x is said to be k-maintained in A
w.r.t.
E if for all trajectories of the form x =
x0 ; a1 ; x1 ; a2 ; : : : ; aj ; xj ; aj+1 ; : : : that is consistent with A
and for all i such that fai+1 ; : : : ; ai+k g  a , we have that
fxi+1 ; : : : ; xi+k g \ E =
6 ;.
A 2-system A = (X; a ; e ; f; d) is k-maintained with respect to E if all its states are k-maintained.

A 2-system A = (X; a ; e ; f; d) is maintained with respect to E if there exists a positive integer n such that it is
n-maintained with respect to E .
2

Proposition 0.5 A state x is k-maintainable in a system
A = (X; a [ e ; f; d) with respect to E iff there exists
a control law K such that x is k-maintained with respect to
E in the 2-system AK = (X; a ; e ; f; dK ), where dK is
as defined earlier in Definition 0.5.

A temporal language with respect to 2-systems
In the past, temporal logic has been used to specify and verify the behavior of reactive systems (Manna & Pnueli 1992;
Clarke, Emerson, & Sistla 1986; Kabanza, Barbeau, & StDenis 1997). Most of these temporal logics do not (perhaps
with the exception of one description in (Singh 1994)) distinguish between transitions due to control actions and due
to exogenous actions. Hence, they are too strong to be able
to characterize the correctness of reactive software systems
such as an active database system. In this section we propose a temporal language that makes a distinction between
transitions due to control actions and exogenous actions and
is able to characterize correctness of reactive software systems such as an active database system. We plan to elaborate
on this in the full paper.
Some of the important future temporal operators as discussed in (Manna & Pnueli 1992) are: Next (), Always
(2), Eventually (), and Until (U ). There meaning with respect a trajectory  = x0 ; a1 ; x1 ; : : : ; xj ; aj +1 ; xj +1 ; : : : is
defined as follows:

 (; j ) j= p iff p is true in xj .

 (; j ) j= p iff (; j + 1) j= p

 (; j ) j= 2p iff (; k ) j= p, for all k  j .

 (; j ) j= p iff (; k ) j= p, for some k  j .
 (; j ) j= p U q iff there exists k 
and for all i, j  i < k , (; i) j= p.

j such that (; k) j= q

It is easy to see that none of the above temporal operators
consider the action type (whether exogenous or control action) behind the transitions. We now introduce some temporal operators that do consider the action type behind the
transitions.

 (; j ) j= k p iff
fai+1 ; : : : ; ai+k g 
r  k.

i  j is the smallest index such that
a and (; i + r) j= p, for some 1 

 (; j ) j= 2k p iff for all i  j if fai+1 ; : : : ; ai+k g 
then (; i + r) j= p for some 1  r  k .

a

 (; j ) j= k;l p iff i  j is the smallest index such that
jfai+1 ; : : : ; ai+k g \ e j  l and (; i + r) j= p for some
1  r  k.
 (; j ) j= 2k;l p iff for all i  j if
jfai+1 ; : : : ; ai+k g \ e j  l then (; i + r) j=
1  r  k.

p for some

We can describe the intuitive meaning behind the above
formal definitions as follows: Intuitively, (; j ) j= 2k p
means that starting from xj , within or after any k consecutive transitions due to control actions p holds. Similarly,
(; j ) j= 2k;l p means that starting from xj , within or after
any k transitions with at most l exogenous actions p holds.

Proposition 0.6 (i) (; j ) j= 2k p iff (; j ) j= 2k;0 p.
(ii) (; j ) j= k p iff (; j ) j= k;0 p.

(iii) Let Ep be the set of states, where a formula p holds. S
is (k; l)-supportable w.r.t. Ep iff for all trajectories  whose
x0 2 S , and for all j , (; j ) j= 2k;l p.
2

Corollary 0.7 1. Let Ep be the set of states, where a formula p holds. S is k maintainable w.r.t. Ep iff for all trajectories  whose x0 2 S , and for all j , (; j ) j= 2k p.
2. Let Ep be the set of states, where a formula p holds. S
is stabilizable w.r.t. Ep iff S is alive and there exists an m
such that for all trajectories  whose x0 2 S , and for all j ,
(; j ) j= 2m;m p.

Conclusion and related work
In this paper we formalized the notion of ‚Äòmaintenance‚Äô often mentioned (Baral & Son 1998) in the context of robots
and agents, as a property of a discrete event dynamic system (DEDS) and compared it with the notion of ‚Äòstability‚Äô
and ‚Äòstabilizability‚Äô that are most popular in DEDS. We argued why ‚Äòmaintainability‚Äô may be a more preferred notion
for certain systems and discussed active database systems
as an example. We then gave simple algorithms for testing
maintainability and generating control for maintainability.
We then developed the notion of ‚Äòsupportability‚Äô that generalizes both ‚Äòmaintainability‚Äô and ‚Äòstabilizability. Finally, we
developed an automata theory that distinguishes between exogenous and control actions, and developed a temporal logic
based on it. Our basic formulation of ‚Äòmaintainability‚Äô is related to the work in (Baral & Son 1998).
Among the other related works, there has been some work
on defining stability of continuous systems in the presence
of discontinuities and disturbances; for example (Sontag
1999). In the planning literature there has been some work
on planning for temporal goals (Bacchus & Kabanza 1998;
Weld & Etzioni 1994) where goals are expressed as temporal formulas. But they use the traditional temporal operators which by themselves can not express our notion of
‚Äòmaintenance‚Äô. Another related notion is planning from the
current situation in a dynamic domain (Baral, Gelfond, &
Provetti 1997) and execution monitoring (DeGiacomo, Reiter, & Soutchanski 1998). In both these notions ‚Äòmaintenance‚Äô is achieved by monitoring (or observing) the world
for discrepancies and making new plans to recover. Finally, the notion of ‚Äòself-stabilization‚Äô (Dijkstra 1974) in distributed and fault-tolerant computing seems to be similar to
our notion of ‚Äòmaintenance‚Äô and we plan to compare and
contrast them in the sequel.

References
Bacchus, F., and Kabanza, F. 1998. Planning for temporally extended goals. Annals of Math and AI 22:5‚Äì27.
Baral, C., and Son, T. 1998. Relating theories of actions
and reactive control. Electronic transactions on Artificial
Intelligence 2(3-4).

Baral, C.; Gelfond, M.; and Provetti, A. 1997. Representing Actions: Laws, Observations and Hypothesis. Journal
of Logic Programming 31(1-3):201‚Äì243.
Brooks, R. 1986. A robust layered control system for a
mobile robot. IEEE journal of robotics and automation
14‚Äì23.
Ceri, S., and Widom, J. 1990. Deriving production rules
for constraint maintainance. In VLDB 90. 566‚Äì577.
Clarke, E.; Emerson, E.; and Sistla, A. 1986. Automatic
verification of finite-state concurrent systems using temporal logic specifications. ACM Transactions on Programming Languages and Systems 8(2):244‚Äì263.
DeGiacomo, G.; Reiter, R.; and Soutchanski, M. 1998. Execution monitoring of high-level robot programs. In Proc.
of KR 98, 453‚Äì464.
Dijkstra, E. W. 1974. Self-stabilizing systems in spite of
distributed control. CACM 17(11):843‚Äì644.
Kabanza, F.; Barbeau, M.; and St-Denis, R. 1997. Planning control rules for reactive agents. Artificial Intelligence
5(1):67‚Äì113.
Kaelbling, L., and Rosenschein, S. 1991. Action and planning in embedded agents. In Maes, P., ed., Designing Autonomous Agents. MIT Press. 35‚Äì48.
Maes, P., ed. 1991. Designing Autonomous Agents.
MIT/Elsevier.
Manna, Z., and Pnueli, A. 1992. The temporal logic of
reactive and concurrent systems: specification. Springer
Verlag.
Ozveren, O.; Willsky, A.; and Antsaklis, P. 1991. Stability and stabilizability of discrete event dynamic systems.
JACM 38(3):730‚Äì752.
Passino, K., and Burgess, K. 1998. Stability Analysis of
Discrete Event Systems. Adaptive and Learning Systems
for Signal Processing, Communications, and Control. New
York: John Wiley and Sons, Inc.
Ramadge, P., and Wonham, W. 1987a. Modular feedback
logic for discrete event systems. SIAM Journal of Control
and Optimization 25(5):1202‚Äì1217.
Ramadge, P., and Wonham, W. 1987b. Supervisory control of a class of discrete event process. SIAM Journal of
Control and Optimization 25(1):206‚Äì230.
Singh, M. 1994. Multiagent systems - a theoretical
framework for intentions, know-how, and communications.
Springer-Verlag.
Sontag, E. 1999. Stability and stabilization: Discontinuities and the effect of disturbances. In Clarke, F., and Stern,
R., eds., Proc. NATO advanced study institute, July/Aug
1998. Kluwer. 551‚Äì598.
Weld, D., and Etzioni, O. 1994. The first law of robotics (a
call to arms). In AAAI, 1042‚Äì1047.
Widom, J., and Ceri, S., eds. 1996. Active Database Systems - Triggers and Rules for advanced database processing. Morgan Kaufmann.

ON HARDWARE SUPPORT FOR INTERVAL COMPUTATIONS AND FOR SOFT COMPUTING: THEOREMS
Hung T. Nguyen, Vladik Kreinovich, Member, IEEE, Vyacheslav Nesterov, and Mutsumi Nakamura

Abstract. This paper provides a rationale for providing hardware supported functions of
more than two variables for processing incomplete knowledge and fuzzy knowledge. The result is in contrast to Kolmogorov's theorem in numerical (non-fuzzy) case.

1. INTRODUCTION
In this paper, we show that for interval computations and for processing fuzzy data (i.e., for soft computing), it is desirable to have hardware supported operations with more than two operands. Before we formulate the problem and go into technical details, we would like to emphasize the importance of this problem by brie y describing in Subsection 1.1 the practical origin (and practical necessity) of interval computations and soft computing.

1.1. Estimating accuracy of the results of data processing: crisp and fuzzy cases
values of the physical quantities. For example, in order to decide whether to approve the scheduled launch of a Space Shuttle, we must know the characteristics of the Shuttle (to make sure that all its systems work), and weather conditions around the launch site during the launch time. Some of these characteristics can be measured directly: e.g., characteristics of the Shuttle's electric systems can be measured by testers. Some of the desired characteristics can be estimated by experts: e.g., some experts meteorologists can provide us with reasonably good short-time weather predictions for a given area. Hung T. Nguyen is with the Department of Mathematical Sciences, New Mexico State University, Las Cruces, NM 88003, USA, email hunguyen@nmsu.edu Vladik Kreinovich is with the Department of Computer Science Department, University of Texas at El Paso, El Paso, TX 79968, USA, email vladik@cs.utep.edu Vyacheslav Nesterov is with the Institute of New Technologies, P. O. Box 52, St. Petersburg 256, 195256 Russia, email nest@into.nit.spb.su Mutsumi Nakamura is with the Department of Mathematics, University of Texas at Austin, Austin, TX 78712, USA, email mutsumin@math.utexas.edu 1

Data processing: why? To make decisions, we must have some information about the

In some cases, however, it is very di cult (or even impossible) to measure the characteristic y that we are interested in, and there are no experts who can predict the values of these characteristics. For example, it is very di cult to directly measure the temperature inside the jet chamber (because this temperature is extremely high); if we are planning a mission to a new planet, it is simply impossible to directly measure the characteristics of the new environment before the mission actually gets there, and often, no expert can help. If we are interested in the value of such a characteristic y, and we cannot estimate y directly (either by measurement, or by using experts), then a natural idea is to estimate y indirectly, i.e.: to estimate some other (easier to estimate) quantities x1 ; :::; xn that are related to y, and then to compute the estimate y ~ for y based on the estimates x ~1 ; ::; x ~n for x1 ; :::; xn. This process is called data processing, and this is what super-computers are doing most of the time: from measured characteristics x ~i of observed collisions in the accelerators, they reconstruct the (directly unobservable) properties of the elementary particles; from the results x ~i of geophysical measurements, computers predict the amount y of oil (or other mineral) in a given area, etc. In this paper, we will assume that we already know what characteristics xi to measure, and how to reconstruct y from xi . In other words, we will assume that we know an algorithm f (x1; :::; xn) that transforms the values of xi into an estimate for y. This algorithm is not necessarily simple: e.g., in geophysics, it may involve solving a complicated non-linear integral equation (\inverse problem"); in elementary particle physics, it may involve solving a system of non-linear operator quantum equations, etc. we know the algorithm f means that if we know the exact values of the variables x1 ; :::; xn, we can then apply the algorithm f and compute the exact value of y. In reality, however, we only know some estimates x ~i for xi that are obtained either by measurements or by an expert estimation. Measurements are never 100% precise; expert estimates are not absolutely precise either. As a result, the available values x ~i di er from the actual (unknown) values xi ; therefore, the estimate y ~ = f (~ x1; :::; x ~n) that we obtain by processing the available data may di er from the desired value y = f (x1; :::; xn).

The result of data processing is never absolutely accurate. The assumption that

In real-life applications, we must know the accuracy of the result of data processing. For practical purposes, it is important to know how di erent the result y ~ of data
processing can be from the actual value y. 2

For example, if we want to decide whether a particular well is worth drilling, and the estimate for the amount of oil is y ~ = 100 mln. tons, then before we start drilling, we would like to know whether this is, say, 100 1, in which case, we should probably start drilling, or it is 100 100 (maybe 100, maybe 0, maybe 200), in which case we would rather undertake further (and more accurate) measurements. In this paper, we consider the problem of nding this accuracy. both measurement results and expert estimates are present, let us consider the simplest case, where there is no expert knowledge, and all the data come from the measurements. In traditional measurement theory (see, e.g., 8,47,35]), it is usually assumed that we know the probabilities of di erent values of a measurement error. These values can be obtained if we calibrate the measuring instrument, i.e.: we use the calibrated instrument in conjunction with a much more accurate one (called a standard) in several measurements; for each measurement, we compute a di erence e(k) = x ~(k) ? x(k) between the results of these two instruments, and use this di erence as an estimate of the error of the measurement performed by the calibrated instrument; reconstruct the error probability distribution from the recorded sample errors e(1) , ..., e(N ) . For the situations in which we know the probabilities of di erent errors, there exist numerous methods that compute statistical characteristics of the resulting error. In many real-life situations, however, the values of the probabilities are not known: in advanced measurements (in radio-astronomy, in elementary particle physics, etc), we are using measuring instruments that have the highest accuracy possible, so, there is simply no \more accurate" measuring instrument that we can for calibrating; in manufacturing applications, we can potentially calibrate all the sensors that we use, but this calibration would cost much more than the sensors themselves, so it is usually not done. In these situations, the manufacturer of the measuring instrument provides us with the guaranteed accuracy , i.e., with a guaranteed upper bound of the error x = x ~ ? x (e.g., \error cannot exceed 0.1"). If our measurement results is x ~, then the possible values of x=x ~ ? x form an interval x ~? ;x ~ + ]. Since we are dealing with intervals, the entire area is called interval computations (see, e.g., 29,11,10,18,14]). 3

Simplest case: measurements only. Before we start analyzing the general case, where

The set of possible values of an error is not necessarily an interval. For example, suppose that we are measuring the current inside the computer, and we know that the error cannot exceed a certain value . If we know nothing else about the error, then we may conclude that the error belongs to the interval ? ; ]. However, we may know that the error is caused by the in uence of a nearby magnetic memory element, which can be in two possible states (corresponding to \0" and \1"). In this case, the error is either positive, or negative (depending on the state), but never 0; actually, the error can never be smaller than some value . In this case, the set X of possible values of the error is not an interval, but a union of two intervals: X = ? ; ? ] ; ]. There can be more complicated cases, in which the error can be described by more complicated (crisp) sets X of possible values. In this case, our problem takes the following form:
We know: an algorithm f that transform n real numbers x1; :::; xn into a real number y = f (x1; :::; xn); sets X1 R, ..., Xn R that contain the actual values of xi ; We must compute: The set Y of possible values of y:

Y = ff (x1; :::; xn) j x1 2 X1; :::; xn 2 Xng
This set Y is usually denoted by f (X1; :::; Xn).

(1:1)

A measuring instrument can measure several di erent quantities x1; :::; xn at a time. In this case, in addition to the information about the possible errors of each measurement, the manufacturer can guarantee that certain combinations of errors are impossible: e.g., it can happen that x1 attains its largest possible value , and it can happen that x2 attains its largest possible value , but they can never attain these extreme values at the 2 (this situation happens, e.g., same time, because of the restriction that x2 1 + x2 2 if we measure geographical coordinates of a point). Such an information can be described by a set X Rn of all the tuples that the manufacturer believes can be possible values of errors ( x1; :::; xn). In this case, the problem takes the following form:

4

We know: an algorithm f that transform n real numbers x1; :::; xn into a real number y = f (x1; :::; xn); a set X Rn that contains the actual value of ~ x = (x1; ::; xn); We must compute: The set Y of possible values of y:

Y = ff (x1; :::; xn) j (x1; :::; xn) 2 X g
This set Y is usually denoted by f (X ).

(1:2)

The previous formulation is a particular case of this one if we take X = X1 ::: Xn. General case: processing data that includes expert knowledge as well. In many cases, in addition to measurements results, we have expert's knowledge about the variables x1 ; :::; xn. For example, in order to make a decision on what doze of radiation to assign to a patient, we must know not only the characteristics that are measurable (like blood count, tumor size, etc), but the characteristics that can only be estimated by an expert (e.g., the granularity of a tumor can be \small" or \medium"). We want to process this informal information automatically, therefore, we must be able to represent it in the computer. A word like \medium-size" does not describe one particular value; it can correspond to several di erent values; some of them are more reasonably described as \medium-size", some values can be in principle described as such, but only occasionally. To describe the meaning of each word, we ascribe to every real number x a value (x) 2 0; 1] that describe to what extent it is reasonable to assume that x is, say, medium-size (1 means that it is absolutely reasonable, 0 that it is not reasonable at all). The resulting function is called a membership function, or a fuzzy set. In some cases, the expert's informal statement describes not one variable, but several of them. For example, if we say that a point with coordinates x1 ; x2 is close to 0, this means that both x1 and x2 are close to 0. Such knowledge can be represented by a function from R2 to 0,1]. This membership function is called a fuzzy subset of R2. If we have such information about xi , and we want to estimate y, we get the following problem: We know: a function f of n variables; a fuzzy set X Rn that describes our knowledge about ~ x = (x1 ; :::; xn). We want: to describe the resulting knowledge about y in terms of a fuzzy set Y . This problem was formulated, e.g., in 1,46,39], and it has appeared in many practical cases, including: 5

testing jet engines 22,20,21]; seismic analysis 3,4]; image processing 19,20,21], etc.

The desired description of the set Y is known as extension principle. This principle was proposed by Zadeh in his pioneer paper 53] (see also 54] and 5]), and it is based on the following idea: A real number y ~ is a reasonable value of y if and only if there exist values x ~1; :::x ~n for which x ~1 is a possible values of x1 , x ~2 is a possible value of x2 , ..., and f (~ x1; :::; x ~n) = y ~. If we follow the traditional fuzzy set theory and interpret \and" as min, and \there exists" as sup, then we arrive at the following formula:

x); f (~ x; y)); Y (y ) = supn (min( X (~ ~ x2R
where f is a characteristic function of the graph of the function f (i.e., (~ x; y) = 1 if f (~ x) = y, and 0 otherwise). Due to this formula, values ~ x for which f (~ x) 6= y, do not in uence on Y (y). Therefore, this formula can be rewritten as follows:

x): Y (y ) = sup X (~ ~ x:f (~ x)=y

(1:3)

This formula is called the extension principle, and the resulting fuzzy set Y is denoted by f (X ). If instead of X , we have n separate fuzzy sets X1 ; :::; Xn that describe our knowledge about x1 ; :::; xn, then similar arguments lead to a formula
Y (y ) = sup min( X1 (x1 ); :::; Xn (xn )): ~ x:f (~ x)=y

(1:4)

The resulting fuzzy set Y is denoted by f (X1; :::; Xn).
Comments. 1. In particular, if we take elementary arithmetic operations (+; ; ?, etc) as f , we get the de nition of arithmetic operations with fuzzy operands X1; :::; Xn.

2. The statement that we have just formalized contains two logical terms: \and" and \there exists". So, to formalize it, we must formalize what these two logical terms mean. 6

\There exists" can be viewed as an in nite \or": namely, \there exist x ~1 ; :::; x ~n with a certain property" means that this property is either true for, say, (0:0; :::; 0:0), or for (1:1; 0:2; :::; 2:3), or for any of in nitely many tuples of n real numbers. Therefore, to get an interpretation of \there exists", we must choose an appropriate fuzzy interpretation f_(a; b) of _ and apply the resulting _?operation f_ in nitely many times (i.e., apply it to N tuples and then take N ! 1). In fuzzy logic, many di erent _?operations have been proposed (e.g., f_(a; b) = a + b ? a b); these operations are also called t?conorms. A usual (and natural) restriction on a t?conorm f_ comes from the fact that for every two statement A and B , our degree of belief in A _ B must be at least as big as the degree of belief in each of these statements A and B . If we denote the degree of belief in A by t(A), then this condition turns into f_(t(A); t(B )) t(A) and f_ (t(A); t(B )) t(B ). In other words, for every a and b, f_(a; b) max(a; b). If we choose one of the known t?conorms for which f_(a; b) > max(a; b) (e.g., if we choose f_ (a; b) = a + b ? ab), then, the more times we apply f_ , the larger the resulting degree of belief, and in the limit, we get 1. For example, for f_ (a; b) = a + b ? ab = 1 ? (1 ? a) (1 ? b), disjunction of N formulas with the same degree of belief a 2 (0; 1) leads to f_(a; : : :; a) = 1 ? (1 ? a)N , and this expression ! 1 as N ! 1. (Here, f_(a; b; :::; c) stands for f_(:::(f_(a; b); :::); c), i.e., it means that we apply the _?operation N times.) A similar result can be proven for any (strict or non-strict) Archimedean t?conorm (see, e.g., 16,34]). Hence, for such operations, we will have Y (y) = 1 for all y, which makes no sense. Therefore, when we de ne operations with fuzzy operands, the only meaningful interpretation of \there exists" is through the _?operation f_ (a; b) = max(a; b), for which for every property A(x), the degree of belief in \there exists x such that A(x)" is equal to the \maximum" (or, to use the precise mathematical term, supremum) of all the degrees of belief t(A(x)) for all x. As far as an &?operation is concerned, we can use an arbitrary function f& : 0; 1] 0; 1] ! 0; 1] that extends a usual & operation de ned for binary values (with 0 as false as 1 as true), i.e., an arbitrary function f& for which f& (0; 0) = f& (0; 1) = f& (1; 0) = 0 and f& (1; 1) = 1. For such interpretation of \and" and \there exists", formula (2) takes the following form: (1:4a) Y (y ) = sup f& ( X1 (x1 ); :::; X (xn ));
~ x:f (~ x)=y
n

7

where f& (a; b; :::; c) stands for f& (:::(f&(a; b); :::); c) (i.e., it means that we apply the &?operation several times). Our results will be true for an arbitrary choice of an &?operation.

1.2. How is the problem of estimating accuracy of the results of data processing solved now? In general, the problem is computationally intractable even for crisp sets (even for intervals). It has been proven that even for the case when the sets Xi are crisp (and
are intervals), and the algorithm f is actually a polynomial, the problem of computing the set Y exactly is computationally intractable (NP-hard) 9]. This result does not mean, of course, that the problem of computing Y is not practically solvable. The sets Xi describe the inaccuracy of the measuring devices, or the inaccuracy of an expert. These inaccuracies are never known precisely, therefore, it would be quite su cient to have an approximate description of Y . Several methods are known for that:

Case when estimates are pretty accurate: linearization technique. If the esti-

In this case, for interval Xi = x ~i ? i ; x ~i + i ], we have Y Xlin = flin (X1; :::; Xn) = y ~? ;y ~ + ], where = jf;1j 1 + ::: + jf;nj n (see, e.g., 35]).

mates x ~i for xi are pretty accurate, then we can neglect the terms that are quadratic (or of higher order) in xi = x ~i ? xi , and thus, for given estimates x ~i , describe y = f (x1; :::; xn) = f (~ x1 ? x1 ; :::; x ~n ? xn ) by the following approximate formula: y flin = y ~ ? f;1 x1 ? ::: ? f;n xn ; where by f;i , we denoted the partial derivative of f w.r.t. xi : @f (~ x1; :::; x ~n): f;i = @x
i

Another case when we can estimate Y is when the function f is monotonic in each + of the variables; in this case, if, e.g., f is monotonically increasing, and Xi = x? i ; xi ], we + ? + have Y = f (x? 1 ; :::; xn ); f (x1 ; :::; xn )]. For these two cases (small errors or monotonic f ), there also exist e cient techniques for fuzzy data processing 4,51].

Expert estimates are rarely very accurate, so, other methods are needed. Mea8

surements typically lead to accurate estimates of xi , so, if all the estimates come from

measurements, we can usually apply linearization techniques. Expert estimates, on the other hand, are rarely very accurate. So, if we have expert estimates, we usually cannot neglect the squares of the errors, and therefore, we need other methods for estimating the error of the result of data processing. For this case, the following idea has been proposed by R. Moore 27,28] (see also 29,11,10,14]). No matter what high-level language we use to describe an algorithm f , inside a computer, this algorithm is translated into a sequence of elementary operations (usually, +, ?, , :, etc). For example, a function f (x1; x2; x3) = (x1 + x2 )2 + 2 x3 is computed as follows (we will enumerate all the input and intermediate values by r1 ; r2, ...): rst, we have r1 = x1, r2 = x2 , and r3 = x3 ; then, we start computing further values: we apply + and get r4 = r1 + r2 = x1 + x2 ; 2 (so, r5 = (x1 + x2 )2 ). we apply the square operation and get r5 = r4 we take r6 = 2; we compute r7 = r6 r3 ; nally, we compute r8 = r5 + r7 ; this is the desired value y. The idea is to repeat the same sequence of operations, but with intervals instead of numbers. Elementary operations g are usually monotonic, so, we can explicitly compute g(X1; :::; Xn) + ? + for intervals Xi : e.g., for addition g(x1; x2) = x1 + x2 , we have g( x? 1 ; x1 ]; x2 ; x2 ]) = ? + + x? 1 + x2 ; x1 + x2 ]. For example, if we start with the intervals R1 = X1 = 0; 1], R2 = X2 = 0; 1], and R3 = X3 = 1; 2], we get the following sequence of computations: we apply + and get R4 = R1 + R2 = 0; 1] + 0; 1] = 0; 2]; 2 = 0; 4]; we apply the square operation and get R5 = R4 take R6 = 2; 2]; compute R7 = R6 R3 = 2; 2] 1; 2] = 2; 4]; ~ = R8 = R5 + R7 = 0; 4] + 2; 4] = 2; 8]; this is the desired nally, we compute Y estimate for Y . ~ contains the desired It has been proven that for intervals Xi , the resulting estimate Y interval Y . A similar procedure can be used for fuzzy processing: here, we implement elementary operations g using extension principle. computations do not always lead to the exact value of Y ; even for intervals Xi , the result 9

These new methods do not always lead to accurate results. The results of these

depends on the exact order of the operations performed to compute f . For example, we can compute f (x1; x2) = x1 x2 by simply multiplying the two numbers, or we can compute the same product by using a more complicated formula x1 x2 = (1=4) (x1 + x2 )2 ? (x1 ? x2 )2 ]. ~ = 1; 4] that coincides If X1 = X2 = 1; 2], then the rst algorithm leads to the estimate Y with the desired interval Y = f (X1; X2). However, the second algorithm leads to a di erent result: indeed, this algorithm can be represented as a following sequence of computations: r3 := r1 + r2. 2. r4 := r3 r5 := r1 ? r2. 2. r6 := r5 r7 := r4 ? r6. r8 := 4. r9 := r7 =r8. So, for Xi = 1; 2], we get R3 = 2; 4], R4 = 4; 16], R5 = ?1; 1], R6 = 0; 1], R7 = 3; 16], ~ = R9 = 0:75; 4] 6= Y = 1; 4]. The resulting interval Y ~ contains extra R7 = 4; 4], and Y points 0:75; 1).

bers, data processing algorithm that computes f (x1; :::; xn) can be quite complicated and time-consuming. When we analyze accuracy of data processing, we must go from operations with numbers to operations with intervals, crisp sets, or fuzzy sets. For example, when we go from precise numbers to fuzzy sets, then instead of processing n numbers according to the known algorithm f , we have to solve complicated optimization problems to nd Y (y). This increases computation time drastically: for example, in a crisp case, to compute a sum of two numbers x1 + x2 , we must process these two numbers xi only; all it takes is one arithmetic operation. To compute a sum of two fuzzy operands, instead of processing two numbers, we must take as input the values X1 (x1 ) and X2 (x2 ) that correspond to di erent xi . Just because of the necessity to process such a long input, these computations are inevitably long. How to speed up fuzzy computations? One known way to speed up computations in general is to design a hardware support for them. This idea worked perfectly well, e.g., for oating point operations that had initially been implemented in software. So, it is desirable to design hardware support for interval and fuzzy computations as well. 10

1.3. Going from numbers to intervals and fuzzy sets drastically increases computation time, so hardware support is in order Hardware support is necessary. We have already mentioned that even for real num-

bring a speed-up, and is, therefore, a great idea. However, the very fact that we have a hardware support of several basic operations with intervals, crisp sets, and/or with fuzzy sets, does not necessarily mean that we have improved the quality of the result (we are thankful to the anonymous referee who helped us clarify this point). As we have shown in Subsection 1.2, if we start with an expression (1=4) (x1 + x2)2 ? (x1 ? x2)2 ] and simply substitute interval operations instead of operations with numbers, we will get an overestimation irrespective on whether we implement these operations in software or in hardware. The only way to get the exact estimate is to transform this expression into an equivalent one x1 x2 for which interval computations give the exact estimate. An even more striking example is a function of one variable de ned as f (x1) = x1 ? x1 . This function is, of course, identically equal to 0, so, for every interval X1, we should get f (X1) = f0g. However, if we take X1 = 0; 1], and apply interval subtraction, we will get X1 ? X1 = 0; 1] ? 0; 1] = ?1; 1]. Whether we are implementing interval subtractions in hardware or in software, we get an overestimation. Again, the only way to get the exact estimate is take into the consideration that the two terms in the original expression cancel each other, and thus, to transform the original expression x1 ? x1 into an equivalent one 0. So, in addition to hardware, we need some appropriate symbolic reasoning engine (of the type implemented in Macsyma or in Mathematica) that would transform the original expression into an equivalent one that will lead to the precise (or at least to a more accurate) estimate.
At present, designing such an engine is a more urgent and more potentially rewarding task than working on hardware. Currently, computers only allow unary and binary operations. So, what this engine will do is, given a function, transform it into a sequence of unary and binary operations. The perfect engine will output a transformation that leads to the best possible estimate (e.g., to the interval with the smallest possible overestimation). However, this \the best" does not necessarily mean that we will have no overestimation at all: As we will see later, for some functions of three and more variables, no matter how we transform these functions into a sequence of unary and binary operations, interval computations will always lead to an overestimation. This overestimation result is true not only for the existing computers, where only elementary arithmetic operations are hardware supported; this result (as we will show) is true for any computer that hardware supports

A word of warning: Hardware support is not su cient. Hardware support does

11

only unary and binary operations. So, for such functions, the only way to avoid overestimation is to implement operations with three or more interval (corr., fuzzy) operands in hardware. For the resulting new computer, the computation scheme will include not only standard unary and binary operations, but some new operations (with interval or fuzzy operands) as well. Again, the very fact that we have added these new operations does not automatically mean that we will achieve the exact estimate: before we apply interval computations, we must transform the original computation scheme (that may be overestimating) into a new (equivalent) scheme with no overestimation. So, we will again need an appropriate symbolic reasoning engine for the new computer. Summarizing, we can say that achieving precise interval and fuzzy computations is a threestep task: First, we must design a symbolic reasoning engine based on the existing hardware supported operations (namely, elementary arithmetic operations). This engine must transform the original expression (in terms of these elementary operations) for which interval and fuzzy computations overestimate into an equivalent expression that leads to more precise result Y . Second, we must select operations with three or more interval or fuzzy operands that need to be hardware supported in order to get precise results. Third, for these new operations included, we must design a new symbolic reasoning engine that will transform every algorithm into a sequence of elementary operations (arithmetic or new ones) for which interval (fuzzy) computations will lead to the precise result. The rst task { the design of the original engine is, in e ect, being currently done in interval computations community (see, e.g., 10] and 14]). In the present paper, we consider the second task: the choice of the hardware operations to be hardware supported. We give only a partial answer to this task. As soon as this problem will be solved, the need will come for the third task: designing a new symbolic reasoning engine for the new computer.

Hardware support of interval and fuzzy operations: a little bit of history. The

existing hardware support of interval operations is described in 23,36,37], and references therein. Usually, the supported operations are arithmetic operations, and the scalar (dot) product a1 b1 + ::: + an bn . The rst hardware implementation of operations with fuzzy sets has been developed by Yamakawa. For the current state of research, see, e.g., 49,50]; for applications, see, 12

e.g., 43] and 52]. This rst implementation included several chips. The rst single-chip hardware implementation of fuzzy operations have been proposed in 45] (for more recent results, see, e.g., 44] and 48]). Parallel hardware implementation has been proposed and described in 2]; see also 38] and 42]. These implementations, however, are mainly oriented towards fuzzy control problems (and not fuzzy data processing). is impossible to implement in hardware fuzzy operations that correspond to all possible functions f (x1; :::; xn). So, it is necessary to choose.

What interval and fuzzy operations should we support for data processing? It
The natural idea is to describe all functions f that are hardware supported on the existing computers, and to support the corresponding operations with fuzzy sets. Since usually, only unary and binary operations are hardware supported, we will thus have hardware implementation only of operations of one and two operands.

What we are planning to do. In this paper, we show that for intervals and for fuzzy sets,

an implementation of only unary and binary operations is not su cient in the following sense: for some functions f and for some intervals (fuzzy sets) Xi , no matter how we represent the function f as a composition of unary and binary operations, if we then ~ will be di erent from the apply the above-described methodology, the resulting estimate Y desired value Y = f (X1; :::; Xn). Therefore, if we want fuzzy data processing to be precise, operations with three or more fuzzy operands should also be implemented in hardware. Some crisp operations with three or more crisp operands are already hardware supported: e.g., many computers contain a math co-processor that, among other things, hardware supports matrix operations, i.e., operations whose operands include an entire matrix (i.e., lots of numerical operands). For example, it is possible, given two arrays a1 ; :::; an and b1; :::; bn, to compute their dot (scalar) product a1 b1 + a2 b2 + ::: + an bn by using a single operation of a math co-processor. For crisp numbers, the main purpose of using such operations is to speed up computations: in principle, we can use operations with two operands (in this case, addition and multiplication) and compute the same expression in several steps. We are planning to show that in interval and fuzzy case, if we restrict ourselves to unary and binary operations only, then not only computations will slow down, but for some functions f , and for some intervals (fuzzy sets) Xi , we will not get the desired value f (X1; :::; Xn) at all. 13

1.4. Structure of the paper
In Section 2, we will give some general de nitions. In Section 3, we will consider the simplest case when inputs are intervals, and when all operations that are hardware supported are smooth (di erentiable) functions. For this case, we will prove that operations with one or two variables are not su cient. The fact that functions are di erentiable makes it possible not only to prove the negative results but also to describe the smallest possible order of the error that can be caused by such computations (linear, quadratic, etc). We also give a list of operations that need to be hardware supported so that we will be able to compute Y with a better accuracy: this list consists of arithmetic operations and a weighted scalar product. In Section 4, these results will be generalized from crisp intervals to fuzzy sets. In Section 5 and 6, we show that even if we allow operations that are not di erentiable, still operations with one or two operands will not be su cient. In Section 7, we discuss the relation between these results and Kolmogorov's theorem (well known in mathematics) that every continuous function of three or more real variables can be represented as a composition of real-valued functions of one and two variables. For reader's convenience, all the proofs are placed in Section 8.

14

2. GENERAL DEFINITIONS
In this Section, we give general de nitions that will be used in the following text.

2.1. Computation scheme
In this subsection, we will formalize the description of a general computation process (presented in Subsection 1.2) into a formal de nition, and show (on an example) how this formalization is related to the original description.

De nition 2.1. By a computation scheme S with n initial values, and with operations
with one or two operands (or, for short, simply a computation scheme), we mean a nite sequence (Sn+1; Sn+2 ; :::; SN ) of expressions Si (called steps). Each step Si is an expression of one of the following three types: ri := ci , where ci is a real number; ri := fi (rj ), where fi is a function of one variable (not necessarily everywhere de ned), and j < i; ri := fi (rj ; rk ), where fi is a function of two variables (not necessarily everywhere de ned), j < i, and k < i. If S is a computation scheme with n initial values, and x1; :::; xn are n real numbers, we say that the result of applying S to xi is y, if rN = y, where the sequence ri is de ned as follows: if i n, then ri = xi : if i > n, then depending on the type of the rule Si , we de ne ri as follows: if the rule if ri := ci , then ri = ci ; if the rule is ri := fi (rj ), then ri = fi (rj ); if the rule is ri := fi (rj ; rk ), then ri = fi (rj ; rk ).

certain value of ri . This value will be denoted by ri (x1; :::; xn).

Denotation. For some x1; :::; xn, and for each i N , this De nition provides us with a

Comment. We have already mentioned that inside a computer, every algorithm is translated into a sequence of elementary operations. Since in the majority of computers, all elementary operations correspond to functions of one or two variables, an arbitrary algorithm computing y = f (x1; :::; xn) can be thus represented as a computation scheme. For example, how in the above-given representation of the function f (x1; x2; x3) = (x1 + x2 )2 +2 x3, we have:

15

r4 = r1 + r2 (here, f4 = +, j = 1, k = 2); 2 (here, f5 (x) = x2 , j = 4); r 5 = r4 r6 = 2 (here, we have a function of 0 variables, that computes a constant 2); r 7 = r6 r3 ; r 8 = r5 + r7 .

De nition 2.2. Let K Rn, and let f be a function from K to R. We say that a computation scheme S computes f if for every (x1; :::; xn) 2 K , the value that S computes
(is de ned and) is equal to f (x1; :::; xn).

2.2. Applying computation scheme to crisp sets (in particular, to intervals)
In this subsection, we will describe how a computation scheme can be applied to crisp sets; in particular, we will describe how it can be applied to intervals.

Xn R be (crisp) sets. Then, the result f (X1; :::; Xn) of applying f to the sets X1 ; :::; Xn is de ned by the formula (1.1). If instead of the sets Xi, we have a (crisp) set X Rn, then the result f (X ) of applying f to X is de ned by the formula (1.2).

De nition 2.3. Let f (x1; :::; xn) be a function of n real variables, and let X1 R, ...,

X1; :::; Xn is Y if RN = Y , where the sequence of (crisp) sets R1; :::; RN is de ned as
follows: if i n, then Ri = Xi ; if i > n, then, depending of the type of the rule Si , Ri is de ned as follows: if Si is ri := ci , then Ri = fci g; if the rule is ri := fi (rj ), then Ri = fi (Rj ); if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).

De nition 2.4. Assume that S is a computation scheme with n input values, and that Xq R, ..., Xn R are (crisp) subsets of R. We say that the result of applying S to

16

De nition 2.5. Assume that S is a computation scheme with n input values, and that X is a (crisp) subset of Rn. We say that the result of applying S to X is Y if RN = Y ,

where the sequence of (crisp) sets R1 ; :::; RN is de ned as follows: if i n, then Ri = i (X ), where i is a projection on i?th component (i.e., i (~ x) = xi ); if i > n, then, depending of the type of the rule Si , Ri is de ned as follows: if Si is ri := ci , then Ri = fci g; if the rule is ri := fi (rj ), then Ri = fi (Rj ); if the rule is ri := fi(rj ; rk ), where j n and k n, then we take Ri = f ( jk (X )), where jk is a projection to j ?th and k?th components (i.e., jk (x1 ; :::; xj ; :::; xk ; :::; xn) = (xj ; xk )); if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).
Comment. The main di erence between these two de nitions is that when we have a set X Rn , and we want to compute the set fi (X ) of possible values of fi (x1 ; :::; xn), we must take into consideration the fact that not all values (x1 ; :::; xn) with xi 2 i (X ) are possible.

2.3. Applying computation scheme to fuzzy sets

In the previous subsection, we described the result of applying a computation scheme to crisp sets. Let us now describe what a computation scheme will do if we apply it to fuzzy sets.

Xn R be fuzzy sets. Then, the result f (X1; :::; Xn) of applying f to the sets X1; :::; Xn is de ned by the formula (1.4a). If instead of the fuzzy sets Xi , we have a fuzzy set X Rn, then the result f (X ) of applying f to X is de ned by the formula (1.3).

De nition 2.6. Let f (x1; :::; xn) be a function of n real variables, and let X1 R, ...,

De nition 2.7. Assume that S is a computation scheme with n input values, and that X1 R, ..., Xn R are fuzzy subsets of R. We say that the result of applying S to
follows: if i n, then Ri = Xi ; if i > n, then, depending of the type of the rule Si , Ri is de ned as follows: if Si is ri := ci , then Ri = fci g (a crisp set); if the rule is ri := fi (rj ), then Ri = fi (Rj ); if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ). 17

X1; :::; Xn is Y if RN = Y , where the sequence of fuzzy sets R1 ; :::; RN is de ned as

De nition 2.8. Assume that S is a computation scheme with n input values, and that X is a fuzzy subset of Rn . We say that the result of applying S to X is Y if RN = Y ,

where the sequence of fuzzy sets R1; :::; RN is de ned as follows: if i n, then Ri = i (X ), where i is a projection on i?th component (i.e., i (~ x) = xi ); if i > n, then, depending of the type of the rule Si , Ri is de ned as follows: if Si is ri := ci , then Ri = fci g (a crisp set); if the rule is ri := fi (rj ), then Ri = fi (Rj ); if the rule is ri := fi(rj ; rk ), where j n and k n, then we take Ri = f ( jk (X )), where jk is a projection to j ?th and k?th components (i.e., jk (x1 ; :::; xj ; :::; xk ; :::; xn) = (xj ; xk )); if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).

3. SIMPLEST CASE: SMOOTH OPERATIONS, INTERVAL UNCERTAINTY; HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS IS NOT SUFFICIENT; WEIGHTED SCALAR PRODUCT MUST ALSO BE SUPPORTED

In this section, we will consider the simplest case when inputs are intervals, and when all operations that are hardware supported are smooth (di erentiable) functions. For this case, we will prove that hardware operations with one or two variables are not su cient. The fact that functions are di erentiable makes it possible not only to prove the negative results but also to describe the smallest possible order of the error that can be caused by such computations (linear, quadratic, etc). We will also give a list of operations that need to be hardware supported so that we will be able to compute Y with a better accuracy: this list consists of arithmetic operations and a weighted scalar product.

De nition 3.1.

We say that a computation scheme S is continuous if all the function fi are continuous. We say that a function f is smooth if it is de ned on an open set, is three times di erentiable, and all its third order derivatives are continuous. We say that a computation scheme S is smooth if all the function fi are smooth.

3.1. The main (negative) result: unary and binary operations are not su cient

In this subsection, we will describe our rst negative result: that for smooth operations on intervals, hardware unary and binary operations are not su cient. 18

De nition 3.2. Assume that a smooth computation scheme S computes a smooth function f de ned on an open set K Rn. We say that S is precise for intervals if for all intervals X1; :::; Xn for which X1 ::: Xn K , the result of applying S to X1 ; :::; Xn
coincides with f (X1; :::; Xn). For example, a 1-step computation scheme that computes f (x1; x2) = x1 x2 by multiplying x1 and x2 is precise for intervals, while the computation scheme based on the expression (1=4) (x1 + x2 )2 ? (x1 ? x2 )2] is not. It can be proven that the above-given computation scheme for f (x1; x2; x3) = (x1 + x2 )2 +2 x3 is precise for intervals. As we have already mentioned, for one and the same function, some computation scheme are precise, and some others are not. The question is: for a give function f , is there any computation scheme that is precise?
putations are precise, if there exists a smooth computation scheme that computes f and that is precise for intervals. If such a smooth computation scheme does not exist, then we say that for this function f , smooth interval computations cannot be always precise.

De nition 3.3. We say that for a smooth function f : Rn ! R, smooth interval com-

We will show that for many reasonable smooth functions, smooth interval computations cannot be always precise. To formulate our result, we will need a few denotations and de nitions.

Denotations.

By f;i, we will denote i?th partial derivative of a function f . By f;ij , we will denote the second partial derivative

@ 2f : f;ij = @x @x
i j

De nition 3.4.

A point ~ s is called a stationary point of a function f if f;i (~ s) = 0 for all i. A stationary point ~ s of a function f is called non-degenerate if the following two conditions are satis ed: at this point ~ s, all components of the Hessian matrix f;ij (~ s) are di erent from 0; at this point ~ s, the determinant of the Hessian matrix is di erent from 0.

Comment. Almost all matrices satisfy these two properties (in the sense that the set of symmetric matrices for which they are not true forms a subspace of co-dimension 1 in the n(n + 1)=2?dimensional set of all matrices). So, we can say that almost all smooth functions with a stationary point have a non-degenerate stationary point.

19

THEOREM 3.1. If a smooth function f (x1; :::; xn), n 3, has a non-degenerate stationary point, then for this function f , smooth interval computations cannot be always precise.

Reformulation of this result in more informal (and hopefully, more understandable) terms. In view of the previous comment, this result means that for almost
all smooth functions with a stationary point, smooth interval computations cannot be always precise.

Our result and known mathematical results. The very fact that there exist smooth
functions for which smooth interval computations are not always precise is not surprising: indeed, it is known (see, e.g., a survey 26]), that there exists a smooth function of three variables that cannot be represented as a composition of smooth functions of one or two variables. For such functions, a smooth computation scheme cannot be precise even for real numbers, and of course, it is not precise for intervals, because every real number xi can be viewed as a (degenerate) interval xi ; xi]. Our negative result is much broader than that: namely: Functions that cannot be represented as a composition of smooth unary and binary operations can be viewed rather as an exception: e.g., every polynomial can de nitely be represented as such a composition. For smooth interval computations, we have shown that (in some reasonable sense) almost all functions (to be more precise, almost all functions with a stationary point) cannot be represented as compositions of smooth unary and binary interval operations. This result includes functions f (x1; :::; xn) like quadratic polynomials, that can be represented as a composition for numerical xi .

What does this theorem tell us about the choice of operations for hardware implementation. With respect to hardware support, Theorem 3.1 says the following:
suppose that we have chosen a list of operations that we intend to implement in hardware (both as operations with numbers and as operations with intervals). On the resulting computer, every algorithm f (x1; :::; xn) will thus be represented as a composition of the hardware supported operations fi . If we want to compute the interval f (X1; :::; Xn), we will apply the same sequence of operations as in computing f (x1; :::; xn), but with intervals instead of numbers (i.e., we will apply the computation scheme S that computes f to intervals X1; :::; Xn). For some computation schemes, e.g., for

x1 x2 = (1=4) (x1 + x2)2 ? (x1 ? x2)2 ];
20

we may get an overestimate of f (X1; :::; Xn); for some others, hopefully, we will get a precise estimate. In view of the previously mentioned result, for some smooth functions, no smooth computation scheme will return the precise interval f (X1; :::; Xn). We would like to choose a set of hardware supported operations in such a way that for each smooth function that has smooth computation schemes, at least one of these schemes will be precise for intervals (i.e., the above-described method will give exactly f (X1; :::; Xn)). Theorem 3.1 tell us that we cannot achieve this goal if we only support unary and binary operations; so, we must also implement some operations with three or more operands in hardware.

3.2. Second negative result: if we only use unary and binary operations, we cannot even compute the main term correctly
According to Theorem 3.1, if a smooth function f (x1; :::; xn) has a non-degenerate stationary point, and if we are only using unary and binary operations, then it is impossible to always compute f (X1; :::; Xn) precisely for intervals Xi. So, if a computation scheme S ~ of applying S to some intervals X1; :::; Xn will be di erent computes f , then the result Y from the desired interval Y = f (X1; :::; Xn). How di erent can it be? Since we consider smooth functions, we can try to describe this di erence in terms of the order: is it linear ( rst order), quadratic (second order), cubic (third order), etc, in i ? It could be that the di erence is, say, of fth order w.r.t. errors i , and therefore, for practical purposes (this di erence being much smaller than the interval itself) we could ~ as a good approximation for Y . Alas, the reality is not so safely neglect it, and treat Y good: it turns out that smooth interval computations (with unary and binary operations) do not even give a correct main term for Y . To describe this result in mathematical terms, let us rst describe the asymptotic of Y :

PROPOSITION 3.1. Let f (x1; :::; xn) be a smooth function. Then, the lower f ? and upper f + bounds of the interval f ( x1 ? 1 ; x1 + 1 ]; :::; xn ? n ; xn + n ]) satisfy the property f = f (x1; :::; xn) (jf;1(~ x)j 1 + ::: + jf;n (~ x)j n ) + O( 2 i ). De nition 3.5. Assume that S is a smooth computation scheme for a smooth function f (x1; :::; xn). We say that S always computes the main error term correctly if for every ~ x,
the di erence between the actual endpoints of the interval Y = f ( x1 ? 1; x1 + 1 ]; :::; xn ? n ; xn + n ]) and the values computed by applying S to intervals Xi = xi ? i ; xi + i ] is O( 2 i ). 21

Comment. In other words, we allow smooth interval computations not to be precise in the sense that their result can di er in terms that are quadratic (or of higher order) in i , but we require that the main term in i be computed precisely. THEOREM 3.2. If a smooth function f (x1; :::; xn), n 3, has a non-degenerate stationary point, then for this function f , smooth interval computations cannot always compute the main error term correctly.

3.3. Third negative result: if we only use unary and binary operations, we cannot even be locally asymptotically correct

An even stronger negative result can be proved. Namely, in our de nition of what it means to compute the main term correctly, we required that the main term should be computed exactly. In general, the fact that a function is several times di erentiable, means that we can approximate it by its Taylor polynomial. For example, if f is twice di erentiable, then in the neighborhood of a point (s1; :::; sn), we can approximate the function f (x1; :::; xn) P by a linear function: f (x1; :::; xn) = f (s1; :::; sn) + f;i (s1; :::; sn)(xi ? si ) + O((xi ? si )2 ). If the function is analytical, these Taylor polynomials actually converge to the function f . So, if by using smooth interval computations, we cannot compute the main term precisely, then maybe, we can at least compute correctly the rst few terms in the expansion of the main term? I.e., e.g., we may be able to compute the main term with the accuracy of O((xi ? si )2) terms? Alas, even this, we cannot compute, as the following result shows. De nition 3.6. Let f (~ x) be a smooth function, ~ s = (s1; :::; sn) is a point in Rn, and S is a smooth computation scheme for f . We say that S is locally asymptotically correct (in computing the main error term) in the neighborhood of ~ s, if the di erence between the actual endpoints of the interval f ( x1 ? 1 ; x1 + 1 ]; :::; xn ? n ; xn + n ]) and the values 2 computed by applying S to the intervals Xi = xi ? i ; xi + i ] is O( 2 i )+ O( i (xj ? sj ) ). THEOREM 3.3. If a smooth function f (x1; :::; xn), n 3, has a non-degenerate stationary point, then for this function f , there exists a point ~ s such that no matter what smooth computation scheme S we choose to compute f , the resulting smooth interval computations are not locally asymptotically correct in the neighborhood of ~ s.

3.4. Positive result: if we add weighted scalar product, smooth interval computations become locally asymptotically correct

Indeed, assume that in our de nition of a computation scheme, we allow, in addition to unary and binary operations, weighted scalar product, i.e., an operation a1 ; :::; an; b1; :::; bn ! w1 a1 b1 + ::: + wn an bn ; (3:1) 22

where n is an arbitrary positive integer, and wi are arbitrary real numbers (called weights). Before we give a formal de nition, we must make one comment. In operations with real numbers, if we can implement a binary operation f (x1; x2), then we can automatically implement the function g(x) = f (x; x) that is obtained by applying f to two equal values: namely, to implement g, we can simply apply f to two equal values. For interval operations, this idea does not always lead to an implementation of g. As an example, we can take subtraction f (x1; x2) = x1 ? x2. For subtraction, + ? + g(x) = f (x; x) = x ? x = 0; the corresponding interval operation is f ( x? 1 ; x1 ]; x2 ; x2 ]) = + + ? ? + ? + x? 1 ? x2 ; x1 ? x2 ]. If we apply this operation to x1 ; x1 ] = x2 ; x2 ] = 0; 1], we get f ( 0; 1]; 0; 1]) = ?1; 1]. This result is di erent from the desired g( 0; 1]) = f0g. Because of this comment, when we describe a computation scheme that involves a certain interval operation f , we must speci cally include interval analogues of all functions that can be obtained from f by applying it to equal values of the variables. As a result, for weighted scalar product, we arrive at the following de nition:

De nition 3.7.

Let a function f (x1; :::; xi?1; xi ; xi+1; :::; xj?1; xj ; xj+1; :::; xn) be given. We say that a function g(x1; :::; xj?1; xj+1; :::; xn) = f (x1; :::; xi?1; xi; xi+1 ; :::; xj?1; xi; xj+1 ; :::; xn) with n ? 1 variables is a simpli ed version of a function f ; transition from f to g will be called a simpli cation. We say that a function g is a version of a function f if g can be obtained from f by a sequence of simpli cations. By a weighted scalar product, we mean an operation (3.1). By a computation scheme with weighted scalar products, we mean a sequence S of expressions each of which is either a function of zero, one, or two variables (like in De nition 2.1), or an application of a weighted scalar product or of one of its versions.

Example. If we use weighted scalar product and its versions, we can simplify the computation of the above-given expression (x1 + x2 )2 + 2 x3 as follows: we still have ri = xi for i = 1; 2; 3; and then: r4 = r2 + r3 (this is a binary operation); r5 = 2; 2 + r5 r3 ; here, to the values r4 , r5 , and r6 , we apply a function f6 (y1 ; y2 ; y3 ) = r 6 = r4 2 + y2 y3 obtained by simplifying a weighted scalar product: f6 (y1 ; y2 ; y3) = y1 f (y1; y1; y2; y3), where f (y1; y4; y2; y3) = y1 y4 + y2 y3 is a weighted scalar product with both weights equal to 1.

23

For such computation schemes, we can repeat de nitions 2.2 (what it means that a scheme computes a function f ), 2.3 (how to apply a scheme to intervals), and 3.6 (what it means to be locally asymptotically correct). Now, we can formulate our positive result:

THEOREM 3.4. For every smooth function f (x1; :::; xn), n 3, and for every point ~ s in its domain, there exists a computation scheme S with weighted scalar products for
which the resulting smooth interval computations are locally asymptotically correct in the neighborhood of ~ s. Comments. Good news: the result is applicable not only to intervals, but to arbitrary crisp sets as well. From the proof of this theorem, one can easily see that the designed computation scheme is locally asymptotically correct not only for intervals Xi = xi ? i ; xi + i ], but also for arbitrary crisp sets Xi xi ? i ; xi + i ]. Not so good news: We know what operations we need to implement in hardware, but we do not yet know how to implement them all. Theorem 3.4 says that if we hardware support all weighted scalar products, then smooth interval computation becomes locally asymptotically correct. A word of warning: this result does not mean that we can immediately implement all these operations and make computations (asymptotically) precise, because we do not yet know how to implement all the necessary operations. Indeed, according to De nition 3.7, we need separate versions of a function to deal with each simpli cation obtained when two or more arguments to the function represent the same variable. For a function with n arguments, this will require n! hardware implementations of the function. When n is large, n! is so unrealistically large that it is practically impossible to have n! di erent hardware devices that compute n! different simpli cations. So, to implement all these simpli cations, we need a exible implementation that will change when some of the arguments represent the same variable. At present, we do not know how to design such a exible implementation. This implementation issue is an interesting open problem.

4. SMOOTH OPERATIONS, INDEPENDENT FUZZY SETS X1; :::; Xn: HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS IS NOT SUFFICIENT; WEIGHTED SCALAR PRODUCT MUST ALSO BE SUPPORTED
In the previous section, we proved that unary and binary operations are not su cient to support arbitrary smooth operations on intervals. In this section, we will show that, 24

similarly, unary and binary operations are not su cient to describe smooth operations on (independent) fuzzy sets.

coincides with f (X1; :::; Xn).

De nition 4.1. Assume that a smooth computation scheme S computes a function f de ned on an open set K Rn. We say that S is precise for independent fuzzy sets if for all fuzzy sets X1 ; :::; Xn for which X1 ::: Xn K , the result of applying S to X1 ; :::; Xn

are precise for independent fuzzy sets, if there exists a smooth computation scheme that computes f and that is precise for fuzzy sets. If such a smooth computation scheme does not exist, then we say that for this function f , smooth computations cannot be always precise for independent fuzzy sets.

De nition 4.2. We say that for a smooth function f : Rn ! R, smooth computations

THEOREM 4.1. If a smooth function f (x1; :::; xn), n 3, has a non-degenerate sta-

tionary point, then for this function f , smooth computations cannot be always precise for independent fuzzy sets. Comments. Theorem 4.1 follows directly from Theorem 3.1: indeed, if a smooth computation scheme is precise for arbitrary independent fuzzy sets, then, in particular, it must be precise for crisp intervals, and this (according to Theorem 3.1) is impossible. Similarly, Theorems 3.2 and 3.3 show that smooth fuzzy computations with only unary and binary operations cannot even describe the main term in f (X1; :::; Xn) correctly. In many reasonable cases, extension principle that de nes Y = f (X1; :::; Xn) for fuzzy sets X1; :::; Xn can be reformulated in terms of their (crisp) ?cuts Xi ( ) = fxj X (x) g: namely, Y ( ) = f (X1( ); ::; Xn( )) (see 33]; for counterexamples, see 33] and 7]). So, if we add weighted scalar product to the list of hardware supported operations, then, due to Theorem 3.4, we will be able to get all ?cuts Y ( ) locally asymptotically correctly, and in this sense, we will be able to compute the fuzzy set Y itself with the same accuracy.
i

5. GENERIC (NOT NECESSARY SMOOTH) OPERATIONS, CRISP SETS: HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS IS NOT SUFFICIENT
Let us now consider the general case of operations that are not necessarily smooth, and of the information that is not necessarily representable by independent sets X1 ; :::; Xn. 25

De nition 5.1. Assume that a computation scheme S computes a function f de ned on a set K Rn. We say that S is precise for all (crisp) sets if for every (crisp) set X K , the result of applying S to X coincides with f (X ).
Comment. We are going to prove that if our list of elementary operations includes only operations with one and two operands, and a function f of three and more variables is (in some reasonable sense) non-degenerate, then no computation scheme is applicable to fuzzy processing (i.e., none of them will provide the exact fuzzy result). Let us describe what we mean by non-degenerate.

De nition 5.2. Let K Rn , n 3. We say that a function f : K ! R is degenerate
if K can be subdivided into nitely many subsets Ki so that on each subset, f coincides with some function of one or two variables (i.e., on which f (x1; :::; xn) = g(xj ; xk ) for some j and k and for some function g). A function that is not degenerate will be called non-degenerate.

Comment. As an example of a degenerate function, we can take f (x1; :::; xn) = max(x1 ; :::; xn). For this function, K = Rn can be subdivided into the subsets Ki in which xi is greater than or equal to all other values, and on each Ki , f (x1; :::; xn) = xi (i.e., is equal to a function of one variable).

The following two results show that many functions of three or more variables are non-degenerate:

PROPOSITION 5.1. If a function f (x1; :::; xn) of three or more variables is de ned
on a domain K , and on some subset M K with a non-empty interior, f is strictly monotonic in each variable, then f is non-degenerate. Comment. To describe non-degenerate functions, we need to recall a notion of a real analytic function: this means a function that can be represented as a sum of its Taylor series. All known elementary functions (arithmetic operations, sin, cos, exp, ln, etc) and their compositions are real analytic functions. It turns out that a real analytical function is non-degenerate if and only if it actually depends on all of its variables:

PROPOSITION 5.2. If f (x1; : : :; xn) is a real analytic function of n 3 variables, and
f is not equal to a function of < n variables, then the function f is non-degenerate (in the
sense of De nition 5.2).

26

Examples. A function f (x1; x2; x3) = sin(x1 + exp(x2 x3)) is non-degenerate, because it actually depends on each of its variables. In contrast, a function f (x1; x2; x3) = x1 x2 is degenerate, because it does not depend on the variable x3 at all and is thus equal to the function of two variables. computation scheme that computes f is precise for all crisp sets.

THEOREM 5.1. If a function f of three and more variables is non-degenerate, then no

Comment. This result is based on our De nition 2.1, in which we assumed that all elementary operations are operations with one or two (set-valued) operands. Thus, in case of incomplete knowledge, when we have sets of possible values of the variables, operations with one and two operands are not su cient. This suggests that for this case, we need to implement hardware operations with 3 or more operands.

6. GENERIC (NOT NECESSARY SMOOTH) OPERATIONS, FUZZY SETS: HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS IS NOT SUFFICIENT
In the previous section, we proved that unary and binary operations are not su cient to support generic (not necessarily smooth) operations on crisp sets. In this section, we will show that, similarly, unary and binary operations are not su cient to describe generic operations on fuzzy sets.

computation scheme that computes f is precise for all fuzzy sets.

De nition 6.1. Assume that a computation scheme S computes a function f de ned on a set K Rn. We say that S is precise for all fuzzy sets if for every fuzzy subset X K , the result of applying S to X coincides with f (X ). THEOREM 6.1. If a function f of three and more variables is non-degenerate, then no
Comments. Since crisp sets are a particular case of fuzzy sets, this theorem is a corollary of Theorem 5.1 (just like Theorem 4.1. is a corollary of Theorem 3.1). This result is based on our De nition 2.1, in which we assumed that all elementary operations are operations with one or two (fuzzy) operands. Thus, for soft computing, operations with one and two operands are not su cient. This suggests that for soft computing, we need to implement hardware operations with 3 or more operands.

27

7. OUR RESULTS AND KOLMOGOROV'S THEOREM 7.1 What is Kolmogorov's theorem: in brief
The fact that every continuous function of three and more variables can be represented as a composition of functions of one or two variables (and can be thus computed by an appropriate computation scheme) has been rst proved by Kolmogorov 15] as a solution to the famous Hilbert's problem: one of 22 problems that Hilbert has proposed in 1900 as a challenge to the XX century mathematics 13]. Kolmogorov's result was later improved in 40,41], and turned out to be applicable to theoretical and practical aspects of computation (see, e.g., 6,12,24,25,31,30]).

7.2. In some reasonable sense, Kolmogorov's theorem may not be extended to interval and fuzzy computations
Our negative theorems (3.1{3.3, 4.1, 5.1, and 6.1) show that Kolmogorov's theorem might not be possible to extend to interval or fuzzy cases: there are functions that cannot be represented as a composition of operations with one or two interval (resp. fuzzy) operands.

7.3. In some other sense (less computationally straightforward) we can extend Kolmogorov's theorem to intervals
The above results are about the following: we have a function; we describe its computations step-by-step, and substitute operations with intervals instead of operations with numbers. In 32], the following result have been proven: if we do not follow the algorithm f step-by-step, i.e., if we do not require that interval operations follow the ow of numerical computations, then Kolmogorov's theorem is true: namely, an arbitrary interval function can be represented as a composition of functions of one and two variables. The proof is rather simple: suppose that we have an interval-valued function f (x1 ; :::; xn) = + ? + f ? (x1 ; :::); f +(x1 ; :::)] of n interval variables x1 = x? 1 ; x1 ]; :::; xn = xn ; xn ] . This means ? + + that we have two functions f ? and f + of 2n real variables x? 1 ; :::; xn ; x1 ; :::; xm. Each of these functions can be (due to Kolmogorov's theorem) represented as a composition of functions of one and two variables. So, we can do the following: rst, apply the interval functions ? and > that transform an interval x? ; x+] into x? ; x? ] and, correspondingly, x+ ; x+]. follow the operations from Kolmogorov's theorem with these degenerate intervals, and get the numerical-valued functions f ?; f ?] and f +; f +] as the desired composition; apply a combination operation comb( a; a]; b; b]) = a; b] to f ?; f ? ] and f +; f +] and get the desired interval f = f ?; f +]. 28

With respect to hardware operations it means that in principle, we can restrict ourselves to unary and binary operations only, but in this case, to compute the interval f (X1; :::; Xn), we will not be able to simply follow the algorithm f step-by-step: for each f , we will have to design a new method of interval (and therefore, for fuzzy) data processing.
Comment. An important open question: the result from 32] (described in this section) is proven for intervals; what happens in the fuzzy case?

8. PROOFS Proof of Proposition 3.1 Since the function f is smooth, if xi are such that j xi j

i , then

f (x1 + 1; :::; xn + xn ) = flin + O( 2 i );
where we denoted flin = f (x1; :::; xn) + x1 f;1 + ::: + xn f;n. The maximum of flin is attained when each of the component terms xi f;i attains the largest value for xi 2 ? i ; i ]: for f;i > 0, the maximum is attained when xi = i , and for f;i < 0, the maximum is attained when xi = ? i . In both cases, the maximum of i?th term is equal to jf;ij i . Therefore, the maximum of flin is equal to f (x1; :::; xn) + jf;1j 1 + ::: + jf;nj n . ? Hence, the maximum f + of f is equal to this expression plus O( 2 i ). The result for f is proved similarly. Q.E.D.

Proof of Theorems 3.1{3.3
Theorems 3.1 and 3.2 follow from Theorem 3.3, so it is su cient to prove Theorem 3.3. We will prove that the statement of this theorem is true for the non-degenerate stationary point ~ s. This will be proven by reduction to a contradiction. Namely, let us assume that there exist a smooth function with a non-degenerate stationary point ~ s and a computation scheme S for which smooth interval computations are locally asymptotically correct in the neighborhood of ~ s. Each such scheme S can be characterized by an integer: namely, by the total number of computation steps. Among such schemes, there exists a scheme with the smallest possible value of this integer. Let us denote this scheme by S , the function that is computed by this scheme by f (x1; :::; xn), and the stationary point for this function by ~ s = (s1; ::; sn). First, let us describe what type of expression we can get after each step of the smooth computation scheme. 29

De nition 8.1. By a generalized linear function of n variables x1; :::; xn, we mean a linear combination of functions 1, x1, ..., xn , and absolute values ja1x1 + ::: + an xn j of

homogeneous linear functions a1x1 + ::: + an xn . Example. A function 1 + x1 + x2 + j2x1 ? x2j + jx + 3j is a generalized linear function. LEMMA 1. For every smooth computation scheme S that computes a function f (x1; :::; xn), and for every point ~ s 2 Rn , the endpoints f~ of the result of smooth interval computations can be represented as X f~ (x ? s ; :::; x ? s ) + O( 2) + O((x ? s )2 ) f (x1; :::; xn) i 1 1 n n i i i j i

in a smooth computation scheme. Induction base. If a smooth computation scheme has not steps at all, this means that the function that we are computing simply coincides with one of the input variables. For an input variable xi , each endpoint xi of the interval xi ? i ; xi + i ] is already represented ~i = 1, and f~j = 0 for j 6= i. in the desired form with f Induction step. Assume now that we have proved this result for all smooth computation schemes of length k, and we want to prove it for smooth computation schemes of length k +1. Let S be any smooth computation scheme of length k +1. By de nition of a smooth computation scheme, the nal result of S is obtained in the last ((k + 1)?st) step by applying a smooth function of one or two variables to the results of previous computations. These results of previous computations are thus computable by computation schemes of length k. Therefore, for these results, due to the induction assumption, the result can be represented in the desired form. Let us use these forms to describe the result of applying (k + 1)?st step. To prove it, we will consider two possible cases: The rst case if when the last step of S consists of applying a smooth function of one variable. The second case if when the last step of S consists of applying a smooth function of two variables. In the rst case, f (x1; :::; xn) = F (r(x1; :::; xn)), and the result of applying smooth interval computations to r is already known to be expressible in the form
2 r(x1; :::; xn) ? l + O( 2 i ) + O((xi ? si ) 2 j ); r(x1; :::; xn) + l + O( 2 i ) + O((xi ? si )
j )];

Proof of Lemma 1. We will prove this lemma using induction over the number of steps

~i . for some generalized linear functions f

30

where l = r ~1 1 + ::: + r ~n n is a linear expression in i , with coe cients r ~i that are generalized linear function in xi ? si . Similarly to the proof of Proposition 3.1, we can prove that applying F results in an interval y?; y+], where

y = F (r(x1; :::; xn)) jF 0 (r(x1; :::; xn))j l + O((xi ? si )2

j ):

To prove the desired result, let us rst approximate jF 0 (r(x1; :::; xn))j by a generalized linear function. To do that, we can rst approximate the composition F 0 (r(x1; :::; xn)) by a generalized linear function. This part is easy: Since both F 0 and r are smooth functions, we conclude that F 0 (r(x1; :::; xn)) is also a smooth function, and therefore, it can be represented as a0 + a1 (x1 ? s1) + ::: + an(xn ? sn ) + O((xi ? si )2). If a0 = 0, then the absolute value of this function can be represented as

ja1(x1 ? s1) + ::: + an (xn ? sn )j + O((xi ? si)2 );
i.e., as a generalized linear function plus O(:::). P P If a0 6= 0, then a0 + ai (xi ?si ) = a0 (1+ (ai =a0)(xi ?si )). The absolute value of the product can be represented as the product of the absolute values. When xi ! si , then P(ai=a0)(xi ?si) ! 0, hence P(ai=a0)(xi ?si) > ?1, and so, j1+P(ai=a0)(xi ?si)j = P 1+ (ai =a0)(xi ? si )+ O((xi ? si )2). Therefore, ja0 + a1 (x1 ? s1)+ ::: + an(xn ? sn )j = ja0j(1 + P(ai =a0)(xi ? si)) + O((xi ? si )2) is a linear (and thus, generalized linear) function of xi ? si . In both cases, we represent jF 0(r(x1; :::; xn))j as a sum of the generalized linear function g ~ and an O((xi ? si)2 ) term. Therefore, the product jF 0 (r(x1; :::; xn)))j l = jF 0 (r(x1; :::; xn)))j r ~1 1 + ::: + jF 0(r(x1; :::; xn)))j r ~n n can be represented as

g ~ r ~1

~ r ~n 1 + ::: + g

n + O((xi ? si )2 j ):

For every i, the coe cient g ~ r ~i at i is a product of two generalized linear functions. By de nition, each generalized linear function is a sum of a constant (maybe 0), and a homogeneous rst order part (i.e., terms ai xi and ja1x1 + ::: + an xn j). The product g ~r ~i of two generalized linear functions g ~ and r ~i is thus a product of two sums and can, therefore, be represented as a sum of four terms: a product of two constants, which is a constant; a product of a constant term of g ~ and a homogeneous rst order part of r ~i , which is a generalized linear function; a product of a constant term of r ~i and a homogeneous rst order part of g ~, which is also a generalized linear function; 31

a product of a homogeneous rst order parts of g ~ and r ~i , which is O((xi ? si)2 ). The sum f~i of the rst three products is generalized linear function; the fourth term lead ~i i + O((xi ? si )2 j ) for to the term O((xi ? si )2 i ) in g ~ r ~i i. Therefore, g ~ r ~i i = f ~i . So, jF 0 (r(x1; :::; xn))j l = L + O((xi ? si )2 j ), where a generalized linear function f L = f~1 1 + ::: + f~n n , f~i are generalized linear, and therefore, the resulting interval is indeed equal to the desired expression f (x1; :::; xn) ? L + O(:::); f (x1; :::; xn) + L + O(:::)]. The second case can be described in a similar manner. In this case, instead of f = F (r), we have f (x1; :::; xn) = F (r(x1; :::; xn); t(x1; :::; xn)) for some functions r and t that have been computed on the previous steps. The resulting proof is similar. The lemma is proved. Q.E.D.

LEMMA 2. Let S be a smooth computation scheme that computes a function f (x1; :::; xn), and let ~ s 2 Rn. Then, jf;ij f~i + O((xi ? si)2 ), where f~i are generalized linear functions
that appear (as coe cients at i ) in the description of the result of applying smooth interval computations.

actual interval of values of f . Due to Lemma 1, the endpoints of the resulting interval are f (f~1 1 + ::: + f~n n )+ O(:::), and due to the Proposition, the endpoints of the interval of values of f are f (jf;1j 1 + ::: + jf;n j n )+ O(:::). The fact that the rst interval contains the second one means, in particular, that the width of the rst interval is than the width of the second interval, i.e., that f~1 1 + ::: + f~n n jf;1j 1 + ::: + jf;n j n + O(:::). If we x i, choose i = 1 for this i, and j = 0 for all j 6= i, we get the desired inequality. Q.E.D.

Proof of Lemma 2. For interval computations, the resulting interval always contains the

LEMMA 3. Let S be a smooth computation scheme that computes a function f (x1; :::; xn), and let ~ s 2 Rn . Then, the following statements are equivalent to each other: for S , smooth interval computations are locally asymptotically correct in the neighborhood of ~ s; ~ jf;i j = fi + O((xi ? si )2), where f~i are generalized linear functions that appear (as coe cients at i ) in the description of the result of applying smooth interval computations.

Q.E.D.

Proof of Lemma 3. This result immediately follows from Lemma 1 and Proposition 3.1.

Proof of Theorem 3.3 itself. Let us now prove Theorem 3.3 itself. By de nition, each step of a smooth computation scheme S that does not assign a constant value to a variable
32

(i.e., that is not of the type Ri = fci g), consists of applying a function of one or two variables either to initial data xi , or to the values computed on one of the previous steps. The last step of the scheme S cannot be of the form Ri = fci g since otherwise the function would have no non-degenerate stationary point. Therefore, the last step of the scheme S can consists of applying either: a function of one variable, or a function of two variables. Let us prove the theorem for these two cases. First case: the last step consists of applying a function of one variable. Let us rst show that this last step cannot consist of applying a smooth function of one variable. We will prove this statement by reduction to a contradiction. Assume that the last step of S does consist in applying a smooth function of one variable F to the result r(x1 ; :::; xn) of some previous step. In this case, f (x1; :::; xn) = F (r(x1; :::; xn)). Let us prove that r(~ x) has a non-degenerate stationary point (at the same ~ s), and that for this function r, smooth interval computations are locally asymptotically correct in the neighborhood of ~ s. Indeed, we know that ~ s is a stationary point for f , i.e., that f;i (s1; :::; sn) = 0. Since f (x1; :::; xn) = F (r(x1; :::; xn)), we have f;i (s1; :::; sn) = F 0 (r(s1; :::; sn)) r;i (s1; :::; sn). Similarly, f;ij (~ s) = F 00 (r(~ s))r;i(~ s)r;j (~ s)+ F 0 (r(~ s)) r;ij (~ s). Since f;i(~ s) = 0, we can conclude that either F 0 (r(~ s)) = 0, or r;i (~ s) = 0. In the rst case, f;ij = F 00 (~ s)r;i r;j , and the determinant of the Hessian at ~ s is 0, which contradicts to our assumption that ~ s is a nondegenerate point. Therefore, F 0 (~ s) 6= 0, and r;i (~ s) = 0, and ~ s is a stationary point of the function r(x1; :::; xn). Since F 0 (r(~ s)) 6= 0 and r;i (~ s) = 0, from f;ij (~ s) = F 00(r(~ s))r;i (~ s)r;j (~ s)+ F 0 (r(~ s)) r;ij (~ s), we can conclude that f;ij (~ s) = F 0 (r(~ s)) r;ij (~ s), and r;ij (~ s) = C f;ij (~ s), where C = 0 1=F (r(~ s)). Since ~ s is a non-degenerate stationary point of f , we have f;ij 6= 0, hence r;ij (~ s) = C f;ij (~ s) 6= 0. Similarly, from det jf;ij j 6= 0, we conclude that det jr;ij j 6= 0. So, ~ s is a non-degenerate stationary point for the function r. Let us now show that for the smooth computation scheme that leads to r, smooth interval computations are locally asymptotically correct in the neighborhood of ~ s. Indeed, let r ~i be the generalized linear functions that appear (as coe cients at i ) in the description of the result of applying smooth interval computations to r. This means that after we reach r, the resulting interval is equal to r (~ r1 1 + ::: + r ~n n ) + O(:::). Due to Proposition 3.1, after applying the function F to this interval, we get F (r) jF 0 (r(x1; :::; xn))j(~ r1 1 + ::: + r ~n n ) + O(:::): 33

Now, since F 0 (r) is a smooth function, we get

F 0 (r(x1; :::; xn)) = F 0 (r(~ s)) +

X F 00(r(~ s))r (x ? s ) + O((x ? s )2 ):
;i i i i i

Since ~ s is a stationary point for r, we have r;i (~ s) = 0, and therefore, F 0 (r(x1; :::; xn)) = F 0 (r(~ s))+ O((xi ? si )2) and jF 0(r(x1; :::; xn))j = jF 0 (r(~ s))j + O((xi ? si )2). So, the result of applying smooth interval computations to S is equal to F (r) jF 0 (r(~ s))j(~ r1 1 +:::+~ rn n )+ O(:::). Since for f and S , smooth interval computations are locally asymptotically correct, we can (due to Lemma 3) conclude that for all i, jF 0 (r(~ s))j r ~i (~ x) = jf;i(~ x)j + O(:::). But, 0 since f (~ x) = F (r(~ x)), we have f;i (~ x) = F (r(~ x))r;i (~ x) and jf;i(~ x)j = jF 0 (r(~ x))j jr;i(~ x)j. We already know that jF 0(r(x1; :::; xn))j = jF 0(r(~ s))j + O((xi ? si )2). Therefore, jf;i (~ x)j = 0 jF (r(~ s))j jr;i(~ x)j + O(:::). So, from

jF 0 (r(~ s))j r ~i (~ x) = jf;i(~ x)j + O(:::) = jF 0 (r(~ s))j jr;i(~ x)j + O(:::);
we can conclude that r ~i (~ x) = jr;i (~ x)j + O(:::), and hence, due to Lemma 3, that for r, smooth interval computations are locally asymptotically correct. Since r is computed on a previous step of the smooth computation scheme S , the number of steps that lead to r is smaller than the number of computation steps in a scheme S , and this contradicts to our choice of S as the shortest smooth computation scheme that leads to a smooth non-degenerate function for which smooth interval computations are locally asymptotically correct. So, the last step of our smooth computation scheme S cannot consist of applying a function of one variable. complete our proof, let us show that the last step cannot consist of applying a function of two variables. Indeed, suppose that the last step consists of applying a smooth function F of two variables to two functions r(~ x) and t(~ x) that have been computed on a previous computation step. In this case, f;i = F;r r;i + F;t t;i , where by F;r and F;t, we denoted partial derivatives of F w.r.t. r and t.

Second case: the last step consists of applying a function of two variables. To

Let us rst show that for ~ s, both partial derivatives of F cannot be 0. Indeed, suppose that they are. For f = F (r; t), the Hessian matrix is equal to f;ij (~ x) = F;rr (~ x)r;ir;j + 2F;rt (~ x)r;i t;j + F;tt (~ x)t;i t;j + F;r (~ x)r;ij + F;t (~ x)t;ij . In particular, for ~ x=~ s, taking into consideration that F;r = F;t = 0, we conclude that f;ij (~ s) = F;rr (~ s)r;ir;j + 2F;rt (~ s)r;i t;j + F;tt (~ s)t;i t;j . If we choose vectors r;i (~ s) and t;i(~ s) as the rst two elements of the base, then the Hessian matrix will only have 11, 12, and 22 components. Therefore, the determinant 34

of the Hessian matrix f;ij (~ s) will be 0, which contradicts to our assumption that the stationary point ~ s is non-degenerate. This contradiction shows that the derivatives F;r (~ s) and F;t (~ s) cannot be both equal to 0. Hence, we only need to consider the following three subcases: F;r (r(~ s); t(~ s)) 6= 0 and F;t(r(~ s); t(~ s)) 6= 0. F;r (r(~ s); t(~ s)) 6= 0 and F;t(r(~ s); t(~ s)) = 0. F;r (r(~ s); t(~ s)) = 0 and F;t(r(~ s); t(~ s)) 6= 0. We will analyze these three subcases separately. from 0 at ~ s. Let us show that in this case, r;i (~ s) = t;i (~ s) = 0. Indeed, the interval that P corresponds to r is equal to r r ~i i + O(:::), and the interval that corresponds to t is P ~i i + O(:::). Due to Proposition 3.1, the interval that corresponds to f is equal to t t P f~i i +O(:::), where f~i(~ ~i(~ thus equal to f x) = jF;r (~ x)j r ~i(~ x)+jF;t(~ x)j t x)+O((xi ?si )2 ). Let us analyze this equality for ~ x=~ s. For this ~ x, the O term is equal to 0, so we have an ~i (~ ~i (~ exact equality f x) = jF;r (~ x)j r ~i (~ x) + jF;t(~ x)j t x). Since smooth interval computations are locally asymptotically correct for f , we have (due to Lemma 2) f~i = jf;ij + O((xi ? si )2 ). In particular, for ~ x=~ s, we have f~;i (~ s) = jf;i(~ x)j = 0. So, the left-hand side of the equality ~i(~ ~i are non-negative for all ~ is 0: 0 = jF;r (~ s)j r ~i(~ s)+ jF;t(~ s)j t s). The coe cients r ~i and t x. ~i (~ So, 0 is equal to the sum of two non-negative products (jF;r (~ s)j r ~i (~ s) and jF;t(~ s)j t s)). The only way for this to happen is when both products are equal to 0. Since F;r 6= 0 for ~ x=~ s, from jF;r (~ s)j r ~i (~ s) = 0, it follows that r;i(~ s) = 0. Similarly, we can conclude that t;i (~ s) = 0. Due to r;i (~ s) = t;i (~ s) = 0, we can (similarly to the case of f = F (r)) conclude that ~i(~ F (~ x) = F (~ s)+ O((xi ? si )2 ). Therefore, f~i (~ x) = jF;r (~ s)jr ~i (~ x)+ jF;t (~ s)jt x)+ O(:::). On the ~i = jf;ij + O(:::), where f;i (~ other hand, f x) = F;r (~ x)r;i(~ x)+ F;t (~ x)t;i (~ x), and due to F (~ x) = 2 F (~ s)+ O((xi ? si ) ), we can rewrite this equality as f;i (~ x) = F;r (~ s)r;i (~ x)+ F;t (~ s)t;i(~ x). So,

First subcase of the second case: both partial derivatives of F are di erent from 0 at ~ s. Let us rst consider the case when both partial derivatives of F are di erent

f~i = jf;ij + O(:::) = jF;r (~ s)r;i(~ x) + F;t (~ s)t;i(~ x)j + O(:::):
Since jp + qj jpj + jqj, we conclude that

f~i jF;r r;i + F;t t;ij + O(:::) jF;r j jr;i j + jF;tj jt;i j + O(:::):
~i + O(:::). Therefore, Due to Lemma 2, jr;ij r ~i + O(:::) and jt;i j t ~i + O(:::): f~i jF;r r;i + F;t t;ij + O(:::) jF;r j jr;ij + jF;tj jt;ij + O(:::) jF;r j r ~i + jF;t j t 35

But the right-hand side of this inequality is already known to be equal to f~i (~ x) (modulo quadratic terms). Therefore,

f~i jF;r r;i + F;t t;ij + O(:::) jF;r j jr;ij + jF;tj jt;ij + O(:::) f~i + O(::):
In this chain of inequalities the starting and the ending expressions coincide, and hence, they are all equalities. So,

jF;r r;i + F;t t;i j = jF;r j jr;i j + jF;t j jt;i j + O(:::):
The only case when jp + qj = jpj + jqj is when p and q are of the same sign. So, we can conclude that the linear parts of the expressions F;r (~ s) r;i (~ x) and F;t (~ s) t;i(~ x) are of the same sign. Clearly, the sign of the linear part of

f;i = F;r (~ s) r;i(~ x) + F;t(~ s) t;i(~ x) + O(:::)
will be of the same sign. This linear part is f;ij (~ s)(xj ? sj ). Similarly, we can express the linear parts of r;i and t;i . We know that the numbers F;r (~ s) and F;t (~ s) are di erent from 0. Let us assume that both numbers are positive (the cases when one of them is negative can be treated in a similar manner). In this case, if a linear term in f;i is positive, then the linear terms in r;i and t;i are also non-negative. In other words, if P P s)(xj ?sj ) 0. Turning to a limit, we can conclude that f s )(xj ? sj ) > 0, then f;ij (~ ;ij (~ P s)(xj ? sj ) 0, then P f;ij (~ P s)(xj ? sj ) 0, if f;ij (~ s )(xj ? sj ) 0. Similarly, if f;ij (~ P s)(xj ? sj ) 0. Therefore, if P f;ij (~ then f;ij (~ s)(xj ? sj ) = 0,P then we have both P f;ij (~ P s)(xj ?sj ) 0 and f;ij (~ s)(xj ?s s)(xj ?sj ) 0 j ) 0, hence, we have both r;ij (~ P P and r;ij (~ s)(xj ? sj ) 0, and thence, r;ij (~ s)(xj ? sj ) = 0. So, if f;ij (~ s)(xj ? sj ) = 0, then r;ij (~ s)(xj ? sj ) = 0. In geometric terms, the ~i with coordinates condition means that a vector xj ? sj is orthogonal to the vector f f;i1(~ s); :::; f;in(~ s). Similarly, the conclusion means that a vector xj ? sj is orthogonal to the vector ~ ri with coordinates r;ij (~ s). Since ~ s is a non-degenerate stationary point, the ~i is not zero, and therefore, vectors that are orthogonal to f ~i form a (hyper)plane. vector f A vector ~ ri is orthogonal to every vector from this (hyper)plane, and is, therefore, collinear ~i . This means that for every i, there exists a constant ci such that r;ij (~ with f s) = ci f;ij (~ s) for all i and j . The matrix of second derivatives is symmetric: r;ij = r;ji . Therefore, for every i and j , ci f;ij = cj f;ji. Since second derivatives of f;ij also form a symmetric matrix, we have 36

P

P

P

ci f;ij = cj f;ij . Due to the fact that ~ s is a non-degenerate stationary point for f , we conclude that f;ij = 6 0 and therefore, ci = cj for all i and j . Let us denote the common value of all ci by c. Then, r;ij (~ s) = cf;ij (~ s). Similarly, t;ij (~ s) = c0 f;ij (~ s). The coe cients c and c0 cannot be both equal to 0, because then, we would have f;ij (~ s) = F;r (~ s)rij (~ s) + F;t (~ s)t;ij (~ s) = 0. 0 So, either c = 6 0, or c = 6 0. If c = 6 0, then r;ij (~ s) = cf;ij (~ s) is a non-degenerate matrix with non-zero determinant and all elements non-zero. Therefore, r is a function that has a non-degenerate stationary point at ~ s, and that can be computed in fewer steps than f , which contradicts to our choice of f . Similarly, if c0 = 6 0, then t is a function that contradicts to our choice of f . In both cases, we get a contradiction.

Second and third subcases of the second case: only one partial derivative of F is di erent from 0 at ~ s. We have derived a contradiction for the case when both partial derivatives F;r (~ s) = 6 0 and F;t (~ s) = 6 0. To complete the proof of the theorem, we

must deduce a contradiction for the case when one of these partial derivatives is equal to 0. Without losing generality, we can assume that F;r (~ s) 6= 0 and F;t (~ s) = 0. ~i (~ In this subcase, from the equality f~i (~ x) = jF;r (~ x)j r ~i (~ x) + jF;t (~ x)j t x) (that can be proven exactly like in the rst subcase), we conclude that r;i (~ s) = 0. Since F;t (~ s) = 0, we can conclude that F;t (~ s) = aj (xj ?sj )+O((xi ?si )2 ). Therefore, only zeroth-order terms in t;i (~ x) need to be taken into consideration, and we have

P

f;i (~ x) =

Xf

s) ;ij (xj ? sj )+ O(:::) = F;r (~

Xr

s)(xj ? sj )+( ;ij (~

X a (x ? s ))t (~ s)+ O(:::):
j j j ;i

Similarly to the rst subcase, we can prove that the two linear components of this sum must be of the same sign as fi , and therefore, that r;ij = cf;ij and aj t;i = c0 f;ij . The coe cient c0 cannot be di erent from 0, because then, we would have f;ij = (1=c0)aj t;i, and det jf;ij j = 0,which contradicts to our assumption that the Hessian matrix f;ij is nondegenerate. Therefore, c0 = 0, and hence, c = 0 is impossible. Therefore, r;ij = (1=c)f;ij , and r is a function that has a non-degenerate stationary point at ~ s, and that can be computed in fewer steps than f , which contradicts to our choice of f . We have proven the result for the rst case, and for all subcases of the second case; therefore, the theorem is proven. Q.E.D.

Proof of Theorem 3.4
Since the function f is smooth, for every point ~ s, we have f (~ x) = fquadr(~ x)+ O((xi ? si )3 ), where X s)(x ? s ) + 1 X f (x ? s )(x ? s ): fquadr = f (~ s) + f;i(~ ;ij i i j j i i 2
i i;j

37

Therefore (similarly to the proof of Proposition 3.1), we can conclude that the di erence between the intervals f (X1; :::; Xn) and fquadr (X1; :::; Xn) is also O((xi ? si )3). The function fquadr is quadratic in xi , so, we can represent it as

fquadr(x1; :::; xn) = a0 +

Xa x + Xa
i i i i;j

ij xi xj

for some real numbers ai and aij . If we de ne a0i = ai for i = 0; 1; :::; n, then we can represent this expression as fquadr(x1 ; :::; xn) = g(x0; x1; :::; xn) for x0 = 1 and

g(x0; :::; xn) =

n X n X a i=0 j =0

ij xi xj :

The function g, in its turn, can be represented as a result of applying n simpli cations xi = yi , 1 i n, to a weighted scalar product
n X n X f (x ; x ; :::; x ; y ; y ; :::; y ) = a

0 1

n 0 1

n

i=0 j =0

ij xi yj

with weights aij . So, fquadr can be computed using a computation scheme S with weighted scalar products. Since the di erence between the intervals f (X1; :::; Xn) and fquadr(X1; :::; Xn) is O((xi ? si )3 ), we can conclude that smooth interval computations described by the scheme S are locally asymptotically correct for the original function f . Q.E.D.

Proof of Proposition 5.1
1. Let us prove this Proposition by reduction to a contradiction. Namely, assume that f : K ! R is strictly monotonic in each variable, and that f is degenerate. By de nition, this means that K can be represented as a union of nitely many sets K1 ; :::; Kp on each of which f is equal to a function of two of fewer variables. Let's deduce a contradiction from here. 2. Since the interior of M

K is non-empty, the set M contains a ball.

Inside the ball, we can place a cube a1; b1] a2; b2] ::: an ; bn]. Let's divide each side ai ; bi] of the cube into p + 1 equally distanced values of xi : ai , ai + (bi ? ai )=p, ai + 2 (bi ? ai)=p, ..., ai + p (bi ? ai )=p = bi . By combining these values for di erent i, we get (p + 1)n di erent points that all belong to the cube and therefore, to K . Let us denote the set of all these points by P . 38

3. Let us take one of the sets Ki , and let us estimate how many of the points from P belong to Ki . Since f is degenerate of Ki , it means that on Ki f is equal to a function of two or fewer variables. But f is a function of n 3 variables. So, this means, that for ~ x 2 Ki , f cannot depend on all the variables. Hence, it does not depend on one of the variables. Let us denote one of such variables by xj . The fact that for ~ x 2 Ki , f does not depend on xj , means that if we have two di erent points with di erent values of xj and equal values of all other coordinates, then the value of f for both point will be the same. 4. Formally, if ~ x = (x1; :::; xj?1; xj ; xj+1; :::; xn) 2 P where xj 6= 0, then f (~ x) = f (~ y). But on M , f is strictly monotonic in each variable. This means, in particular, that f is either strictly increasing in xj , or strictly decreasing in xj . In both cases, f (~ x) 6= f (~ y). This contradiction with f (~ x) = f (~ y) shows that no such pairs (~ x; ~ y) are possible. In other words, if we x the values of n ? 1 coordinates (all of them except for xj ), i.e., if we x the values x1; :::; xj?1; xj+1; :::; xn, then at most one point with these values of n ? 1 coordinates belongs to Ki . 5. For P , if we x the values of all the coordinates but one, then, we can choose p + 1 di erent values of xj and hence, have p + 1 di erent points from P K . At most one of them belongs to Ki. Therefore, Ki contains at most 1=(p + 1) part of all the points from P. 6. The same inequality is true for each of the sets Ki . So, totally, p sets K1, ..., Kp contain p=(p + 1) of all the points from P . Since p=(p + 1) < 1, it means that there are points from P (and hence from K ) that are not covered by any of the sets Ki . This contradicts to our assumption that f is degenerate and K = Ki . This contradiction shows that our assumption was false, and so f is not degenerate. Q.E.D.

M and

~ y = (x1 ; :::; xj?1; xj + xj ; xj+1; :::; xn) 2 M;

Proof of Proposition 5.2
Let us show that if a real analytic function f (x1; :::; xn) does not coincide with a function of less than n variables, then it is non-degenerate in the sense of De nition 5.2. Indeed, an arbitrary real analytic function g(x1; :::; xn) has the following property (similar to complex analytical functions): it is either identically equal to 0, or it is equal to 0 on a set of (Lebesgue) measure 0 (i.e., it is di erent from 0 on a set of full measure) (see, e.g., 17]). 39

Also, for an arbitrary real analytic function, each of its derivatives is also real analytic. In particular, the partial derivative @f=@x1 of the given function is real analytic. If it was identically equal to 0, then f would not depend on x1 at all. Therefore, according to the above-cited result, the set of points (x1 ; :::; xn) on which this derivative is equal to 0 is of Lebesgue measure 0. Similarly, for each i = 2; :::; n, the set of all points (x1 ; :::; xn), at which i?th partial derivative @f=@xi is equal to zero, is also of measure 0. Therefore, the union of these n sets, i.e., the set of all points on which at least one of the partial derivatives is di erent from 0, is also of measure 0 (as a union of measure-zero (0) sets). Therefore, there exists a point (x(0) 1 ; :::; xn ) that does not belong to this union. By de nition of the union it means that in this point, all n partial derivatives are di erent from 0. These derivatives are real analytic and therefore, continuous. Therefore, there exists (0) a spherical neighborhood M of this point (x(0) 1 ; :::; xn ) in which sign of each of the partial (0) derivatives coincides with its sign at the point (x(0) 1 ; :::; xn ). For those i for which this sign is positive (@f=@xi > 0), f is strictly increasing in xi . For those i for which this sign is negative (@f=@xi < 0), f is strictly decreasing in xi . So, for all points from a set M with a non-empty interior, the function f is strictly monotonic in each variable. Therefore, according to Proposition 5.1, this function f is non-degenerate. Q.E.D.

Proof of Theorem 5.1
1. Let us prove this theorem by reduction to a contradiction. Namely, we will assume that there exists a non-degenerate function f and a computation scheme S that computes f and that is precise for all (crisp) sets, and we will deduce a contradiction from this assumption. To deduce this contradiction, we will use the following observation: According to our de nitions, the phrase \S is precise for all (crisp) sets" means that for every (crisp) set X Rn , the result RN of applying S to X coincides with f (X ). In this proof, we will need the following two Lemmas:

LEMMA 4. Assume that a function f : K ! R (K Rn ) is computed by a composition scheme S , and X K . Let's denote by RN the result of applying S to X . Then, f (X )
RN .
tions (see, e.g., 29]), and is proved similarly: namely, using induction, one can then prove that for every i, ri (X ) Ri. For i = N , we get the desired result. Q.E.D. 40

Proof of Lemma 4. This Lemma is similar to the Main Theorem of Interval Computa-

is a composition of f and g (i.e., h(~ x) = f (g(~ x))). Then, for every (crisp) set X h(X ) = f (g(X )).

LEMMA 5. Assume that k is an integer, f : R ! R, g : Rk ! R, and h : Rk ! R

Rk ,

Proof of Lemma 5 follows directly from the de nitions. Q.E.D.
2. We will need the following auxiliary notion: by a complexity of a computation scheme S = (Sn+1 ; :::; SN ), we will understand the number N . We assumed that there exists a computation scheme that computes a non-degenerate function of n variables and that is precise for all (crisp) sets. Out of all computation schemes with this property, there exists a one with the smallest possible complexity N . Let's choose one of these \simplest" schemes. In the following text, this chosen scheme will be denoted by Ss (s stands for simplest). The corresponding function will be denoted by fs .
Comment. A computation scheme Ss consists of the rules of the type ri := ci , ri := fi (rj ), and ri := fi (rj ; rk ). In principle, the corresponding functions fi can be de ned everywhere. However, when we apply this computation scheme to compute the value of the function fs that is de ned on some set K , we will use only the values of fi for rj 2 ri (K ); or, for the function of two variables, only the values for (rj ; rk ) 2 Djk , where

Djk = f(a; b) j 9~ x (~ x 2 K & rj (~ x) = a & rk (~ x) = bg:
Therefore, to simplify our proofs, we will assume in the following text that fi is de ned only for these values. It is easy to check that if initially Ss computed fs and was precise for all (crisp) sets, then after such a restriction on fi it still has the same properties. 3. Depending on what the nal step SN of Ss is, we have the following ve possibilities: N n; N > n and rN := cN ; N > n and rN := fN (rj ), where j < N ; N > n and rN := fN (rj ; rk ), where j n and k n; N > n and rN := fN (rj ; rk ), where j > n or k > n. In the following ve subsections, we will prove that in all these ve cases, we have a contradiction with our initial assumption. 4. N

n.
41

In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = xN . So, fs depends only on one of its variables. Hence, fs is degenerate, which contradicts to the assumption that it is nondegenerate. 5. N > n and rN := cN . In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = cN does not depend on any variables at all. Therefore, it is degenerate. 6. N > n and rN := fN (rj ), where j < N . Let us prove (by considering all possible cases) that this case is impossible. Depending on the case, we will prove it either directly, or by \merging" the last step with one of the previous ones, and thus coming up with a new computation scheme that is simpler than the scheme Ss that is by de nition the simplest possible (so, we have a contradiction). 6.1. If j n, then rj = xj , and fs = fN (rj ) = fN (xj ) is a function of one variable (namely, xj ) and is thus degenerate, which contradicts to our choice of fs. 6.2. If j > n, and j ?th step is rj := cj , then fs = rN = fN (cj ) =const, i.e., fs is also degenerate. 6.3. If j > n, and j ?th step is rj := fj (rk ) for some k < j , then rN = fN (fj (rk )). In ~N (rk ), where by f~N , we denoted the composition of fN and fj . other words, rN = f 6.3.1. If k n, then fs is again a function of one variable xk (i.e., degenerate). 6.3.2. If k > n, then, we can replace the original computation scheme S with the ~ = (Sn+1 ; :::; Sk ; S ~N ), where by S ~N , we denoted the following simpli ed one: S ~N (rk ). Because of our formulas, this scheme computes following step: rN := f exactly the same function fs . The fact that this scheme computes the same function and is precise for all (crisp) sets, follows from Lemma 5. Since we deleted at least one step (Sj ), this new scheme has a smaller complexity that Ss . This contradicts to our choice of Ss as the computation scheme with the smallest possible complexity that computes a non-degenerate function of 3 or more variables and that is precise for all (crisp) sets. 6.4 If j > n, and j ?th step is rj := fj (rk ; rl ) for some k; l < j , then rN = fN (fj (rk ; rl)) = f~N (rk ; rl ), where by f~N , we denoted a composition f~N (a; b) = fN (fj (a; b)). In this case, we can also delete one step from the computation scheme and thus arrive at the contradiction. 42

7. N > n and rN := fN (rj ; rk ), where j n and k n. In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = fN (xj ; xk ). Hence, fs depends on only two of its variables, and is therefore degenerate. 8. N > n and rN := fN (rj ; rk ), where j > n or k > n. 8.1. We assumed that Ss computes fs , and that Ss is precise for all (crisp) sets. This means, in particular, that for each input set X K , RN = fs(X ). In particular, if we take arbitrary two elements ~ x 2 K and ~ y 2 K , then this equality must be true for a 2-point set X = f~ x; ~ yg. 8.2. For this choice of X , the right-hand side of the equality RN = fs (X ) (i.e., the set fs(X )) is easy to describe: it consists of two values fs (~ x) = fN (rj (~ x); rk (~ x)) and fs(~ y) = fN (rj (~ y); rk (~ y)). 8.3. Now, let's nd an element of the left-hand side. By de nition of RN , this set is equal to RN = fN (Rj ; Rk ). Due to Lemma 4, Rj rj (X ), and Rk rk (X ). Since rj (~ x) 2 rj (X ), we can thus conclude that rj (~ x) 2 Rj . Similarly, we can conclude that rk (~ y) 2 Rk . Therefore, fN (rj (~ x); rk (~ y)) 2 fN (Rj ; Rk ) = RN . Since RN = fs(X ), every element of RN must coincide with one of the two elements of fs (X ). In particular, for the above-discovered element, it means the following:
For every ~ x 2 K and ~ y 2 K , fN (rj (~ x); rk (~ y)) is either equal to fN (rj (~ x); rk (~ x)), or it is equal to fN (rj (~ y); rk (~ y)).

8.4. This statement enables us to make the following conclusion about the function fN (a; b):
If we can nd ~ x and ~ y such that a = rj (~ x) and b = rk (~ y), then either fN (a; b) = fN (a; rk (~ x)), or fN (a; b) = fN (rj (~ y); b).

8.5. For each a 2 rj (K ), there exists a vector ~ x for which rj (~ x) = a (it is possible that several such vectors exist). For di erent vectors ~ x, the value rk (~ x) may also be di erent. For each a, let us pick one of these values rk (~ x) and denote it by gkj (a). Similarly, for each b 2 rk (K ), we will pick a vector ~ x with the property that rk (~ x) = b, and denote the value rj (~ x) for thus picked ~ x by gjk (b). 8.6. Using these denotations, we can reformulate the statement from 8.4 as follows: 43

For every a 2 rj (K ) and b 2 rk (K ), either fN (a; b) = fN (a; gkj (a)), or fN (a; b) = fN (gjk (b); b).

If we denote h1 (a) = fN (a; gkj (a)) and h2 (b) = fN (gjk (b); b), then we can further simplify this conclusion: For every (a; b) 2 Djk , either fN (a; b) = h1 (a), or fN (a; b) = h2 (b). 8.7. In particular, this property is true if we choose an arbitrary ~ x 2 K and take a = rj (~ x) and b = rk (~ x). Let us denote by K1 the set of all ~ x 2 K for which fN (rj (~ x); rk (~ x)) = h1 (rj (~ x)), and by K2, the set of all values ~ x 2 K for which fN (rj (~ x); rk (~ x)) = h2 (rk (~ x)). Then, this property means that K = K1 K2. 8.8. Since the function f de ned on K is non-degenerate, its restriction to either K1 or K2 is also non-degenerate. Indeed, if it were not true, then we would be able to describe both K1 and K2 (and hence, their union) as the union of nitely many subsets on which fs is degenerate. On the other hand, we assumed that fs : K ! R is non-degenerate, which means that for K , such a representation is impossible. 8.9. Let us choose a set Ki (i.e., K1 or K2) for which the restriction of fs is non-degenerate. For this set, we can form the restriction of fs and Ss . For this restriction, we can take rN := h1 (rj ) (or rN := h2 (rk )) as a last step of the computation scheme (instead of the step rN := fN (rj ; rk )), and the resulting computation scheme will still compute the restriction of fs , and it will still precise for all (crisp) sets. If we were able to compute a non-degenerate function fs by another computation scheme S1 whose complexity is < N computation steps, then we would get a contradiction with our choice of N as the smallest possible complexity of a computation scheme that computes a non-degerenate function. Therefore, the resulting computation scheme is still the \simplest" in the sense that its complexity N is the smallest possible among all computation schemes that compute non-degenerate functions. So, we arrive at the situation where we have the \simplest" computation scheme, and the function at the last step is a function of one variable; we have already proved (in part 6 of this proof) that such situation leads to a contradiction. 9. So, in all ve cases, we arrive at a contradiction. Hence, our initial assumption is false, namely, the assumption that a non-degenerate function of 3 or more variables can 44

be computed by a computation scheme (with unary and binary operations only) that is precise for all (crisp) sets. Q.E.D.

CONCLUSIONS Theoretical. The main theoretical result of this paper is that functions of several interval
or fuzzy variables cannot always be computed precisely if we use only operations with one or two interval (resp. fuzzy) variables. Moreover, for smooth functions f , we show that even the main term in the result of fuzzy (interval) computations cannot always be computed correctly. The accuracy of interval and fuzzy data processing drastically improves if we add weighted scalar product to the list of elementary (hardware supported) operations. For numerical operands, scalar product is already hardware supported in modern computers: by math co-processors. There have been successful attempts to hardware support scalar product of interval operands. it is desirable to hardware support (weighted) scalar product of fuzzy operands as well (at least, some operations with three or more fuzzy operands). and No. EEC-9322370, by a Grant No. PF90{018 from the General Services Administration (GSA), administered by the Materials Research Institute and the Institute for Manufacturing and Materials Management, and by a NASA grant No. NAG 9-757. The authors are greatly thankful to Paul Kainen, Baker Kearfott, Vera Kurkova, and Reza Langari for valuable discussions, and to the anonymous referees for their extremely valuable suggestions and help.

Practical. Therefore, our main practical recommendation is that for fuzzy data processing,

Acknowledgments. This work was partially supported by NSF grants No. CDA-9015006

45

REFERENCES
1] O. Artbauer, \Application of interval, statistical, and fuzzy methods to the evaluation of measurements", Metrologia, 1988, Vol. 25, pp. 81{86. 2] H. Dhirf and D. Sarkar, \Fuzzy arithmetic on systolic arrays", Parallel Computing, 1993, Vol. 19, pp. 1283{1301. 3] W. M. Dong, W. L. Chiang, H. C. Shah, \Fuzzy information processing in seismic hazard analysis and decision making", International Journal of Soil Dynamics and Earthquake Engineering, 1987, Vol. 6, No. 4., pp. 220{226. 4] W. Dong and F. Wong, \Fuzzy weighted averages and implementation of the extension principle", Fuzzy Sets and Systems, 1987, Vol. 21, pp. 183{199. 5] D. Dubois and H. Prade. Fuzzy sets and systems: theory and applications, Academic Press, N.Y., London, 1980. 6] H. L. Frisch, C. Borzi, G. Ord, J. K. Percus, and G. O. Williams, \Approximate Representation of Functions of Several Variables in Terms of Functions of One Variable", Physical Review Letters, 1989, Vol. 63, No. 9, pp. 927{929. 7] R. Fuller and T. Keresztfalvi, \On generalization of Nguyen's theorem", Fuzzy Sets and Systems, 1990, Vol. 4, pp. 371{374. 8] W. A. Fuller, Measurement error models, J. Wiley & Sons, New York, 1987. 9] A. A. Gaganov, \Computational complexity of the range of the polynomial in several variables", Cybernetics, 1985, pp. 418{421. 10] R. Hammer, M. Hocks, U. Kulisch, D. Ratz, Numerical toolbox for veri ed computing. I. Basic numerical problems, Springer Verlag, Heidelberg, N.Y., 1993. 11] E. R. Hansen, Global optimization using interval analysis, Marcel Dekker, N.Y., 1992. 12] R. Hecht-Nielsen, \Kolmogorov's Mapping Neural Network Existence Theorem", IEEE International Conference on Neural Networks, San Diego, SOS Printing, 1987, Vol. 2, pp. 11{14. 13] D. Hilbert, \Mathematical Problems, lecture delivered before the International Congress of Mathematics in Paris in 1900", translated in Bull. Amer. Math, Soc., 1902, Vol. 8, pp. 437{479. 14] R. B. Kearfott and V. Kreinovich (eds.), Applications of Interval Computations, Kluwer, Dordrecht, 1996. 15] A. N. Kolmogorov, \On the Representation of Continuous Functions of Several Variables by Superposition of Continuous Functions of One Variable and Addition", Dokl. Akad. Nauk SSSR, 1957, Vol. 114, pp. 369{373. 16] G. Klir and B. Yuan, Fuzzy sets and fuzzy logic: theory and applications, Prentice 46

17]

18] 19]

20]

21] 22]

23] 24] 25] 26] 27]

Hall, Upper Saddle River, NJ, 1995. V. Kreinovich, \On the problem of recovering the ?function in non-relativistic quantum mechanics", Teoreticheskaya i Mathematicheskaya Fizika, 1976, Vol. 28, No. 1, pp. 56{64 (in Russian); English translation: Theoretical and Mathematical Physics, 1976, Vol. 8, No. 7, pp. 56{64. V. Kreinovich (ed.), Reliable Computing, 1995, Supplement (Extended Abstracts of APIC'95: International Workshop on Applications of Interval Computations, El Paso, TX, Febr. 23{25, 1995). V. Kreinovich, Ching-Chuang Chang, L. Reznik, G. N. Solopchenko, \Inverse problems: fuzzy representation of uncertainty generates a regularization", Proceedings of NAFIPS'92: North American Fuzzy Information Processing Society Conference, Puerto Vallarta, Mexico, December 15{17, 1992, NASA Johnson Space Center, Houston, TX, 1992, Vol. II, pp. 418{426. V. Kreinovich, C. Quintana, L. Reznik, Gaussian membership functions are most adequate in representing uncertainty in measurements, In: Proceedings of NAFIPS'92: North American Fuzzy Information Processing Society Conference, Puerto Vallarta, Mexico, December 15{17, 1992, NASA Johnson Space Center, Houston, TX, 1992, Vol. II, pp. 618{624. V. Kreinovich et al, What non-linearity to choose? Mathematical foundations of fuzzy control, Proceedings of the 1992 International Conference on Fuzzy Systems and Intelligent Control, Louisville, KY, 1992, pp. 349{412. V. Kreinovich and L. K. Reznik, \Methods and models of formalizing a priori information (on the example of processing measurements results)", In: Analysis and Formalization of Computer Experiments, Proceedings of the Mendeleev Metrology Institute, 1986, pp.37{41 (in Russian). U. Kulisch, G. Bohlender, \Features of a hardware implementation of an optimal arithmetic", In: U. Kulisch, W. L. Miranker (eds), A new approach to scienti c computation, Academic Press, Orlando, FL, 1983, pp. 269{290. V. Kurkova, \Kolmogorov's Theorem Is Relevant", Neural Computation, 1991, Vol. 3, pp. 617{622. V. Kurkova, \Kolmogorov's Theorem and Multilayer Neural Networks", Neural Networks, 1992, Vol. 5, pp. 501{506. G. G. Lorentz, \The 13-th problem of Hilbert", in: F. E. Browder (ed.), Mathematical Developments Arizing from Hilbert's Problems, American Math. Society, Providence, RI, 1976, Part 2, pp. 419{430. R. E. Moore, Automatic error analysis in digital computation, Lockheed Missiles and 47

28] 29] 30] 31] 32] 33] 34] 35] 36] 37]

38] 39] 40] 41] 42] 43]

Space Co. Technical Report LMSD-48421, Palo Alto, CA, 1959. R. E. Moore, C. T. Yang, Interval analysis, Lockheed Missiles and Space Co. Technical Report LMSD-285875, Palo Alto, CA, 1959. R. E. Moore, Methods and applications of interval analysis, SIAM, Philadelphia, 1979. M. Nakamura, R. Mines, V. Kreinovich, \Guaranteed Intervals for Kolmogorov's Theorem (and Their Possible Relation to Neural Networks)", Interval Computations, 1993, No. 3, pp. 183{199. M. Ness, \Approximative versions of Kolmogorov's superposition theorem, proved constructively", J. Comput. Appl. Math., 1993. V. M. Nesterov, \Interval analogues of Hilbert's 13th problem", In: Abstracts of the Int'l Conference Interval'94, St. Petersburg, Russia, March 7{10, 1994, 185{186. H. T. Nguyen, \A note on the extension principle for fuzzy sets", J. Math. Anal. and Appl., 1978, Vol. 64, pp. 359{380. H. T. Nguyen and E. A. Walker, A First Course in Fuzzy Logic, CRC Press, Boca Raton, Florida, 1996 (to appear). S. Rabinovich, Measurement errors: theory and practice, American Institute of Physics, N.Y., 1993. M. J. Schulte and E. E. Swartzlander, Jr., \Parallel Hardware Designs for Correctly Rounded Elementary Functions", Interval Computations, 1993, No. 4, pp. 65{88. M. J. Schulte and E. E. Swartzlander, Jr., \Design and applications for variableprecision, interval arithmetic coprocessors", In: V. Kreinovich (ed.), Reliable Computing, 1995, Supplement (Extended Abstracts of APIC'95: International Workshop on Applications of Interval Computations, El Paso, TX, Febr. 23{25, 1995), pp. 166{172. S. M. Shah and R. Horvath, A hardware digital fuzzy inference engine using standard integrated circuits, Information Sciences, 1994, Vol. 1, pp. 1{7. G. N. Solopchenko, \Formal metrological components of measuring systems", Measurement, 1994, Vol. 13, pp. 1{12. D. A. Sprecher, \On the Structure of Continuous Functions of Several Variables", Transactions Amer. Math. Soc., 1965, Vol. 115, No. 3, pp. 340{355. D. A. Sprecher, \An Improvement in the Superposition Theorem of Kolmogorov", Journal of Mathematical Analysis and Applications, 1972, Vol. 38, pp. 208{213. H. Surmann et al., \What kind of hardware is necessary for a fuzzy rule based system?", In: Proceedings of the FUZZ-IEEE'94 International Conference, Orlando, FL, July 1994, Vol. 1, pp. 274{278. M. Takahashi, E. Sanchez, R. Bartolin, J. P. Aurrand-Lions, E. Akaiwa, T. Yamakawa, 48

44] 45] 46] 47] 48] 49] 50] 51] 52] 53] 54]

and J. R. Monties, \Biomedical applications of fuzzy logic controllers", In: Intl. Conference on Fuzzy Logic and Neural Networks, Iizuka, Fukuoka, Japan, 1990, pp. 553{ 556. M. Togai and S. Chiu, \A fuzzy accelerator and a programming environment for realtime fuzzy control", In: Second IFSA Congress, Tokyo, Japan, 1987, pp. 147{151. M. Togai and H. Watanabe, \Expert systems on a chip: an engine for real-time approximate reasoning", IEEE Experts Systems Magazine, 1986, No. 1, pp. 55{62. M. J. Tretter, \Interval analysis isn`t fuzzy is it?", Abstracts for an International Conference on Numerical Analysis with Automatic Result Veri cation: Mathematics, Application and Software, February 25 { March 1, 1993, Lafayette, LA, 1993, p. 104. H. M. Wadsworth, Jr. (editor), Handbook of statistical methods for engineers and scientists, McGraw-Hill Publishing Co., N.Y., 1990. H. Watanabe and W. Detlo , \Recon gurable fuzzy logic processor: a full custom digital VLSI", In: Intl. Workshop on Fuzzy Systems Applications, Iizuka, Japan, 1988, pp. 49{50. T. Yamakawa, \Fuzzy microprocessors { rule chip and defuzzi er chip", In: Intl. Workshop on Fuzzy Systems Applications, Iizuka, Japan, 1988, pp. 51{52. T. Yamakawa, \Intrinsic fuzzy electronic circuits for sixth generation computer", In: M. M. Gupta and T. Yamakawa (eds.), Fuzzy Computing, Elsevier, 1988, pp. 157{181. H. Q. Yang, H. Yao, and J. D. Jones, \Calculating functions of fuzzy numbers", Fuzzy Sets and Systems, 1993, Vol. 55, pp. 273{283. Y. Yoshikawa, T. Deguchi, and T. Yamakawa, \Exclusive fuzzy hardware systems for the appraisal of orthodentic results", In: Intl. Conference on Fuzzy Logic and Neural Networks, Iizuka, Fukuoka, Japan, 1990, pp. 939{942. L. A. Zadeh, \Fuzzy sets", Information and control, 1965, Vol. 8, pp. 338{353. L. A. Zadeh, Outline of a new approach to the analysis of complex systems and decision processes, IEEE Transactions on Systems, Man and Cybernetics, 1973, Vol. 3, pp. 28{44.

49
The author has requested enhancement of the downloaded file. All in-text references underlined in blue are linked to publications on ResearchGate.

Invariance, Maintenance and other declarative objectives of triggers { a formal characterization of active databases
Department of CSE Department of CSE University of Texas at Arlington Arizona State University Arlington, TX 76019, USA Tempe, AZ 85287, USA nakamura@cse.uta.edu chitta@asu.edu

Mutsumi Nakamura

Chitta Baral

1 Introduction and Motivation

In this paper we take steps towards a systematic design of active features in an active database. We propose having declarative speci cations that specify the objective of an active database and formulate the correctness of triggers with respect to such speci cations. In the process we distinguish between the notions of `invariance' and `maintenance' and propose four di erent classes of speci cation constraints. We also propose three di erent types of triggers with distinct purposes and show through the analysis of an example from the literature, the correspondence between these trigger types and the speci cation classes. Finally, we brie y introduce the notion of k-maintenance that is important from the perspective of a reactive (active database) system.

Abstract

Many commercial database systems (such as Oracle, Sybase, IBM's DB2-V2, etc.) and the database standard SQL3 incorporate active features { namely constraints (also referred to as integrity constraints) and triggers. Due to these active features explicit update requests to the database may have several consequences from the request being refused (as it may violate `integrity constraints'), to the request being ful lled with slight changes (as modi ed through `before triggers'), to additional changes triggered by cascade deletes and inserts used in the processing of some constraints and/or ring of `after triggers'. Although originally, integrity constraints were thought of as declarative constraints about database states and de ned which database states were valid and which were not, with the presence of cascade operations in the SQL3 constraints and the use of after triggers to maintain the integrity of the data, there is currently little tradition (except in CF97] and few other cases) of using or following standard software engineering practices of separating speci cation from implementation when designing and developing active databases. This means that 1

often active database developers do not even specify what the purpose of the active features of their database are. Thus there is no way to verify the correctness of the active features. We believe this is one of the reasons why many companies balk at using the active features of a database. Our goal in this paper is to take steps towards developing a systematic approach to the design of active databases. In the process we will develop several language constructs that can be used in specifying the purpose of an active database; formulate the correctness of the procedural triggers with respect to declarative speci cations; and develop guidelines that match the procedural aspects with the declarative aspects. One major hindrance in this pursuit has been the multitude of syntax and semantics (and their complexity) associated with the various di erent implementation of active rules WC96, Pat98] and the complexity of their semantics. In this paper we will follow the SQL3 standard (and the DB2-V2 implementation) to some extent and make certain simpli cations. The basic goal of the active features of a database is to constrain the evolution of the database. Based on analyzing a large class of active database examples, we have identi ed four kind of constraints: state invariance constraints; state maintenance constraints (or quiescent state constraints); trajectory invariance constraints; and trajectory maintenance constraints. In the above constraints there are two dimensions: (i) state vs trajectory (ii) invariance vs maintenance. Intuitively, in state constraints we are concerned about the integrity about particular states, while the trajectory constraints focus on the trajectory of evolution of the database. On the other hand, invariance constraints worry about all states of the database, while the maintenance constraints focus only on the quiescent states. De nition 1 (State Constraints) ADA93] A state constraint s on a database scheme R, is a function that associates with each database r of R a boolean value s (r). A database r of R is said to satisfy s if s (r) is true and is said to violate s if s (r) is false. In the former case, it is also said that s holds in r. A database r is said to satisfy a set of state constraints if it satis es each element of the set. 2 De nition 2 (Trajectory Constraints) A trajectory constraint t on a database scheme R, is a function that associates with each database sequence of R a boolean value t ( ). A database sequence of R is said to satisfy t if t ( ) is true and is said to violate t if t ( ) is false. In the former case, it is also said that t holds in . A database sequence is said to satisfy a set of trajectory constraints if it satis es each element of the set. 2 Often static integrity constraints are expressed through sentences in propositional logic or rst-order predicate calculus while we need temporal operators to express trajectory constraints. We further discuss this in Section 3. 2

1.1 The declarative notions

1.2 The procedural features of an active database

In SQL3 (and DB2-V2) the active features are: Constraints; Before triggers; and After triggers. The constraints in DB2-V2 are of the kinds: NOT NULL constraints, column defaults, unique indexes, check constraints, primary key constraints, and foreign key constraints. Among these, the NOT NULL constraints, unique indexes, check constraints, primary key constraints and some of the foreign key constraints (with NO ACTION or RESTRICT in the action part) refuse updates that violate the constraints. These correspond to the state invariance constraints mentioned in the previous section. On the other hand column default constraints and the foreign key constraints with CASCADE or SET NULL in the action part accept the updates but make additional changes. The former correspond to the state invariance constraints, while the later correspond to the state maintenance constraints. The before triggers act on the update request directly (instead of the updated database) and modify it if necessary while the after triggers are triggered by the update request and can either refuse the update (through a rollback) or force additional changes. Here, the former can implement state and trajectory invariance constraints, while the later can implement any of the four types of constraints. From the above analysis, it seems that certain speci cations such as a state maintenance constraint can be implemented in multiple ways, through a DB2V2 constraint or through after triggers. But the trigger processing architecture treats DB2-V2 constraints very di erently from after triggers. Thus it becomes very di cult to formulate and verify the correctness of the DB2-V2 (or SQL3) active features with respect to speci cations mentioned in Section 1.1. We propose a di erent class of active features that are close to the SQL3 features, but that are distinct in terms of their goals. Our class consists of three kind of procedural features (triggers): refusal triggers, wrapper triggers, and maintenance triggers. Intuitively, the refusal triggers when triggered refuse the update that caused the triggering. Thus refusal triggers can express not only after triggers with refuse actions, but also NOT NULL constraints, unique indexes, check constraints, primary key constraints, and foreign key constraints with NO ACTION or RESTRICT in the action part. The wrapper triggers, wrap the update request by additional changes and thus can express both before triggers and column default constraints. The maintenance triggers1 trigger additional updates and thus can express both after triggers with similar purpose, and foreign key constraints with CASCADE or SET NULL in the action part.

1 In Section 4 we will further divide maintenance triggers to two classes: short-term and long-term. This becomes necessary when we need to worry about reactive response to update requests.

3

Our division of the triggers into the above three classes makes them distinct in terms of what they set out to achieve. This is di erent from the active features in DB2-V2 and SQL3 where there is overlapping of goals making it di cult in designing active databases and formulating their correctness.

2 Actions, Events and Triggers

In this section we describe the necessary mechanism for reasoning about actions and events which we will then use to formulate correctness of triggers with respect to declarative speci cations. Intuitively, an action when executed in a world changes the state of the world. In databases, an action can take several meanings; from the basic insert, delete and update actions to SQL update statements. In this paper by an action we will usually refer to an uninterruptable transaction. To specify the e ects of an action on a database we borrow constructs from the speci cation language A GL93] and our earlier work in BL96, BLT97]. In the following by a uent we will mean a database fact, and by a uent literal we will mean either a database fact or its negation. E ects of actions are speci ed through e ect axioms of the following form:

2.1 Actions and e ects

state. A word of caution is needed regarding the safeness Ull88] of variables in the causal law . The preconditions p1 (X1 ); : : : ; pn (Xn ) will be evaluated as regular queries in the database and a(X ) is an action that could be invoked by a user or an active rule. Thus, variables appearing in Y or in any negated uent in the preconditions must also appear in one of the positive uents in the precondition. If there are variables in X that do not appear in any of the positive uents in the preconditions these arguments must be ground at the time of the invocation of the action, otherwise there will be an error in the execution. Moreover, the variables are schema variables, and intuitively an e ect axiom with variables represents the set of ground e ect axioms where the variables are replaced by ground terms in the domain. Two e ect axioms with preconditions p1 ; : : : ; pn and q1 ; : : : ; qm respectively are said to be contradictory if they describe the e ect of the same action a on complementary f s, and fp1; : : : ; pn g \ fq1 ; : : : ; qm g = ; A state is a set of uent names. Given a uent name f and a state , we say that f holds in if f 2 ; :f holds in if f 62 . A transition function is a 4

a(X ) causes f (Y ) if p1 (X1 ); : : : ; pn (Xn ) (2.1) where a(X ) is an action and f (Y ); p1 (X1 ); : : : ; pn (Xn ) are uent literals (n 0). p1 (X1 ); : : : ; pn (Xn ) are called preconditions. The intuitive meaning of (2.1) is that in any state of the active database execution in which p1 (X1 ); : : : ; pn(Xn ) are true, the execution of the action a(X ) causes f (Y ) to be true in the resulting

mapping of the set of pairs (a; ), where a is an action name and is a state, into the set of states. A collection of e ect axioms (EA) for various actions in our world { with no contradictory e ect axioms in them, de ne a transition function from the set of actions and the set of database states to the set of database states. For every action a and every state ,
0 ) n 00 ; (a; ) = ( where 0 ( 00 ) is the set of uent names f such that EA includes an e ect proposition describing the e ect of action a on f (respectively, :f ) whose preconditions hold in . We now show how the e ect of simple actions such as insert, delete and update can be speci ed using e ect axioms.

insert(R(t)) causes R(t) delete(R(t)) causes :R(t) update(R(t); R(t0)) causes R(t0 ) if R(t) update(R(t); R(t0)) causes :R(t) if R(t)

(2.2) (2.3) (2.4) (2.5)

We now show how we can specify the e ect of actions corresponding to more complex transactions:

Example 1 Consider another transaction a2 from Cha96]:

UPDATE parts SET qonorder = qonhand, qonhand = qonorder WHERE partno = `P207'; Its e ects can be described in our language through the following e ect propositions: a2 causes parts(P 207; Descr; qonhand; qonorder) if parts(P 207; Descr; qonorder; qonhand) a2 causes :parts(P 207; Descr; qonhand; qonorder) if parts(P 207; Descr; qonhand; qonorder) 2

To reason about the e ect of a sequence of actions on a database , we need to extend the function , to allow sequence of actions as its rst parameter. This extension is de ned as follows: ( ]; ) = , and ( ja]; ) = (a; ( ; )). 5

2.2 Events and ECA rules

Triggers (or active rules) in active databases are normally WC96] represented as a triple consisting of events, conditions and actions. In most active database architectures, the sequence of actions that have been executed since the last evaluation point are evaluated to decide on what events have taken place. These events together with the valuation of the condition with respect to the current database state determine whether a particular ECA active rule should be triggered or not. Di erent active databases allow di erent event sets and have di erent ways of evaluating the events. In the simplest case, the events can be the set of inserts and deletes explicitly performed by the last action. On the other hand, in Starburst Wid96] events are de ned in terms of the net e ects of a sequence of transitions. To allow the exibility of de ning a set of events and computing them from a sequence of actions we use the notion of event de nitions from BLT97]. An event de nition proposition is an expression of the form:

where e(X ); e1 (Y1 ); : : : ; em (Ym ) are event literals2 and q1 (Z1 ); : : : ; qn (Zn ) are uent literals. This proposition says that the execution of the action a(W ) ordered in a state in which each of the uent literals qi (Zi ) is true and each of the event literals ej (Yj ) is true generates the event literal e(X ) if the event literal is positive, or removes the event from the set of current events if the event literal e(X ) is negative. If the execution is ordered in a state in which some of the qi (Zi ) or ej (Yj ) does not hold then (2.6) has no e ect. Each of the (schema) variables appearing in X or in a negated event or uent literals, has to appear either in W or in a positive event/ uent literal. The default assumption is that the event persists from one state to another, with two possible exceptions: either the event is consumed by an active rule (see below), or the event is removed by an action based on the speci cation of an event de nition. For example, if we have an expression :e1 after a1 , the execution of the action a1 will cause the event e1 not to be present in the resulting state. Hence, the meaning of \an event is true in a given state" is: the event was induced (i.e. generated) in some state prior to the given one and the event persisted, or the event was induced by an execution of an action in the previous state.

e(X ) after a(W ) if e1(Y1 ); : : : ; em (Ym ); q1 (Z1 ); : : : ; qn (Zn )

(2.6)

Example 2 (Events in Starburst) In Starburst net e ects (or events) are
expressed in words through the following conditions: If a tuple is inserted and then updated, it is considered an insertion of the updated tuple.
2

Like uent literals, an event literal is an event or its negation.

6

If a tuple is updated and then deleted, it is considered as a deletion of the original tuple. If a tuple is updated more than once, it is considered as an update from the original value to the newest value. If a tuple is inserted and then deleted, it is not considered in the net e ect at all. These four premises can be encoded through event de nitions as follows:

e del(G) :e upd(G; F ) e upd(G; I ) :e upd(G; H ) :e add(G)

:e add(G)

e add(H )

after upd(G; H ) if e add(G) after upd(G; H ) if e add(G) after del(F ) if e upd(G; F ) after del(F ) if e upd(G; F ) after upd(H; I ) if e upd(G; H ) after upd(H; I ) if e upd(G; H ) after del(G) if e add(G)

(2.7)

In the above example, at the rst glance it appears that our notation is more verbose than the original rules. For each of the rst three rules we needed two event de nition propositions. This is because we assume that events have inertia. This assumption actually cuts down in writing individual event de nition propositions encoding the persistence of each event due to actions that do not a ect it. For example we do not need to explicitly write:

e add(H ) after del(G) if e add(H ); H 6= G
We characterize events using the function whose input is a set of events, a state, and an action and the output is a set of events. More formally, let E + (E; ; a) = f e : there is an event de nition proposition of the form e after a if e1 ; : : : em; q1 ; : : : ; qn where e1 ; : : : ; em hold in E and q1 ; : : : ; qn hold in g; and let E ? (E; ; a) = f e : there is an event de nition proposition of the form :e after a if e1 ; : : : em ; q1 ; : : : ; qn where e1 ; : : : ; em hold in E and q1 ; : : : ; qn hold in g. (E; ; a) is then de ned as follows: (E; ; a) = (E E + (E; ; a)) n E ? (E; ; a) To be able to compute events with respect to a sequence of actions we extend as follows: (E; ; ]) = E , and (E; ; ja]) = ( (E; ; ); ( ; ); a). 7

As mentioned in Section 1.2, we have three kinds of triggers: wrapper triggers, refusal triggers and maintenance triggers. We represent each of them through ECA rules but distinguish them by the action part. In wrapper triggers the action part is a wrapping function ! which maps an action sequence and a database state to an action sequence. Intuitively, for a single action a, by !(a; ) = a0 we mean that a0 is the action obtained by wrapping a with ! in state . In refusal triggers the action part is the special action REFUSE and in maintenance triggers the action part could be an arbitrary sequence of actions. Thus an ECA rule is a triple he; c; i, where e is an event in our language, c is a temporal formula about the database history, and is either a wrapping function, the special action REFUSE, or a sequence of actions. Often we will represent a single action as the ECA rule h;; True; ai. In this subsection our goal is to give a formal characterization of the evolution of a database due to a sequence of actions in presence of a set of ECA rules. In our characterization we strive to keep a balance between not making the semantics too complicated and at not losing expressibility. We now give an intuitive description of our characterization. Intuitively, after the action sequence (with necessary modi cations due to wrapper triggers) is executed the set of events corresponding to that sequence of actions are evaluated. Then the ECA rules that match with the events are identi ed. We assume (as in many implemented systems Cha96]) that there is a total ordering among the ECA rules with the condition that refusal triggers have higher priority than maintenance triggers. Using this total ordering a priority list of the identi ed ECA rules is created. Then the condition parts of the ECA rules in the priority list are evaluated in the order of their priority and if the condition evaluates to be true, the action part is executed. Since the action part may trigger additional ECA rules, an important concern is how these ECA rules are assimilated into the already existing prioritized list of ECA rules. Two straightforward approaches are to view the list as a stack where newly triggered ECA rules are pushed onto the top of the stack, or to view the list as a queue where newly triggered ECA rules are put at the end of the queue. In both cases, among the newly added rules, the wrapper triggers have the highest priority, the refusal triggers have the second highest priority and the maintenance triggers have the lowest priority. So after the execution of the action part of the currently considered ECA rule, the newly triggered ECA rules are put into the priority list and the evaluation of the ECA rules in the modi ed list are again done based on their priority. This loop of executing the action part of the currently chosen ECA rule, updating the list of ECA rules, and evaluating the list to nd the next ECA rule, continues until the list is empty. During the execution when faced with a trigger whose action part is REFUSE, the database is rolled back. We now formally de ne the function ( ; ; List), where is a database state, is a sequence of actions and List is a prioritized list of ECA rules that are 8

2.3 Characterizing database evolution due to ECA rules

yet to be processed, and the output of the function is a sequence of database states. Once we de ne this function, the evolution of a database state due to an action sequence , can then be expressed by ( ; ; ]). (For lack of space we only consider the simple case where there are no triggers with REFUSE in their action part.)

De nition 3 Evolution due to actions and triggers]
1. ( ; ; List) = if is a state, is an empty sequence, and List = ]. 2. ( ; ; List) is an empty list if is unde ned. 3. ( ; ; List) = if (a) 0 = (!( ); ), where ! is the composition of the wrapping functions of the before triggers triggered by the events in (;; ; ). (If there are no before triggers triggered by the events in (;; ; ) then ! is the identity function; i.e., 8 :!( ) = ). (b) List1 is the list obtained by adding the new ECA rules triggered by the events in (;; ; !( )) to List and adjusting the priorities, (c) eca is the ECA rule with the highest priority in the priority list List1, (d) 0 is the action part in eca, (e) List2 = List1 n fecag, and (f) ( 0 ; 0 ; List2) = . 2 Because of the second condition above, when (!( ); ) is unde ned we obtain as an empty list, and then ( ; ; List) is a sequence of length one with as the only element. Rollbacks can be accounted for by having an additional parameter in which stores the initial state, where the database should be rolled back to when a trigger with REFUSE in its action part is triggered.

Our next step is to formally de ne when a set of ECA rules are correct with respect to invariant and maintenance constraints. For state maintenance constraints, intuitively, the correctness means that the ECA rules force the database to evolve in such a way that the nal state that is reached is a state where all the state maintenance constraints are satis ed. For state invariant constraints, intuitively, the correctness means that the ECA rules force the database to evolve in such a way that the state invariance constraints are satis ed in all states of the trajectory. Since our ultimate goal is to be able to use this de nition to verify the correctness, we add another dimension to the de nition: the class of exogenous actions that we consider; where exogenous actions are the actions that outside users are 9

2.4 Correctness of ECA rules

allowed to execute on the database. It should be noted that the action part of the ECA rules may have actions other than the exogenous actions. We now formally de ne correctness with respect to state invariant and maintenance constraints. state maintenance constraints, A be a set of exogenous actions, and T be a set of ECA rules. We say T is correct with respect to ?si ?sm and A, if for all database states where the constraints in ?si and ?sm hold, and for all action sequences consisting of exogenous actions from A, all the states in the sequence ( ; ; ]) satisfy the constraints in ?si ; and the last state of the evolution given by ( ; ; ]) satis es the constraints in ?sm . 2 To expand the De nition 4 to de ne correctness with respect to trajectory constraints we need to consider a larger evolution window where the database evolves through several exogenous requests each consisting of a sequence of (exogenous) actions. For this we use the notation to denote the last state of the evolution given by ( ; ; ]). We use the notation ( 1 ; 2 ) to denote the last state of the evolution given by ( 1 ; 2 ; ]), and similarly de ne ( 1 ;:::; i ) . state maintenance constraints, ?ti be a set of trajectory invariant constraints, ?tm be a set of trajectory maintenance constraints, A be a set of exogenous actions, and T be a set of ECA rules. We say T is correct with respect to ?si ?sm ?ti ?tm and A, if for all database states where the constraints in ?si and ?sm hold, and for all action sequences 1 ; : : : ; n consisting of exogenous actions from A, all the states in the sequences ( ; 1 ; ]), ( 1 ; 2 ; ]), . . . , ( ( 1 ;:::; n?1 ) ; n ; ]) satisfy the constraints in ?si ; all the states 1 ; : : : ; ( 1 ;:::; n ) satisfy the constraints in ?sm ; the trajectory obtained by concatenating ( ; 1 ; ]) with ( 1 ; 2 ; ]), . . . , ( ( 1 ;:::; n?1 ) ; n ; ]) satisfy the constraints in ?ti ; and the trajectory ; 1 ; : : : ; ( 1 ;:::; n ) satis es the constraints in ?tm . 2 Example 3 Consider the relational Schema: Employee(Emp#; Name; Salary; Dept#) Dept(Dept#; Mgr#) We have two state maintenance constraints: (i) If (e; n; s; d) is a tuple in Employee then there must be a tuple (d0 ; m0 ) in 10

De nition 4 Let ?si be a set of state invariant constraints, ?sm be a set of

De nition 5 Let ?si be a set of state invariant constraints, ?sm be a set of

The set of maintenance triggers that can be shown to be correct with respect to the above maintenance constraints and exogenous actions consists of the following trigger. For any Delete (e; n; s; d) from Employee, if (d; e) is a tuple in Dept, delete that tuple from Dept and delete all tuples of the form (e0 ; n0 ; s0 ; d0 ) from Employee, where d = d0 . 2 We can now make the formal claim that the above maintenance triggers are correct with respect to the above mentioned state maintenance constraints and exogenous actions.

Dept such that d = d0 . (ii) If (d; m) is a tuple in Dept, then there must be a tuple (e0 ; n0 ; s0 ; d0 ) in Employee such that d = d0 and m = e0 The only allowable exogenous action is del(Employee(E; N; S; D)).

3 Elaborating on our abstractions

In Section 1.1 we de ned state constraints and trajectory constraints as boolean functions on database states and sequences of database states respectively. Our next concern is how to represent such functions parsimoniously. One approach is to use logical constructs. In this section we introduce several language constructs that we proposed to use in specifying state and trajectory constraints and show their use through examples. We start with a description of the mail order business active database from Cha96]. To save space and to make it readable without knowing the syntax of triggers in DB2-V2, we describe the triggers of this active database in words, and not in the syntax of DB2-V2. The ve tables that are mentioned in the database in Cha96] and their attributes are: Cust(C#, Cname, Caddr, Baldue, Creditlmt) Suppl(S#, Sname, Saddr, Amtowed) Inv(It#, Iname, S#, Qonhand, Unitsalpr, Qonorder, Unitorderpr, Orderthreshold, Minorder) Purch(Orddate, Ordtime, S#, It#, Qordered, Dtrecvd, Qrcvd, Unitpr) Sales(Sldate, Sltime, C#, It#, Qsold, Unitpr, Totalsale) Due to lack of space we only consider two of the eight triggers given in Cha96], and identify the state and trajectory constraints corresponding to these triggers. (PT1: a wrapper trigger) When inserting into the Purch table modify the tuples (to be inserted) 11

3.1 The tables

3.2 A subset of the triggers

so that for any It#, the values for S# and Unitpr are the values for S# and Unitorderpr for that It# in the Inv table. (Note that because of the constraints associated with the Purch table that allow Orddate and Ordtime to get the current date and time by default, It# and Qordered are the only pieces of information required to do insertions into the Purch table.) (PT2 { a maintenance trigger) After inserting an order for an It# to Purch, update the Inv table by increasing the Qonorder (in the tuple with that It#) by Qordered. We rst list the constraints in a high level language that we developed and then explain the meaning of the constructs in this language. (C1) ForAll It#: Inv:S # = Purch:S # is invariant (C2) ForAll It#: Inv:Unitorderpr = Purch:Unitpr is invariant (C3) newtuple Purch requires Orddate = Currentdate and Ordtime = Currenttime (C4) ForAll It#: Purch:Sum(Qordered) ? Purch:Sum(Qrcvd) = Inv:Qonorder is maintained Among the above constraints, the rst two are state invariant constraints, the second is a trajectory invariant constraint, and the third is a state maintenance constraint. These constraints can be speci ed in rst-order logic with temporal and aggregate constructs. We specify them using such constructs below with the assumption that all free variables are universally quanti ed and all the existentially quanti ed variables are denoted by underscores \ ". (C1') (Inv(It#; ; S1 ; ; ; ; ; ; ) ^ Purch( ; ; S2 ; It#; ; ; ; )) ) (S1 = S2 ) (C2') (Inv(It#; ; ; ; ; ; UOP1 ; ; ) ^ Purch( ; ; ; It#; ; ; ; UP2 )) ) (UOP1 = UP2 ) (C3') (:Purch(OD; OT; S #; It#; ; ; ; )^ nexttime (Purch(OD; OT; S #; It#; ; ; ; ))) ) nexttime (OD = date ^ OT = time) (C4.1') R1 (It#; Sum Qord) = It# GSum Qordered(Purch) (C4.2') R2 (It#; Sum Qrcvd) = It# GSum Qrcvd(Purch) (C4') (quiescent ^ R1 (It#; Sum Qord) ^ R2 (It#; Sum Qrcvd) ^ Inv(It#; ; ; ; ; Qonorder; ; ; )) ) (Sum Qord?Sum Qrcvd = Qonorder) 12

3.2.1 The corresponding constraints

The rst order formulas (C1') and (C2') are low level representations of the state invariant constraints (C1) and (C2) respectively. The temporal formula (C3') is a low level representation of the trajectory invariant constraints (C3) and the temporal operator nexttime in (C3') has the usual FTL (future temporal logic) CT95] meaning. Next we have the formulas (C4.1'), (C4.2') containing grouping aggregation expressions using the notation3 from the text book SKS96], and (C4') which are a low level representation of the state maintenance constraint (C4). Note the di erence between (C4') and (C1'-C2'). Since the former is a maintenance constraint, we use the proposition quiescent in the left hand side of the implication, meaning that the implication only holds in quiescent states. On the other hand the implications in (C1'-C2') must hold in all states.

Proposition 1 Let DB be the schema declaration in Section 3.1, and the only allowable exogenous action is `Insert into Purch with Dtrecvd and Qrcvd as null, and Qordered as a positive value'. Then in the context of DB the set of triggers fPT1,PT2g, is correct w.r.t. the set of constraints fC1, C2, C3, C4g, and the above mentioned exogenous action. 2

4 Interrupting exogenous updates
So far we have (implicitly) assumed that if new exogenous update requests come in when the active database system is in the midst of processing ECA rules due to a previous exogenous update, the new requests are kept in hold until the processing (due to the previous update) comes to an end. Such an assumption is perhaps acceptable when the exogenous updates are not that frequent and/or trigger processing is not that time consuming, and there is no guaranteed quality of service requirement. With the popularity of e-commerce where updates to the database would often be due to e-transactions over the web, companies may require a guaranteed quality of service requirement. In particular, they may require immediate response to requests. In such a case, it may be a good idea to partition maintenance triggers to two kinds short term and long term, with the idea that in order to give reactive response to new update requests, processing of long term maintenance triggers may be postponed in favor of processing the new update request.
3 In this notation the general form is: G1 ;G2 ;:::;Gn GF1 A1 ;F2 A2 ;:::;Fm Am (E ), where E is any relational-algebra expression, G1 ; : : : ; Gn constitute a list of attributes on which to group, each Fi is an aggregate function, and each Ai is an attribute name. The meaning of the operation is de ned as follows. The tuples in the result of expression E are partitioned into groups such that: (i) All tuples in a group have the same values for G1 ; : : : ; Gn . (ii) Tuples in di erent groups have di erent values for G1 ; : : : ; Gn . The groups now can be identi ed by the values of the attributes G1 ; : : : ; Gn of the relation, and for each group (g1 ; : : : ; gn ), the result has a tuple (g1 ; : : : ; gn ; a1 ; : : : ; am ) where, for each i, ai is the result of applying the aggregate function Fi on the multi-set of values for the attribute Ai in the group.

13

The formulation of correctness in such a case becomes tricky, and we have made a small start in that direction. In this we only consider condition-action triggers, and consider all triggers to be long term. Before we get to our de nition of correctness in such cases, we have the following notation. Let T be a set of condition-action triggers, and be a database state. By T ( ) we denote the action of the trigger which has the highest priority among the triggers whose conditions are satis ed in . We also have the following additional notations: 0 0 T ( ) = T ( ) and T = . k+1 ( ) = T ( k+1 ) and k+1 = ( K ( ); k ).

De nition 6 (k-maintenance) Let T be a set of condition-action triggers, ?

T

T

T

T

T

be a set of long term maintenance constraints, S be a set of states, and A be a set of allowable exogenous actions. By Closure(S; T; A) we denote the smallest set of states that is a superset of S and that satis es the properties that if 2 S , then for an exogenous action a from A, (a; ) 2 S , and ( T ( ); )) 2 S . We say T k-maintains the maintenance constraints ? from S and A, if for each 0;:::; T k satis es ?. state in S , the sequence T 2

5 Conclusion and future work

Intuitively, the notion of k-maintenance means that the active database system will get back to consistency (with respect to ?) if it is given a window of opportunity of processing k triggers without any outside interference in terms of new update requests. An important aspect of such a notion of k-maintainability is that in reactive (active database) systems, if we know that our system is k-maintainable, and each transition takes say t time units, then we can implement a transaction mechanism that will regulate the number of exogenous actions allowed per unit time to be k 1 t . On the other hand, given a requirement that we must allow m requests (exogenous actions) per unit time, we can work backwards to determine the value of k, and then nd a set of triggers to make the system k-maintainable.

In this paper we have taken several steps towards the systematic design of active features in an active database. The main steps that we have taken are identifying a few constructs for speci cation, classifying triggers into distinct classes based on their purpose, linking the trigger classes with the speci cation classes, formulating correctness of triggers with respect to a given speci cation, elaborating our formulation through examples and brie y introducing the notion of k-maintainability. Due to space limitations we were not able to detail our formulation (especially, the prioritization used in de ning and the di erentiation between row and statement triggers) and show the design methodology with respect to a large 14

example. In the full version we will show how our formulation in this paper can be used in systematically developing the triggers for the complete example in Cha96], starting from a speci cation which is not given in Cha96]. Our main future work will be to develop composition methods and theorems so that given sets of triggers T1 and T2 that are correct with respect to speci cations S1 and S2 respectively, we can construct triggers that are correct with respect to S1 S2 . We also plan to identify additional speci cation constructs with matching trigger sub-classes, and further elaborate on our notion of k-maintainability.

References
ADA93] P. Atzeni and V. De Antonellis. Relational database theory. The Benjamin/Cummings publishing company, 1993. BL96] C. Baral and J. Lobo. Formal characterization of active databases. In Proc. of International Workshop on Logic in Databases { LID'96 (LNCS 1154), pages 175{195, 1996. BLT97] C. Baral, J. Lobo, and G. Trajcevski. Formal characterization of active databases: Part II. In DOOD 97, 1997. CF97] S. Ceri and P. Fraternali. Designing database applications with objects and rules { the IDEA methodology. Addison-Wesley, 1997. Cha96] D. Chamberlin. Using the new DB2: IBM's Object-relational database system. Morgan Kaufmann, 1996. CT95] J. Chomicki and D. Toman. Implementing temporal integrity constraints using an active dbms. IEEE transactions on knowledge and data engineering, 1995. GL93] M. Gelfond and V. Lifschitz. Representing actions and change by logic programs. Journal of Logic Programming, 17(2,3,4):301{323, 1993. Pat98] N. Paton. Active rules in database systems. Springer-Verlag, 1998. SKS96] A. Silberschatz, H. Korth, and S. Sudershan. Database System Concepts. McGraw Hill, 3rd edition, 1996. Ull88] J. Ullman. Principles of Database and Knowledge-base Systems, volume I. Computer Science Press, 1988. WC96] J. Widom and S Ceri, editors. Active Database Systems - Triggers and Rules for advanced database processing. Morgan Kaufmann, 1996. Wid96] J. Widom. The Starbust rule system. In J. Widom and S Ceri, editors, Active Database Systems, pages 87{110. Morgan Kaufmann, 1996.

15

ON HARDWARE SUPPORT FOR INTERVAL COMPUTATIONS
AND FOR SOFT COMPUTING: THEOREMS
Hung T. Nguyen, Vladik Kreinovich, Member, IEEE, Vyacheslav Nesterov,
and Mutsumi Nakamura

Abstract. This paper provides a rationale for providing hardware supported functions of
more than two variables for processing incomplete knowledge and fuzzy knowledge. The
result is in contrast to Kolmogorov's theorem in numerical (non-fuzzy) case.

1. INTRODUCTION
In this paper, we show that for interval computations and for processing fuzzy data (i.e.,
for soft computing), it is desirable to have hardware supported operations with more than
two operands.
Before we formulate the problem and go into technical details, we would like to emphasize the importance of this problem by briey describing in Subsection 1.1 the practical
origin (and practical necessity) of interval computations and soft computing.

1.1. Estimating accuracy of the results of data processing:
crisp and fuzzy cases
Data processing: why? To make decisions, we must have some information about the

values of the physical quantities. For example, in order to decide whether to approve
the scheduled launch of a Space Shuttle, we must know the characteristics of the Shuttle
(to make sure that all its systems work), and weather conditions around the launch site
during the launch time. Some of these characteristics can be measured directly: e.g.,
characteristics of the Shuttle's electric systems can be measured by testers. Some of the
desired characteristics can be estimated by experts: e.g., some experts meteorologists can
provide us with reasonably good short-time weather predictions for a given area.
Hung T. Nguyen is with the Department of Mathematical Sciences, New Mexico
State University, Las Cruces, NM 88003, USA, email hunguyen@nmsu.edu
Vladik Kreinovich is with the Department of Computer Science Department, University of Texas at El Paso, El Paso, TX 79968, USA, email vladik@cs.utep.edu
Vyacheslav Nesterov is with the Institute of New Technologies, P. O. Box 52, St.
Petersburg 256, 195256 Russia, email nest@into.nit.spb.su
Mutsumi Nakamura is with the Department of Mathematics, University of Texas at
Austin, Austin, TX 78712, USA, email mutsumin@math.utexas.edu
1

In some cases, however, it is very dicult (or even impossible) to measure the characteristic y that we are interested in, and there are no experts who can predict the values of
these characteristics. For example, it is very dicult to directly measure the temperature
inside the jet chamber (because this temperature is extremely high); if we are planning a
mission to a new planet, it is simply impossible to directly measure the characteristics of
the new environment before the mission actually gets there, and often, no expert can help.
If we are interested in the value of such a characteristic y, and we cannot estimate y
directly (either by measurement, or by using experts), then a natural idea is to estimate y
indirectly, i.e.:
 to estimate some other (easier to estimate) quantities x1 ; :::; xn that are related to y,
and then
 to compute the estimate y~ for y based on the estimates x~1 ; ::; x~n for x1 ; :::; xn.
This process is called data processing, and this is what super-computers are doing most of
the time: from measured characteristics x~i of observed collisions in the accelerators, they
reconstruct the (directly unobservable) properties of the elementary particles; from the
results x~i of geophysical measurements, computers predict the amount y of oil (or other
mineral) in a given area, etc.
In this paper, we will assume that we already know what characteristics xi to measure,
and how to reconstruct y from xi . In other words, we will assume that we know an algorithm
f (x1; :::; xn) that transforms the values of xi into an estimate for y. This algorithm is
not necessarily simple: e.g., in geophysics, it may involve solving a complicated non-linear
integral equation (\inverse problem"); in elementary particle physics, it may involve solving
a system of non-linear operator quantum equations, etc.

The result of data processing is never absolutely accurate. The assumption that

we know the algorithm f means that if we know the exact values of the variables x1 ; :::; xn,
we can then apply the algorithm f and compute the exact value of y. In reality, however, we only know some estimates x~i for xi that are obtained either by measurements
or by an expert estimation. Measurements are never 100% precise; expert estimates are
not absolutely precise either. As a result, the available values x~i dier from the actual
(unknown) values xi ; therefore, the estimate y~ = f (~x1; :::; x~n) that we obtain by processing
the available data may dier from the desired value y = f (x1; :::; xn).

In real-life applications, we must know the accuracy of the result of data processing. For practical purposes, it is important to know how dierent the result y~ of data
processing can be from the actual value y.

2

For example, if we want to decide whether a particular well is worth drilling, and the
estimate for the amount of oil is y~ = 100 mln. tons, then before we start drilling, we
would like to know whether this is, say, 100  1, in which case, we should probably start
drilling, or it is 100  100 (maybe 100, maybe 0, maybe 200), in which case we would rather
undertake further (and more accurate) measurements.
In this paper, we consider the problem of nding this accuracy.

Simplest case: measurements only. Before we start analyzing the general case, where

both measurement results and expert estimates are present, let us consider the simplest
case, where there is no expert knowledge, and all the data come from the measurements.
In traditional measurement theory (see, e.g., [8,47,35]), it is usually assumed that we know
the probabilities of dierent values of a measurement error. These values can be obtained
if we calibrate the measuring instrument, i.e.:
 we use the calibrated instrument in conjunction with a much more accurate one (called
a standard) in several measurements;
 for each measurement, we compute a dierence e(k) = x~(k) ? x(k) between the results
of these two instruments, and use this dierence as an estimate of the error of the
measurement performed by the calibrated instrument;
 reconstruct the error probability distribution from the recorded sample errors e(1) , ...,
e(N ) .
For the situations in which we know the probabilities of dierent errors, there exist numerous methods that compute statistical characteristics of the resulting error.
In many real-life situations, however, the values of the probabilities are not known:
 in advanced measurements (in radio-astronomy, in elementary particle physics, etc),
we are using measuring instruments that have the highest accuracy possible, so, there
is simply no \more accurate" measuring instrument that we can for calibrating;
 in manufacturing applications, we can potentially calibrate all the sensors that we
use, but this calibration would cost much more than the sensors themselves, so it is
usually not done.
In these situations, the manufacturer of the measuring instrument provides us with the
guaranteed accuracy , i.e., with a guaranteed upper bound of the error x = x~ ? x (e.g.,
\error cannot exceed 0.1"). If our measurement results is x~, then the possible values of
x = x~ ? x form an interval [~x ? ; x~ + ]. Since we are dealing with intervals, the entire
area is called interval computations (see, e.g., [29,11,10,18,14]).
3

The set of possible values of an error is not necessarily an interval. For example,
suppose that we are measuring the current inside the computer, and we know that the
error cannot exceed a certain value . If we know nothing else about the error, then we
may conclude that the error belongs to the interval [?; ]. However, we may know that
the error is caused by the inuence of a nearby magnetic memory element, which can be
in two possible states (corresponding to \0" and \1"). In this case, the error is either
positive, or negative (depending on the state), but never 0; actually, the error can never
be smaller than some value . In this case, the set X of possible values of the error is
not an interval, but a union of two intervals: X = [?; ?] [ [; ]. There can be more
complicated cases, in which the error can be described by more complicated (crisp) sets X
of possible values.
In this case, our problem takes the following form:
We know:
 an algorithm f that transform n real numbers x1; :::; xn into a real number y =
f (x1; :::; xn);
 sets X1  R, ..., Xn  R that contain the actual values of xi ;
We must compute: The set Y of possible values of y:

Y = ff (x1; :::; xn) j x1 2 X1; :::; xn 2 Xng

(1:1)

This set Y is usually denoted by f (X1; :::; Xn).
A measuring instrument can measure several dierent quantities x1; :::; xn at a time.
In this case, in addition to the information about the possible errors of each measurement,
the manufacturer can guarantee that certain combinations of errors are impossible: e.g.,
it can happen that x1 attains its largest possible value , and it can happen that x2
attains its largest possible value , but they can never attain these extreme values at the
same time, because of the restriction that x21 + x22  2 (this situation happens, e.g.,
if we measure geographical coordinates of a point). Such an information can be described
by a set X  Rn of all the tuples that the manufacturer believes can be possible values of
errors (x1; :::; xn). In this case, the problem takes the following form:

4

We know:
 an algorithm f that transform n real numbers x1; :::; xn into a real number y =
f (x1; :::; xn);
 a set X  Rn that contains the actual value of ~x = (x1; ::; xn);
We must compute: The set Y of possible values of y:

Y = ff (x1; :::; xn) j (x1; :::; xn) 2 X g

(1:2)

This set Y is usually denoted by f (X ).
The previous formulation is a particular case of this one if we take X = X1  :::  Xn.

General case: processing data that includes expert knowledge as well. In many

cases, in addition to measurements results, we have expert's knowledge about the variables
x1 ; :::; xn. For example, in order to make a decision on what doze of radiation to assign to
a patient, we must know not only the characteristics that are measurable (like blood count,
tumor size, etc), but the characteristics that can only be estimated by an expert (e.g., the
granularity of a tumor can be \small" or \medium"). We want to process this informal
information automatically, therefore, we must be able to represent it in the computer.
A word like \medium-size" does not describe one particular value; it can correspond to
several dierent values; some of them are more reasonably described as \medium-size",
some values can be in principle described as such, but only occasionally. To describe the
meaning of each word, we ascribe to every real number x a value (x) 2 [0; 1] that describe
to what extent it is reasonable to assume that x is, say, medium-size (1 means that it is
absolutely reasonable, 0 that it is not reasonable at all). The resulting function is called a
membership function, or a fuzzy set.
In some cases, the expert's informal statement describes not one variable, but several
of them. For example, if we say that a point with coordinates x1 ; x2 is close to 0, this
means that both x1 and x2 are close to 0. Such knowledge can be represented by a function
from R2 to [0,1]. This membership function is called a fuzzy subset of R2. If we have such
information about xi , and we want to estimate y, we get the following problem:
We know:
 a function f of n variables;
 a fuzzy set X  Rn that describes our knowledge about ~x = (x1 ; :::; xn).
We want: to describe the resulting knowledge about y in terms of a fuzzy set Y .
This problem was formulated, e.g., in [1,46,39], and it has appeared in many practical
cases, including:
5

 testing jet engines [22,20,21];
 seismic analysis [3,4];
 image processing [19,20,21],
etc.

The desired description of the set Y is known as extension principle. This principle was
proposed by Zadeh in his pioneer paper [53] (see also [54] and [5]), and it is based on the
following idea:
A real number y~ is a reasonable value of y if and only if
there exist values x~1; :::x~n for which
x~1 is a possible values of x1 , x~2 is a possible value of x2 , ..., and f (~x1; :::; x~n) = y~.
If we follow the traditional fuzzy set theory and interpret \and" as min, and \there
exists" as sup, then we arrive at the following formula:

Y (y) = sup (min(X (~x); f (~x; y));
~x2Rn

where f is a characteristic function of the graph of the function f (i.e., (~x; y) = 1 if
f (~x) = y, and 0 otherwise). Due to this formula, values ~x for which f (~x) 6= y, do not
inuence on Y (y). Therefore, this formula can be rewritten as follows:

Y (y) = sup X (~x):

(1:3)

~x:f (~x)=y

This formula is called the extension principle, and the resulting fuzzy set Y is denoted by
f (X ).
If instead of X , we have n separate fuzzy sets X1 ; :::; Xn that describe our knowledge
about x1 ; :::; xn, then similar arguments lead to a formula

Y (y) = sup min(X1 (x1); :::; X (xn)):
~x:f (~x)=y

n

(1:4)

The resulting fuzzy set Y is denoted by f (X1; :::; Xn).
Comments.
1. In particular, if we take elementary arithmetic operations (+; ; ?, etc) as f , we get
the denition of arithmetic operations with fuzzy operands X1; :::; Xn.

2. The statement that we have just formalized contains two logical terms: \and" and
\there exists". So, to formalize it, we must formalize what these two logical terms mean.
6

\There exists" can be viewed as an innite \or": namely, \there exist x~1 ; :::; x~n with
a certain property" means that this property is either true for, say, (0:0; :::; 0:0), or for
(1:1; 0:2; :::; 2:3), or for any of innitely many tuples of n real numbers. Therefore, to get
an interpretation of \there exists", we must choose an appropriate fuzzy interpretation
f_(a; b) of _ and apply the resulting _?operation f_ innitely many times (i.e., apply it
to N tuples and then take N ! 1).
In fuzzy logic, many dierent _?operations have been proposed (e.g., f_(a; b) =
a + b ? a  b); these operations are also called t?conorms. A usual (and natural) restriction
on a t?conorm f_ comes from the fact that for every two statement A and B , our degree
of belief in A _ B must be at least as big as the degree of belief in each of these statements
A and B . If we denote the degree of belief in A by t(A), then this condition turns into
f_(t(A); t(B ))  t(A) and f_ (t(A); t(B ))  t(B ). In other words, for every a and b,
f_(a; b)  max(a; b).
If we choose one of the known t?conorms for which f_(a; b) > max(a; b) (e.g., if we
choose f_ (a; b) = a + b ? ab), then, the more times we apply f_ , the larger the resulting
degree of belief, and in the limit, we get 1. For example, for f_ (a; b) = a + b ? ab =
1 ? (1 ? a)  (1 ? b), disjunction of N formulas with the same degree of belief a 2 (0; 1) leads
to f_(a; : : :; a) = 1 ? (1 ? a)N , and this expression ! 1 as N ! 1. (Here, f_(a; b; :::; c)
stands for f_(:::(f_(a; b); :::); c), i.e., it means that we apply the _?operation N times.)
A similar result can be proven for any (strict or non-strict) Archimedean t?conorm (see,
e.g., [16,34]). Hence, for such operations, we will have Y (y) = 1 for all y, which makes
no sense.
Therefore, when we dene operations with fuzzy operands, the only meaningful interpretation of \there exists" is through the _?operation f_ (a; b) = max(a; b), for which for
every property A(x), the degree of belief in \there exists x such that A(x)" is equal to the
\maximum" (or, to use the precise mathematical term, supremum) of all the degrees of
belief t(A(x)) for all x.
As far as an &?operation is concerned, we can use an arbitrary function f& : [0; 1] 
[0; 1] ! [0; 1] that extends a usual & operation dened for binary values (with 0 as false
as 1 as true), i.e., an arbitrary function f& for which f& (0; 0) = f& (0; 1) = f& (1; 0) = 0
and f& (1; 1) = 1.
For such interpretation of \and" and \there exists", formula (2) takes the following
form:
Y (y) = sup f& (X1 (x1); :::; X (xn ));
(1:4a)
~x:f (~x)=y

n

7

where f& (a; b; :::; c) stands for f& (:::(f&(a; b); :::); c) (i.e., it means that we apply the
&?operation several times).
Our results will be true for an arbitrary choice of an &?operation.

1.2. How is the problem of
estimating accuracy of the results of data processing
solved now?
In general, the problem is computationally intractable even for crisp sets (even
for intervals). It has been proven that even for the case when the sets Xi are crisp (and
are intervals), and the algorithm f is actually a polynomial, the problem of computing the
set Y exactly is computationally intractable (NP-hard) [9].

This result does not mean, of course, that the problem of computing Y is not practically solvable. The sets Xi describe the inaccuracy of the measuring devices, or the
inaccuracy of an expert. These inaccuracies are never known precisely, therefore, it would
be quite sucient to have an approximate description of Y . Several methods are known
for that:

Case when estimates are pretty accurate: linearization technique. If the esti-

mates x~i for xi are pretty accurate, then we can neglect the terms that are quadratic
(or of higher order) in xi = x~i ? xi , and thus, for given estimates x~i , describe
y = f (x1; :::; xn) = f (~x1 ? x1 ; :::; x~n ? xn ) by the following approximate formula:
y  flin = y~ ? f;1x1 ? ::: ? f;nxn ; where by f;i , we denoted the partial derivative of f
w.r.t. xi :
@f (~x ; :::; x~ ):
f;i = @x
1
n
i

In this case, for interval Xi = [~xi ? i ; x~i + i ], we have Y  Xlin = flin (X1; :::; Xn) =
[~y ? ; y~ + ], where  = jf;1j1 + ::: + jf;njn (see, e.g., [35]).

Another case when we can estimate Y is when the function f is monotonic in each
of the variables; in this case, if, e.g., f is monotonically increasing, and Xi = [x?i ; x+i ], we
have Y = [f (x?1 ; :::; x?n ); f (x+1; :::; x+n )].
For these two cases (small errors or monotonic f ), there also exist ecient techniques
for fuzzy data processing [4,51].

Expert estimates are rarely very accurate, so, other methods are needed. Mea-

surements typically lead to accurate estimates of xi , so, if all the estimates come from
8

measurements, we can usually apply linearization techniques. Expert estimates, on the
other hand, are rarely very accurate. So, if we have expert estimates, we usually cannot
neglect the squares of the errors, and therefore, we need other methods for estimating the
error of the result of data processing. For this case, the following idea has been proposed
by R. Moore [27,28] (see also [29,11,10,14]). No matter what high-level language we use
to describe an algorithm f , inside a computer, this algorithm is translated into a sequence
of elementary operations (usually, +, ?, , :, etc).
For example, a function f (x1; x2; x3) = (x1 + x2 )2 + 2  x3 is computed as follows (we will
enumerate all the input and intermediate values by r1 ; r2, ...): rst, we have r1 = x1,
r2 = x2 , and r3 = x3 ; then, we start computing further values:
 we apply + and get r4 = r1 + r2 = x1 + x2 ;
 we apply the square operation and get r5 = r42 (so, r5 = (x1 + x2 )2).
 we take r6 = 2;
 we compute r7 = r6  r3 ;
 nally, we compute r8 = r5 + r7 ; this is the desired value y.
The idea is to repeat the same sequence of operations, but with intervals instead of numbers.
Elementary operations g are usually monotonic, so, we can explicitly compute g(X1; :::; Xn)
for intervals Xi : e.g., for addition g(x1; x2) = x1 + x2 , we have g([x?1 ; x+1]; [x?2 ; x+2]) =
[x?1 + x?2 ; x+1 + x+2 ].
For example, if we start with the intervals R1 = X1 = [0; 1], R2 = X2 = [0; 1], and
R3 = X3 = [1; 2], we get the following sequence of computations:
 we apply + and get R4 = R1 + R2 = [0; 1] + [0; 1] = [0; 2];
 we apply the square operation and get R5 = R42 = [0; 4];
 take R6 = [2; 2];
 compute R7 = R6  R3 = [2; 2]  [1; 2] = [2; 4];
 nally, we compute Y~ = R8 = R5 + R7 = [0; 4] + [2; 4] = [2; 8]; this is the desired
estimate for Y .
It has been proven that for intervals Xi , the resulting estimate Y~ contains the desired
interval Y .
A similar procedure can be used for fuzzy processing: here, we implement elementary
operations g using extension principle.

These new methods do not always lead to accurate results. The results of these

computations do not always lead to the exact value of Y ; even for intervals Xi , the result
9

depends on the exact order of the operations performed to compute f . For example, we can
compute f (x1; x2) = x1  x2 by simply multiplying the two numbers, or we can compute the
same product by using a more complicated formula x1  x2 = (1=4)  [(x1 + x2 )2 ? (x1 ? x2 )2 ].
If X1 = X2 = [1; 2], then the rst algorithm leads to the estimate Y~ = [1; 4] that coincides
with the desired interval Y = f (X1; X2). However, the second algorithm leads to a dierent
result: indeed, this algorithm can be represented as a following sequence of computations:
 r3 := r1 + r2.
 r4 := r32 .
 r5 := r1 ? r2.
 r6 := r52 .
 r7 := r4 ? r6.
 r8 := 4.
 r9 := r7 =r8.
So, for Xi = [1; 2], we get R3 = [2; 4], R4 = [4; 16], R5 = [?1; 1], R6 = [0; 1], R7 = [3; 16],
R7 = [4; 4], and Y~ = R9 = [0:75; 4] 6= Y = [1; 4]. The resulting interval Y~ contains extra
points [0:75; 1).

1.3. Going from numbers to intervals and fuzzy sets
drastically increases computation time,
so hardware support is in order
Hardware support is necessary. We have already mentioned that even for real num-

bers, data processing algorithm that computes f (x1; :::; xn) can be quite complicated and
time-consuming. When we analyze accuracy of data processing, we must go from operations with numbers to operations with intervals, crisp sets, or fuzzy sets. For example,
when we go from precise numbers to fuzzy sets, then instead of processing n numbers
according to the known algorithm f , we have to solve complicated optimization problems
to nd Y (y). This increases computation time drastically: for example, in a crisp case,
to compute a sum of two numbers x1 + x2 , we must process these two numbers xi only;
all it takes is one arithmetic operation. To compute a sum of two fuzzy operands, instead
of processing two numbers, we must take as input the values X1 (x1 ) and X2 (x2 ) that
correspond to dierent xi . Just because of the necessity to process such a long input, these
computations are inevitably long. How to speed up fuzzy computations?
One known way to speed up computations in general is to design a hardware support
for them. This idea worked perfectly well, e.g., for oating point operations that had
initially been implemented in software. So, it is desirable to design hardware support for
interval and fuzzy computations as well.
10

A word of warning: Hardware support is not sucient. Hardware support does

bring a speed-up, and is, therefore, a great idea. However, the very fact that we have a
hardware support of several basic operations with intervals, crisp sets, and/or with fuzzy
sets, does not necessarily mean that we have improved the quality of the result (we are
thankful to the anonymous referee who helped us clarify this point).
As we have shown in Subsection 1.2, if we start with an expression
(1=4)  [(x1 + x2)2 ? (x1 ? x2)2 ]
and simply substitute interval operations instead of operations with numbers, we will get
an overestimation irrespective on whether we implement these operations in software or in
hardware. The only way to get the exact estimate is to transform this expression into an
equivalent one x1  x2 for which interval computations give the exact estimate.
An even more striking example is a function of one variable dened as f (x1) = x1 ? x1 .
This function is, of course, identically equal to 0, so, for every interval X1, we should get
f (X1) = f0g. However, if we take X1 = [0; 1], and apply interval subtraction, we will get
X1 ? X1 = [0; 1] ? [0; 1] = [?1; 1]. Whether we are implementing interval subtractions in
hardware or in software, we get an overestimation. Again, the only way to get the exact
estimate is take into the consideration that the two terms in the original expression cancel
each other, and thus, to transform the original expression x1 ? x1 into an equivalent one
0.
So, in addition to hardware, we need some appropriate symbolic reasoning engine (of
the type implemented in Macsyma or in Mathematica) that would transform the original
expression into an equivalent one that will lead to the precise (or at least to a more
accurate) estimate.
At present, designing such an engine is a more urgent and more potentially rewarding
task than working on hardware. Currently, computers only allow unary and binary operations. So, what this engine will do is, given a function, transform it into a sequence of
unary and binary operations. The perfect engine will output a transformation that leads to
the best possible estimate (e.g., to the interval with the smallest possible overestimation).
However, this \the best" does not necessarily mean that we will have no overestimation
at all: As we will see later, for some functions of three and more variables, no matter
how we transform these functions into a sequence of unary and binary operations, interval
computations will always lead to an overestimation. This overestimation result is true not
only for the existing computers, where only elementary arithmetic operations are hardware
supported; this result (as we will show) is true for any computer that hardware supports

11

only unary and binary operations. So, for such functions, the only way to avoid overestimation is to implement operations with three or more interval (corr., fuzzy) operands in
hardware.
For the resulting new computer, the computation scheme will include not only standard unary and binary operations, but some new operations (with interval or fuzzy
operands) as well. Again, the very fact that we have added these new operations does
not automatically mean that we will achieve the exact estimate: before we apply interval
computations, we must transform the original computation scheme (that may be overestimating) into a new (equivalent) scheme with no overestimation. So, we will again need
an appropriate symbolic reasoning engine for the new computer.
Summarizing, we can say that achieving precise interval and fuzzy computations is a threestep task:
 First, we must design a symbolic reasoning engine based on the existing hardware
supported operations (namely, elementary arithmetic operations). This engine must
transform the original expression (in terms of these elementary operations) for which
interval and fuzzy computations overestimate into an equivalent expression that leads
to more precise result Y .
 Second, we must select operations with three or more interval or fuzzy operands that
need to be hardware supported in order to get precise results.
 Third, for these new operations included, we must design a new symbolic reasoning
engine that will transform every algorithm into a sequence of elementary operations
(arithmetic or new ones) for which interval (fuzzy) computations will lead to the
precise result.
The rst task { the design of the original engine is, in eect, being currently done in interval
computations community (see, e.g., [10] and [14]). In the present paper, we consider the
second task: the choice of the hardware operations to be hardware supported. We give
only a partial answer to this task. As soon as this problem will be solved, the need will
come for the third task: designing a new symbolic reasoning engine for the new computer.

Hardware support of interval and fuzzy operations: a little bit of history. The

existing hardware support of interval operations is described in [23,36,37], and references
therein. Usually, the supported operations are arithmetic operations, and the scalar (dot)
product a1  b1 + ::: + an  bn .
The rst hardware implementation of operations with fuzzy sets has been developed
by Yamakawa. For the current state of research, see, e.g., [49,50]; for applications, see,
12

e.g., [43] and [52]. This rst implementation included several chips. The rst single-chip
hardware implementation of fuzzy operations have been proposed in [45] (for more recent
results, see, e.g., [44] and [48]). Parallel hardware implementation has been proposed
and described in [2]; see also [38] and [42]. These implementations, however, are mainly
oriented towards fuzzy control problems (and not fuzzy data processing).

What interval and fuzzy operations should we support for data processing? It

is impossible to implement in hardware fuzzy operations that correspond to all possible
functions f (x1; :::; xn). So, it is necessary to choose.

The natural idea is to describe all functions f that are hardware supported on the
existing computers, and to support the corresponding operations with fuzzy sets. Since
usually, only unary and binary operations are hardware supported, we will thus have
hardware implementation only of operations of one and two operands.

What we are planning to do. In this paper, we show that for intervals and for fuzzy sets,

an implementation of only unary and binary operations is not sucient in the following
sense: for some functions f and for some intervals (fuzzy sets) Xi , no matter how we
represent the function f as a composition of unary and binary operations, if we then
apply the above-described methodology, the resulting estimate Y~ will be dierent from the
desired value Y = f (X1; :::; Xn). Therefore, if we want fuzzy data processing to be precise,
operations with three or more fuzzy operands should also be implemented in hardware.
Some crisp operations with three or more crisp operands are already hardware supported: e.g., many computers contain a math co-processor that, among other things, hardware supports matrix operations, i.e., operations whose operands include an entire matrix
(i.e., lots of numerical operands). For example, it is possible, given two arrays a1 ; :::; an
and b1; :::; bn, to compute their dot (scalar) product a1  b1 + a2  b2 + ::: + an  bn by using
a single operation of a math co-processor. For crisp numbers, the main purpose of using
such operations is to speed up computations: in principle, we can use operations with two
operands (in this case, addition and multiplication) and compute the same expression in
several steps.
We are planning to show that in interval and fuzzy case, if we restrict ourselves to
unary and binary operations only, then not only computations will slow down, but for
some functions f , and for some intervals (fuzzy sets) Xi , we will not get the desired value
f (X1; :::; Xn) at all.
13

1.4. Structure of the paper
In Section 2, we will give some general denitions. In Section 3, we will consider the simplest case when inputs are intervals, and when all operations that are hardware supported
are smooth (dierentiable) functions. For this case, we will prove that operations with
one or two variables are not sucient. The fact that functions are dierentiable makes it
possible not only to prove the negative results but also to describe the smallest possible
order of the error that can be caused by such computations (linear, quadratic, etc). We
also give a list of operations that need to be hardware supported so that we will be able
to compute Y with a better accuracy: this list consists of arithmetic operations and a
weighted scalar product. In Section 4, these results will be generalized from crisp intervals
to fuzzy sets. In Section 5 and 6, we show that even if we allow operations that are not
dierentiable, still operations with one or two operands will not be sucient. In Section
7, we discuss the relation between these results and Kolmogorov's theorem (well known in
mathematics) that every continuous function of three or more real variables can be represented as a composition of real-valued functions of one and two variables. For reader's
convenience, all the proofs are placed in Section 8.

14

2. GENERAL DEFINITIONS
In this Section, we give general denitions that will be used in the following text.

2.1. Computation scheme
In this subsection, we will formalize the description of a general computation process
(presented in Subsection 1.2) into a formal denition, and show (on an example) how this
formalization is related to the original description.

Denition 2.1. By a computation scheme S with n initial values, and with operations
with one or two operands (or, for short, simply a computation scheme), we mean a nite
sequence (Sn+1; Sn+2 ; :::; SN ) of expressions Si (called steps). Each step Si is an expression
of one of the following three types:
 ri := ci , where ci is a real number;
 ri := fi (rj ), where fi is a function of one variable (not necessarily everywhere dened),
and j < i;
 ri := fi (rj ; rk ), where fi is a function of two variables (not necessarily everywhere
dened), j < i, and k < i.
If S is a computation scheme with n initial values, and x1; :::; xn are n real numbers, we
say that the result of applying S to xi is y, if rN = y, where the sequence ri is dened as
follows:
 if i  n, then ri = xi :
 if i > n, then depending on the type of the rule Si , we dene ri as follows:
 if the rule if ri := ci , then ri = ci ;
 if the rule is ri := fi (rj ), then ri = fi (rj );
 if the rule is ri := fi (rj ; rk ), then ri = fi (rj ; rk ).

Denotation. For some x1; :::; xn, and for each i  N , this Denition provides us with a

certain value of ri . This value will be denoted by ri (x1; :::; xn).

Comment. We have already mentioned that inside a computer, every algorithm is translated into a sequence of elementary operations. Since in the majority of computers, all elementary operations correspond to functions of one or two variables, an arbitrary algorithm
computing y = f (x1; :::; xn) can be thus represented as a computation scheme. For example, how in the above-given representation of the function f (x1; x2; x3) = (x1 + x2 )2 +2  x3,
we have:

15

 r4 = r1 + r2 (here, f4 = +, j = 1, k = 2);
 r5 = r42 (here, f5(x) = x2, j = 4);
 r6 = 2 (here, we have a function of 0 variables, that computes a constant 2);
 r 7 = r6  r3 ;
 r 8 = r5 + r7 .
Denition 2.2. Let K  Rn, and let f be a function from K to R. We say that a
computation scheme S computes f if for every (x1; :::; xn) 2 K , the value that S computes
(is dened and) is equal to f (x1; :::; xn).
2.2. Applying computation scheme to crisp sets
(in particular, to intervals)
In this subsection, we will describe how a computation scheme can be applied to crisp sets;
in particular, we will describe how it can be applied to intervals.

Denition 2.3. Let f (x1; :::; xn) be a function of n real variables, and let X1  R, ...,
Xn  R be (crisp) sets. Then, the result f (X1; :::; Xn) of applying f to the sets X1 ; :::; Xn
is dened by the formula (1.1). If instead of the sets Xi, we have a (crisp) set X  Rn,
then the result f (X ) of applying f to X is dened by the formula (1.2).

Denition 2.4. Assume that S is a computation scheme with n input values, and that
Xq  R, ..., Xn  R are (crisp) subsets of R. We say that the result of applying S to

X1; :::; Xn is Y if RN = Y , where the sequence of (crisp) sets R1; :::; RN is dened as
follows:
 if i  n, then Ri = Xi ;
 if i > n, then, depending of the type of the rule Si , Ri is dened as follows:
 if Si is ri := ci , then Ri = fci g;
 if the rule is ri := fi (rj ), then Ri = fi (Rj );
 if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).

16

Denition 2.5. Assume that S is a computation scheme with n input values, and that
X is a (crisp) subset of Rn. We say that the result of applying S to X is Y if RN = Y ,

where the sequence of (crisp) sets R1 ; :::; RN is dened as follows:
 if i  n, then Ri = i (X ), where i is a projection on i?th component (i.e., i (~x) =
xi );
 if i > n, then, depending of the type of the rule Si , Ri is dened as follows:
 if Si is ri := ci , then Ri = fci g;
 if the rule is ri := fi (rj ), then Ri = fi (Rj );
 if the rule is ri := fi(rj ; rk ), where j  n and k  n, then we take
Ri = f (jk (X )), where jk is a projection to j ?th and k?th components (i.e.,
jk (x1 ; :::; xj ; :::; xk ; :::; xn) = (xj ; xk ));
 if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).
Comment. The main dierence between these two denitions is that when we have a set
X  Rn , and we want to compute the set fi (X ) of possible values of fi (x1 ; :::; xn), we
must take into consideration the fact that not all values (x1 ; :::; xn) with xi 2 i (X ) are
possible.

2.3. Applying computation scheme to fuzzy sets

In the previous subsection, we described the result of applying a computation scheme to
crisp sets. Let us now describe what a computation scheme will do if we apply it to fuzzy
sets.

Denition 2.6. Let f (x1; :::; xn) be a function of n real variables, and let X1  R, ...,
Xn  R be fuzzy sets. Then, the result f (X1; :::; Xn) of applying f to the sets X1; :::; Xn is
dened by the formula (1.4a). If instead of the fuzzy sets Xi , we have a fuzzy set X  Rn,

then the result f (X ) of applying f to X is dened by the formula (1.3).

Denition 2.7. Assume that S is a computation scheme with n input values, and that
X1  R, ..., Xn  R are fuzzy subsets of R. We say that the result of applying S to

X1; :::; Xn is Y if RN = Y , where the sequence of fuzzy sets R1 ; :::; RN is dened as
follows:
 if i  n, then Ri = Xi ;
 if i > n, then, depending of the type of the rule Si , Ri is dened as follows:
 if Si is ri := ci , then Ri = fci g (a crisp set);
 if the rule is ri := fi (rj ), then Ri = fi (Rj );
 if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).
17

Denition 2.8. Assume that S is a computation scheme with n input values, and that
X is a fuzzy subset of Rn . We say that the result of applying S to X is Y if RN = Y ,

where the sequence of fuzzy sets R1; :::; RN is dened as follows:
 if i  n, then Ri = i (X ), where i is a projection on i?th component (i.e., i (~x) =
xi );
 if i > n, then, depending of the type of the rule Si , Ri is dened as follows:
 if Si is ri := ci , then Ri = fci g (a crisp set);
 if the rule is ri := fi (rj ), then Ri = fi (Rj );
 if the rule is ri := fi(rj ; rk ), where j  n and k  n, then we take
Ri = f (jk (X )), where jk is a projection to j ?th and k?th components (i.e.,
jk (x1 ; :::; xj ; :::; xk ; :::; xn) = (xj ; xk ));
 if the rule is ri := fi (rj ; rk ), where j > n or k > n, then Ri = fi (Rj ; Rk ).

3. SIMPLEST CASE:
SMOOTH OPERATIONS, INTERVAL UNCERTAINTY;
HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS
IS NOT SUFFICIENT;
WEIGHTED SCALAR PRODUCT MUST ALSO BE SUPPORTED

In this section, we will consider the simplest case when inputs are intervals, and when
all operations that are hardware supported are smooth (dierentiable) functions. For this
case, we will prove that hardware operations with one or two variables are not sucient.
The fact that functions are dierentiable makes it possible not only to prove the
negative results but also to describe the smallest possible order of the error that can be
caused by such computations (linear, quadratic, etc). We will also give a list of operations
that need to be hardware supported so that we will be able to compute Y with a better
accuracy: this list consists of arithmetic operations and a weighted scalar product.

Denition 3.1.
 We say that a computation scheme S is continuous if all the function fi are continuous.
 We say that a function f is smooth if it is dened on an open set, is three times
dierentiable, and all its third order derivatives are continuous.
 We say that a computation scheme S is smooth if all the function fi are smooth.

3.1. The main (negative) result:
unary and binary operations are not sucient

In this subsection, we will describe our rst negative result: that for smooth operations on
intervals, hardware unary and binary operations are not sucient.
18

Denition 3.2. Assume that a smooth computation scheme S computes a smooth function f dened on an open set K  Rn. We say that S is precise for intervals if for all
intervals X1; :::; Xn for which X1  :::  Xn  K , the result of applying S to X1 ; :::; Xn
coincides with f (X1; :::; Xn).

For example, a 1-step computation scheme that computes f (x1; x2) = x1  x2 by
multiplying x1 and x2 is precise for intervals, while the computation scheme based on the
expression (1=4)  [(x1 + x2 )2 ? (x1 ? x2 )2] is not. It can be proven that the above-given
computation scheme for f (x1; x2; x3) = (x1 + x2 )2 +2  x3 is precise for intervals. As we have
already mentioned, for one and the same function, some computation scheme are precise,
and some others are not. The question is: for a give function f , is there any computation
scheme that is precise?

Denition 3.3. We say that for a smooth function f : Rn ! R, smooth interval com-

putations are precise, if there exists a smooth computation scheme that computes f and
that is precise for intervals. If such a smooth computation scheme does not exist, then we
say that for this function f , smooth interval computations cannot be always precise.

We will show that for many reasonable smooth functions, smooth interval computations cannot be always precise. To formulate our result, we will need a few denotations
and denitions.

Denotations.
 By f;i, we will denote i?th partial derivative of a function f .
 By f;ij , we will denote the second partial derivative
2f
:
f;ij = @x@ @x
i

j

Denition 3.4.
 A point ~s is called a stationary point of a function f if f;i (~s) = 0 for all i.
 A stationary point ~s of a function f is called non-degenerate if the following two

conditions are satised:
 at this point ~s, all components of the Hessian matrix f;ij (~s) are dierent from 0;
 at this point ~s, the determinant of the Hessian matrix is dierent from 0.

Comment. Almost all matrices satisfy these two properties (in the sense that the set of
symmetric matrices for which they are not true forms a subspace of co-dimension 1 in
the n(n + 1)=2?dimensional set of all matrices). So, we can say that almost all smooth
functions with a stationary point have a non-degenerate stationary point.

19

THEOREM 3.1. If a smooth function f (x1; :::; xn), n  3, has a non-degenerate stationary point, then for this function f , smooth interval computations cannot be always
precise.

Reformulation of this result in more informal (and hopefully, more understandable) terms. In view of the previous comment, this result means that for almost
all smooth functions with a stationary point, smooth interval computations cannot be always precise.

Our result and known mathematical results. The very fact that there exist smooth
functions for which smooth interval computations are not always precise is not surprising:
indeed, it is known (see, e.g., a survey [26]), that there exists a smooth function of three
variables that cannot be represented as a composition of smooth functions of one or two
variables. For such functions, a smooth computation scheme cannot be precise even for
real numbers, and of course, it is not precise for intervals, because every real number xi
can be viewed as a (degenerate) interval [xi ; xi]. Our negative result is much broader than
that: namely:
 Functions that cannot be represented as a composition of smooth unary and binary
operations can be viewed rather as an exception: e.g., every polynomial can denitely
be represented as such a composition.
 For smooth interval computations, we have shown that (in some reasonable sense)
almost all functions (to be more precise, almost all functions with a stationary point)
cannot be represented as compositions of smooth unary and binary interval operations.
This result includes functions f (x1; :::; xn) like quadratic polynomials, that can be
represented as a composition for numerical xi .

What does this theorem tell us about the choice of operations for hardware
implementation. With respect to hardware support, Theorem 3.1 says the following:
suppose that we have chosen a list of operations that we intend to implement in hardware
(both as operations with numbers and as operations with intervals). On the resulting
computer, every algorithm f (x1; :::; xn) will thus be represented as a composition of the
hardware supported operations fi . If we want to compute the interval f (X1; :::; Xn),
we will apply the same sequence of operations as in computing f (x1; :::; xn), but with
intervals instead of numbers (i.e., we will apply the computation scheme S that computes
f to intervals X1; :::; Xn). For some computation schemes, e.g., for

x1  x2 = (1=4)  [(x1 + x2)2 ? (x1 ? x2)2 ];
20

we may get an overestimate of f (X1; :::; Xn); for some others, hopefully, we will get a
precise estimate. In view of the previously mentioned result, for some smooth functions,
no smooth computation scheme will return the precise interval f (X1; :::; Xn).
We would like to choose a set of hardware supported operations in such a way that
for each smooth function that has smooth computation schemes, at least one of these
schemes will be precise for intervals (i.e., the above-described method will give exactly
f (X1; :::; Xn)). Theorem 3.1 tell us that we cannot achieve this goal if we only support
unary and binary operations; so, we must also implement some operations with three or
more operands in hardware.

3.2. Second negative result: if we only use unary and binary operations,
we cannot even compute the main term correctly
According to Theorem 3.1, if a smooth function f (x1; :::; xn) has a non-degenerate stationary point, and if we are only using unary and binary operations, then it is impossible to
always compute f (X1; :::; Xn) precisely for intervals Xi. So, if a computation scheme S
computes f , then the result Y~ of applying S to some intervals X1; :::; Xn will be dierent
from the desired interval Y = f (X1; :::; Xn). How dierent can it be?
Since we consider smooth functions, we can try to describe this dierence in terms of
the order: is it linear (rst order), quadratic (second order), cubic (third order), etc, in
i ? It could be that the dierence is, say, of fth order w.r.t. errors i , and therefore,
for practical purposes (this dierence being much smaller than the interval itself) we could
safely neglect it, and treat Y~ as a good approximation for Y . Alas, the reality is not so
good: it turns out that smooth interval computations (with unary and binary operations)
do not even give a correct main term for Y .
To describe this result in mathematical terms, let us rst describe the asymptotic of Y :

PROPOSITION 3.1. Let f (x1; :::; xn) be a smooth function. Then, the lower f ? and
upper f + bounds of the interval f ([x1 ? 1 ; x1 + 1 ]; :::; [xn ? n ; xn + n ]) satisfy the
property f  = f (x1; :::; xn)  (jf;1(~x)j1 + ::: + jf;n (~x)jn ) + O(2i ).
Denition 3.5. Assume that S is a smooth computation scheme for a smooth function
f (x1; :::; xn). We say that S always computes the main error term correctly if for every ~x,
the dierence between the actual endpoints of the interval
Y = f ([x1 ? 1; x1 + 1 ]; :::; [xn ? n ; xn + n ])
and the values computed by applying S to intervals Xi = [xi ? i ; xi + i ] is O(2i ).
21

Comment. In other words, we allow smooth interval computations not to be precise in the
sense that their result can dier in terms that are quadratic (or of higher order) in i , but
we require that the main term in i be computed precisely.
THEOREM 3.2. If a smooth function f (x1; :::; xn), n  3, has a non-degenerate stationary point, then for this function f , smooth interval computations cannot always compute
the main error term correctly.

3.3. Third negative result:
if we only use unary and binary operations,
we cannot even be locally asymptotically correct

An even stronger negative result can be proved. Namely, in our denition of what it means
to compute the main term correctly, we required that the main term should be computed
exactly. In general, the fact that a function is several times dierentiable, means that we
can approximate it by its Taylor polynomial. For example, if f is twice dierentiable, then
in the neighborhood of a point (s1; :::; sn), we can approximate the function f (x1; :::; xn)
P
by a linear function: f (x1; :::; xn) = f (s1; :::; sn) + f;i (s1; :::; sn)(xi ? si ) + O((xi ? si )2 ).
If the function is analytical, these Taylor polynomials actually converge to the function f .
So, if by using smooth interval computations, we cannot compute the main term precisely,
then maybe, we can at least compute correctly the rst few terms in the expansion of the
main term? I.e., e.g., we may be able to compute the main term with the accuracy of
O((xi ? si )2) terms? Alas, even this, we cannot compute, as the following result shows.
Denition 3.6. Let f (~x) be a smooth function, ~s = (s1; :::; sn) is a point in Rn, and
S is a smooth computation scheme for f . We say that S is locally asymptotically correct
(in computing the main error term) in the neighborhood of ~s, if the dierence between the
actual endpoints of the interval f ([x1 ? 1 ; x1 +1 ]; :::; [xn ? n ; xn +n ]) and the values
computed by applying S to the intervals Xi = [xi ? i ; xi +i ] is O(2i )+ O(i  (xj ? sj )2 ).
THEOREM 3.3. If a smooth function f (x1; :::; xn), n  3, has a non-degenerate stationary point, then for this function f , there exists a point ~s such that no matter what smooth
computation scheme S we choose to compute f , the resulting smooth interval computations
are not locally asymptotically correct in the neighborhood of ~s.

3.4. Positive result: if we add weighted scalar product,
smooth interval computations become locally asymptotically correct

Indeed, assume that in our denition of a computation scheme, we allow, in addition to
unary and binary operations, weighted scalar product, i.e., an operation
a1 ; :::; an; b1; :::; bn ! w1  a1  b1 + ::: + wn  an  bn ;
(3:1)
22

where n is an arbitrary positive integer, and wi are arbitrary real numbers (called weights).
Before we give a formal denition, we must make one comment.
In operations with real numbers, if we can implement a binary operation f (x1; x2),
then we can automatically implement the function g(x) = f (x; x) that is obtained by
applying f to two equal values: namely, to implement g, we can simply apply f to two
equal values. For interval operations, this idea does not always lead to an implementation
of g. As an example, we can take subtraction f (x1; x2) = x1 ? x2. For subtraction,
g(x) = f (x; x) = x ? x = 0; the corresponding interval operation is f ([x?1 ; x+1]; [x?2 ; x+2]) =
[x?1 ? x+2 ; x+1 ? x?2 ]. If we apply this operation to [x?1 ; x+1 ] = [x?2 ; x+2] = [0; 1], we get
f ([0; 1]; [0; 1]) = [?1; 1]. This result is dierent from the desired g([0; 1]) = f0g. Because
of this comment, when we describe a computation scheme that involves a certain interval
operation f , we must specically include interval analogues of all functions that can be
obtained from f by applying it to equal values of the variables. As a result, for weighted
scalar product, we arrive at the following denition:

Denition 3.7.
 Let a function f (x1; :::; xi?1; xi ; xi+1; :::; xj?1; xj ; xj+1; :::; xn) be given. We say that a

function g(x1; :::; xj?1; xj+1; :::; xn) = f (x1; :::; xi?1; xi; xi+1 ; :::; xj?1; xi; xj+1 ; :::; xn)
with n ? 1 variables is a simplied version of a function f ; transition from f to g will
be called a simplication.
 We say that a function g is a version of a function f if g can be obtained from f by
a sequence of simplications.
 By a weighted scalar product, we mean an operation (3.1).
 By a computation scheme with weighted scalar products, we mean a sequence S of
expressions each of which is either a function of zero, one, or two variables (like in
Denition 2.1), or an application of a weighted scalar product or of one of its versions.

Example. If we use weighted scalar product and its versions, we can simplify the computation of the above-given expression (x1 + x2 )2 + 2  x3 as follows: we still have ri = xi for
i = 1; 2; 3; and then:
 r4 = r2 + r3 (this is a binary operation);
 r5 = 2;
 r6 = r42 + r5  r3; here, to the values r4 , r5 , and r6 , we apply a function f6(y1; y2; y3) =
y12 + y2  y3 obtained by simplifying a weighted scalar product: f6 (y1; y2; y3) =
f  (y1; y1; y2; y3), where f (y1; y4; y2; y3) = y1  y4 + y2  y3 is a weighted scalar product
with both weights equal to 1.

23

For such computation schemes, we can repeat denitions 2.2 (what it means that a scheme
computes a function f ), 2.3 (how to apply a scheme to intervals), and 3.6 (what it means
to be locally asymptotically correct). Now, we can formulate our positive result:

THEOREM 3.4. For every smooth function f (x1; :::; xn), n  3, and for every point
~s in its domain, there exists a computation scheme S with weighted scalar products for
which the resulting smooth interval computations are locally asymptotically correct in the
neighborhood of ~s.

Comments.
 Good news: the result is applicable not only to intervals, but to arbitrary crisp sets as
well. From the proof of this theorem, one can easily see that the designed computation
scheme is locally asymptotically correct not only for intervals Xi = [xi ? i ; xi + i ],
but also for arbitrary crisp sets Xi  [xi ? i ; xi + i ].

 Not so good news: We know what operations we need to implement in hardware, but

we do not yet know how to implement them all. Theorem 3.4 says that if we hardware
support all weighted scalar products, then smooth interval computation becomes locally asymptotically correct. A word of warning: this result does not mean that we can
immediately implement all these operations and make computations (asymptotically)
precise, because we do not yet know how to implement all the necessary operations.
Indeed, according to Denition 3.7, we need separate versions of a function to deal
with each simplication obtained when two or more arguments to the function represent the same variable. For a function with n arguments, this will require n! hardware
implementations of the function. When n is large, n! is so unrealistically large that
it is practically impossible to have n! dierent hardware devices that compute n! different simplications. So, to implement all these simplications, we need a exible
implementation that will change when some of the arguments represent the same variable. At present, we do not know how to design such a exible implementation. This
implementation issue is an interesting open problem.

4. SMOOTH OPERATIONS, INDEPENDENT FUZZY SETS X1; :::; Xn:
HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS
IS NOT SUFFICIENT;
WEIGHTED SCALAR PRODUCT MUST ALSO BE SUPPORTED
In the previous section, we proved that unary and binary operations are not sucient
to support arbitrary smooth operations on intervals. In this section, we will show that,
24

similarly, unary and binary operations are not sucient to describe smooth operations on
(independent) fuzzy sets.

Denition 4.1. Assume that a smooth computation scheme S computes a function f
dened on an open set K  Rn. We say that S is precise for independent fuzzy sets if for
all fuzzy sets X1 ; :::; Xn for which X1  :::  Xn  K , the result of applying S to X1 ; :::; Xn

coincides with f (X1; :::; Xn).

Denition 4.2. We say that for a smooth function f : Rn ! R, smooth computations

are precise for independent fuzzy sets, if there exists a smooth computation scheme that
computes f and that is precise for fuzzy sets. If such a smooth computation scheme does
not exist, then we say that for this function f , smooth computations cannot be always
precise for independent fuzzy sets.

THEOREM 4.1. If a smooth function f (x1; :::; xn), n  3, has a non-degenerate sta-

tionary point, then for this function f , smooth computations cannot be always precise for
independent fuzzy sets.
Comments.
 Theorem 4.1 follows directly from Theorem 3.1: indeed, if a smooth computation
scheme is precise for arbitrary independent fuzzy sets, then, in particular, it must be
precise for crisp intervals, and this (according to Theorem 3.1) is impossible.
 Similarly, Theorems 3.2 and 3.3 show that smooth fuzzy computations with only unary
and binary operations cannot even describe the main term in f (X1; :::; Xn) correctly.
 In many reasonable cases, extension principle that denes Y = f (X1; :::; Xn) for
fuzzy sets X1; :::; Xn can be reformulated in terms of their (crisp) ?cuts Xi () =
fxjX (x)  g: namely, Y () = f (X1(); ::; Xn()) (see [33]; for counterexamples,
see [33] and [7]). So, if we add weighted scalar product to the list of hardware supported operations, then, due to Theorem 3.4, we will be able to get all ?cuts Y ()
locally asymptotically correctly, and in this sense, we will be able to compute the
fuzzy set Y itself with the same accuracy.
i

5. GENERIC (NOT NECESSARY SMOOTH) OPERATIONS, CRISP SETS:
HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS
IS NOT SUFFICIENT
Let us now consider the general case of operations that are not necessarily smooth, and of
the information that is not necessarily representable by independent sets X1 ; :::; Xn.
25

Denition 5.1. Assume that a computation scheme S computes a function f dened on
a set K  Rn. We say that S is precise for all (crisp) sets if for every (crisp) set X  K ,
the result of applying S to X coincides with f (X ).
Comment. We are going to prove that if our list of elementary operations includes only
operations with one and two operands, and a function f of three and more variables is
(in some reasonable sense) non-degenerate, then no computation scheme is applicable to
fuzzy processing (i.e., none of them will provide the exact fuzzy result). Let us describe
what we mean by non-degenerate.

Denition 5.2. Let K  Rn , n  3. We say that a function f : K ! R is degenerate
if K can be subdivided into nitely many subsets Ki so that on each subset, f coincides
with some function of one or two variables (i.e., on which f (x1; :::; xn) = g(xj ; xk ) for
some j and k and for some function g). A function that is not degenerate will be called
non-degenerate.

Comment. As an example of a degenerate function, we can take f (x1; :::; xn) =
max(x1 ; :::; xn). For this function, K = Rn can be subdivided into the subsets Ki in
which xi is greater than or equal to all other values, and on each Ki , f (x1; :::; xn) = xi
(i.e., is equal to a function of one variable).

The following two results show that many functions of three or more variables are
non-degenerate:

PROPOSITION 5.1. If a function f (x1; :::; xn) of three or more variables is dened
on a domain K , and on some subset M  K with a non-empty interior, f is strictly
monotonic in each variable, then f is non-degenerate.

Comment. To describe non-degenerate functions, we need to recall a notion of a real
analytic function: this means a function that can be represented as a sum of its Taylor
series. All known elementary functions (arithmetic operations, sin, cos, exp, ln, etc) and
their compositions are real analytic functions. It turns out that a real analytical function
is non-degenerate if and only if it actually depends on all of its variables:

PROPOSITION 5.2. If f (x1; : : :; xn) is a real analytic function of n  3 variables, and
f is not equal to a function of < n variables, then the function f is non-degenerate (in the
sense of Denition 5.2).

26

Examples.
 A function f (x1; x2; x3) = sin(x1 + exp(x2  x3)) is non-degenerate, because it actually
depends on each of its variables.
 In contrast, a function f (x1; x2; x3) = x1  x2 is degenerate, because it does not depend
on the variable x3 at all and is thus equal to the function of two variables.

THEOREM 5.1. If a function f of three and more variables is non-degenerate, then no

computation scheme that computes f is precise for all crisp sets.

Comment. This result is based on our Denition 2.1, in which we assumed that all elementary operations are operations with one or two (set-valued) operands. Thus, in case
of incomplete knowledge, when we have sets of possible values of the variables, operations
with one and two operands are not sucient. This suggests that for this case, we need to
implement hardware operations with 3 or more operands.

6. GENERIC (NOT NECESSARY SMOOTH) OPERATIONS, FUZZY SETS:
HARDWARE SUPPORT OF UNARY AND BINARY OPERATIONS
IS NOT SUFFICIENT
In the previous section, we proved that unary and binary operations are not sucient to
support generic (not necessarily smooth) operations on crisp sets. In this section, we will
show that, similarly, unary and binary operations are not sucient to describe generic
operations on fuzzy sets.

Denition 6.1. Assume that a computation scheme S computes a function f dened on
a set K  Rn. We say that S is precise for all fuzzy sets if for every fuzzy subset X  K ,
the result of applying S to X coincides with f (X ).
THEOREM 6.1. If a function f of three and more variables is non-degenerate, then no

computation scheme that computes f is precise for all fuzzy sets.

Comments.
 Since crisp sets are a particular case of fuzzy sets, this theorem is a corollary of
Theorem 5.1 (just like Theorem 4.1. is a corollary of Theorem 3.1).
 This result is based on our Denition 2.1, in which we assumed that all elementary
operations are operations with one or two (fuzzy) operands. Thus, for soft computing,
operations with one and two operands are not sucient. This suggests that for soft
computing, we need to implement hardware operations with 3 or more operands.

27

7. OUR RESULTS AND KOLMOGOROV'S THEOREM
7.1 What is Kolmogorov's theorem: in brief
The fact that every continuous function of three and more variables can be represented
as a composition of functions of one or two variables (and can be thus computed by an
appropriate computation scheme) has been rst proved by Kolmogorov [15] as a solution
to the famous Hilbert's problem: one of 22 problems that Hilbert has proposed in 1900 as a
challenge to the XX century mathematics [13]. Kolmogorov's result was later improved in
[40,41], and turned out to be applicable to theoretical and practical aspects of computation
(see, e.g., [6,12,24,25,31,30]).

7.2. In some reasonable sense, Kolmogorov's theorem
may not be extended to interval and fuzzy computations
Our negative theorems (3.1{3.3, 4.1, 5.1, and 6.1) show that Kolmogorov's theorem might
not be possible to extend to interval or fuzzy cases: there are functions that cannot be
represented as a composition of operations with one or two interval (resp. fuzzy) operands.

7.3. In some other sense (less computationally straightforward)
we can extend Kolmogorov's theorem to intervals
The above results are about the following: we have a function; we describe its computations
step-by-step, and substitute operations with intervals instead of operations with numbers.
In [32], the following result have been proven: if we do not follow the algorithm
f step-by-step, i.e., if we do not require that interval operations follow the ow of numerical computations, then Kolmogorov's theorem is true: namely, an arbitrary interval
function can be represented as a composition of functions of one and two variables. The
proof is rather simple: suppose that we have an interval-valued function f (x1 ; :::; xn) =
[f ? (x1 ; :::); f +(x1 ; :::)] of n interval variables x1 = [x?1 ; x+1]; :::; xn = [x?n ; x+n ] . This means
that we have two functions f ? and f + of 2n real variables x?1 ; :::; x?n ; x+1 ; :::; x+m. Each
of these functions can be (due to Kolmogorov's theorem) represented as a composition of
functions of one and two variables. So, we can do the following:
 rst, apply the interval functions ? and > that transform an interval [x? ; x+] into
[x? ; x? ] and, correspondingly, [x+ ; x+].
 follow the operations from Kolmogorov's theorem with these degenerate intervals, and
get the numerical-valued functions [f ?; f ?] and [f +; f +] as the desired composition;
 apply a combination operation comb([a; a]; [b; b]) = [a; b] to [f ?; f ? ] and [f +; f +] and
get the desired interval f = [f ?; f +].
28

With respect to hardware operations it means that in principle, we can restrict ourselves to
unary and binary operations only, but in this case, to compute the interval f (X1; :::; Xn),
we will not be able to simply follow the algorithm f step-by-step: for each f , we will have
to design a new method of interval (and therefore, for fuzzy) data processing.
Comment. An important open question:
 the result from [32] (described in this section) is proven for intervals;
 what happens in the fuzzy case?

8. PROOFS
Proof of Proposition 3.1
Since the function f is smooth, if xi are such that jxi j  i , then
f (x1 + 1; :::; xn + xn ) = flin + O(2i );
where we denoted flin = f (x1; :::; xn) + x1  f;1 + ::: + xn  f;n. The maximum of
flin is attained when each of the component terms xi  f;i attains the largest value for
xi 2 [?i ; i ]: for f;i > 0, the maximum is attained when xi = i , and for f;i < 0, the
maximum is attained when xi = ?i . In both cases, the maximum of i?th term is equal
to jf;iji . Therefore, the maximum of flin is equal to f (x1; :::; xn) + jf;1j1 + ::: + jf;njn .
Hence, the maximum f + of f is equal to this expression plus O(2i ). The result for f ? is
proved similarly. Q.E.D.

Proof of Theorems 3.1{3.3
Theorems 3.1 and 3.2 follow from Theorem 3.3, so it is sucient to prove Theorem 3.3.
We will prove that the statement of this theorem is true for the non-degenerate stationary
point ~s. This will be proven by reduction to a contradiction. Namely, let us assume that
there exist a smooth function with a non-degenerate stationary point ~s and a computation
scheme S for which smooth interval computations are locally asymptotically correct in the
neighborhood of ~s. Each such scheme S can be characterized by an integer: namely, by
the total number of computation steps. Among such schemes, there exists a scheme with
the smallest possible value of this integer. Let us denote this scheme by S , the function
that is computed by this scheme by f (x1; :::; xn), and the stationary point for this function
by ~s = (s1; ::; sn).
First, let us describe what type of expression we can get after each step of the smooth
computation scheme.
29

Denition 8.1. By a generalized linear function of n variables x1; :::; xn, we mean a
linear combination of functions 1, x1, ..., xn , and absolute values ja1x1 + ::: + an xn j of

homogeneous linear functions a1x1 + ::: + an xn .
Example. A function 1 + x1 + x2 + j2x1 ? x2j + jx + 3j is a generalized linear function.
LEMMA 1. For every smooth computation scheme S that computes a function
f (x1; :::; xn), and for every point ~s 2 Rn , the endpoints f~ of the result of smooth interval computations can be represented as
X
f (x1; :::; xn)  f~i (x1 ? s1; :::; xn ? sn)i + O(2i ) + O((xi ? si )2j )
for some generalized linear functions f~i .

Proof of Lemma 1. We will prove this lemma using induction over the number of steps

in a smooth computation scheme.
Induction base. If a smooth computation scheme has not steps at all, this means that the
function that we are computing simply coincides with one of the input variables. For an
input variable xi , each endpoint xi of the interval [xi ? i ; xi + i ] is already represented
in the desired form with f~i = 1, and f~j = 0 for j 6= i.
Induction step. Assume now that we have proved this result for all smooth computation
schemes of length  k, and we want to prove it for smooth computation schemes of length
k +1. Let S be any smooth computation scheme of length k +1. By denition of a smooth
computation scheme, the nal result of S is obtained in the last ((k + 1)?st) step by
applying a smooth function of one or two variables to the results of previous computations.
These results of previous computations are thus computable by computation schemes of
length  k. Therefore, for these results, due to the induction assumption, the result can be
represented in the desired form. Let us use these forms to describe the result of applying
(k + 1)?st step.
To prove it, we will consider two possible cases:
 The rst case if when the last step of S consists of applying a smooth function of one
variable.
 The second case if when the last step of S consists of applying a smooth function of
two variables.
In the rst case, f (x1; :::; xn) = F (r(x1; :::; xn)), and the result of applying smooth interval
computations to r is already known to be expressible in the form
[r(x1; :::; xn) ? l + O(2i ) + O((xi ? si )2  j ); r(x1; :::; xn) + l + O(2i ) + O((xi ? si )2  j )];
30

where l = r~1 1 + ::: + r~n n is a linear expression in i , with coecients r~i that are
generalized linear function in xi ? si . Similarly to the proof of Proposition 3.1, we can
prove that applying F results in an interval [y?; y+], where

y = F (r(x1; :::; xn))  jF 0 (r(x1; :::; xn))j  l + O((xi ? si )2  j ):
To prove the desired result, let us rst approximate jF 0 (r(x1; :::; xn))j by a generalized
linear function. To do that, we can rst approximate the composition F 0 (r(x1; :::; xn))
by a generalized linear function. This part is easy: Since both F 0 and r are smooth
functions, we conclude that F 0 (r(x1; :::; xn)) is also a smooth function, and therefore, it
can be represented as a0 + a1 (x1 ? s1) + ::: + an(xn ? sn ) + O((xi ? si )2).
 If a0 = 0, then the absolute value of this function can be represented as

ja1(x1 ? s1) + ::: + an (xn ? sn )j + O((xi ? si)2 );
i.e., as a generalized linear function plus O(:::).
 If a0 6= 0, then a0 +P ai (xi ?si ) = a0 (1+P(ai =a0)(xi ?si )). The absolute value of the
product can be represented as the product of the absolute values. When xi ! si , then
P(ai=a0)(xi ?si) ! 0, hence P(ai=a0)(xi ?si) > ?1, and so, j1+P(ai=a0)(xi ?si)j =
P
1+ (ai =a0)(xi ? si )+ O((xi ? si )2). Therefore, ja0 + a1 (x1 ? s1)+ ::: + an(xn ? sn )j =
ja0j(1 + P(ai =a0)(xi ? si)) + O((xi ? si )2) is a linear (and thus, generalized linear)
function of xi ? si .
In both cases, we represent jF 0(r(x1; :::; xn))j as a sum of the generalized linear function g~ and an O((xi ? si)2 ) term. Therefore, the product jF 0 (r(x1; :::; xn)))j  l =
jF 0 (r(x1; :::; xn)))j  r~1 1 + ::: + jF 0(r(x1; :::; xn)))j  r~n n can be represented as

g~  r~1  1 + ::: + g~  r~n  n + O((xi ? si )2j ):
For every i, the coecient g~  r~i at i is a product of two generalized linear functions.
By denition, each generalized linear function is a sum of a constant (maybe 0), and a
homogeneous rst order part (i.e., terms ai xi and ja1x1 + ::: + an xn j). The product g~  r~i of
two generalized linear functions g~ and r~i is thus a product of two sums and can, therefore,
be represented as a sum of four terms:
 a product of two constants, which is a constant;
 a product of a constant term of g~ and a homogeneous rst order part of r~i , which is
a generalized linear function;
 a product of a constant term of r~i and a homogeneous rst order part of g~, which is
also a generalized linear function;
31

 a product of a homogeneous rst order parts of g~ and r~i , which is O((xi ? si)2 ).
The sum f~i of the rst three products is generalized linear function; the fourth term lead
to the term O((xi ? si )2 i ) in g~  r~i  i. Therefore, g~  r~i i = f~i i + O((xi ? si )2  j ) for
a generalized linear function f~i . So, jF 0 (r(x1; :::; xn))j  l = L + O((xi ? si )2  j ), where
L = f~11 + ::: + f~n n , f~i are generalized linear, and therefore, the resulting interval is
indeed equal to the desired expression [f (x1; :::; xn) ? L + O(:::); f (x1; :::; xn) + L + O(:::)].
The second case can be described in a similar manner. In this case, instead of f =
F (r), we have f (x1; :::; xn) = F (r(x1; :::; xn); t(x1; :::; xn)) for some functions r and t that
have been computed on the previous steps. The resulting proof is similar. The lemma is
proved. Q.E.D.

LEMMA 2. Let S be a smooth computation scheme that computes a function f (x1; :::; xn),
and let ~s 2 Rn. Then, jf;ij  f~i + O((xi ? si)2 ), where f~i are generalized linear functions
that appear (as coecients at i ) in the description of the result of applying smooth interval
computations.

Proof of Lemma 2. For interval computations, the resulting interval always contains the

actual interval of values of f . Due to Lemma 1, the endpoints of the resulting interval are
f  (f~1 1 + ::: + f~n n )+ O(:::), and due to the Proposition, the endpoints of the interval of
values of f are f  (jf;1j1 + ::: + jf;n jn )+ O(:::). The fact that the rst interval contains
the second one means, in particular, that the width of the rst interval is  than the width
of the second interval, i.e., that f~1 1 + ::: + f~n n  jf;1j1 + ::: + jf;n jn + O(:::). If
we x i, choose i = 1 for this i, and j = 0 for all j 6= i, we get the desired inequality.
Q.E.D.

LEMMA 3. Let S be a smooth computation scheme that computes a function f (x1; :::; xn),
and let ~s 2 Rn . Then, the following statements are equivalent to each other:
 for S , smooth interval computations are locally asymptotically correct in the neighborhood of ~s;
 jf;i j = f~i + O((xi ? si )2), where f~i are generalized linear functions that appear (as
coecients at i ) in the description of the result of applying smooth interval computations.

Proof of Lemma 3. This result immediately follows from Lemma 1 and Proposition 3.1.

Q.E.D.

Proof of Theorem 3.3 itself. Let us now prove Theorem 3.3 itself. By denition, each
step of a smooth computation scheme S that does not assign a constant value to a variable
32

(i.e., that is not of the type Ri = fci g), consists of applying a function of one or two
variables either to initial data xi , or to the values computed on one of the previous steps.
The last step of the scheme S cannot be of the form Ri = fci g since otherwise the
function would have no non-degenerate stationary point. Therefore, the last step of the
scheme S can consists of applying either:
 a function of one variable, or
 a function of two variables.
Let us prove the theorem for these two cases.
First case: the last step consists of applying a function of one variable. Let us
rst show that this last step cannot consist of applying a smooth function of one variable.
We will prove this statement by reduction to a contradiction. Assume that the last step of
S does consist in applying a smooth function of one variable F to the result r(x1 ; :::; xn)
of some previous step. In this case, f (x1; :::; xn) = F (r(x1; :::; xn)). Let us prove that r(~x)
has a non-degenerate stationary point (at the same ~s), and that for this function r, smooth
interval computations are locally asymptotically correct in the neighborhood of ~s.
Indeed, we know that ~s is a stationary point for f , i.e., that f;i (s1; :::; sn) = 0. Since
f (x1; :::; xn) = F (r(x1; :::; xn)), we have f;i (s1; :::; sn) = F 0 (r(s1; :::; sn))  r;i (s1; :::; sn).
Similarly, f;ij (~s) = F 00 (r(~s))r;i(~s)r;j (~s)+ F 0 (r(~s))  r;ij (~s). Since f;i(~s) = 0, we can conclude
that either F 0 (r(~s)) = 0, or r;i (~s) = 0. In the rst case, f;ij = F 00 (~s)r;i r;j , and the
determinant of the Hessian at ~s is 0, which contradicts to our assumption that ~s is a nondegenerate point. Therefore, F 0 (~s) 6= 0, and r;i (~s) = 0, and ~s is a stationary point of the
function r(x1; :::; xn).
Since F 0 (r(~s)) 6= 0 and r;i (~s) = 0, from f;ij (~s) = F 00(r(~s))r;i (~s)r;j (~s)+ F 0 (r(~s))  r;ij (~s),
we can conclude that f;ij (~s) = F 0 (r(~s))  r;ij (~s), and r;ij (~s) = C  f;ij (~s), where C =
1=F 0(r(~s)). Since ~s is a non-degenerate stationary point of f , we have f;ij 6= 0, hence
r;ij (~s) = C  f;ij (~s) 6= 0. Similarly, from det jf;ij j 6= 0, we conclude that det jr;ij j 6= 0. So,
~s is a non-degenerate stationary point for the function r.
Let us now show that for the smooth computation scheme that leads to r, smooth
interval computations are locally asymptotically correct in the neighborhood of ~s. Indeed,
let r~i be the generalized linear functions that appear (as coecients at i ) in the description of the result of applying smooth interval computations to r. This means that after
we reach r, the resulting interval is equal to r  (~r11 + ::: + r~n n ) + O(:::). Due to
Proposition 3.1, after applying the function F to this interval, we get
F (r)  jF 0 (r(x1; :::; xn))j(~r11 + ::: + r~n n ) + O(:::):
33

Now, since F 0 (r) is a smooth function, we get

F 0 (r(x1; :::; xn)) = F 0 (r(~s)) +

X F 00(r(~s))r (x ? s ) + O((x ? s )2):
;i i

i

i

i

Since ~s is a stationary point for r, we have r;i (~s) = 0, and therefore, F 0 (r(x1; :::; xn)) =
F 0 (r(~s))+ O((xi ? si )2) and jF 0(r(x1; :::; xn))j = jF 0 (r(~s))j + O((xi ? si )2). So, the result of
applying smooth interval computations to S is equal to F (r)jF 0 (r(~s))j(~r11 +:::+~rn n )+
O(:::). Since for f and S , smooth interval computations are locally asymptotically correct,
we can (due to Lemma 3) conclude that for all i, jF 0 (r(~s))j  r~i (~x) = jf;i(~x)j + O(:::). But,
since f (~x) = F (r(~x)), we have f;i (~x) = F 0 (r(~x))r;i (~x) and jf;i(~x)j = jF 0 (r(~x))j  jr;i(~x)j.
We already know that jF 0(r(x1; :::; xn))j = jF 0(r(~s))j + O((xi ? si )2). Therefore, jf;i (~x)j =
jF 0 (r(~s))j  jr;i(~x)j + O(:::). So, from

jF 0 (r(~s))j  r~i (~x) = jf;i(~x)j + O(:::) = jF 0 (r(~s))j  jr;i(~x)j + O(:::);
we can conclude that r~i (~x) = jr;i (~x)j + O(:::), and hence, due to Lemma 3, that for r,
smooth interval computations are locally asymptotically correct.
Since r is computed on a previous step of the smooth computation scheme S , the
number of steps that lead to r is smaller than the number of computation steps in a scheme
S , and this contradicts to our choice of S as the shortest smooth computation scheme that
leads to a smooth non-degenerate function for which smooth interval computations are
locally asymptotically correct. So, the last step of our smooth computation scheme S
cannot consist of applying a function of one variable.

Second case: the last step consists of applying a function of two variables. To

complete our proof, let us show that the last step cannot consist of applying a function of
two variables. Indeed, suppose that the last step consists of applying a smooth function
F of two variables to two functions r(~x) and t(~x) that have been computed on a previous
computation step. In this case, f;i = F;r  r;i + F;t  t;i , where by F;r and F;t, we denoted
partial derivatives of F w.r.t. r and t.

Let us rst show that for ~s, both partial derivatives of F cannot be 0. Indeed, suppose
that they are. For f = F (r; t), the Hessian matrix is equal to f;ij (~x) = F;rr (~x)r;ir;j +
2F;rt (~x)r;i t;j + F;tt (~x)t;i t;j + F;r (~x)r;ij + F;t (~x)t;ij . In particular, for ~x = ~s, taking into
consideration that F;r = F;t = 0, we conclude that f;ij (~s) = F;rr (~s)r;ir;j + 2F;rt (~s)r;i t;j +
F;tt (~s)t;i t;j . If we choose vectors r;i (~s) and t;i(~s) as the rst two elements of the base, then
the Hessian matrix will only have 11, 12, and 22 components. Therefore, the determinant
34

of the Hessian matrix f;ij (~s) will be 0, which contradicts to our assumption that the
stationary point ~s is non-degenerate. This contradiction shows that the derivatives F;r (~s)
and F;t (~s) cannot be both equal to 0. Hence, we only need to consider the following three
subcases:
 F;r (r(~s); t(~s)) 6= 0 and F;t(r(~s); t(~s)) 6= 0.
 F;r (r(~s); t(~s)) 6= 0 and F;t(r(~s); t(~s)) = 0.
 F;r (r(~s); t(~s)) = 0 and F;t(r(~s); t(~s)) 6= 0.
We will analyze these three subcases separately.

First subcase of the second case: both partial derivatives of F are dierent
from 0 at ~s. Let us rst consider the case when both partial derivatives of F are dierent

from 0 at ~s. Let us show that in this case, r;i (~s) = t;i (~s) = 0. Indeed, the interval that
P
corresponds to r is equal to r  r~i i + O(:::), and the interval that corresponds to t is
P
equal to t  t~i i + O(:::). Due to Proposition 3.1, the interval that corresponds to f is
P
thus equal to f  f~i i +O(:::), where f~i (~x) = jF;r (~x)jr~i(~x)+jF;t(~x)jt~i(~x)+O((xi ?si )2 ).
Let us analyze this equality for ~x = ~s. For this ~x, the O term is equal to 0, so we have an
exact equality f~i (~x) = jF;r (~x)j  r~i (~x) + jF;t(~x)j  t~i (~x). Since smooth interval computations
are locally asymptotically correct for f , we have (due to Lemma 2) f~i = jf;ij + O((xi ? si )2 ).
In particular, for ~x = ~s, we have f~;i (~s) = jf;i(~x)j = 0. So, the left-hand side of the equality
is 0: 0 = jF;r (~s)j r~i(~s)+ jF;t(~s)j t~i(~s). The coecients r~i and t~i are non-negative for all ~x.
So, 0 is equal to the sum of two non-negative products (jF;r (~s)j  r~i (~s) and jF;t(~s)j  t~i (~s)).
The only way for this to happen is when both products are equal to 0. Since F;r 6= 0 for
~x = ~s, from jF;r (~s)j  r~i (~s) = 0, it follows that r;i(~s) = 0. Similarly, we can conclude that
t;i (~s) = 0.
Due to r;i (~s) = t;i (~s) = 0, we can (similarly to the case of f = F (r)) conclude that
F (~x) = F (~s)+ O((xi ? si )2 ). Therefore, f~i (~x) = jF;r (~s)jr~i (~x)+ jF;t (~s)jt~i(~x)+ O(:::). On the
other hand, f~i = jf;ij + O(:::), where f;i (~x) = F;r (~x)r;i(~x)+ F;t (~x)t;i (~x), and due to F (~x) =
F (~s)+ O((xi ? si )2), we can rewrite this equality as f;i (~x) = F;r (~s)r;i (~x)+ F;t (~s)t;i(~x). So,

f~i = jf;ij + O(:::) = jF;r (~s)r;i(~x) + F;t (~s)t;i(~x)j + O(:::):
Since jp + qj  jpj + jqj, we conclude that

f~i  jF;r  r;i + F;t  t;ij + O(:::)  jF;r j  jr;i j + jF;tj  jt;i j + O(:::):
Due to Lemma 2, jr;ij  r~i + O(:::) and jt;i j  t~i + O(:::). Therefore,

f~i  jF;r  r;i + F;t  t;ij + O(:::)  jF;r jjr;ij + jF;tjjt;ij + O(:::)  jF;r j r~i + jF;t j t~i + O(:::):
35

But the right-hand side of this inequality is already known to be equal to f~i (~x) (modulo
quadratic terms). Therefore,

f~i  jF;r  r;i + F;t  t;ij + O(:::)  jF;r j  jr;ij + jF;tj  jt;ij + O(:::)  f~i + O(::):
In this chain of inequalities the starting and the ending expressions coincide, and hence,
they are all equalities. So,

jF;r  r;i + F;t  t;i j = jF;r j  jr;i j + jF;t j  jt;i j + O(:::):
The only case when jp + qj = jpj + jqj is when p and q are of the same sign. So, we can
conclude that the linear parts of the expressions F;r (~s)  r;i (~x) and F;t (~s)  t;i(~x) are of the
same sign. Clearly, the sign of the linear part of

f;i = F;r (~s)  r;i(~x) + F;t(~s)  t;i(~x) + O(:::)

P

will be of the same sign. This linear part is f;ij (~s)(xj ? sj ). Similarly, we can express
the linear parts of r;i and t;i . We know that the numbers F;r (~s) and F;t (~s) are dierent
from 0. Let us assume that both numbers are positive (the cases when one of them
is negative can be treated in a similar manner). In this case, if a linear term in f;i
then the linear terms in r;i and t;i are also non-negative. In other words, if
Pis positive,
P
f
;ij (~s)(xj ? sj ) > 0, then f;ij (~s)(xj ? sj )  0. Turning to a limit, we can conclude that
P
P
P
if f;ij (~s)(xj ? sj )  0, then f;ij (~s)(xj ? sj )  0. Similarly, if f;ij (~s)(xj ? sj )  0,
P
P
then f;ij (~s)(xj ? sj )  0. Therefore, if f;ij (~s)(xj ? sj ) = 0, then we have both
P f;ij (~s)(xj ?sj )  0 and P f;ij (~s)(xj ?sj )  0, hence, we have both P r;ij (~s)(xj ?sj )  0
P
P
and r;ij (~s)(xj ? sj )  0, and thence, r;ij (~s)(xj ? sj ) = 0.

P

P

So, if f;ij (~s)(xj ? sj ) = 0, then r;ij (~s)(xj ? sj ) = 0. In geometric terms, the
condition means that a vector xj ? sj is orthogonal to the vector f~i with coordinates
f;i1(~s); :::; f;in(~s). Similarly, the conclusion means that a vector xj ? sj is orthogonal to
the vector ~ri with coordinates r;ij (~s). Since ~s is a non-degenerate stationary point, the
vector f~i is not zero, and therefore, vectors that are orthogonal to f~i form a (hyper)plane.
A vector ~ri is orthogonal to every vector from this (hyper)plane, and is, therefore, collinear
with f~i . This means that for every i, there exists a constant ci such that r;ij (~s) = ci f;ij (~s)
for all i and j .
The matrix of second derivatives is symmetric: r;ij = r;ji . Therefore, for every i and
j , ci f;ij = cj f;ji. Since second derivatives of f;ij also form a symmetric matrix, we have
36

ci f;ij = cj f;ij . Due to the fact that ~s is a non-degenerate stationary point for f , we conclude
that f;ij =
6 0 and therefore, ci = cj for all i and j . Let us denote the common value of all ci
by c. Then, r;ij (~s) = cf;ij (~s). Similarly, t;ij (~s) = c0 f;ij (~s). The coecients c and c0 cannot
be both equal to 0, because then, we would have f;ij (~s) = F;r (~s)rij (~s) + F;t (~s)t;ij (~s) = 0.
So, either c =
6 0, or c0 =
6 0. If c =6 0, then r;ij (~s) = cf;ij (~s) is a non-degenerate matrix
with non-zero determinant and all elements non-zero. Therefore, r is a function that has
a non-degenerate stationary point at ~s, and that can be computed in fewer steps than
f , which contradicts to our choice of f . Similarly, if c0 =
6 0, then t is a function that
contradicts to our choice of f . In both cases, we get a contradiction.

Second and third subcases of the second case: only one partial derivative of
F is dierent from 0 at ~s. We have derived a contradiction for the case when both
partial derivatives F;r (~s) =
6 0 and F;t (~s) =
6 0. To complete the proof of the theorem, we

must deduce a contradiction for the case when one of these partial derivatives is equal to
0. Without losing generality, we can assume that F;r (~s) 6= 0 and F;t (~s) = 0.
In this subcase, from the equality f~i (~x) = jF;r (~x)j  r~i (~x) + jF;t (~x)j  t~i (~x) (that can be
proven exactly like in the rst subcase), we conclude that r;i (~s) = 0.

P

Since F;t (~s) = 0, we can conclude that F;t (~s) = aj (xj ?sj )+O((xi ?si )2 ). Therefore,
only zeroth-order terms in t;i (~x) need to be taken into consideration, and we have

f;i (~x) =

Xf

;ij (xj ? sj )+ O(:::) = F;r (~s)

Xr

;ij (~s)(xj ? sj )+(

X a (x ? s ))t (~s)+ O(:::):
j j

j

;i

Similarly to the rst subcase, we can prove that the two linear components of this sum
must be of the same sign as fi , and therefore, that r;ij = cf;ij and aj t;i = c0 f;ij . The
coecient c0 cannot be dierent from 0, because then, we would have f;ij = (1=c0)aj t;i,
and det jf;ij j = 0,which contradicts to our assumption that the Hessian matrix f;ij is nondegenerate. Therefore, c0 = 0, and hence, c = 0 is impossible. Therefore, r;ij = (1=c)f;ij ,
and r is a function that has a non-degenerate stationary point at ~s, and that can be
computed in fewer steps than f , which contradicts to our choice of f .
We have proven the result for the rst case, and for all subcases of the second case;
therefore, the theorem is proven. Q.E.D.

Proof of Theorem 3.4
Since the function f is smooth, for every point ~s, we have f (~x) = fquadr(~x)+ O((xi ? si )3 ),
where
X
X
fquadr = f (~s) + f;i(~s)(xi ? si ) + 21 f;ij (xi ? si )(xj ? sj ):
i;j

i

37

Therefore (similarly to the proof of Proposition 3.1), we can conclude that the dierence
between the intervals f (X1; :::; Xn) and fquadr (X1; :::; Xn) is also O((xi ? si )3). The function fquadr is quadratic in xi , so, we can represent it as

fquadr(x1; :::; xn) = a0 +

Xa x + Xa
i

i i

i;j

ij xi xj

for some real numbers ai and aij . If we dene a0i = ai for i = 0; 1; :::; n, then we can
represent this expression as fquadr(x1 ; :::; xn) = g(x0; x1; :::; xn) for x0 = 1 and

g(x0; :::; xn) =

Xn Xn a
i=0 j =0

ij xi xj :

The function g, in its turn, can be represented as a result of applying n simplications
xi = yi , 1  i  n, to a weighted scalar product

f (x0; x1; :::; xn; y0; y1; :::; yn) =

Xn Xn a
i=0 j =0

ij xi yj

with weights aij .
So, fquadr can be computed using a computation scheme S with weighted scalar products. Since the dierence between the intervals f (X1; :::; Xn) and fquadr(X1; :::; Xn) is
O((xi ? si )3 ), we can conclude that smooth interval computations described by the scheme
S are locally asymptotically correct for the original function f . Q.E.D.

Proof of Proposition 5.1
1. Let us prove this Proposition by reduction to a contradiction. Namely, assume that
f : K ! R is strictly monotonic in each variable, and that f is degenerate. By denition,
this means that K can be represented as a union of nitely many sets K1 ; :::; Kp on each
of which f is equal to a function of two of fewer variables. Let's deduce a contradiction
from here.
2. Since the interior of M  K is non-empty, the set M contains a ball.
Inside the ball, we can place a cube [a1; b1]  [a2; b2]  :::  [an ; bn]. Let's divide each
side [ai ; bi] of the cube into p + 1 equally distanced values of xi : ai , ai + (bi ? ai )=p,
ai + 2  (bi ? ai)=p, ..., ai + p  (bi ? ai )=p = bi . By combining these values for dierent i,
we get (p + 1)n dierent points that all belong to the cube and therefore, to K . Let us
denote the set of all these points by P .
38

3. Let us take one of the sets Ki , and let us estimate how many of the points from P
belong to Ki . Since f is degenerate of Ki , it means that on Ki f is equal to a function
of two or fewer variables. But f is a function of n  3 variables. So, this means, that for
~x 2 Ki , f cannot depend on all the variables. Hence, it does not depend on one of the
variables. Let us denote one of such variables by xj . The fact that for ~x 2 Ki , f does not
depend on xj , means that if we have two dierent points with dierent values of xj and
equal values of all other coordinates, then the value of f for both point will be the same.
4. Formally, if ~x = (x1; :::; xj?1; xj ; xj+1; :::; xn) 2 P  M and

~y = (x1 ; :::; xj?1; xj + xj ; xj+1; :::; xn) 2 M;
where xj 6= 0, then f (~x) = f (~y).
But on M , f is strictly monotonic in each variable. This means, in particular, that f
is either strictly increasing in xj , or strictly decreasing in xj . In both cases, f (~x) 6= f (~y).
This contradiction with f (~x) = f (~y) shows that no such pairs (~x; ~y) are possible. In other
words, if we x the values of n ? 1 coordinates (all of them except for xj ), i.e., if we
x the values x1; :::; xj?1; xj+1; :::; xn, then at most one point with these values of n ? 1
coordinates belongs to Ki .
5. For P , if we x the values of all the coordinates but one, then, we can choose p + 1
dierent values of xj and hence, have p + 1 dierent points from P  K . At most one of
them belongs to Ki. Therefore, Ki contains at most 1=(p + 1) part of all the points from
P.
6. The same inequality is true for each of the sets Ki . So, totally, p sets K1, ..., Kp contain
 p=(p + 1) of all the points from P . Since p=(p + 1) < 1, it means that there are points
from P (and hence from K ) that are not covered by any of the sets Ki . This contradicts
to our assumption that f is degenerate and K = [Ki .
This contradiction shows that our assumption was false, and so f is not degenerate.
Q.E.D.

Proof of Proposition 5.2
Let us show that if a real analytic function f (x1; :::; xn) does not coincide with a function
of less than n variables, then it is non-degenerate in the sense of Denition 5.2. Indeed, an
arbitrary real analytic function g(x1; :::; xn) has the following property (similar to complex
analytical functions): it is either identically equal to 0, or it is equal to 0 on a set of
(Lebesgue) measure 0 (i.e., it is dierent from 0 on a set of full measure) (see, e.g., [17]).
39

Also, for an arbitrary real analytic function, each of its derivatives is also real analytic.
In particular, the partial derivative @f=@x1 of the given function is real analytic. If it was
identically equal to 0, then f would not depend on x1 at all. Therefore, according to the
above-cited result, the set of points (x1 ; :::; xn) on which this derivative is equal to 0 is of
Lebesgue measure 0. Similarly, for each i = 2; :::; n, the set of all points (x1 ; :::; xn), at
which i?th partial derivative @f=@xi is equal to zero, is also of measure 0.
Therefore, the union of these n sets, i.e., the set of all points on which at least one of
the partial derivatives is dierent from 0, is also of measure 0 (as a union of measure-zero
(0)
sets). Therefore, there exists a point (x(0)
1 ; :::; xn ) that does not belong to this union. By
denition of the union it means that in this point, all n partial derivatives are dierent
from 0.
These derivatives are real analytic and therefore, continuous. Therefore, there exists
(0)
a spherical neighborhood M of this point (x(0)
1 ; :::; xn ) in which sign of each of the partial
(0)
derivatives coincides with its sign at the point (x(0)
1 ; :::; xn ). For those i for which this
sign is positive (@f=@xi > 0), f is strictly increasing in xi . For those i for which this sign
is negative (@f=@xi < 0), f is strictly decreasing in xi . So, for all points from a set M
with a non-empty interior, the function f is strictly monotonic in each variable. Therefore,
according to Proposition 5.1, this function f is non-degenerate. Q.E.D.

Proof of Theorem 5.1
1. Let us prove this theorem by reduction to a contradiction. Namely, we will assume that
there exists a non-degenerate function f and a computation scheme S that computes f and
that is precise for all (crisp) sets, and we will deduce a contradiction from this assumption.
To deduce this contradiction, we will use the following observation: According to our
denitions, the phrase \S is precise for all (crisp) sets" means that for every (crisp) set
X  Rn , the result RN of applying S to X coincides with f (X ).
In this proof, we will need the following two Lemmas:

LEMMA 4. Assume that a function f : K ! R (K  Rn ) is computed by a composition
scheme S , and X  K . Let's denote by RN the result of applying S to X . Then, f (X ) 
RN .

Proof of Lemma 4. This Lemma is similar to the Main Theorem of Interval Computa-

tions (see, e.g., [29]), and is proved similarly: namely, using induction, one can then prove
that for every i, ri (X )  Ri. For i = N , we get the desired result. Q.E.D.
40

LEMMA 5. Assume that k is an integer, f : R ! R, g : Rk ! R, and h : Rk ! R
is a composition of f and g (i.e., h(~x) = f (g(~x))). Then, for every (crisp) set X  Rk ,

h(X ) = f (g(X )).

Proof of Lemma 5 follows directly from the denitions. Q.E.D.
2. We will need the following auxiliary notion: by a complexity of a computation scheme
S = (Sn+1 ; :::; SN ), we will understand the number N .
We assumed that there exists a computation scheme that computes a non-degenerate
function of n variables and that is precise for all (crisp) sets. Out of all computation
schemes with this property, there exists a one with the smallest possible complexity N .
Let's choose one of these \simplest" schemes. In the following text, this chosen scheme
will be denoted by Ss (s stands for simplest). The corresponding function will be denoted
by fs .
Comment. A computation scheme Ss consists of the rules of the type ri := ci , ri := fi (rj ),
and ri := fi (rj ; rk ). In principle, the corresponding functions fi can be dened everywhere.
However, when we apply this computation scheme to compute the value of the function fs
that is dened on some set K , we will use only the values of fi for rj 2 ri (K ); or, for the
function of two variables, only the values for (rj ; rk ) 2 Djk , where

Djk = f(a; b) j 9~x (~x 2 K & rj (~x) = a & rk (~x) = bg:
Therefore, to simplify our proofs, we will assume in the following text that fi is dened
only for these values.
It is easy to check that if initially Ss computed fs and was precise for all (crisp) sets,
then after such a restriction on fi it still has the same properties.
3. Depending on what the nal step SN of Ss is, we have the following ve possibilities:
 N  n;
 N > n and rN := cN ;
 N > n and rN := fN (rj ), where j < N ;
 N > n and rN := fN (rj ; rk ), where j  n and k  n;
 N > n and rN := fN (rj ; rk ), where j > n or k > n.
In the following ve subsections, we will prove that in all these ve cases, we have a
contradiction with our initial assumption.
4. N  n.
41

In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = xN . So, fs depends only on one of its
variables. Hence, fs is degenerate, which contradicts to the assumption that it is nondegenerate.
5. N > n and rN := cN .
In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = cN does not depend on any variables at
all. Therefore, it is degenerate.
6. N > n and rN := fN (rj ), where j < N .
Let us prove (by considering all possible cases) that this case is impossible. Depending
on the case, we will prove it either directly, or by \merging" the last step with one of the
previous ones, and thus coming up with a new computation scheme that is simpler than
the scheme Ss that is by denition the simplest possible (so, we have a contradiction).
6.1. If j  n, then rj = xj , and fs = fN (rj ) = fN (xj ) is a function of one variable (namely,
xj ) and is thus degenerate, which contradicts to our choice of fs.
6.2. If j > n, and j ?th step is rj := cj , then fs = rN = fN (cj ) =const, i.e., fs is also
degenerate.
6.3. If j > n, and j ?th step is rj := fj (rk ) for some k < j , then rN = fN (fj (rk )). In
other words, rN = f~N (rk ), where by f~N , we denoted the composition of fN and fj .
6.3.1. If k  n, then fs is again a function of one variable xk (i.e., degenerate).
6.3.2. If k > n, then, we can replace the original computation scheme S with the
following simplied one: S~ = (Sn+1 ; :::; Sk ; S~N ), where by S~N , we denoted the
following step: rN := f~N (rk ). Because of our formulas, this scheme computes
exactly the same function fs . The fact that this scheme computes the same
function and is precise for all (crisp) sets, follows from Lemma 5.
Since we deleted at least one step (Sj ), this new scheme has a smaller complexity
that Ss . This contradicts to our choice of Ss as the computation scheme with
the smallest possible complexity that computes a non-degenerate function of 3 or
more variables and that is precise for all (crisp) sets.
6.4 If j > n, and j ?th step is rj := fj (rk ; rl ) for some k; l < j , then rN = fN (fj (rk ; rl)) =
f~N (rk ; rl ), where by f~N , we denoted a composition f~N (a; b) = fN (fj (a; b)). In this
case, we can also delete one step from the computation scheme and thus arrive at the
contradiction.
42

7. N > n and rN := fN (rj ; rk ), where j  n and k  n.
In this case, fs (x1; :::; xn) = rN (x1; :::; xn) = fN (xj ; xk ). Hence, fs depends on only
two of its variables, and is therefore degenerate.
8. N > n and rN := fN (rj ; rk ), where j > n or k > n.
8.1. We assumed that Ss computes fs , and that Ss is precise for all (crisp) sets. This
means, in particular, that for each input set X  K , RN = fs(X ). In particular, if we
take arbitrary two elements ~x 2 K and ~y 2 K , then this equality must be true for a 2-point
set X = f~x; ~yg.
8.2. For this choice of X , the right-hand side of the equality RN = fs (X ) (i.e., the
set fs(X )) is easy to describe: it consists of two values fs (~x) = fN (rj (~x); rk (~x)) and
fs(~y) = fN (rj (~y); rk (~y)).
8.3. Now, let's nd an element of the left-hand side. By denition of RN , this set is
equal to RN = fN (Rj ; Rk ). Due to Lemma 4, Rj  rj (X ), and Rk  rk (X ). Since
rj (~x) 2 rj (X ), we can thus conclude that rj (~x) 2 Rj . Similarly, we can conclude that
rk (~y) 2 Rk . Therefore, fN (rj (~x); rk (~y)) 2 fN (Rj ; Rk ) = RN .
Since RN = fs(X ), every element of RN must coincide with one of the two elements
of fs (X ). In particular, for the above-discovered element, it means the following:
For every ~x 2 K and ~y 2 K , fN (rj (~x); rk (~y)) is either equal to fN (rj (~x); rk (~x)), or it is
equal to fN (rj (~y); rk (~y)).

8.4. This statement enables us to make the following conclusion about the function
fN (a; b):
If we can nd ~x and ~y such that a = rj (~x) and b = rk (~y), then either fN (a; b) =
fN (a; rk (~x)), or fN (a; b) = fN (rj (~y); b).

8.5. For each a 2 rj (K ), there exists a vector ~x for which rj (~x) = a (it is possible that
several such vectors exist). For dierent vectors ~x, the value rk (~x) may also be dierent.
For each a, let us pick one of these values rk (~x) and denote it by gkj (a).
Similarly, for each b 2 rk (K ), we will pick a vector ~x with the property that rk (~x) = b,
and denote the value rj (~x) for thus picked ~x by gjk (b).
8.6. Using these denotations, we can reformulate the statement from 8.4 as follows:
43

For every a 2 rj (K ) and b 2 rk (K ), either fN (a; b) = fN (a; gkj (a)), or fN (a; b) =
fN (gjk (b); b).

If we denote h1 (a) = fN (a; gkj (a)) and h2 (b) = fN (gjk (b); b), then we can further
simplify this conclusion:
For every (a; b) 2 Djk , either fN (a; b) = h1 (a), or fN (a; b) = h2 (b).
8.7. In particular, this property is true if we choose an arbitrary ~x 2 K and take a = rj (~x)
and b = rk (~x).
Let us denote by K1 the set of all ~x 2 K for which fN (rj (~x); rk (~x)) = h1 (rj (~x)), and
by K2, the set of all values ~x 2 K for which fN (rj (~x); rk (~x)) = h2 (rk (~x)). Then, this
property means that K = K1 [ K2.
8.8. Since the function f dened on K is non-degenerate, its restriction to either K1 or
K2 is also non-degenerate.
Indeed, if it were not true, then we would be able to describe both K1 and K2 (and
hence, their union) as the union of nitely many subsets on which fs is degenerate. On
the other hand, we assumed that fs : K ! R is non-degenerate, which means that for K ,
such a representation is impossible.
8.9. Let us choose a set Ki (i.e., K1 or K2) for which the restriction of fs is non-degenerate.
For this set, we can form the restriction of fs and Ss . For this restriction, we can take
rN := h1 (rj ) (or rN := h2 (rk )) as a last step of the computation scheme (instead of the step
rN := fN (rj ; rk )), and the resulting computation scheme will still compute the restriction
of fs , and it will still precise for all (crisp) sets.
If we were able to compute a non-degenerate function fs by another computation
scheme S1 whose complexity is < N computation steps, then we would get a contradiction with our choice of N as the smallest possible complexity of a computation scheme
that computes a non-degerenate function. Therefore, the resulting computation scheme is
still the \simplest" in the sense that its complexity N is the smallest possible among all
computation schemes that compute non-degenerate functions.
So, we arrive at the situation where we have the \simplest" computation scheme, and
the function at the last step is a function of one variable; we have already proved (in part
6 of this proof) that such situation leads to a contradiction.
9. So, in all ve cases, we arrive at a contradiction. Hence, our initial assumption is
false, namely, the assumption that a non-degenerate function of 3 or more variables can
44

be computed by a computation scheme (with unary and binary operations only) that is
precise for all (crisp) sets. Q.E.D.

CONCLUSIONS
Theoretical. The main theoretical result of this paper is that functions of several interval

or fuzzy variables cannot always be computed precisely if we use only operations with one or
two interval (resp. fuzzy) variables. Moreover, for smooth functions f , we show that even
the main term in the result of fuzzy (interval) computations cannot always be computed
correctly. The accuracy of interval and fuzzy data processing drastically improves if we
add weighted scalar product to the list of elementary (hardware supported) operations.
For numerical operands, scalar product is already hardware supported in modern
computers: by math co-processors. There have been successful attempts to hardware
support scalar product of interval operands.

Practical. Therefore, our main practical recommendation is that for fuzzy data processing,

it is desirable to hardware support (weighted) scalar product of fuzzy operands as well (at
least, some operations with three or more fuzzy operands).

Acknowledgments. This work was partially supported by NSF grants No. CDA-9015006

and No. EEC-9322370, by a Grant No. PF90{018 from the General Services Administration (GSA), administered by the Materials Research Institute and the Institute for
Manufacturing and Materials Management, and by a NASA grant No. NAG 9-757. The
authors are greatly thankful to Paul Kainen, Baker Kearfott, Vera Kurkova, and Reza Langari for valuable discussions, and to the anonymous referees for their extremely valuable
suggestions and help.

45

REFERENCES
[1] O. Artbauer, \Application of interval, statistical, and fuzzy methods to the evaluation
of measurements", Metrologia, 1988, Vol. 25, pp. 81{86.
[2] H. Dhirf and D. Sarkar, \Fuzzy arithmetic on systolic arrays", Parallel Computing,
1993, Vol. 19, pp. 1283{1301.
[3] W. M. Dong, W. L. Chiang, H. C. Shah, \Fuzzy information processing in seismic
hazard analysis and decision making", International Journal of Soil Dynamics and
Earthquake Engineering, 1987, Vol. 6, No. 4., pp. 220{226.
[4] W. Dong and F. Wong, \Fuzzy weighted averages and implementation of the extension
principle", Fuzzy Sets and Systems, 1987, Vol. 21, pp. 183{199.
[5] D. Dubois and H. Prade. Fuzzy sets and systems: theory and applications, Academic
Press, N.Y., London, 1980.
[6] H. L. Frisch, C. Borzi, G. Ord, J. K. Percus, and G. O. Williams, \Approximate Representation of Functions of Several Variables in Terms of Functions of One Variable",
Physical Review Letters, 1989, Vol. 63, No. 9, pp. 927{929.
[7] R. Fuller and T. Keresztfalvi, \On generalization of Nguyen's theorem", Fuzzy Sets
and Systems, 1990, Vol. 4, pp. 371{374.
[8] W. A. Fuller, Measurement error models, J. Wiley & Sons, New York, 1987.
[9] A. A. Gaganov, \Computational complexity of the range of the polynomial in several
variables", Cybernetics, 1985, pp. 418{421.
[10] R. Hammer, M. Hocks, U. Kulisch, D. Ratz, Numerical toolbox for veried computing.
I. Basic numerical problems, Springer Verlag, Heidelberg, N.Y., 1993.
[11] E. R. Hansen, Global optimization using interval analysis, Marcel Dekker, N.Y., 1992.
[12] R. Hecht-Nielsen, \Kolmogorov's Mapping Neural Network Existence Theorem",
IEEE International Conference on Neural Networks, San Diego, SOS Printing, 1987,
Vol. 2, pp. 11{14.
[13] D. Hilbert, \Mathematical Problems, lecture delivered before the International
Congress of Mathematics in Paris in 1900", translated in Bull. Amer. Math, Soc.,
1902, Vol. 8, pp. 437{479.
[14] R. B. Kearfott and V. Kreinovich (eds.), Applications of Interval Computations,
Kluwer, Dordrecht, 1996.
[15] A. N. Kolmogorov, \On the Representation of Continuous Functions of Several Variables by Superposition of Continuous Functions of One Variable and Addition", Dokl.
Akad. Nauk SSSR, 1957, Vol. 114, pp. 369{373.
[16] G. Klir and B. Yuan, Fuzzy sets and fuzzy logic: theory and applications, Prentice
46

[17]

[18]
[19]

[20]

[21]
[22]

[23]
[24]
[25]
[26]
[27]

Hall, Upper Saddle River, NJ, 1995.
V. Kreinovich, \On the problem of recovering the ?function in non-relativistic quantum mechanics", Teoreticheskaya i Mathematicheskaya Fizika, 1976, Vol. 28, No. 1,
pp. 56{64 (in Russian); English translation: Theoretical and Mathematical Physics,
1976, Vol. 8, No. 7, pp. 56{64.
V. Kreinovich (ed.), Reliable Computing, 1995, Supplement (Extended Abstracts of
APIC'95: International Workshop on Applications of Interval Computations, El Paso,
TX, Febr. 23{25, 1995).
V. Kreinovich, Ching-Chuang Chang, L. Reznik, G. N. Solopchenko, \Inverse problems: fuzzy representation of uncertainty generates a regularization", Proceedings
of NAFIPS'92: North American Fuzzy Information Processing Society Conference,
Puerto Vallarta, Mexico, December 15{17, 1992, NASA Johnson Space Center, Houston, TX, 1992, Vol. II, pp. 418{426.
V. Kreinovich, C. Quintana, L. Reznik, Gaussian membership functions are most
adequate in representing uncertainty in measurements, In: Proceedings of NAFIPS'92:
North American Fuzzy Information Processing Society Conference, Puerto Vallarta,
Mexico, December 15{17, 1992, NASA Johnson Space Center, Houston, TX, 1992,
Vol. II, pp. 618{624.
V. Kreinovich et al, What non-linearity to choose? Mathematical foundations of fuzzy
control, Proceedings of the 1992 International Conference on Fuzzy Systems and Intelligent Control, Louisville, KY, 1992, pp. 349{412.
V. Kreinovich and L. K. Reznik, \Methods and models of formalizing a priori information (on the example of processing measurements results)", In: Analysis and
Formalization of Computer Experiments, Proceedings of the Mendeleev Metrology Institute, 1986, pp.37{41 (in Russian).
U. Kulisch, G. Bohlender, \Features of a hardware implementation of an optimal
arithmetic", In: U. Kulisch, W. L. Miranker (eds), A new approach to scientic computation, Academic Press, Orlando, FL, 1983, pp. 269{290.
V. Kurkova, \Kolmogorov's Theorem Is Relevant", Neural Computation, 1991, Vol.
3, pp. 617{622.
V. Kurkova, \Kolmogorov's Theorem and Multilayer Neural Networks", Neural Networks, 1992, Vol. 5, pp. 501{506.
G. G. Lorentz, \The 13-th problem of Hilbert", in: F. E. Browder (ed.), Mathematical
Developments Arizing from Hilbert's Problems, American Math. Society, Providence,
RI, 1976, Part 2, pp. 419{430.
R. E. Moore, Automatic error analysis in digital computation, Lockheed Missiles and
47

[28]
[29]
[30]
[31]
[32]
[33]
[34]
[35]
[36]
[37]

[38]
[39]
[40]
[41]
[42]
[43]

Space Co. Technical Report LMSD-48421, Palo Alto, CA, 1959.
R. E. Moore, C. T. Yang, Interval analysis, Lockheed Missiles and Space Co. Technical
Report LMSD-285875, Palo Alto, CA, 1959.
R. E. Moore, Methods and applications of interval analysis, SIAM, Philadelphia, 1979.
M. Nakamura, R. Mines, V. Kreinovich, \Guaranteed Intervals for Kolmogorov's Theorem (and Their Possible Relation to Neural Networks)", Interval Computations, 1993,
No. 3, pp. 183{199.
M. Ness, \Approximative versions of Kolmogorov's superposition theorem, proved
constructively", J. Comput. Appl. Math., 1993.
V. M. Nesterov, \Interval analogues of Hilbert's 13th problem", In: Abstracts of the
Int'l Conference Interval'94, St. Petersburg, Russia, March 7{10, 1994, 185{186.
H. T. Nguyen, \A note on the extension principle for fuzzy sets", J. Math. Anal. and
Appl., 1978, Vol. 64, pp. 359{380.
H. T. Nguyen and E. A. Walker, A First Course in Fuzzy Logic, CRC Press, Boca
Raton, Florida, 1996 (to appear).
S. Rabinovich, Measurement errors: theory and practice, American Institute of
Physics, N.Y., 1993.
M. J. Schulte and E. E. Swartzlander, Jr., \Parallel Hardware Designs for Correctly
Rounded Elementary Functions", Interval Computations, 1993, No. 4, pp. 65{88.
M. J. Schulte and E. E. Swartzlander, Jr., \Design and applications for variableprecision, interval arithmetic coprocessors", In: V. Kreinovich (ed.), Reliable Computing, 1995, Supplement (Extended Abstracts of APIC'95: International Workshop
on Applications of Interval Computations, El Paso, TX, Febr. 23{25, 1995), pp.
166{172.
S. M. Shah and R. Horvath, A hardware digital fuzzy inference engine using standard
integrated circuits, Information Sciences, 1994, Vol. 1, pp. 1{7.
G. N. Solopchenko, \Formal metrological components of measuring systems", Measurement, 1994, Vol. 13, pp. 1{12.
D. A. Sprecher, \On the Structure of Continuous Functions of Several Variables",
Transactions Amer. Math. Soc., 1965, Vol. 115, No. 3, pp. 340{355.
D. A. Sprecher, \An Improvement in the Superposition Theorem of Kolmogorov",
Journal of Mathematical Analysis and Applications, 1972, Vol. 38, pp. 208{213.
H. Surmann et al., \What kind of hardware is necessary for a fuzzy rule based system?", In: Proceedings of the FUZZ-IEEE'94 International Conference, Orlando, FL,
July 1994, Vol. 1, pp. 274{278.
M. Takahashi, E. Sanchez, R. Bartolin, J. P. Aurrand-Lions, E. Akaiwa, T. Yamakawa,
48

[44]
[45]
[46]
[47]
[48]
[49]
[50]
[51]
[52]
[53]
[54]

and J. R. Monties, \Biomedical applications of fuzzy logic controllers", In: Intl. Conference on Fuzzy Logic and Neural Networks, Iizuka, Fukuoka, Japan, 1990, pp. 553{
556.
M. Togai and S. Chiu, \A fuzzy accelerator and a programming environment for realtime fuzzy control", In: Second IFSA Congress, Tokyo, Japan, 1987, pp. 147{151.
M. Togai and H. Watanabe, \Expert systems on a chip: an engine for real-time
approximate reasoning", IEEE Experts Systems Magazine, 1986, No. 1, pp. 55{62.
M. J. Tretter, \Interval analysis isn`t fuzzy is it?", Abstracts for an International
Conference on Numerical Analysis with Automatic Result Verication: Mathematics,
Application and Software, February 25 { March 1, 1993, Lafayette, LA, 1993, p. 104.
H. M. Wadsworth, Jr. (editor), Handbook of statistical methods for engineers and
scientists, McGraw-Hill Publishing Co., N.Y., 1990.
H. Watanabe and W. Detlo, \Recongurable fuzzy logic processor: a full custom
digital VLSI", In: Intl. Workshop on Fuzzy Systems Applications, Iizuka, Japan,
1988, pp. 49{50.
T. Yamakawa, \Fuzzy microprocessors { rule chip and defuzzier chip", In: Intl.
Workshop on Fuzzy Systems Applications, Iizuka, Japan, 1988, pp. 51{52.
T. Yamakawa, \Intrinsic fuzzy electronic circuits for sixth generation computer", In:
M. M. Gupta and T. Yamakawa (eds.), Fuzzy Computing, Elsevier, 1988, pp. 157{181.
H. Q. Yang, H. Yao, and J. D. Jones, \Calculating functions of fuzzy numbers", Fuzzy
Sets and Systems, 1993, Vol. 55, pp. 273{283.
Y. Yoshikawa, T. Deguchi, and T. Yamakawa, \Exclusive fuzzy hardware systems for
the appraisal of orthodentic results", In: Intl. Conference on Fuzzy Logic and Neural
Networks, Iizuka, Fukuoka, Japan, 1990, pp. 939{942.
L. A. Zadeh, \Fuzzy sets", Information and control, 1965, Vol. 8, pp. 338{353.
L. A. Zadeh, Outline of a new approach to the analysis of complex systems and decision
processes, IEEE Transactions on Systems, Man and Cybernetics, 1973, Vol. 3, pp.
28{44.

49
The author has requested enhancement of the downloaded file. All in-text references underlined in blue are linked to publications on ResearchGate.

Genomic Information Retrieval through Selective Extraction and
Tagging by the ASU-BioAI Group
Lian Yu, Syed Toufeeq Ahmed, Graciela Gonzalez, Brandon Logsdon, Mutsumi Nakamura, Shawn
Nikkila, Kalpesh Shah, Luis Tari, Ryan Wendt, Amanda Zeigler, Chitta Baral
Department of Computer Science and Engineering,
Arizona State University,
PO Box 878809,
Tempe, AZ 85287-8809, USA
ABSTRACT
In this paper we describe the approach used by the Arizona
State University BioAI group for the ad-hoc retrieval task of
the TREC Genomics Track 2005. We pre-process TREC
query expression by adding the synonyms of genes,
diseases, bio-processes, functions of organs, and selectively
adding stemming verbs, nouns, and Mesh Heading
categories. The pre-processed queries are used to perform
initial search on the TREC Genomics collection of MEDLINE
abstracts and produce a set of target abstracts using Apache
Lucene. Tagging, anaphor resolution and fact extraction are
performed on the target abstracts to refine the search results
in terms of relevance. Finally, we rank the target abstracts
according to the extracted facts, distance between terms and
terms appeared in the query.

1

INTRODUCTION

The BioAI Research Group of the Fulton School of
Engineering in Arizona State University participated in the
Ad-hoc Retrieval Task of the TREC (Text Retrieval
Conference) Genomics Track in 2005. Provided were a set
of retrieval queries collected from biologists that conformed
to a set of generic topic templates (GTTs). There are 5
GTTs, each of which has 10 instances, for a total of 50
topics. Following is a list of the 5 GTTs listed as given,
(available at http://ir.ohsu.edu/genomics/2005protocol.html)
with the semantic types in each GTT underlined:
1. Find articles describing standard methods or protocols
for doing some sort of experiment or procedure.
2. Find articles describing the role of a gene involved in
a given disease.
3. Find articles describing the role of a gene in a specific
biological process.
4. Find articles describing interactions (e.g., promote,
suppress, inhibit, etc.) between two or more genes in
the function of an organ or in a disease.
5. Find articles describing one or more mutations of a
given gene and its biological impact.
The dataset for the TREC 2005 Genomics Track consists
of completed citations from the MEDLINE database
*

To whom correspondence should be addressed.

inclusive from 1994 to 2003. Records were extracted using
the Date Completed (DCOM) field for all references in the
range of 19940101 - 20031231. This provided a total of
4,591,008 records, which is about one third of the full
MEDLINE database. The subset of articles provided by
TREC is available in the "MEDLINE" format, which
consists of ASCII text with fields indicated and delimited by
different 2-4 character abbreviations.
The aim for our first participation in the TREC Genomics
Track was to provide an efficient approach to retrieve most
relevant abstracts from the subset regarding to the queries.
We found that about 25% of MEDLINE records do not have
an abstract, mainly because the article itself does not have
one. We focused our retrieval task on the remaining 75%,
giving us close to 3.5 million abstracts. A guiding principle
for us was that relevance of a topic should not be just based
on individual terms or keywords, such as genes or diseases,
but rather it should take into account the subject of the
whole document. In order to implement this principle, we
would first parse the abstract to identify complete facts: the
right semantic terms plus the right relationship among them,
as specified in the query topic. We would extract those facts
as a whole, noting that they might appear more than once in
the abstract, and then take both fact and term frequency into
consideration when ranking the abstracts for relevance.
The idea was that if we could extract all relevant facts
from each abstract, we would just need to search among
those extracted facts for those closely related to the query
(rank) and return results. However, we needed to process a
large volume of abstracts within a limited time in order to
submit experiment results on time. We decided to retrieve a
set of potential target abstracts from the given dataset using
the given query topics, and then apply the extraction and
ranking schema on that reduced set.
We choose Apache Lucene [1] to perform the initial
retrieval. Apache Lucene is a high-performance, fullfeatured text search engine library written in Java. It is a
technology suitable for an application that requires full-text
search, especially cross-platform. Apache Lucene is an open
source project available from Apache Jakarta. Figure 1
shows the architecture of our approach:

1

Lian Yu et al.

1. Pre-processing queries: To apply Lucene in the
biomedical domain, we needed to first incorporate
bio-domain knowledge into the Lucene queries. For
example, we needed to pre-process each of the 50
queries by adding synonyms, alias, and acronyms to
genes, diseases, bio-processes, and functions of
organs, as well Mesh categories information.
2. Indexing: uses Lucene indexing APIs to create a
comprehensive index of terms on about 3.4 million of
the given subset of MEDLINE abstracts.
3. Retrieval of target abstracts: uses a batch queryprocess Java program to input each pre-processed
query topic and output a list of PubMed IDs (hereafter
called PMIDs) associated to it. The size of target
abstracts is narrowed down to 12K MEDLINE
abstracts through this process.

4. Tagging: tags entities such as genes and diseases to
facilitate anaphor resolution and fact extraction.
5. Resolving Anaphors: resolves pronouns of genes,
diseases, and bio-processes so that the text extraction
tool can extract facts of interest.
6. Fact extraction: extracts facts in terms of the relation
identified from the queries.
7. Ranking of abstracts: we define a formula which takes
the fact frequency, the distance of terms, as well as
terms frequency into consideration.
In the following section, we expand on each step in this
process. In Section 3 we describe the evaluation of our
approach. In Section 4 we sketch future research
directions.

Fig. 1. Architecture of the Ad-hoc Retrieval System
Gene 1 or MeSH 2 , respectively. Entrez Gene [6] is a gene
database from NCBI and MeSH [4] (short for Medical
2 INFORMATION RETRIEVAL SYSTEM
Subject Headings) is an ontology of terms used for
2.1 Pre-process Queries
categorizing articles in PubMed [6]. Both Entrez Gene and
Query pre-processing can be divided into three phases:
MeSH provide flat files available at their FTP sites. For
synonym matching, stemming and fine tuning. Both the
topics that involve biological processes and functions, a
synonym matching and stemming phases are automatic,
selected set of terms from MeSH is used with their
while the fine tuning phase is manually done based on the
corresponding synonyms.
topics and the number of abstracts retrieved. We elaborate
Synonyms are grouped by ‚ÄúOR‚Äù Boolean operator and
on each of them below. Since we use Lucene as our
groups of synonyms are connected with ‚ÄúAND‚Äù Boolean
indexing system, the queries follow the Lucene syntax.
operator. For instance, suppose g is a gene name, and g1 and
g2 are synonyms of g, and d is a disease name while d1 is a
2.1.1 Synonym Matching
synonym of d. Then the query formed would be:
Given a list of words provided by TREC for each topic,
(g OR g1 OR g2) AND (d OR d1)
synonym matching automatically checks if the given word
is a gene or a disease. If it is either of the two, all of the
corresponding synonyms are extracted from either Entrez
1
2

2

ftp://ftp.ncbi.nlm.nih.gov/gene/
http://www.nlm.nih.gov/mesh/filelist.html

Genomic Information Retrieval through Selective Extraction and Tagging by the ASU-BioAI Group

2.1.2 Stemming
Words that are not identified as genes or diseases are
stemmed using the Porter Stemming algorithm [9], which
returns the root form of a word. A wildcard is attached to
each stemmed word to form the query. For instance, the
word ‚Äúprogression‚Äù is stemmed as ‚Äúprogress‚Äù and
‚Äúprogress*‚Äù is formed as part of the query.

2.1.3 Fine-Tuning
Queries formed by the previous two phases can result in a
large number of relevant abstracts for some of the topics.
Furthermore, our queries have to reflect the specific needs
of TREC. Therefore, it is insufficient to have the keywords
and their synonyms as part of the queries. It is necessary to
add extra information to the queries. For example, in the
case of topic 110, we are interested in the role of interferonbeta gene in Multiple Sclerosis. Using ‚Äúinterferon-beta‚Äù,
‚Äúmultiple sclerosis‚Äù and their corresponding synonyms as a
query would retrieve articles that used interferon-beta as a
treatment, which is not of our interest.
The fine tuning approach differs in the various templates.
In template 1 about methods and protocols, if the given
keywords appear in MeSH, the query is modified so that the
keywords must appear as the MeSH heading of the
abstracts. MeSH headings act as categories of the articles.
For instance, in topic 100, electroporation is a MeSH
heading, so the query for topic 100 contains ‚ÄúMH ‚Äì
electroporation‚Äù to make use of the MedLine format of the
abstracts. The query for topic 100 is formed as follows in
Lucene syntax:
"MH \- Electroporation" AND "cell" AND
"open"

For template 2 regarding the role of genes in diseases,
MeSH headings such as genetics and pathology are added in
the queries. In the case of topic 118 regarding the gene
TGFB and Cerebral Amyloid Angiopathy, we added
‚Äúgenetics AND pathology‚Äù as part of the query. The query is
formed as follows:
(TGFB1 OR CED OR DPD1 OR TGFB OR beta 1)
AND ("Cerebral Amyloid Angiopathy" OR
"Congophilic Angiopathy" OR "Sporadic
Cerebral Amyloid Angiopathy" OR "Cerebral
Amyloid Angiopathies" OR "Congophilic
Angiopathies") AND pathology AND genetics

On the other hand, NOT operators ‚Äò-‚Äô are used on words
such as treatment and clinical trials as part of the queries in
template 2 to exclude them from the search. The query for
topic 110 regarding interferon-beta and multiple sclerosis is
formed as follows:
("interferon* beta*") AND ("Multiple
Sclerosis" OR "MS" OR "Disseminated
Sclerosis") AND -"PT - Clinical Trial" AND
-treat* AND -therap*

Similarly, words such as polymorphism and mutation are
added as part of the queries for template 5, to reflect the fact
that we are interested in only articles about mutation of
genes. The query for topic 143 regarding the mutation of
NM23 and tracheal development is formed as follows:
("NME1" OR "AWD" OR "GAAD" OR "NDPKA" OR
"NM23" OR "NM23\-H1") AND (("tracheal
development" OR "tracheal develop*")) AND
(polymorphism OR mutation)

2.2

Indexing

Using the Standard Analyzer provided by Lucene, it
tokenizes the words in the abstracts to perform indexing.
The process of tokenization involves the use of stop-word
list, so that frequently used but uninformative words, such
as a, an, the, would not be used for indexing. The Lucene
index stores the tokens and a list of files in which each of
the token appears.

2.3

Entity Tagging

The task is to parse a biomedical text to identify entities
such as diseases, biological processes and biological
functions, and then tag them accordingly with
DISE_<term>, PROC_<term>, and FUNC_<term>, where
<term> represents the name of the disease, biological
process, or biological function, usually consisting of several
words. Abner [11], a system based on statistical machine
learning techniques, was used to identify gene and protein
names.
Two problems arise when dealing with this task. The first
problem is the looseness of the English language in
conjunction with synonyms, alias, acronyms and even
spelling errors. Tagging can not be done by simply
matching token by token because of names spanning
multiple words, so we must consider one or multiple words
when making comparisons. The second problem is
efficiency. Brute force methods will allow us to tag all
instances of biological words; however, the running time
makes it an unrealistic choice for the amount of abstracts
with which we have to deal.
We tried to exclude as many words as possible from being
matched such that the only words that are matched are
words of meaning and content. In the English language,
nouns, verbs, adjectives, and adverbs convey the real
meaning and content. Everything else just works to make a
more readable sentence, and they never change the content.
In order to reduce the number of word groups matched we
chunked words into noun and verb groups. Recognizing that
most likely an entity of interest would be either a noun
phrase (adjective/noun) or a verb phrase (adverb/verb) we
grouped words using a part-of-speech tagger tool called
Monty Tagger [5] into sequences. Thus, given an abstract,
before attempting to tag biological terms, we tag parts of
speech using the Monty Tagger Java API. An abstract where

3

Lian Yu et al.

each of the words is tagged with a part of speech preceded
by ‚Äò/‚Äô looks as follows:
Haemopoietic/NNP cell/NN growth/NN and/CC
differentiation/NN is/VBZ primarily/RB
regulated/VBN by/IN the/DT local/JJ
production/NN of/IN various/JJ
cytokines/NN within/IN the/DT bone/NN
marrow/NN micro_environment/NN 3/CD ,/,
as/IN well/RB as/IN by/IN the/DT
circulating/VBG hormone/NN ,/,
erythropoietin/NNP GENE_EPO/NNP ./.

This tagged string is then tokenized and one by one
analyzed for its part of speech in order to be grouped. There
are four main parts of speech that we care about: Noun,
Verb, Adjective, and Adverb. Nouns are tagged with /NN,
/NNS, /NNP, and /NNPS. Verbs are tagged with /VB,
/VBD, /VBG, /VBN, /VBP, and /VBZ. Adjectives are
tagged with /JJ, /JJR, and /JJS. Adverbs are tagged with
/RB, /RBR and /RBS. In the example above, the first noun
group is, ‚ÄúHaemopoetic/NNP cell/NN growth/NN‚Äù.
This group is then matched against our dictionaries of
diseases, biological processes, and functions (compiled from
MeSH). If there is a direct match the string is tagged as a
Disease, Process, or Function respectively. The same
process is applied to verb groups. In the above example the
first
verb
group
is
‚Äúis/VBZ
primarily/RB
regulated/VBN‚Äù. The tagged abstracts are then used for
anaphor resolution.

2.4

Anaphora Resolution

In linguistics, an anaphora is an expression that is used to
refer back to some entity (or entities). Pronouns (such as it,
their, this) are the most common anaphora, though other
pro-forms are also anaphoras. The entity to which an
anaphora refers is its referent or antecedent. Consider:
‚ÄúLuis sent me an email. It was the first
thing he did that day.‚Äù

Here, both ‚Äúit‚Äù and ‚Äúhe‚Äù are anaphoras that refer back to
the email and Luis (the antecedents), which were mentioned
before. A human reader has no problem identifying what
they refer to, but automatic processing of the text requires
their resolution: that is, finding a potential replacement for
them and substituting the anaphoras. For the biomedical
domain, we also need to apply some semantic information
to accurately replace some anaphoras.
The subtasks for anaphor resolution include creating a
referent candidate list, doing a proximity search, and finding
the longest common substring to identify the right
antecedent. We elaborate on each of them next.

2.4.1 Creating a referent candidate list
A list of referents is maintained as they are encountered in
the sequential parsing of the abstract. The number of
referents can grow very large and prohibit efficient and

4

sensible search for resolution of ambiguous anaphora. So
the list is limited to only those words that are tagged as
potential names for genes, proteins or diseases. To facilitate
this, a variable is kept to track the most recent reference to
an antecedent entity, since sometimes there are some
anaphoras that are used more than once (like using ‚Äúhe‚Äù or
‚Äúit‚Äù in subsequent sentences in the example above).
Semantic Chunk Objects (SCO) [2] are the potential
candidates for the anaphoras, and contain a potential
antecedent plus information such as the distance of the SCO
from the first word in the abstract, the score received by the
SCO as a potential candidate for the anaphora and semantic
information such as whether the SCO is a gene, disease or
protein.

2.4.2 Proximity Search
Information regarding sentence number and distance from
the beginning of the text is kept for each SCO. Usually the
correct antecedent is the closest one to the anaphora. Using
the scoring heuristic and semantic information along with
the proximity information helps better resolve the
anaphoras.

2.4.3 Longest Common Substring
Anaphoras such as ‚Äúthese‚Äù or ‚Äòboth‚Äù are resolved by
looking at the word that follow them. A longest common
substring comparison is run on that word and the potential
SCOs. Depending upon how long the common substring is
one can decide which semantic chuck object the anaphora
substitutes. Consider the example:
‚ÄúThe exon1 and exon3 are most crucial in
expression of these genes. These exons
are‚Ä¶‚Äù.

In this case the word next to ‚Äúthese‚Äù is exon and that is
compared to all the SCO‚Äôs finding the noun group exon1
and exon3 as the closest matches thus are replacement for
anaphora ‚Äúthese‚Äù.
The comparison is run not only on the antecedent attribute
of the SCO but also on the semantic information of the
SCO. Consider for example:
‚ÄúAlzheimer‚Äôs disease and variant
Creutzfeldt-Jakob disease affect the brain.
These diseases are more prominent‚Ä¶‚Äù

The comparison will include the word following ‚Äúthese‚Äù
i.e. ‚Äúdisease‚Äù and thus we get the group ‚ÄúAlzheimer‚Äôs
disease and variant Creutzfeldt-Jakob disease‚Äù as the
potential replacement.

2.5

Fact Extraction

As explained before, we consider a ‚Äúfact‚Äù the entity or
set of entities participating in a relationship of interest for
the topic. Once the entities are recognized through tagging
‚ÄìSection 2.3- and anaphor resolution ‚ÄìSection 2.4-, the
abstracts are ready for fact extraction. Recall that the

Genomic Information Retrieval through Selective Extraction and Tagging by the ASU-BioAI Group

abstracts are tagged with the following information (an
example is shown in Fig. 2):
‚Ä¢ Gene names as GENE_<phrase of a gene name>
‚Ä¢ Diseases as DISE_< phrase of a disease>
‚Ä¢ Biological Processes as PROC_< phrase of a
biological process >
‚Ä¢ Molecular Functions as FUNC_< phrase of a
molecular function>

The method can be explained with the help of windowing
technique. Let‚Äôs consider the input text (sentence by
sentence) to be a single stream of text with a window of size
. A chain of related terms that fit within this window size
is a potential candidate for fact extraction. The extraction
module now considers the terms lexically related within this
window. This window is moved one word at a time
throughout the text. Fig. 3 shows the window and the input
text. The fact extraction task is performed on all generelated TREC topics (i.e. all topics except topic 1).

2.6
Fig. 2: An example of tagging

Extraction of facts corresponding to the templates (shown
below) is carried out by the extraction module, where the
idea of lexical chaining is applied. The premise is that words
that are closer to each other are more likely related than the
ones that are far apart. The general schema for extracted
facts is as follows:
PMID| Fact Id| Fact Frequency| GENE_< phrase >|
Interaction Word | GENE_< phrase > | DISE_< phrase >|
PROC_< phrase > | FUNC_< phrase > |
where PMID is a unique PMID, Fact Id is unique fact
number within the given abstract, Fact Frequency is
frequency of the fact occurring in the given abstract,
GENE_< phrase > is gene name prefixed with GENE_,
similarly DISE_< phrase >, PROC_< phrase > and FUNC_<
phrase > is for disease, process and function respectively.

Extraction Solution
A lexical chain [8] is a lexical cohesion of related words
that contribute to the continuity of meaning. Based on this
idea, the extraction module tries heuristically to construct a
chain of related words (such as gene names and diseases)
and include them as a fact only if they are considered to be
related. The relation of these words is primarily assumed to
be in a single sentence.

Ranking Abstracts

The Ranking module takes two input files: 1) a query file
which contains a TREC template or query ID and
corresponding queries (created earlier in the Query Preprocessing step) and 2) a query results file, which contains a
list of query IDs and associated PMIDs returned from a
Lucene search. For each query ID, the ranking module
outputs a ranking of the PMIDs based on relevancy.
To rank the abstracts with for a given query ID, a
hierarchical ranking approach is used in this paper: the
abstracts associated with a query ID are first ranked based
on the number of times relevant facts occur in each abstract.
This measure is called the fact frequency. The fact
frequency counts the number of times that related terms in
the query appear in a same sentence (see description of the
Extraction module) in the abstracts of interest. If any two
abstracts have the same fact frequency the tie is broken by
comparing the abstracts'term/distance scores, abbreviated
TD. (see Equation 2). The TD score incorporates both the
term frequency and term distance (where terms are not
necessarily in the same sentence, unlike fact frequency) of
the abstracts in order to determine which abstract is more
relevant.
TREC requires that each abstract be assigned a single score
to represent its relevancy. To accomplish this, a ranking
formula called rf(a) is used to assign a value to an abstract a
that meets the above two requirements.
If A represents all the abstracts that have the same query
ID, a ‚àà A, ff(a) represents the fact frequency of a, and td(a)
represents the TD score of a, then the value rf(a) is as
follows in Equation (1):

rf (a ) = td (a ) + max(td ( A)) * ff (a )

Fig. 3: Heuristic based on Lexical (semantic) cohesion of words.
Windowing technique is used to limit the chain size under
consideration.

(1)

In Equation 1 the maximum score of all the abstracts in A
is used in order to ensure that an abstract that has a high fact
frequency, and is thus more relevant, will have a high value
of rf(a). The TD score of the abstract is also taken into
account to break ties between abstracts with identical fact
frequencies, resulting in a single value which ranks an
abstract using the hierarchical ranking approach described
earlier.

5

Lian Yu et al.

Once rf(a) for each abstract has been computed, the list of
abstracts, sorted by query ID and then sub sorted in
decreasing order by rf(a), are written to two files, qrels.txt
and topic_document.txt, which were then submitted to
TREC for evaluation.
The notations used in the following formula are listed as
follows:
a:
A:
G:
D:
s(a):
d = (s1, s2):
Mina (d):
f(a, s):
w(a):
df(a, d):

an abstract with a query ID of ID
the set of all the abstracts with a query ID of
ID and a ‚àà A.
the set of all genes and their synonyms found
in the query ID
the set of all the diseases and their synonyms
found in the query ID
the number of sentences in a
the distance between strings s1 and s2 (such
as strings of a gene or a disease) in terms of
sentences in between
the minimum distance in sentences between
s1 and s2 If either s1 or s2 is not in a then Mina
(d) is defined to be equal to s(a)
the number of times the string s occurs in a
the total number of words in a
the number of times the pair of strings of d is
at a distance of Mina (d) (if either string in d
is not in a then df(a, d) is defined to be equal
to 1).

Then the TD score of a, td(a), is computed as follows in
Equation (2).

td (a) =

ratio * dist * rel , if w(a ) > 0 ‚àß s (a ) > 0
0, if w(a ) = 0 ‚à® s( a) = 0

(2)
where the variable ratio is computed with gene or disease
overlap and the weights of the genes or diseases in the query
ID, dist represents the distance between gene/disease pairs
in the query ID (see Equation (3)). rel, or relevancy,
represents the frequency of the genes and diseases in the
query ID appearing in a (see Equation (6)).
The portion of ratio in TD score consists of the product of
three factors as follows in Equation (3)[1]:

ratio =

overlap
1
*
* weight
G+D
w(a )

(3)

The first factor is called the coordination, which is the
overlap (see Equation (4)) divided by the number of genes
and diseases in the query ID. The second factor is known as
length normalization, which is the reciprocal of the square
root of the total number of items, tokens, or the words of the
abstract searched. The last factor, weight, represents the
weights assigned to each gene and disease in the query ID:

6

since each gene and disease has equal weight this score will
be the square root of the number of genes and diseases in
the query ID (see Equation (5)) [1].
The overlap of an abstract a is the number of genes or
diseases in the query ID that occur at least once in a.

overlap = d ‚àà G ‚à™ D : f (a, d ) > 0

(4)

The weight value normalizes the weights for the genes
and diseases in the query ID.

weight =

1
2

wgh(d )

(5)

d‚ààG ‚à™ D

where wgh(d) represents the individual weight of a gene or
disease d in the query ID: by default, this value is equal to
one divided by the number of genes and diseases in the
query ID.
The distance, dist, is the product of the distance scores for
each possible ordered pair of genes and diseases in the
query ID. A distance score for a gene/disease pair is a
product of two factors: a sentence distance factor and a
distance frequency factor. The sentence distance factor is a
value between one and two inclusive, with a value of one
signifying that the gene/disease pair do not occur together in
the abstract a and a score of two signifying that the gene and
disease occur in the same sentence in the abstract a. The
value of the distance frequency factor is how often the
gene/disease pair occurs at the distance used to calculate the
sentence distance factor: the square root is applied to this
value for normalization. If ID is between a certain range the
query includes not one but two sets of genes (G1 and G2) for
which the distance must be taken into account (see
corresponding template): therefore, a second product term
must be included which measures the distance between each
possible ordered pair of genes in these two sets.
The distance (dist) value is the product of the distance
values between each possible ordered pair of genes and
diseases in the query ID. A distance value for a gene/disease
pair is itself a product of two factors: a sentence distance
factor and a distance frequency factor. The sentence
distance factor is a value between one and two inclusive:
one signifying that the gene/disease pair does not occur
together in the abstract a and two signifying that the gene
and disease occur in the same sentence in the abstract a. The
value of the distance frequency factor indicates how often
the gene/disease pair occurs at the distance used to calculate
the sentence distance factor, and the square root is applied to
this value for normalization. If ID is between 130 and 139
then Equation (6b) is used to calculate the value of dist.
Within this range the query includes not one but two sets of
genes (G1 and G2) for which the distance must be taken into
account (see corresponding template): therefore, along with
the product found in Equation (6a), a second product term
must be included which measures the distance between each
possible ordered pair of genes in these two sets.

Genomic Information Retrieval through Selective Extraction and Tagging by the ASU-BioAI Group

d ( a, d )
) * df (a, d )
s(a)
d ‚ààG√ó D
(T < 130 ‚à® T > 139) ‚àß s (a ) ‚â† 0 (6a)
d ( a, d )
dist = ‚àè (2 ‚àí
) * df (a, d ) *
s(a)
d‚ààG√óD
d ( a, g )
(2 ‚àí
) * df (a, g )
‚àè
s ( a)
g‚ààG1√óG 2
dist =

‚àè

(2 ‚àí

T ‚â• 130 ‚àß T ‚â§ 139 ‚àß s (a ) ‚â† 0 (6b)
The relevancy portion in TD of a, rel, is a sum of the
relevancy of each gene or disease searched for in a. The
relevancy of an individual gene or disease is a product of its
frequency and its inverse document frequency [3],[10]. The
square root of the frequency is taken to normalize the value,
while the inverse document frequency measures how rare a
gene or disease is: the rarer the gene or disease, the higher
the inverse document frequency, and thus the relevancy,
will be. This is because the occurrence of a rare gene or
disease in an abstract is a better indicator of relevancy than a
common one.

rel =

f (a, d ) * log(
d ‚ààG ‚à™ D

A
) (7)
dfr ( A, d ) ‚àí 1

The document frequency, dfr(A,d) (see Equation (8)),
represents the number of abstracts in A that contain the gene
or disease d at least once. The smaller the value of dfr(A,d)
the rarer the gene or disease d is.

dfr ( A, d ) = a ‚àà A : f (a, d ) > 0
3

(8)

EVALUATION AND DICUSSION

This section demonstrates the experiment results of our
approach, and the comparison with results from Pubmed
search engine in regarding to the 50 topics.

3.1

Run Results

We performed Lucene indexing on the collection of 4.5
million abstracts in MEDLINE format, used 50 formatted
queries to search in the Lucene index, and retrieved about
12K target abstracts. The number of search results varied
from query to query ranging from 0 to 7,000.
For each template, we performed tagging, anaphor
resolution, extraction (exception template 1) and ranking.
We performed fact extraction on abstracts pertinent to
templates 2 through 5, and calculated the fact frequencies,
which were incorporated into the ranking formula. For
abstracts related to template 1, we performed tagging and
anaphor resolution without fact extraction. The ranking is
only dependent on the score as described in Section 2.5.

3.2

TREC Evaluation Results

TREC ad-hoc relevance judgments were done based on
the top 60 documents from the two runs submitted by each
group for each topic, which yielded an average pool size of
822 documents. Relevance judgments were performed only
on 49 of the 50 topics, as no relevant document was found
for one of the topics, which is topic #135. Evaluation results
returned by TREC were summarized in terms of precision at
top 10 relevant documents retrieved (denoted as P10),
precision at top 100 relevant documents retrieved (P100)
and uninterpolated average precision for the 49 topics.
Our system for the ad hoc retrieval task achieves an
overall precision of 0.2714 for P10 and precision of 0.1061
for P100 among the 49 topics. This implies that our system
achieves a low recall, as the number of articles retrieved by
our system is low. Table 1 shows the average number of
articles retrieved as well as minimum and maximum number
for each template. We further analyzed our performance and
noticed that our system performs best in template 2, which
is to retrieve articles describing the role(s) of a gene
involved in a disease. It is evident that our extraction-based
retrieval system benefits from the rich dictionaries of gene
and disease names compiled from Entrez Gene and MeSH.
On the contrary, the lack of rich dictionaries for functions of
an organ (for template 4) and biological impact or role (for
template 5) is the main reason on why our system suffers in
the precision of the retrieval task for templates 4 and 5. Our
system also failed to retrieve any documents for some of the
topics in templates 4 and 5.
Table 1: Average of the number of articles retrieved
Template #
1 (topic # 100-109)
2 (topic # 110-119)
3 (topic # 120-129)
4 (topic # 130-139)
5 (topic # 140-149)

4

Number of articles retrieved on
average
95 (min = 2, max = 436)
110 (min = 4, max = 303)
122.5 (min = 4, max = 1000)
8.11 (min = 0, max = 52)
26.9 (min = 0, max = 207)

CONCLUSION AND FUTURE WORK

The TREC Genomics team included 8 members from the
BioAI group, 3 of them undergraduates. We spent about 6
weeks completing the ad-hoc retrieval task. We used
Apache Lucene to perform the initial retrieval and got 12K
target abstracts out of 4.5 million abstracts. Then tagging,
anaphor resolution, extraction and ranking were performed
to refine relevance of search results.
Retrieval systems such as NCBI PubMed generally return
a large number of documents that are supposed to be
relevant to the users‚Äô queries. In other words, such retrieval
systems achieve high recall but relatively low precision.
Users of a retrieval system with high precision can benefit
on the preciseness and conciseness of the articles returned to

7

Lian Yu et al.

them. With this in mind, we emphasized the precision aspect
of our retrieval system. Our system could achieve higher
precision on templates 4 and 5 if richer ontologies were
used for functions of an organ and biological impact.
Future work includes investigating ways to improve the
accuracy of the tagging module for diseases, bio-processes
and functions of organs. A quantitative approach to assign
scores to SCOs is needed for the anaphor resolution module.
The extraction module needs to be able to extract various
types of the topics, such as topics in the template 1.

REFERENCES
[1] Apache Lucene. http://lucene.apache.org/java/docs/.
[2] J. Casta√±o, J. Zhang, J. Pustejovsky. Anaphora Resolution in
Biomedical Literature. International Symposium on Reference
Resolution, 2002.
[3] K.S. Jones. Index term weighting. Information Storage and
Retrieval, 9: 619-633, 1973.
[4] MeSH. http://www.nlm.nih.gov/mesh/.
[5] Monty Tagger. http://web.media.mit.edu/~hugo/montytagger/.
[6] NCBI Entrez Gene.
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=gene.
[7] NCBI Entrez PubMed.
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed.
[8] J. Morris, G. Hirst, Lexical Cohesion Computed by Thesaural
Relations as an indicator of the structure of Text. Association
of Computational Linguists, 1991.
[9] M.F. Porter. An algorithm for suffix stripping, Program,
14(3):130-137, 1980.
[10] S.E. Robertson and K.S. Jones. Relevance weighting of
search terms. Journal of the American Society for Information
Science, 27, 129‚Äî146, 1976.
[11] B. Settles. ABNER: an open source tool for automatically
tagging genes, proteins, and other entity names in text.
Bioinformatics, 21(14):3191-3192, 2005.

8

Using Smodels (Declarative Logic Programming) to Verify Correctness of Certain Active Rules
Mutsumi Nakamura, Ramez Elmasri Department of Computer Science and Engineering The University of Texas at Arlington, Arlington, TX 76019 nakamura@asu.edu, elmasri@cse.uta.edu

Abstract
In this paper we show that the language of declarative logic programming (DLP) with answer sets and its extensions can be used to specify database evolution due to updates and active rules, and to verify correctness of active rules with respect to a specification described using temporal logic and aggregate operators. We classify the specification of active rules into four kind of constraints which can be expressed using a particular extension of DLP called Smodels. Smodels allows us to specify the evolution, to specify the constraints, and to enumerate all possible initial database states and initial updates. Together, these can be used to analyze all possible evolution paths of an active database system to verify if they satisfy a set of given constraints. Active databases have tremendous potential to simplify database programming by specifying appropriate ECA(Event-Condition-Action) rules. One impediment to their widespread use has been the need for design methodologies and verification techniques to show that a set of rules is consistent and satisfies the system requirements. Database triggers are typically activated when a particular update occurs. When we have a set of triggers, an update which is activated by one trigger can activate other triggers and can create a sequence of updates. A designer of an active database should make sure that sequences of updates do not violate the "purpose" of the triggers. Triggers are an essential component of active database systems and are now part of the SQL3 database standard. After their implementation in several research prototypes, they are now incorporated in commercial database systems such as Oracle, Sybase and IBM's DB2-V2 [1]. There has been much work on the syntax of triggers, how they are to be executed, their execution models, and their implementations, and some work on formal frameworks for active databases in regards to semantics and expressiveness. However, comparatively fewer work has been done on methodologies to design triggers, specify what triggers

are supposed to achieve (their "purpose"), and ways to verify their correctness.We have made some progress on these issues in [2] where we developed a specification language for triggers which can be used to specify the purpose of triggers. In this paper, we show how one can simulate the effect of active rules (triggers), specify their purpose, and a limited verification of the correctness of a set of triggers with respect to its purpose. For this we use declarative logic programming (DLP) with answer set semantics and the Smodels system [3]. Using Smodels, we can also enumerate all possible initial database states and initial updates, and specify active rules. In this way, the database evolution can be specified and tested against a given specification. If it satisfies all constraints of the specification we can conclude that the set of active rules is correct with respect to the specification. Our work in this paper extends our earlier work in [2] where we identified state and trajectory invariance and maintenance constraints as important parameters in specifying the purpose of triggers and defined correctness of triggers. Here we show DLP and Smodels to be a candidate language for both specification and perhaps even to serve as the engine for a trigger verification system. Developing a general trigger verifications system with a DLP engine is one of our future goals. The full version of this paper is available at: http://www.public.asu.edu/ mutsumi/activedb/papers/icde02.pdf or icde02.ps.

References
[1] D. Chamberlin. Using the new DB2: IBM's Object-relational database system. Morgan Kaufmann, 1996. [2] M. Nakamura and C. Baral. Invariance, maintenance and other declarative objectives of triggers ≠ a formal characterization of active databases. In CL 2000, pages 1210≠1224, 2000. [3] I. Niemela and P. Simons. Smodels ≠ an implementation of the stable model and well-founded semantics for normal logic programs. In LPNMR '97, pages 420≠429, 1997.

Proceedings of the 18th International Conference on Data Engineering (ICDE'02) 1063-6382/02 $17.00 © 2002 IEEE

I N F S Y S
R

E S E A R C H

R

E P O R T

I NSTITUT F UÃàR I NFORMATIONSSYSTEME
A RBEITSBEREICH W ISSENSBASIERTE S YSTEME

M AINTENANCE G OALS OF AGENTS IN A
DYNAMIC E NVIRONMENT: F ORMULATION
AND P OLICY C ONSTRUCTION

Chitta Baral

Thomas Eiter
Marcus BjaÃàreland
Mutsumi Nakamura

INFSYS R ESEARCH R EPORT 1843-04-04
O CTOBER 2004

Institut fuÃàr Informationssysteme
AB Wissensbasierte Systeme
Technische UniversitaÃàt Wien
Favoritenstrass√üe 9-11
A-1040 Wien, Austria
Tel:

+43-1-58801-18405

Fax:

+43-1-58801-18493

sek@kr.tuwien.ac.at
www.kr.tuwien.ac.at

INFSYS R ESEARCH R EPORT
INFSYS R ESEARCH R EPORT 1843-04-04, O CTOBER 2004

M AINTENANCE G OALS OF AGENTS IN A DYNAMIC E NVIRONMENT:
F ORMULATION AND P OLICY C ONSTRUCTION
Chitta Baral1

Thomas Eiter2

Marcus BjaÃàreland3

Mutsumi Nakamura1

Abstract.The notion of maintenance often appears in the AI literature in the context of agent behavior and planning. In this paper, we argue that earlier characterizations of the notion of maintenance
are not intuitive to characterize the maintenance behavior of certain agents in a dynamic environment. We propose a different characterization of maintenance and distinguish it from earlier notions
such as stabilizability. Our notion of maintenance is more sensitive to a good-natured agent which
struggles with an ‚Äúadversary‚Äù environment, which hinders her by unforeseeable events to reach her
goals (not in principle, but in case). It has a parameter k, referring to the length of non-interference
(from exogenous events) needed to maintain a goal; we refer to this notion as k-maintainability. We
demonstrate the notion on examples, and address the important but non-trivial issue of efficient construction of maintainability control functions. We present an algorithm which in polynomial time
constructs a k-maintainable control function, if one exists, or tells that no such control is possible.
Our algorithm is based on SAT Solving, and employs a suitable formulation of the existence of kmaintainable control in a fragment of SAT which is tractable. For small k (bounded by a constant),
our algorithm is linear time. We then give a logic programming implementation of our algorithm
and use it to give a standard procedural algorithm, and analyze the complexity of constructing kmaintainable controls, under different assumptions such as k = 1, and states described by variables.
On the one hand, our work provides new concepts and algorithms for maintenance in dynamic environment, and on the other hand, a very fruitful application of computational logic tools.
Keywords: intelligent agents, maintenance goals, maintainability, agent control, policy construction, declarative logic programming, SAT solving, computational complexity, discrete event dynamic systems.
1

Department of Computer Science and Engineering, Arizona State University, Tempe, AZ 85233, USA.
Email: {chitta, mutsumi}@asu.edu
2
Institut fuÃàr Informationssysteme, Knowledge Based Systems Group, Technische UniversitaÃàt Wien, Favoritenstra√üe
9-11, A-1040 Vienna, Austria. E-mail: eiter@kr.tuwien.ac.at.
3
AstraZeneca R&D, S-43183 MoÃàlndal, Sweden. Email: marcus.bjareland@astrazeneca.com
Acknowledgements: This work was partially supported by FWF (Austrian Science Funds) projects
P-16536-N04 and Z29-N04, a research collaboration grant by TU Wien, the European Commission under
grant IST 2001-37004 WASP, the NSF (National Science Foundation of USA) grant numbers 0070463, and
0412000, NASA grant number NCC2-1232, and an ARDA contract.
A preliminary version of the formulation part, entitled ‚ÄúA formal characterization of maintenance goals,‚Äù
has been presented at AAAI‚Äô00, and a preliminary version of the algorithm part entitled ‚ÄúA polynomial time
algorithm for constructing k-maintainable policies‚Äù has been presented at ICAPS‚Äô04. The current version
revises and combines both of them with additional elaborations, examples, results, and proofs.
c 2007 by the authors
Copyright 

INFSYS RR 1843-04-04

I

Contents
1 Introduction and Motivation

1

2 Background: Systems, Goals, Control, Stability and Stabilizability
2.1 Stabilizability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3
5

3 Example Scenario: Two Finite Buffers

6

4 Limited Interference and k-Maintainability
8
4.1 An alternative characterization of k-maintainability . . . . . . . . . . . . . . . . . . . . . . 11
5 Polynomial Time Methods to Construct k-Maintainable Controls
5.1 Deterministic transition function Œ¶(s, a) . . . . . . . . . . . .
5.1.1 Horn SAT encoding . . . . . . . . . . . . . . . . . . .
5.2 Non-deterministic transition function Œ¶(s, a) . . . . . . . . .
5.2.1 Horn SAT encoding (general case) . . . . . . . . . . .
5.3 Genuine algorithm . . . . . . . . . . . . . . . . . . . . . . .
6 Encoding Maintainability for an Answer Set Solver
6.1 Input representation . . . . . . . . . . . . . . . .
6.2 Deterministic transition function Œ¶ . . . . . . . .
6.3 Nondeterministic transition function Œ¶ . . . . . .
6.4 Layered use of negation . . . . . . . . . . . . . .
6.5 State descriptions by variables . . . . . . . . . .

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

12
13
15
18
20
23

.
.
.
.
.

24
25
25
27
28
29

7 Computational Complexity
30
7.1 Problems considered and overview of results . . . . . . . . . . . . . . . . . . . . . . . . . . 30
7.2 Enumerative representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
7.3 State variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
8 Discussion and Conclusion
39
8.1 Other related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
8.2 Future work and open issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

INFSYS RR 1843-04-04

1

1 Introduction and Motivation
For an agent situated in a static environment, the goal is often to reach one out of several states where certain
conditions are satisfied. Such a goal is usually expressed by a formula in propositional or first-order logic.
Sometimes the goal requires constraining the path taken to reach one of the states. In that case, the goal can
be expressed by a formula in temporal logic [1, 41, 4].
Our concern in this paper is about agents in a dynamic environment. In that case, things are more complex
since the state of the world can change through both actions of the agent and of the environment. The agent‚Äôs
goal in a dynamic environment is then often more than just achieving a desired state, as after the agent has
successfully acted to reach a desired state, the environment may change that state. In such a case, a common
goal of an agent is to ‚Äòmaintain‚Äô rather than just ‚Äòachieve‚Äô certain conditions. The goal of maintaining certain
conditions (or a set of states that satisfy these conditions) is referred to as maintenance goals. Maintenance
goals are well-known in the AI literature, e.g., [52, 30, 1, 42], and have counterparts in other areas such as
in stability theory of discrete event dynamic systems [43, 45, 47, 46, 51] and in active databases [10, 38].
However, as we argue in this paper, earlier characterizations of maintenance goals are not adequate under
all circumstances.
To see what is wrong with earlier definition of maintenance goals, suppose an agent‚Äôs goal is to maintain
a fluent f , i.e., the proposition f should be true. A straightforward attempt1 to express it using temporal
operators is the formula 2f , where 2 is the temporal operator ‚ÄúAlways‚Äù and 2f means that f is true in all
the future states of the world. This is too strong a condition, as maintaining inherently means that things go
out of shape and they have to be maintained back to shape. A better temporal logic representation of this
goal is thus the formula 23f , where 3 is the temporal operator ‚ÄúEventually.‚Äù Intuitively, the formula 23f
is satisfied by an infinite trajectory of states of the form s0 , s1 , s2 , . . ., if at any stage i ‚â• 0, there exists
some stage j ‚â• i such that f is true in sj . An agent‚Äôs control is said to satisfy 23f if all trajectories that
characterize the evolution of the world due to the environment and the agent‚Äôs control satisfy 23f . At first
glance the formula 23f seems to express the goal of maintaining f , as it encodes that if f becomes f alse
in any state in the trajectory then it becomes true in a later state.
We consider 23f to be also too strong a specification‚Äîin many situations‚Äîto express the intuitive notion
of ‚Äòmaintaining f ‚Äô, if we take on a more refined view of the (sometimes nasty) part which the environment
might play, which we illustrate by some examples. Suppose f denotes the condition that the Inbox of a
customer service department be empty. Here the environment makes f false by adding new requests to the
Inbox while the agent tries to make f true by processing the messages in the Inbox and removing them from
it. If the agent is diligent in processing the message in the Inbox and makes it empty every chance the agent
gets, we would then like to say that agent maintains the Inbox empty. But such a control does not satisfy the
formula 23f under all circumstances, because there will be trajectories where the agent is overwhelmed by
the environment (flooding the Inbox) and f never becomes true.
Another example in support of our intuition behind maintainability is the notion of maintaining the consistency of a database [10, 38, 53]. When direct updates are made to a database, maintaining the consistency
of the database entails the triggering of additional updates that may bring about additional changes to the
database so that in the final state (after the triggering is done) the database reaches a consistent state. This
does not mean that the database will reach consistency if continuous updates are made to it and it is not
given a chance to recover. In fact, if continuous update requests are made we may have something similar
1
All through the paper we consider the evaluation of linear temporal formulas with respect to all ‚Äòvalid‚Äô trajectories. An
alternative approach would be to use a variation of the branching time quantifier A, such as the operator AœÄ from [6], before the
linear temporal formulas.

2

INFSYS RR 1843-04-04

to denial service of attacks. In this case we can not fault the triggers saying that they do not maintain the
consistency of the database. They do. It is just that they need to be given a window of opportunity or a
respite from continuous harassment from the environment to bring about the additional changes which are
necessary to restore database consistency. The same holds for maintaining a room clean; we can not fault
the cleaning person if he or she is continually sent away because the room is being continuously used.
Another example is a mobile robot [8, 35] which is asked to ‚Äòmaintain‚Äô a state where there are no obstacles
in front of it. Here, if there is a belligerent adversary that keeps on putting an obstacle in front of the robot,
there is no way for the robot to reach a state with no obstacle in front of it. But often we will be satisfied if
the robot avoids obstacles in its front when it is not continually harassed. Of course, we would rather have
the robot take a path that does not have such an adversary, but in the absence of such a path, it would be
acceptable if it takes an available path and ‚Äòmaintains‚Äô states where there are no obstacles in front.
The inadequacy of the expression 23f in expressing our intuition about ‚Äòmaintaining f ‚Äô is because 23f
is defined on trajectories which do not distinguish between transitions due to agent actions and environment
actions. Thus we can not distinguish the cases
(i) where the agent does its best to maintain f (and is sometimes thwarted by the environment) and can
indeed make f true in some (say, k) steps if there is no interference from the environment during those
steps; and
(ii) where the agent really does not even try.
We refer to (i) as k-maintainability in this paper. The expression 23f can not express the idea of a window
of opportunity (or window of non-interference) during which an agent can perform the actions necessary
for maintaining. In fact, none of the standard notions of temporal logics [12, 36], which are defined on
trajectories that do not distinguish between the cause behind the transitions (whether they are due to agent‚Äôs
actions or due to the environment), can express the idea behind k-maintainability.
The main contributions of this paper can be summarized as follows.
1. We introduce and formally define the notion of k-maintainability, and distinguish it from earlier notions of maintainability, in particular the specification 23f and the similar notion of stabilizability
from discrete event dynamic systems.
2. We provide polynomial time algorithms that can construct k-maintainable control policies, if one
exists. (In the rest of the paper we will refer to ‚Äòcontrol policy‚Äô simply by ‚Äòcontrol‚Äô.) Our algorithm is
based on SAT Solving, and employs a suitable formulation of the existence of k-maintainable control
in a tractable fragment of SAT. We then give a logic programming implementation of this method,
and finally distill from it a standard procedural algorithm.
3. We analyze the computational complexity of constructing k-maintainable controls, under different settings of the environment and the windows of opportunity open to the agent, as well as under different
forms of representation. We show that the problem is complete for PTIME in the standard setting,
where the possible states are enumerated, and complete for EXPTIME in a STRIPS-style setting
where states are given by value assignments to fluents. Furthermore, we elucidate the impact of the
different factors and show, by our proofs of the hardness results, that the full problem complexity is
inherent already to certain restricted cases.
Overall, our work not only provides new concepts and algorithms for realizing maintenance of an agent in
dynamic environment, but also illustrates a very fruitful application of computational logic tools.

INFSYS RR 1843-04-04

3

The rest of this paper is organized as follows. In Section 2 we present the background definitions of a
system with an agent in an environment and define the notions of stability and stabilizability. In Section 3
we describe a running example of a system with two buffers. We use this example for illustrating the
concepts of stabilizability and k-maintainability, which is formally defined in Section 4. In Section 5 we
present our algorithms for constructing k-maintaining controls, based on SAT Solving as well as a genuine
algorithm extracted from it. In Section 6 we present an encoding for computing a control function using a
logic programming engine and devote Section 7 to complexity analysis. Finally, in Section 8 we conclude,
mention related work and outline some future directions.

2 Background: Systems, Goals, Control, Stability and Stabilizability
In this paper, we are concerned with goal-directed agents in a dynamic world. Such agents can perform
actions that change the state of the world. Because of the dynamic nature of the world, certain changes can
happen to the state of the world beyond the control of an agent. The agent‚Äôs job is thus to make the world
evolve in a way coherent with a goal assigned to it. As for the agent control, we adopt here that an agent
follows a Markovian control policy to do its job; that is, its control is a function from the set of states to the
set of actions, detailed as follows.
Definition 1 (System) A system is a quadruple A = (S, A, Œ¶, poss), where
‚Ä¢ S is the set of system states;
‚Ä¢ A is the set of actions, which is the union of the set of agents actions, Aagent , and the set of environmental actions, Aenv ;
‚Ä¢ Œ¶ : S √ó A ‚Üí 2S is a non-deterministic transition function that specifies how the state of the world
changes in response to actions; and
‚Ä¢ poss : S ‚Üí 2A is a function that describes which actions are possible to take in which states.
The above notion of system is used in the discrete event dynamic systems community, for instance in [43, 45,
47, 46, 51]. In practice, the functions Œ¶ and poss are required to be effectively (and efficiently) computable,
and they may often be specified in a representation language such as in [25, 23, 48]. The possibility of an
action has different meaning depending on whether it is an agent‚Äôs action or whether it is an environmental
action. In case of an agent‚Äôs action, it is often dictated by the policy followed by the agent. For environmental
actions, it encodes the various possibilities that are being accounted for in the model. We tacitly assume
here that possible actions lead always to some successor state, i.e., the axiom that Œ¶(s, a) 6= ‚àÖ whenever
a ‚àà poss(s) holds for any state s and action a, is satisfied by any system.
An example of a system A = (S, A, Œ¶, poss), where S = {b, c, d, f, g, h}, A = { a, a‚Ä≤ , e}, and the
transition function Œ¶ is shown in Figure 1, where s‚Ä≤ ‚àà Œ¶(s, a) iff an arc s ‚Üí s‚Ä≤ labeled with a is present
and poss(s) are all actions that label arcs leaving s. Notice that in this example, Œ¶(s, a) is deterministic,
i.e., Œ¶(s, a) is a singleton if nonempty.
The evolution of the world with respect to a system is characterized by the following definition.
Definition 2 (Trajectory) Given a system A = (S, A, Œ¶, poss), an alternating infinite sequence of states
and actions s0 , a1 , s1 , a2 , . . . , sk , ak+1 , sk+1 , . . . is said to be a trajectory consistent with A, if sk+1 ‚àà
Œ¶(sk , ak+1 ), and ak+1 ‚àà poss(sk ).
2

4

INFSYS RR 1843-04-04
a

c

a

d

a

b
a‚Ä≤

h

a
f

e
g

Figure 1: Transition diagram of system A

A common restriction on how the world evolves is defined using the notion of stability. The following
definition of stability is adapted from [43] and has its origin in control theory and discrete event dynamic
systems [43, 45, 47, 46].
Definition 3 (Stable state 1) Given a system A = (S, A, Œ¶, poss) and a set of states E, a state s is said
to be stable in A w.r.t. E if all trajectories consistent with A and starting from s go through a state in E
in a finite number of transitions and they visit E infinitely often afterwards. A set of states S is stable with
respect to E if all states in S are stable with respect to E.
We say A = (S, A, Œ¶, poss) is a stable system, if all states in S are stable in A with respect to E.

2

Although the above definition of stability is with respect to a set of states E, it can be easily adapted to a
formula œï that can be evaluated at the states of system A. In that case E = {s ‚àà S | A, s |= œï}, i.e., it is
the set of states s at which œï is true.
An alternative approach to characterize the evolution of states is through temporal operators. Some of the
important temporal operators talking about the future are (cf. [36, 21]): Next (), Always (2), Eventually
(3), and Until (U). Their meaning with respect a trajectory œÑ = s0 , a1 , s1 , . . . , sk , ak+1 , sk+1 , . . . is defined
as follows.
Let (œÑ, j), for j ‚â• 0, denote the remainder of œÑ starting at sj ; then
‚Ä¢ (œÑ, j) |= p iff p is true in sj , for any proposition p;
‚Ä¢ (œÑ, j) |= œÜ iff (œÑ, j + 1) |= œÜ;
‚Ä¢ (œÑ, j) |= 2œÜ iff (œÑ, k) |= œÜ, for all k ‚â• j.
‚Ä¢ (œÑ, j) |= 3œÜ iff (œÑ, k) |= œÜ, for some k ‚â• j.
‚Ä¢ (œÑ, j) |= œÜ1 U œÜ2 iff there exists k ‚â• j such that (œÑ, k) |= œÜ2 and for all i, j ‚â§ i < k, (œÑ, i) |= œÜ1 .
The standard Boolean connectives ‚àß, ‚à®, and ¬¨ are defined as usual. An alternative definition of stability can
then be given as follows:
Definition 4 (Stable state 2) Given a system A = (S, A, Œ¶, poss) and an objective formula œï (i.e., without
temporal operators), let EœÜ = {s ‚àà S | œÜ is true in s}. A state s is then said to be stable in A w.r.t. E
if for all trajectories œÑ of the form œÑ = s0 , a1 , s1 , . . . , sk , ak+1 , sk+1 , . . . consistent with A, it holds that
(œÑ, 0) |= 23œï.
2

INFSYS RR 1843-04-04

5

In fact, this definition is equivalent to Definition 3. The advantage of using temporal operators, as in the
above definition, instead of Definition 3 is that the former allows us to specify a larger class of goals and
build on top of the notion of stability. For example, a notion similar to stability, referred to as a response
property [36], is of the form 2(p ‚Üí 3q).

2.1

Stabilizability

The notion of stability is defined with respect to a system and the evolution of the world consistent with the
system. When we focus on an agent and its ability to make a system stable, we need a notion of stabilizability
which intuitively means that there exists a control policy which the agent can use to fashion a stable system.
Given a system A = (S, A, Œ¶, poss), when discussing stabilizability of the system, we need to consider the
following additional aspects:
‚Ä¢ the set of actions Aagent which the agent is capable of executing in principle (where Aagent ‚äÜ A);
‚Ä¢ the set of exogenous actions that may occur in the state s, beyond the agent‚Äôs control, modeled by
a function exo : S ‚Üí 2Aenv , where exo(s) ‚äÜ poss(s) for each state s (recall that Aenv are the
environmental actions). We call any such exo an exogenous function.
Intuitively, given a system A = (S, A, Œ¶, poss), Aagent , exo, and E, a state s is stabilizable with respect to
E, if we are able to find a policy or control function such that the agent picks an action it can do in s, we
have stability if all other agent actions in s and the other states that are reached are disabled, and no state is
reached from s where no further actions are possible.
The last condition is referred to as aliveness. It is formally defined by the following two definitions, the first
of which defines the set R(A, s) of states that can be reached from s in the system A.
Definition 5 Given a system A = (S, A, Œ¶, poss) and a state s, R(A, s) ‚äÜ S is the smallest set of states
that satisfying the following conditions:
1. s ‚àà R(A, s),
2. If s‚Ä≤ ‚àà R(A, s), and a ‚àà poss(s‚Ä≤ ), then Œ¶(s‚Ä≤ , a) ‚äÜ R(A, s).

2

Definition 6 (Aliveness) Given a system A=(S, A, Œ¶, poss) and a state s, we say s is alive if poss(s‚Ä≤ ) 6= ‚àÖ,
for all s‚Ä≤ ‚àà R(A, s). We say A=(S, A, Œ¶, poss) is alive if all states in S are alive.
2
The notion of control function is formally defined as follows.
Definition 7 (Control) Given a system A = (S, A, Œ¶, poss) and a set Aagent ‚äÜ A of agent actions, a
control function for A w.r.t. Aagent is a partial function
K : S ‚Üí Aagent ,
such that K(s) ‚àà poss(s) whenever K(s) is defined.

2

We are now ready to formally define the notion of stabilizability.
Definition 8 (Stabilizability) Given a system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A, a function exo as
above, and a set of states E, we say that s ‚àà S is stabilizable with respect to E, if there exists a control
function K : S ‚Üí Aagent for A w.r.t. Aagent with the following properties:

6

INFSYS RR 1843-04-04

1. s is stable with respect to E in the system AK,exo = (S, A, Œ¶, poss K,exo ), where, for any state s‚Ä≤ ,
poss K,exo (s‚Ä≤ ) = {K(s‚Ä≤ )} ‚à™ exo(s‚Ä≤ ); and
2. s is alive in AK,exo .
A set of states S ‚äÜ S is stabilizable with respect to E, if there is a control function K for A w.r.t. Aagent
such that every state s ‚àà S is stabilizable with respect to E witnessed by K.
2
Having provided this definition, we shall illustrate it on an elaborated example in the next section, where we
describe an intuitive control function for the management of two finite buffers.
Before closing this section, we introduce for later use the notion of a super control.
Definition 9 (Super-control) Given a system A = (S, A, Œ¶, poss) and a set Aagent ‚äÜ A of agent actions,
a partial function K : S ‚Üí 2Aagent such that K(s) ‚äÜ poss(s) and K(s) 6= ‚àÖ whenever K(s) is defined, is
called super-control for A w.r.t. Aagent .
2
Informally, a super-control is an envelope for multiple control functions, which result by refining K to some
arbitrary action in K(s) whenever K(s) is defined; the notion of stabilizability is defined similar as for
control functions, with the only change that in AK,exo , we set poss K,exo (s‚Ä≤ ) = K(s‚Ä≤ ) ‚à™ exo(s‚Ä≤ ) in place of
poss K,exo (s‚Ä≤ ) = {K(s‚Ä≤ )} ‚à™ exo(s‚Ä≤ ).
The following proposition is immediate.
Proposition 1 Given a system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A, and a function exo, a set of states
S ‚äÜ S is stabilizable with respect to a set of states E ‚äÜ S under a control function K for A w.r.t. Aagent iff
S is stabilizable with respect to E under a super-control K + for A w.r.t. Aagent . Furthermore, each such
K is a refinement of some K + with this property (i.e., for each s, K(s) ‚àà K + (s) and K(s) is defined iff
K + (s) is defined), and each refinement K of K + is a control function witnessing stabilizability of S with
respect to E.

3 Example Scenario: Two Finite Buffers
In this section, we introduce a running example which we will use in illustrating the notion of stabilizability
and also other concepts in the rest of the paper.
We imagine a system with two finite buffers, b1 and b2 , where objects are added to b1 in an uncontrollable
way. An agent moves objects from b1 to b2 and processes them there. When an object has been processed,
it is automatically removed from b2 . This is a slight modification of a finite buffer example from [45] and
generalizes problems such as ftp agents maintaining a clean ftp area by moving submitted files to other
directories, or robots moving physical objects from one location to another.
In our framework, we shall describe a system Ab which models this scenario. For simplicity, we assume
that the agent has three control actions M12 that moves an object from b1 to b2 (if such an object exists), the
opposite action, M21 that moves an object from b2 to b1 , and Proc that processes and removes an object in
b2 . There is one exogenous action, Ins, that inserts an object into buffer b1 . The capacities of b1 and b2 are
assumed to be equal.
Let us assume that the control goal of this system is to keep b1 empty. Then, the system is not stabilizable,
since objects can be continually inserted before the agent has a chance to empty the buffer. However, if
no insertions are performed for a certain window of non-interference, the agent can always empty b1 . This
implies that the system is maintainable but not stabilizable. We now make the above argument explicit by
using a concrete instance of Ab .

INFSYS RR 1843-04-04

7

Example 1 (Running Example)
We assume that the maximum capacity of the buffers b1 and b2 is 3. The components of Ab = (Sb , Ab , Œ¶b ,
poss b ) are then as follows.
‚Ä¢ We model every state by the current number of objects in b1 and b2 . That is, a state s is identified by
a pair of integers hi, ji where i denotes the number of objects in b1 and j the number of objects in b2 .
With the maximum capacity of 3, the set of states, Sb , consists of 4 √ó 4 = 16 states and is given by
Sb = {0, 1, 2, 3} √ó {0, 1, 2, 3}.
‚Ä¢ The set of actions is Ab = {M12 , M21 , Proc, Ins}.
‚Ä¢ We assume that the transition function Œ¶b is deterministic, i.e., |Œ¶b (s, a)| ‚â§ 1, defined as follows,
where we write Œ¶b (s, a) = s‚Ä≤ for Œ¶b (s, a) = {s‚Ä≤ }. For every i, j ‚àà {0, . . . , 3}, let
Œ¶b (hi, ji, M12 ) = hi ‚àí 1, j + 1i
Œ¶b (hi, ji, M21 ) = hi + 1, j ‚àí 1i,
Œ¶b (hi, ji, Proc) = hi, j ‚àí 1i,
Œ¶b (hi, ji, Ins) = hi + 1, ji,
where addition and subtraction are modulo 3, and and in all other cases Œ¶b (s, a) = ‚àÖ.
‚Ä¢ The enabling function, poss b , is defined by

M12 ‚àà poss b (hi, ji)

iff i ‚â• 1 and j ‚â§ 2

M21 ‚àà poss b (hi, ji)

iff i ‚â§ 2 and j ‚â• 1

Proc ‚àà poss b (hi, ji)
Ins ‚àà poss b (hi, ji)

iff j ‚â• 1
iff i ‚â§ 2

It is easy to see that for S = {h0, 0i} (no objects in the buffers) and E = {h0, 0i, h0, 1i, h0, 2i, h0, 3i} (that
is, we want to keep b1 empty) S is not stabilizable w.r.t. E, since the exogenous action Ins can always
interfere in the task of bringing the system back to E. For example, consider the control Kb defined as
follows:
Kb (hi, ji) = M12 when i ‚â• 1 and j < 3, and
Kb (hi, ji) = Proc when (i = 0 and j ‚â• 1) or j = 3.
Intuitively, the above control directs the transfer of objects from buffer 1 to 2 whenever possible, and if that
is not possible it directs processing of objects in buffer 2 if that is possible. In Figure 1, which shows the
transition diagram between states, the transitions by the control Kb are marked with M12 and Proc.
Consider the following trajectory consistent with the control system AK,exo = (Sb , Ab , Œ¶b , poss bK ,exo ):
b

œÑ = h0, 0i, Ins, h1, 0i, Ins, h2, 0i, M12 , h1, 1i, Ins, h2, 1i, M12 , h1, 2i, Ins, h2, 2i, M12 , h1, 3i, Proc.

8

INFSYS RR 1843-04-04

h0,0i

Ins

M21
Proc

h0,1i

M12
Ins

M21
Proc

h0,2i

M21
Ins

M21
Proc

h0,3i

M12
Ins

h1,0i

Ins

M21
Proc

h1,1i

M12
Ins

M21
Proc

h1,2i

M12
Ins

M21
Proc

h1,3i

M12
Ins

h2,0i

Ins

M21
Proc

h2,1i

M12
Ins

M21
Proc

h2,2i

M12
Ins

M21
Proc

h2,3i

M12
Ins

h3,0i

Proc

h3,1i

Proc

h3,2i

Proc

h3,3i

Figure 2: The transition diagram of the buffer system Ab for the concrete instance (buffer capacity 3).

It consists of a prefix h0, 0i, Ins, . . . , M12 and a cycle h1, 2i, . . . , Proc. In œÑ , no state in E is ever reached
after the starting state h0, 0i. Similar trajectories can be found for any control and hence S is not stabilizable
with respect to E.
On the other hand, S = {h0, 0i} is stabilizable w.r.t. E ‚Ä≤ = {0, 1, 2} √ó {0, 1, 2, 3} (that is, we want to
have at most two objects in b1 at any time): Following Kb we can go from any of the states in Sb \ E ‚Ä≤ =
{h3, 0i, h3, 1i, h3, 2i, h3, 3i} to E ‚Ä≤ with the execution of at most two control actions, while no exogenous
actions are possible for those states.
2

4 Limited Interference and k-Maintainability
As we mentioned in Section 1, our main intuition behind the notion of maintainability is that maintenance
becomes possible only if there is a window of non-interference from the environment during which maintenance is performed by the agent. In other words, an agent k-maintains a condition c if its control (or its
reaction) is such that if we allow it to make the controlling actions without interference from the environment
for at least k steps, then it gets to a state that satisfies c within those k steps.
Our definition of maintainability has the following parameters:
(i) a set of initial states S that the system may be initially in,
(ii) a set of desired states E that we want to maintain,
(iii) a system A = (S, A, Œ¶, poss),
(iv) a set Aagent ‚äÜ A of agent actions,
(v) a function exo : S ‚Üí 2Aenv detailing exogenous actions, such that exo(s) ‚äÜ poss(s), and
(vi) a control function K (mapping a relevant part of S to Aagent ) such that K(s) ‚àà poss(s).

INFSYS RR 1843-04-04

9

The next step is to formulate when the control K maintains E assuming that the system is initially in one of
the states in S. The exogenous actions are accounted for by defining the notion of a closure of S with respect
to the system AK,exo = (S, A, Œ¶, poss K,exo ), denoted by Closure(S, AK,exo ); where poss K,exo (s) is the
set {K(s)} ‚à™ exo(s). This closure is the set of states that the system may get into starting from S because
of K and/or exo. Maintainability is then defined by requiring the control to be such that if the system is
in any state in the closure and is given a window of non-interference from exogenous actions, then it gets
into a desired state during that window. One of the importance of using the notion of closure is that one can
focus only on a possibly smaller state of states, rather than all the states, thus limiting the possibility of an
exponential blow-up - as warned in [26] - of the number of control rules.
Now a next question might be: Suppose the above condition of maintainability is satisfied, and while the
control is leading the system towards a desired state, an exogenous action happens and takes the system off
that path. What then? The answer is that the state the system will reach after the exogenous action will be a
state from the closure. Thus, if the system is then left alone (without interference from exogenous actions)
it will be again on its way to a desired state. So in our notion of maintainability, the control is always taking
the system towards a desired state, and after any disturbance from an exogenous action, the control again
puts the system back on a path to a desired state.
We now formally define the notions of closure and maintainability.
Definition 10 (Closure) Let A = (S, A, Œ¶, poss) be a system and let S ‚äÜ S be a set of states. Then the
S
closure of A w.r.t. S, denoted by Closure(S, A), is defined by Closure(S, A) = s‚ààS R(A, s).
2
Example 2 In the system A in Figure 1, we have that R(A, d) = {d, h} and R(A, f ) = {f, g, h}, and
therefore Closure({d, f }, A) = {d, f, g, h}.
2
We note some properties of Closure(S, A), which follow immediately from the definition of R(A, s).
Lemma 2 Let A = (S, A, Œ¶, poss) be a system and S ‚äÜ S be a set of states. Then,
1. Closure(S, A) satisfies the Kuratowski closure axioms [32], i.e.,
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢

Closure(‚àÖ, A) = ‚àÖ,
S ‚äÜ Closure(S, A),
Closure(Closure(S, A), A) = Closure(S, A), and
Closure(S1 ‚à™ S2 , A) = Closure(S1 , A) ‚à™ Closure(S2 , A));

2. if s ‚àà Closure(S, A), and a ‚àà poss(s), then Œ¶(s, a) ‚äÜ Closure(S, A).

2

Next we define the notion of unfolding a control.
Definition 11 (Unfold k (s, A, K)) Let A=(S, A, Œ¶, poss) be a system, let s‚ààS, and let K be a control for
A. Then Unfold k (s, A, K) is the set of all sequences œÉ = s0 , s1 , . . . , sl where l‚â§k and s0 =s such that
K(sj ) is defined for all j<l, sj+1 ‚ààŒ¶(sj , K(sj )), and if l<k, then K(sl ) is undefined.
2
Intuitively, an element of Unfold k (s, A, K) is a sequence of states of length at most k+1 that the system may
go through if it follows the control K starting from the state s. The above definition of Unfold k (s, A, K) is
easily extended to the case when K is a super-control, meaning K(s) is a set of actions instead of a single
S
action. In that case, we overload Œ¶ and for any set of actions a‚àó , define Œ¶(s, a‚àó ) = a‚ààa‚àó Œ¶(s, a).
We now define the notion of k-maintainability. This definition can be used to verify the correctness of a
control.

10

INFSYS RR 1843-04-04

Definition 12 (k-Maintainability) Given a system A = (S, A, Œ¶, poss), a set of agents action Aagent ‚äÜ A,
and a specification of exogenous action occurrence exo, we say that a control2 K for A w.r.t. Aagent kmaintains S ‚äÜ S with respect to E ‚äÜ S, where k ‚â• 0, if for each state s ‚àà Closure(S, AK,exo ) and each
sequence œÉ = s0 , s1 , . . . , sl in Unfold k (s, A, K) with s0 = s, it holds that {s0 , . . . , sl } ‚à© E 6= ‚àÖ.
We say that a set of states S ‚äÜ S (resp. A, if S = S) is k-maintainable, k ‚â• 0, with respect to a set of states
E ‚äÜ S, if there exists a control K which k-maintains S w.r.t. E. K is then referred to as the witnessing
control function. Furthermore, S (resp. A) is called maintainable w.r.t E, if S (resp. A) is k-maintainable
w.r.t. E for some k ‚â• 0.
2
We often will omit explicit mention of Aagent , S, and E for control functions and maintainability if they are
clear from the context.
Intuitively, the condition {s0 , s1 , . . . , sl } ‚à© E 6= ‚àÖ above means that we can get from a state s0 outside E to
a state in E within at most k transitions‚Äîwhere each transition is dictated by the control K‚Äîif the world
were to unfold as in s = s0 , s1 , . . . , sl . In particular, 0-maintainability means that the agent has nothing to
do: after any exogenous action happening, the system will be in a state from E. Therefore, a trivial control
K will do which is undefined on every state.
Example 3 Reconsider the system A in Figure 1. Let us assume that Aagent = { a, a‚Ä≤ }, that exo(s)
= { e } iff s = f and that exo(s) = ‚àÖ otherwise. Suppose now that we want a 3-maintainable control
policy for S = {b} w.r.t. E = {h}. Clearly, such a control policy K is to take a in b, c, and d. Indeed,
Closure({b}, AK,exo ) = {b, c, d, h} and Unfold 3 (b, A, K) = {hb, c, d, hi}, Unfold 3 (c, A, K) = {hc, d, hi},
and Unfold 3 (d, A, K) = {hd, hi}; furthermore, each sequence contains h.
Suppose now that Œ¶(c, a)={d, f } instead of {d} (i.e., nondeterminism in c). Then, no k-maintainable
control policy for S = {b} w.r.t. E = {h} exists for any k ‚â• 0. Indeed, the agent can always end up in the
dead-end g. If, however, in addition Œ¶(g, a‚Ä≤ ) = {f, h} and a‚Ä≤ ‚àà poss(g), a 3-maintainable control policy K
is K(s) = a for s ‚àà {b, c, d, f } and K(g)= a‚Ä≤ .
2
Example 4 Buffer Example (cont‚Äôd)
Earlier we showed that in Ab , S = {h0, 0i} is not stabilizable w.r.t. E = {h0, 0i, h0, 1i, h0, 2i, h0, 3i}.
Thus, we might ask whether S is at least maintainable w.r.t. E? The answer is positive: For the worst case
system state, h3, 3i, a control can move the system to h3, 0i (by three transitions executing Proc) without
interfering occurrences of exogenous actions. If there then are three further transitions without interference,
the control can apply M12 three times and effect the state h0, 3i. This implies that S is 6-maintainable w.r.t.
E. We can, with a similar argument show that A is 9-maintainable w.r.t. {h0, 0i}. A similar argument can
be made with respect to the control Kb of Example 1.
However, we have that A is not maintainable w.r.t., for example, {h0, 3i} (Since we cannot go from, for
example, {h0, 0i}, to {h0, 3i} with control actions only).
2
As the above example points out, it is possible that S is maintainable but not stabilizable with respect to E.
The converse is also possible. In other words, in certain cases we may have a system where a given S is
stabilizable with respect to a set E, but yet is not maintainable. This happens when every path between a
state in S and a state in E involves at least one exogenous action. In that case the agent, who does not have
control over the exogenous actions, can not on its own make the transition from a state in S to a state in E.
However, often for each exogenous action there are equivalent (in terms of effects) agent actions. In that
case, any stabilizable system is also maintainable.
2

Note that here only K(s) for s ‚àà Closure(S, AK,exo ) is of relevance. For all other s, K(s) can be arbitrary or undefined.

INFSYS RR 1843-04-04

11

We note the following monotonicity property of k-maintainability, which is an easy consequence of the
definition:
Proposition 3 Suppose that for a system A = (S, A, Œ¶, poss), a set of agents action Aagent ‚äÜ A, and
a specification of exogenous action occurrence exo, the control function K k-maintains S ‚äÜ S w.r.t.
E ‚äÜ S. Then, K also k-maintains any set S ‚Ä≤ ‚äÜ Closure(S, AK,exo ) with respect to any set E ‚Ä≤ ‚äÜ
Closure(S, AK,exo ) such that E ‚äÜ E ‚Ä≤ .
2

4.1

An alternative characterization of k-maintainability

The characterization of stability and stabilizability in Section 2 is based on imposing conditions on trajectories obtained from the transition graph of a system. Such a characterization has the advantage that it is
amenable to developing temporal operators that can express more general conditions.
In contrast, the definition of maintainability in Definition 12 is not based on trajectories. Nonetheless, one
can give an alternative characterization based on trajectories, which we do next. To bridge from finite trajectories (which are relevant with respect to maintainability), to infinite ones as in Definition 2, we consider for
each system A = (S, A, Œ¶, poss) an extension, A‚àû , which results by adding a fresh environmental action
anop such that in A‚àû , for each state s we have Œ¶(s, anop ) = {s} and anop ‚àà poss(s) if poss(s) = ‚àÖ in A.
Informally, A‚àû adds infinite loops to halting states of A.
Proposition 4 Given a system A = (S, A, Œ¶, poss), a set of agents action Aagent ‚äÜ A, a specification of
exogenous action occurrence exo, and a set of states E, a set of states S is k-maintainable with respect to
E, k ‚â• 0, if and only if there exists a control K for A w.r.t. Aagent such that for each state s in S and every
‚àû
trajectory of form œÑ = s0 , a1 , s1 , a2 , . . . , aj , sj , aj+1 , . . . consistent with AK,exo
and s0 = s, it holds that
{ai+1 , . . . , ai+k } ‚äÜ Aagent or ai+k = anop for some i ‚â• 0 implies that {si , . . . , si+k } ‚à© E 6= ‚àÖ.
2
Proof. For the only if direction, suppose that S is k-maintainable w.r.t. E, witnessed by the control function
‚àû
K. Let s ‚àà S and œÑ = s0 , a1 , s1 , a2 , . . . , aj , sj , aj+1 , . . . be consistent with AK,exo
such that s0 = s and
‚àû ). If
{ai+1 , . . . , ai+k } ‚äÜ Aagent or ai+k = anop , for some i ‚â• 0. Then, we have si ‚àà Closure(S, AK,exo
k = 0, then since K is a witnessing control, we have si ‚àà E, and thus {si , si+1 , . . . , si+k } ‚à© E 6= ‚àÖ holds.
Consider thus k > 0. If ai+k ‚àà Aagent (which implies {ai+1 , . . . , ai+k } ‚äÜ Aagent ), then the sequence
si , si+1 , . . . , si+k belongs to Unfold k (si , A, K). Since K is a witnessing control function, we again have
{si , si+1 , . . . , si+k } ‚à© E 6= ‚àÖ. Otherwise, if ai+k = anop , let l ‚â• 1 be the least index such that al = anop .
‚àû , we have that K(s
By definition of AK,exo
l‚àí1 ) is undefined. Hence, the sequence œÉ = sl‚àí1 belongs to
Unfold k (sl‚àí1 , A, K). Since K is a control, it follows that sl‚àí1 ‚àà E. Since sj = sl‚àí1 for each j ‚â• l, and in
particular si+k = sl‚àí1 , it follows again that {si , si+1 , . . . , si+k } ‚à© E 6= ‚àÖ. This proves the only if direction.
Conversely, suppose K is a control for A w.r.t. Aagent such that for each s ‚àà S and trajectory œÑ =
‚àû
and s0 = s, it holds that {ai+1 , . . . , ai+k } ‚äÜ
s0 , a1 , s1 , a2 , . . . , aj , sj , aj+1 , . . . consistent with AK,exo
Aagent or ai+k = anop for some i ‚â• 0 implies that {si , si+1 , . . . , si+k } ‚à© E 6= ‚àÖ. We claim that K witnesses k-maintainability of S w.r.t. E. Towards a contradiction, suppose the contrary. Hence, it follows from
‚àû , that there is some state s ‚àà S and trajectory œÑ = s , a , s , a , . . . , a , s , a
the definition of AK,exo
0 1 1 2
j j j+1 , . . .
‚àû ) and
‚àû
consistent with AK,exo and s0 = s, such that for some j ‚â• 0 we have sj ‚àà Closure(S, AK,exo
sj , sj+1 , . . . , sj+l is in Unfold k (sj , A, K), where l ‚â§ k, but E ‚à© {sj , . . . , sj+l } = ‚àÖ.
By definition of Unfold k (sj , A, K), we have that {aj+1 , . . . , aj+l‚àí1 } ‚äÜ Aagent and that aj+l = aj+l+1
= ¬∑ ¬∑ ¬∑ = aj+k = anop . By hypothesis, E ‚à© {sj , . . . , sj+k } =
6 ‚àÖ holds. Thus, we conclude that E ‚à©
{sj+l+1 , . . . , sj+k } =
6 ‚àÖ must hold, and hence l < k. However, by definition of Œ¶(s, anop ) we have sj+l =

12

INFSYS RR 1843-04-04

sj+l+1 = ¬∑ ¬∑ ¬∑ = sj+k . This implies that E ‚à© {sj , . . . , sj+l } =
6 ‚àÖ, which is a contradiction. This proves that K
witnesses k-maintainability of S w.r.t. E.
2
While this result shows that we could equally well have developed our notion of k-maintainability on the
basis of trajectories, in the rest of this paper we shall stick to the setting which uses closure and unfolding.
We find the latter more intuitive, as well as more convenient for designing algorithms and for proofs. Furthermore, this setting requires no special handling of possible finite trajectories, which complicates matters
as becomes apparent from Proposition 4.

5 Polynomial Time Methods to Construct k-Maintainable Controls
Now that we have defined the notion of k-maintainability, our next step is to show how some k-maintainable
control can be constructed in an automated way. We start with some historical background. There has been
extensive use of situation control rules [17] and reactive control in the literature. But there have been far
fewer efforts [30] to define correctness of such control rules3 , and to automatically construct correct control
rules. In [31], it is suggested that in a control rule of the form: ‚Äúif condition c is satisfied then do action
a‚Äù, the action a is the action that leads to the goal from any state where the condition c is satisfied. In [5] a
formal meaning of ‚Äúleads to‚Äù is given as: for all states s that satisfy c, a is the first action of a minimal cost
plan from s to the goal. Using this definition, an algorithm is presented in [39] to construct k-maintainable
controls. This algorithm is sound but not complete, in the sense that it generates correct controls only, but
there is no guarantee that it will find always a control if one exists. The difficulty in developing a complete
algorithm ‚Äì also recognized in [29] in a slightly different context ‚Äì can be explained as follows. Suppose
one were to do forward search from a state in S. Now suppose there are multiple actions from this state that
‚Äòlead‚Äô to E. Deciding on which of the actions or which subsets one needs to chose is a nondeterministic
choice necessitating backtracking if one were to discover that a particular choice leads to a state (due to
exogenous actions) from where E can not be reached. Same happens in backward search too. In this paper
we overcome the problems one faces in following the straightforward approaches and give a sound and
complete algorithm for constructing k-maintainable control policies.
We provide it in two sets: First we consider the case when the transition function Œ¶ is deterministic, and then
we generalize to the case where Œ¶ may be non-deterministic. In each case, we present different methods,
which illustrates our discovery process and also gives a better grasp of the final algorithm. We first present
an encoding of our problem as a propositional theory and appeal to propositional SAT solvers to construct
the control. As it turns out, this encoding is in a tractable fragment of SAT, for which specialized solvers (in
particular, Horn SAT solvers) can be used easily. Finally, we present a direct algorithm distilled from the
previous methods.
The reasoning behind this line of presentation is the following:
(i) It illustrates the methodology of using SAT and Horn SAT encodings to solve problems;
(ii) the encodings allow us to quickly implement and test algorithms;
(iii) the proof of correctness mimics the encodings; and
(iv) we can exploit known complexity results for Horn SAT to determine the complexity of our algorithm,
and in particularly to establish tractability.
3
Here we exclude the works related to MDPs as it is not known how to express the kind of goal we are interested in ‚Äì such as k
maintenance goals ‚Äì using reward functions.

INFSYS RR 1843-04-04

13

As for (ii), we can make use of Answer Set Solvers such as DLV [20, 33] or Smodels [40, 50] which extend
Horn logic programs by nonmonotonic negation. These solvers allow efficient computation of the least
model and some maximal models of a Horn theory, and can be exploited to construct robust or ‚Äúsmall‚Äù
controls, respectively.
The problem we want to solve, which we refer to as k-M AINTAIN, has the following input and output:
Input: An input I is a system A = (S, A, Œ¶, poss), sets of states E ‚äÜ S and S ‚äÜ S, a set Aagent ‚äÜ A, a
function exo, and an integer k ‚â• 0.
Output: A control K such that S is k-maintainable with respect to E (using the control K), if such a control
exists. Otherwise the output is the answer that no such control exists.
We assume here that the functions poss(s) and exo(s) can be efficiently evaluated; e.g., when both functions
are given by their graphs (i.e., in a table).

5.1

Deterministic transition function Œ¶(s, a)

We start with the case of deterministic transitions, i.e., Œ¶(s, a) is a singleton set {s‚Ä≤ } whenever nonempty.
In abuse of notation, we simply will write Œ¶(s, a) = s‚Ä≤ in this case.
Our first algorithm to solve k-M AINTAIN will be based on a reduction to propositional SAT solving. Given
an input I for k-M AINTAIN, we construct a SAT instance sat(I) in polynomial time such that sat(I) is
satisfiable if and only if the input I allows for a k-maintainable control, and that the satisfying assignments
for sat(I) encode possible such controls.
In our encoding, we shall use for each state s ‚àà S propositional variables s0 , s1 , . . . , sk . Intuitively, si will
denote that there is a path from state s to some state in E using only agent actions and at most i of them, to
which we refer as ‚Äúthere is an a-path from s to E of length at most i.‚Äù
The encoding sat(I) contains the following formulas:
(0) For all s ‚àà S, and for all j, 0 ‚â§ j < k:
sj ‚áí sj+1
(1) For all s ‚àà E ‚à© S:
s0
(2) For any two states s, s‚Ä≤ ‚àà S such that Œ¶(a, s) = s‚Ä≤ for some action a ‚àà exo(s):
sk ‚áí s‚Ä≤k
(3) For any state s ‚àà S \ E and all i, 1 ‚â§ i ‚â§ k:
si ‚áí
P S(s) =

‚Ä≤
s‚Ä≤ ‚ààP S(s) si‚àí1 ,
{s‚Ä≤ ‚àà S | ‚àÉa ‚àà

W

(4) For all s ‚àà S \ E:
sk
(5) For all s ‚àà S \ E:
¬¨s0

where
Aagent ‚à© poss(s) : s‚Ä≤ = Œ¶(a, s)};

14

INFSYS RR 1843-04-04

The intuition behind the above encoding is as follows. The clauses in (0) state that if there is an a-path from
s to E of length at most j then, logically, there is also an a-path of length at most j+1. Next, the clauses in
(1) say that for states s in S ‚à© E, there is an a-path of length 0 from s to E. Next, (4) states that for any
starting state s in S outside E, there is an a-path from s to E of length at most k, and (5) states that for any
state s outside E, there is no a-path from s to E of length 0. The clauses in (3) state that if, for any state s,
there is an a-path from s to E of length at most i, then for some possible agent action a and successor state
s‚Ä≤ = Œ¶(a, s), there is an a-path from s‚Ä≤ to E of length at most i-1. When looking for k-maintainable controls
the clauses in (2) take into account the possibility that s may be in the closure. If indeed s is in the closure
and there is an a-path from s to E of length at most k, then the same must be true with respect to the states
s‚Ä≤ reachable from s using exogenous actions. When looking for super-control they play a role in computing
maximal super-controls. The role of each of the above clauses become more clear when relating the models
of sat(I) with controls that k-maintain.
Given any model M of sat(I), we can extract a desired control K from it by defining K(s) = a for all s
outside E with sk true in M , where a is a possible agent action in s such that s‚Ä≤ = Œ¶(s, a) and s‚Ä≤ is closer
to E than s is. In case of multiple possible a and s‚Ä≤ , one a can be arbitrarily picked. Otherwise, K(s) is left
undefined.
In particular, for k = 0, only the clauses from (1), (2), (4) and (5) do exist. As easily seen, sat(I) is
satisfiable in this case if and only if S ‚äÜ E and no exogenous action leads outside E, i.e., the closure of S
under exogenous actions is contained in E. This means that no actions of the agent are required at any point
in time, and we thus obtain the trivial 0-control K which is undefined on all states, as desired.
The next result states that the SAT encoding works properly in general.
Proposition 5 Let I consist of a system A = (S, A, Œ¶, poss) where Œ¶ is deterministic, a set Aagent ‚äÜ A,
sets of states E ‚äÜ S and S ‚äÜ S, an exogenous function exo, and an integer k. For any model M of sat(I),
let CM = {s ‚àà S | M |= sk }, and for any state s ‚àà CM let ‚ÑìM (s) denote the smallest index j such that
M |= sj (i.e., s0 , s1 ,. . . , sj ‚àó ‚àí1 are f alse and sj ‚àó is true), which we call the level of s w.r.t. M . Then,
(i) S is k-maintainable w.r.t. E iff sat(I) is satisfiable.
+
(ii) Given any model M of sat(I), the partial function KM
: S ‚Üí 2Aagent defined on CM \ E such that
+
KM
(s) = {a ‚àà Aagent ‚à© poss(s) | Œ¶(s, a) = s‚Ä≤ ,

s‚Ä≤ ‚àà CM , ‚ÑìM (s‚Ä≤ ) < ‚ÑìM (s)},
is a valid super-control for A w.r.t. Aagent ;
+
(iii) any control K which refines KM
for some model M of sat(I) k-maintains S w.r.t. E.

2

Proof. Since the if direction of (i) follows from (ii) and (iii), it is sufficient to show the only if direction of
(i), and then (ii) and (iii).
As for the only if direction of (i), suppose S is k-maintainable w.r.t. E. Then there exists a control K such
that for each state s ‚àà Closure(S, AK,exo ), and for each sequence œÉ = s(0) , s(1) , . . . , s(l) where s(0) = s in
Unfold k (s, A, K), {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ. We now construct an interpretation M for sat(I) as follows.
Since Œ¶ is deterministic, for each s in Closure(S, AK,exo ) there is a unique sequence s(0) (=s), s(1) , . . ., s(l)
in Unfold k (s, A, K). Let i (‚â• 0) be the smallest index such that s(i) ‚àà E. We assign f alse to s0 , s1 ,. . . ,
si‚àí1 and assign true to si , si+1 ,. . . , sk . All other propositions are assigned f alse. We now argue that M is
a model of sat(I).

INFSYS RR 1843-04-04

15

It is straightforward to see that M satisfies the formulas generated by (0), (1), (4) and (5). Now consider the
formulas generated in (2). If sk is true, then s ‚àà Closure(S, AK,exo ) by construction. In this case, in order to
k-maintain S w.r.t. E, for any s‚Ä≤ = Œ¶(a, s) of an exogenous action a, one of the states in Unfold k (s‚Ä≤ , A, K)
must be in E. Hence, s‚Ä≤k has been assigned true in M . Now let us consider the formulas generated in (3).
If si is true for some i ‚â§ k, then there must be an a-path from s to E of length at most i, emerging from
possible agent actions only (via control K). Let s‚Ä≤ be the next state in this path. Obviously, there must be an
a-path from s‚Ä≤ to E of length at most i‚àí1 (via K). Hence, s‚Ä≤i‚àí1 must be true in M . Thus, M is a model of
sat(I), which means that sat(I) is satisfiable.
+
To show (ii), let us assume that sat(I) has a model M and consider the partial function KM
: S ‚Üí 2Aagent
+
which is defined on CM \ E by KM (s) = {a ‚àà Aagent ‚à© poss(s) | Œ¶(s, a) = s‚Ä≤ , s‚Ä≤ ‚àà CM and ‚ÑìM (s‚Ä≤ ) <
+
+
‚ÑìM (s)}; and for any other s, KM
(s) is undefined. For KM
to be a valid super-control it must satisfy the
+
+
+
following conditions: (a) KM (s) ‚äÜ poss(s), and (b) KM (s) 6= ‚àÖ whenever KM
(s) is defined. Condition
+
+
(a) is true by virtue of the construction of KM . Condition (b) is true because KM
(s) is defined when
s ‚àà CM \ E which means M |= sk for some k > 0, which in turn means that ‚ÑìM (s) > 0, thus making
+
KM
(s) 6= ‚àÖ.
+
Now to show (iii), let K be any control which refines KM
for some model M of sat(I). Let the distance
dK (s, S) of a state s from the set of states S be the minimum number of transitions ‚Äì through exogenous
actions and/or control actions dictated by the control K ‚Äì needed to reach s from any state in S.
We will show, by using induction on d(s, S) ‚â• 0, that for every state s ‚àà Closure(S, AK,exo ) and every
sequence œÉ = s(0) , s(1) , . . . , s(l) with s = s(0) in Unfold k (s, A, K), the set {s(0) , . . . , s(l) } intersects with
E and that M |= sk (i.e., s ‚àà CM ). This proves the claim.
The base case, d(s, S) = 0, is about states s ‚àà S. From the formulas in (0), (1), and (4) we have M |= sk
+
for every such state s. Then from the construction of KM
above and the formulas in (3), it follows that
(0)
(1)
for any such state s and for every sequence œÉ = s , s , . . . , s(l) with s = s(0) in Unfold k (s, A, K), the
+ (i)
set {s(0) , . . . , s(l) } intersects with E. Indeed, by taking the action K(s(i) ) (‚àà KM
(s )) in s(i) , a state
(i+1)
(i+1)
(i+1)
(i)
s
= Œ¶(s, K(s
)) is reached, such that ‚ÑìM (s
) < ‚ÑìM (s ). If l = k, then clearly ‚ÑìM (s(l) ) = 0;
(l)
otherwise, if l < k, then K(s ) must be undefined, which again implies ‚ÑìM (s(l) ) = 0. Thus, s(l) ‚àà E,
which means that {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ.
Thus the statement holds in the base case. Now for the induction step, let us assume that it holds for every
state s ‚àà Closure(S, AK,exo ) at distance d ‚â• 0 from S. Let us now consider a state s ‚àà Closure(S, AK,exo )
at distance d+1 from S. Then there is a state s‚Ä≤ at distance d from S such that s = Œ¶(a, s‚Ä≤ ) and either (i)
a ‚àà exo(s‚Ä≤ ) or (ii) a = K(s‚Ä≤ ). In both cases, we have by the induction hypothesis that M |= s‚Ä≤k , and
using (2), (3), and (1) we can conclude M |= sk ; Furthermore, by construction of K and the formulas in
(3), we have by similar arguments as above that for each sequence œÉ = s(0) , s(1) , . . . , s(l) with s = s(0) in
Unfold k (s, A, K), {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ.
+
This proves our claim. Now each control K as in (ii) is a refinement of KM
. This completes the proof. 2
5.1.1 Horn SAT encoding
While sat(I) is constructible in polynomial time from I, we can not automatically infer that solving kM AINTAIN is polynomial, since SAT is a canonical NP-hard problem. However, a closer look at the structure
of the clauses in sat(I) reveals that this instance is solvable in polynomial time. Indeed, it is a reverse Horn
theory; i.e., by reversing the propositions, we obtain a Horn theory. Let us use propositions si whose intuitive
meaning is converse of the meaning of si . Then the Horn theory corresponding to sat(I), denoted sat(I),
is as follows:

16

INFSYS RR 1843-04-04

(0) For all s‚ààS and j, 0‚â§j<k:
sj+1 ‚áí sj .
(1) For all s ‚àà E ‚à© S:
s0 ‚áí ‚ä•.
(2) For any states s, s‚Ä≤ ‚àà S such that s‚Ä≤ =Œ¶(a, s) for some action a‚ààexo(s):
s‚Ä≤k ‚áí sk .
(3) For any state in S \ E, and for all i, 1 ‚â§ i ‚â§ k:
V

‚Ä≤
s‚Ä≤ ‚ààP S(s) si‚àí1



‚áí si ,

where

P S(s)={s‚Ä≤ ‚ààS | ‚àÉa‚ààAagent ‚à©poss(s): s‚Ä≤ =Œ¶(a, s)}.
(4) For all s ‚àà S \ E:
sk ‚áí ‚ä•.
(5) For all s ‚àà S \ E:
s0 .
Here, ‚ä• denotes falsity. We then obtain a result similar to Proposition 5, and the models M of sat(I) lead
to k-maintainable controls, which we can construct similarly; just replace in part (ii) CM with C M = {s ‚àà
S | M 6|= sk }. Notice that C M coincides with the set of states CM for the model M of sat(I) such that
M |= p iff M 6|= p, for each atom p.
We now illustrate the above Horn encoding with respect to an example.
Example 5 Consider the system A = (S, A, Œ¶, poss), where S = {b, c, d, f, g, h}, A = { a, a‚Ä≤ , e}, and the
(deterministic) transition function Œ¶ was shown in Figure 1, where Œ¶(s, a) = s‚Ä≤ iff an arc s ‚Üí s‚Ä≤ labeled
with a is present and poss(s) are all actions that label arcs leaving s.
For A = { a, a‚Ä≤ } and exo(s) = { e } iff s = f and exo(s) = ‚àÖ otherwise, this leads for S = {b}, E = {h},
and k = 3 to the following Horn encoding sat(I):
(From 0)
b1 ‚áí b 0 .
d1 ‚áí d0 .
g1 ‚áí g0 .
(From 1)
(From 2)
g3 ‚áí f3 .
(From 3)

b2 ‚áí b 1 .
d2 ‚áí d1 .
g2 ‚áí g1 .

b3 ‚áí b 2 .
d3 ‚áí d2 .
g3 ‚áí g2 .

c1 ‚áí c0 .
f1 ‚áí f0 .
h1 ‚áí h0 .

c2 ‚áí c1 .
f2 ‚áí f1 .
h2 ‚áí h1 .

c3 ‚áí c2 .
f3 ‚áí f2 .
h3 ‚áí h2 .

INFSYS RR 1843-04-04

c0 ‚àß f0 ‚áí b1 .
d 0 ‚áí c1 .
h0 ‚áí d1 .
h0 ‚áí f1 .
g1 .

17

c1 ‚àß f1 ‚áí b2 .
d 1 ‚áí c2 .
h1 ‚áí d2 .
h1 ‚áí f2 .
g2 .

c2 ‚àß f2 ‚áí b3 .
d 2 ‚áí c3 .
h2 ‚áí d3 .
h2 ‚áí f3 .
g3 .

(From 4)
b3 ‚áí ‚ä•.
(From 5)
b0 .

c0 .

d0 .

f0 .

g0 .

This theory has the least model
M = {g3 , g2 , g1 , g0 , f3 , f2 , f1 , f0 , b2 , b1 , b0 , c1 , c0 , d0 };
hence, C M = {b, c, d, h}, which gives rise to the super-control K + such that K + (s) = {a} for s ‚àà {b, c, d}
and K + (s) is undefined for s ‚àà {f, g, h}. In this case, there is a single control K refining K + , which has
K(s) = a for s ‚àà {b, c, d} and is undefined otherwise. This is intuitive: The agent must reach h, and has
to avoid taking a‚Ä≤ in b since then it might arrive at the no-good state g. Thus, she has to take a in b and, as
the only choice, in the subsequent states c and d. Also, we might not add any state apart from b, c, and d
without losing 3-maintainability. In this particular case, M is also maximal on the propositions s3 , where
s ‚àà S \ E = {b, c, d, f, g}: By (4), we can not add b3 , and by (0) and the clauses c2 ‚àß f2 ‚áí b3 and d1 ‚áí c2
in (3) then also neither c3 nor d3 . Thus, the above control K is also smallest and, in fact, the only one
possible for 3-maintainability.
2
As computing a model of a Horn theory is a well-known polynomial problem [16], we thus obtain the
following result.
Theorem 6 Under deterministic state transitions, problem k-M AINTAIN is solvable in polynomial time. 2
An interesting aspect of the above is that, as well-known, each satisfiable Horn theory T has the least model,
MT , which is given by the intersection of all its models. Moreover, the least model is computable in linear
time, cf. [16, 37]. This model not only leads to a k-maintainable control, but also leads to a maximal control,
in the sense that the control is defined on a greatest set of states outside E among all possible k-maintainable
controls for S ‚Ä≤ w.r.t. E such that S ‚äÜ S ‚Ä≤ . This gives a clear picture of which other states may be added to
S while k-maintainability is preserved; namely, any states in C MT . Furthermore, any control K computed
from MT applying the method in Proposition 5 (using C MT ) works for such an extension of S as well.
On the other hand, intuitively a k-maintainable control constructed from some maximal model of sat(I) with
respect to the propositions sk is undefined to a largest extent, and works merely for a smallest extension.
We may generate, starting from MT , such a maximal model of T by trying to flip first, step by step all
propositions sk which are f alse to true, as well as other propositions entailed. In this way, we can generate
a maximal model of T on {sk | s ‚àà S \ E} in polynomial time, from which a ‚Äúlean‚Äù control can also be
computed in polynomial time.

18

5.2

INFSYS RR 1843-04-04

Non-deterministic transition function Œ¶(s, a)

We now generalize our method for constructing k-maintainable controls to the case in which transitions due
to Œ¶ may be non-deterministic. As before, we first present a general propositional SAT encoding, and then
rewrite to a propositional Horn SAT encoding. To explain some of the notations, we need the following
definition, which generalizes the notion of an a-path to the non-deterministic setting.
Definition 13 (a-path) We say that there exists an a-path of length at most k ‚â• 0 from a state s to a set of
states S ‚Ä≤ , if either s ‚àà S ‚Ä≤ , or s ‚àà
/ S ‚Ä≤ , k > 0 and there is some action a ‚àà Aagent ‚à© poss(s) such that for
every s‚Ä≤ ‚àà Œ¶(s, a) there exists an a-path of length at most k ‚àí 1 from s‚Ä≤ to S ‚Ä≤ .
2
In the following encoding of an instance I of problem k-M AINTAIN to SAT, referred to as sat‚Ä≤ (I), si will
again intuitively denote that there is an a-path from s to E of length at most i. The proposition s ai , i > 0,
will denote that for such s there is an a-path from s to E of length at most i starting with action a (‚àà poss(s)).
The encoding sat‚Ä≤ (I) has again groups (0)‚Äì(5) of clauses as follows:
(0), (1), (4) and (5) are the same as in sat(I).
(2) For any state s ‚àà S and s‚Ä≤ such that s‚Ä≤ ‚àà Œ¶(a, s) for some action a ‚àà exo(s):
sk ‚áí s‚Ä≤k
(3) For every state s ‚àà S \ E and for all i, 1 ‚â§ i ‚â§ k:
(3.1) si ‚áí a‚ààAagent ‚à©poss(s) s ai ;
(3.2) for every a ‚àà Aagent ‚à©poss(s) and s‚Ä≤ ‚ààŒ¶(s, a):
W

s ai ‚áí s‚Ä≤i‚àí1 ;
(3.3) for every a ‚àà Aagent ‚à© poss(s), if i < k:
s ai ‚áí s ai+1 .
Group (2) above is very similar to group (2) of sat(I) in the previous subsection. The only change is that
we now have s‚Ä≤ ‚àà Œ¶(a, s) instead of s‚Ä≤ = Œ¶(a, s). The main difference is in group (3). We now explain
those clauses. The clauses in (3.1) and (3.2) together state that if there is an a-path from s to E of length at
most i, then there is some possible action a for the agent, such that for each state s‚Ä≤ that potentially results
by taking a in s, there must be an a-path from s‚Ä≤ to E of length at most i-1. The clauses s ai ‚áí s ai+1
in (3.3) say that on a longer a-path from s the agent must be able to pick a also. Notice that there are no
formulas in sat‚Ä≤ (I) which forbid to pick different actions a and a‚Ä≤ in the same state s, and thus we have a
super-control; however, we can always refine it easily to a control.
Proposition 7 Let I consist of a system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A, sets of states E, S ‚äÜ S,
an exogenous function exo, and an integer k. For any model M of sat‚Ä≤ (I), let CM = {s ‚àà S | M |= sk },
and for any state s ‚àà CM \ E let ‚ÑìM (s) denote the smallest index j such that M |= s aj for some action
a ‚àà Aagent ‚à© poss(s), which we call the a-level of s w.r.t. M . Then,
(i) S is k-maintainable w.r.t. E iff sat‚Ä≤ (I) is satisfiable;
+
(ii) given any model M of sat‚Ä≤ (I), the partial function KM
: S ‚Üí 2Aagent which is defined on CM \ E by
+
KM
(s) = {a | M |= s a‚ÑìM (s) }

is a valid super-control; and

INFSYS RR 1843-04-04

19

+
(iii) any control K which refines KM
for some model M of sat‚Ä≤ (I) k-maintains S w.r.t. E.

Proof. The proof follows the line of argumentation in the proof of Proposition 5. It is sufficient to show the
only if direction of (i) and both (ii) and (iii).
As for the only if direction of (i), suppose S is k-maintainable w.r.t. E. Then there exists a control
K such that for each state s ‚àà Closure(S, AK,exo ), and for each sequence œÉ = s(0) , s(1) , . . . , s(l) in
Unfold k (s, A, K) where s(0) = s, {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ. We now construct an interpretation M for
sat‚Ä≤ (I) as follows.
For each s ‚àà Closure(S, AK,exo ), let in each sequence œÉ = s(0) , s(1) , . . ., s(l) in Unfold k (s, A, K) with
s = s(0) , the number iœÉ (‚â• 0) be the smallest index i such that s(i) ‚àà E, and let i‚àó be the maximum over all
iœÉ for s. Intuitively, i‚àó is the length of the longest path in the tree with root s where each node n not in E is
sprouted by taking the control action K(n) and adding each state in Œ¶(n, K(n)) as a child. Then, we assign
true to si‚àó , si‚àó +1 ,. . . , sk and, if i‚àó > 0, to s ai‚àó , s ai‚àó +1 , . . . .s ak , where K(s) = a. All other propositions
are assigned f alse in M . We now argue that M is a model of sat(I).
It is straightforward to see that M satisfies the formulas generated by (0), (1), (4) and (5). Now consider the
formulas sk ‚áí s‚Ä≤k generated in (2). If sk is true, then s ‚àà Closure(S, AK,exo ) by construction. In this case,
for any s‚Ä≤ ‚àà Œ¶(a, s) of an exogenous action a, we have s‚Ä≤ ‚àà Closure(S, AK,exo ), and since K k-maintains
S w.r.t. E, s‚Ä≤i is true in M for some i ‚â§ k which implies, by construction, that s‚Ä≤k is assigned true in M .
Let us finally consider the formulas generated in (3). If si , where s ‚àà S \ E, is assigned true in M for some
i ‚àà {1 ‚â§ i ‚â§ k}, then s ‚àà Closure(S, A, Kexo ) holds by construction of M . Since K is a k-maintaining
control and s ‚àà
/ E, we must have K(s) defined and thus, by construction of M , we have s K(s)i assigned
true in M . Since K(s) ‚àà Aagent ‚à© poss(s), the clause (3.1) is thus satisfied. Furthermore, each clause in
(3.2) is satisfied when a 6= K(s), since then sai is assigned f alse in M . For a = K(s), proposition sai
is true in M and thus, by construction, also si . Since K is k-maintaining control, every state s‚Ä≤ ‚àà Œ¶(s, a)
belongs to Closure(S, A, Kexo ). Let, for each sequence œÉ ‚Ä≤ = s(0) , s(1) , . . ., s(l) in Unfold k (s, A, K) such
that s(0) = s‚Ä≤ , the sequence P (œÉ) = s(0) , s(1) , . . . , s(i) be the shortest prefix of œÉ such that s(i) ‚àà E (notice
that i < k). Then, the sequence s, P (œÉ) is a prefix of some sequence in Unfold (s, A, K). Hence, it follows
that in the construction of M , the number i‚àó for s is larger than the one for s‚Ä≤ . Thus, by construction of M ,
it follows that s‚Ä≤i‚àí1 is assigned true in M . This means that the formulas in (3.2) are satisfied in M . Finally,
the clauses (3.3) are clearly satisfied in M by construction of M . Thus, M is a model of sat‚Ä≤ (I), which
means that sat‚Ä≤ (I) is satisfiable.
+
To show (ii), let us assume that sat‚Ä≤ (I) has a model M , and consider the partial function KM
: S ‚Üí 2Aagent
+
+
(s) ‚äÜ
which is defined on CM \ E by KM (s) = {a | M |= s a‚ÑìM (s) }. We thus have to show that KM
+
+
+
poss(s) and KM (s) 6= ‚àÖ when KM (s) is defined. By clause (3.1), and the definition of CM , ‚ÑìM , and KM
this is immediate.
+
To show (iii), let K be any control which refines KM
for some model M of sat‚Ä≤ (I). Let the distance
dK (s, S) of a state s from the set of states S be as in the proof of Proposition 5. i.e., the minimum number
of transitions ‚Äì through exogenous actions and/or control actions dictated by the control K ‚Äì needed to reach
s from any state in S.
We will show, by using induction on d(s, S) ‚â• 0, that for every state s ‚àà Closure(S, AK,exo ) and every
sequence œÉ = s(0) , s(1) , . . . , s(l) with s = s(0) in Unfold k (s, A, K), the set {s(0) , . . . , s(l) } intersects with
E and that M |= sk (i.e., s ‚àà CM ). This proves that K k-maintains S w.r.t. E.
The base case, d(s, S) = 0, is about states s ‚àà S. From the formulas in (0), (1), and (4) we have M |= sk for
every such state s. Consider any sequence œÉ = s(0) , s(1) , . . . , s(l) in Unfold k (s, A, K) such that s = s(0) .
If s ‚àà E, then we must have l = 0, and {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ. Otherwise, M |= sak where a = K(s).

20

INFSYS RR 1843-04-04

We then have s(1) ‚àà Œ¶(s, a), and thus by our construction of K and the clauses in (3.2) we have that
(1)
(0) (1)
(l)
M |= sk‚àí1 . Repeating this argument, we can infer that sk , sk‚àí1 , . . . , sk‚àíl are all assigned true in M . If
k = l, it follows from the clauses in (5) that s(l) ‚àà E. Otherwise, if l < k, then K must be undefined on
s(l) ; by the clauses (1), this again means s(l) ‚àà E. Hence, {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ.
Thus the statement holds in the base case. Now for the induction step, let us assume that it holds for
every state s ‚àà Closure(S, AK,exo ) at distance d(s, S) = d ‚â• 0 from S. Let us now consider a state
s ‚àà Closure(S, AK,exo ) at distance d(s‚Ä≤ , S) = d + 1 from S. Then there is a state s‚Ä≤ at distance d(s, S) = d
from S such that s ‚àà Œ¶(a, s‚Ä≤ ) and either (i) a ‚àà exo(s‚Ä≤ ) or (ii) a ‚àà K(s‚Ä≤ ). In both cases, we have by the
induction hypothesis that M |= s‚Ä≤k , and we can conclude M |= sk from the clauses in (2) in case (i) and
from our construction of K and the clauses in (3.2), (1), and (0) in case (ii), respectively. Furthermore, by
similar argumentation as in the case d = 0 above, we obtain that for each sequence œÉ = s(0) , s(1) , . . . , s(l)
in Unfold k (s, A, K) with s = s(0) it holds that {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ. This concludes the induction and
the proof of (iii).
2
One advantage of the encoding sat‚Ä≤ (I) over the encoding sat(I) for deterministic transition function Œ¶
above is that it directly gives us the possibility to read off a suitable control from the s ai propositions, a ‚àà
poss(s), which are true in any model M that we have computed, without looking at the transition function
Œ¶(s, a) again. On the other hand, the encoding is more involved, and uses a larger set of propositions.
Nonetheless, the structure of the formulas in sat‚Ä≤ (I) is benign for computation and allows us to compute a
model, and from it a k-maintainable control in polynomial time.
5.2.1

Horn SAT encoding (general case)

The encoding sat‚Ä≤ (I) is, like sat(I), a reverse Horn theory. We thus can rewrite sat‚Ä≤ (I) similarly to a Horn
‚Ä≤
theory, sat (I) by reversing the propositions, where the intuitive meaning of si and s ai is the converse of
‚Ä≤
the meaning of si and s ai respectively. The encoding sat (I) is as follows:
(0), (1), (4) and (5) are as in sat(I)
(2) For every states s, s‚Ä≤ ‚àà S such that s‚Ä≤ ‚àà Œ¶(a, s) for some action a ‚àà exo(s):

s‚Ä≤k ‚áí sk .

(3) For every state s ‚àà S \ E and for all i, 1 ‚â§ i ‚â§ k:
(3.1)

V

a‚ààAagent ‚à©poss(s)



s ai ‚áí si ;

(3.2) for every a ‚àà Aagent ‚à©poss(s) and s‚Ä≤ ‚ààŒ¶(s, a):
s‚Ä≤i‚àí1 ‚áí s ai ;
(3.3) for every a ‚àà Aagent ‚à© poss(s), if i < k:
s ai+1 ‚áí s ai .
We obtain from Proposition 7 easily the following result, which is the main result of this section so far.
Theorem 8 Let I consist of a system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A, sets of states E, S ‚äÜ S, an
‚Ä≤
exogenous function exo, and an integer k. Let, for any model M of sat (I), C M = {s | M 6|= sk }, and let
‚ÑìM (s) = min{j | M 6|= s aj , a ‚àà Aagent ‚à© poss(s)} for every s ‚àà S. Then,
‚Ä≤

(i) S is k-maintainable w.r.t. E iff the Horn SAT instance sat (I) is satisfiable;

INFSYS RR 1843-04-04

21
‚Ä≤

(ii) Given any model M of sat (I), every control K such that K(s) is defined iff s ‚àà C M \ E and satisfies
K(s) ‚àà {a ‚àà Aagent ‚à© poss(s) | M 6|= s aj , j = ‚ÑìM (s)},
k-maintains S w.r.t. E.

2

Corollary 9 Problem k-M AINTAIN is solvable in polynomial time. More precisely, it is solvable in time
O(kkIk), where kIk denotes the size of input I.
2
‚Ä≤

Proof. A straightforward analysis yields that the size of sat (I), measured by the number of atoms in it,
is O(k(|S| + |Œ¶| + |poss|)), if Aagent , S, E, Œ¶, poss and exo are stored in a standard way as bitmaps,
i.e., a (multi-dimensional) array with value range {0,1} (thus, kIk = O(|S|2 |A| + log k)). Furthermore,
‚Ä≤
the clauses in sat (I) can be easily generated within the same time bound. Since the least model of any
Horn theory T is computable in time O(|T |) where |T | is the number of atoms in it [16, 37], deciding
‚Ä≤
satisfiability and computing some model M of sat (I) is feasible in O(kkIk) time. Furthermore, C M and
{(s, ‚ÑìM (s)) | s ‚àà S} are computable from M in linear time in the number of atoms, using suitable data
structures, and from this a control K as in Theorem 8.(ii) in the same time. Hence, a k-maintaining control
for S w.r.t. E is computable in O(kkIk) time.
Note that a more economic representation stores S, E, Aagent as sets (i.e., lists) and Œ¶, poss, and exo by
their graphs in tables, i.e., sets of tuples {hs, a, Œ¶(s, a)i | s ‚àà S, a ‚àà A}, {hs, poss(s)i | s ‚àà S}, and
{hs, exo(s)i | s ‚àà S}. Also under this representation, and if moreover tuples where Œ¶(s, a)=‚àÖ (resp.,
poss(s)=‚àÖ and exo(s)=‚àÖ) are not stored (which is of the same order as storing the sets of tuples {hs, a, s‚Ä≤ i |
s‚Ä≤ ‚àà Œ¶(a, s)}, {hs, ai | a ‚àà poss(s)}, {hs, ai | a ‚àà exo(s)}), the O(kkIk) time bound holds. Indeed, arrays
storing S, E, and Aagent for lookup in O(1) time are constructible in time O(|S| + |A|). Then, poss agent =
{hs, ai ‚àà poss | a ‚àà Aagent } storing Aagent ‚à© poss(s) for all s is constructible in O(|poss|) time. From
‚Ä≤
this, all clauses of sat (I) except (2) and (3.2) can be readily generated in time O(k(|S| + |poss agent |)).
The clauses (2) and (3.2) can be easily constructed from Œ¶exo = {hs, a, s‚Ä≤ i ‚àà Œ¶ | a ‚àà exo(s)} and
Œ¶poss = {hs, a, s‚Ä≤ i ‚àà Œ¶ | a ‚àà poss(s)} in time O(|Œ¶exo |) and O(k|Œ¶poss |), respectively. The sets Œ¶exo and
Œ¶poss can be generated from Œ¶ and exo in time O(|Œ¶|+|exo|+poss|), using an auxiliary array aux[A, S] to
‚Ä≤
enable random access to Œ¶(a, s); notice that aux[a, s] needs not be defined if Œ¶(a, s) = ‚àÖ. In total, sat (I)
is constructible in O(|A| + |exo| + k(|S| + |Œ¶| + |poss|)) = O(kkIk) time.
2
Thus in particular, finding a maintaining control under a small window of opportunity, a k-maintaining
control for k bounded by a constant, is feasible in linear time in the size of the input.
‚Ä≤
Similar as in Section 5.1.1, the least model of the theory given by sat (I), Msat‚Ä≤ (I) , leads to a maximal
control in the sense that the pre-image of K outside E, i.e., the states outside E in which K is defined, is
greatest among all possible k-maintaining controls which include S. Furthermore, a smallest k-maintaining
‚Ä≤
control can be similarly computed from any maximal model of sat (I) with respect to the propositions sk
where s is outside E, which can be generated from Msat‚Ä≤ (I) by stepwise maximization. Again, both maximal
and smallest controls can be computed in polynomial time.
Example 6 Reconsider the system A = (S, A, Œ¶, poss) from Example 5. Let us modify the transition
function Œ¶ such that Œ¶(c, a) = {d, f } instead of Œ¶(c, a) = {d}. Then, for the respective modified instance
‚Ä≤
I of 3-M AINTAIN, denoted I1 , the encoding sat (I1 ) looks as follows.
(0), (1), (2), (4), and (5) are as in sat(I1 ) in Example 5;

22

INFSYS RR 1843-04-04

(3.1): b a1 ‚àß b a‚Ä≤1 ‚áí b1 .
c a 1 ‚áí c1 .
d a1 ‚áí d 1 .
f a1 ‚áí f1 .
g1 .
(3.2): h0 ‚áí d a1 .
d0 ‚áí c a1 .
c0 ‚áí b a 1 .

b a2 ‚àß b a‚Ä≤2 ‚áí b2 .
c a 2 ‚áí c2 .
d a2 ‚áí d 2 .
f a2 ‚áí f2 .
g2 .

h1 ‚áí d a2 .
d 1 ‚áí c a2 .
c1 ‚áí b a 2 .

(3.3): d a2 ‚áí d a1 .
c a3 ‚áí c a2 .

h2 ‚áí d a3 .
d 2 ‚áí c a3 .
c2 ‚áí b a 3 .

d a3 ‚áí d a2 .
b a2 ‚áí b a1 .

b a3 ‚àß b a‚Ä≤3 ‚áí b3 .
c a 3 ‚áí c3 .
d a3 ‚áí d 3 .
f a3 ‚áí f3 .
g3 .
h0 ‚áí f a1 .
f0 ‚áí c a1 .
f0 ‚áí b a‚Ä≤1 .

f a2 ‚áí f a1 .
b a3 ‚áí b a2 .

h1 ‚áí f a2 .
f1 ‚áí c a2 .
f1 ‚áí b a‚Ä≤2 .

f a3 ‚áí f a2 .
b‚Ä≤ a 2 ‚áí b‚Ä≤ a 1 .

h2 ‚áí f a3 .
f2 ‚áí c a3 .
f2 ‚áí b a‚Ä≤3 .

c a2 ‚áí c a1 .
a 3 ‚áí b‚Ä≤ a 2 .

b‚Ä≤

‚Ä≤

It turns out that sat (I) has no models: From g3 , the clause g3 ‚áí f3 in (2), and clauses in (0), we obtain
‚Ä≤
that fi , i ‚àà {0, . . . , 3}, is true in every model M of sat (I1 ). Hence, by the clause f2 ‚áí b a3 in (3.2), also
b a‚Ä≤3 is true in M . On the other hand, from the formula f1 ‚áí c a2 in (3.2), we obtain that c a2 must be true
in M , and thus by the clauses c a2 ‚áí c2 in (3.1) and c2 ‚áí b a3 in (3.2) that b a3 is true in M . The clause
b a3 ‚àß b a‚Ä≤3 ‚áí b3 thus implies that b3 is true in M . However, by the formula b3 ‚áí ‚ä• in (4), b3 must be false
‚Ä≤
in M . Thus, no model M of sat (I1 ) can exist, which by Theorem 8 means that there is no 3-maintaining
control for S = {b} w.r.t E = {h}. Indeed, regardless of whether a control function K selects a or a‚Ä≤ in
state b, within at most 2 steps from b the state f might be reached, from which the exogenous function might
move the system to the no-good state g.
Suppose now again that Œ¶(c, a) = {d, f } and that the agent can take a‚Ä≤ in g, which results in either h or f
‚Ä≤
(i.e., Œ¶(g, a‚Ä≤ ) = {f, h} and a‚Ä≤ ‚àà poss(g)). Then the Horn encoding sat (I1 ) changes as follows:
In (3.1), the facts gi , i ‚àà {1, 2, 3}, are replaced by g ai ‚áí gi ;
In (3.2.), the clauses for a‚Ä≤ and f, h are added, i ‚àà {1, 2, 3}:
f0 ‚áí g a‚Ä≤1 .

f1 ‚áí g a‚Ä≤2 .

f2 ‚áí g a‚Ä≤3 .

h0 ‚áí g a‚Ä≤1 .

h1 ‚áí g a‚Ä≤2 .

h2 ‚áí g a‚Ä≤3 .

In (3.3), the clauses for a‚Ä≤ and g are added:
g a‚Ä≤2 ‚áí g a‚Ä≤1 .

g a‚Ä≤3 ‚áí g a‚Ä≤2 .
‚Ä≤

In this encoding sat (I2 ) of the modified instance I2 , we now longer have a fact g3 in (3.1.) and thus the
‚Ä≤
above derivation of a contradiction for the truth value of b3 in any model of sat (I2 ) is not applicable. In
‚Ä≤
fact, sat (I2 ) is satisfiable, and its least model is
M = {b0 , c0 , d0 f0 , g0 , b a1 , c a1 , b a‚Ä≤1 , g a‚Ä≤1 , b1 , c1 , g1 , b a2 }.
Then, we have C M = {b, c, d, f, g, h}, ‚ÑìM (b) = ‚ÑìM (c) = ‚ÑìM (g) = 2 and ‚ÑìM (d) = ‚ÑìM (f ) = 1, which
leads to a single 3-maintaining control K such that K(s) = a for s ‚àà {b, c, d, f } and K(g)= a‚Ä≤ . Note that
since K is defined on every state except h, it 3-maintains every set S w.r.t. every E which includes h. As
for S = {b}, K(c) and K(d) could remain undefined, since they are not in the closure of b (which can be
easily detected) at the price of losing robustness with respect to enlarging S. There is an alternative solution
in which K(b) = a‚Ä≤ instead of K(b) = a. Here K(s) can not be made undefined on any s 6= h.2

INFSYS RR 1843-04-04

5.3

23

Genuine algorithm

From the encoding to Horn SAT above, we can distill a direct algorithm to construct a k-maintainable
control, if one exists. The algorithm mimics the steps which a SAT solver might take in order to solve
sat‚Ä≤ (I). It uses counters c[s] and c[s a] for each state s ‚àà S and possible agent action a in state s, which
range over {‚àí1, 0, . . . , k} and {0, 1, . . . , k}, respectively. Intuitively, value i of counter c[s] (at a particular
step in the computation) represents that so far s0 , . . . , si are assigned true; in particular, i = ‚àí1 represents
that no si is assigned true yet. Similarly, value i for c[s a] (at a particular step in the computation) represents
that so far s a1 , . . . , s ai are assigned true (and in particular, i = 0 that no s ai is assigned true yet).
‚Ä≤
Starting from an initialization, the algorithm updates by demand of the clauses in sat (I) the counters (i.e.,
sets propositions true) using a command upd(c, i) which is short for ‚Äúif c < i then c := i,‚Äù towards a
fixpoint. If a counter violation is detected, corresponding to violation of a clause s0 ‚Üí ‚ä• for s ‚àà S ‚à© E in
(1) or sk ‚Üí ‚ä• for s ‚àà S \ E in (4), then no control is possible. Otherwise, a control is constructed from the
counters.
In detail, the algorithm is as follows:
Algorithm k-C ONTROL
Input: A system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A of agent actions, sets of states E, S ‚äÜ S, an
exogenous function exo, and an integer k ‚â• 0.
Output: A control K which k-maintains S with respect to E, if any such control exists. Otherwise, output
that no such control exists.
(Step 1) Initialization
‚Ä≤
(i) Set Œ¶exo = {hs, a, s‚Ä≤ i | s ‚àà S, a ‚àà exo(s), s‚Ä≤ ‚àà Œ¶(s, a)}, Œ¶E
poss = {hs, a, s i | s ‚àà S \ E, a ‚àà
poss(s), s‚Ä≤ ‚àà Œ¶(s, a)}, and for every s ‚àà S, poss ag (s) = Aagent ‚à© poss(s).

(ii) For every s in E, set c[s] := ‚àí1.
(iii) For every s in S \ E, set c[s] := k if s ‚àà S and poss ag (s) = ‚àÖ; otherwise, set c[s] := 0.
(iv) For every s in S \ E and a ‚àà poss ag (s), set c[s a] := 0.
(Step 2) Repeat the following steps until there is no change or c[s]=k for some s ‚àà S \ E or c[s]‚â•0 for
some s ‚àà S ‚à© E:
(i) For any hs, a, s‚Ä≤ i ‚àà Œ¶exo such that c[s‚Ä≤ ]=k do upd(c[s], k).
‚Ä≤
(ii) For any hs, a, s‚Ä≤ i ‚àà Œ¶E
poss such that c[s ]=i and 0 ‚â§ i < k do upd(c[s a], i + 1).

(iii) For any state s ‚àà S \ E such that poss ag (s) 6= ‚àÖ and i= min(c[s a] | a ‚àà poss ag (s))
do upd(c[s], i).
(Step 3) If c[s]=k for some s ‚àà S\E or c[s]‚â•0 for some s ‚àà S‚à©E, then output that S is not k-maintainable
w.r.t. E and halt.
(Step 4) Output any control K : S \ E ‚Üí Aagent defined on all states s ‚àà S \ E with c[s] < k and such
that K(s) ‚àà {a ‚àà poss ag (s) | c[s a] = minb‚ààposs ag (s) c[s b] < k}.
2

24

INFSYS RR 1843-04-04

The above algorithm is easily modifiable if we simply want to output a super-control such that each of its
refinements is a k-maintainable control, leaving a choice about the refinement to the user. Alternatively, we
can implement in Step 4 such a choice based on preference information.
The following proposition states that the algorithm works correctly and runs in polynomial time.
Proposition 10 Algorithm k-C ONTROL solves problem k-M AINTAIN, and terminates for any input I in
polynomial time. Furthermore, it can be implemented to run in O(kkIk) time.
Proof. The correctness of the algorithms follows from Theorem 8 and the fact that k-C ONTROL mimics,
‚Ä≤
starting from facts in (5) and (3.1), the computation of the least model of sat (I) by a standard fix-point
computation. As for the polynomial time complexity, since counters are only increased, and the loop in
Step 2 is reentered only if at least one counter has increased in the latest run, it follows that the number of
iterations is polynomially bounded. Since the body of Step 2 and each other step is polynomial, it follows
that k-C ONTROL runs in polynomial time.
For the more detailed account, note that bitmaps for S, E and A (if not available in the input) can be
generated in time O(|S| + |A|). In (i) of Step 1, the sets Œ¶exo and Œ¶E
poss can be constructed in time O(|Œ¶| +
|exo|) and O(|Œ¶| + |poss| + |S|), respectively, using an auxiliary array for random access to Œ¶(a, s) in case
if the functions are given by their graphs (cf. proof of Corollary 9). Constructing poss ag (s) for all s‚ààS takes
O(|poss|) time, and (ii)‚Äì(iv) of Step 1 is feasible in time O(|S| + |poss|).
Using flags to signal changes to counters c[s], c[sa ], and auxiliary counters for min(c[s a] | a ‚àà poss ag (s)),
the number of calls of upd in Step 2 is O(k(|Œ¶exo | + |Œ¶poss | + |S|)), and each call takes O(1) time. The
loop condition can be checked in O(m) time where m is the number of changes in the loop. Hence, the total
time for Step 2 is O(kkIk). Step 3 is O(1) if a flag is set in Step 2 indicating the reason for the loop exit.
Finally, in Step 4, a control K can be easily output in time O(|poss|). In total, the time is O(kkIk)
2
Thus, for k bounded by a constant, k-C ONTROL can be implemented to run in linear time. We remark that
further improvements are possible. For example, states may be eliminated beforehand which will not be
reachable from any state in S under any control that is eventually constructed. This can be done efficiently
by computing an upper bound of Closure(S, KA,exo ) in which all possible actions at any state are merged
into a single action. We leave a detailed discussion of this and further refinements for future work.

6 Encoding Maintainability for an Answer Set Solver
In this section, we use the results of the previous section to show how computing a k-maintainable control
can be encoded as finding answer sets of a non-monotonic logic program. More precisely, we describe an
encoding to non-monotonic logic programs under the Answer Set Semantics [24], which can be executed on
one of the available Answer Set Solvers such as DLV [20, 33] or Smodels [40, 50]. These solvers support the
computation of answer sets (models) of a given program, from which solutions (in our case, k-maintaining
controls) can be extracted.
The encoding is generic, i.e., given by a fixed program which is evaluated over the instance I represented
by input facts F (I). It makes use of the fact that non-monotonic logic programs can have multiple models,
which correspond to different solutions, i.e., different k-maintainable controls.
In the following, we first describe how a system is represented in a logic program, and then we develop
the logic programs for both deterministic and general, nondeterministic domains. We shall follow here the
syntax of the DLV system; the changes needed to adapt the programs to other Answer Set Solvers such as
Smodels are very minor.

INFSYS RR 1843-04-04

6.1

25

Input representation

The input I of problem k-M AINTAIN, can be represented by facts F (I) as follows.
‚Ä¢ The system A = (S, A, Œ¶, poss) can be represented using predicates state, transition, and
poss by the following facts:
‚Äì state(s), for each s ‚àà S;
‚Äì action(a), for each a ‚àà A;
‚Äì transition(s,a,s‚Ä≤ ), for each s, s‚Ä≤ ‚àà S and a ‚àà A such that s‚Ä≤ ‚àà Œ¶(s, a);
‚Äì poss(s,a), for each s ‚àà S and a ‚àà A such that a ‚àà poss(s).
‚Ä¢ the set Aagent ‚äÜA of agent actions is represented using a predicate agent by facts agent(a), for
each a‚ààAagent ;
‚Ä¢ the set of states S is represented by using a predicate start by facts start(s), for each s ‚àà S;
‚Ä¢ the set of states E is represented by using a predicate goals by facts goal(s), for each s ‚àà E;
‚Ä¢ the exogenous function exo is represented by using a predicate exo by facts exo(s,a) for each s‚ààS
and a‚ààexo(s).
‚Ä¢ finally, the integer k is represented using a predicate limit by the fact limit(k).
Example 7 Coming back to Example 3, the input I is represented as follows:
state(b). state(c). state(d). state(f). state(g). state(h).
action(a). action(a1). action(e).
trans(b,a,c). trans(b,a1,f). trans(c,a,d). trans(d,a,h).
trans(f,a,h). trans(f,e,g).
poss(b,a). poss(b,a1). poss(f,a). poss(f,e).
poss(c,a). poss(d,a).
agent(a). agent(a1).
start(b). goal(h).
exo(f,e).
limit(3).

6.2

2

Deterministic transition function Œ¶

The following is a program, executable on the DLV engine, for deciding the existence of a k-control. In
addition to the predicates for the input facts F (I), it employs a predicate n path(X,I), which intuitively
corresponds to XI , and further auxiliary predicates.
% Define range of 0,1,...,k for stages.
range(I) :- #int(I), I <= K, limit(K).
% Rule for (0).
n_path(X,I) :- state(X), range(I), limit(K), I<K, n_path(X,J), J = I+1.

26

INFSYS RR 1843-04-04

% Rule for (1).
:- n_path(X,0), goal(X), start(X).
% Rule for (2)
n_path(X,K) :- trans(X,A,Y), exo(X,A), n_path(Y,K), limit(K).
% Rules for (3)
n_path(X,I) :- state(X), not goal(X), range(I), I>0, not some_pass(X,I).
some_pass(X,I) :- range(I), I>0, trans(X,A,Y), agent(A),
poss(X,A), not n_path(Y,J), I=J+1.
% Rule for (4)
:- n_path(X,K), limit(K), start(X), not goal(X).
% Rule for (5)
n_path(X,0) :- state(X), not goal(X).

The predicate range(I) specifies the index range from 0 to k, given by the input limit(k). The rules
encoding the clause groups (0) ‚Äì (2) and (4), (5) are straightforward and self explanatory. For (3), we need to
encode rules with bodies of different size depending on the transition function Œ¶, which itself is part of the
input. We use that the antecedent of any implication (3) is true if it is not falsified, where falsification means
that some atom s‚Ä≤i‚àí1 , s‚Ä≤ ‚àà P S(s), is false; to assess this, we use the auxiliary predicate some pass(X,I).
To compute the super-control K + , we may add the rule:
% Define C M
cbar(X) :- state(X), not n_path(X,K), limit(K).
%Define state level L
level(X,I) :- cbar(X), not n_path(X,I), I > 0,

n_path(X,J), I=J+1.

level(X,0) :- cbar(X), not n_path(X,0).
% Define super-control k_plus
k_plus(X,A) :- agent(A), trans(X,A,Y), poss(X,A), level(X,I),
level(Y,J), J<I, not goal(X).

In cbar(X), we compute the states in C M , and in level(X,I) the level ‚ÑìM (s) of each state s ‚àà C M
+
(=CM for the corresponding model M of sat(I)). The super-control KM
is then computed in k plus(X,A).
+
Finally, by the following rules we can nondeterministically generate any control which refines KM
:
% Selecting a control from k_plus.
control(X,Y) :- k_plus(X,Y), not exclude_k_plus(X,Y).
exclude_k_plus(X,Y) :- k_plus(X,Y), control(X,Z), Y<>Z.

The first rule enforces that any possible choice for K(s) must be taken unless it is excluded, which by the
second rule is the case if some other choice has been made. In combination the two rules effect that one and
+
only one element from KM
(s) is chosen for K(s).

INFSYS RR 1843-04-04

27

Example 8 If the input representation of Example 5 is in a file exa3.dlv and the above program, denoted
by Œ†det , in a file det.dlv, the DLV engine can be invoked e.g. by
dlv exa3.dlv det.dlv -N=3 -filter=control
which outputs the controls; here -N=3 sets the range of integers dynamically supported by the engine to 3,
and -filter=control effects that the answer sets are clipped to the predicate control. In the particular case,
the output on the call is (apart from system version information)
control(b,a), control(c,a), control(d,a)
yielding the unique control which exists in this case. If we would add a further agent action a2 to the action
set, and extend the transition function by Œ¶(b, a2 ) = c, then a call of DLV for the respective representation
would yield
{control(b,a2), control(c,a), control(d,a)}
{control(b,a), control(c,a), control(d,a)}
corresponding to the two alternative controls which emerge, since the agent can take either action a or action
a2 in state a.

6.3

Nondeterministic transition function Œ¶

As for deciding the existence of a k-maintaining control, the only change in the code for the deterministic
case affects Step (3). The modified code is as follows, where n apath(X,A,I) intuitively corresponds to
X AI .
% Rules for (3); different from above
% (3.1)
n_path(X,I) :- state(X), not goal(X), range(I), I>0, not some_apass(X,I).
some_apass(X,I) :- range(I), I>0, agent(A), poss(X,A), not n_apath(X,A,I),
not goal(X).
% (3.2)
n_apath(X,A,I) :- agent(A), trans(X,A,Y), poss(X,A), range(I), I>0,
n_path(Y,J), I=J+1, not goal(X).
% (3.3)
n_apath(X,A,I) :- agent(A), poss(X,A), range(I), I>0, limit(K), I<K,
n_apath(X,A,J), J=I+1, not goal(X).

Here, some apass(X,A,I) plays for encoding (3.1) a similar role as some pass(X,I) for encoding
(3) in the deterministic encoding.
+
To compute the super-control KM
, we may then add the following rules:
% Define C M
cbar(X) :- state(X), not n_path(X,K), limit(K).

28

INFSYS RR 1843-04-04

% Define state action level, alevel (>=1)
alevel(X,I) :- alevel_leq(X,I), I=J+1, range(J), not level_leq(X,J).
alevel_leq(X,I) :- cbar(X), not goal(X), poss(X,A), agent(A), I>0,
range(I), not n_apath(X,A,I).
% Define super-control k_plus
k_plus(X,A) :- agent(A), alevel(X,I), poss(X,A), not n_apath(X,A,I).

Here, the value of ‚ÑìM (s) is computed in alevel(X,I), using the auxiliary predicate alevel leq(X,I)
which intuitively means that ‚ÑìM (X) ‚â§ I.
+
For computing the controls refining KM
, we can add the two rules for selecting a control from k plus
from the program for the deterministic case.
Example 9 Let us revisit the instance I1 in Example 6. We get the DLV representation of I1 by adding the
fact trans(c,a,f). to the representation for I. Assuming that it is in a file exa4.dlv and the program
Œ†ndet in a file ndet.dlv, a call
dlv exa4.dlv ndet.dlv -N=3 -filter=control
yields no output (apart from some system version print), which is correct. On the other hand, if we consider
the input I2 for the variant of Example 6 (with agent action a‚Ä≤ possible in g and Œ¶(g, a‚Ä≤ ) = {f, h}), then the
output is
{control(b,a1), control(c,a), control(d,a), control(f,a), control(g,a1)}
{control(b,a), control(c,a), control(d,a), control(f,a), control(g,a1)}

(where a1 encodes a‚Ä≤ ). Again, this is the correct result.

6.4

Layered use of negation

An important note at this point is that the programs Œ†det and Œ†ndet do not necessarily have models which
‚Ä≤
correspond to the least models of the Horn theories sat(I) and sat (I), respectively. The reason is that the
use of negation not some pass(X,I) and resp. not some apass(X,I) may lead through cycles
in recursion. Thus, not each control computed is necessarily maximal (even though the maximal controls
will be computed in some models). Furthermore, because of cyclic negation it is not a priori clear that the
part of the program deciding the existence of a control is evaluated by DLV in polynomial time. However,
‚Ä≤
consistency (i.e., existence of an answer set) is guaranteed whenever sat(I) resp. sat (I) has a model.
It is possible to modify Œ†det such that the use of negation in recursion cycles is eliminated, by using standard
coding methods to evaluate the body of the rule in (3). Namely, introduce for Œ†det a predicate all true
and replace not some pass(X,I) in the code for (3) with all true(X,I), which is defined such
that all true(s, i) represents that every s‚Ä≤ i‚àí1 ‚àà P S(s) is assigned true, which can be checked using a
linear ordering ‚â§ on P S(s). However, we refrain from this here.
Notice that in the case where P S(s) has size bounded by a constant c, we can use a predicate ps of arity
c + 1 to represent P S(s) = {s(1) , . . . , s(l) } by a single fact ps(s, s(1) , . . . , s(l) , . . . , s(l) ) where s(l) is
reduplicated if l < c. It is then easy to express the clause (3).
We can similarly modify Œ†ndet such that the use of negation in recursion cycles is eliminated, where we
use a linear ordering on Aagent ‚à© poss(s) (or simply on Aagent , assuming that there are not many agent

INFSYS RR 1843-04-04

29

actions overall). Finally, we can also use for the program Œ†det simply an ordering of Aagent , since the
deterministic transformation Œ¶(s, a) is a (partial) surjective mapping of A onto P S(s), which guarantees
that via A ‚à© poss(s) each s‚Ä≤ ‚àà P S(s) can be accessed through Œ¶.
The modified programs use negation only in a stratified manner, and thus will be evaluated by DLV in
‚Ä≤
guaranteed polynomial time in the size of the DLV representation of sat(I) and sat (I), respectively.

6.5

State descriptions by variables

In many cases, states of a system are described by a vector of values for parameters which are variable over
time. It is easy to incorporate such state descriptions into the LP encoding from above, and to evaluate them
on Answer Set Solvers provided that the variables range over finite domains. In fact, if any state s is given
by a (unique) vector s = hs1 , . . . , sm i m > 0, of values si , 1 ‚â§ i ‚â§ m, for variables Xi ranging over
nonempty domains, then we can represent s as fact state(v1i ,...,vri i ) and use a vector X1,...,Xm
of state variables in the DLV code, in place of a single variable, X. No further change of the programs from
above is needed.
Similarly, we can easily accommodate actions a(P1 , P2 , . . . , Pm ) with parameters P1 , . . . , Pm (which is
important) from a finite set if desired. However, here rule the defining exclude k plus(X,Y) should be
replaced by all rules emerging if the atom Y <> Z in the body is replaced by Yi <> Zi, i ‚àà {1,...,m}
(assuming that Y and Z are replaced by Y1,...,Ym and Z1,...,Zm, respectively).
Another possibility to handle state descriptions by variables would be to implement a coding scheme, which
maps each vector s = hs1 , . . . , sm i into an integer i(s), represented by fact code(i(s), s1 , . . . , sm ).
Furthermore, we point out that the input need not consist merely of facts, but may also involve rules to define
the predicates of the input representation more compactly. Finally, the facts for action can be dropped,
since they are not referenced by any rule in programs Œ†det and Œ†ndet .
For illustration, we consider the buffer example from Section 3.
Example 10 Recall that states in the buffer example are given by pairs of integers hi, ji where i and j are
the numbers of objects in buffer b1 and b2 , respectively. We thus use variables X1,X2 and Y1,Y2 in place
of X and Y, respectively.
For buffer capacity of 3, S = {h0, 0i}, E = {h0, ji | 1 ‚â§ j ‚â§ 3}, and k = 6, the input can be represented
as follows:
state(X1,X2) :- #int(X1), #int(X2), X1 <= 3, X2 <= 3.
start(0,0).
goal(0,X2) :- state(0,X2).
trans(X1,X2,m_12,Y1,Y2) :- state(X1,X2), state(Y1,Y2), X1=Y1+1, Y2=X2+1.
trans(X1,X2,m_21,Y1,Y2) :- state(X1,X2), state(Y1,Y2), Y1=X1+1, X2=Y2+1.
trans(X,X2,proc,X,Y2) :- state(X,X2), state(X,Y2), X2=Y2+1.
trans(X1,X,ins,Y1,X) :- state(X1,X), state(Y1,X), Y1=X1+1.
poss(X1,X2,m_12) :- state(X1,X2), 1
poss(X1,X2,m_21) :- state(X1,X2), 1
poss(X1,X2,proc) :- state(X1,X2), 1
poss(X1,X2,ins) :- state(X1,X2), X1

<=
<=
<=
<=

X1, X2 <= 2.
X2, X1 <= 2.
X2.
2.

30

INFSYS RR 1843-04-04

agent(m_12). agent(m_21). agent(proc). exo(ins).
limit(6).

Here, equalities X1=0 for X1,X2 in the rule defining goal and X1=Y1 in the definition of trans(X,X2,
proc,X,Y2) etc are pushed through.
Invoking DLV, assuming the representation is stored in file exa-buffer.dlv and the expanded version
of Œ†det in a file det2.dlv, with
dlv exa-buffer.dlv det2.dlv -N=6 -filter=control
yields 13 models, of which encode different controls. Among the maximal controls is
{ control(1,0,m_12), control(1,1,m_12), control(1,2,m_12), control(1,3,proc),
control(2,0,m_12), control(2,1,m_12), control(2,2,proc), control(2,3,proc),
control(3,0,m_12), control(3,1,proc), control(3,2,proc), control(3,3,proc)}

which is defined on all states outside E, and thus constitutes a 6-maintaining control for the whole system.

7 Computational Complexity
In this section, we consider the complexity of constructing k-maintainable controls under various assumptions. To this end, we first describe the problems analyzed and give an overview of the complexity results.
After that, the results are established in a separate subsection; the reader who is not interested in the technical
proofs might safely skip it.

7.1

Problems considered and overview of results

Following the common practice, we consider here the decision problem associated with k-M AINTAIN, which
we refer to as k-M AINTAINABILITY: Given a system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A of agent
actions, sets of states E, S ‚äÜ S, an exogenous function exo, and an integer k ‚â• 0, decide whether S is
k-maintainable with respect to E in A. Furthermore, we also consider œâ-M AINTAINABILITY, which has
the same input except k and asks whether S is maintainable with respect to E in A.
We consider the problems in two different input settings, in line with the previous sections:
Enumerative representation: The constituents of an instance I are explicitly given, i.e., the sets (A, S,
Aagent , S, and E) in enumerative form and the functions (Œ¶(a, s), poss(s), and exo) by their graphs
in tables.
State variables representation: A system state s is represented by a vector s = (v1 , . . . , vm ) of values for variables f1 ,. . . ,fm ranging over given finite domains D1 , . . . , Dm , while A and Aagent are
given in enumerative form. We assume that polynomial-time procedures for evaluating the following
predicates are available:
‚Ä¢ in Phi (s, a, s‚Ä≤ ), in poss(s, a), and in exo(s, a) respectively for deciding s‚Ä≤ ‚àà Œ¶(s, a),
a ‚àà poss(s), and a ‚àà exo(s), respectively.
‚Ä¢ in S (s) and in E (s) for deciding whether s ‚àà S and s ‚àà E, respectively.

INFSYS RR 1843-04-04

+/- exogenous actions

31

k-M AINTAINABILITY
given k

deterministic
nondeterministic

P / NL (Th.11/15)
P (Th.11/13)

œâ-M AINTAINABILITY

constant k ‚â• 1
P / in LH (‚äÇ L) (Th.11/16)
P / in LH (‚äÇ L) (Th.11/16)

P / NL (Co.12/Th.15)
P (Co.12/Th.13)

Table 1: Complexity of deciding k- and œâ-M AINTAINABILITY under enumerative representation (logspace
completeness)

+/- exogenous actions
deterministic
nondeterministic

k-M AINTAINABILITY
given k
constant k ‚â• 1

œâ-M AINTAINABILITY

EXP / PSPACE (Th.18/21)

EXP / co-NP (Th.18/22)

EXP / PSPACE (Co.19/Th.21)

EXP (Th.18/20)

EXP / co-NP (Th.18/22)

EXP (Co.19/Th.20)

Table 2: Complexity of deciding k- and œâ-M AINTAINABILITY under state variables representation
(logspace completeness)
Orthogonal to this, we also consider (1) general k versus constant k, in order to highlight the complexity of
small windows of opportunity for maintenance; (2) absence of exogenous actions, to see what cost intuitively
is caused by an adversary; and (3) nondeterministic versus deterministic actions.
The results of the complexity analysis are compactly summarized in Tables 1 and 2, in which unless stated
otherwise, the entries stand for completeness results under logspace reductions. We assume that the reader
is familiar with the classes P (polynomial time), EXP (exponential time), L (logarithmic workspace), NL
(nondeterministic logarithmic work space), co-NP (co-nondeterministic polynomial time), and PSPACE
(polynomial space) appearing in the tables, and refer to [44] and references therein for further background
S
on complexity. By LH we denote the logarithmic time hierarchy [7, 27], which is given by LH = i‚â•0 Œ£log
i ,
log
where Œ£i denotes the decision problems solvable on an alternating Turing machine in logarithmic time
with at most i‚àí1 alternations between existential and universal states, starting in an existential state. Note
that LH is strictly included in L. A more refined complexity assessment is given in Section 7.2. However,
we refrain here from providing a sharp complexity characterization of the problems classified within LH in
terms of completeness under a suitable notion of reduction, since they are not central to the maintainability
issue under an ‚Äúadversarial‚Äù environment.
Under enumerative representation (Table 1), k- and œâ-M AINTAINABILITY have the same complexity as
Horn SAT, which is P-complete [44]. Thus, according to widely believed complexity hypotheses, the problem is difficult to parallelize and to solve within poly-logarithmic workspace. In fact, this holds also for
the case of constant k = 1 and the restriction that all actions are deterministic and that there is a single exogenous action. Thus, even in the simplest setting with an adversary according to the dimensions above,
the problem already harbors its full complexity; excluding nondeterministic actions and/or fixing k does not
make the problems simpler. Intuitively, this is because with the help of exogenous actions, one can simulate
nondeterminism and split sequences of agent maintenance actions into small segments.
On the other hand, when exogenous actions are excluded (listed under ‚Äú-‚Äù), k- and œâ-M AINTAINABILITY
are always easier when the actions are deterministic or the window of opportunity is small (k is constant).
In summary, the results show that exogenous actions can not be compiled efficiently away (with reasonable
complexity) to an instance of maintainability under a small window opportunity, and that nondeterministic

32

INFSYS RR 1843-04-04

actions are indispensable for such a compilation.
The reason is that in absence of exogenous actions, k-M AINTAINABILITY is akin to a graph reachability
resp. planning problem (for the latter, see Section 8.1). Indeed, define for a fixed system A=(S, A, Œ¶, poss),
a set of agent action Aagent ‚äÜ A, and sets E, S ‚äÜ S of states the predicates ri (s), i ‚â• 0, on s ‚àà S
inductively by
r0 (s) = s ‚àà E,
ri+1 (s) = s ‚àà E ‚à® ‚àÉa ‚àà Aagent ‚à© poss(s)
‚àÄs‚Ä≤ ‚àà S(s‚Ä≤ ‚àà Œ¶(s, a) ‚áí ri (s‚Ä≤ )),

for i ‚â• 0.

(1)

Informally, ri (s) expresses that some state in E can be reached from s within i agent actions, and it holds that
S is k-maintainable with respect to E, exactly if rk (s) holds for every s in S (as proved in Lemma 1 below).
The predicate rk (s) is definable in first-order predicate logic with a suitable relational vocabulary (using
the predicates given for enumerative representation). As well-known, the first-order definable properties are
those which can be decided in LH [7, 27]. Since LH is considered to contain problems which have much
lower complexity than hard problems in P, the effect of exogenous actions is drastic in complexity terms.
Furthermore, problems in LH are amenable to parallelization (see [27]).
Under state variables representation (Table 2), the complexity of the problems, with few exceptions increases
by an exponential. This increase is intuitively explained by the fact that state variables permit in general an
exponentially smaller input representation, which must be unpacked for solving the problem. The exception
for constant k in absence of exogenous functions, where the complexity increases from within LH to co-NP,
is intuitively explained by the fact that the quantifier ‚Äú‚àÉa ‚àà Aagent ‚à© poss(s)‚Äù in equation (1), as opposed
to ‚Äú‚àÄs‚Ä≤ ‚àà S‚Äù, ranges over a polynomial set of values (in the input size), and thus can be deterministically
eliminated.
The EXP-completeness means that the problems are provably intractable, i.e., have an exponential lower
bound in this setting. Even in the ‚Äúcheapest‚Äù cases under state variable representation, the problems are
intractable. Exogenous actions cannot be compiled efficiently away in the same cases as under enumerative
representation.

7.2

Enumerative representation

We start with the case of enumerative representation. Our first result is the following.
Theorem 11 Problem k-M AINTAINABILITY is P-complete (under logspace reductions). The P-hardness
holds under the restriction that k = f (A, S, E) is any function of A, S, and E such that f (A, S, E) ‚â• 1 (in
particular, for fixed k ‚â• 1), even if in addition all actions are deterministic and there is only one exogenous
action.
Proof. The membership of k-M AINTAINABILITY in P follows from Corollary 9.
We prove P-hardness under the stated restriction by a reduction from deciding logical entailment œÄ |= q of a
propositional atom q from a propositional Horn logic program (PHLP) œÄ, which is a set of rules of the form
b0 ‚Üê b1 , . . . , bn ,

n ‚â• 0,

(2)

and each bi is a propositional atom from an underlying atom set At; b0 is the head and b1 , . . . , bn is the body
of the rule.

INFSYS RR 1843-04-04

33

As well-known, œÄ |= q holds iff there is a sequence of rules r1 , r2 , . . . , rm , m ‚â• 1, from œÄ where ri
is of form bi0 ‚Üê bi1 , . . . , bin , such that {bi1 , . . . , bin } ‚äÜ {b10 , . . . , bi‚àí10 }, for all i ‚àà {1, . . . , m} (thus
in particular, 1n = 0) and bm0 = q, called a proof of q from œÄ. Informally, q is derived by successive
application of the rules r1 , . . . , rm , where ri ‚Äúfires‚Äù after all previous rules r1 , . . . , ri‚àí1 have fired.
A natural idea is to represent backward rule application rm , rm‚àí1 , . . . , r1 through agent actions; for a rule
r of form (2), there is an agent action a r which applied to a state sb0 representing b0 , brings the agent
nondeterministically to any state sbi representing bi , i ‚àà {1, . . . , n}. Given a state sq encoding q, S = {sq }
is maintainable w.r.t. a set of states E encoding the facts in œÄ if q has a proof from œÄ. However, this does
not account for the restriction that k = f (A, S, E) for any such f . The key for this is to establish the result
for the extremal case where k = 1 is constant (i.e., for 1-MAINTAINABILITY) and then to extend it to the
general case.
Using a constrained rule format in œÄ and an exogenous action, we can emulate nondeterministic agent
actions and sequences of agent actions with some coding tricks by alternating sequences of deterministic
agent and exogenous actions, such that provability of q from œÄ corresponds to 1-maintainability of S w.r.t.
a set E in a system A constructible in logarithmic workspace from q and œÄ.
Without loss of generality, we assume that each rule has either zero or two atoms in the body (i.e., n = 0
or n = 2 in (2)). We construct from œÄ and q a system A = (S, A, Œ¶, poss), sets of states S and E, a set
Aagent ‚äÜ A, and a function exo as follows:
(b, c)2
a r2

e
S
a3

a r1

(b, c)1

a2

r13

a r1

a r2

c3

a r3

a r2

e
r12

e
b3

(b, c)0

a1

a r1

e
r11

e

a0
e

r23

b2

a r2

r22

b1

a r2

r21

b0

r33

c2

a r3

r32

c1

a r3

r31

c0

E

Figure 3: Transition diagram of the system for œÄ = {a ‚Üê b, c; b ‚Üê ; c ‚Üê} and q = a (S and E encircled).

1. S: For each atom f in œÄ and rule r ‚àà œÄ, f 0 , . . . f m and r1 , . . . , rm are states in S. Furthermore, if the
body of r is u, v then (u, v)0 , . . . , (u, v)m‚àí1 are states in S.
2. A = {a r | r ‚àà œÄ} ‚à™ {e}.
3. Œ¶: For any rule r ‚àà œÄ with head f , Œ¶(a r, f i ) = {ri } for i ‚àà {1, . . . , m} and Œ¶(a r, (u, v)i ) = {ri },
for (u, v)i ‚àà S, i ‚àà {1, . . . , m ‚àí 1}. If moreover r has body u, v, then Œ¶(e, ri ) = {(u, v)i‚àí1 }, and
Œ¶(e, (u, v)i‚àí1 ) = {v i‚àí1 }, for i ‚àà {1, . . . , m ‚àí 1}. In all other cases, Œ¶(a, s) = ‚àÖ.
4. poss: For each state s, poss(s) = {a ‚àà A | Œ¶(a, s) 6= ‚àÖ}.
5. E = {r1 , . . . , rm | r ‚àà œÄ}

34

INFSYS RR 1843-04-04

6. S = {q m }.
7. Aagent = A \ {e}.
8. exo: for all rules r ‚àà œÄ of form f ‚Üê u, v, exo(ri ) = {e} for i ‚àà {1, . . . , m} and exo((u, v)j ) = {e}
for j ‚àà {1, . . . , m ‚àí 1}. For all other states s, exo(s) = ‚àÖ.
The transition diagram for the system constructed for œÄ = {a ‚Üê b, b ‚Üê, c ‚Üê} is shown in Figure 7.2.
Intuitively, the state f i encodes that f can be derived from œÄ with a proof of length at most i. This is
propagated in backward rule application. Each agent action a r selects a rule r to prove an atom f ; if the
rule has a body u, v, the exogenous action pushes the agent to prove both u (from (u, v)) and v within
decreased recursion depth.
We claim that œÄ |= q iff there exists some 1-maintaining control K for S with respect to E in A.
Suppose first that œÄ |= q. We then construct a 1-maintaining control K for S with respect to E as follows.
Let P = r1 , . . . , rk be a proof of q from œÄ such that, without loss of generality, all rules ri have different
heads. Set D = {q m } and iterate the following until D remains unchanged: For each f i ‚àà D resp. (u, v)i ‚àà
D, i ‚â• 0, let rj be the rule with head f resp. u in P . Define K(f i ) = {a rj } resp. K((u, v)i ) = {a rj },
and add, if rj has body u‚Ä≤ , v ‚Ä≤ the states (u, v)i‚àí1 and v ‚Ä≤ i‚àí1 to D. Since P is a proof of q from œÄ, the rule rj
always exists, and for each state s in Closure(S, AK,exo ) \ E (=D), K(s) is defined and Œ¶(K(s), s) yields
some state in E. Hence, K is a 1-maintaining control for S with respect to E in A.
Conversely, suppose K is a 1-maintaining control for S with respect to E in A. Without loss of generality, K(s) is undefined for all states s ‚àà E. An easy induction on i ‚â• 1 shows that for each f i ‚àà
Closure(S, AK,exo ) resp. (u, v)i ‚àà Closure(S, AK,exo ), it holds that œÄ |= f resp. œÄ |= u and œÄ |= v. For
i=1, suppose first K(f 1 ) = a r. Rule r must have form f ‚Üê ; otherwise, some states (u, v)0 , v 0 would
be in Closure(S, AK,exo ), which contradicts that K is a 1-maintaining control. Hence, œÄ |= f . Next suppose K((u, v)1 ) = a r. Then, for similar reasons, r must be of form u ‚Üê, hence œÄ |= u. Furthermore,
v 1 ‚àà Closure(S, A,exo ) and as already established œÄ |= v. For i > 1, suppose K(f i ) = a r. Then either r
is of form f ‚Üê and thus œÄ |= f , or of form f ‚Üê u, v. In the latter case, (u, v)i‚àí1 ‚àà Closure(S, AK,exo ) and
hence, by the induction hypothesis, œÄ |= u and œÄ |= v. Consequently, œÄ |= f . Similarly, if K((u, v)i ) = a r,
then either r is of form u ‚Üê or of form u ‚Üê u‚Ä≤ , v ‚Ä≤ and (u‚Ä≤ , v ‚Ä≤ )i‚àí1 ‚àà Closure(S, AK,exo ), which by the
induction hypothesis implies œÄ |= u‚Ä≤ and œÄ |= v ‚Ä≤ , thus œÄ |= u. Since v i ‚àà Closure(S, AK,exo ), as already
established œÄ |= v. Consequently, œÄ |= f . This proves the statement for i > 1, and concludes the induction.
Since q m ‚àà Closure(S, AK,exo ), we have œÄ |= q. This proves our claim.
Notice that A, S and E can be constructed in logarithmic workspace from œÄ and q. This proves P-hardness
of 1-M AINTAINTABILITY. An easy observation is that every agent action in the system A leads to some
state in the set E described. Hence, S is 1-maintainable with respect to E in A iff S is k-maintainable
with respect to E in A for any f (A, S, E) such that f (A, S, E) ‚â• 1. Hence, P-hardness under the stated
restriction follows.
2
The following result is immediate from this result and the fact that maintainability is equivalent to kmaintainability where k = |S| is the number of states.
Corollary 12 œâ-M AINTAINABILITY is P-complete. The P-hardness holds even if all actions are deterministic and there is only one exogenous action.
The following result states a further P-complete restriction of the above problems.
Theorem 13 k-M AINTAINABILITY and œâ-M AINTAINABILITY without exogenous actions are P-complete.

INFSYS RR 1843-04-04

35

Proof. Membership in P was established above. The P-hardness follows from Theorem 11 by merging the
(single) exogenous action e into the agent actions as follows: For each state s such that e ‚àà exo(s), redefine
every action a ‚àà poss(s) ‚à© Aagent by Œ¶(s, a) := Œ¶(s, a) ‚à™ Œ¶(s, e). It is easy to see that given S and E, S
is |S|-maintainable w.r.t. E in the resulting system A‚Ä≤ iff S is |S|-maintainable w.r.t. E in A. Furthermore,
A‚Ä≤ is computable in logspace from A. This implies the result.
2
The hardness results above are at the border of the hardness frontier, in the sense that in the absence of
exogenous actions and, in case of œâ-M AINTAINABILITY also nondeterminism, the problems are no longer
P-hard. The following lemma gives a useful characterization of k-maintainability for this purpose.
Lemma 14 Given a system A = (S, A, Œ¶, poss), a set of agents action Aagent ‚äÜ A, and a set of states E, a
set of states S is k-maintainable with respect to E in absence of exogenous actions (i.e., exo is void), k ‚â• 0,
iff rk (s) as in (1) holds for all s ‚àà S.
Proof. For the only if direction, consider any 1-maintaining control K which without loss of generality is
undefined on every s ‚àà E. For every state s ‚àà Closure(S, AK,exo ) = Closure(S, AK ), let ds be the distance
of s from E under K, i.e., the largest i such that œÉ = s0 , s1 , . . . , si ‚àà Unfold k (s, A, K) where s0 = s. By
an easy induction on ds ‚â• 0, we obtain using K(s) as witness for a in (1), that rds (s), rds +1 (s), . . . , rk (s)
must hold for s. Hence, rk (s) holds for every s ‚àà S.
Conversely, let for each s ‚àà S be is the least integer i such that ri (s) holds. If is > 0, then define
K(s) := a for some arbitrary action a ‚àà Aagent ‚à© poss(s) witnessing (1) for i + 1 = is , otherwise
(i.e., if is = 0 or ri (s) does not hold for any i ‚â• 0) let K(s) undefined. Then, K is a k-maintaining
control for S with respect to E, since by definition of the relations ri , for each s ‚àà Closure(S, AK ), and
œÉ = s0 , s1 , . . . , sl ‚àà Unfold k (s, A, K) such that s0 = s it holds that l ‚â§ k and sl ‚àà E (recall that, as tacitly
assumed, Œ¶(a, s) 6= ‚àÖ for each a ‚àà poss(a)). Hence, S is k-maintainable with respect to E.
2
We then establish the following result.
Theorem 15 k-M AINTAINABILITY and œâ-M AINTAINABILITY for systems with only deterministic actions
and no exogenous actions are NL-complete.
Proof. In this case, deciding ri (s) for given s ‚àà S and i ‚â• 0 is in NL: If s ‚àà
/ E, a proper a in (1) and
‚Ä≤
‚Ä≤
s = Œ¶(s, a) can be guessed and, recursively, rk‚àí1 (s ) established, maintaining a counter i. This is feasible in logarithmic workspace in the representation size of A. By looping through all s ‚àà S, it thus follows
from Lemma 14 that deciding whether S is k-maintainable with respect to E, where k ‚â§ |S|, is nondeterministically feasible in logarithmic workspace. This implies NL-membership of k-M AINTAINABILITY
and œâ-M AINTAINABILITY. The hardness follows from a simple reduction of the well-known NL-complete
R EACHABILITY problem [44] to k- resp. œâ-M AINTAINABILITY: Given a directed graph G = (V, E) and
nodes s, t ‚àà V , decide whether there is a directed path from s to t in G. Define A = (S, A, Œ¶, poss) such
that S = A = V , Œ¶(v, w) = w, and poss(v) = {w | v ‚Üí w ‚àà E}. Then, for Aagent = A, S = {s} is
|V |-maintainable w.r.t. E = {t} in A iff there is a directed path from s to t in G. Clearly, A is constructible
in logarithmic workspace from G. This shows the NL-hardness.
2
In case of constant k, equation (1) is decidable by a straightforward deterministic recursive procedure in
logarithmic workspace, even under nondeterminism, since the recursion depth is bounded by a constant and
each recursion level requires only logarithmic work space. Hence, k-M AINTAINABILITY is decidable in
logarithmic space. A finer grained analysis that it is within the class Œ†log
k+1 of the logarithmic time hierarchy,
which is a much better upper bound and makes completeness for logspace (under suitable reductions) fairly
unlikely.

36

INFSYS RR 1843-04-04

We assume that the input I of k-M AINTAINABILITY for fixed k, is a relational structure MI with universe
U (MI ) = S ‚à™ A, and relations over U (MI ) for the predicates in Phi (s, a, s‚Ä≤ ), in poss(s, a), in exo(s, a),
in S (s) and in E (s) from above, and relations for the additional predicates ag act(a), in S(s), and
in A(a) representing membership a ‚àà Aagent , s ‚àà S and a ‚àà A for each s, a ‚àà U (M ), respectively.
The structure MI is encoded in a standard way by a bit-string [27].
Theorem 16 Problem k-M AINTAINABILITY for systems without exogenous actions is in Œ†log
2k+1 (=colog
Œ£2k+1 ), if k ‚â• 0 is constant.
Proof. Any first-order formula œà1 ‚à® Qx œà2 resp. œà1 ‚àß Qx œà2 such that œà1 has no free variables and
Q ‚àà {‚àÉ, ‚àÄ}, is logically equivalent to Qx(œà1 ‚à® œà2 ) resp. Qx(œà1 ‚àß œà2 ). Exploiting this, rk (s) in (1) can
be written, using the vocabulary from above, as a first-order formula œÜk (x) in prenex form
‚àÉx1 ‚àÄx2 ‚àÉx3 ¬∑ ¬∑ ¬∑ Qk xk œà(x1 , . . . , xk , x)
where œà(x1 , . . . , xk , x) is quantifier-free, such that for any element s ‚àà U (MI ) of an input structure M, the
sentence in S(s) ‚àß œÜk (s) is true on M iff rk (s) holds. Hence, by Lemma 14, k-maintainability of S w.r.t. E
in A is definable by a Œ†k+1 prenex sentence ‚àÄx0 ‚àÉx1 ¬∑ ¬∑ ¬∑ Qk xk œà ‚Ä≤ (x0 , x1 , . . . , xk ), where œà ‚Ä≤ (x0 , x1 , . . . , xk )
is quantifier-free, on the above vocabulary. Whether a fixed such sentence is false on a given structure MI
can be decided by an alternating Turing machine, starting in an existential state, in logarithmic time using k
log
alternations [7, 27]. Hence, the problem is in co-Œ£log
2
k+1 = Œ†2k+1 .
We remark that the hardness results in this section can be further strengthened to the case where only 2 agent
actions are available, but leave a proof of this to the interested reader.

7.3

State variables

The following is an easy lemma, which in combination with the results in the previous subsection implies
most upper bounds in Table 2.
Lemma 17 For any instance of k-M AINTAINABILITY resp., œâ-M AINTAINABILITY in which states are represented by variables, the corresponding instance in ordinary (enumerative) form can be generated in polynomial workspace.
Using this lemma, we then prove the following result.
Theorem 18 Under state representation by variables, k-M AINTAINABILITY is EXP-complete. The EXPhardness holds under the restriction that k = f (A, S, E) is any function of A, S, and E such that f (A, S, E) ‚â•
1 (in particular, for fixed k ‚â• 1), even if in addition all actions are deterministic and there is only one exogenous action.
Proof. Membership in EXP follows easily from Lemma 17 and Theorem 11. The EXP-hardness is shown
by a reduction from deciding inference œÄ |= p(t) of a ground atom p(c) from a function-free Horn logic
program œÄ with variables (i.e., a datalog program), which consists of rules of the form
p0 (t0 ) ‚Üê p1 (t1 ), . . . , pn (tn ),

n ‚â• 0,

(3)

where each pi is the name of a predicate of arity ai ‚â• 0 and ti = ti,1 , . . . , ti,n is a list of constants and
variables ti,j ; p0 (t0 ) is the head and p1 (t1 ), . . . , pn (tn ) the body of the rule.

INFSYS RR 1843-04-04

37

It holds that œÄ |= p(c) iff there is a sequence rules ri of the form pi0 (ti0 ) ‚Üê pi1 (ti1 ), . . . , pin (tin ) and
substitutions Œ∏i for ri , i.e., a mappings from the variables in ri to the set of constants CœÄ in œÄ, such that
{pi1 (ti1 Œ∏i ), . . . , pin (tin Œ∏i )} ‚äÜ {p10 (t10 Œ∏1 ), . . . , pi‚àí10 (ti‚àí10 Œ∏i‚àí1 )}, for all i ‚àà {1, . . . , m} (thus in particular, 1n = 0) and pm0 (tm0 Œ∏m ) = p(c), called a proof of p(c) from œÄ. Informally, p(c) is derived by successive
application of the rule instances r1 Œ∏1 , . . . , rm Œ∏m , like in a propositional logic program.
Deciding whether œÄ |= p(t) is well-known to be EXP-complete, cf. [13]. The construction is similar in
spirit to the one in proof of Theorem 11 but more involved.
To prove EXP-hardness of k-M AINTAINABILITY under the given restriction, we first focus on problem
1-M AINTAINABILITY, and we describe how to reduce œÄ |= p(c) in logarithmic workspace to deciding
1-maintainability of a set of states S w.r.t. a set of states E in an agent system A.
Without loss of generality, we make the following assumptions on œÄ and p(c):
‚Ä¢ The set of constants occurring in œÄ, CœÄ , is {0, 1};
‚Ä¢ each rule r in œÄ has either zero or two atoms in the body;
‚Ä¢ all rules in r are safe, i.e., each variable X occurring in the head of a rule r also occurs in the body;
‚Ä¢ œÄ uses only one predicate, p;
‚Ä¢ c = (0, 0, . . . , 0).
Any problem œÄ |= p(c) can be transformed to an equivalent one of this form in logarithmic workspace.
Similar as in the propositional case, the idea is to represent a reversed proof rm , Œ∏m , . . . , r1 Œ∏1 of p(c) from
œÄ through agent actions, and model backward rule applications through agent actions; note that m ranges
from 1 to 2ap , where ap is the arity of p (thus m requires ap bits). The problem here which makes this more
complex is the fact that we must, for each rule ri , also take Œ∏i into account. If ri has a nonempty body, the
candidates for Œ∏i are systematically generated by alternating agent and exogenous actions. For each possible
such Œ∏i , the derivation of the body atoms p(ti2 Œ∏i ) and p(ti2 Œ∏i ) is then explored.
More precisely, for each ground atom p(c), and m ‚àà {0, . . . , 2pa }, we have a state (c, m, prove) outside E
which intuitively says that p(c) is derivable within m (0 ‚â§ m ‚â§ 2pa ) steps. For each rule r in œÄ, there is
an agent action ar , which is possible on (c, m, prove) if m > 0 and p(c) unifies with the head p(t) of r,
and it results in the state (c, m, r, apply), which is in E. For r of form p(t) ‚Üê p(t1 ), p(t2 ), two phases are
now established: (1) the selection of a substitution Œ∏ for the variables X in r, and (2) the generation of states
(c1 , m‚àí1, prove) and (c1 , m‚àí1, prove), where c1 = Œ∏1 and c2 = Œ∏2 , for the recursive test.
As for 1) an exogenous action e pushes the agent from (c, m, r, apply) to a state (c, m, (0, 0, ..., 0), r, sel Œ∏).
Here (0, 0, . . . , 0) is the substitution Œ∏ : X1 = 0, . . . , Xk = 0 to all variables in r. By executing an agent
action incŒ∏ on this state, this vector is incremented to (0, 0, ..., 0, 1), resulting in a state (c, m, (0, 0, ...0, 1), r,
incŒ∏ ) in E, from which e pushes the agent to a state (c, m, (0, 0, ..., 1), r, sel Œ∏), where Xn = 1 in Œ∏. Here
again incŒ∏ is possible, leading to a state (c, m, (0, 0, ..., 1, 0), r, incŒ∏ ) in E from which e pushes the agent to
the state (m‚àí1, t, (0, 0, ...1, 0), r, sel Œ∏). Here again an inc action is possible for the agent etc.
In each state (c, m, Œ∏, r, sel Œ∏) such that p(tŒ∏) = c, the agent might alternatively take the action choose,
which brings her to the state (c, m, Œ∏, r, chosenŒ∏ ) in E, which closes phase 1. The exogenous action e
pushes the agent from this state to the state (m, t1 Œ∏, t2 Œ∏, do split) out of E. From this state, e pushes
the agent further to the state (t1 Œ∏, m‚àí1, prove), and the agent must take at (m, t1 Œ∏, t2 Œ∏, do split) the action split, which brings her to the state (t2 Œ∏, m‚àí1, goto prove) in E, from which e pushes the agent to
(t2 Œ∏, m‚àí1, prove). Figure 4 gives a summary of the steps in graphical form.

38

INFSYS RR 1843-04-04

(c, m, (0, ..., 1), r, selŒ∏ )
(c, m, prove)
...
(c, m, (0, ..., 0), r, selŒ∏ )
ar

e

incŒ∏

e

incŒ∏

...

(c, m, (0, ..., 2), r, incŒ∏ )
(c, m, r, apply)
(c, m, (0, ..., 1), r, incŒ∏ )

(t2 Œ∏, m‚àí1, prove)
(m, t1 Œ∏, t2 Œ∏, do split)
(t1 Œ∏, m‚àí1, prove)
(c, m, Œ∏, r, selŒ∏ )
choose e

incŒ∏

...

split

e

(t2 Œ∏, m‚àí1, do prove)
(c, m, Œ∏, r, chosenŒ∏ )

e

E

Figure 4: Schematic transition diagram for backward application of rule r : p(t) ‚Üê p(t1 ), p(t2 ) with
substitution Œ∏ to prove p(c).

In this way, the derivation of p(0, 0, . . . , 0) from œÄ is encoded to deciding 1-maintainability of S = {(2d ,
(0, 0, ..., 0), prove)} with respect to the set of states E described above. Note that to prove p(c) from œÄ
via rule r, only one instance of rŒ∏ must be chosen; the 1-maintaining control has to single out this Œ∏, by
proper placement of the action chosenŒ∏ . The proof of correctness is along the lines of the respective one in
Theorem 11.
Given the regular structure of the states and the easy checks and manipulations that need to be done for
determining applicability of actions and determining the successor state, respectively, it is not difficult to
see that a representation of the above 1-M AINTAINABILITY instance using state variables can be compiled
from œÄ and p(0, 0, . . . , 0) in logarithmic work space (in particular, that the polynomial-time procedures for
deciding the membership predicates in Phi (s, a, s‚Ä≤ ), in poss(s, a), in exo(s, a) in S (s), and in E (s) can
be provided in polynomial time). Note that this instance employs only deterministic actions, and there is a
single exogenous action. This establishes EXP-hardness for 1-M AINTAINABILITY.
Furthermore, for A and E as constructed, each agent action results in a state in E. Thus, k-maintainability
of S w.r.t. E in A, for any k = f (A, S, E) such that f (A, S, E) ‚â• 1, is equivalent to 1-maintainability of
S w.r.t. E in A. Hence, the reduction shows EXP-hardness of k‚àíM AINTAINABILITY under the stated
restriction.
2
Corollary 19 Under state representation by variables, œâ-M AINTAINABILITY is EXP-complete. The EXPhardness holds even if all actions are deterministic and there is only one exogenous action.
Using Theorem 18 instead of Theorem 11, we can prove the following result similarly as Theorem 13:
Theorem 20 Under state representation by variables and in absence of exogenous actions, the problems
k-M AINTAINABILITY and œâ-M AINTAINABILITY are EXP-complete.
For the case without exogenous actions and with only deterministic actions, we have lower complexity:
Theorem 21 Under state representation by variables, k-M AINTAINABILITY and œâ-M AINTAINABILITY for
systems with only deterministic actions and no exogenous actions are PSPACE-complete.
Proof. By well-known standard methods, a computation composed of a PSPACE computation A piped
into an NL computation B (which is NPSPACE in the size of the input for A) can be redesigned as an
NPSPACE computation. Since NPSPACE = PSPACE, membership of the problems in PSPACE thus
follows from Lemma 17 and Theorem 15.

INFSYS RR 1843-04-04

39

The PSPACE-hardness can be shown e.g. by a straightforward reduction from propositional STRIPS planning [9]. Rather than to introduce STRIPS here, we give for completeness sake a simple reduction from
S UCCINCT R EACHABILITY [44], which is the version of R EACHABILITY where G = (V, E) is such that
the nodes v are given by the binary vectors v = (v1 , . . . , vn ), n ‚â• 1, on {0, 1} and the problem input consists of a Boolean circuit CG with 2n inputs v1 , . . . , vn , w1 , . . . , wn which outputs true iff v ‚Üí w ‚àà E, and
s = (0, 0, . . . , 0) and t = (1, 1, . . . , 1). We construct from this an instance of k-M AINTAINABILITY resp. œâM AINTAINABILITY as follows: S = V √ó V , described by 2n binary variables f1 , . . . , f2n ; A = {inc, arc}
= Aagent ; Œ¶(v √ów, inc) = v √ów‚Ä≤ such that w‚Ä≤ = w + 1 modulo 2n , and Œ¶(v √ów, arc) = w √ó(0, 0, . . . , 0)
if v ‚Üí w in G and Œ¶(v √ó w, arc) = v √ó w otherwise; poss(s) = A, for each state s. Then, the state
s = (1, 1, . . . , ) √ó (0, 0, . . . , ) is |S|-maintainable with respect to E = {(1, 1, . . . , 1) √ó (1, 1, . . . , 1)} in
A iff (1, 1, . . . , 1) is reachable from (0, 0, . . . , 0) in G. A state variable representation of A can be easily
generated from the circuit CG in logarithmic workspace. This implies PSPACE-hardness of the problems.2
If the maintenance window is bounded by a constant, the problem is easier.
Theorem 22 Under state representation by variables, k-M AINTAINABILITY for systems without exogenous
actions and constant k ‚â• 0 is co-NP-complete.
Proof. For a given s ‚àà S, falsity of rk (s) can be proved by exhibiting (assuming s ‚àà
/ E), for each a ‚àà
Aagent ‚à© poss(s) a witness w(s, a) ‚àà S such that w(s, a) ‚àà Œ¶(s, a) and rk‚àí1 (w(s, a)) is false, which in
recursion can be proved similarly. For constant k, this leads to O(|Aagent |k ) many guesses w(s, a), which
is polynomial in the size of the input. By Lemma 14, it thus follows that deciding the complement of
k-M AINTAINABILITY is in NP. This proves membership in co-NP.
The co-NP-hardness, for every k ‚â• 0, is a simple consequence that under representation by state variables, deciding whether S ‚äÜ E is co-NP-complete (this can be shown, e.g., by a simple reduction from
propositional unsatisfiability).
2

8 Discussion and Conclusion
In this paper, we gave a formal characterization of maintenance goals and distinguished it from the notions
of stabilizability and temporal goals of the form 23f (over all valid trajectories). We present several
motivating examples that illustrate the need for our notion of maintainability. The basic idea being that
for certain kinds of maintenance it is important that the maintaining agent be given a window of noninterference from the environment so that it can do the maintenance. To formalize this we need to distinguish
between the agent‚Äôs actions and the environment‚Äôs actions. In our formalization we define the notion of kmaintainability, where k refers to the maximum window of opportunity necessary for the maintenance.
We then gave polynomial time algorithms to compute k-maintainable controls, which are linear-time for
small k, and we analyzed the complexity of determining k-maintainability under various assumptions. One
interesting aspect of our polynomial time algorithm is the approach that led to its finding: use of SAT
encoding, and complexity results regarding the special Horn sub-class of propositional logic.

8.1

Other related work

Besides the related works we already mentioned such as stabilizability and temporal logic, the notion of
maintenance has appeared in AI in many other papers. For example, in [42], Ortiz discusses maintenance
actions. His notion of maintenance is stronger than both the notion of stabilizability and our notion as he

40

INFSYS RR 1843-04-04

requires the formula that is maintained to be true throughout. The notion of maintenance is also related
to the notion of ‚Äòexecution monitoring‚Äô which is studied in the context of robot programs in [14]. In ‚Äòexecution monitoring‚Äô the world is monitored and if a discrepancy is found between the prediction made by
the agent and the real world, then new plans are made to recover from the discrepancy. A deliberative architecture for maintenance can be extrapolated from the notions in [2], where an agent executes a cycle of
observe; assimilate; (re)plan f rom current situation; execute part of the plan.
In other related work, Jensen et al. [28, 29] consider the somewhat dual problem of developing policies
that achieve a given goal while there are interferences from the environment. In their model, environment
actions and actions of multiple agents are combined to a joint action, by which the system is transferred
from the current state to one out of a set of possible successor states. With such nondeterministic transitions,
Jensen et al. aim at modeling both an adversial environment and infrequent errors which make an otherwise
deterministic action non-deterministic. In [28], they consider constructing policies coping with arbitrarily
many interferences of the environment (but without action failure) by an extension of OBDD-based universal
planning, and in [29] they consider generating policies which tolerate up to a given number n of errors
modeled as ‚Äúsecondary action effects‚Äù (caused by improper action execution or environment interference),
by reducing it to a so called strong planning problem, which is solved using OBDD based methods. For
arbitrarily many environment interferences as in [28], the problem is basically very similar to our problem
of unbounded maintainability, but interference in goal states has different significance and goal achievement
is not guaranteed because of possible loops. A formal connection between k-maintainable controls and
n-fault tolerant policies, if any, remains open. Intuitively, n-fault tolerant plans are easier to construct,
since the number of errors that have occurred can be recorded in plan construction and when the limit n is
reached, the problem boils down to an ordinary planning problem. For k-maintaining controls, however,
each environment interference (even at a goal state) causes a restart which pushes the agent to a new initial
state.
In a series of papers [54, 19, 18], Wooldridge and Dunne have formalized the problem of constructing
agent control functions and analyzed its complexity in a rich framework, for various kinds of tasks such
as ‚Äúachievement‚Äù tasks (where the agent has to bring about a certain goal condition), ‚Äúmaintenance‚Äù tasks
(where the agent has to avoid that some goal condition is ever satisfied during execution), and combinations
thereof [18]. In their framework, action effects and the selection of the agent action by the control may
depend on the history of the execution, and most importantly, exogenous actions resp. an adversary are not
taken into account. Under restriction to history-independent state transitions and reactive agents, finding
controls for achievement tasks in their framework corresponds to finding maintaining controls with an unbounded window of opportunity in our framework. Theorems 15 and 21 correspond to respective results in
the Wooldridge-Dunne framework [18].
In AI planning, the seminal STRIPS approach [23] has been one of the most influential approaches. We
briefly recall that in STRIPS, states are modeled as sets of propositional atoms and actions as operators
which, given that a precondition in terms of a conjunction of literals is true on the current state, transform
it to a successor state by removing atoms from a delete list and adding atoms from an add list. A plan for
achieving a goal, described by a conjunction of atoms Œ≥, from an initial state S0 is a sequence of operators
op1 , . . . , pn which takes the agent from S0 to a state where Œ≥ holds. STRIPS planning has been generalized
in several directions, such as conditional effects, nondeterministic actions, or planning under incomplete
information and partial observability using conditional and conformant plans, respectively, and a number of
papers has considered the computation and complexity of planning in such settings, e.g., [9, 3, 11, 22, 49].
However, like in the framework of Wooldridge and Dunne, in none of these works agent actions and exogenous actions are viewed separately, and thus they are best compared to our framework in absence of

INFSYS RR 1843-04-04

41

exogenous functions. Furthermore, plans per se are conceived as action strategies (cf. [49]) in which, in
principle, different actions might be taken by the agent if during plan execution the same state is entered
again; however, such looping is a priori excluded if the goal must be achieved under all contingencies.
Cimatti et al. [11] consider constructing universal plans akin to our policies, with different semantics for
goal achievement, based on OBDD methods and algorithms. In particular, in absence of exogenous actions
our maintaining controls correspond to what they call strong solutions for a planning problem. Jensen et al.
[28, 29] have generalized this by adversial actions (see above).
As for complexity, Theorem 21, corresponds to the classical result of Bylander [9] that deciding plan existence in propositional STRIPS is PSPACE-complete, while Theorem 20 corresponds to Littman‚Äôs result
that conditional planning for STRIPS with nondeterministic actions is EXPTIME-complete [34, 49]. In
conditional planning, via conditions on the current state branching to subplans is possible, such that an appropriate plan is followed depending on the state evolution. Branching might be modeled by actions and the
conditional planning problem, with loops disregarded, as the problem of constructing a maintaining control.
Outside of AI, our notion of k-maintenance is very closely related to the notion of self-stabilization in [15]
which is used in characterizing fault-tolerant systems. There the concern is about proving correctness of
(hand developed) self-stabilization protocols and achieving self-stabilization for various distributed algorithms such as mutual exclusion. Our algorithm here can be thought of as an algorithm that automatically
generates a self-stabilization protocol. Although, this is a new dimension to the existing work on selfstabilization, further research is needed to compare assumptions made in our formulation and the ones in
the self-stabilization literature, and overcome them. In particular, often in the self-stabilization literature
the global states are composed of local states of various distributed elements and a particular element does
not have the access to the complete global state. In those cases one can not directly use the kind of global
policies generated by the algorithm in this paper.

8.2

Future work and open issues

There are several directions for further research extending the work of this paper. One direction concerns
variations of the maintenance problem, for instance by taking action duration into account. In such scenario,
the maintenance goal may be formulated as requirement that the agent reaches some desired state always
within a given time frame, if she is not disturbed by the environment. Preliminary investigations suggest
that the results in this paper can be extended to handle this setting.
The intractability results for the problems under state variable representations challenges methods and techniques for handling the problem in practice. Suitable heuristics may therefore be researched that allow to
solve the problems in many cases in polynomial time, and, in a refined complexity analysis, meaningful
tractable cases should be singled out. Furthermore, the issue of computing optimal k-maintenance controls efficiently, in the sense that k is as small as possible (which is trivially polynomially solvable in the
enumerative setting), is an interesting issue for variable state representation.
Another issue concerns investigating computational transformations between maintenance and planning. By
the complexity results in [34] and this paper, transformations between k-M AINTAINABILITY and conditional
planning are feasible in polynomial time. It would be interesting to study different transformations, and to
assess possible benefits of these transformations for solving k-M AINTAINABILITY and planning by crossutilizing different algorithms and implementations (e.g. [11] for planning in non-deterministic domains).
In particular a transformation similar to the one in the proof of Theorem 13, with an additional parameter
that keeps count the number of agent‚Äôs actions since the last exogenous action, can4 be used to compile out
4

This transformation increases the number of states by k times. It is unknown if there exist a transformation that can eliminate

42

INFSYS RR 1843-04-04

exogenous actions and transform finding k-maintainable policies to finding strong cyclic plans [11]; on the
other hand, encodings similar to the one in Section 5.2 for obtaining strong cyclic plans through linear-time
Horn logic programming might be interesting.
Acknowledgment We would like to acknowledge W. Cushing for his feedback on an earlier draft and
S. Gupta and M. Gouda for their clarifications on self-stabilization. Furthermore, we acknowledge comments by J. Rintanen on the ICAPS‚Äô04 paper and are grateful for his pointers to related work.
The major part of the algorithms was done when Chitta Baral was visiting TU Wien in May 2003. Marcus BjaÃàreland carried out the major part of his work while he was with the Department of Computer and
Information Science of Linkoping University.

References
[1] F. Bacchus and F. Kabanza. Planning for temporally extended goals. Annals of Mathematics and Artificial
Intelligence, 22:5‚Äì27, 1998.
[2] C. Baral, M. Gelfond, and A. Provetti. Representing actions: Laws, observations, and hypothesis. Journal of
Logic Programming, 31:201‚Äì243, 1997.
[3] C. Baral, V. Kreinovich, and R. Trejo. Computational complexity of planning and approximate planning in the
presence of incompleteness. Artificial Intelligence, 122(1-2):241‚Äì267, 2000.
[4] C. Baral, V. Kreinovich, and R. Trejo. Computational complexity of planning with temporal goals. In B. Nebel,
editor, Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI-01), pages 509‚Äì
514. Morgan Kaufmann, 2001.
[5] C. Baral and T. Son. Relating theories of actions and reactive control. Electronic Transactions on Artificial
Intelligence, 2(3-4):211‚Äì271, 1998.
[6] C. Baral and J. Zhao. Goal specification in presence of non-deterministic actions. In R. L. de MaÃÅntaras and
L. Saitta, editors, Proceedings of the 16th European Conference on Artificial Intelligence (ECAI 2004), Valencia,
Spain, August 22-27, 2004, pages 273‚Äì277. IOS Press, 2004.
[7] D. Barrington, N. Immerman, and H. Straubing. On uniformity within N C 1 . J. Comput. Syst. Sci., 41:274‚Äì306,
1990.
[8] R. Brooks. A robust layered control system for a mobile robot. IEEE Journal of Robotics and Automation,
2(1):14‚Äì23, 1986.
[9] T. Bylander. The computational complexity of propositional strips planning. Artificial Intelligence, 69:165‚Äì204,
1994.
[10] S. Ceri and J. Widom. Deriving production rules for constraint maintenance. In Proceedings VLDB-90, pages
566‚Äì577, 1990.
[11] A. Cimatti, M. Pistore, M. Roveri, and P. Traverso. Weak, strong, and strong cyclic planning via symbolic model
checking. Artificial Intelligence, 147(1-2):35‚Äì84, 2003.
[12] E. Clarke, E. Emerson, and A. Sistla. Automatic verification of finite-state concurrent systems using temporal
logic specifications. ACM Transactions on Programming Languages, 8(2):244‚Äì263, 1986.
[13] E. Dantsin, T. Eiter, G. Gottlob, and A. Voronkov. Complexity and expressive power of logic programming.
ACM Computing Surveys, 33(3):374‚Äì425, 2001.
exogenous actions without increasing the number of states, and yet is able to model the notion of k-maintainability.

INFSYS RR 1843-04-04

43

[14] G. De Giacomo, R. Reiter, and M. Soutchanski. Execution monitoring of high-level robot programs. In Proc.
Conference on Principles of Knowledge Representation and Reasoning (KR-98), pages 453‚Äì465, 1998.
[15] E. Dijkstra. A theory of the learnable. Commun. ACM, 17(11):643‚Äì644, 1974.
[16] W. Dowling and J. H. Gallier. Linear-time algorithms for testing the satisfiability of propositional Horn theories.
Journal of Logic Programming, 3:267‚Äì284, 1984.
[17] M. Drummond. Situation control rules. In Proceedings First International Conference on Principles of Knowledge Representation and Reasoning (KR-89), pages 103‚Äì113, 1989.
[18] P. Dunne, M. Laurence, and M. Wooldridge. Complexity results for agent design problems. Annals of Mathematics, Computing & Teleinformatics, 1(1):19‚Äì36, 2003.
[19] P. Dunne and M. Wooldridge. , atal 2000, boston, ma, usa, july 7-9, 2000, proceedings. In C. Castelfranchi
and Y. LespeÃÅrance, editors, Proceedings 7th International Workshop on Intelligent Agents VII. Agent Theories
Architectures and Languages (ATAL), volume 1986 of Lecture Notes in Computer Science, pages 1‚Äì14. Springer,
2001.
[20] T. Eiter, W. Faber, N. Leone, and G. Pfeifer. Declarative problem-solving using the DLV system. In J. Minker,
editor, Logic-Based Artificial Intelligence, pages 79‚Äì103. Kluwer Academic Publishers, 2000.
[21] E. Emerson. Temporal and modal logics. In J. van Leeuwen, editor, Handbook of Theoretical Computer Science,
volume B, chapter 16. Elsevier Science Publishers B.V. (North-Holland), 1990.
[22] K. Erol, V. Subrahmanian, and D. Nau. Complexity, decidability and undecidability results for domainindependent planning. Artificial Intelligence, 76:75‚Äì88, 1995.
[23] R. E. Fikes and N. J. Nilsson. Strips: A new approach to the application of theorem proving to problem solving.
Artificial Intelligence, 2(3-4):189‚Äì208, 1971.
[24] M. Gelfond and V. Lifschitz. Classical negation in logic programs and disjunctive databases. New Generation
Computing, 9:365‚Äì385, 1991.
[25] M. Gelfond and V. Lifschitz. Representing action in extended logic programs. In Proceedings of the Joint International Conference and Symposium on Logic Programming (JICSLP‚Äô92), pages 559‚Äì573. MIT Press, 1992.
[26] M. L. Ginsberg. Universal planning: An (almost) universally bad idea. AI Magazine, 10(4):40‚Äì44, 1989.
[27] N. Immerman. Descriptive Complexity. Springer, 1999.
[28] R. M. Jensen, M. M. Veloso, and M. H. Bowling. Obdd-based optimistic and strong cyclic adversarial planning.
In Proceedings 6th European Conference on Planning (ECP-01), 2001.
[29] R. M. Jensen, M. M. Veloso, and R. E. Bryant. Fault tolerant planning: Toward probabilistic uncertainty models
in symbolic non-deterministic planning. In S. Zilberstein, J. Koehler, and S. Koenig, editors, Proceedings 14th
International Conference on Automated Planning and Scheduling (ICAPS 2004), Whistler, British Columbia,
Canada, June 3-7, 2004, pages 335‚Äì344, 2004.
[30] F. Kabanza, M. Barbeau, and R. St-Denis. Planning control rules for reactive agents. Artificial Intelligence,
95(1):67‚Äì113, 1997.
[31] L. P. Kaelbling and S. J. Rosenschein. Action and planning in embedded agents. In P. Maes, editor, Designing
Autonomous Agents: Theory and Practice from Biology to Engineering and Back, pages 35‚Äì48. The MIT Press:
Cambridge, MA, USA, 1990.
[32] C. Kuratowski. Topology I. Academic Press, New York, 1966.
[33] N. Leone, G. Pfeifer, W. Faber, T. Eiter, G. Gottlob, S. Perri, and F. Scarcello. The dlv system for knowledge
representation and reasoning. ACM Transactions on Computational Logic, 2004. To appear. Available via
http://www.arxiv.org/ps/cs.AI/0211004.

44

INFSYS RR 1843-04-04

[34] M. L. Littman. Probabilistic propositional planning: Representations and complexity. In Proceedings AAAI/IAAI
1997, pages 748‚Äì754, 1997.
[35] P. Maes, editor. Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back.
The MIT Press: Cambridge, MA, USA, 1990.
[36] Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems, Specification. SpringerVerlag, 1992.
[37] M. Minoux. LTUR: a simplified linear time unit resolution for Horn formulae and computer implementation.
Information Processing Letters, 29:1‚Äì12, 1988.
[38] M. Nakamura and C. Baral. Invariance, maintenance and other declarative objectives of triggers ‚Äì a formal
characterization of active databases. In J. Lloyd, V. Dahl, U. Furbach, M. Kerber, K.-K. Lau, C. Palamidessi,
L. M. Pereira, Y. Sagiv, and P. J. Stuckey, editors, Proceedings First International Conference on Computational
Logic - CL 2000, number 1861 in LNAI, pages 1210‚Äì1224. Springer Verlag, July 2000.
[39] M. Nakamura, C. Baral, and M. Bj√¶reland. Maintainability: a weaker stabilizability like notion for high level
control. In Proceedings National Conference on AI (AAAI ‚Äô00), July 30-August 3, 2000, Austin, Texas, pages
62‚Äì67. AAAI Press, 2000.
[40] I. NiemelaÃà, P. Simons, and T. SyrjaÃànen. Smodels: A system for answer set programming. In C. Baral
and M. TruszczynÃÅski, editors, Proceedings of the 8th International Workshop on Non-Monotonic Reasoning
(NMR‚Äô2000), Breckenridge, Colorado, USA, April 2000.
[41] R. Niyogi and S. Sarkar. Logical specification of goals. In Proceedings 3rd International Conference on Information Technology, pages 77‚Äì82. Tata McGraw-Hill, July 2000.
[42] C. Ortiz. A commonsense language for reasoning about causation and rational action. Artificial Intelligence,
111(2):73‚Äì130, 1999.
[43] O. Ozveren, A. Willsky, and P. Antsaklis. Stability and stabilizability of discrete event dynamic systems. J. ACM,
38(3):7300‚Äì752, 1991.
[44] C. H. Papadimitriou. Computational Complexity. Addison-Wesley, 1994.
[45] K. Passino and K. Burgess. Stability Analysis of Discrete Event Systems. John Wiley and Sons, 1998.
[46] P. Ramadge and W. Wonham. Modular feedback logic for discrete event systems. SIAM Journal of Control and
Optimization, 25(5):1202‚Äì1217, 1987.
[47] P. Ramadge and W. Wonham. Supervisory control of a class of discrete event process. SIAM Journal of Control
and Optimization, 25(1):206‚Äì230, 1987.
[48] R. Reiter. Knowledge in Action: Logical Foundation for Describing and Implementing Dynamical Systems. MIT
Press, 2001.
[49] J. Rintanen. Complexity of planning with partial observability. In S. Zilberstein, J. Koehler, and S. Koenig, editors, Proceedings 14th International Conference on Automated Planning and Scheduling (ICAPS 2004), Whistler,
British Columbia, Canada, June 3-7, 2004, pages 345‚Äì354, 2004.
[50] P. Simons, I. NiemelaÃà, and T. Soininen. Extending and implementing the stable model semantics. Artificial
Intelligence, 138:181‚Äì234, June 2002.
[51] E. Sontag. Stability and stabilization: Discontinuities and the effect of disturbances. In F. Clarke and R. Stern,
editors, Proceedings NATO Advanced Study Institute, pages 551‚Äì598. Kluwer, July 1998.
[52] D. Weld and O. Etzioni. The first law of robotics (a call to arms). In Proceedings of the Twelfth National
Conference on Artificial Intelligence (AAAI-94), pages 1042‚Äì1047. AAAI Press, 1994.
[53] J. Widom and S. Ceri, editors. Active Database Systems: Triggers and Rules For Advanced Database Processing.
Morgan Kaufmann, 1996.
[54] M. Wooldridge. The computational complexity of agent design problems. In Proceedings of the Fourth International Conference on Multi-Agent Systems (ICMAS 2000). IEEE Press, 2000.

Using Smodels (Declarative Logic Programming) to Verify Correctness of
Certain Active Rules
Mutsumi Nakamura, Ramez Elmasri
Department of Computer Science and Engineering
The University of Texas at Arlington, Arlington, TX 76019
nakamura@asu.edu, elmasri@cse.uta.edu

Abstract
In this paper we show that the language of declarative
logic programming (DLP) with answer sets and its extensions can be used to specify database evolution due to updates and active rules, and to verify correctness of active
rules with respect to a speciÔ¨Åcation described using temporal logic and aggregate operators. We classify the speciÔ¨Åcation of active rules into four kind of constraints which
can be expressed using a particular extension of DLP called
Smodels. Smodels allows us to specify the evolution, to
specify the constraints, and to enumerate all possible initial database states and initial updates. Together, these can
be used to analyze all possible evolution paths of an active
database system to verify if they satisfy a set of given constraints.
Active databases have tremendous potential to simplify database programming by specifying appropriate
ECA(Event-Condition-Action) rules. One impediment to
their widespread use has been the need for design methodologies and veriÔ¨Åcation techniques to show that a set of
rules is consistent and satisÔ¨Åes the system requirements.
Database triggers are typically activated when a particular update occurs. When we have a set of triggers, an update
which is activated by one trigger can activate other triggers
and can create a sequence of updates. A designer of an active database should make sure that sequences of updates
do not violate the ‚Äùpurpose‚Äù of the triggers. Triggers are
an essential component of active database systems and are
now part of the SQL3 database standard. After their implementation in several research prototypes, they are now
incorporated in commercial database systems such as Oracle, Sybase and IBM‚Äôs DB2-V2 [1].
There has been much work on the syntax of triggers, how
they are to be executed, their execution models, and their
implementations, and some work on formal frameworks for
active databases in regards to semantics and expressiveness. However, comparatively fewer work has been done
on methodologies to design triggers, specify what triggers

Proceedings of the 18th International Conference on Data Engineering (ICDE‚Äô02)
1063-6382/02 $17.00 ¬© 2002 IEEE

are supposed to achieve (their ‚Äùpurpose‚Äù), and ways to verify their correctness.We have made some progress on these
issues in [2] where we developed a speciÔ¨Åcation language
for triggers which can be used to specify the purpose of triggers.
In this paper, we show how one can simulate the effect
of active rules (triggers), specify their purpose, and a limited veriÔ¨Åcation of the correctness of a set of triggers with
respect to its purpose. For this we use declarative logic programming (DLP) with answer set semantics and the Smodels system [3].
Using Smodels, we can also enumerate all possible initial database states and initial updates, and specify active
rules. In this way, the database evolution can be speciÔ¨Åed
and tested against a given speciÔ¨Åcation. If it satisÔ¨Åes all
constraints of the speciÔ¨Åcation we can conclude that the set
of active rules is correct with respect to the speciÔ¨Åcation.
Our work in this paper extends our earlier work in [2]
where we identiÔ¨Åed state and trajectory invariance and
maintenance constraints as important parameters in specifying the purpose of triggers and deÔ¨Åned correctness of triggers. Here we show DLP and Smodels to be a candidate
language for both speciÔ¨Åcation and perhaps even to serve
as the engine for a trigger veriÔ¨Åcation system. Developing
a general trigger veriÔ¨Åcations system with a DLP engine is
one of our future goals. The full version of this paper is
available at: http://www.public.asu.edu/mutsumi/activedb/papers/icde02.pdf or icde02.ps.

References
[1] D. Chamberlin. Using the new DB2: IBM‚Äôs Object-relational
database system. Morgan Kaufmann, 1996.
[2] M. Nakamura and C. Baral. Invariance, maintenance and other
declarative objectives of triggers ‚Äì a formal characterization of
active databases. In CL 2000, pages 1210‚Äì1224, 2000.
[3] I. Niemela and P. Simons. Smodels ‚Äì an implementation of
the stable model and well-founded semantics for normal logic
programs. In LPNMR ‚Äô97, pages 420‚Äì429, 1997.

I N F S Y S
R

E S E A R C H

R

E P O R T

I NSTITUT F UÃàR I NFORMATIONSSYSTEME
A RBEITSBEREICH W ISSENSBASIERTE S YSTEME

M AINTENANCE G OALS OF AGENTS IN A
DYNAMIC E NVIRONMENT: F ORMULATION
AND P OLICY C ONSTRUCTION

Chitta Baral

Thomas Eiter
Marcus BjaÃàreland
Mutsumi Nakamura

INFSYS R ESEARCH R EPORT 1843-04-04
O CTOBER 2004

Institut fuÃàr Informationssysteme
AB Wissensbasierte Systeme
Technische UniversitaÃàt Wien
Favoritenstrass√üe 9-11
A-1040 Wien, Austria
Tel:

+43-1-58801-18405

Fax:

+43-1-58801-18493

sek@kr.tuwien.ac.at
www.kr.tuwien.ac.at

INFSYS R ESEARCH R EPORT
INFSYS R ESEARCH R EPORT 1843-04-04, O CTOBER 2004

M AINTENANCE G OALS OF AGENTS IN A DYNAMIC E NVIRONMENT:
F ORMULATION AND P OLICY C ONSTRUCTION
Chitta Baral1

Thomas Eiter2

Marcus BjaÃàreland3

Mutsumi Nakamura1

Abstract.The notion of maintenance often appears in the AI literature in the context of agent behavior and planning. In this paper, we argue that earlier characterizations of the notion of maintenance
are not intuitive to characterize the maintenance behavior of certain agents in a dynamic environment. We propose a different characterization of maintenance and distinguish it from earlier notions
such as stabilizability. Our notion of maintenance is more sensitive to a good-natured agent which
struggles with an ‚Äúadversary‚Äù environment, which hinders her by unforeseeable events to reach her
goals (not in principle, but in case). It has a parameter k, referring to the length of non-interference
(from exogenous events) needed to maintain a goal; we refer to this notion as k-maintainability. We
demonstrate the notion on examples, and address the important but non-trivial issue of efficient construction of maintainability control functions. We present an algorithm which in polynomial time
constructs a k-maintainable control function, if one exists, or tells that no such control is possible.
Our algorithm is based on SAT Solving, and employs a suitable formulation of the existence of kmaintainable control in a fragment of SAT which is tractable. For small k (bounded by a constant),
our algorithm is linear time. We then give a logic programming implementation of our algorithm
and use it to give a standard procedural algorithm, and analyze the complexity of constructing kmaintainable controls, under different assumptions such as k = 1, and states described by variables.
On the one hand, our work provides new concepts and algorithms for maintenance in dynamic environment, and on the other hand, a very fruitful application of computational logic tools.
Keywords: intelligent agents, maintenance goals, maintainability, agent control, policy construction, declarative logic programming, SAT solving, computational complexity, discrete event dynamic systems.
1

Department of Computer Science and Engineering, Arizona State University, Tempe, AZ 85233, USA.
Email: {chitta, mutsumi}@asu.edu
2
Institut fuÃàr Informationssysteme, Knowledge Based Systems Group, Technische UniversitaÃàt Wien, Favoritenstra√üe
9-11, A-1040 Vienna, Austria. E-mail: eiter@kr.tuwien.ac.at.
3
AstraZeneca R&D, S-43183 MoÃàlndal, Sweden. Email: marcus.bjareland@astrazeneca.com
Acknowledgements: This work was partially supported by FWF (Austrian Science Funds) projects
P-16536-N04 and Z29-N04, a research collaboration grant by TU Wien, the European Commission under
grant IST 2001-37004 WASP, the NSF (National Science Foundation of USA) grant numbers 0070463, and
0412000, NASA grant number NCC2-1232, and an ARDA contract.
A preliminary version of the formulation part, entitled ‚ÄúA formal characterization of maintenance goals,‚Äù
has been presented at AAAI‚Äô00, and a preliminary version of the algorithm part entitled ‚ÄúA polynomial time
algorithm for constructing k-maintainable policies‚Äù has been presented at ICAPS‚Äô04. The current version
revises and combines both of them with additional elaborations, examples, results, and proofs.
c 2007 by the authors
Copyright 

INFSYS RR 1843-04-04

I

Contents
1 Introduction and Motivation

1

2 Background: Systems, Goals, Control, Stability and Stabilizability
2.1 Stabilizability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3
5

3 Example Scenario: Two Finite Buffers

6

4 Limited Interference and k-Maintainability
8
4.1 An alternative characterization of k-maintainability . . . . . . . . . . . . . . . . . . . . . . 11
5 Polynomial Time Methods to Construct k-Maintainable Controls
5.1 Deterministic transition function Œ¶(s, a) . . . . . . . . . . . .
5.1.1 Horn SAT encoding . . . . . . . . . . . . . . . . . . .
5.2 Non-deterministic transition function Œ¶(s, a) . . . . . . . . .
5.2.1 Horn SAT encoding (general case) . . . . . . . . . . .
5.3 Genuine algorithm . . . . . . . . . . . . . . . . . . . . . . .
6 Encoding Maintainability for an Answer Set Solver
6.1 Input representation . . . . . . . . . . . . . . . .
6.2 Deterministic transition function Œ¶ . . . . . . . .
6.3 Nondeterministic transition function Œ¶ . . . . . .
6.4 Layered use of negation . . . . . . . . . . . . . .
6.5 State descriptions by variables . . . . . . . . . .

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

12
13
15
18
20
23

.
.
.
.
.

24
25
25
27
28
29

7 Computational Complexity
30
7.1 Problems considered and overview of results . . . . . . . . . . . . . . . . . . . . . . . . . . 30
7.2 Enumerative representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
7.3 State variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
8 Discussion and Conclusion
39
8.1 Other related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
8.2 Future work and open issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

INFSYS RR 1843-04-04

1

1 Introduction and Motivation
For an agent situated in a static environment, the goal is often to reach one out of several states where certain
conditions are satisfied. Such a goal is usually expressed by a formula in propositional or first-order logic.
Sometimes the goal requires constraining the path taken to reach one of the states. In that case, the goal can
be expressed by a formula in temporal logic [1, 41, 4].
Our concern in this paper is about agents in a dynamic environment. In that case, things are more complex
since the state of the world can change through both actions of the agent and of the environment. The agent‚Äôs
goal in a dynamic environment is then often more than just achieving a desired state, as after the agent has
successfully acted to reach a desired state, the environment may change that state. In such a case, a common
goal of an agent is to ‚Äòmaintain‚Äô rather than just ‚Äòachieve‚Äô certain conditions. The goal of maintaining certain
conditions (or a set of states that satisfy these conditions) is referred to as maintenance goals. Maintenance
goals are well-known in the AI literature, e.g., [52, 30, 1, 42], and have counterparts in other areas such as
in stability theory of discrete event dynamic systems [43, 45, 47, 46, 51] and in active databases [10, 38].
However, as we argue in this paper, earlier characterizations of maintenance goals are not adequate under
all circumstances.
To see what is wrong with earlier definition of maintenance goals, suppose an agent‚Äôs goal is to maintain
a fluent f , i.e., the proposition f should be true. A straightforward attempt1 to express it using temporal
operators is the formula 2f , where 2 is the temporal operator ‚ÄúAlways‚Äù and 2f means that f is true in all
the future states of the world. This is too strong a condition, as maintaining inherently means that things go
out of shape and they have to be maintained back to shape. A better temporal logic representation of this
goal is thus the formula 23f , where 3 is the temporal operator ‚ÄúEventually.‚Äù Intuitively, the formula 23f
is satisfied by an infinite trajectory of states of the form s0 , s1 , s2 , . . ., if at any stage i ‚â• 0, there exists
some stage j ‚â• i such that f is true in sj . An agent‚Äôs control is said to satisfy 23f if all trajectories that
characterize the evolution of the world due to the environment and the agent‚Äôs control satisfy 23f . At first
glance the formula 23f seems to express the goal of maintaining f , as it encodes that if f becomes f alse
in any state in the trajectory then it becomes true in a later state.
We consider 23f to be also too strong a specification‚Äîin many situations‚Äîto express the intuitive notion
of ‚Äòmaintaining f ‚Äô, if we take on a more refined view of the (sometimes nasty) part which the environment
might play, which we illustrate by some examples. Suppose f denotes the condition that the Inbox of a
customer service department be empty. Here the environment makes f false by adding new requests to the
Inbox while the agent tries to make f true by processing the messages in the Inbox and removing them from
it. If the agent is diligent in processing the message in the Inbox and makes it empty every chance the agent
gets, we would then like to say that agent maintains the Inbox empty. But such a control does not satisfy the
formula 23f under all circumstances, because there will be trajectories where the agent is overwhelmed by
the environment (flooding the Inbox) and f never becomes true.
Another example in support of our intuition behind maintainability is the notion of maintaining the consistency of a database [10, 38, 53]. When direct updates are made to a database, maintaining the consistency
of the database entails the triggering of additional updates that may bring about additional changes to the
database so that in the final state (after the triggering is done) the database reaches a consistent state. This
does not mean that the database will reach consistency if continuous updates are made to it and it is not
given a chance to recover. In fact, if continuous update requests are made we may have something similar
1
All through the paper we consider the evaluation of linear temporal formulas with respect to all ‚Äòvalid‚Äô trajectories. An
alternative approach would be to use a variation of the branching time quantifier A, such as the operator AœÄ from [6], before the
linear temporal formulas.

2

INFSYS RR 1843-04-04

to denial service of attacks. In this case we can not fault the triggers saying that they do not maintain the
consistency of the database. They do. It is just that they need to be given a window of opportunity or a
respite from continuous harassment from the environment to bring about the additional changes which are
necessary to restore database consistency. The same holds for maintaining a room clean; we can not fault
the cleaning person if he or she is continually sent away because the room is being continuously used.
Another example is a mobile robot [8, 35] which is asked to ‚Äòmaintain‚Äô a state where there are no obstacles
in front of it. Here, if there is a belligerent adversary that keeps on putting an obstacle in front of the robot,
there is no way for the robot to reach a state with no obstacle in front of it. But often we will be satisfied if
the robot avoids obstacles in its front when it is not continually harassed. Of course, we would rather have
the robot take a path that does not have such an adversary, but in the absence of such a path, it would be
acceptable if it takes an available path and ‚Äòmaintains‚Äô states where there are no obstacles in front.
The inadequacy of the expression 23f in expressing our intuition about ‚Äòmaintaining f ‚Äô is because 23f
is defined on trajectories which do not distinguish between transitions due to agent actions and environment
actions. Thus we can not distinguish the cases
(i) where the agent does its best to maintain f (and is sometimes thwarted by the environment) and can
indeed make f true in some (say, k) steps if there is no interference from the environment during those
steps; and
(ii) where the agent really does not even try.
We refer to (i) as k-maintainability in this paper. The expression 23f can not express the idea of a window
of opportunity (or window of non-interference) during which an agent can perform the actions necessary
for maintaining. In fact, none of the standard notions of temporal logics [12, 36], which are defined on
trajectories that do not distinguish between the cause behind the transitions (whether they are due to agent‚Äôs
actions or due to the environment), can express the idea behind k-maintainability.
The main contributions of this paper can be summarized as follows.
1. We introduce and formally define the notion of k-maintainability, and distinguish it from earlier notions of maintainability, in particular the specification 23f and the similar notion of stabilizability
from discrete event dynamic systems.
2. We provide polynomial time algorithms that can construct k-maintainable control policies, if one
exists. (In the rest of the paper we will refer to ‚Äòcontrol policy‚Äô simply by ‚Äòcontrol‚Äô.) Our algorithm is
based on SAT Solving, and employs a suitable formulation of the existence of k-maintainable control
in a tractable fragment of SAT. We then give a logic programming implementation of this method,
and finally distill from it a standard procedural algorithm.
3. We analyze the computational complexity of constructing k-maintainable controls, under different settings of the environment and the windows of opportunity open to the agent, as well as under different
forms of representation. We show that the problem is complete for PTIME in the standard setting,
where the possible states are enumerated, and complete for EXPTIME in a STRIPS-style setting
where states are given by value assignments to fluents. Furthermore, we elucidate the impact of the
different factors and show, by our proofs of the hardness results, that the full problem complexity is
inherent already to certain restricted cases.
Overall, our work not only provides new concepts and algorithms for realizing maintenance of an agent in
dynamic environment, but also illustrates a very fruitful application of computational logic tools.

INFSYS RR 1843-04-04

3

The rest of this paper is organized as follows. In Section 2 we present the background definitions of a
system with an agent in an environment and define the notions of stability and stabilizability. In Section 3
we describe a running example of a system with two buffers. We use this example for illustrating the
concepts of stabilizability and k-maintainability, which is formally defined in Section 4. In Section 5 we
present our algorithms for constructing k-maintaining controls, based on SAT Solving as well as a genuine
algorithm extracted from it. In Section 6 we present an encoding for computing a control function using a
logic programming engine and devote Section 7 to complexity analysis. Finally, in Section 8 we conclude,
mention related work and outline some future directions.

2 Background: Systems, Goals, Control, Stability and Stabilizability
In this paper, we are concerned with goal-directed agents in a dynamic world. Such agents can perform
actions that change the state of the world. Because of the dynamic nature of the world, certain changes can
happen to the state of the world beyond the control of an agent. The agent‚Äôs job is thus to make the world
evolve in a way coherent with a goal assigned to it. As for the agent control, we adopt here that an agent
follows a Markovian control policy to do its job; that is, its control is a function from the set of states to the
set of actions, detailed as follows.
Definition 1 (System) A system is a quadruple A = (S, A, Œ¶, poss), where
‚Ä¢ S is the set of system states;
‚Ä¢ A is the set of actions, which is the union of the set of agents actions, Aagent , and the set of environmental actions, Aenv ;
‚Ä¢ Œ¶ : S √ó A ‚Üí 2S is a non-deterministic transition function that specifies how the state of the world
changes in response to actions; and
‚Ä¢ poss : S ‚Üí 2A is a function that describes which actions are possible to take in which states.
The above notion of system is used in the discrete event dynamic systems community, for instance in [43, 45,
47, 46, 51]. In practice, the functions Œ¶ and poss are required to be effectively (and efficiently) computable,
and they may often be specified in a representation language such as in [25, 23, 48]. The possibility of an
action has different meaning depending on whether it is an agent‚Äôs action or whether it is an environmental
action. In case of an agent‚Äôs action, it is often dictated by the policy followed by the agent. For environmental
actions, it encodes the various possibilities that are being accounted for in the model. We tacitly assume
here that possible actions lead always to some successor state, i.e., the axiom that Œ¶(s, a) 6= ‚àÖ whenever
a ‚àà poss(s) holds for any state s and action a, is satisfied by any system.
An example of a system A = (S, A, Œ¶, poss), where S = {b, c, d, f, g, h}, A = { a, a‚Ä≤ , e}, and the
transition function Œ¶ is shown in Figure 1, where s‚Ä≤ ‚àà Œ¶(s, a) iff an arc s ‚Üí s‚Ä≤ labeled with a is present
and poss(s) are all actions that label arcs leaving s. Notice that in this example, Œ¶(s, a) is deterministic,
i.e., Œ¶(s, a) is a singleton if nonempty.
The evolution of the world with respect to a system is characterized by the following definition.
Definition 2 (Trajectory) Given a system A = (S, A, Œ¶, poss), an alternating infinite sequence of states
and actions s0 , a1 , s1 , a2 , . . . , sk , ak+1 , sk+1 , . . . is said to be a trajectory consistent with A, if sk+1 ‚àà
Œ¶(sk , ak+1 ), and ak+1 ‚àà poss(sk ).
2

4

INFSYS RR 1843-04-04
a

c

a

d

a

b
a‚Ä≤

h

a
f

e
g

Figure 1: Transition diagram of system A

A common restriction on how the world evolves is defined using the notion of stability. The following
definition of stability is adapted from [43] and has its origin in control theory and discrete event dynamic
systems [43, 45, 47, 46].
Definition 3 (Stable state 1) Given a system A = (S, A, Œ¶, poss) and a set of states E, a state s is said
to be stable in A w.r.t. E if all trajectories consistent with A and starting from s go through a state in E
in a finite number of transitions and they visit E infinitely often afterwards. A set of states S is stable with
respect to E if all states in S are stable with respect to E.
We say A = (S, A, Œ¶, poss) is a stable system, if all states in S are stable in A with respect to E.

2

Although the above definition of stability is with respect to a set of states E, it can be easily adapted to a
formula œï that can be evaluated at the states of system A. In that case E = {s ‚àà S | A, s |= œï}, i.e., it is
the set of states s at which œï is true.
An alternative approach to characterize the evolution of states is through temporal operators. Some of the
important temporal operators talking about the future are (cf. [36, 21]): Next (), Always (2), Eventually
(3), and Until (U). Their meaning with respect a trajectory œÑ = s0 , a1 , s1 , . . . , sk , ak+1 , sk+1 , . . . is defined
as follows.
Let (œÑ, j), for j ‚â• 0, denote the remainder of œÑ starting at sj ; then
‚Ä¢ (œÑ, j) |= p iff p is true in sj , for any proposition p;
‚Ä¢ (œÑ, j) |= œÜ iff (œÑ, j + 1) |= œÜ;
‚Ä¢ (œÑ, j) |= 2œÜ iff (œÑ, k) |= œÜ, for all k ‚â• j.
‚Ä¢ (œÑ, j) |= 3œÜ iff (œÑ, k) |= œÜ, for some k ‚â• j.
‚Ä¢ (œÑ, j) |= œÜ1 U œÜ2 iff there exists k ‚â• j such that (œÑ, k) |= œÜ2 and for all i, j ‚â§ i < k, (œÑ, i) |= œÜ1 .
The standard Boolean connectives ‚àß, ‚à®, and ¬¨ are defined as usual. An alternative definition of stability can
then be given as follows:
Definition 4 (Stable state 2) Given a system A = (S, A, Œ¶, poss) and an objective formula œï (i.e., without
temporal operators), let EœÜ = {s ‚àà S | œÜ is true in s}. A state s is then said to be stable in A w.r.t. E
if for all trajectories œÑ of the form œÑ = s0 , a1 , s1 , . . . , sk , ak+1 , sk+1 , . . . consistent with A, it holds that
(œÑ, 0) |= 23œï.
2

INFSYS RR 1843-04-04

5

In fact, this definition is equivalent to Definition 3. The advantage of using temporal operators, as in the
above definition, instead of Definition 3 is that the former allows us to specify a larger class of goals and
build on top of the notion of stability. For example, a notion similar to stability, referred to as a response
property [36], is of the form 2(p ‚Üí 3q).

2.1

Stabilizability

The notion of stability is defined with respect to a system and the evolution of the world consistent with the
system. When we focus on an agent and its ability to make a system stable, we need a notion of stabilizability
which intuitively means that there exists a control policy which the agent can use to fashion a stable system.
Given a system A = (S, A, Œ¶, poss), when discussing stabilizability of the system, we need to consider the
following additional aspects:
‚Ä¢ the set of actions Aagent which the agent is capable of executing in principle (where Aagent ‚äÜ A);
‚Ä¢ the set of exogenous actions that may occur in the state s, beyond the agent‚Äôs control, modeled by
a function exo : S ‚Üí 2Aenv , where exo(s) ‚äÜ poss(s) for each state s (recall that Aenv are the
environmental actions). We call any such exo an exogenous function.
Intuitively, given a system A = (S, A, Œ¶, poss), Aagent , exo, and E, a state s is stabilizable with respect to
E, if we are able to find a policy or control function such that the agent picks an action it can do in s, we
have stability if all other agent actions in s and the other states that are reached are disabled, and no state is
reached from s where no further actions are possible.
The last condition is referred to as aliveness. It is formally defined by the following two definitions, the first
of which defines the set R(A, s) of states that can be reached from s in the system A.
Definition 5 Given a system A = (S, A, Œ¶, poss) and a state s, R(A, s) ‚äÜ S is the smallest set of states
that satisfying the following conditions:
1. s ‚àà R(A, s),
2. If s‚Ä≤ ‚àà R(A, s), and a ‚àà poss(s‚Ä≤ ), then Œ¶(s‚Ä≤ , a) ‚äÜ R(A, s).

2

Definition 6 (Aliveness) Given a system A=(S, A, Œ¶, poss) and a state s, we say s is alive if poss(s‚Ä≤ ) 6= ‚àÖ,
for all s‚Ä≤ ‚àà R(A, s). We say A=(S, A, Œ¶, poss) is alive if all states in S are alive.
2
The notion of control function is formally defined as follows.
Definition 7 (Control) Given a system A = (S, A, Œ¶, poss) and a set Aagent ‚äÜ A of agent actions, a
control function for A w.r.t. Aagent is a partial function
K : S ‚Üí Aagent ,
such that K(s) ‚àà poss(s) whenever K(s) is defined.

2

We are now ready to formally define the notion of stabilizability.
Definition 8 (Stabilizability) Given a system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A, a function exo as
above, and a set of states E, we say that s ‚àà S is stabilizable with respect to E, if there exists a control
function K : S ‚Üí Aagent for A w.r.t. Aagent with the following properties:

6

INFSYS RR 1843-04-04

1. s is stable with respect to E in the system AK,exo = (S, A, Œ¶, poss K,exo ), where, for any state s‚Ä≤ ,
poss K,exo (s‚Ä≤ ) = {K(s‚Ä≤ )} ‚à™ exo(s‚Ä≤ ); and
2. s is alive in AK,exo .
A set of states S ‚äÜ S is stabilizable with respect to E, if there is a control function K for A w.r.t. Aagent
such that every state s ‚àà S is stabilizable with respect to E witnessed by K.
2
Having provided this definition, we shall illustrate it on an elaborated example in the next section, where we
describe an intuitive control function for the management of two finite buffers.
Before closing this section, we introduce for later use the notion of a super control.
Definition 9 (Super-control) Given a system A = (S, A, Œ¶, poss) and a set Aagent ‚äÜ A of agent actions,
a partial function K : S ‚Üí 2Aagent such that K(s) ‚äÜ poss(s) and K(s) 6= ‚àÖ whenever K(s) is defined, is
called super-control for A w.r.t. Aagent .
2
Informally, a super-control is an envelope for multiple control functions, which result by refining K to some
arbitrary action in K(s) whenever K(s) is defined; the notion of stabilizability is defined similar as for
control functions, with the only change that in AK,exo , we set poss K,exo (s‚Ä≤ ) = K(s‚Ä≤ ) ‚à™ exo(s‚Ä≤ ) in place of
poss K,exo (s‚Ä≤ ) = {K(s‚Ä≤ )} ‚à™ exo(s‚Ä≤ ).
The following proposition is immediate.
Proposition 1 Given a system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A, and a function exo, a set of states
S ‚äÜ S is stabilizable with respect to a set of states E ‚äÜ S under a control function K for A w.r.t. Aagent iff
S is stabilizable with respect to E under a super-control K + for A w.r.t. Aagent . Furthermore, each such
K is a refinement of some K + with this property (i.e., for each s, K(s) ‚àà K + (s) and K(s) is defined iff
K + (s) is defined), and each refinement K of K + is a control function witnessing stabilizability of S with
respect to E.

3 Example Scenario: Two Finite Buffers
In this section, we introduce a running example which we will use in illustrating the notion of stabilizability
and also other concepts in the rest of the paper.
We imagine a system with two finite buffers, b1 and b2 , where objects are added to b1 in an uncontrollable
way. An agent moves objects from b1 to b2 and processes them there. When an object has been processed,
it is automatically removed from b2 . This is a slight modification of a finite buffer example from [45] and
generalizes problems such as ftp agents maintaining a clean ftp area by moving submitted files to other
directories, or robots moving physical objects from one location to another.
In our framework, we shall describe a system Ab which models this scenario. For simplicity, we assume
that the agent has three control actions M12 that moves an object from b1 to b2 (if such an object exists), the
opposite action, M21 that moves an object from b2 to b1 , and Proc that processes and removes an object in
b2 . There is one exogenous action, Ins, that inserts an object into buffer b1 . The capacities of b1 and b2 are
assumed to be equal.
Let us assume that the control goal of this system is to keep b1 empty. Then, the system is not stabilizable,
since objects can be continually inserted before the agent has a chance to empty the buffer. However, if
no insertions are performed for a certain window of non-interference, the agent can always empty b1 . This
implies that the system is maintainable but not stabilizable. We now make the above argument explicit by
using a concrete instance of Ab .

INFSYS RR 1843-04-04

7

Example 1 (Running Example)
We assume that the maximum capacity of the buffers b1 and b2 is 3. The components of Ab = (Sb , Ab , Œ¶b ,
poss b ) are then as follows.
‚Ä¢ We model every state by the current number of objects in b1 and b2 . That is, a state s is identified by
a pair of integers hi, ji where i denotes the number of objects in b1 and j the number of objects in b2 .
With the maximum capacity of 3, the set of states, Sb , consists of 4 √ó 4 = 16 states and is given by
Sb = {0, 1, 2, 3} √ó {0, 1, 2, 3}.
‚Ä¢ The set of actions is Ab = {M12 , M21 , Proc, Ins}.
‚Ä¢ We assume that the transition function Œ¶b is deterministic, i.e., |Œ¶b (s, a)| ‚â§ 1, defined as follows,
where we write Œ¶b (s, a) = s‚Ä≤ for Œ¶b (s, a) = {s‚Ä≤ }. For every i, j ‚àà {0, . . . , 3}, let
Œ¶b (hi, ji, M12 ) = hi ‚àí 1, j + 1i
Œ¶b (hi, ji, M21 ) = hi + 1, j ‚àí 1i,
Œ¶b (hi, ji, Proc) = hi, j ‚àí 1i,
Œ¶b (hi, ji, Ins) = hi + 1, ji,
where addition and subtraction are modulo 3, and and in all other cases Œ¶b (s, a) = ‚àÖ.
‚Ä¢ The enabling function, poss b , is defined by

M12 ‚àà poss b (hi, ji)

iff i ‚â• 1 and j ‚â§ 2

M21 ‚àà poss b (hi, ji)

iff i ‚â§ 2 and j ‚â• 1

Proc ‚àà poss b (hi, ji)
Ins ‚àà poss b (hi, ji)

iff j ‚â• 1
iff i ‚â§ 2

It is easy to see that for S = {h0, 0i} (no objects in the buffers) and E = {h0, 0i, h0, 1i, h0, 2i, h0, 3i} (that
is, we want to keep b1 empty) S is not stabilizable w.r.t. E, since the exogenous action Ins can always
interfere in the task of bringing the system back to E. For example, consider the control Kb defined as
follows:
Kb (hi, ji) = M12 when i ‚â• 1 and j < 3, and
Kb (hi, ji) = Proc when (i = 0 and j ‚â• 1) or j = 3.
Intuitively, the above control directs the transfer of objects from buffer 1 to 2 whenever possible, and if that
is not possible it directs processing of objects in buffer 2 if that is possible. In Figure 1, which shows the
transition diagram between states, the transitions by the control Kb are marked with M12 and Proc.
Consider the following trajectory consistent with the control system AK,exo = (Sb , Ab , Œ¶b , poss bK ,exo ):
b

œÑ = h0, 0i, Ins, h1, 0i, Ins, h2, 0i, M12 , h1, 1i, Ins, h2, 1i, M12 , h1, 2i, Ins, h2, 2i, M12 , h1, 3i, Proc.

8

INFSYS RR 1843-04-04

h0,0i

Ins

M21
Proc

h0,1i

M12
Ins

M21
Proc

h0,2i

M21
Ins

M21
Proc

h0,3i

M12
Ins

h1,0i

Ins

M21
Proc

h1,1i

M12
Ins

M21
Proc

h1,2i

M12
Ins

M21
Proc

h1,3i

M12
Ins

h2,0i

Ins

M21
Proc

h2,1i

M12
Ins

M21
Proc

h2,2i

M12
Ins

M21
Proc

h2,3i

M12
Ins

h3,0i

Proc

h3,1i

Proc

h3,2i

Proc

h3,3i

Figure 2: The transition diagram of the buffer system Ab for the concrete instance (buffer capacity 3).

It consists of a prefix h0, 0i, Ins, . . . , M12 and a cycle h1, 2i, . . . , Proc. In œÑ , no state in E is ever reached
after the starting state h0, 0i. Similar trajectories can be found for any control and hence S is not stabilizable
with respect to E.
On the other hand, S = {h0, 0i} is stabilizable w.r.t. E ‚Ä≤ = {0, 1, 2} √ó {0, 1, 2, 3} (that is, we want to
have at most two objects in b1 at any time): Following Kb we can go from any of the states in Sb \ E ‚Ä≤ =
{h3, 0i, h3, 1i, h3, 2i, h3, 3i} to E ‚Ä≤ with the execution of at most two control actions, while no exogenous
actions are possible for those states.
2

4 Limited Interference and k-Maintainability
As we mentioned in Section 1, our main intuition behind the notion of maintainability is that maintenance
becomes possible only if there is a window of non-interference from the environment during which maintenance is performed by the agent. In other words, an agent k-maintains a condition c if its control (or its
reaction) is such that if we allow it to make the controlling actions without interference from the environment
for at least k steps, then it gets to a state that satisfies c within those k steps.
Our definition of maintainability has the following parameters:
(i) a set of initial states S that the system may be initially in,
(ii) a set of desired states E that we want to maintain,
(iii) a system A = (S, A, Œ¶, poss),
(iv) a set Aagent ‚äÜ A of agent actions,
(v) a function exo : S ‚Üí 2Aenv detailing exogenous actions, such that exo(s) ‚äÜ poss(s), and
(vi) a control function K (mapping a relevant part of S to Aagent ) such that K(s) ‚àà poss(s).

INFSYS RR 1843-04-04

9

The next step is to formulate when the control K maintains E assuming that the system is initially in one of
the states in S. The exogenous actions are accounted for by defining the notion of a closure of S with respect
to the system AK,exo = (S, A, Œ¶, poss K,exo ), denoted by Closure(S, AK,exo ); where poss K,exo (s) is the
set {K(s)} ‚à™ exo(s). This closure is the set of states that the system may get into starting from S because
of K and/or exo. Maintainability is then defined by requiring the control to be such that if the system is
in any state in the closure and is given a window of non-interference from exogenous actions, then it gets
into a desired state during that window. One of the importance of using the notion of closure is that one can
focus only on a possibly smaller state of states, rather than all the states, thus limiting the possibility of an
exponential blow-up - as warned in [26] - of the number of control rules.
Now a next question might be: Suppose the above condition of maintainability is satisfied, and while the
control is leading the system towards a desired state, an exogenous action happens and takes the system off
that path. What then? The answer is that the state the system will reach after the exogenous action will be a
state from the closure. Thus, if the system is then left alone (without interference from exogenous actions)
it will be again on its way to a desired state. So in our notion of maintainability, the control is always taking
the system towards a desired state, and after any disturbance from an exogenous action, the control again
puts the system back on a path to a desired state.
We now formally define the notions of closure and maintainability.
Definition 10 (Closure) Let A = (S, A, Œ¶, poss) be a system and let S ‚äÜ S be a set of states. Then the
S
closure of A w.r.t. S, denoted by Closure(S, A), is defined by Closure(S, A) = s‚ààS R(A, s).
2
Example 2 In the system A in Figure 1, we have that R(A, d) = {d, h} and R(A, f ) = {f, g, h}, and
therefore Closure({d, f }, A) = {d, f, g, h}.
2
We note some properties of Closure(S, A), which follow immediately from the definition of R(A, s).
Lemma 2 Let A = (S, A, Œ¶, poss) be a system and S ‚äÜ S be a set of states. Then,
1. Closure(S, A) satisfies the Kuratowski closure axioms [32], i.e.,
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢

Closure(‚àÖ, A) = ‚àÖ,
S ‚äÜ Closure(S, A),
Closure(Closure(S, A), A) = Closure(S, A), and
Closure(S1 ‚à™ S2 , A) = Closure(S1 , A) ‚à™ Closure(S2 , A));

2. if s ‚àà Closure(S, A), and a ‚àà poss(s), then Œ¶(s, a) ‚äÜ Closure(S, A).

2

Next we define the notion of unfolding a control.
Definition 11 (Unfold k (s, A, K)) Let A=(S, A, Œ¶, poss) be a system, let s‚ààS, and let K be a control for
A. Then Unfold k (s, A, K) is the set of all sequences œÉ = s0 , s1 , . . . , sl where l‚â§k and s0 =s such that
K(sj ) is defined for all j<l, sj+1 ‚ààŒ¶(sj , K(sj )), and if l<k, then K(sl ) is undefined.
2
Intuitively, an element of Unfold k (s, A, K) is a sequence of states of length at most k+1 that the system may
go through if it follows the control K starting from the state s. The above definition of Unfold k (s, A, K) is
easily extended to the case when K is a super-control, meaning K(s) is a set of actions instead of a single
S
action. In that case, we overload Œ¶ and for any set of actions a‚àó , define Œ¶(s, a‚àó ) = a‚ààa‚àó Œ¶(s, a).
We now define the notion of k-maintainability. This definition can be used to verify the correctness of a
control.

10

INFSYS RR 1843-04-04

Definition 12 (k-Maintainability) Given a system A = (S, A, Œ¶, poss), a set of agents action Aagent ‚äÜ A,
and a specification of exogenous action occurrence exo, we say that a control2 K for A w.r.t. Aagent kmaintains S ‚äÜ S with respect to E ‚äÜ S, where k ‚â• 0, if for each state s ‚àà Closure(S, AK,exo ) and each
sequence œÉ = s0 , s1 , . . . , sl in Unfold k (s, A, K) with s0 = s, it holds that {s0 , . . . , sl } ‚à© E 6= ‚àÖ.
We say that a set of states S ‚äÜ S (resp. A, if S = S) is k-maintainable, k ‚â• 0, with respect to a set of states
E ‚äÜ S, if there exists a control K which k-maintains S w.r.t. E. K is then referred to as the witnessing
control function. Furthermore, S (resp. A) is called maintainable w.r.t E, if S (resp. A) is k-maintainable
w.r.t. E for some k ‚â• 0.
2
We often will omit explicit mention of Aagent , S, and E for control functions and maintainability if they are
clear from the context.
Intuitively, the condition {s0 , s1 , . . . , sl } ‚à© E 6= ‚àÖ above means that we can get from a state s0 outside E to
a state in E within at most k transitions‚Äîwhere each transition is dictated by the control K‚Äîif the world
were to unfold as in s = s0 , s1 , . . . , sl . In particular, 0-maintainability means that the agent has nothing to
do: after any exogenous action happening, the system will be in a state from E. Therefore, a trivial control
K will do which is undefined on every state.
Example 3 Reconsider the system A in Figure 1. Let us assume that Aagent = { a, a‚Ä≤ }, that exo(s)
= { e } iff s = f and that exo(s) = ‚àÖ otherwise. Suppose now that we want a 3-maintainable control
policy for S = {b} w.r.t. E = {h}. Clearly, such a control policy K is to take a in b, c, and d. Indeed,
Closure({b}, AK,exo ) = {b, c, d, h} and Unfold 3 (b, A, K) = {hb, c, d, hi}, Unfold 3 (c, A, K) = {hc, d, hi},
and Unfold 3 (d, A, K) = {hd, hi}; furthermore, each sequence contains h.
Suppose now that Œ¶(c, a)={d, f } instead of {d} (i.e., nondeterminism in c). Then, no k-maintainable
control policy for S = {b} w.r.t. E = {h} exists for any k ‚â• 0. Indeed, the agent can always end up in the
dead-end g. If, however, in addition Œ¶(g, a‚Ä≤ ) = {f, h} and a‚Ä≤ ‚àà poss(g), a 3-maintainable control policy K
is K(s) = a for s ‚àà {b, c, d, f } and K(g)= a‚Ä≤ .
2
Example 4 Buffer Example (cont‚Äôd)
Earlier we showed that in Ab , S = {h0, 0i} is not stabilizable w.r.t. E = {h0, 0i, h0, 1i, h0, 2i, h0, 3i}.
Thus, we might ask whether S is at least maintainable w.r.t. E? The answer is positive: For the worst case
system state, h3, 3i, a control can move the system to h3, 0i (by three transitions executing Proc) without
interfering occurrences of exogenous actions. If there then are three further transitions without interference,
the control can apply M12 three times and effect the state h0, 3i. This implies that S is 6-maintainable w.r.t.
E. We can, with a similar argument show that A is 9-maintainable w.r.t. {h0, 0i}. A similar argument can
be made with respect to the control Kb of Example 1.
However, we have that A is not maintainable w.r.t., for example, {h0, 3i} (Since we cannot go from, for
example, {h0, 0i}, to {h0, 3i} with control actions only).
2
As the above example points out, it is possible that S is maintainable but not stabilizable with respect to E.
The converse is also possible. In other words, in certain cases we may have a system where a given S is
stabilizable with respect to a set E, but yet is not maintainable. This happens when every path between a
state in S and a state in E involves at least one exogenous action. In that case the agent, who does not have
control over the exogenous actions, can not on its own make the transition from a state in S to a state in E.
However, often for each exogenous action there are equivalent (in terms of effects) agent actions. In that
case, any stabilizable system is also maintainable.
2

Note that here only K(s) for s ‚àà Closure(S, AK,exo ) is of relevance. For all other s, K(s) can be arbitrary or undefined.

INFSYS RR 1843-04-04

11

We note the following monotonicity property of k-maintainability, which is an easy consequence of the
definition:
Proposition 3 Suppose that for a system A = (S, A, Œ¶, poss), a set of agents action Aagent ‚äÜ A, and
a specification of exogenous action occurrence exo, the control function K k-maintains S ‚äÜ S w.r.t.
E ‚äÜ S. Then, K also k-maintains any set S ‚Ä≤ ‚äÜ Closure(S, AK,exo ) with respect to any set E ‚Ä≤ ‚äÜ
Closure(S, AK,exo ) such that E ‚äÜ E ‚Ä≤ .
2

4.1

An alternative characterization of k-maintainability

The characterization of stability and stabilizability in Section 2 is based on imposing conditions on trajectories obtained from the transition graph of a system. Such a characterization has the advantage that it is
amenable to developing temporal operators that can express more general conditions.
In contrast, the definition of maintainability in Definition 12 is not based on trajectories. Nonetheless, one
can give an alternative characterization based on trajectories, which we do next. To bridge from finite trajectories (which are relevant with respect to maintainability), to infinite ones as in Definition 2, we consider for
each system A = (S, A, Œ¶, poss) an extension, A‚àû , which results by adding a fresh environmental action
anop such that in A‚àû , for each state s we have Œ¶(s, anop ) = {s} and anop ‚àà poss(s) if poss(s) = ‚àÖ in A.
Informally, A‚àû adds infinite loops to halting states of A.
Proposition 4 Given a system A = (S, A, Œ¶, poss), a set of agents action Aagent ‚äÜ A, a specification of
exogenous action occurrence exo, and a set of states E, a set of states S is k-maintainable with respect to
E, k ‚â• 0, if and only if there exists a control K for A w.r.t. Aagent such that for each state s in S and every
‚àû
trajectory of form œÑ = s0 , a1 , s1 , a2 , . . . , aj , sj , aj+1 , . . . consistent with AK,exo
and s0 = s, it holds that
{ai+1 , . . . , ai+k } ‚äÜ Aagent or ai+k = anop for some i ‚â• 0 implies that {si , . . . , si+k } ‚à© E 6= ‚àÖ.
2
Proof. For the only if direction, suppose that S is k-maintainable w.r.t. E, witnessed by the control function
‚àû
K. Let s ‚àà S and œÑ = s0 , a1 , s1 , a2 , . . . , aj , sj , aj+1 , . . . be consistent with AK,exo
such that s0 = s and
‚àû ). If
{ai+1 , . . . , ai+k } ‚äÜ Aagent or ai+k = anop , for some i ‚â• 0. Then, we have si ‚àà Closure(S, AK,exo
k = 0, then since K is a witnessing control, we have si ‚àà E, and thus {si , si+1 , . . . , si+k } ‚à© E 6= ‚àÖ holds.
Consider thus k > 0. If ai+k ‚àà Aagent (which implies {ai+1 , . . . , ai+k } ‚äÜ Aagent ), then the sequence
si , si+1 , . . . , si+k belongs to Unfold k (si , A, K). Since K is a witnessing control function, we again have
{si , si+1 , . . . , si+k } ‚à© E 6= ‚àÖ. Otherwise, if ai+k = anop , let l ‚â• 1 be the least index such that al = anop .
‚àû , we have that K(s
By definition of AK,exo
l‚àí1 ) is undefined. Hence, the sequence œÉ = sl‚àí1 belongs to
Unfold k (sl‚àí1 , A, K). Since K is a control, it follows that sl‚àí1 ‚àà E. Since sj = sl‚àí1 for each j ‚â• l, and in
particular si+k = sl‚àí1 , it follows again that {si , si+1 , . . . , si+k } ‚à© E 6= ‚àÖ. This proves the only if direction.
Conversely, suppose K is a control for A w.r.t. Aagent such that for each s ‚àà S and trajectory œÑ =
‚àû
and s0 = s, it holds that {ai+1 , . . . , ai+k } ‚äÜ
s0 , a1 , s1 , a2 , . . . , aj , sj , aj+1 , . . . consistent with AK,exo
Aagent or ai+k = anop for some i ‚â• 0 implies that {si , si+1 , . . . , si+k } ‚à© E 6= ‚àÖ. We claim that K witnesses k-maintainability of S w.r.t. E. Towards a contradiction, suppose the contrary. Hence, it follows from
‚àû , that there is some state s ‚àà S and trajectory œÑ = s , a , s , a , . . . , a , s , a
the definition of AK,exo
0 1 1 2
j j j+1 , . . .
‚àû ) and
‚àû
consistent with AK,exo and s0 = s, such that for some j ‚â• 0 we have sj ‚àà Closure(S, AK,exo
sj , sj+1 , . . . , sj+l is in Unfold k (sj , A, K), where l ‚â§ k, but E ‚à© {sj , . . . , sj+l } = ‚àÖ.
By definition of Unfold k (sj , A, K), we have that {aj+1 , . . . , aj+l‚àí1 } ‚äÜ Aagent and that aj+l = aj+l+1
= ¬∑ ¬∑ ¬∑ = aj+k = anop . By hypothesis, E ‚à© {sj , . . . , sj+k } =
6 ‚àÖ holds. Thus, we conclude that E ‚à©
{sj+l+1 , . . . , sj+k } =
6 ‚àÖ must hold, and hence l < k. However, by definition of Œ¶(s, anop ) we have sj+l =

12

INFSYS RR 1843-04-04

sj+l+1 = ¬∑ ¬∑ ¬∑ = sj+k . This implies that E ‚à© {sj , . . . , sj+l } =
6 ‚àÖ, which is a contradiction. This proves that K
witnesses k-maintainability of S w.r.t. E.
2
While this result shows that we could equally well have developed our notion of k-maintainability on the
basis of trajectories, in the rest of this paper we shall stick to the setting which uses closure and unfolding.
We find the latter more intuitive, as well as more convenient for designing algorithms and for proofs. Furthermore, this setting requires no special handling of possible finite trajectories, which complicates matters
as becomes apparent from Proposition 4.

5 Polynomial Time Methods to Construct k-Maintainable Controls
Now that we have defined the notion of k-maintainability, our next step is to show how some k-maintainable
control can be constructed in an automated way. We start with some historical background. There has been
extensive use of situation control rules [17] and reactive control in the literature. But there have been far
fewer efforts [30] to define correctness of such control rules3 , and to automatically construct correct control
rules. In [31], it is suggested that in a control rule of the form: ‚Äúif condition c is satisfied then do action
a‚Äù, the action a is the action that leads to the goal from any state where the condition c is satisfied. In [5] a
formal meaning of ‚Äúleads to‚Äù is given as: for all states s that satisfy c, a is the first action of a minimal cost
plan from s to the goal. Using this definition, an algorithm is presented in [39] to construct k-maintainable
controls. This algorithm is sound but not complete, in the sense that it generates correct controls only, but
there is no guarantee that it will find always a control if one exists. The difficulty in developing a complete
algorithm ‚Äì also recognized in [29] in a slightly different context ‚Äì can be explained as follows. Suppose
one were to do forward search from a state in S. Now suppose there are multiple actions from this state that
‚Äòlead‚Äô to E. Deciding on which of the actions or which subsets one needs to chose is a nondeterministic
choice necessitating backtracking if one were to discover that a particular choice leads to a state (due to
exogenous actions) from where E can not be reached. Same happens in backward search too. In this paper
we overcome the problems one faces in following the straightforward approaches and give a sound and
complete algorithm for constructing k-maintainable control policies.
We provide it in two sets: First we consider the case when the transition function Œ¶ is deterministic, and then
we generalize to the case where Œ¶ may be non-deterministic. In each case, we present different methods,
which illustrates our discovery process and also gives a better grasp of the final algorithm. We first present
an encoding of our problem as a propositional theory and appeal to propositional SAT solvers to construct
the control. As it turns out, this encoding is in a tractable fragment of SAT, for which specialized solvers (in
particular, Horn SAT solvers) can be used easily. Finally, we present a direct algorithm distilled from the
previous methods.
The reasoning behind this line of presentation is the following:
(i) It illustrates the methodology of using SAT and Horn SAT encodings to solve problems;
(ii) the encodings allow us to quickly implement and test algorithms;
(iii) the proof of correctness mimics the encodings; and
(iv) we can exploit known complexity results for Horn SAT to determine the complexity of our algorithm,
and in particularly to establish tractability.
3
Here we exclude the works related to MDPs as it is not known how to express the kind of goal we are interested in ‚Äì such as k
maintenance goals ‚Äì using reward functions.

INFSYS RR 1843-04-04

13

As for (ii), we can make use of Answer Set Solvers such as DLV [20, 33] or Smodels [40, 50] which extend
Horn logic programs by nonmonotonic negation. These solvers allow efficient computation of the least
model and some maximal models of a Horn theory, and can be exploited to construct robust or ‚Äúsmall‚Äù
controls, respectively.
The problem we want to solve, which we refer to as k-M AINTAIN, has the following input and output:
Input: An input I is a system A = (S, A, Œ¶, poss), sets of states E ‚äÜ S and S ‚äÜ S, a set Aagent ‚äÜ A, a
function exo, and an integer k ‚â• 0.
Output: A control K such that S is k-maintainable with respect to E (using the control K), if such a control
exists. Otherwise the output is the answer that no such control exists.
We assume here that the functions poss(s) and exo(s) can be efficiently evaluated; e.g., when both functions
are given by their graphs (i.e., in a table).

5.1

Deterministic transition function Œ¶(s, a)

We start with the case of deterministic transitions, i.e., Œ¶(s, a) is a singleton set {s‚Ä≤ } whenever nonempty.
In abuse of notation, we simply will write Œ¶(s, a) = s‚Ä≤ in this case.
Our first algorithm to solve k-M AINTAIN will be based on a reduction to propositional SAT solving. Given
an input I for k-M AINTAIN, we construct a SAT instance sat(I) in polynomial time such that sat(I) is
satisfiable if and only if the input I allows for a k-maintainable control, and that the satisfying assignments
for sat(I) encode possible such controls.
In our encoding, we shall use for each state s ‚àà S propositional variables s0 , s1 , . . . , sk . Intuitively, si will
denote that there is a path from state s to some state in E using only agent actions and at most i of them, to
which we refer as ‚Äúthere is an a-path from s to E of length at most i.‚Äù
The encoding sat(I) contains the following formulas:
(0) For all s ‚àà S, and for all j, 0 ‚â§ j < k:
sj ‚áí sj+1
(1) For all s ‚àà E ‚à© S:
s0
(2) For any two states s, s‚Ä≤ ‚àà S such that Œ¶(a, s) = s‚Ä≤ for some action a ‚àà exo(s):
sk ‚áí s‚Ä≤k
(3) For any state s ‚àà S \ E and all i, 1 ‚â§ i ‚â§ k:
si ‚áí
P S(s) =

‚Ä≤
s‚Ä≤ ‚ààP S(s) si‚àí1 ,
{s‚Ä≤ ‚àà S | ‚àÉa ‚àà

W

(4) For all s ‚àà S \ E:
sk
(5) For all s ‚àà S \ E:
¬¨s0

where
Aagent ‚à© poss(s) : s‚Ä≤ = Œ¶(a, s)};

14

INFSYS RR 1843-04-04

The intuition behind the above encoding is as follows. The clauses in (0) state that if there is an a-path from
s to E of length at most j then, logically, there is also an a-path of length at most j+1. Next, the clauses in
(1) say that for states s in S ‚à© E, there is an a-path of length 0 from s to E. Next, (4) states that for any
starting state s in S outside E, there is an a-path from s to E of length at most k, and (5) states that for any
state s outside E, there is no a-path from s to E of length 0. The clauses in (3) state that if, for any state s,
there is an a-path from s to E of length at most i, then for some possible agent action a and successor state
s‚Ä≤ = Œ¶(a, s), there is an a-path from s‚Ä≤ to E of length at most i-1. When looking for k-maintainable controls
the clauses in (2) take into account the possibility that s may be in the closure. If indeed s is in the closure
and there is an a-path from s to E of length at most k, then the same must be true with respect to the states
s‚Ä≤ reachable from s using exogenous actions. When looking for super-control they play a role in computing
maximal super-controls. The role of each of the above clauses become more clear when relating the models
of sat(I) with controls that k-maintain.
Given any model M of sat(I), we can extract a desired control K from it by defining K(s) = a for all s
outside E with sk true in M , where a is a possible agent action in s such that s‚Ä≤ = Œ¶(s, a) and s‚Ä≤ is closer
to E than s is. In case of multiple possible a and s‚Ä≤ , one a can be arbitrarily picked. Otherwise, K(s) is left
undefined.
In particular, for k = 0, only the clauses from (1), (2), (4) and (5) do exist. As easily seen, sat(I) is
satisfiable in this case if and only if S ‚äÜ E and no exogenous action leads outside E, i.e., the closure of S
under exogenous actions is contained in E. This means that no actions of the agent are required at any point
in time, and we thus obtain the trivial 0-control K which is undefined on all states, as desired.
The next result states that the SAT encoding works properly in general.
Proposition 5 Let I consist of a system A = (S, A, Œ¶, poss) where Œ¶ is deterministic, a set Aagent ‚äÜ A,
sets of states E ‚äÜ S and S ‚äÜ S, an exogenous function exo, and an integer k. For any model M of sat(I),
let CM = {s ‚àà S | M |= sk }, and for any state s ‚àà CM let ‚ÑìM (s) denote the smallest index j such that
M |= sj (i.e., s0 , s1 ,. . . , sj ‚àó ‚àí1 are f alse and sj ‚àó is true), which we call the level of s w.r.t. M . Then,
(i) S is k-maintainable w.r.t. E iff sat(I) is satisfiable.
+
(ii) Given any model M of sat(I), the partial function KM
: S ‚Üí 2Aagent defined on CM \ E such that
+
KM
(s) = {a ‚àà Aagent ‚à© poss(s) | Œ¶(s, a) = s‚Ä≤ ,

s‚Ä≤ ‚àà CM , ‚ÑìM (s‚Ä≤ ) < ‚ÑìM (s)},
is a valid super-control for A w.r.t. Aagent ;
+
(iii) any control K which refines KM
for some model M of sat(I) k-maintains S w.r.t. E.

2

Proof. Since the if direction of (i) follows from (ii) and (iii), it is sufficient to show the only if direction of
(i), and then (ii) and (iii).
As for the only if direction of (i), suppose S is k-maintainable w.r.t. E. Then there exists a control K such
that for each state s ‚àà Closure(S, AK,exo ), and for each sequence œÉ = s(0) , s(1) , . . . , s(l) where s(0) = s in
Unfold k (s, A, K), {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ. We now construct an interpretation M for sat(I) as follows.
Since Œ¶ is deterministic, for each s in Closure(S, AK,exo ) there is a unique sequence s(0) (=s), s(1) , . . ., s(l)
in Unfold k (s, A, K). Let i (‚â• 0) be the smallest index such that s(i) ‚àà E. We assign f alse to s0 , s1 ,. . . ,
si‚àí1 and assign true to si , si+1 ,. . . , sk . All other propositions are assigned f alse. We now argue that M is
a model of sat(I).

INFSYS RR 1843-04-04

15

It is straightforward to see that M satisfies the formulas generated by (0), (1), (4) and (5). Now consider the
formulas generated in (2). If sk is true, then s ‚àà Closure(S, AK,exo ) by construction. In this case, in order to
k-maintain S w.r.t. E, for any s‚Ä≤ = Œ¶(a, s) of an exogenous action a, one of the states in Unfold k (s‚Ä≤ , A, K)
must be in E. Hence, s‚Ä≤k has been assigned true in M . Now let us consider the formulas generated in (3).
If si is true for some i ‚â§ k, then there must be an a-path from s to E of length at most i, emerging from
possible agent actions only (via control K). Let s‚Ä≤ be the next state in this path. Obviously, there must be an
a-path from s‚Ä≤ to E of length at most i‚àí1 (via K). Hence, s‚Ä≤i‚àí1 must be true in M . Thus, M is a model of
sat(I), which means that sat(I) is satisfiable.
+
To show (ii), let us assume that sat(I) has a model M and consider the partial function KM
: S ‚Üí 2Aagent
+
which is defined on CM \ E by KM (s) = {a ‚àà Aagent ‚à© poss(s) | Œ¶(s, a) = s‚Ä≤ , s‚Ä≤ ‚àà CM and ‚ÑìM (s‚Ä≤ ) <
+
+
‚ÑìM (s)}; and for any other s, KM
(s) is undefined. For KM
to be a valid super-control it must satisfy the
+
+
+
following conditions: (a) KM (s) ‚äÜ poss(s), and (b) KM (s) 6= ‚àÖ whenever KM
(s) is defined. Condition
+
+
(a) is true by virtue of the construction of KM . Condition (b) is true because KM
(s) is defined when
s ‚àà CM \ E which means M |= sk for some k > 0, which in turn means that ‚ÑìM (s) > 0, thus making
+
KM
(s) 6= ‚àÖ.
+
Now to show (iii), let K be any control which refines KM
for some model M of sat(I). Let the distance
dK (s, S) of a state s from the set of states S be the minimum number of transitions ‚Äì through exogenous
actions and/or control actions dictated by the control K ‚Äì needed to reach s from any state in S.
We will show, by using induction on d(s, S) ‚â• 0, that for every state s ‚àà Closure(S, AK,exo ) and every
sequence œÉ = s(0) , s(1) , . . . , s(l) with s = s(0) in Unfold k (s, A, K), the set {s(0) , . . . , s(l) } intersects with
E and that M |= sk (i.e., s ‚àà CM ). This proves the claim.
The base case, d(s, S) = 0, is about states s ‚àà S. From the formulas in (0), (1), and (4) we have M |= sk
+
for every such state s. Then from the construction of KM
above and the formulas in (3), it follows that
(0)
(1)
for any such state s and for every sequence œÉ = s , s , . . . , s(l) with s = s(0) in Unfold k (s, A, K), the
+ (i)
set {s(0) , . . . , s(l) } intersects with E. Indeed, by taking the action K(s(i) ) (‚àà KM
(s )) in s(i) , a state
(i+1)
(i+1)
(i+1)
(i)
s
= Œ¶(s, K(s
)) is reached, such that ‚ÑìM (s
) < ‚ÑìM (s ). If l = k, then clearly ‚ÑìM (s(l) ) = 0;
(l)
otherwise, if l < k, then K(s ) must be undefined, which again implies ‚ÑìM (s(l) ) = 0. Thus, s(l) ‚àà E,
which means that {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ.
Thus the statement holds in the base case. Now for the induction step, let us assume that it holds for every
state s ‚àà Closure(S, AK,exo ) at distance d ‚â• 0 from S. Let us now consider a state s ‚àà Closure(S, AK,exo )
at distance d+1 from S. Then there is a state s‚Ä≤ at distance d from S such that s = Œ¶(a, s‚Ä≤ ) and either (i)
a ‚àà exo(s‚Ä≤ ) or (ii) a = K(s‚Ä≤ ). In both cases, we have by the induction hypothesis that M |= s‚Ä≤k , and
using (2), (3), and (1) we can conclude M |= sk ; Furthermore, by construction of K and the formulas in
(3), we have by similar arguments as above that for each sequence œÉ = s(0) , s(1) , . . . , s(l) with s = s(0) in
Unfold k (s, A, K), {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ.
+
This proves our claim. Now each control K as in (ii) is a refinement of KM
. This completes the proof. 2
5.1.1 Horn SAT encoding
While sat(I) is constructible in polynomial time from I, we can not automatically infer that solving kM AINTAIN is polynomial, since SAT is a canonical NP-hard problem. However, a closer look at the structure
of the clauses in sat(I) reveals that this instance is solvable in polynomial time. Indeed, it is a reverse Horn
theory; i.e., by reversing the propositions, we obtain a Horn theory. Let us use propositions si whose intuitive
meaning is converse of the meaning of si . Then the Horn theory corresponding to sat(I), denoted sat(I),
is as follows:

16

INFSYS RR 1843-04-04

(0) For all s‚ààS and j, 0‚â§j<k:
sj+1 ‚áí sj .
(1) For all s ‚àà E ‚à© S:
s0 ‚áí ‚ä•.
(2) For any states s, s‚Ä≤ ‚àà S such that s‚Ä≤ =Œ¶(a, s) for some action a‚ààexo(s):
s‚Ä≤k ‚áí sk .
(3) For any state in S \ E, and for all i, 1 ‚â§ i ‚â§ k:
V

‚Ä≤
s‚Ä≤ ‚ààP S(s) si‚àí1



‚áí si ,

where

P S(s)={s‚Ä≤ ‚ààS | ‚àÉa‚ààAagent ‚à©poss(s): s‚Ä≤ =Œ¶(a, s)}.
(4) For all s ‚àà S \ E:
sk ‚áí ‚ä•.
(5) For all s ‚àà S \ E:
s0 .
Here, ‚ä• denotes falsity. We then obtain a result similar to Proposition 5, and the models M of sat(I) lead
to k-maintainable controls, which we can construct similarly; just replace in part (ii) CM with C M = {s ‚àà
S | M 6|= sk }. Notice that C M coincides with the set of states CM for the model M of sat(I) such that
M |= p iff M 6|= p, for each atom p.
We now illustrate the above Horn encoding with respect to an example.
Example 5 Consider the system A = (S, A, Œ¶, poss), where S = {b, c, d, f, g, h}, A = { a, a‚Ä≤ , e}, and the
(deterministic) transition function Œ¶ was shown in Figure 1, where Œ¶(s, a) = s‚Ä≤ iff an arc s ‚Üí s‚Ä≤ labeled
with a is present and poss(s) are all actions that label arcs leaving s.
For A = { a, a‚Ä≤ } and exo(s) = { e } iff s = f and exo(s) = ‚àÖ otherwise, this leads for S = {b}, E = {h},
and k = 3 to the following Horn encoding sat(I):
(From 0)
b1 ‚áí b 0 .
d1 ‚áí d0 .
g1 ‚áí g0 .
(From 1)
(From 2)
g3 ‚áí f3 .
(From 3)

b2 ‚áí b 1 .
d2 ‚áí d1 .
g2 ‚áí g1 .

b3 ‚áí b 2 .
d3 ‚áí d2 .
g3 ‚áí g2 .

c1 ‚áí c0 .
f1 ‚áí f0 .
h1 ‚áí h0 .

c2 ‚áí c1 .
f2 ‚áí f1 .
h2 ‚áí h1 .

c3 ‚áí c2 .
f3 ‚áí f2 .
h3 ‚áí h2 .

INFSYS RR 1843-04-04

c0 ‚àß f0 ‚áí b1 .
d 0 ‚áí c1 .
h0 ‚áí d1 .
h0 ‚áí f1 .
g1 .

17

c1 ‚àß f1 ‚áí b2 .
d 1 ‚áí c2 .
h1 ‚áí d2 .
h1 ‚áí f2 .
g2 .

c2 ‚àß f2 ‚áí b3 .
d 2 ‚áí c3 .
h2 ‚áí d3 .
h2 ‚áí f3 .
g3 .

(From 4)
b3 ‚áí ‚ä•.
(From 5)
b0 .

c0 .

d0 .

f0 .

g0 .

This theory has the least model
M = {g3 , g2 , g1 , g0 , f3 , f2 , f1 , f0 , b2 , b1 , b0 , c1 , c0 , d0 };
hence, C M = {b, c, d, h}, which gives rise to the super-control K + such that K + (s) = {a} for s ‚àà {b, c, d}
and K + (s) is undefined for s ‚àà {f, g, h}. In this case, there is a single control K refining K + , which has
K(s) = a for s ‚àà {b, c, d} and is undefined otherwise. This is intuitive: The agent must reach h, and has
to avoid taking a‚Ä≤ in b since then it might arrive at the no-good state g. Thus, she has to take a in b and, as
the only choice, in the subsequent states c and d. Also, we might not add any state apart from b, c, and d
without losing 3-maintainability. In this particular case, M is also maximal on the propositions s3 , where
s ‚àà S \ E = {b, c, d, f, g}: By (4), we can not add b3 , and by (0) and the clauses c2 ‚àß f2 ‚áí b3 and d1 ‚áí c2
in (3) then also neither c3 nor d3 . Thus, the above control K is also smallest and, in fact, the only one
possible for 3-maintainability.
2
As computing a model of a Horn theory is a well-known polynomial problem [16], we thus obtain the
following result.
Theorem 6 Under deterministic state transitions, problem k-M AINTAIN is solvable in polynomial time. 2
An interesting aspect of the above is that, as well-known, each satisfiable Horn theory T has the least model,
MT , which is given by the intersection of all its models. Moreover, the least model is computable in linear
time, cf. [16, 37]. This model not only leads to a k-maintainable control, but also leads to a maximal control,
in the sense that the control is defined on a greatest set of states outside E among all possible k-maintainable
controls for S ‚Ä≤ w.r.t. E such that S ‚äÜ S ‚Ä≤ . This gives a clear picture of which other states may be added to
S while k-maintainability is preserved; namely, any states in C MT . Furthermore, any control K computed
from MT applying the method in Proposition 5 (using C MT ) works for such an extension of S as well.
On the other hand, intuitively a k-maintainable control constructed from some maximal model of sat(I) with
respect to the propositions sk is undefined to a largest extent, and works merely for a smallest extension.
We may generate, starting from MT , such a maximal model of T by trying to flip first, step by step all
propositions sk which are f alse to true, as well as other propositions entailed. In this way, we can generate
a maximal model of T on {sk | s ‚àà S \ E} in polynomial time, from which a ‚Äúlean‚Äù control can also be
computed in polynomial time.

18

5.2

INFSYS RR 1843-04-04

Non-deterministic transition function Œ¶(s, a)

We now generalize our method for constructing k-maintainable controls to the case in which transitions due
to Œ¶ may be non-deterministic. As before, we first present a general propositional SAT encoding, and then
rewrite to a propositional Horn SAT encoding. To explain some of the notations, we need the following
definition, which generalizes the notion of an a-path to the non-deterministic setting.
Definition 13 (a-path) We say that there exists an a-path of length at most k ‚â• 0 from a state s to a set of
states S ‚Ä≤ , if either s ‚àà S ‚Ä≤ , or s ‚àà
/ S ‚Ä≤ , k > 0 and there is some action a ‚àà Aagent ‚à© poss(s) such that for
every s‚Ä≤ ‚àà Œ¶(s, a) there exists an a-path of length at most k ‚àí 1 from s‚Ä≤ to S ‚Ä≤ .
2
In the following encoding of an instance I of problem k-M AINTAIN to SAT, referred to as sat‚Ä≤ (I), si will
again intuitively denote that there is an a-path from s to E of length at most i. The proposition s ai , i > 0,
will denote that for such s there is an a-path from s to E of length at most i starting with action a (‚àà poss(s)).
The encoding sat‚Ä≤ (I) has again groups (0)‚Äì(5) of clauses as follows:
(0), (1), (4) and (5) are the same as in sat(I).
(2) For any state s ‚àà S and s‚Ä≤ such that s‚Ä≤ ‚àà Œ¶(a, s) for some action a ‚àà exo(s):
sk ‚áí s‚Ä≤k
(3) For every state s ‚àà S \ E and for all i, 1 ‚â§ i ‚â§ k:
(3.1) si ‚áí a‚ààAagent ‚à©poss(s) s ai ;
(3.2) for every a ‚àà Aagent ‚à©poss(s) and s‚Ä≤ ‚ààŒ¶(s, a):
W

s ai ‚áí s‚Ä≤i‚àí1 ;
(3.3) for every a ‚àà Aagent ‚à© poss(s), if i < k:
s ai ‚áí s ai+1 .
Group (2) above is very similar to group (2) of sat(I) in the previous subsection. The only change is that
we now have s‚Ä≤ ‚àà Œ¶(a, s) instead of s‚Ä≤ = Œ¶(a, s). The main difference is in group (3). We now explain
those clauses. The clauses in (3.1) and (3.2) together state that if there is an a-path from s to E of length at
most i, then there is some possible action a for the agent, such that for each state s‚Ä≤ that potentially results
by taking a in s, there must be an a-path from s‚Ä≤ to E of length at most i-1. The clauses s ai ‚áí s ai+1
in (3.3) say that on a longer a-path from s the agent must be able to pick a also. Notice that there are no
formulas in sat‚Ä≤ (I) which forbid to pick different actions a and a‚Ä≤ in the same state s, and thus we have a
super-control; however, we can always refine it easily to a control.
Proposition 7 Let I consist of a system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A, sets of states E, S ‚äÜ S,
an exogenous function exo, and an integer k. For any model M of sat‚Ä≤ (I), let CM = {s ‚àà S | M |= sk },
and for any state s ‚àà CM \ E let ‚ÑìM (s) denote the smallest index j such that M |= s aj for some action
a ‚àà Aagent ‚à© poss(s), which we call the a-level of s w.r.t. M . Then,
(i) S is k-maintainable w.r.t. E iff sat‚Ä≤ (I) is satisfiable;
+
(ii) given any model M of sat‚Ä≤ (I), the partial function KM
: S ‚Üí 2Aagent which is defined on CM \ E by
+
KM
(s) = {a | M |= s a‚ÑìM (s) }

is a valid super-control; and

INFSYS RR 1843-04-04

19

+
(iii) any control K which refines KM
for some model M of sat‚Ä≤ (I) k-maintains S w.r.t. E.

Proof. The proof follows the line of argumentation in the proof of Proposition 5. It is sufficient to show the
only if direction of (i) and both (ii) and (iii).
As for the only if direction of (i), suppose S is k-maintainable w.r.t. E. Then there exists a control
K such that for each state s ‚àà Closure(S, AK,exo ), and for each sequence œÉ = s(0) , s(1) , . . . , s(l) in
Unfold k (s, A, K) where s(0) = s, {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ. We now construct an interpretation M for
sat‚Ä≤ (I) as follows.
For each s ‚àà Closure(S, AK,exo ), let in each sequence œÉ = s(0) , s(1) , . . ., s(l) in Unfold k (s, A, K) with
s = s(0) , the number iœÉ (‚â• 0) be the smallest index i such that s(i) ‚àà E, and let i‚àó be the maximum over all
iœÉ for s. Intuitively, i‚àó is the length of the longest path in the tree with root s where each node n not in E is
sprouted by taking the control action K(n) and adding each state in Œ¶(n, K(n)) as a child. Then, we assign
true to si‚àó , si‚àó +1 ,. . . , sk and, if i‚àó > 0, to s ai‚àó , s ai‚àó +1 , . . . .s ak , where K(s) = a. All other propositions
are assigned f alse in M . We now argue that M is a model of sat(I).
It is straightforward to see that M satisfies the formulas generated by (0), (1), (4) and (5). Now consider the
formulas sk ‚áí s‚Ä≤k generated in (2). If sk is true, then s ‚àà Closure(S, AK,exo ) by construction. In this case,
for any s‚Ä≤ ‚àà Œ¶(a, s) of an exogenous action a, we have s‚Ä≤ ‚àà Closure(S, AK,exo ), and since K k-maintains
S w.r.t. E, s‚Ä≤i is true in M for some i ‚â§ k which implies, by construction, that s‚Ä≤k is assigned true in M .
Let us finally consider the formulas generated in (3). If si , where s ‚àà S \ E, is assigned true in M for some
i ‚àà {1 ‚â§ i ‚â§ k}, then s ‚àà Closure(S, A, Kexo ) holds by construction of M . Since K is a k-maintaining
control and s ‚àà
/ E, we must have K(s) defined and thus, by construction of M , we have s K(s)i assigned
true in M . Since K(s) ‚àà Aagent ‚à© poss(s), the clause (3.1) is thus satisfied. Furthermore, each clause in
(3.2) is satisfied when a 6= K(s), since then sai is assigned f alse in M . For a = K(s), proposition sai
is true in M and thus, by construction, also si . Since K is k-maintaining control, every state s‚Ä≤ ‚àà Œ¶(s, a)
belongs to Closure(S, A, Kexo ). Let, for each sequence œÉ ‚Ä≤ = s(0) , s(1) , . . ., s(l) in Unfold k (s, A, K) such
that s(0) = s‚Ä≤ , the sequence P (œÉ) = s(0) , s(1) , . . . , s(i) be the shortest prefix of œÉ such that s(i) ‚àà E (notice
that i < k). Then, the sequence s, P (œÉ) is a prefix of some sequence in Unfold (s, A, K). Hence, it follows
that in the construction of M , the number i‚àó for s is larger than the one for s‚Ä≤ . Thus, by construction of M ,
it follows that s‚Ä≤i‚àí1 is assigned true in M . This means that the formulas in (3.2) are satisfied in M . Finally,
the clauses (3.3) are clearly satisfied in M by construction of M . Thus, M is a model of sat‚Ä≤ (I), which
means that sat‚Ä≤ (I) is satisfiable.
+
To show (ii), let us assume that sat‚Ä≤ (I) has a model M , and consider the partial function KM
: S ‚Üí 2Aagent
+
+
(s) ‚äÜ
which is defined on CM \ E by KM (s) = {a | M |= s a‚ÑìM (s) }. We thus have to show that KM
+
+
+
poss(s) and KM (s) 6= ‚àÖ when KM (s) is defined. By clause (3.1), and the definition of CM , ‚ÑìM , and KM
this is immediate.
+
To show (iii), let K be any control which refines KM
for some model M of sat‚Ä≤ (I). Let the distance
dK (s, S) of a state s from the set of states S be as in the proof of Proposition 5. i.e., the minimum number
of transitions ‚Äì through exogenous actions and/or control actions dictated by the control K ‚Äì needed to reach
s from any state in S.
We will show, by using induction on d(s, S) ‚â• 0, that for every state s ‚àà Closure(S, AK,exo ) and every
sequence œÉ = s(0) , s(1) , . . . , s(l) with s = s(0) in Unfold k (s, A, K), the set {s(0) , . . . , s(l) } intersects with
E and that M |= sk (i.e., s ‚àà CM ). This proves that K k-maintains S w.r.t. E.
The base case, d(s, S) = 0, is about states s ‚àà S. From the formulas in (0), (1), and (4) we have M |= sk for
every such state s. Consider any sequence œÉ = s(0) , s(1) , . . . , s(l) in Unfold k (s, A, K) such that s = s(0) .
If s ‚àà E, then we must have l = 0, and {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ. Otherwise, M |= sak where a = K(s).

20

INFSYS RR 1843-04-04

We then have s(1) ‚àà Œ¶(s, a), and thus by our construction of K and the clauses in (3.2) we have that
(1)
(0) (1)
(l)
M |= sk‚àí1 . Repeating this argument, we can infer that sk , sk‚àí1 , . . . , sk‚àíl are all assigned true in M . If
k = l, it follows from the clauses in (5) that s(l) ‚àà E. Otherwise, if l < k, then K must be undefined on
s(l) ; by the clauses (1), this again means s(l) ‚àà E. Hence, {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ.
Thus the statement holds in the base case. Now for the induction step, let us assume that it holds for
every state s ‚àà Closure(S, AK,exo ) at distance d(s, S) = d ‚â• 0 from S. Let us now consider a state
s ‚àà Closure(S, AK,exo ) at distance d(s‚Ä≤ , S) = d + 1 from S. Then there is a state s‚Ä≤ at distance d(s, S) = d
from S such that s ‚àà Œ¶(a, s‚Ä≤ ) and either (i) a ‚àà exo(s‚Ä≤ ) or (ii) a ‚àà K(s‚Ä≤ ). In both cases, we have by the
induction hypothesis that M |= s‚Ä≤k , and we can conclude M |= sk from the clauses in (2) in case (i) and
from our construction of K and the clauses in (3.2), (1), and (0) in case (ii), respectively. Furthermore, by
similar argumentation as in the case d = 0 above, we obtain that for each sequence œÉ = s(0) , s(1) , . . . , s(l)
in Unfold k (s, A, K) with s = s(0) it holds that {s(0) , . . . , s(l) } ‚à© E 6= ‚àÖ. This concludes the induction and
the proof of (iii).
2
One advantage of the encoding sat‚Ä≤ (I) over the encoding sat(I) for deterministic transition function Œ¶
above is that it directly gives us the possibility to read off a suitable control from the s ai propositions, a ‚àà
poss(s), which are true in any model M that we have computed, without looking at the transition function
Œ¶(s, a) again. On the other hand, the encoding is more involved, and uses a larger set of propositions.
Nonetheless, the structure of the formulas in sat‚Ä≤ (I) is benign for computation and allows us to compute a
model, and from it a k-maintainable control in polynomial time.
5.2.1

Horn SAT encoding (general case)

The encoding sat‚Ä≤ (I) is, like sat(I), a reverse Horn theory. We thus can rewrite sat‚Ä≤ (I) similarly to a Horn
‚Ä≤
theory, sat (I) by reversing the propositions, where the intuitive meaning of si and s ai is the converse of
‚Ä≤
the meaning of si and s ai respectively. The encoding sat (I) is as follows:
(0), (1), (4) and (5) are as in sat(I)
(2) For every states s, s‚Ä≤ ‚àà S such that s‚Ä≤ ‚àà Œ¶(a, s) for some action a ‚àà exo(s):

s‚Ä≤k ‚áí sk .

(3) For every state s ‚àà S \ E and for all i, 1 ‚â§ i ‚â§ k:
(3.1)

V

a‚ààAagent ‚à©poss(s)



s ai ‚áí si ;

(3.2) for every a ‚àà Aagent ‚à©poss(s) and s‚Ä≤ ‚ààŒ¶(s, a):
s‚Ä≤i‚àí1 ‚áí s ai ;
(3.3) for every a ‚àà Aagent ‚à© poss(s), if i < k:
s ai+1 ‚áí s ai .
We obtain from Proposition 7 easily the following result, which is the main result of this section so far.
Theorem 8 Let I consist of a system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A, sets of states E, S ‚äÜ S, an
‚Ä≤
exogenous function exo, and an integer k. Let, for any model M of sat (I), C M = {s | M 6|= sk }, and let
‚ÑìM (s) = min{j | M 6|= s aj , a ‚àà Aagent ‚à© poss(s)} for every s ‚àà S. Then,
‚Ä≤

(i) S is k-maintainable w.r.t. E iff the Horn SAT instance sat (I) is satisfiable;

INFSYS RR 1843-04-04

21
‚Ä≤

(ii) Given any model M of sat (I), every control K such that K(s) is defined iff s ‚àà C M \ E and satisfies
K(s) ‚àà {a ‚àà Aagent ‚à© poss(s) | M 6|= s aj , j = ‚ÑìM (s)},
k-maintains S w.r.t. E.

2

Corollary 9 Problem k-M AINTAIN is solvable in polynomial time. More precisely, it is solvable in time
O(kkIk), where kIk denotes the size of input I.
2
‚Ä≤

Proof. A straightforward analysis yields that the size of sat (I), measured by the number of atoms in it,
is O(k(|S| + |Œ¶| + |poss|)), if Aagent , S, E, Œ¶, poss and exo are stored in a standard way as bitmaps,
i.e., a (multi-dimensional) array with value range {0,1} (thus, kIk = O(|S|2 |A| + log k)). Furthermore,
‚Ä≤
the clauses in sat (I) can be easily generated within the same time bound. Since the least model of any
Horn theory T is computable in time O(|T |) where |T | is the number of atoms in it [16, 37], deciding
‚Ä≤
satisfiability and computing some model M of sat (I) is feasible in O(kkIk) time. Furthermore, C M and
{(s, ‚ÑìM (s)) | s ‚àà S} are computable from M in linear time in the number of atoms, using suitable data
structures, and from this a control K as in Theorem 8.(ii) in the same time. Hence, a k-maintaining control
for S w.r.t. E is computable in O(kkIk) time.
Note that a more economic representation stores S, E, Aagent as sets (i.e., lists) and Œ¶, poss, and exo by
their graphs in tables, i.e., sets of tuples {hs, a, Œ¶(s, a)i | s ‚àà S, a ‚àà A}, {hs, poss(s)i | s ‚àà S}, and
{hs, exo(s)i | s ‚àà S}. Also under this representation, and if moreover tuples where Œ¶(s, a)=‚àÖ (resp.,
poss(s)=‚àÖ and exo(s)=‚àÖ) are not stored (which is of the same order as storing the sets of tuples {hs, a, s‚Ä≤ i |
s‚Ä≤ ‚àà Œ¶(a, s)}, {hs, ai | a ‚àà poss(s)}, {hs, ai | a ‚àà exo(s)}), the O(kkIk) time bound holds. Indeed, arrays
storing S, E, and Aagent for lookup in O(1) time are constructible in time O(|S| + |A|). Then, poss agent =
{hs, ai ‚àà poss | a ‚àà Aagent } storing Aagent ‚à© poss(s) for all s is constructible in O(|poss|) time. From
‚Ä≤
this, all clauses of sat (I) except (2) and (3.2) can be readily generated in time O(k(|S| + |poss agent |)).
The clauses (2) and (3.2) can be easily constructed from Œ¶exo = {hs, a, s‚Ä≤ i ‚àà Œ¶ | a ‚àà exo(s)} and
Œ¶poss = {hs, a, s‚Ä≤ i ‚àà Œ¶ | a ‚àà poss(s)} in time O(|Œ¶exo |) and O(k|Œ¶poss |), respectively. The sets Œ¶exo and
Œ¶poss can be generated from Œ¶ and exo in time O(|Œ¶|+|exo|+poss|), using an auxiliary array aux[A, S] to
‚Ä≤
enable random access to Œ¶(a, s); notice that aux[a, s] needs not be defined if Œ¶(a, s) = ‚àÖ. In total, sat (I)
is constructible in O(|A| + |exo| + k(|S| + |Œ¶| + |poss|)) = O(kkIk) time.
2
Thus in particular, finding a maintaining control under a small window of opportunity, a k-maintaining
control for k bounded by a constant, is feasible in linear time in the size of the input.
‚Ä≤
Similar as in Section 5.1.1, the least model of the theory given by sat (I), Msat‚Ä≤ (I) , leads to a maximal
control in the sense that the pre-image of K outside E, i.e., the states outside E in which K is defined, is
greatest among all possible k-maintaining controls which include S. Furthermore, a smallest k-maintaining
‚Ä≤
control can be similarly computed from any maximal model of sat (I) with respect to the propositions sk
where s is outside E, which can be generated from Msat‚Ä≤ (I) by stepwise maximization. Again, both maximal
and smallest controls can be computed in polynomial time.
Example 6 Reconsider the system A = (S, A, Œ¶, poss) from Example 5. Let us modify the transition
function Œ¶ such that Œ¶(c, a) = {d, f } instead of Œ¶(c, a) = {d}. Then, for the respective modified instance
‚Ä≤
I of 3-M AINTAIN, denoted I1 , the encoding sat (I1 ) looks as follows.
(0), (1), (2), (4), and (5) are as in sat(I1 ) in Example 5;

22

INFSYS RR 1843-04-04

(3.1): b a1 ‚àß b a‚Ä≤1 ‚áí b1 .
c a 1 ‚áí c1 .
d a1 ‚áí d 1 .
f a1 ‚áí f1 .
g1 .
(3.2): h0 ‚áí d a1 .
d0 ‚áí c a1 .
c0 ‚áí b a 1 .

b a2 ‚àß b a‚Ä≤2 ‚áí b2 .
c a 2 ‚áí c2 .
d a2 ‚áí d 2 .
f a2 ‚áí f2 .
g2 .

h1 ‚áí d a2 .
d 1 ‚áí c a2 .
c1 ‚áí b a 2 .

(3.3): d a2 ‚áí d a1 .
c a3 ‚áí c a2 .

h2 ‚áí d a3 .
d 2 ‚áí c a3 .
c2 ‚áí b a 3 .

d a3 ‚áí d a2 .
b a2 ‚áí b a1 .

b a3 ‚àß b a‚Ä≤3 ‚áí b3 .
c a 3 ‚áí c3 .
d a3 ‚áí d 3 .
f a3 ‚áí f3 .
g3 .
h0 ‚áí f a1 .
f0 ‚áí c a1 .
f0 ‚áí b a‚Ä≤1 .

f a2 ‚áí f a1 .
b a3 ‚áí b a2 .

h1 ‚áí f a2 .
f1 ‚áí c a2 .
f1 ‚áí b a‚Ä≤2 .

f a3 ‚áí f a2 .
b‚Ä≤ a 2 ‚áí b‚Ä≤ a 1 .

h2 ‚áí f a3 .
f2 ‚áí c a3 .
f2 ‚áí b a‚Ä≤3 .

c a2 ‚áí c a1 .
a 3 ‚áí b‚Ä≤ a 2 .

b‚Ä≤

‚Ä≤

It turns out that sat (I) has no models: From g3 , the clause g3 ‚áí f3 in (2), and clauses in (0), we obtain
‚Ä≤
that fi , i ‚àà {0, . . . , 3}, is true in every model M of sat (I1 ). Hence, by the clause f2 ‚áí b a3 in (3.2), also
b a‚Ä≤3 is true in M . On the other hand, from the formula f1 ‚áí c a2 in (3.2), we obtain that c a2 must be true
in M , and thus by the clauses c a2 ‚áí c2 in (3.1) and c2 ‚áí b a3 in (3.2) that b a3 is true in M . The clause
b a3 ‚àß b a‚Ä≤3 ‚áí b3 thus implies that b3 is true in M . However, by the formula b3 ‚áí ‚ä• in (4), b3 must be false
‚Ä≤
in M . Thus, no model M of sat (I1 ) can exist, which by Theorem 8 means that there is no 3-maintaining
control for S = {b} w.r.t E = {h}. Indeed, regardless of whether a control function K selects a or a‚Ä≤ in
state b, within at most 2 steps from b the state f might be reached, from which the exogenous function might
move the system to the no-good state g.
Suppose now again that Œ¶(c, a) = {d, f } and that the agent can take a‚Ä≤ in g, which results in either h or f
‚Ä≤
(i.e., Œ¶(g, a‚Ä≤ ) = {f, h} and a‚Ä≤ ‚àà poss(g)). Then the Horn encoding sat (I1 ) changes as follows:
In (3.1), the facts gi , i ‚àà {1, 2, 3}, are replaced by g ai ‚áí gi ;
In (3.2.), the clauses for a‚Ä≤ and f, h are added, i ‚àà {1, 2, 3}:
f0 ‚áí g a‚Ä≤1 .

f1 ‚áí g a‚Ä≤2 .

f2 ‚áí g a‚Ä≤3 .

h0 ‚áí g a‚Ä≤1 .

h1 ‚áí g a‚Ä≤2 .

h2 ‚áí g a‚Ä≤3 .

In (3.3), the clauses for a‚Ä≤ and g are added:
g a‚Ä≤2 ‚áí g a‚Ä≤1 .

g a‚Ä≤3 ‚áí g a‚Ä≤2 .
‚Ä≤

In this encoding sat (I2 ) of the modified instance I2 , we now longer have a fact g3 in (3.1.) and thus the
‚Ä≤
above derivation of a contradiction for the truth value of b3 in any model of sat (I2 ) is not applicable. In
‚Ä≤
fact, sat (I2 ) is satisfiable, and its least model is
M = {b0 , c0 , d0 f0 , g0 , b a1 , c a1 , b a‚Ä≤1 , g a‚Ä≤1 , b1 , c1 , g1 , b a2 }.
Then, we have C M = {b, c, d, f, g, h}, ‚ÑìM (b) = ‚ÑìM (c) = ‚ÑìM (g) = 2 and ‚ÑìM (d) = ‚ÑìM (f ) = 1, which
leads to a single 3-maintaining control K such that K(s) = a for s ‚àà {b, c, d, f } and K(g)= a‚Ä≤ . Note that
since K is defined on every state except h, it 3-maintains every set S w.r.t. every E which includes h. As
for S = {b}, K(c) and K(d) could remain undefined, since they are not in the closure of b (which can be
easily detected) at the price of losing robustness with respect to enlarging S. There is an alternative solution
in which K(b) = a‚Ä≤ instead of K(b) = a. Here K(s) can not be made undefined on any s 6= h.2

INFSYS RR 1843-04-04

5.3

23

Genuine algorithm

From the encoding to Horn SAT above, we can distill a direct algorithm to construct a k-maintainable
control, if one exists. The algorithm mimics the steps which a SAT solver might take in order to solve
sat‚Ä≤ (I). It uses counters c[s] and c[s a] for each state s ‚àà S and possible agent action a in state s, which
range over {‚àí1, 0, . . . , k} and {0, 1, . . . , k}, respectively. Intuitively, value i of counter c[s] (at a particular
step in the computation) represents that so far s0 , . . . , si are assigned true; in particular, i = ‚àí1 represents
that no si is assigned true yet. Similarly, value i for c[s a] (at a particular step in the computation) represents
that so far s a1 , . . . , s ai are assigned true (and in particular, i = 0 that no s ai is assigned true yet).
‚Ä≤
Starting from an initialization, the algorithm updates by demand of the clauses in sat (I) the counters (i.e.,
sets propositions true) using a command upd(c, i) which is short for ‚Äúif c < i then c := i,‚Äù towards a
fixpoint. If a counter violation is detected, corresponding to violation of a clause s0 ‚Üí ‚ä• for s ‚àà S ‚à© E in
(1) or sk ‚Üí ‚ä• for s ‚àà S \ E in (4), then no control is possible. Otherwise, a control is constructed from the
counters.
In detail, the algorithm is as follows:
Algorithm k-C ONTROL
Input: A system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A of agent actions, sets of states E, S ‚äÜ S, an
exogenous function exo, and an integer k ‚â• 0.
Output: A control K which k-maintains S with respect to E, if any such control exists. Otherwise, output
that no such control exists.
(Step 1) Initialization
‚Ä≤
(i) Set Œ¶exo = {hs, a, s‚Ä≤ i | s ‚àà S, a ‚àà exo(s), s‚Ä≤ ‚àà Œ¶(s, a)}, Œ¶E
poss = {hs, a, s i | s ‚àà S \ E, a ‚àà
poss(s), s‚Ä≤ ‚àà Œ¶(s, a)}, and for every s ‚àà S, poss ag (s) = Aagent ‚à© poss(s).

(ii) For every s in E, set c[s] := ‚àí1.
(iii) For every s in S \ E, set c[s] := k if s ‚àà S and poss ag (s) = ‚àÖ; otherwise, set c[s] := 0.
(iv) For every s in S \ E and a ‚àà poss ag (s), set c[s a] := 0.
(Step 2) Repeat the following steps until there is no change or c[s]=k for some s ‚àà S \ E or c[s]‚â•0 for
some s ‚àà S ‚à© E:
(i) For any hs, a, s‚Ä≤ i ‚àà Œ¶exo such that c[s‚Ä≤ ]=k do upd(c[s], k).
‚Ä≤
(ii) For any hs, a, s‚Ä≤ i ‚àà Œ¶E
poss such that c[s ]=i and 0 ‚â§ i < k do upd(c[s a], i + 1).

(iii) For any state s ‚àà S \ E such that poss ag (s) 6= ‚àÖ and i= min(c[s a] | a ‚àà poss ag (s))
do upd(c[s], i).
(Step 3) If c[s]=k for some s ‚àà S\E or c[s]‚â•0 for some s ‚àà S‚à©E, then output that S is not k-maintainable
w.r.t. E and halt.
(Step 4) Output any control K : S \ E ‚Üí Aagent defined on all states s ‚àà S \ E with c[s] < k and such
that K(s) ‚àà {a ‚àà poss ag (s) | c[s a] = minb‚ààposs ag (s) c[s b] < k}.
2

24

INFSYS RR 1843-04-04

The above algorithm is easily modifiable if we simply want to output a super-control such that each of its
refinements is a k-maintainable control, leaving a choice about the refinement to the user. Alternatively, we
can implement in Step 4 such a choice based on preference information.
The following proposition states that the algorithm works correctly and runs in polynomial time.
Proposition 10 Algorithm k-C ONTROL solves problem k-M AINTAIN, and terminates for any input I in
polynomial time. Furthermore, it can be implemented to run in O(kkIk) time.
Proof. The correctness of the algorithms follows from Theorem 8 and the fact that k-C ONTROL mimics,
‚Ä≤
starting from facts in (5) and (3.1), the computation of the least model of sat (I) by a standard fix-point
computation. As for the polynomial time complexity, since counters are only increased, and the loop in
Step 2 is reentered only if at least one counter has increased in the latest run, it follows that the number of
iterations is polynomially bounded. Since the body of Step 2 and each other step is polynomial, it follows
that k-C ONTROL runs in polynomial time.
For the more detailed account, note that bitmaps for S, E and A (if not available in the input) can be
generated in time O(|S| + |A|). In (i) of Step 1, the sets Œ¶exo and Œ¶E
poss can be constructed in time O(|Œ¶| +
|exo|) and O(|Œ¶| + |poss| + |S|), respectively, using an auxiliary array for random access to Œ¶(a, s) in case
if the functions are given by their graphs (cf. proof of Corollary 9). Constructing poss ag (s) for all s‚ààS takes
O(|poss|) time, and (ii)‚Äì(iv) of Step 1 is feasible in time O(|S| + |poss|).
Using flags to signal changes to counters c[s], c[sa ], and auxiliary counters for min(c[s a] | a ‚àà poss ag (s)),
the number of calls of upd in Step 2 is O(k(|Œ¶exo | + |Œ¶poss | + |S|)), and each call takes O(1) time. The
loop condition can be checked in O(m) time where m is the number of changes in the loop. Hence, the total
time for Step 2 is O(kkIk). Step 3 is O(1) if a flag is set in Step 2 indicating the reason for the loop exit.
Finally, in Step 4, a control K can be easily output in time O(|poss|). In total, the time is O(kkIk)
2
Thus, for k bounded by a constant, k-C ONTROL can be implemented to run in linear time. We remark that
further improvements are possible. For example, states may be eliminated beforehand which will not be
reachable from any state in S under any control that is eventually constructed. This can be done efficiently
by computing an upper bound of Closure(S, KA,exo ) in which all possible actions at any state are merged
into a single action. We leave a detailed discussion of this and further refinements for future work.

6 Encoding Maintainability for an Answer Set Solver
In this section, we use the results of the previous section to show how computing a k-maintainable control
can be encoded as finding answer sets of a non-monotonic logic program. More precisely, we describe an
encoding to non-monotonic logic programs under the Answer Set Semantics [24], which can be executed on
one of the available Answer Set Solvers such as DLV [20, 33] or Smodels [40, 50]. These solvers support the
computation of answer sets (models) of a given program, from which solutions (in our case, k-maintaining
controls) can be extracted.
The encoding is generic, i.e., given by a fixed program which is evaluated over the instance I represented
by input facts F (I). It makes use of the fact that non-monotonic logic programs can have multiple models,
which correspond to different solutions, i.e., different k-maintainable controls.
In the following, we first describe how a system is represented in a logic program, and then we develop
the logic programs for both deterministic and general, nondeterministic domains. We shall follow here the
syntax of the DLV system; the changes needed to adapt the programs to other Answer Set Solvers such as
Smodels are very minor.

INFSYS RR 1843-04-04

6.1

25

Input representation

The input I of problem k-M AINTAIN, can be represented by facts F (I) as follows.
‚Ä¢ The system A = (S, A, Œ¶, poss) can be represented using predicates state, transition, and
poss by the following facts:
‚Äì state(s), for each s ‚àà S;
‚Äì action(a), for each a ‚àà A;
‚Äì transition(s,a,s‚Ä≤ ), for each s, s‚Ä≤ ‚àà S and a ‚àà A such that s‚Ä≤ ‚àà Œ¶(s, a);
‚Äì poss(s,a), for each s ‚àà S and a ‚àà A such that a ‚àà poss(s).
‚Ä¢ the set Aagent ‚äÜA of agent actions is represented using a predicate agent by facts agent(a), for
each a‚ààAagent ;
‚Ä¢ the set of states S is represented by using a predicate start by facts start(s), for each s ‚àà S;
‚Ä¢ the set of states E is represented by using a predicate goals by facts goal(s), for each s ‚àà E;
‚Ä¢ the exogenous function exo is represented by using a predicate exo by facts exo(s,a) for each s‚ààS
and a‚ààexo(s).
‚Ä¢ finally, the integer k is represented using a predicate limit by the fact limit(k).
Example 7 Coming back to Example 3, the input I is represented as follows:
state(b). state(c). state(d). state(f). state(g). state(h).
action(a). action(a1). action(e).
trans(b,a,c). trans(b,a1,f). trans(c,a,d). trans(d,a,h).
trans(f,a,h). trans(f,e,g).
poss(b,a). poss(b,a1). poss(f,a). poss(f,e).
poss(c,a). poss(d,a).
agent(a). agent(a1).
start(b). goal(h).
exo(f,e).
limit(3).

6.2

2

Deterministic transition function Œ¶

The following is a program, executable on the DLV engine, for deciding the existence of a k-control. In
addition to the predicates for the input facts F (I), it employs a predicate n path(X,I), which intuitively
corresponds to XI , and further auxiliary predicates.
% Define range of 0,1,...,k for stages.
range(I) :- #int(I), I <= K, limit(K).
% Rule for (0).
n_path(X,I) :- state(X), range(I), limit(K), I<K, n_path(X,J), J = I+1.

26

INFSYS RR 1843-04-04

% Rule for (1).
:- n_path(X,0), goal(X), start(X).
% Rule for (2)
n_path(X,K) :- trans(X,A,Y), exo(X,A), n_path(Y,K), limit(K).
% Rules for (3)
n_path(X,I) :- state(X), not goal(X), range(I), I>0, not some_pass(X,I).
some_pass(X,I) :- range(I), I>0, trans(X,A,Y), agent(A),
poss(X,A), not n_path(Y,J), I=J+1.
% Rule for (4)
:- n_path(X,K), limit(K), start(X), not goal(X).
% Rule for (5)
n_path(X,0) :- state(X), not goal(X).

The predicate range(I) specifies the index range from 0 to k, given by the input limit(k). The rules
encoding the clause groups (0) ‚Äì (2) and (4), (5) are straightforward and self explanatory. For (3), we need to
encode rules with bodies of different size depending on the transition function Œ¶, which itself is part of the
input. We use that the antecedent of any implication (3) is true if it is not falsified, where falsification means
that some atom s‚Ä≤i‚àí1 , s‚Ä≤ ‚àà P S(s), is false; to assess this, we use the auxiliary predicate some pass(X,I).
To compute the super-control K + , we may add the rule:
% Define C M
cbar(X) :- state(X), not n_path(X,K), limit(K).
%Define state level L
level(X,I) :- cbar(X), not n_path(X,I), I > 0,

n_path(X,J), I=J+1.

level(X,0) :- cbar(X), not n_path(X,0).
% Define super-control k_plus
k_plus(X,A) :- agent(A), trans(X,A,Y), poss(X,A), level(X,I),
level(Y,J), J<I, not goal(X).

In cbar(X), we compute the states in C M , and in level(X,I) the level ‚ÑìM (s) of each state s ‚àà C M
+
(=CM for the corresponding model M of sat(I)). The super-control KM
is then computed in k plus(X,A).
+
Finally, by the following rules we can nondeterministically generate any control which refines KM
:
% Selecting a control from k_plus.
control(X,Y) :- k_plus(X,Y), not exclude_k_plus(X,Y).
exclude_k_plus(X,Y) :- k_plus(X,Y), control(X,Z), Y<>Z.

The first rule enforces that any possible choice for K(s) must be taken unless it is excluded, which by the
second rule is the case if some other choice has been made. In combination the two rules effect that one and
+
only one element from KM
(s) is chosen for K(s).

INFSYS RR 1843-04-04

27

Example 8 If the input representation of Example 5 is in a file exa3.dlv and the above program, denoted
by Œ†det , in a file det.dlv, the DLV engine can be invoked e.g. by
dlv exa3.dlv det.dlv -N=3 -filter=control
which outputs the controls; here -N=3 sets the range of integers dynamically supported by the engine to 3,
and -filter=control effects that the answer sets are clipped to the predicate control. In the particular case,
the output on the call is (apart from system version information)
control(b,a), control(c,a), control(d,a)
yielding the unique control which exists in this case. If we would add a further agent action a2 to the action
set, and extend the transition function by Œ¶(b, a2 ) = c, then a call of DLV for the respective representation
would yield
{control(b,a2), control(c,a), control(d,a)}
{control(b,a), control(c,a), control(d,a)}
corresponding to the two alternative controls which emerge, since the agent can take either action a or action
a2 in state a.

6.3

Nondeterministic transition function Œ¶

As for deciding the existence of a k-maintaining control, the only change in the code for the deterministic
case affects Step (3). The modified code is as follows, where n apath(X,A,I) intuitively corresponds to
X AI .
% Rules for (3); different from above
% (3.1)
n_path(X,I) :- state(X), not goal(X), range(I), I>0, not some_apass(X,I).
some_apass(X,I) :- range(I), I>0, agent(A), poss(X,A), not n_apath(X,A,I),
not goal(X).
% (3.2)
n_apath(X,A,I) :- agent(A), trans(X,A,Y), poss(X,A), range(I), I>0,
n_path(Y,J), I=J+1, not goal(X).
% (3.3)
n_apath(X,A,I) :- agent(A), poss(X,A), range(I), I>0, limit(K), I<K,
n_apath(X,A,J), J=I+1, not goal(X).

Here, some apass(X,A,I) plays for encoding (3.1) a similar role as some pass(X,I) for encoding
(3) in the deterministic encoding.
+
To compute the super-control KM
, we may then add the following rules:
% Define C M
cbar(X) :- state(X), not n_path(X,K), limit(K).

28

INFSYS RR 1843-04-04

% Define state action level, alevel (>=1)
alevel(X,I) :- alevel_leq(X,I), I=J+1, range(J), not level_leq(X,J).
alevel_leq(X,I) :- cbar(X), not goal(X), poss(X,A), agent(A), I>0,
range(I), not n_apath(X,A,I).
% Define super-control k_plus
k_plus(X,A) :- agent(A), alevel(X,I), poss(X,A), not n_apath(X,A,I).

Here, the value of ‚ÑìM (s) is computed in alevel(X,I), using the auxiliary predicate alevel leq(X,I)
which intuitively means that ‚ÑìM (X) ‚â§ I.
+
For computing the controls refining KM
, we can add the two rules for selecting a control from k plus
from the program for the deterministic case.
Example 9 Let us revisit the instance I1 in Example 6. We get the DLV representation of I1 by adding the
fact trans(c,a,f). to the representation for I. Assuming that it is in a file exa4.dlv and the program
Œ†ndet in a file ndet.dlv, a call
dlv exa4.dlv ndet.dlv -N=3 -filter=control
yields no output (apart from some system version print), which is correct. On the other hand, if we consider
the input I2 for the variant of Example 6 (with agent action a‚Ä≤ possible in g and Œ¶(g, a‚Ä≤ ) = {f, h}), then the
output is
{control(b,a1), control(c,a), control(d,a), control(f,a), control(g,a1)}
{control(b,a), control(c,a), control(d,a), control(f,a), control(g,a1)}

(where a1 encodes a‚Ä≤ ). Again, this is the correct result.

6.4

Layered use of negation

An important note at this point is that the programs Œ†det and Œ†ndet do not necessarily have models which
‚Ä≤
correspond to the least models of the Horn theories sat(I) and sat (I), respectively. The reason is that the
use of negation not some pass(X,I) and resp. not some apass(X,I) may lead through cycles
in recursion. Thus, not each control computed is necessarily maximal (even though the maximal controls
will be computed in some models). Furthermore, because of cyclic negation it is not a priori clear that the
part of the program deciding the existence of a control is evaluated by DLV in polynomial time. However,
‚Ä≤
consistency (i.e., existence of an answer set) is guaranteed whenever sat(I) resp. sat (I) has a model.
It is possible to modify Œ†det such that the use of negation in recursion cycles is eliminated, by using standard
coding methods to evaluate the body of the rule in (3). Namely, introduce for Œ†det a predicate all true
and replace not some pass(X,I) in the code for (3) with all true(X,I), which is defined such
that all true(s, i) represents that every s‚Ä≤ i‚àí1 ‚àà P S(s) is assigned true, which can be checked using a
linear ordering ‚â§ on P S(s). However, we refrain from this here.
Notice that in the case where P S(s) has size bounded by a constant c, we can use a predicate ps of arity
c + 1 to represent P S(s) = {s(1) , . . . , s(l) } by a single fact ps(s, s(1) , . . . , s(l) , . . . , s(l) ) where s(l) is
reduplicated if l < c. It is then easy to express the clause (3).
We can similarly modify Œ†ndet such that the use of negation in recursion cycles is eliminated, where we
use a linear ordering on Aagent ‚à© poss(s) (or simply on Aagent , assuming that there are not many agent

INFSYS RR 1843-04-04

29

actions overall). Finally, we can also use for the program Œ†det simply an ordering of Aagent , since the
deterministic transformation Œ¶(s, a) is a (partial) surjective mapping of A onto P S(s), which guarantees
that via A ‚à© poss(s) each s‚Ä≤ ‚àà P S(s) can be accessed through Œ¶.
The modified programs use negation only in a stratified manner, and thus will be evaluated by DLV in
‚Ä≤
guaranteed polynomial time in the size of the DLV representation of sat(I) and sat (I), respectively.

6.5

State descriptions by variables

In many cases, states of a system are described by a vector of values for parameters which are variable over
time. It is easy to incorporate such state descriptions into the LP encoding from above, and to evaluate them
on Answer Set Solvers provided that the variables range over finite domains. In fact, if any state s is given
by a (unique) vector s = hs1 , . . . , sm i m > 0, of values si , 1 ‚â§ i ‚â§ m, for variables Xi ranging over
nonempty domains, then we can represent s as fact state(v1i ,...,vri i ) and use a vector X1,...,Xm
of state variables in the DLV code, in place of a single variable, X. No further change of the programs from
above is needed.
Similarly, we can easily accommodate actions a(P1 , P2 , . . . , Pm ) with parameters P1 , . . . , Pm (which is
important) from a finite set if desired. However, here rule the defining exclude k plus(X,Y) should be
replaced by all rules emerging if the atom Y <> Z in the body is replaced by Yi <> Zi, i ‚àà {1,...,m}
(assuming that Y and Z are replaced by Y1,...,Ym and Z1,...,Zm, respectively).
Another possibility to handle state descriptions by variables would be to implement a coding scheme, which
maps each vector s = hs1 , . . . , sm i into an integer i(s), represented by fact code(i(s), s1 , . . . , sm ).
Furthermore, we point out that the input need not consist merely of facts, but may also involve rules to define
the predicates of the input representation more compactly. Finally, the facts for action can be dropped,
since they are not referenced by any rule in programs Œ†det and Œ†ndet .
For illustration, we consider the buffer example from Section 3.
Example 10 Recall that states in the buffer example are given by pairs of integers hi, ji where i and j are
the numbers of objects in buffer b1 and b2 , respectively. We thus use variables X1,X2 and Y1,Y2 in place
of X and Y, respectively.
For buffer capacity of 3, S = {h0, 0i}, E = {h0, ji | 1 ‚â§ j ‚â§ 3}, and k = 6, the input can be represented
as follows:
state(X1,X2) :- #int(X1), #int(X2), X1 <= 3, X2 <= 3.
start(0,0).
goal(0,X2) :- state(0,X2).
trans(X1,X2,m_12,Y1,Y2) :- state(X1,X2), state(Y1,Y2), X1=Y1+1, Y2=X2+1.
trans(X1,X2,m_21,Y1,Y2) :- state(X1,X2), state(Y1,Y2), Y1=X1+1, X2=Y2+1.
trans(X,X2,proc,X,Y2) :- state(X,X2), state(X,Y2), X2=Y2+1.
trans(X1,X,ins,Y1,X) :- state(X1,X), state(Y1,X), Y1=X1+1.
poss(X1,X2,m_12) :- state(X1,X2), 1
poss(X1,X2,m_21) :- state(X1,X2), 1
poss(X1,X2,proc) :- state(X1,X2), 1
poss(X1,X2,ins) :- state(X1,X2), X1

<=
<=
<=
<=

X1, X2 <= 2.
X2, X1 <= 2.
X2.
2.

30

INFSYS RR 1843-04-04

agent(m_12). agent(m_21). agent(proc). exo(ins).
limit(6).

Here, equalities X1=0 for X1,X2 in the rule defining goal and X1=Y1 in the definition of trans(X,X2,
proc,X,Y2) etc are pushed through.
Invoking DLV, assuming the representation is stored in file exa-buffer.dlv and the expanded version
of Œ†det in a file det2.dlv, with
dlv exa-buffer.dlv det2.dlv -N=6 -filter=control
yields 13 models, of which encode different controls. Among the maximal controls is
{ control(1,0,m_12), control(1,1,m_12), control(1,2,m_12), control(1,3,proc),
control(2,0,m_12), control(2,1,m_12), control(2,2,proc), control(2,3,proc),
control(3,0,m_12), control(3,1,proc), control(3,2,proc), control(3,3,proc)}

which is defined on all states outside E, and thus constitutes a 6-maintaining control for the whole system.

7 Computational Complexity
In this section, we consider the complexity of constructing k-maintainable controls under various assumptions. To this end, we first describe the problems analyzed and give an overview of the complexity results.
After that, the results are established in a separate subsection; the reader who is not interested in the technical
proofs might safely skip it.

7.1

Problems considered and overview of results

Following the common practice, we consider here the decision problem associated with k-M AINTAIN, which
we refer to as k-M AINTAINABILITY: Given a system A = (S, A, Œ¶, poss), a set Aagent ‚äÜ A of agent
actions, sets of states E, S ‚äÜ S, an exogenous function exo, and an integer k ‚â• 0, decide whether S is
k-maintainable with respect to E in A. Furthermore, we also consider œâ-M AINTAINABILITY, which has
the same input except k and asks whether S is maintainable with respect to E in A.
We consider the problems in two different input settings, in line with the previous sections:
Enumerative representation: The constituents of an instance I are explicitly given, i.e., the sets (A, S,
Aagent , S, and E) in enumerative form and the functions (Œ¶(a, s), poss(s), and exo) by their graphs
in tables.
State variables representation: A system state s is represented by a vector s = (v1 , . . . , vm ) of values for variables f1 ,. . . ,fm ranging over given finite domains D1 , . . . , Dm , while A and Aagent are
given in enumerative form. We assume that polynomial-time procedures for evaluating the following
predicates are available:
‚Ä¢ in Phi (s, a, s‚Ä≤ ), in poss(s, a), and in exo(s, a) respectively for deciding s‚Ä≤ ‚àà Œ¶(s, a),
a ‚àà poss(s), and a ‚àà exo(s), respectively.
‚Ä¢ in S (s) and in E (s) for deciding whether s ‚àà S and s ‚àà E, respectively.

INFSYS RR 1843-04-04

+/- exogenous actions

31

k-M AINTAINABILITY
given k

deterministic
nondeterministic

P / NL (Th.11/15)
P (Th.11/13)

œâ-M AINTAINABILITY

constant k ‚â• 1
P / in LH (‚äÇ L) (Th.11/16)
P / in LH (‚äÇ L) (Th.11/16)

P / NL (Co.12/Th.15)
P (Co.12/Th.13)

Table 1: Complexity of deciding k- and œâ-M AINTAINABILITY under enumerative representation (logspace
completeness)

+/- exogenous actions
deterministic
nondeterministic

k-M AINTAINABILITY
given k
constant k ‚â• 1

œâ-M AINTAINABILITY

EXP / PSPACE (Th.18/21)

EXP / co-NP (Th.18/22)

EXP / PSPACE (Co.19/Th.21)

EXP (Th.18/20)

EXP / co-NP (Th.18/22)

EXP (Co.19/Th.20)

Table 2: Complexity of deciding k- and œâ-M AINTAINABILITY under state variables representation
(logspace completeness)
Orthogonal to this, we also consider (1) general k versus constant k, in order to highlight the complexity of
small windows of opportunity for maintenance; (2) absence of exogenous actions, to see what cost intuitively
is caused by an adversary; and (3) nondeterministic versus deterministic actions.
The results of the complexity analysis are compactly summarized in Tables 1 and 2, in which unless stated
otherwise, the entries stand for completeness results under logspace reductions. We assume that the reader
is familiar with the classes P (polynomial time), EXP (exponential time), L (logarithmic workspace), NL
(nondeterministic logarithmic work space), co-NP (co-nondeterministic polynomial time), and PSPACE
(polynomial space) appearing in the tables, and refer to [44] and references therein for further background
S
on complexity. By LH we denote the logarithmic time hierarchy [7, 27], which is given by LH = i‚â•0 Œ£log
i ,
log
where Œ£i denotes the decision problems solvable on an alternating Turing machine in logarithmic time
with at most i‚àí1 alternations between existential and universal states, starting in an existential state. Note
that LH is strictly included in L. A more refined complexity assessment is given in Section 7.2. However,
we refrain here from providing a sharp complexity characterization of the problems classified within LH in
terms of completeness under a suitable notion of reduction, since they are not central to the maintainability
issue under an ‚Äúadversarial‚Äù environment.
Under enumerative representation (Table 1), k- and œâ-M AINTAINABILITY have the same complexity as
Horn SAT, which is P-complete [44]. Thus, according to widely believed complexity hypotheses, the problem is difficult to parallelize and to solve within poly-logarithmic workspace. In fact, this holds also for
the case of constant k = 1 and the restriction that all actions are deterministic and that there is a single exogenous action. Thus, even in the simplest setting with an adversary according to the dimensions above,
the problem already harbors its full complexity; excluding nondeterministic actions and/or fixing k does not
make the problems simpler. Intuitively, this is because with the help of exogenous actions, one can simulate
nondeterminism and split sequences of agent maintenance actions into small segments.
On the other hand, when exogenous actions are excluded (listed under ‚Äú-‚Äù), k- and œâ-M AINTAINABILITY
are always easier when the actions are deterministic or the window of opportunity is small (k is constant).
In summary, the results show that exogenous actions can not be compiled efficiently away (with reasonable
complexity) to an instance of maintainability under a small window opportunity, and that nondeterministic

32

INFSYS RR 1843-04-04

actions are indispensable for such a compilation.
The reason is that in absence of exogenous actions, k-M AINTAINABILITY is akin to a graph reachability
resp. planning problem (for the latter, see Section 8.1). Indeed, define for a fixed system A=(S, A, Œ¶, poss),
a set of agent action Aagent ‚äÜ A, and sets E, S ‚äÜ S of states the predicates ri (s), i ‚â• 0, on s ‚àà S
inductively by
r0 (s) = s ‚àà E,
ri+1 (s) = s ‚àà E ‚à® ‚àÉa ‚àà Aagent ‚à© poss(s)
‚àÄs‚Ä≤ ‚àà S(s‚Ä≤ ‚àà Œ¶(s, a) ‚áí ri (s‚Ä≤ )),

for i ‚â• 0.

(1)

Informally, ri (s) expresses that some state in E can be reached from s within i agent actions, and it holds that
S is k-maintainable with respect to E, exactly if rk (s) holds for every s in S (as proved in Lemma 1 below).
The predicate rk (s) is definable in first-order predicate logic with a suitable relational vocabulary (using
the predicates given for enumerative representation). As well-known, the first-order definable properties are
those which can be decided in LH [7, 27]. Since LH is considered to contain problems which have much
lower complexity than hard problems in P, the effect of exogenous actions is drastic in complexity terms.
Furthermore, problems in LH are amenable to parallelization (see [27]).
Under state variables representation (Table 2), the complexity of the problems, with few exceptions increases
by an exponential. This increase is intuitively explained by the fact that state variables permit in general an
exponentially smaller input representation, which must be unpacked for solving the problem. The exception
for constant k in absence of exogenous functions, where the complexity increases from within LH to co-NP,
is intuitively explained by the fact that the quantifier ‚Äú‚àÉa ‚àà Aagent ‚à© poss(s)‚Äù in equation (1), as opposed
to ‚Äú‚àÄs‚Ä≤ ‚àà S‚Äù, ranges over a polynomial set of values (in the input size), and thus can be deterministically
eliminated.
The EXP-completeness means that the problems are provably intractable, i.e., have an exponential lower
bound in this setting. Even in the ‚Äúcheapest‚Äù cases under state variable representation, the problems are
intractable. Exogenous actions cannot be compiled efficiently away in the same cases as under enumerative
representation.

7.2

Enumerative representation

We start with the case of enumerative representation. Our first result is the following.
Theorem 11 Problem k-M AINTAINABILITY is P-complete (under logspace reductions). The P-hardness
holds under the restriction that k = f (A, S, E) is any function of A, S, and E such that f (A, S, E) ‚â• 1 (in
particular, for fixed k ‚â• 1), even if in addition all actions are deterministic and there is only one exogenous
action.
Proof. The membership of k-M AINTAINABILITY in P follows from Corollary 9.
We prove P-hardness under the stated restriction by a reduction from deciding logical entailment œÄ |= q of a
propositional atom q from a propositional Horn logic program (PHLP) œÄ, which is a set of rules of the form
b0 ‚Üê b1 , . . . , bn ,

n ‚â• 0,

(2)

and each bi is a propositional atom from an underlying atom set At; b0 is the head and b1 , . . . , bn is the body
of the rule.

INFSYS RR 1843-04-04

33

As well-known, œÄ |= q holds iff there is a sequence of rules r1 , r2 , . . . , rm , m ‚â• 1, from œÄ where ri
is of form bi0 ‚Üê bi1 , . . . , bin , such that {bi1 , . . . , bin } ‚äÜ {b10 , . . . , bi‚àí10 }, for all i ‚àà {1, . . . , m} (thus
in particular, 1n = 0) and bm0 = q, called a proof of q from œÄ. Informally, q is derived by successive
application of the rules r1 , . . . , rm , where ri ‚Äúfires‚Äù after all previous rules r1 , . . . , ri‚àí1 have fired.
A natural idea is to represent backward rule application rm , rm‚àí1 , . . . , r1 through agent actions; for a rule
r of form (2), there is an agent action a r which applied to a state sb0 representing b0 , brings the agent
nondeterministically to any state sbi representing bi , i ‚àà {1, . . . , n}. Given a state sq encoding q, S = {sq }
is maintainable w.r.t. a set of states E encoding the facts in œÄ if q has a proof from œÄ. However, this does
not account for the restriction that k = f (A, S, E) for any such f . The key for this is to establish the result
for the extremal case where k = 1 is constant (i.e., for 1-MAINTAINABILITY) and then to extend it to the
general case.
Using a constrained rule format in œÄ and an exogenous action, we can emulate nondeterministic agent
actions and sequences of agent actions with some coding tricks by alternating sequences of deterministic
agent and exogenous actions, such that provability of q from œÄ corresponds to 1-maintainability of S w.r.t.
a set E in a system A constructible in logarithmic workspace from q and œÄ.
Without loss of generality, we assume that each rule has either zero or two atoms in the body (i.e., n = 0
or n = 2 in (2)). We construct from œÄ and q a system A = (S, A, Œ¶, poss), sets of states S and E, a set
Aagent ‚äÜ A, and a function exo as follows:
(b, c)2
a r2

e
S
a3

a r1

(b, c)1

a2

r13

a r1

a r2

c3

a r3

a r2

e
r12

e
b3

(b, c)0

a1

a r1

e
r11

e

a0
e

r23

b2

a r2

r22

b1

a r2

r21

b0

r33

c2

a r3

r32

c1

a r3

r31

c0

E

Figure 3: Transition diagram of the system for œÄ = {a ‚Üê b, c; b ‚Üê ; c ‚Üê} and q = a (S and E encircled).

1. S: For each atom f in œÄ and rule r ‚àà œÄ, f 0 , . . . f m and r1 , . . . , rm are states in S. Furthermore, if the
body of r is u, v then (u, v)0 , . . . , (u, v)m‚àí1 are states in S.
2. A = {a r | r ‚àà œÄ} ‚à™ {e}.
3. Œ¶: For any rule r ‚àà œÄ with head f , Œ¶(a r, f i ) = {ri } for i ‚àà {1, . . . , m} and Œ¶(a r, (u, v)i ) = {ri },
for (u, v)i ‚àà S, i ‚àà {1, . . . , m ‚àí 1}. If moreover r has body u, v, then Œ¶(e, ri ) = {(u, v)i‚àí1 }, and
Œ¶(e, (u, v)i‚àí1 ) = {v i‚àí1 }, for i ‚àà {1, . . . , m ‚àí 1}. In all other cases, Œ¶(a, s) = ‚àÖ.
4. poss: For each state s, poss(s) = {a ‚àà A | Œ¶(a, s) 6= ‚àÖ}.
5. E = {r1 , . . . , rm | r ‚àà œÄ}

34

INFSYS RR 1843-04-04

6. S = {q m }.
7. Aagent = A \ {e}.
8. exo: for all rules r ‚àà œÄ of form f ‚Üê u, v, exo(ri ) = {e} for i ‚àà {1, . . . , m} and exo((u, v)j ) = {e}
for j ‚àà {1, . . . , m ‚àí 1}. For all other states s, exo(s) = ‚àÖ.
The transition diagram for the system constructed for œÄ = {a ‚Üê b, b ‚Üê, c ‚Üê} is shown in Figure 7.2.
Intuitively, the state f i encodes that f can be derived from œÄ with a proof of length at most i. This is
propagated in backward rule application. Each agent action a r selects a rule r to prove an atom f ; if the
rule has a body u, v, the exogenous action pushes the agent to prove both u (from (u, v)) and v within
decreased recursion depth.
We claim that œÄ |= q iff there exists some 1-maintaining control K for S with respect to E in A.
Suppose first that œÄ |= q. We then construct a 1-maintaining control K for S with respect to E as follows.
Let P = r1 , . . . , rk be a proof of q from œÄ such that, without loss of generality, all rules ri have different
heads. Set D = {q m } and iterate the following until D remains unchanged: For each f i ‚àà D resp. (u, v)i ‚àà
D, i ‚â• 0, let rj be the rule with head f resp. u in P . Define K(f i ) = {a rj } resp. K((u, v)i ) = {a rj },
and add, if rj has body u‚Ä≤ , v ‚Ä≤ the states (u, v)i‚àí1 and v ‚Ä≤ i‚àí1 to D. Since P is a proof of q from œÄ, the rule rj
always exists, and for each state s in Closure(S, AK,exo ) \ E (=D), K(s) is defined and Œ¶(K(s), s) yields
some state in E. Hence, K is a 1-maintaining control for S with respect to E in A.
Conversely, suppose K is a 1-maintaining control for S with respect to E in A. Without loss of generality, K(s) is undefined for all states s ‚àà E. An easy induction on i ‚â• 1 shows that for each f i ‚àà
Closure(S, AK,exo ) resp. (u, v)i ‚àà Closure(S, AK,exo ), it holds that œÄ |= f resp. œÄ |= u and œÄ |= v. For
i=1, suppose first K(f 1 ) = a r. Rule r must have form f ‚Üê ; otherwise, some states (u, v)0 , v 0 would
be in Closure(S, AK,exo ), which contradicts that K is a 1-maintaining control. Hence, œÄ |= f . Next suppose K((u, v)1 ) = a r. Then, for similar reasons, r must be of form u ‚Üê, hence œÄ |= u. Furthermore,
v 1 ‚àà Closure(S, A,exo ) and as already established œÄ |= v. For i > 1, suppose K(f i ) = a r. Then either r
is of form f ‚Üê and thus œÄ |= f , or of form f ‚Üê u, v. In the latter case, (u, v)i‚àí1 ‚àà Closure(S, AK,exo ) and
hence, by the induction hypothesis, œÄ |= u and œÄ |= v. Consequently, œÄ |= f . Similarly, if K((u, v)i ) = a r,
then either r is of form u ‚Üê or of form u ‚Üê u‚Ä≤ , v ‚Ä≤ and (u‚Ä≤ , v ‚Ä≤ )i‚àí1 ‚àà Closure(S, AK,exo ), which by the
induction hypothesis implies œÄ |= u‚Ä≤ and œÄ |= v ‚Ä≤ , thus œÄ |= u. Since v i ‚àà Closure(S, AK,exo ), as already
established œÄ |= v. Consequently, œÄ |= f . This proves the statement for i > 1, and concludes the induction.
Since q m ‚àà Closure(S, AK,exo ), we have œÄ |= q. This proves our claim.
Notice that A, S and E can be constructed in logarithmic workspace from œÄ and q. This proves P-hardness
of 1-M AINTAINTABILITY. An easy observation is that every agent action in the system A leads to some
state in the set E described. Hence, S is 1-maintainable with respect to E in A iff S is k-maintainable
with respect to E in A for any f (A, S, E) such that f (A, S, E) ‚â• 1. Hence, P-hardness under the stated
restriction follows.
2
The following result is immediate from this result and the fact that maintainability is equivalent to kmaintainability where k = |S| is the number of states.
Corollary 12 œâ-M AINTAINABILITY is P-complete. The P-hardness holds even if all actions are deterministic and there is only one exogenous action.
The following result states a further P-complete restriction of the above problems.
Theorem 13 k-M AINTAINABILITY and œâ-M AINTAINABILITY without exogenous actions are P-complete.

INFSYS RR 1843-04-04

35

Proof. Membership in P was established above. The P-hardness follows from Theorem 11 by merging the
(single) exogenous action e into the agent actions as follows: For each state s such that e ‚àà exo(s), redefine
every action a ‚àà poss(s) ‚à© Aagent by Œ¶(s, a) := Œ¶(s, a) ‚à™ Œ¶(s, e). It is easy to see that given S and E, S
is |S|-maintainable w.r.t. E in the resulting system A‚Ä≤ iff S is |S|-maintainable w.r.t. E in A. Furthermore,
A‚Ä≤ is computable in logspace from A. This implies the result.
2
The hardness results above are at the border of the hardness frontier, in the sense that in the absence of
exogenous actions and, in case of œâ-M AINTAINABILITY also nondeterminism, the problems are no longer
P-hard. The following lemma gives a useful characterization of k-maintainability for this purpose.
Lemma 14 Given a system A = (S, A, Œ¶, poss), a set of agents action Aagent ‚äÜ A, and a set of states E, a
set of states S is k-maintainable with respect to E in absence of exogenous actions (i.e., exo is void), k ‚â• 0,
iff rk (s) as in (1) holds for all s ‚àà S.
Proof. For the only if direction, consider any 1-maintaining control K which without loss of generality is
undefined on every s ‚àà E. For every state s ‚àà Closure(S, AK,exo ) = Closure(S, AK ), let ds be the distance
of s from E under K, i.e., the largest i such that œÉ = s0 , s1 , . . . , si ‚àà Unfold k (s, A, K) where s0 = s. By
an easy induction on ds ‚â• 0, we obtain using K(s) as witness for a in (1), that rds (s), rds +1 (s), . . . , rk (s)
must hold for s. Hence, rk (s) holds for every s ‚àà S.
Conversely, let for each s ‚àà S be is the least integer i such that ri (s) holds. If is > 0, then define
K(s) := a for some arbitrary action a ‚àà Aagent ‚à© poss(s) witnessing (1) for i + 1 = is , otherwise
(i.e., if is = 0 or ri (s) does not hold for any i ‚â• 0) let K(s) undefined. Then, K is a k-maintaining
control for S with respect to E, since by definition of the relations ri , for each s ‚àà Closure(S, AK ), and
œÉ = s0 , s1 , . . . , sl ‚àà Unfold k (s, A, K) such that s0 = s it holds that l ‚â§ k and sl ‚àà E (recall that, as tacitly
assumed, Œ¶(a, s) 6= ‚àÖ for each a ‚àà poss(a)). Hence, S is k-maintainable with respect to E.
2
We then establish the following result.
Theorem 15 k-M AINTAINABILITY and œâ-M AINTAINABILITY for systems with only deterministic actions
and no exogenous actions are NL-complete.
Proof. In this case, deciding ri (s) for given s ‚àà S and i ‚â• 0 is in NL: If s ‚àà
/ E, a proper a in (1) and
‚Ä≤
‚Ä≤
s = Œ¶(s, a) can be guessed and, recursively, rk‚àí1 (s ) established, maintaining a counter i. This is feasible in logarithmic workspace in the representation size of A. By looping through all s ‚àà S, it thus follows
from Lemma 14 that deciding whether S is k-maintainable with respect to E, where k ‚â§ |S|, is nondeterministically feasible in logarithmic workspace. This implies NL-membership of k-M AINTAINABILITY
and œâ-M AINTAINABILITY. The hardness follows from a simple reduction of the well-known NL-complete
R EACHABILITY problem [44] to k- resp. œâ-M AINTAINABILITY: Given a directed graph G = (V, E) and
nodes s, t ‚àà V , decide whether there is a directed path from s to t in G. Define A = (S, A, Œ¶, poss) such
that S = A = V , Œ¶(v, w) = w, and poss(v) = {w | v ‚Üí w ‚àà E}. Then, for Aagent = A, S = {s} is
|V |-maintainable w.r.t. E = {t} in A iff there is a directed path from s to t in G. Clearly, A is constructible
in logarithmic workspace from G. This shows the NL-hardness.
2
In case of constant k, equation (1) is decidable by a straightforward deterministic recursive procedure in
logarithmic workspace, even under nondeterminism, since the recursion depth is bounded by a constant and
each recursion level requires only logarithmic work space. Hence, k-M AINTAINABILITY is decidable in
logarithmic space. A finer grained analysis that it is within the class Œ†log
k+1 of the logarithmic time hierarchy,
which is a much better upper bound and makes completeness for logspace (under suitable reductions) fairly
unlikely.

36

INFSYS RR 1843-04-04

We assume that the input I of k-M AINTAINABILITY for fixed k, is a relational structure MI with universe
U (MI ) = S ‚à™ A, and relations over U (MI ) for the predicates in Phi (s, a, s‚Ä≤ ), in poss(s, a), in exo(s, a),
in S (s) and in E (s) from above, and relations for the additional predicates ag act(a), in S(s), and
in A(a) representing membership a ‚àà Aagent , s ‚àà S and a ‚àà A for each s, a ‚àà U (M ), respectively.
The structure MI is encoded in a standard way by a bit-string [27].
Theorem 16 Problem k-M AINTAINABILITY for systems without exogenous actions is in Œ†log
2k+1 (=colog
Œ£2k+1 ), if k ‚â• 0 is constant.
Proof. Any first-order formula œà1 ‚à® Qx œà2 resp. œà1 ‚àß Qx œà2 such that œà1 has no free variables and
Q ‚àà {‚àÉ, ‚àÄ}, is logically equivalent to Qx(œà1 ‚à® œà2 ) resp. Qx(œà1 ‚àß œà2 ). Exploiting this, rk (s) in (1) can
be written, using the vocabulary from above, as a first-order formula œÜk (x) in prenex form
‚àÉx1 ‚àÄx2 ‚àÉx3 ¬∑ ¬∑ ¬∑ Qk xk œà(x1 , . . . , xk , x)
where œà(x1 , . . . , xk , x) is quantifier-free, such that for any element s ‚àà U (MI ) of an input structure M, the
sentence in S(s) ‚àß œÜk (s) is true on M iff rk (s) holds. Hence, by Lemma 14, k-maintainability of S w.r.t. E
in A is definable by a Œ†k+1 prenex sentence ‚àÄx0 ‚àÉx1 ¬∑ ¬∑ ¬∑ Qk xk œà ‚Ä≤ (x0 , x1 , . . . , xk ), where œà ‚Ä≤ (x0 , x1 , . . . , xk )
is quantifier-free, on the above vocabulary. Whether a fixed such sentence is false on a given structure MI
can be decided by an alternating Turing machine, starting in an existential state, in logarithmic time using k
log
alternations [7, 27]. Hence, the problem is in co-Œ£log
2
k+1 = Œ†2k+1 .
We remark that the hardness results in this section can be further strengthened to the case where only 2 agent
actions are available, but leave a proof of this to the interested reader.

7.3

State variables

The following is an easy lemma, which in combination with the results in the previous subsection implies
most upper bounds in Table 2.
Lemma 17 For any instance of k-M AINTAINABILITY resp., œâ-M AINTAINABILITY in which states are represented by variables, the corresponding instance in ordinary (enumerative) form can be generated in polynomial workspace.
Using this lemma, we then prove the following result.
Theorem 18 Under state representation by variables, k-M AINTAINABILITY is EXP-complete. The EXPhardness holds under the restriction that k = f (A, S, E) is any function of A, S, and E such that f (A, S, E) ‚â•
1 (in particular, for fixed k ‚â• 1), even if in addition all actions are deterministic and there is only one exogenous action.
Proof. Membership in EXP follows easily from Lemma 17 and Theorem 11. The EXP-hardness is shown
by a reduction from deciding inference œÄ |= p(t) of a ground atom p(c) from a function-free Horn logic
program œÄ with variables (i.e., a datalog program), which consists of rules of the form
p0 (t0 ) ‚Üê p1 (t1 ), . . . , pn (tn ),

n ‚â• 0,

(3)

where each pi is the name of a predicate of arity ai ‚â• 0 and ti = ti,1 , . . . , ti,n is a list of constants and
variables ti,j ; p0 (t0 ) is the head and p1 (t1 ), . . . , pn (tn ) the body of the rule.

INFSYS RR 1843-04-04

37

It holds that œÄ |= p(c) iff there is a sequence rules ri of the form pi0 (ti0 ) ‚Üê pi1 (ti1 ), . . . , pin (tin ) and
substitutions Œ∏i for ri , i.e., a mappings from the variables in ri to the set of constants CœÄ in œÄ, such that
{pi1 (ti1 Œ∏i ), . . . , pin (tin Œ∏i )} ‚äÜ {p10 (t10 Œ∏1 ), . . . , pi‚àí10 (ti‚àí10 Œ∏i‚àí1 )}, for all i ‚àà {1, . . . , m} (thus in particular, 1n = 0) and pm0 (tm0 Œ∏m ) = p(c), called a proof of p(c) from œÄ. Informally, p(c) is derived by successive
application of the rule instances r1 Œ∏1 , . . . , rm Œ∏m , like in a propositional logic program.
Deciding whether œÄ |= p(t) is well-known to be EXP-complete, cf. [13]. The construction is similar in
spirit to the one in proof of Theorem 11 but more involved.
To prove EXP-hardness of k-M AINTAINABILITY under the given restriction, we first focus on problem
1-M AINTAINABILITY, and we describe how to reduce œÄ |= p(c) in logarithmic workspace to deciding
1-maintainability of a set of states S w.r.t. a set of states E in an agent system A.
Without loss of generality, we make the following assumptions on œÄ and p(c):
‚Ä¢ The set of constants occurring in œÄ, CœÄ , is {0, 1};
‚Ä¢ each rule r in œÄ has either zero or two atoms in the body;
‚Ä¢ all rules in r are safe, i.e., each variable X occurring in the head of a rule r also occurs in the body;
‚Ä¢ œÄ uses only one predicate, p;
‚Ä¢ c = (0, 0, . . . , 0).
Any problem œÄ |= p(c) can be transformed to an equivalent one of this form in logarithmic workspace.
Similar as in the propositional case, the idea is to represent a reversed proof rm , Œ∏m , . . . , r1 Œ∏1 of p(c) from
œÄ through agent actions, and model backward rule applications through agent actions; note that m ranges
from 1 to 2ap , where ap is the arity of p (thus m requires ap bits). The problem here which makes this more
complex is the fact that we must, for each rule ri , also take Œ∏i into account. If ri has a nonempty body, the
candidates for Œ∏i are systematically generated by alternating agent and exogenous actions. For each possible
such Œ∏i , the derivation of the body atoms p(ti2 Œ∏i ) and p(ti2 Œ∏i ) is then explored.
More precisely, for each ground atom p(c), and m ‚àà {0, . . . , 2pa }, we have a state (c, m, prove) outside E
which intuitively says that p(c) is derivable within m (0 ‚â§ m ‚â§ 2pa ) steps. For each rule r in œÄ, there is
an agent action ar , which is possible on (c, m, prove) if m > 0 and p(c) unifies with the head p(t) of r,
and it results in the state (c, m, r, apply), which is in E. For r of form p(t) ‚Üê p(t1 ), p(t2 ), two phases are
now established: (1) the selection of a substitution Œ∏ for the variables X in r, and (2) the generation of states
(c1 , m‚àí1, prove) and (c1 , m‚àí1, prove), where c1 = Œ∏1 and c2 = Œ∏2 , for the recursive test.
As for 1) an exogenous action e pushes the agent from (c, m, r, apply) to a state (c, m, (0, 0, ..., 0), r, sel Œ∏).
Here (0, 0, . . . , 0) is the substitution Œ∏ : X1 = 0, . . . , Xk = 0 to all variables in r. By executing an agent
action incŒ∏ on this state, this vector is incremented to (0, 0, ..., 0, 1), resulting in a state (c, m, (0, 0, ...0, 1), r,
incŒ∏ ) in E, from which e pushes the agent to a state (c, m, (0, 0, ..., 1), r, sel Œ∏), where Xn = 1 in Œ∏. Here
again incŒ∏ is possible, leading to a state (c, m, (0, 0, ..., 1, 0), r, incŒ∏ ) in E from which e pushes the agent to
the state (m‚àí1, t, (0, 0, ...1, 0), r, sel Œ∏). Here again an inc action is possible for the agent etc.
In each state (c, m, Œ∏, r, sel Œ∏) such that p(tŒ∏) = c, the agent might alternatively take the action choose,
which brings her to the state (c, m, Œ∏, r, chosenŒ∏ ) in E, which closes phase 1. The exogenous action e
pushes the agent from this state to the state (m, t1 Œ∏, t2 Œ∏, do split) out of E. From this state, e pushes
the agent further to the state (t1 Œ∏, m‚àí1, prove), and the agent must take at (m, t1 Œ∏, t2 Œ∏, do split) the action split, which brings her to the state (t2 Œ∏, m‚àí1, goto prove) in E, from which e pushes the agent to
(t2 Œ∏, m‚àí1, prove). Figure 4 gives a summary of the steps in graphical form.

38

INFSYS RR 1843-04-04

(c, m, (0, ..., 1), r, selŒ∏ )
(c, m, prove)
...
(c, m, (0, ..., 0), r, selŒ∏ )
ar

e

incŒ∏

e

incŒ∏

...

(c, m, (0, ..., 2), r, incŒ∏ )
(c, m, r, apply)
(c, m, (0, ..., 1), r, incŒ∏ )

(t2 Œ∏, m‚àí1, prove)
(m, t1 Œ∏, t2 Œ∏, do split)
(t1 Œ∏, m‚àí1, prove)
(c, m, Œ∏, r, selŒ∏ )
choose e

incŒ∏

...

split

e

(t2 Œ∏, m‚àí1, do prove)
(c, m, Œ∏, r, chosenŒ∏ )

e

E

Figure 4: Schematic transition diagram for backward application of rule r : p(t) ‚Üê p(t1 ), p(t2 ) with
substitution Œ∏ to prove p(c).

In this way, the derivation of p(0, 0, . . . , 0) from œÄ is encoded to deciding 1-maintainability of S = {(2d ,
(0, 0, ..., 0), prove)} with respect to the set of states E described above. Note that to prove p(c) from œÄ
via rule r, only one instance of rŒ∏ must be chosen; the 1-maintaining control has to single out this Œ∏, by
proper placement of the action chosenŒ∏ . The proof of correctness is along the lines of the respective one in
Theorem 11.
Given the regular structure of the states and the easy checks and manipulations that need to be done for
determining applicability of actions and determining the successor state, respectively, it is not difficult to
see that a representation of the above 1-M AINTAINABILITY instance using state variables can be compiled
from œÄ and p(0, 0, . . . , 0) in logarithmic work space (in particular, that the polynomial-time procedures for
deciding the membership predicates in Phi (s, a, s‚Ä≤ ), in poss(s, a), in exo(s, a) in S (s), and in E (s) can
be provided in polynomial time). Note that this instance employs only deterministic actions, and there is a
single exogenous action. This establishes EXP-hardness for 1-M AINTAINABILITY.
Furthermore, for A and E as constructed, each agent action results in a state in E. Thus, k-maintainability
of S w.r.t. E in A, for any k = f (A, S, E) such that f (A, S, E) ‚â• 1, is equivalent to 1-maintainability of
S w.r.t. E in A. Hence, the reduction shows EXP-hardness of k‚àíM AINTAINABILITY under the stated
restriction.
2
Corollary 19 Under state representation by variables, œâ-M AINTAINABILITY is EXP-complete. The EXPhardness holds even if all actions are deterministic and there is only one exogenous action.
Using Theorem 18 instead of Theorem 11, we can prove the following result similarly as Theorem 13:
Theorem 20 Under state representation by variables and in absence of exogenous actions, the problems
k-M AINTAINABILITY and œâ-M AINTAINABILITY are EXP-complete.
For the case without exogenous actions and with only deterministic actions, we have lower complexity:
Theorem 21 Under state representation by variables, k-M AINTAINABILITY and œâ-M AINTAINABILITY for
systems with only deterministic actions and no exogenous actions are PSPACE-complete.
Proof. By well-known standard methods, a computation composed of a PSPACE computation A piped
into an NL computation B (which is NPSPACE in the size of the input for A) can be redesigned as an
NPSPACE computation. Since NPSPACE = PSPACE, membership of the problems in PSPACE thus
follows from Lemma 17 and Theorem 15.

INFSYS RR 1843-04-04

39

The PSPACE-hardness can be shown e.g. by a straightforward reduction from propositional STRIPS planning [9]. Rather than to introduce STRIPS here, we give for completeness sake a simple reduction from
S UCCINCT R EACHABILITY [44], which is the version of R EACHABILITY where G = (V, E) is such that
the nodes v are given by the binary vectors v = (v1 , . . . , vn ), n ‚â• 1, on {0, 1} and the problem input consists of a Boolean circuit CG with 2n inputs v1 , . . . , vn , w1 , . . . , wn which outputs true iff v ‚Üí w ‚àà E, and
s = (0, 0, . . . , 0) and t = (1, 1, . . . , 1). We construct from this an instance of k-M AINTAINABILITY resp. œâM AINTAINABILITY as follows: S = V √ó V , described by 2n binary variables f1 , . . . , f2n ; A = {inc, arc}
= Aagent ; Œ¶(v √ów, inc) = v √ów‚Ä≤ such that w‚Ä≤ = w + 1 modulo 2n , and Œ¶(v √ów, arc) = w √ó(0, 0, . . . , 0)
if v ‚Üí w in G and Œ¶(v √ó w, arc) = v √ó w otherwise; poss(s) = A, for each state s. Then, the state
s = (1, 1, . . . , ) √ó (0, 0, . . . , ) is |S|-maintainable with respect to E = {(1, 1, . . . , 1) √ó (1, 1, . . . , 1)} in
A iff (1, 1, . . . , 1) is reachable from (0, 0, . . . , 0) in G. A state variable representation of A can be easily
generated from the circuit CG in logarithmic workspace. This implies PSPACE-hardness of the problems.2
If the maintenance window is bounded by a constant, the problem is easier.
Theorem 22 Under state representation by variables, k-M AINTAINABILITY for systems without exogenous
actions and constant k ‚â• 0 is co-NP-complete.
Proof. For a given s ‚àà S, falsity of rk (s) can be proved by exhibiting (assuming s ‚àà
/ E), for each a ‚àà
Aagent ‚à© poss(s) a witness w(s, a) ‚àà S such that w(s, a) ‚àà Œ¶(s, a) and rk‚àí1 (w(s, a)) is false, which in
recursion can be proved similarly. For constant k, this leads to O(|Aagent |k ) many guesses w(s, a), which
is polynomial in the size of the input. By Lemma 14, it thus follows that deciding the complement of
k-M AINTAINABILITY is in NP. This proves membership in co-NP.
The co-NP-hardness, for every k ‚â• 0, is a simple consequence that under representation by state variables, deciding whether S ‚äÜ E is co-NP-complete (this can be shown, e.g., by a simple reduction from
propositional unsatisfiability).
2

8 Discussion and Conclusion
In this paper, we gave a formal characterization of maintenance goals and distinguished it from the notions
of stabilizability and temporal goals of the form 23f (over all valid trajectories). We present several
motivating examples that illustrate the need for our notion of maintainability. The basic idea being that
for certain kinds of maintenance it is important that the maintaining agent be given a window of noninterference from the environment so that it can do the maintenance. To formalize this we need to distinguish
between the agent‚Äôs actions and the environment‚Äôs actions. In our formalization we define the notion of kmaintainability, where k refers to the maximum window of opportunity necessary for the maintenance.
We then gave polynomial time algorithms to compute k-maintainable controls, which are linear-time for
small k, and we analyzed the complexity of determining k-maintainability under various assumptions. One
interesting aspect of our polynomial time algorithm is the approach that led to its finding: use of SAT
encoding, and complexity results regarding the special Horn sub-class of propositional logic.

8.1

Other related work

Besides the related works we already mentioned such as stabilizability and temporal logic, the notion of
maintenance has appeared in AI in many other papers. For example, in [42], Ortiz discusses maintenance
actions. His notion of maintenance is stronger than both the notion of stabilizability and our notion as he

40

INFSYS RR 1843-04-04

requires the formula that is maintained to be true throughout. The notion of maintenance is also related
to the notion of ‚Äòexecution monitoring‚Äô which is studied in the context of robot programs in [14]. In ‚Äòexecution monitoring‚Äô the world is monitored and if a discrepancy is found between the prediction made by
the agent and the real world, then new plans are made to recover from the discrepancy. A deliberative architecture for maintenance can be extrapolated from the notions in [2], where an agent executes a cycle of
observe; assimilate; (re)plan f rom current situation; execute part of the plan.
In other related work, Jensen et al. [28, 29] consider the somewhat dual problem of developing policies
that achieve a given goal while there are interferences from the environment. In their model, environment
actions and actions of multiple agents are combined to a joint action, by which the system is transferred
from the current state to one out of a set of possible successor states. With such nondeterministic transitions,
Jensen et al. aim at modeling both an adversial environment and infrequent errors which make an otherwise
deterministic action non-deterministic. In [28], they consider constructing policies coping with arbitrarily
many interferences of the environment (but without action failure) by an extension of OBDD-based universal
planning, and in [29] they consider generating policies which tolerate up to a given number n of errors
modeled as ‚Äúsecondary action effects‚Äù (caused by improper action execution or environment interference),
by reducing it to a so called strong planning problem, which is solved using OBDD based methods. For
arbitrarily many environment interferences as in [28], the problem is basically very similar to our problem
of unbounded maintainability, but interference in goal states has different significance and goal achievement
is not guaranteed because of possible loops. A formal connection between k-maintainable controls and
n-fault tolerant policies, if any, remains open. Intuitively, n-fault tolerant plans are easier to construct,
since the number of errors that have occurred can be recorded in plan construction and when the limit n is
reached, the problem boils down to an ordinary planning problem. For k-maintaining controls, however,
each environment interference (even at a goal state) causes a restart which pushes the agent to a new initial
state.
In a series of papers [54, 19, 18], Wooldridge and Dunne have formalized the problem of constructing
agent control functions and analyzed its complexity in a rich framework, for various kinds of tasks such
as ‚Äúachievement‚Äù tasks (where the agent has to bring about a certain goal condition), ‚Äúmaintenance‚Äù tasks
(where the agent has to avoid that some goal condition is ever satisfied during execution), and combinations
thereof [18]. In their framework, action effects and the selection of the agent action by the control may
depend on the history of the execution, and most importantly, exogenous actions resp. an adversary are not
taken into account. Under restriction to history-independent state transitions and reactive agents, finding
controls for achievement tasks in their framework corresponds to finding maintaining controls with an unbounded window of opportunity in our framework. Theorems 15 and 21 correspond to respective results in
the Wooldridge-Dunne framework [18].
In AI planning, the seminal STRIPS approach [23] has been one of the most influential approaches. We
briefly recall that in STRIPS, states are modeled as sets of propositional atoms and actions as operators
which, given that a precondition in terms of a conjunction of literals is true on the current state, transform
it to a successor state by removing atoms from a delete list and adding atoms from an add list. A plan for
achieving a goal, described by a conjunction of atoms Œ≥, from an initial state S0 is a sequence of operators
op1 , . . . , pn which takes the agent from S0 to a state where Œ≥ holds. STRIPS planning has been generalized
in several directions, such as conditional effects, nondeterministic actions, or planning under incomplete
information and partial observability using conditional and conformant plans, respectively, and a number of
papers has considered the computation and complexity of planning in such settings, e.g., [9, 3, 11, 22, 49].
However, like in the framework of Wooldridge and Dunne, in none of these works agent actions and exogenous actions are viewed separately, and thus they are best compared to our framework in absence of

INFSYS RR 1843-04-04

41

exogenous functions. Furthermore, plans per se are conceived as action strategies (cf. [49]) in which, in
principle, different actions might be taken by the agent if during plan execution the same state is entered
again; however, such looping is a priori excluded if the goal must be achieved under all contingencies.
Cimatti et al. [11] consider constructing universal plans akin to our policies, with different semantics for
goal achievement, based on OBDD methods and algorithms. In particular, in absence of exogenous actions
our maintaining controls correspond to what they call strong solutions for a planning problem. Jensen et al.
[28, 29] have generalized this by adversial actions (see above).
As for complexity, Theorem 21, corresponds to the classical result of Bylander [9] that deciding plan existence in propositional STRIPS is PSPACE-complete, while Theorem 20 corresponds to Littman‚Äôs result
that conditional planning for STRIPS with nondeterministic actions is EXPTIME-complete [34, 49]. In
conditional planning, via conditions on the current state branching to subplans is possible, such that an appropriate plan is followed depending on the state evolution. Branching might be modeled by actions and the
conditional planning problem, with loops disregarded, as the problem of constructing a maintaining control.
Outside of AI, our notion of k-maintenance is very closely related to the notion of self-stabilization in [15]
which is used in characterizing fault-tolerant systems. There the concern is about proving correctness of
(hand developed) self-stabilization protocols and achieving self-stabilization for various distributed algorithms such as mutual exclusion. Our algorithm here can be thought of as an algorithm that automatically
generates a self-stabilization protocol. Although, this is a new dimension to the existing work on selfstabilization, further research is needed to compare assumptions made in our formulation and the ones in
the self-stabilization literature, and overcome them. In particular, often in the self-stabilization literature
the global states are composed of local states of various distributed elements and a particular element does
not have the access to the complete global state. In those cases one can not directly use the kind of global
policies generated by the algorithm in this paper.

8.2

Future work and open issues

There are several directions for further research extending the work of this paper. One direction concerns
variations of the maintenance problem, for instance by taking action duration into account. In such scenario,
the maintenance goal may be formulated as requirement that the agent reaches some desired state always
within a given time frame, if she is not disturbed by the environment. Preliminary investigations suggest
that the results in this paper can be extended to handle this setting.
The intractability results for the problems under state variable representations challenges methods and techniques for handling the problem in practice. Suitable heuristics may therefore be researched that allow to
solve the problems in many cases in polynomial time, and, in a refined complexity analysis, meaningful
tractable cases should be singled out. Furthermore, the issue of computing optimal k-maintenance controls efficiently, in the sense that k is as small as possible (which is trivially polynomially solvable in the
enumerative setting), is an interesting issue for variable state representation.
Another issue concerns investigating computational transformations between maintenance and planning. By
the complexity results in [34] and this paper, transformations between k-M AINTAINABILITY and conditional
planning are feasible in polynomial time. It would be interesting to study different transformations, and to
assess possible benefits of these transformations for solving k-M AINTAINABILITY and planning by crossutilizing different algorithms and implementations (e.g. [11] for planning in non-deterministic domains).
In particular a transformation similar to the one in the proof of Theorem 13, with an additional parameter
that keeps count the number of agent‚Äôs actions since the last exogenous action, can4 be used to compile out
4

This transformation increases the number of states by k times. It is unknown if there exist a transformation that can eliminate

42

INFSYS RR 1843-04-04

exogenous actions and transform finding k-maintainable policies to finding strong cyclic plans [11]; on the
other hand, encodings similar to the one in Section 5.2 for obtaining strong cyclic plans through linear-time
Horn logic programming might be interesting.
Acknowledgment We would like to acknowledge W. Cushing for his feedback on an earlier draft and
S. Gupta and M. Gouda for their clarifications on self-stabilization. Furthermore, we acknowledge comments by J. Rintanen on the ICAPS‚Äô04 paper and are grateful for his pointers to related work.
The major part of the algorithms was done when Chitta Baral was visiting TU Wien in May 2003. Marcus BjaÃàreland carried out the major part of his work while he was with the Department of Computer and
Information Science of Linkoping University.

References
[1] F. Bacchus and F. Kabanza. Planning for temporally extended goals. Annals of Mathematics and Artificial
Intelligence, 22:5‚Äì27, 1998.
[2] C. Baral, M. Gelfond, and A. Provetti. Representing actions: Laws, observations, and hypothesis. Journal of
Logic Programming, 31:201‚Äì243, 1997.
[3] C. Baral, V. Kreinovich, and R. Trejo. Computational complexity of planning and approximate planning in the
presence of incompleteness. Artificial Intelligence, 122(1-2):241‚Äì267, 2000.
[4] C. Baral, V. Kreinovich, and R. Trejo. Computational complexity of planning with temporal goals. In B. Nebel,
editor, Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI-01), pages 509‚Äì
514. Morgan Kaufmann, 2001.
[5] C. Baral and T. Son. Relating theories of actions and reactive control. Electronic Transactions on Artificial
Intelligence, 2(3-4):211‚Äì271, 1998.
[6] C. Baral and J. Zhao. Goal specification in presence of non-deterministic actions. In R. L. de MaÃÅntaras and
L. Saitta, editors, Proceedings of the 16th European Conference on Artificial Intelligence (ECAI 2004), Valencia,
Spain, August 22-27, 2004, pages 273‚Äì277. IOS Press, 2004.
[7] D. Barrington, N. Immerman, and H. Straubing. On uniformity within N C 1 . J. Comput. Syst. Sci., 41:274‚Äì306,
1990.
[8] R. Brooks. A robust layered control system for a mobile robot. IEEE Journal of Robotics and Automation,
2(1):14‚Äì23, 1986.
[9] T. Bylander. The computational complexity of propositional strips planning. Artificial Intelligence, 69:165‚Äì204,
1994.
[10] S. Ceri and J. Widom. Deriving production rules for constraint maintenance. In Proceedings VLDB-90, pages
566‚Äì577, 1990.
[11] A. Cimatti, M. Pistore, M. Roveri, and P. Traverso. Weak, strong, and strong cyclic planning via symbolic model
checking. Artificial Intelligence, 147(1-2):35‚Äì84, 2003.
[12] E. Clarke, E. Emerson, and A. Sistla. Automatic verification of finite-state concurrent systems using temporal
logic specifications. ACM Transactions on Programming Languages, 8(2):244‚Äì263, 1986.
[13] E. Dantsin, T. Eiter, G. Gottlob, and A. Voronkov. Complexity and expressive power of logic programming.
ACM Computing Surveys, 33(3):374‚Äì425, 2001.
exogenous actions without increasing the number of states, and yet is able to model the notion of k-maintainability.

INFSYS RR 1843-04-04

43

[14] G. De Giacomo, R. Reiter, and M. Soutchanski. Execution monitoring of high-level robot programs. In Proc.
Conference on Principles of Knowledge Representation and Reasoning (KR-98), pages 453‚Äì465, 1998.
[15] E. Dijkstra. A theory of the learnable. Commun. ACM, 17(11):643‚Äì644, 1974.
[16] W. Dowling and J. H. Gallier. Linear-time algorithms for testing the satisfiability of propositional Horn theories.
Journal of Logic Programming, 3:267‚Äì284, 1984.
[17] M. Drummond. Situation control rules. In Proceedings First International Conference on Principles of Knowledge Representation and Reasoning (KR-89), pages 103‚Äì113, 1989.
[18] P. Dunne, M. Laurence, and M. Wooldridge. Complexity results for agent design problems. Annals of Mathematics, Computing & Teleinformatics, 1(1):19‚Äì36, 2003.
[19] P. Dunne and M. Wooldridge. , atal 2000, boston, ma, usa, july 7-9, 2000, proceedings. In C. Castelfranchi
and Y. LespeÃÅrance, editors, Proceedings 7th International Workshop on Intelligent Agents VII. Agent Theories
Architectures and Languages (ATAL), volume 1986 of Lecture Notes in Computer Science, pages 1‚Äì14. Springer,
2001.
[20] T. Eiter, W. Faber, N. Leone, and G. Pfeifer. Declarative problem-solving using the DLV system. In J. Minker,
editor, Logic-Based Artificial Intelligence, pages 79‚Äì103. Kluwer Academic Publishers, 2000.
[21] E. Emerson. Temporal and modal logics. In J. van Leeuwen, editor, Handbook of Theoretical Computer Science,
volume B, chapter 16. Elsevier Science Publishers B.V. (North-Holland), 1990.
[22] K. Erol, V. Subrahmanian, and D. Nau. Complexity, decidability and undecidability results for domainindependent planning. Artificial Intelligence, 76:75‚Äì88, 1995.
[23] R. E. Fikes and N. J. Nilsson. Strips: A new approach to the application of theorem proving to problem solving.
Artificial Intelligence, 2(3-4):189‚Äì208, 1971.
[24] M. Gelfond and V. Lifschitz. Classical negation in logic programs and disjunctive databases. New Generation
Computing, 9:365‚Äì385, 1991.
[25] M. Gelfond and V. Lifschitz. Representing action in extended logic programs. In Proceedings of the Joint International Conference and Symposium on Logic Programming (JICSLP‚Äô92), pages 559‚Äì573. MIT Press, 1992.
[26] M. L. Ginsberg. Universal planning: An (almost) universally bad idea. AI Magazine, 10(4):40‚Äì44, 1989.
[27] N. Immerman. Descriptive Complexity. Springer, 1999.
[28] R. M. Jensen, M. M. Veloso, and M. H. Bowling. Obdd-based optimistic and strong cyclic adversarial planning.
In Proceedings 6th European Conference on Planning (ECP-01), 2001.
[29] R. M. Jensen, M. M. Veloso, and R. E. Bryant. Fault tolerant planning: Toward probabilistic uncertainty models
in symbolic non-deterministic planning. In S. Zilberstein, J. Koehler, and S. Koenig, editors, Proceedings 14th
International Conference on Automated Planning and Scheduling (ICAPS 2004), Whistler, British Columbia,
Canada, June 3-7, 2004, pages 335‚Äì344, 2004.
[30] F. Kabanza, M. Barbeau, and R. St-Denis. Planning control rules for reactive agents. Artificial Intelligence,
95(1):67‚Äì113, 1997.
[31] L. P. Kaelbling and S. J. Rosenschein. Action and planning in embedded agents. In P. Maes, editor, Designing
Autonomous Agents: Theory and Practice from Biology to Engineering and Back, pages 35‚Äì48. The MIT Press:
Cambridge, MA, USA, 1990.
[32] C. Kuratowski. Topology I. Academic Press, New York, 1966.
[33] N. Leone, G. Pfeifer, W. Faber, T. Eiter, G. Gottlob, S. Perri, and F. Scarcello. The dlv system for knowledge
representation and reasoning. ACM Transactions on Computational Logic, 2004. To appear. Available via
http://www.arxiv.org/ps/cs.AI/0211004.

44

INFSYS RR 1843-04-04

[34] M. L. Littman. Probabilistic propositional planning: Representations and complexity. In Proceedings AAAI/IAAI
1997, pages 748‚Äì754, 1997.
[35] P. Maes, editor. Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back.
The MIT Press: Cambridge, MA, USA, 1990.
[36] Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems, Specification. SpringerVerlag, 1992.
[37] M. Minoux. LTUR: a simplified linear time unit resolution for Horn formulae and computer implementation.
Information Processing Letters, 29:1‚Äì12, 1988.
[38] M. Nakamura and C. Baral. Invariance, maintenance and other declarative objectives of triggers ‚Äì a formal
characterization of active databases. In J. Lloyd, V. Dahl, U. Furbach, M. Kerber, K.-K. Lau, C. Palamidessi,
L. M. Pereira, Y. Sagiv, and P. J. Stuckey, editors, Proceedings First International Conference on Computational
Logic - CL 2000, number 1861 in LNAI, pages 1210‚Äì1224. Springer Verlag, July 2000.
[39] M. Nakamura, C. Baral, and M. Bj√¶reland. Maintainability: a weaker stabilizability like notion for high level
control. In Proceedings National Conference on AI (AAAI ‚Äô00), July 30-August 3, 2000, Austin, Texas, pages
62‚Äì67. AAAI Press, 2000.
[40] I. NiemelaÃà, P. Simons, and T. SyrjaÃànen. Smodels: A system for answer set programming. In C. Baral
and M. TruszczynÃÅski, editors, Proceedings of the 8th International Workshop on Non-Monotonic Reasoning
(NMR‚Äô2000), Breckenridge, Colorado, USA, April 2000.
[41] R. Niyogi and S. Sarkar. Logical specification of goals. In Proceedings 3rd International Conference on Information Technology, pages 77‚Äì82. Tata McGraw-Hill, July 2000.
[42] C. Ortiz. A commonsense language for reasoning about causation and rational action. Artificial Intelligence,
111(2):73‚Äì130, 1999.
[43] O. Ozveren, A. Willsky, and P. Antsaklis. Stability and stabilizability of discrete event dynamic systems. J. ACM,
38(3):7300‚Äì752, 1991.
[44] C. H. Papadimitriou. Computational Complexity. Addison-Wesley, 1994.
[45] K. Passino and K. Burgess. Stability Analysis of Discrete Event Systems. John Wiley and Sons, 1998.
[46] P. Ramadge and W. Wonham. Modular feedback logic for discrete event systems. SIAM Journal of Control and
Optimization, 25(5):1202‚Äì1217, 1987.
[47] P. Ramadge and W. Wonham. Supervisory control of a class of discrete event process. SIAM Journal of Control
and Optimization, 25(1):206‚Äì230, 1987.
[48] R. Reiter. Knowledge in Action: Logical Foundation for Describing and Implementing Dynamical Systems. MIT
Press, 2001.
[49] J. Rintanen. Complexity of planning with partial observability. In S. Zilberstein, J. Koehler, and S. Koenig, editors, Proceedings 14th International Conference on Automated Planning and Scheduling (ICAPS 2004), Whistler,
British Columbia, Canada, June 3-7, 2004, pages 345‚Äì354, 2004.
[50] P. Simons, I. NiemelaÃà, and T. Soininen. Extending and implementing the stable model semantics. Artificial
Intelligence, 138:181‚Äì234, June 2002.
[51] E. Sontag. Stability and stabilization: Discontinuities and the effect of disturbances. In F. Clarke and R. Stern,
editors, Proceedings NATO Advanced Study Institute, pages 551‚Äì598. Kluwer, July 1998.
[52] D. Weld and O. Etzioni. The first law of robotics (a call to arms). In Proceedings of the Twelfth National
Conference on Artificial Intelligence (AAAI-94), pages 1042‚Äì1047. AAAI Press, 1994.
[53] J. Widom and S. Ceri, editors. Active Database Systems: Triggers and Rules For Advanced Database Processing.
Morgan Kaufmann, 1996.
[54] M. Wooldridge. The computational complexity of agent design problems. In Proceedings of the Fourth International Conference on Multi-Agent Systems (ICMAS 2000). IEEE Press, 2000.

Simplification of processing elements is greatly desired in cellular neural networks to realize ultra-large scale integration. First, we propose reducing a neuron to two-inverter two-switch circuit, two-inverter one-switch circuit, or two-inverter circuit. Next, we propose reducing a synapse only to one variable resistor or one variable capacitor. Finally, we confirm the correct workings of the cellular neural networks using circuit simulation. These results will be one of the theoretical bases to apply cellular neural networks to brain-type integrated circuits.
From: AAAI-00 Proceedings. Copyright ¬© 2000, AAAI (www.aaai.org). All rights reserved.

Maintainability: a weaker stabilizability like notion for high level control
Mutsumi Nakamura
Department of CSE
University of Texas at Arlington
Arlington, TX 76019, USA
nakamura@cse.uta.edu

Chitta Baral
Department of CSE
Arizona State University
Tempe, AZ 85287, USA
chitta@asu.edu

Abstract
The goal of most agents is not just to reach a goal state, but
rather also (or alternatively) to put restrictions on its trajectory, in terms of states it must avoid and goals that it must
‚Äòmaintain‚Äô. This is analogous to the notions of ‚Äòsafety‚Äô and
‚Äòstability‚Äô in the discrete event systems and temporal logic
community.
In this paper we argue that the notion of ‚Äòstability‚Äô is too
strong for formulating ‚Äòmaintenance‚Äô goals of an agent ‚Äì in
particular, reactive and software agents, and give examples of
such agents. We present a weaker notion of ‚Äòmaintainability‚Äô
and show that our agents which do not satisfy the stability criteria, do satisfy the weaker criteria. We give algorithms to test
maintainability, and also to generate control for maintainability. We then develop the notion of ‚Äòsupportability‚Äô that generalizes both ‚Äòmaintainability‚Äô and ‚Äòstabilizability, develop an
automata theory that distinguishes between exogenous and
control actions, and develop a temporal logic based on it.

Motivation and Introduction
Stability has undergone extensive investigations in the control theory community (Passino & Burgess 1998), both for
continuous systems (e.g. Lyapunov stability and asymptotic
stability) and Discrete Event Dynamic Systems (DEDS)
(Ramadge & Wonham 1987b; 1987a; Ozveren, Willsky, &
Antsaklis 1991). All these notions can be summarized as in
(Passino & Burgess 1998):
We say that a system is stable if when it begins in a
good state and is perturbed into any other state it will
always return to a good state.
The appropriate stability notion in a particular case depends
on how the notions ‚Äúsystem‚Äù, ‚Äúbegins‚Äù, ‚Äústate‚Äù, ‚Äúgood‚Äù, and
‚Äúperturbed‚Äù are defined, For DEDS the mainstream definition can be found in (Ozveren, Willsky, & Antsaklis 1991),
and that definition is the one we use in this paper. They also
mention that relation between stability and the notions of
safety, fairness, livelock, deadlock are well studied. In this
paper we present a related notion which we call maintainability, and argue its importance, particularly for high level
control of agents.



Copyright c 2000, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.

Marcus BjaÃàreland
Department of Comp and Info Sc
LinkoÃàping University
S-581 83 Linkoping, Sweden
marbj@ida.liu.se

Intuitively, we can view stabilizability as a hard constraint
of the system while maintainability is a softer constraint. In
both maintainability and stabilizability our goal is that the
system should be among a given set of states E as much
as possible. In stabilizability, we want a control such that
regardless of where the system is now and what exogenous
actions may happen, the system will reach one of the states
in E within a finite number of transitions and keep visiting it infinitely often after that. In maintainability, we have
a weaker requirement where the system reaches a state in
E within a finite number of transitions, provided it is not
interfered with during those transitions. Thus in maintainability, we admit that if there is continuous interference (by
exogenous actions) we can not get to E in a finite number
of transition. Such a system will not satisfy the condition of
stabilizability, but may satisfy the condition of maintainability.
Many practical closed-loop systems are not stabilizable, but
they still serve a purpose and we believe that such systems purpose can be specified by using the weaker notion
of maintainability. An example of such a system is an active
database system (Widom & Ceri 1996) where ‚Äòconsistency‚Äô
of data is ‚Äòmaintained‚Äô using active rules (also referred to
as triggers). In such a database system, external updates
are made to the database through Insert, Delete and Update
commands. But the direct result of the updates may take
the database to an inconsistent state where ‚Äòintegrity constraints‚Äô of the database may be violated. In that case, the
active part of the database triggers rules that result in additional changes to the database to bring it back to a consistent
state. Now suppose E is the set of consistent states of a
database. We can not capture the correctness of the triggers
by directly using the notions of ‚Äòstability‚Äô. That is because,
if there is a continuous stream of external updates with no
time in between for getting back to consistency, then there is
no guarantee that the database will reach a state in E within
a finite number of transitions. But we can have a different
notion of correctness of triggers, where the triggers are correct if given a window of non-interference (from external
updates) the triggers will ultimately make the database consistent. In fact that is what happens in a database system
where external updates are blocked until the triggers bring
back the database to a consistent state.

Another example is a mobile robot (Brooks 1986; Maes
1991) which is asked to ‚Äòmaintain‚Äô a state where there are
no obstacles in its front. Here, if there is a belligerent adversary that keeps on putting an obstacle in front of the robot,
then the robot can not get to a state with no obstacle in its
front. But often we will be satisfied if the robot avoids obstacle in its front when it is not continually harassed. Of
course, we would rather have the robot take a path that does
not have such an adversary, but in the absence of such a path,
it would be acceptable if it takes an available path and ‚Äòmaintains‚Äô states where there are no obstacle in front.
Other examples include agents that perform tasks based on
commands. Here, the correctness of the agent‚Äôs behavior
can be formalized as ‚Äòmaintaining‚Äô states where there are no
commands in the queue. We can not use the notion of stability because if there is a continuous stream of commands,
then there is no guarantee that the agent would get to a state
with no commands in its queue within a finite number of
transitions.
The rest of the paper is structured as follows. We first formally define the notion of stability and stabilizability. We
then introduce the notion of maintainability and compare it
with the notion of stabilizability. Next we show that the correctness of an active database can be formalized as maintainability of consistent states. We then present algorithms
to verify maintainability, and to construct controls to make a
system maintain a set of states. Finally, we develop a general
notion called supportability and show that stabilizability and
maintainability are special cases of it.

Alternatively, A is stable w.r.t. E if, for any state x 62 E ,
every infinite trajectory starting with x will lead to E in a
finite number of steps.
Definition 0.4 R(A; x) denotes the set of states that can be
reached from x in a system A.

A state x is said to be alive if d(y ) 6= ;, for all y 2 R(A; x).
(I.e., we can not reach a state y from x, where no action is
possible.)
We say A

2

Stabilizability
We now consider control and exogenous actions. The set of
control actions U is a subset of , that can be performed by
the (controlling) agent. A particular control K is a function
from X to U . The set of exogenous actions that can occur in
a state (and that are beyond the control of the agent) is given
by a function e from X to 2 , such that e(x)  d(x).

Definition 0.5 Let A = (X; ; f; d) be a system. In presence of e, U , and K , we define AK 1 , the closed loop system of A as the four-tuple (X; ; f; dK ), where dK (x) =
(d(X ) \ fK (x)g) [ e(x).
2.
Definition 0.6 Given a system A, a function e, and a set of
states E , we say S  X is stabilizable with respect to E if
there exists a control law2 K such that for all x in S , x is
alive and stable with respect to E in the closed loop system
Ak . If S = X , we say A is stabilizable with respect to E .

2

Reviewing stability and stabilizability
In this section we review the notions of stability and stabilizability adapted from the definitions in (Ozveren, Willsky,
& Antsaklis 1991).

Stability and aliveness

Definition 0.1 A system A is a 4-tuple (X; ; f; d), where
X is a finite set of states,  is a finite set of actions, d is a
function from X to 2 listing what actions may occur (or
are executable) in what state, and f is a non-deterministic
2
transition function from X and  to 2X .
Definition 0.2 A trajectory is an alternating sequence of
states and actions, and could be either a finite trajectory that
starts and ends with a state or an infinite trajectory.
A trajectory x0 ; a1 ; x1 ; a2 ; : : : ; xk ; ak+1 ; xk+1 (: : :) is said
to be consistent with a system A if:

 xk+1 2 f (xk ; ak+1 ), and
 ak+1 2 d(xk ).
2
Definition 0.3 Given a system A and a set of states E , a
state x is said to be stable in A w.r.t. E if all trajectories
consistent with A and starting from x go through a state in
E in a finite number of transitions and they visit E infinitely
often afterwards.
We say A = (X; ; f; d) is a stable system if all states in X
are stable in A w.r.t. E .
2

= (X; ; f; d) is alive if all states in X are alive.

Maintainability
Our intuition behind maintainability is that we would like
our system to ‚Äòmaintain‚Äô a formula (or a set of states where
the formula is satisfied) in presence of exogenous actions.
By ‚Äòmaintain‚Äô we mean a weaker requirement than the temporal operator always (2) where 2f means that f should
be true in all the states in the trajectory. The weaker requirement is that our system needs to get to a desired state within
a finite number of transitions provided it is not interfered in
between by exogenous actions. The question then is what
role the exogenous actions play.
Our definition of maintainability has parameters as a set of
initial states S , that the system may be initially in, a set of
desired state E , that we want to maintain, a system A and
a control law K . Our goal is to formulate when the control
law K maintains E assuming that the system is initially in
one of the states in S . We account for the exogenous actions
by defining the notion ‚Äì Closure(S; A) ‚Äì of a closure of
S with respect to A. This closure is the set of states that
the system may get into starting from S . Then we define
maintainability by requiring that the control law be such that
A more appropriate terminology would be AK;e . We use
to remain consistent with the usage in (Ozveren, Willsky, &
Antsaklis 1991).
2
It is also referred to as ‚Äòfeedback law‚Äô, ‚Äòfeedback control‚Äô or
‚Äòstate feedback‚Äô in the literature.

A

1

K

if the system is in any state in the closure and is given a
window of non-interference from exogenous actions then it
gets into a desired state.
Now a question might be that suppose the above condition
of maintainability is satisfied, and while the control law is
leading the system towards a desired state an exogenous action happens and takes the system off that path. What then?
The answer is that the state that the system will reach after
the exogenous action will be a state from the closure. Thus,
if the system is then left alone (without interference from
exogenous actions) it will be again on its way to a desired
state. So in our notion of maintainability, the control is always taking the system towards a desired state, and after any
disturbance from an exogenous action, the control again puts
the system on a path to a desired state.
We now formally define the notions of closure and maintainability.
Definition 0.7 Let A = (X; ; f; d) be a system and S
be a set of states. By Closure(S; A) we refer to the set
2
x2S R(A; x).

S

Definition 0.8 Given a system A = (X; ; f; d), a set of
control actions U  , a specification of exogenous actions e, and a set of states E , we say a set of states S is
k-maintainable with respect to E if there exists a feedback
control K such that from each state x in Closure(S; AK ),
we will get to a state in E with at most k transitions, where
each action (behind the transitions) is dictated by the control
K.
If there exists an integer n such that S is n-maintainable with
respect to E , we say S is maintainable with respect to E .
If S

= X , then we say A is maintainable with respect to E .
2

We now show that while stabilizability guarantees maintainability, the opposite is not true.
Proposition 0.1 Given a system A, if a set of states S is
stabilizable with respect to a set of states E , then S is maintainable with respect to E .
2

Proof : Suppose that a set S  X and S is stabilizable with
respect to E . Then there exists a control law K such that for
each x 2 S , x is alive and is stable with respect E .
Claim: There is a trajectory from each state x in S to a state
in E with a finite transitions.
Case 1. Suppose x 2 S . Then x is stable, therefore we can
get from x to a state in E with a finite number of transitions
dictated by K , say nx transitions.
Case 2. Suppose x 2 Closure(S; A)nS . Then there exists y 2 S such that there is a trajectory T from y which
goes through x. Since y 2 S , y is stabilizable. Thus
all trajectories consistent with A and starting from y go
through a state in E in a finite number of transitions and
they visit E infinitely often afterwards. Therefore any trajectory from y which goes through x will visit E infinitely.
Thus there must be a sub trajectory T 0 from x to a state in
E which is contained in the trajectory T from y to a state
in E through x. Through this trajectory T 0 , we can reach

from x to a state in E in a finite number of transitions dictated by K , say nx . Note that the maximum possible cardinality of Closure(S; A) is the cardinality of X . Thus it
is finite. Let n be maxfnx jx 2 Closure(S; A)g. Since
Closure(S; A) is finite, n exists (n < 1) and from all
states in Closure(S; A) we can reach a state in E within
n transitions dictated by K . Hence S is n-maintainable with
respect to E and thus S is maintainable with respect to E . 2
But the converse of the above proposition is not true. I.e.
Maintainability does not necessarily imply stabilizability.
We now show an example of a system which is maintainable but is not stabilizable.

P

Consider a system A = (X; ; f; d) with the following:
X = fs1 ; s2 ; s3 ; s4 ; s5 g,
= fa1; a2 ; a3 ; a4 ; a5 g fe1 ; e2g;

P

S

d(s1 ) = fa1g, d(s2 ) = fa2; e1 ; e2 g, d(s3 ) = fa3 g,
d(s4 ) = fa4 g, d(s5 ) = fa5 g
f (s1 ; a1 ) = fs2g, f (s2 ; a2 ) = fs4 g, f (s2 ; e1 ) = fs3 g,
f (s2 ; e2) = fs2 g, f (s3 ; a3 ) = fs4 g, f (s4 ; a4 ) = fs5 g,
f (s5 ; a5 ) = fs4g
Given E = fs4 ; s5 g, this system is maintainable, but is not
stabilizable. With the control law K , where K (si ) = ai ,
with at most 3 transitions, we can reach from any state in X
to a state in E , therefore it is maintainable. But if we consider all trajectories, at the state s2 , the exogenous action e2
can keep interfering and we might never reach from the state
s2 to a state in E . Therefore it is not stabilizable. 2
Maintainability in an active database
In this section we show how the notion of ‚Äòmaintainability‚Äô
is useful in defining the correctness of an active database.
Consider an active database with the following aspects:
 Relational Schema:

Employee(Emp#; Name; Salary; Dept#)
Dept(Dept#; Mgr#)
 Goal of the active database: Maintain Integrity constraints. I.e., Maintain the database in states where
(i) If (e; n; s; d) is a tuple in Employee then there
must be a tuple (d0 ; m0 ) in Dept such that d = d0 ;
and
(ii) If (d; m) is a tuple in Dept, then there must be
a tuple (e0 ; n0 ; s0 ; d0 ) in Employee such that d = d0
and m = e0
(In addition we may have other constraints ‚Äì which we
do not focus here ‚Äì such as each department has a single manager and each employee works in a single department.)
 Exogenous actions are of the kind: Delete (E; N; S; D)
from Employee. (The direct effect of this action is the
deletion of the tuple.)

 Triggers are of the kind:

1. For any Delete (e; n; s; d) from Employee, if (d; e) is
a tuple in Dept, delete that tuple from Dept and delete
all tuples of the form (e0 ; n0 ; s0 ; d0 ) from Employee,
where d = d0 .

To formulate the correctness of such an active database, we
can treat the triggers as control laws, as was done initially
in (Ceri & Widom 1990). The overall system operates in a
way that whenever an exogenous action occurs if it modifies
the database such that integrity constraints are violated, the
triggers (control laws) kick in and force additional changes
to the database such that it reaches a state where the integrity
constraints are satisfied. This can be formulated as maintenance of the integrity constraints.
Now, if there were a continuous stream of exogenous actions (whose direct effects were immediately reflected in the
database) then there is no guarantee that the database would
reach a state satisfying the integrity constraints within a finite number of transitions. Hence, we can not formulate this
as stabilizability.
Another important aspect of maintainability is that in reactive software systems like this, if we know that our system is k-maintainable, and each transition takes say at most
t time units, then we can implement a transaction mechanism that will regulate the number of exogenous actions al1 . This will also be useful in
lowed per unit time to be k
t
web-based transaction softwares where exogenous actions
are external interactions and the internal service mechanism
is modeled as control laws. On the other hand, given a requirement that we must allow m requests (exogenous actions) per unit time, we can work backwards to determine
the value of k , and then find a control to make the system
k-maintainable. In general, since in high level controls we
may have the opportunity to limit (say through a transaction
mechanism) the exogenous actions, we think ‚Äòmaintainability‚Äô is an important notion for high level control.

Algorithms
In this section we give two simple algorithms to verify maintainability, and to generate control for maintainability. We
will further analyze them in the full paper.

Testing maintainability

Input: A system A = (X; ; f; d), a set of states E , a set of
states S , and a control K .

Output: To find out if S is maintainable with respect to E ,
using the control K .
Algorithm:
Step 1: Compute Closure(S; AK ).
Step 2: For each
quence

x in Closure(S; AK ) compute the se-

x0 ; x1 ; : : : ; xk ; xk+1 ; : : : ; xjX j , where x0 = x, and xk+1 =
xk if xk 2 E , and xk+1 = f (xk ; K (xk )) otherwise.

Step 3: If for all x, fx0 ; : : : ; xjX j g \ E 6= ; then S is maintainable with respect to E , using the control K ; Otherwise it
is not maintainable with respect to E , using the control K .

Generating control for maintainability of a set of
states
Input: A system A
set of states S .

= (X; ; f; d), a set of states E , and a

Output: Find a control K such that S is maintainable with
respect to E , using the control K .
Algorithm:
Step 0: Sin

:= S , Sout = ;.
Step 1: While Sin 6= Sout Do.
Pick an x from Sin n Sout . Find a shortest path (or a minimal
cost path) from x to a state in E using only control actions.
If no such path exists then EXIT and return(FAIL).
Let a be the first action of that path.
Assign K (x) = a.
Sout := Sout [ fxg
Sin := Sin [ ff (x; a)g [ fx : x 2
e(X )g.
Step 2: If Sin

f (x; b); for some b 2

= Sout , return(Sout; K ).

Proposition 0.2 If the above algorithm terminates by returning S 0 and K , then: (i) S 0 = Closure(S; AK ), and (ii)
S is maintainable with respect to E , using the control K . 2
One important aspect of the above algorithm and its proof
of correctness is the requirement of picking the first action
of a shortest path or a minimal cost path. Picking the first
action of a minimal path (as normally used in the notions of
minimal plans) will not be sufficient as that may lead to cycles and the system may never reach its goal. An algorithm
based on a minimal path will have to be more complicated
so as to avoid this. On the other hand, our use of shortest
path allows us to easily enhance the control when additional
states are added to S . We then only need to consider the new
states in the closure, find shortest paths from each of these
states (say x), and have the first action as the value of K (x).
Thus our algorithm is useful in incrementally broadening the
control when the set of initial states S is broadened.
At this point we would like to point out the relation between
our work here and some research on reactive and situated
agents (Kaelbling & Rosenschein 1991). In (Kaelbling &
Rosenschein 1991), they say that in a control rule ‚Äòif c then
a‚Äô, the action a, must be the action that leads to the goal from
any situation that satisfies the condition c. The above algorithm interprets the notion of ‚Äòleading to‚Äô as the first action
of a minimal cost plan.

Supportability: a notion that generalizes
stabilizability and maintainability
In this section we generalize the notion of maintainability
and show that the notion of stabilizability is a special case

of this generalization. Our generalization is based on the
intuition that perhaps, we can allow a limited number of
exogenous actions during our so called ‚Äòwindow of noninterference‚Äô and still be able to get back to a state in E .
We refer to this general notion as supportability.
Definition 0.9 Given a system A = (X; ; f; d), a set of
agents action U  , a specification of exogenous actions
e, and a set of states E , we say a set of states S is (k,l)supportable (l  k ) with respect to E if there exists a control
law K such that for each state x in Closure(S; AK ), all
trajectories ‚Äì consistent with AK ‚Äì from x whose next k
transitions contain at most l transitions due to exogenous
actions and the rest is dictated by the control K , reach a
state in E by the k -th transition.
2
Proposition 0.3 (k; 0)-supportable is equivalent to k maintainable. (A set of states S is (k; 0)-supportable with
respect to a set of states E if and only if S is k -maintainable
with respect to E .)
Proposition 0.4 A set of states S is stabilizable iff S is
alive and there exists an integer m such that S is (m,m)supportable with respect to E .

An automata and a temporal logic for
‚Äòmaintainability‚Äô and ‚Äòsupportability‚Äô
The notion of a system defined earlier does not distinguish
between exogenous action and control action. They are both
part of . In this section we first define the notion of a 2system where we distinguish between exogenous and control actions. Using the notion of a two system we define the
notion of ‚Äòmaintained‚Äô which is analogous to the notion of
being ‚Äòstable‚Äô and related it to our earlier notion of maintainability. We then use the notion of 2-systems to define
a temporal logic that makes the distinction between transitions due to exogenous action and transitions due to control
actions.
Definition 0.10
A 2-system A is a 5-tuple (X; a ; e ; f; d), where X is a
finite set of states, a is a finite set of control actions, e
is a finite set of control events, d is a function from X to
2a [e listing what actions and events may occur (or are
executable) in what state, and f is a transition function from
X and a [ e to 2X .
2
The notion of a trajectory with respect to a 2-system remains
the same as with respect to a system, which we earlier defined in Definition 0.2.
Definition 0.11 Given a 2-system A and a set of
states E , a state x is said to be k-maintained in A
w.r.t.
E if for all trajectories of the form x =
x0 ; a1 ; x1 ; a2 ; : : : ; aj ; xj ; aj+1 ; : : : that is consistent with A
and for all i such that fai+1 ; : : : ; ai+k g  a , we have that
fxi+1 ; : : : ; xi+k g \ E =
6 ;.
A 2-system A = (X; a ; e ; f; d) is k-maintained with respect to E if all its states are k-maintained.

A 2-system A = (X; a ; e ; f; d) is maintained with respect to E if there exists a positive integer n such that it is
n-maintained with respect to E .
2

Proposition 0.5 A state x is k-maintainable in a system
A = (X; a [ e ; f; d) with respect to E iff there exists
a control law K such that x is k-maintained with respect to
E in the 2-system AK = (X; a ; e ; f; dK ), where dK is
as defined earlier in Definition 0.5.

A temporal language with respect to 2-systems
In the past, temporal logic has been used to specify and verify the behavior of reactive systems (Manna & Pnueli 1992;
Clarke, Emerson, & Sistla 1986; Kabanza, Barbeau, & StDenis 1997). Most of these temporal logics do not (perhaps
with the exception of one description in (Singh 1994)) distinguish between transitions due to control actions and due
to exogenous actions. Hence, they are too strong to be able
to characterize the correctness of reactive software systems
such as an active database system. In this section we propose a temporal language that makes a distinction between
transitions due to control actions and exogenous actions and
is able to characterize correctness of reactive software systems such as an active database system. We plan to elaborate
on this in the full paper.
Some of the important future temporal operators as discussed in (Manna & Pnueli 1992) are: Next (), Always
(2), Eventually (), and Until (U ). There meaning with respect a trajectory  = x0 ; a1 ; x1 ; : : : ; xj ; aj +1 ; xj +1 ; : : : is
defined as follows:

 (; j ) j= p iff p is true in xj .

 (; j ) j= p iff (; j + 1) j= p

 (; j ) j= 2p iff (; k ) j= p, for all k  j .

 (; j ) j= p iff (; k ) j= p, for some k  j .
 (; j ) j= p U q iff there exists k 
and for all i, j  i < k , (; i) j= p.

j such that (; k) j= q

It is easy to see that none of the above temporal operators
consider the action type (whether exogenous or control action) behind the transitions. We now introduce some temporal operators that do consider the action type behind the
transitions.

 (; j ) j= k p iff
fai+1 ; : : : ; ai+k g 
r  k.

i  j is the smallest index such that
a and (; i + r) j= p, for some 1 

 (; j ) j= 2k p iff for all i  j if fai+1 ; : : : ; ai+k g 
then (; i + r) j= p for some 1  r  k .

a

 (; j ) j= k;l p iff i  j is the smallest index such that
jfai+1 ; : : : ; ai+k g \ e j  l and (; i + r) j= p for some
1  r  k.
 (; j ) j= 2k;l p iff for all i  j if
jfai+1 ; : : : ; ai+k g \ e j  l then (; i + r) j=
1  r  k.

p for some

We can describe the intuitive meaning behind the above
formal definitions as follows: Intuitively, (; j ) j= 2k p
means that starting from xj , within or after any k consecutive transitions due to control actions p holds. Similarly,
(; j ) j= 2k;l p means that starting from xj , within or after
any k transitions with at most l exogenous actions p holds.

Proposition 0.6 (i) (; j ) j= 2k p iff (; j ) j= 2k;0 p.
(ii) (; j ) j= k p iff (; j ) j= k;0 p.

(iii) Let Ep be the set of states, where a formula p holds. S
is (k; l)-supportable w.r.t. Ep iff for all trajectories  whose
x0 2 S , and for all j , (; j ) j= 2k;l p.
2

Corollary 0.7 1. Let Ep be the set of states, where a formula p holds. S is k maintainable w.r.t. Ep iff for all trajectories  whose x0 2 S , and for all j , (; j ) j= 2k p.
2. Let Ep be the set of states, where a formula p holds. S
is stabilizable w.r.t. Ep iff S is alive and there exists an m
such that for all trajectories  whose x0 2 S , and for all j ,
(; j ) j= 2m;m p.

Conclusion and related work
In this paper we formalized the notion of ‚Äòmaintenance‚Äô often mentioned (Baral & Son 1998) in the context of robots
and agents, as a property of a discrete event dynamic system (DEDS) and compared it with the notion of ‚Äòstability‚Äô
and ‚Äòstabilizability‚Äô that are most popular in DEDS. We argued why ‚Äòmaintainability‚Äô may be a more preferred notion
for certain systems and discussed active database systems
as an example. We then gave simple algorithms for testing
maintainability and generating control for maintainability.
We then developed the notion of ‚Äòsupportability‚Äô that generalizes both ‚Äòmaintainability‚Äô and ‚Äòstabilizability. Finally, we
developed an automata theory that distinguishes between exogenous and control actions, and developed a temporal logic
based on it. Our basic formulation of ‚Äòmaintainability‚Äô is related to the work in (Baral & Son 1998).
Among the other related works, there has been some work
on defining stability of continuous systems in the presence
of discontinuities and disturbances; for example (Sontag
1999). In the planning literature there has been some work
on planning for temporal goals (Bacchus & Kabanza 1998;
Weld & Etzioni 1994) where goals are expressed as temporal formulas. But they use the traditional temporal operators which by themselves can not express our notion of
‚Äòmaintenance‚Äô. Another related notion is planning from the
current situation in a dynamic domain (Baral, Gelfond, &
Provetti 1997) and execution monitoring (DeGiacomo, Reiter, & Soutchanski 1998). In both these notions ‚Äòmaintenance‚Äô is achieved by monitoring (or observing) the world
for discrepancies and making new plans to recover. Finally, the notion of ‚Äòself-stabilization‚Äô (Dijkstra 1974) in distributed and fault-tolerant computing seems to be similar to
our notion of ‚Äòmaintenance‚Äô and we plan to compare and
contrast them in the sequel.

References
Bacchus, F., and Kabanza, F. 1998. Planning for temporally extended goals. Annals of Math and AI 22:5‚Äì27.
Baral, C., and Son, T. 1998. Relating theories of actions
and reactive control. Electronic transactions on Artificial
Intelligence 2(3-4).

Baral, C.; Gelfond, M.; and Provetti, A. 1997. Representing Actions: Laws, Observations and Hypothesis. Journal
of Logic Programming 31(1-3):201‚Äì243.
Brooks, R. 1986. A robust layered control system for a
mobile robot. IEEE journal of robotics and automation
14‚Äì23.
Ceri, S., and Widom, J. 1990. Deriving production rules
for constraint maintainance. In VLDB 90. 566‚Äì577.
Clarke, E.; Emerson, E.; and Sistla, A. 1986. Automatic
verification of finite-state concurrent systems using temporal logic specifications. ACM Transactions on Programming Languages and Systems 8(2):244‚Äì263.
DeGiacomo, G.; Reiter, R.; and Soutchanski, M. 1998. Execution monitoring of high-level robot programs. In Proc.
of KR 98, 453‚Äì464.
Dijkstra, E. W. 1974. Self-stabilizing systems in spite of
distributed control. CACM 17(11):843‚Äì644.
Kabanza, F.; Barbeau, M.; and St-Denis, R. 1997. Planning control rules for reactive agents. Artificial Intelligence
5(1):67‚Äì113.
Kaelbling, L., and Rosenschein, S. 1991. Action and planning in embedded agents. In Maes, P., ed., Designing Autonomous Agents. MIT Press. 35‚Äì48.
Maes, P., ed. 1991. Designing Autonomous Agents.
MIT/Elsevier.
Manna, Z., and Pnueli, A. 1992. The temporal logic of
reactive and concurrent systems: specification. Springer
Verlag.
Ozveren, O.; Willsky, A.; and Antsaklis, P. 1991. Stability and stabilizability of discrete event dynamic systems.
JACM 38(3):730‚Äì752.
Passino, K., and Burgess, K. 1998. Stability Analysis of
Discrete Event Systems. Adaptive and Learning Systems
for Signal Processing, Communications, and Control. New
York: John Wiley and Sons, Inc.
Ramadge, P., and Wonham, W. 1987a. Modular feedback
logic for discrete event systems. SIAM Journal of Control
and Optimization 25(5):1202‚Äì1217.
Ramadge, P., and Wonham, W. 1987b. Supervisory control of a class of discrete event process. SIAM Journal of
Control and Optimization 25(1):206‚Äì230.
Singh, M. 1994. Multiagent systems - a theoretical
framework for intentions, know-how, and communications.
Springer-Verlag.
Sontag, E. 1999. Stability and stabilization: Discontinuities and the effect of disturbances. In Clarke, F., and Stern,
R., eds., Proc. NATO advanced study institute, July/Aug
1998. Kluwer. 551‚Äì598.
Weld, D., and Etzioni, O. 1994. The first law of robotics (a
call to arms). In AAAI, 1042‚Äì1047.
Widom, J., and Ceri, S., eds. 1996. Active Database Systems - Triggers and Rules for advanced database processing. Morgan Kaufmann.

Collaborative Curation of Data from Bio-medical Texts
and Abstracts and its integration
Chitta Baral, Hasan Davulcu, Mutsumi Nakamura, Prabhdeep Singh, Luis Tari, and
Lian Yu
Department of Computer Science and Engineering,
Arizona State University,
PO Box 878809, Tempe, AZ 85287-8809, USA
{chitta,hdavulcu,mutsumi,prabhdeep,luis.tari,lianyu}@asu.edu

Abstract. We propose an inexpensive and scalable approach for curation that
takes advantage of automatic information extraction methods as a starting point,
and is based on the premise that if there are a lot of articles, then there must be
a lot of readers and authors of these articles. Thus we provide a mechanism by
which the readers of the articles can participate and collaborate in the curation
of information.

1 Introduction
Besides the data that exists in various public and private databases, there is a much
larger and ever increasing amount of information buried in existing biomedical articles. It is beyond human ability to read the various relevant articles and recall relevant
findings of these articles for further research. Therefore, it becomes clear that the
findings in these articles have to be culled and stored in a database such that the data
can be integrated with other existing databases. The sheer volume of the articles and
their constant growth makes it prohibitively expensive to employ (and monetarily
compensate) human curators to read through the articles and cull the necessary knowledge/data buried in them. Nevertheless, such human curation (see for example [1,37,21]) has been tried for specific domains. Due to the issue of cost, many of the curated databases are proprietary with limited coverage.
In recent years an alternative approach of using automatic text extraction systems
[2,8-20] has been proposed. Although good progress has been made in this area, the
systems are not fool-proof. They at times infer incorrect information or miss out important information. Moreover, most existing systems focus on simpler data forms,
such as identifying gene or protein names, simple interactions without context. Sometimes such simplicity may lead to inconsistency.
In this paper we propose a solution to the problem of curating information from the
large and growing body of biomedical texts and abstracts. We propose a methodology
where the community collaboratively contributes to the curation process. We use
automatic information extraction methods as a starting point, and promote mass col-

laboration with the premise that if there are a lot of articles, then there must be a lot of
readers and authors of these articles.

2 CBioC System Architecture
The two main components of our CBioC system are (i) the CBioC interface and (ii)
the CBioC database. The user interacts with the CBioC system through the CBioC
interface. When a user views a PubMed article, the CBioC interface is automatically
invoked to display all the extracted interaction data relevant to the article. The user
curates the extracted interaction data through voting. Depending on the access level,
an user can also enter or modify data.
The CBioC interface has many subcomponents such as the automatic invocation
component, the user and access management component, and the voting and other
interactions component. Two auxiliary components of the system are (a) a suite of
automated text extraction systems and (b) a data exchange system. The text extraction
systems are used to automatically extract data from texts and abstracts and the data
exchange system is used to download relevant data from existing databases (such as
[7,9-13] ) and convert them to our format. This is illustrated in Figure 1 below.

Fig. 1. Functional architecture of the CBioC System
We now illustrate the use of the CBioC system which also further illuminates on the
architecture of the CBioC system.
Installation and Invocation: An important goal of ours is to make it easier for a researcher to participate in the collaborative curation. For that a researcher has to

download our system and install it in her computer. Once the system is installed it
watches the researcher's access of the web through Internet Explorer windows. Whenever the researcher accesses a web page from where she can access an article or an
abstract, the CBioC system is invoked and an interaction frame is created, as shown
below in Figure 2.

Fig.2.

Automatic triggering of CBioC interaction frame

System Implementation: From the implementation angle, the CBioC system consists of three main parts: (i) Web forms and connection to database; (ii) WebBand and
Browser Helper components, and (iii) Connector to Interaction Extractor, and is currently implemented for Internet Explorer in the client side and Linux-MySQL-Php on
the server side. This is illustrated in Figure 3 below.

Fig. 3

Implementation Architecture of CBioC System

Acknowledgement: Deepthi, Toufeeq, Haishan, Luping, Ning, Drs. Kambhampati,
Das, Berens, Fukuda, Bittner, and Gaasterland and, NSF grant 0412000.

References
[1] Bader, G.D., Donaldson, I., Wolting, C., Ouellette, B.F., Pawson, T., and Hogue, C.W.
(2001) BIND-The biomolecular interaction Netwoek database. Nucleic Ac. R. 29, 242-245.
[2] Rzhetsky, A. et al. (2004) Geneways: a system for extracting, analyzing, visualizing, and
integrating molecular pathway data. Journal of Biomedical Informatics 27, 43-53.
[3] Stein, Lincoln (2002), Creating a bioinformatics nation, Nature, 417, 119-120.
[4] Xenarios, I. and Eisenberg, D. (2001) Protein interacting databases. Current Opinion in
Biotechnology. 12, 334-339.
[5] KEGG: Kyoto Encyclopedia of Genes and Genomes,
http://www.genome.jp/kegg/
[6] BIND: Interaction Network Database, http://www.bind.ca
[7] HPRD: Human Protein Reference Database, http://www.hprd.org/
[8]Fukuda, K., Tamura, A., Tsunoda, T., and Takagi, T. (1998) Toward information extraction: identifying protein names from biological papers. PSB 1998, 707-718
[9] Tanabe, L. and Wilbur, W.J. (2002) Tagging gene and protein names in biomedical text.
Bioinformatics. 2002 Aug;18(8):1124-1132.
[10] Blaschke, C., Andrade, M.A., Ouzounis, C., and Valencia, A. (1999) Automatic extraction
of biological information from scientific text: protein-protein interactions. Proceedings of
the International Conference on Intelligent System Molecular Biology. 1999, 60-67.
[11] Ono, T., Hishigaki, H., Tanigami, A., and Takagi, T. (2001) Automated extraction of
information on protein-protein interactions from the biological literature. Bioinformatics.
2001 Feb;17(2):155-561.
[12] Novichkova, S., Egorov, S., and Daraselia, N. (2003) MedScan, a natural language processing engine for MEDLINE abstracts. Bioinformatics. 2003 September. 19(13), 1699-1706
[13] Friedman, C., Kra, P., Yu, H., Krauthammer, M., Rzhetsky, A. (2001) GENIES: a natural-language processing system for the extraction of molecular pathways from journal articles. Bioinformatics. 2001, 17 Suppl 1:S74-82.
[14] Rzhetsky, A., Iossifov, I., Koike, T., Krauthammer, M., Kra, P., Morris, M., Yu, H., Duboue, P.A., Weng, W., Wilbur, W.J., Hatzivassiloglou, V., and Friedman, C. (2004) GeneWays: a system for extracting, analyzing, visualizing, and integrating molecular pathway
data. J Biomed Inform. 2004 February, 37(1), 43-53.
[15] Corney, D.P., Buxton, B.F., Langdon, W.B., and Jones, D.T. (2004) BioRAT: extracting
biological information from full-length papers. Bioinformatics. 2004 November 22, 20(17),
3206-3213. Epub 2004 Nov 22.
[16] Temkin, J.M. and Gilder, M.R. (2003) Extraction of protein interaction information from
unstructured text using a context-free grammar. Bioinf. 2003 Nov 1, 19(16), 2046-2053.
[17] Chiang, J.H., Yu, H.C., and Hsu, H.J. (2004) GIS: a biomedical text-mining system for
gene information discovery. Bioinformatics. 2004 Jan 1, 20(1), 120-121.
[18] Craven, M. and Kumlien, J. (1999) Constructing biological knowledge bases by extracting
information from text sources. Proceedings of International Conference on Intelligent System Molecular Biology. 1999, 77-86.
[19] Bunescu, R., Ge, R., Kate, R.K., Marcotte, E.M., Mooney, R.J., Ramani, A.K., and Wong,
Y.W. (2004) Comparative Experiments on Learning Information Extractors for Proteins and
their Interactions. Journal Artificial Intelligence in Medicine 2004.
[20] Ding, J., Berleant, D., Xu, J., and Fulmer, A. (2003) Extracting biochemical interactions
from MEDLINE using a link grammar parser. In Proceedings of the 15th IEEE International Conference on Tools with Artificial Intelligence (ICTAI‚Äô03), 467. IEEE Computer
Society, 2003.
[21] www.biocurator.org

Collaborative Curation of Data from Bio-medical Texts
and Abstracts and its integration
Chitta Baral, Hasan Davulcu, Mutsumi Nakamura, Prabhdeep Singh, Luis Tari, and
Lian Yu
Department of Computer Science and Engineering,
Arizona State University,
PO Box 878809, Tempe, AZ 85287-8809, USA
{chitta,hdavulcu,mutsumi,prabhdeep,luis.tari,lianyu}@asu.edu

Abstract. We propose an inexpensive and scalable approach for curation that
takes advantage of automatic information extraction methods as a starting point,
and is based on the premise that if there are a lot of articles, then there must be
a lot of readers and authors of these articles. Thus we provide a mechanism by
which the readers of the articles can participate and collaborate in the curation
of information.

1 Introduction
Besides the data that exists in various public and private databases, there is a much
larger and ever increasing amount of information buried in existing biomedical articles. It is beyond human ability to read the various relevant articles and recall relevant
findings of these articles for further research. Therefore, it becomes clear that the
findings in these articles have to be culled and stored in a database such that the data
can be integrated with other existing databases. The sheer volume of the articles and
their constant growth makes it prohibitively expensive to employ (and monetarily
compensate) human curators to read through the articles and cull the necessary knowledge/data buried in them. Nevertheless, such human curation (see for example [1,37,21]) has been tried for specific domains. Due to the issue of cost, many of the curated databases are proprietary with limited coverage.
In recent years an alternative approach of using automatic text extraction systems
[2,8-20] has been proposed. Although good progress has been made in this area, the
systems are not fool-proof. They at times infer incorrect information or miss out important information. Moreover, most existing systems focus on simpler data forms,
such as identifying gene or protein names, simple interactions without context. Sometimes such simplicity may lead to inconsistency.
In this paper we propose a solution to the problem of curating information from the
large and growing body of biomedical texts and abstracts. We propose a methodology
where the community collaboratively contributes to the curation process. We use
automatic information extraction methods as a starting point, and promote mass col-

laboration with the premise that if there are a lot of articles, then there must be a lot of
readers and authors of these articles.

2 CBioC System Architecture
The two main components of our CBioC system are (i) the CBioC interface and (ii)
the CBioC database. The user interacts with the CBioC system through the CBioC
interface. When a user views a PubMed article, the CBioC interface is automatically
invoked to display all the extracted interaction data relevant to the article. The user
curates the extracted interaction data through voting. Depending on the access level,
an user can also enter or modify data.
The CBioC interface has many subcomponents such as the automatic invocation
component, the user and access management component, and the voting and other
interactions component. Two auxiliary components of the system are (a) a suite of
automated text extraction systems and (b) a data exchange system. The text extraction
systems are used to automatically extract data from texts and abstracts and the data
exchange system is used to download relevant data from existing databases (such as
[7,9-13] ) and convert them to our format. This is illustrated in Figure 1 below.

Fig. 1. Functional architecture of the CBioC System
We now illustrate the use of the CBioC system which also further illuminates on the
architecture of the CBioC system.
Installation and Invocation: An important goal of ours is to make it easier for a researcher to participate in the collaborative curation. For that a researcher has to

download our system and install it in her computer. Once the system is installed it
watches the researcher's access of the web through Internet Explorer windows. Whenever the researcher accesses a web page from where she can access an article or an
abstract, the CBioC system is invoked and an interaction frame is created, as shown
below in Figure 2.

Fig.2.

Automatic triggering of CBioC interaction frame

System Implementation: From the implementation angle, the CBioC system consists of three main parts: (i) Web forms and connection to database; (ii) WebBand and
Browser Helper components, and (iii) Connector to Interaction Extractor, and is currently implemented for Internet Explorer in the client side and Linux-MySQL-Php on
the server side. This is illustrated in Figure 3 below.

Fig. 3

Implementation Architecture of CBioC System

Acknowledgement: Deepthi, Toufeeq, Haishan, Luping, Ning, Drs. Kambhampati,
Das, Berens, Fukuda, Bittner, and Gaasterland and, NSF grant 0412000.

References
[1] Bader, G.D., Donaldson, I., Wolting, C., Ouellette, B.F., Pawson, T., and Hogue, C.W.
(2001) BIND-The biomolecular interaction Netwoek database. Nucleic Ac. R. 29, 242-245.
[2] Rzhetsky, A. et al. (2004) Geneways: a system for extracting, analyzing, visualizing, and
integrating molecular pathway data. Journal of Biomedical Informatics 27, 43-53.
[3] Stein, Lincoln (2002), Creating a bioinformatics nation, Nature, 417, 119-120.
[4] Xenarios, I. and Eisenberg, D. (2001) Protein interacting databases. Current Opinion in
Biotechnology. 12, 334-339.
[5] KEGG: Kyoto Encyclopedia of Genes and Genomes,
http://www.genome.jp/kegg/
[6] BIND: Interaction Network Database, http://www.bind.ca
[7] HPRD: Human Protein Reference Database, http://www.hprd.org/
[8]Fukuda, K., Tamura, A., Tsunoda, T., and Takagi, T. (1998) Toward information extraction: identifying protein names from biological papers. PSB 1998, 707-718
[9] Tanabe, L. and Wilbur, W.J. (2002) Tagging gene and protein names in biomedical text.
Bioinformatics. 2002 Aug;18(8):1124-1132.
[10] Blaschke, C., Andrade, M.A., Ouzounis, C., and Valencia, A. (1999) Automatic extraction
of biological information from scientific text: protein-protein interactions. Proceedings of
the International Conference on Intelligent System Molecular Biology. 1999, 60-67.
[11] Ono, T., Hishigaki, H., Tanigami, A., and Takagi, T. (2001) Automated extraction of
information on protein-protein interactions from the biological literature. Bioinformatics.
2001 Feb;17(2):155-561.
[12] Novichkova, S., Egorov, S., and Daraselia, N. (2003) MedScan, a natural language processing engine for MEDLINE abstracts. Bioinformatics. 2003 September. 19(13), 1699-1706
[13] Friedman, C., Kra, P., Yu, H., Krauthammer, M., Rzhetsky, A. (2001) GENIES: a natural-language processing system for the extraction of molecular pathways from journal articles. Bioinformatics. 2001, 17 Suppl 1:S74-82.
[14] Rzhetsky, A., Iossifov, I., Koike, T., Krauthammer, M., Kra, P., Morris, M., Yu, H., Duboue, P.A., Weng, W., Wilbur, W.J., Hatzivassiloglou, V., and Friedman, C. (2004) GeneWays: a system for extracting, analyzing, visualizing, and integrating molecular pathway
data. J Biomed Inform. 2004 February, 37(1), 43-53.
[15] Corney, D.P., Buxton, B.F., Langdon, W.B., and Jones, D.T. (2004) BioRAT: extracting
biological information from full-length papers. Bioinformatics. 2004 November 22, 20(17),
3206-3213. Epub 2004 Nov 22.
[16] Temkin, J.M. and Gilder, M.R. (2003) Extraction of protein interaction information from
unstructured text using a context-free grammar. Bioinf. 2003 Nov 1, 19(16), 2046-2053.
[17] Chiang, J.H., Yu, H.C., and Hsu, H.J. (2004) GIS: a biomedical text-mining system for
gene information discovery. Bioinformatics. 2004 Jan 1, 20(1), 120-121.
[18] Craven, M. and Kumlien, J. (1999) Constructing biological knowledge bases by extracting
information from text sources. Proceedings of International Conference on Intelligent System Molecular Biology. 1999, 77-86.
[19] Bunescu, R., Ge, R., Kate, R.K., Marcotte, E.M., Mooney, R.J., Ramani, A.K., and Wong,
Y.W. (2004) Comparative Experiments on Learning Information Extractors for Proteins and
their Interactions. Journal Artificial Intelligence in Medicine 2004.
[20] Ding, J., Berleant, D., Xu, J., and Fulmer, A. (2003) Extracting biochemical interactions
from MEDLINE using a link grammar parser. In Proceedings of the 15th IEEE International Conference on Tools with Artificial Intelligence (ICTAI‚Äô03), 467. IEEE Computer
Society, 2003.
[21] www.biocurator.org

Genomic Information Retrieval through Selective Extraction and
Tagging by the ASU-BioAI Group
Lian Yu, Syed Toufeeq Ahmed, Graciela Gonzalez, Brandon Logsdon, Mutsumi Nakamura, Shawn
Nikkila, Kalpesh Shah, Luis Tari, Ryan Wendt, Amanda Zeigler, Chitta Baral
Department of Computer Science and Engineering,
Arizona State University,
PO Box 878809,
Tempe, AZ 85287-8809, USA
ABSTRACT
In this paper we describe the approach used by the Arizona
State University BioAI group for the ad-hoc retrieval task of
the TREC Genomics Track 2005. We pre-process TREC
query expression by adding the synonyms of genes,
diseases, bio-processes, functions of organs, and selectively
adding stemming verbs, nouns, and Mesh Heading
categories. The pre-processed queries are used to perform
initial search on the TREC Genomics collection of MEDLINE
abstracts and produce a set of target abstracts using Apache
Lucene. Tagging, anaphor resolution and fact extraction are
performed on the target abstracts to refine the search results
in terms of relevance. Finally, we rank the target abstracts
according to the extracted facts, distance between terms and
terms appeared in the query.

1

INTRODUCTION

The BioAI Research Group of the Fulton School of
Engineering in Arizona State University participated in the
Ad-hoc Retrieval Task of the TREC (Text Retrieval
Conference) Genomics Track in 2005. Provided were a set
of retrieval queries collected from biologists that conformed
to a set of generic topic templates (GTTs). There are 5
GTTs, each of which has 10 instances, for a total of 50
topics. Following is a list of the 5 GTTs listed as given,
(available at http://ir.ohsu.edu/genomics/2005protocol.html)
with the semantic types in each GTT underlined:
1. Find articles describing standard methods or protocols
for doing some sort of experiment or procedure.
2. Find articles describing the role of a gene involved in
a given disease.
3. Find articles describing the role of a gene in a specific
biological process.
4. Find articles describing interactions (e.g., promote,
suppress, inhibit, etc.) between two or more genes in
the function of an organ or in a disease.
5. Find articles describing one or more mutations of a
given gene and its biological impact.
The dataset for the TREC 2005 Genomics Track consists
of completed citations from the MEDLINE database
*

To whom correspondence should be addressed.

inclusive from 1994 to 2003. Records were extracted using
the Date Completed (DCOM) field for all references in the
range of 19940101 - 20031231. This provided a total of
4,591,008 records, which is about one third of the full
MEDLINE database. The subset of articles provided by
TREC is available in the "MEDLINE" format, which
consists of ASCII text with fields indicated and delimited by
different 2-4 character abbreviations.
The aim for our first participation in the TREC Genomics
Track was to provide an efficient approach to retrieve most
relevant abstracts from the subset regarding to the queries.
We found that about 25% of MEDLINE records do not have
an abstract, mainly because the article itself does not have
one. We focused our retrieval task on the remaining 75%,
giving us close to 3.5 million abstracts. A guiding principle
for us was that relevance of a topic should not be just based
on individual terms or keywords, such as genes or diseases,
but rather it should take into account the subject of the
whole document. In order to implement this principle, we
would first parse the abstract to identify complete facts: the
right semantic terms plus the right relationship among them,
as specified in the query topic. We would extract those facts
as a whole, noting that they might appear more than once in
the abstract, and then take both fact and term frequency into
consideration when ranking the abstracts for relevance.
The idea was that if we could extract all relevant facts
from each abstract, we would just need to search among
those extracted facts for those closely related to the query
(rank) and return results. However, we needed to process a
large volume of abstracts within a limited time in order to
submit experiment results on time. We decided to retrieve a
set of potential target abstracts from the given dataset using
the given query topics, and then apply the extraction and
ranking schema on that reduced set.
We choose Apache Lucene [1] to perform the initial
retrieval. Apache Lucene is a high-performance, fullfeatured text search engine library written in Java. It is a
technology suitable for an application that requires full-text
search, especially cross-platform. Apache Lucene is an open
source project available from Apache Jakarta. Figure 1
shows the architecture of our approach:

1

Lian Yu et al.

1. Pre-processing queries: To apply Lucene in the
biomedical domain, we needed to first incorporate
bio-domain knowledge into the Lucene queries. For
example, we needed to pre-process each of the 50
queries by adding synonyms, alias, and acronyms to
genes, diseases, bio-processes, and functions of
organs, as well Mesh categories information.
2. Indexing: uses Lucene indexing APIs to create a
comprehensive index of terms on about 3.4 million of
the given subset of MEDLINE abstracts.
3. Retrieval of target abstracts: uses a batch queryprocess Java program to input each pre-processed
query topic and output a list of PubMed IDs (hereafter
called PMIDs) associated to it. The size of target
abstracts is narrowed down to 12K MEDLINE
abstracts through this process.

4. Tagging: tags entities such as genes and diseases to
facilitate anaphor resolution and fact extraction.
5. Resolving Anaphors: resolves pronouns of genes,
diseases, and bio-processes so that the text extraction
tool can extract facts of interest.
6. Fact extraction: extracts facts in terms of the relation
identified from the queries.
7. Ranking of abstracts: we define a formula which takes
the fact frequency, the distance of terms, as well as
terms frequency into consideration.
In the following section, we expand on each step in this
process. In Section 3 we describe the evaluation of our
approach. In Section 4 we sketch future research
directions.

Fig. 1. Architecture of the Ad-hoc Retrieval System
Gene 1 or MeSH 2 , respectively. Entrez Gene [6] is a gene
database from NCBI and MeSH [4] (short for Medical
2 INFORMATION RETRIEVAL SYSTEM
Subject Headings) is an ontology of terms used for
2.1 Pre-process Queries
categorizing articles in PubMed [6]. Both Entrez Gene and
Query pre-processing can be divided into three phases:
MeSH provide flat files available at their FTP sites. For
synonym matching, stemming and fine tuning. Both the
topics that involve biological processes and functions, a
synonym matching and stemming phases are automatic,
selected set of terms from MeSH is used with their
while the fine tuning phase is manually done based on the
corresponding synonyms.
topics and the number of abstracts retrieved. We elaborate
Synonyms are grouped by ‚ÄúOR‚Äù Boolean operator and
on each of them below. Since we use Lucene as our
groups of synonyms are connected with ‚ÄúAND‚Äù Boolean
indexing system, the queries follow the Lucene syntax.
operator. For instance, suppose g is a gene name, and g1 and
g2 are synonyms of g, and d is a disease name while d1 is a
2.1.1 Synonym Matching
synonym of d. Then the query formed would be:
Given a list of words provided by TREC for each topic,
(g OR g1 OR g2) AND (d OR d1)
synonym matching automatically checks if the given word
is a gene or a disease. If it is either of the two, all of the
corresponding synonyms are extracted from either Entrez
1
2

2

ftp://ftp.ncbi.nlm.nih.gov/gene/
http://www.nlm.nih.gov/mesh/filelist.html

Genomic Information Retrieval through Selective Extraction and Tagging by the ASU-BioAI Group

2.1.2 Stemming
Words that are not identified as genes or diseases are
stemmed using the Porter Stemming algorithm [9], which
returns the root form of a word. A wildcard is attached to
each stemmed word to form the query. For instance, the
word ‚Äúprogression‚Äù is stemmed as ‚Äúprogress‚Äù and
‚Äúprogress*‚Äù is formed as part of the query.

2.1.3 Fine-Tuning
Queries formed by the previous two phases can result in a
large number of relevant abstracts for some of the topics.
Furthermore, our queries have to reflect the specific needs
of TREC. Therefore, it is insufficient to have the keywords
and their synonyms as part of the queries. It is necessary to
add extra information to the queries. For example, in the
case of topic 110, we are interested in the role of interferonbeta gene in Multiple Sclerosis. Using ‚Äúinterferon-beta‚Äù,
‚Äúmultiple sclerosis‚Äù and their corresponding synonyms as a
query would retrieve articles that used interferon-beta as a
treatment, which is not of our interest.
The fine tuning approach differs in the various templates.
In template 1 about methods and protocols, if the given
keywords appear in MeSH, the query is modified so that the
keywords must appear as the MeSH heading of the
abstracts. MeSH headings act as categories of the articles.
For instance, in topic 100, electroporation is a MeSH
heading, so the query for topic 100 contains ‚ÄúMH ‚Äì
electroporation‚Äù to make use of the MedLine format of the
abstracts. The query for topic 100 is formed as follows in
Lucene syntax:
"MH \- Electroporation" AND "cell" AND
"open"

For template 2 regarding the role of genes in diseases,
MeSH headings such as genetics and pathology are added in
the queries. In the case of topic 118 regarding the gene
TGFB and Cerebral Amyloid Angiopathy, we added
‚Äúgenetics AND pathology‚Äù as part of the query. The query is
formed as follows:
(TGFB1 OR CED OR DPD1 OR TGFB OR beta 1)
AND ("Cerebral Amyloid Angiopathy" OR
"Congophilic Angiopathy" OR "Sporadic
Cerebral Amyloid Angiopathy" OR "Cerebral
Amyloid Angiopathies" OR "Congophilic
Angiopathies") AND pathology AND genetics

On the other hand, NOT operators ‚Äò-‚Äô are used on words
such as treatment and clinical trials as part of the queries in
template 2 to exclude them from the search. The query for
topic 110 regarding interferon-beta and multiple sclerosis is
formed as follows:
("interferon* beta*") AND ("Multiple
Sclerosis" OR "MS" OR "Disseminated
Sclerosis") AND -"PT - Clinical Trial" AND
-treat* AND -therap*

Similarly, words such as polymorphism and mutation are
added as part of the queries for template 5, to reflect the fact
that we are interested in only articles about mutation of
genes. The query for topic 143 regarding the mutation of
NM23 and tracheal development is formed as follows:
("NME1" OR "AWD" OR "GAAD" OR "NDPKA" OR
"NM23" OR "NM23\-H1") AND (("tracheal
development" OR "tracheal develop*")) AND
(polymorphism OR mutation)

2.2

Indexing

Using the Standard Analyzer provided by Lucene, it
tokenizes the words in the abstracts to perform indexing.
The process of tokenization involves the use of stop-word
list, so that frequently used but uninformative words, such
as a, an, the, would not be used for indexing. The Lucene
index stores the tokens and a list of files in which each of
the token appears.

2.3

Entity Tagging

The task is to parse a biomedical text to identify entities
such as diseases, biological processes and biological
functions, and then tag them accordingly with
DISE_<term>, PROC_<term>, and FUNC_<term>, where
<term> represents the name of the disease, biological
process, or biological function, usually consisting of several
words. Abner [11], a system based on statistical machine
learning techniques, was used to identify gene and protein
names.
Two problems arise when dealing with this task. The first
problem is the looseness of the English language in
conjunction with synonyms, alias, acronyms and even
spelling errors. Tagging can not be done by simply
matching token by token because of names spanning
multiple words, so we must consider one or multiple words
when making comparisons. The second problem is
efficiency. Brute force methods will allow us to tag all
instances of biological words; however, the running time
makes it an unrealistic choice for the amount of abstracts
with which we have to deal.
We tried to exclude as many words as possible from being
matched such that the only words that are matched are
words of meaning and content. In the English language,
nouns, verbs, adjectives, and adverbs convey the real
meaning and content. Everything else just works to make a
more readable sentence, and they never change the content.
In order to reduce the number of word groups matched we
chunked words into noun and verb groups. Recognizing that
most likely an entity of interest would be either a noun
phrase (adjective/noun) or a verb phrase (adverb/verb) we
grouped words using a part-of-speech tagger tool called
Monty Tagger [5] into sequences. Thus, given an abstract,
before attempting to tag biological terms, we tag parts of
speech using the Monty Tagger Java API. An abstract where

3

Lian Yu et al.

each of the words is tagged with a part of speech preceded
by ‚Äò/‚Äô looks as follows:
Haemopoietic/NNP cell/NN growth/NN and/CC
differentiation/NN is/VBZ primarily/RB
regulated/VBN by/IN the/DT local/JJ
production/NN of/IN various/JJ
cytokines/NN within/IN the/DT bone/NN
marrow/NN micro_environment/NN 3/CD ,/,
as/IN well/RB as/IN by/IN the/DT
circulating/VBG hormone/NN ,/,
erythropoietin/NNP GENE_EPO/NNP ./.

This tagged string is then tokenized and one by one
analyzed for its part of speech in order to be grouped. There
are four main parts of speech that we care about: Noun,
Verb, Adjective, and Adverb. Nouns are tagged with /NN,
/NNS, /NNP, and /NNPS. Verbs are tagged with /VB,
/VBD, /VBG, /VBN, /VBP, and /VBZ. Adjectives are
tagged with /JJ, /JJR, and /JJS. Adverbs are tagged with
/RB, /RBR and /RBS. In the example above, the first noun
group is, ‚ÄúHaemopoetic/NNP cell/NN growth/NN‚Äù.
This group is then matched against our dictionaries of
diseases, biological processes, and functions (compiled from
MeSH). If there is a direct match the string is tagged as a
Disease, Process, or Function respectively. The same
process is applied to verb groups. In the above example the
first
verb
group
is
‚Äúis/VBZ
primarily/RB
regulated/VBN‚Äù. The tagged abstracts are then used for
anaphor resolution.

2.4

Anaphora Resolution

In linguistics, an anaphora is an expression that is used to
refer back to some entity (or entities). Pronouns (such as it,
their, this) are the most common anaphora, though other
pro-forms are also anaphoras. The entity to which an
anaphora refers is its referent or antecedent. Consider:
‚ÄúLuis sent me an email. It was the first
thing he did that day.‚Äù

Here, both ‚Äúit‚Äù and ‚Äúhe‚Äù are anaphoras that refer back to
the email and Luis (the antecedents), which were mentioned
before. A human reader has no problem identifying what
they refer to, but automatic processing of the text requires
their resolution: that is, finding a potential replacement for
them and substituting the anaphoras. For the biomedical
domain, we also need to apply some semantic information
to accurately replace some anaphoras.
The subtasks for anaphor resolution include creating a
referent candidate list, doing a proximity search, and finding
the longest common substring to identify the right
antecedent. We elaborate on each of them next.

2.4.1 Creating a referent candidate list
A list of referents is maintained as they are encountered in
the sequential parsing of the abstract. The number of
referents can grow very large and prohibit efficient and

4

sensible search for resolution of ambiguous anaphora. So
the list is limited to only those words that are tagged as
potential names for genes, proteins or diseases. To facilitate
this, a variable is kept to track the most recent reference to
an antecedent entity, since sometimes there are some
anaphoras that are used more than once (like using ‚Äúhe‚Äù or
‚Äúit‚Äù in subsequent sentences in the example above).
Semantic Chunk Objects (SCO) [2] are the potential
candidates for the anaphoras, and contain a potential
antecedent plus information such as the distance of the SCO
from the first word in the abstract, the score received by the
SCO as a potential candidate for the anaphora and semantic
information such as whether the SCO is a gene, disease or
protein.

2.4.2 Proximity Search
Information regarding sentence number and distance from
the beginning of the text is kept for each SCO. Usually the
correct antecedent is the closest one to the anaphora. Using
the scoring heuristic and semantic information along with
the proximity information helps better resolve the
anaphoras.

2.4.3 Longest Common Substring
Anaphoras such as ‚Äúthese‚Äù or ‚Äòboth‚Äù are resolved by
looking at the word that follow them. A longest common
substring comparison is run on that word and the potential
SCOs. Depending upon how long the common substring is
one can decide which semantic chuck object the anaphora
substitutes. Consider the example:
‚ÄúThe exon1 and exon3 are most crucial in
expression of these genes. These exons
are‚Ä¶‚Äù.

In this case the word next to ‚Äúthese‚Äù is exon and that is
compared to all the SCO‚Äôs finding the noun group exon1
and exon3 as the closest matches thus are replacement for
anaphora ‚Äúthese‚Äù.
The comparison is run not only on the antecedent attribute
of the SCO but also on the semantic information of the
SCO. Consider for example:
‚ÄúAlzheimer‚Äôs disease and variant
Creutzfeldt-Jakob disease affect the brain.
These diseases are more prominent‚Ä¶‚Äù

The comparison will include the word following ‚Äúthese‚Äù
i.e. ‚Äúdisease‚Äù and thus we get the group ‚ÄúAlzheimer‚Äôs
disease and variant Creutzfeldt-Jakob disease‚Äù as the
potential replacement.

2.5

Fact Extraction

As explained before, we consider a ‚Äúfact‚Äù the entity or
set of entities participating in a relationship of interest for
the topic. Once the entities are recognized through tagging
‚ÄìSection 2.3- and anaphor resolution ‚ÄìSection 2.4-, the
abstracts are ready for fact extraction. Recall that the

Genomic Information Retrieval through Selective Extraction and Tagging by the ASU-BioAI Group

abstracts are tagged with the following information (an
example is shown in Fig. 2):
‚Ä¢ Gene names as GENE_<phrase of a gene name>
‚Ä¢ Diseases as DISE_< phrase of a disease>
‚Ä¢ Biological Processes as PROC_< phrase of a
biological process >
‚Ä¢ Molecular Functions as FUNC_< phrase of a
molecular function>

The method can be explained with the help of windowing
technique. Let‚Äôs consider the input text (sentence by
sentence) to be a single stream of text with a window of size
. A chain of related terms that fit within this window size
is a potential candidate for fact extraction. The extraction
module now considers the terms lexically related within this
window. This window is moved one word at a time
throughout the text. Fig. 3 shows the window and the input
text. The fact extraction task is performed on all generelated TREC topics (i.e. all topics except topic 1).

2.6
Fig. 2: An example of tagging

Extraction of facts corresponding to the templates (shown
below) is carried out by the extraction module, where the
idea of lexical chaining is applied. The premise is that words
that are closer to each other are more likely related than the
ones that are far apart. The general schema for extracted
facts is as follows:
PMID| Fact Id| Fact Frequency| GENE_< phrase >|
Interaction Word | GENE_< phrase > | DISE_< phrase >|
PROC_< phrase > | FUNC_< phrase > |
where PMID is a unique PMID, Fact Id is unique fact
number within the given abstract, Fact Frequency is
frequency of the fact occurring in the given abstract,
GENE_< phrase > is gene name prefixed with GENE_,
similarly DISE_< phrase >, PROC_< phrase > and FUNC_<
phrase > is for disease, process and function respectively.

Extraction Solution
A lexical chain [8] is a lexical cohesion of related words
that contribute to the continuity of meaning. Based on this
idea, the extraction module tries heuristically to construct a
chain of related words (such as gene names and diseases)
and include them as a fact only if they are considered to be
related. The relation of these words is primarily assumed to
be in a single sentence.

Ranking Abstracts

The Ranking module takes two input files: 1) a query file
which contains a TREC template or query ID and
corresponding queries (created earlier in the Query Preprocessing step) and 2) a query results file, which contains a
list of query IDs and associated PMIDs returned from a
Lucene search. For each query ID, the ranking module
outputs a ranking of the PMIDs based on relevancy.
To rank the abstracts with for a given query ID, a
hierarchical ranking approach is used in this paper: the
abstracts associated with a query ID are first ranked based
on the number of times relevant facts occur in each abstract.
This measure is called the fact frequency. The fact
frequency counts the number of times that related terms in
the query appear in a same sentence (see description of the
Extraction module) in the abstracts of interest. If any two
abstracts have the same fact frequency the tie is broken by
comparing the abstracts'term/distance scores, abbreviated
TD. (see Equation 2). The TD score incorporates both the
term frequency and term distance (where terms are not
necessarily in the same sentence, unlike fact frequency) of
the abstracts in order to determine which abstract is more
relevant.
TREC requires that each abstract be assigned a single score
to represent its relevancy. To accomplish this, a ranking
formula called rf(a) is used to assign a value to an abstract a
that meets the above two requirements.
If A represents all the abstracts that have the same query
ID, a ‚àà A, ff(a) represents the fact frequency of a, and td(a)
represents the TD score of a, then the value rf(a) is as
follows in Equation (1):

rf (a ) = td (a ) + max(td ( A)) * ff (a )

Fig. 3: Heuristic based on Lexical (semantic) cohesion of words.
Windowing technique is used to limit the chain size under
consideration.

(1)

In Equation 1 the maximum score of all the abstracts in A
is used in order to ensure that an abstract that has a high fact
frequency, and is thus more relevant, will have a high value
of rf(a). The TD score of the abstract is also taken into
account to break ties between abstracts with identical fact
frequencies, resulting in a single value which ranks an
abstract using the hierarchical ranking approach described
earlier.

5

Lian Yu et al.

Once rf(a) for each abstract has been computed, the list of
abstracts, sorted by query ID and then sub sorted in
decreasing order by rf(a), are written to two files, qrels.txt
and topic_document.txt, which were then submitted to
TREC for evaluation.
The notations used in the following formula are listed as
follows:
a:
A:
G:
D:
s(a):
d = (s1, s2):
Mina (d):
f(a, s):
w(a):
df(a, d):

an abstract with a query ID of ID
the set of all the abstracts with a query ID of
ID and a ‚àà A.
the set of all genes and their synonyms found
in the query ID
the set of all the diseases and their synonyms
found in the query ID
the number of sentences in a
the distance between strings s1 and s2 (such
as strings of a gene or a disease) in terms of
sentences in between
the minimum distance in sentences between
s1 and s2 If either s1 or s2 is not in a then Mina
(d) is defined to be equal to s(a)
the number of times the string s occurs in a
the total number of words in a
the number of times the pair of strings of d is
at a distance of Mina (d) (if either string in d
is not in a then df(a, d) is defined to be equal
to 1).

Then the TD score of a, td(a), is computed as follows in
Equation (2).

td (a) =

ratio * dist * rel , if w(a ) > 0 ‚àß s (a ) > 0
0, if w(a ) = 0 ‚à® s( a) = 0

(2)
where the variable ratio is computed with gene or disease
overlap and the weights of the genes or diseases in the query
ID, dist represents the distance between gene/disease pairs
in the query ID (see Equation (3)). rel, or relevancy,
represents the frequency of the genes and diseases in the
query ID appearing in a (see Equation (6)).
The portion of ratio in TD score consists of the product of
three factors as follows in Equation (3)[1]:

ratio =

overlap
1
*
* weight
G+D
w(a )

(3)

The first factor is called the coordination, which is the
overlap (see Equation (4)) divided by the number of genes
and diseases in the query ID. The second factor is known as
length normalization, which is the reciprocal of the square
root of the total number of items, tokens, or the words of the
abstract searched. The last factor, weight, represents the
weights assigned to each gene and disease in the query ID:

6

since each gene and disease has equal weight this score will
be the square root of the number of genes and diseases in
the query ID (see Equation (5)) [1].
The overlap of an abstract a is the number of genes or
diseases in the query ID that occur at least once in a.

overlap = d ‚àà G ‚à™ D : f (a, d ) > 0

(4)

The weight value normalizes the weights for the genes
and diseases in the query ID.

weight =

1
2

wgh(d )

(5)

d‚ààG ‚à™ D

where wgh(d) represents the individual weight of a gene or
disease d in the query ID: by default, this value is equal to
one divided by the number of genes and diseases in the
query ID.
The distance, dist, is the product of the distance scores for
each possible ordered pair of genes and diseases in the
query ID. A distance score for a gene/disease pair is a
product of two factors: a sentence distance factor and a
distance frequency factor. The sentence distance factor is a
value between one and two inclusive, with a value of one
signifying that the gene/disease pair do not occur together in
the abstract a and a score of two signifying that the gene and
disease occur in the same sentence in the abstract a. The
value of the distance frequency factor is how often the
gene/disease pair occurs at the distance used to calculate the
sentence distance factor: the square root is applied to this
value for normalization. If ID is between a certain range the
query includes not one but two sets of genes (G1 and G2) for
which the distance must be taken into account (see
corresponding template): therefore, a second product term
must be included which measures the distance between each
possible ordered pair of genes in these two sets.
The distance (dist) value is the product of the distance
values between each possible ordered pair of genes and
diseases in the query ID. A distance value for a gene/disease
pair is itself a product of two factors: a sentence distance
factor and a distance frequency factor. The sentence
distance factor is a value between one and two inclusive:
one signifying that the gene/disease pair does not occur
together in the abstract a and two signifying that the gene
and disease occur in the same sentence in the abstract a. The
value of the distance frequency factor indicates how often
the gene/disease pair occurs at the distance used to calculate
the sentence distance factor, and the square root is applied to
this value for normalization. If ID is between 130 and 139
then Equation (6b) is used to calculate the value of dist.
Within this range the query includes not one but two sets of
genes (G1 and G2) for which the distance must be taken into
account (see corresponding template): therefore, along with
the product found in Equation (6a), a second product term
must be included which measures the distance between each
possible ordered pair of genes in these two sets.

Genomic Information Retrieval through Selective Extraction and Tagging by the ASU-BioAI Group

d ( a, d )
) * df (a, d )
s(a)
d ‚ààG√ó D
(T < 130 ‚à® T > 139) ‚àß s (a ) ‚â† 0 (6a)
d ( a, d )
dist = ‚àè (2 ‚àí
) * df (a, d ) *
s(a)
d‚ààG√óD
d ( a, g )
(2 ‚àí
) * df (a, g )
‚àè
s ( a)
g‚ààG1√óG 2
dist =

‚àè

(2 ‚àí

T ‚â• 130 ‚àß T ‚â§ 139 ‚àß s (a ) ‚â† 0 (6b)
The relevancy portion in TD of a, rel, is a sum of the
relevancy of each gene or disease searched for in a. The
relevancy of an individual gene or disease is a product of its
frequency and its inverse document frequency [3],[10]. The
square root of the frequency is taken to normalize the value,
while the inverse document frequency measures how rare a
gene or disease is: the rarer the gene or disease, the higher
the inverse document frequency, and thus the relevancy,
will be. This is because the occurrence of a rare gene or
disease in an abstract is a better indicator of relevancy than a
common one.

rel =

f (a, d ) * log(
d ‚ààG ‚à™ D

A
) (7)
dfr ( A, d ) ‚àí 1

The document frequency, dfr(A,d) (see Equation (8)),
represents the number of abstracts in A that contain the gene
or disease d at least once. The smaller the value of dfr(A,d)
the rarer the gene or disease d is.

dfr ( A, d ) = a ‚àà A : f (a, d ) > 0
3

(8)

EVALUATION AND DICUSSION

This section demonstrates the experiment results of our
approach, and the comparison with results from Pubmed
search engine in regarding to the 50 topics.

3.1

Run Results

We performed Lucene indexing on the collection of 4.5
million abstracts in MEDLINE format, used 50 formatted
queries to search in the Lucene index, and retrieved about
12K target abstracts. The number of search results varied
from query to query ranging from 0 to 7,000.
For each template, we performed tagging, anaphor
resolution, extraction (exception template 1) and ranking.
We performed fact extraction on abstracts pertinent to
templates 2 through 5, and calculated the fact frequencies,
which were incorporated into the ranking formula. For
abstracts related to template 1, we performed tagging and
anaphor resolution without fact extraction. The ranking is
only dependent on the score as described in Section 2.5.

3.2

TREC Evaluation Results

TREC ad-hoc relevance judgments were done based on
the top 60 documents from the two runs submitted by each
group for each topic, which yielded an average pool size of
822 documents. Relevance judgments were performed only
on 49 of the 50 topics, as no relevant document was found
for one of the topics, which is topic #135. Evaluation results
returned by TREC were summarized in terms of precision at
top 10 relevant documents retrieved (denoted as P10),
precision at top 100 relevant documents retrieved (P100)
and uninterpolated average precision for the 49 topics.
Our system for the ad hoc retrieval task achieves an
overall precision of 0.2714 for P10 and precision of 0.1061
for P100 among the 49 topics. This implies that our system
achieves a low recall, as the number of articles retrieved by
our system is low. Table 1 shows the average number of
articles retrieved as well as minimum and maximum number
for each template. We further analyzed our performance and
noticed that our system performs best in template 2, which
is to retrieve articles describing the role(s) of a gene
involved in a disease. It is evident that our extraction-based
retrieval system benefits from the rich dictionaries of gene
and disease names compiled from Entrez Gene and MeSH.
On the contrary, the lack of rich dictionaries for functions of
an organ (for template 4) and biological impact or role (for
template 5) is the main reason on why our system suffers in
the precision of the retrieval task for templates 4 and 5. Our
system also failed to retrieve any documents for some of the
topics in templates 4 and 5.
Table 1: Average of the number of articles retrieved
Template #
1 (topic # 100-109)
2 (topic # 110-119)
3 (topic # 120-129)
4 (topic # 130-139)
5 (topic # 140-149)

4

Number of articles retrieved on
average
95 (min = 2, max = 436)
110 (min = 4, max = 303)
122.5 (min = 4, max = 1000)
8.11 (min = 0, max = 52)
26.9 (min = 0, max = 207)

CONCLUSION AND FUTURE WORK

The TREC Genomics team included 8 members from the
BioAI group, 3 of them undergraduates. We spent about 6
weeks completing the ad-hoc retrieval task. We used
Apache Lucene to perform the initial retrieval and got 12K
target abstracts out of 4.5 million abstracts. Then tagging,
anaphor resolution, extraction and ranking were performed
to refine relevance of search results.
Retrieval systems such as NCBI PubMed generally return
a large number of documents that are supposed to be
relevant to the users‚Äô queries. In other words, such retrieval
systems achieve high recall but relatively low precision.
Users of a retrieval system with high precision can benefit
on the preciseness and conciseness of the articles returned to

7

Lian Yu et al.

them. With this in mind, we emphasized the precision aspect
of our retrieval system. Our system could achieve higher
precision on templates 4 and 5 if richer ontologies were
used for functions of an organ and biological impact.
Future work includes investigating ways to improve the
accuracy of the tagging module for diseases, bio-processes
and functions of organs. A quantitative approach to assign
scores to SCOs is needed for the anaphor resolution module.
The extraction module needs to be able to extract various
types of the topics, such as topics in the template 1.

REFERENCES
[1] Apache Lucene. http://lucene.apache.org/java/docs/.
[2] J. Casta√±o, J. Zhang, J. Pustejovsky. Anaphora Resolution in
Biomedical Literature. International Symposium on Reference
Resolution, 2002.
[3] K.S. Jones. Index term weighting. Information Storage and
Retrieval, 9: 619-633, 1973.
[4] MeSH. http://www.nlm.nih.gov/mesh/.
[5] Monty Tagger. http://web.media.mit.edu/~hugo/montytagger/.
[6] NCBI Entrez Gene.
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=gene.
[7] NCBI Entrez PubMed.
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed.
[8] J. Morris, G. Hirst, Lexical Cohesion Computed by Thesaural
Relations as an indicator of the structure of Text. Association
of Computational Linguists, 1991.
[9] M.F. Porter. An algorithm for suffix stripping, Program,
14(3):130-137, 1980.
[10] S.E. Robertson and K.S. Jones. Relevance weighting of
search terms. Journal of the American Society for Information
Science, 27, 129‚Äî146, 1976.
[11] B. Settles. ABNER: an open source tool for automatically
tagging genes, proteins, and other entity names in text.
Bioinformatics, 21(14):3191-3192, 2005.

8

Invariance, Maintenance and other declarative
objectives of triggers { a formal characterization
of active databases
Mutsumi Nakamura

Chitta Baral

Department of CSE
Department of CSE
University of Texas at Arlington Arizona State University
Arlington, TX 76019, USA
Tempe, AZ 85287, USA
nakamura@cse.uta.edu
chitta@asu.edu

Abstract

In this paper we take steps towards a systematic design of active features in an active database. We propose having declarative specications
that specify the objective of an active database and formulate the correctness of triggers with respect to such specications. In the process
we distinguish between the notions of `invariance' and `maintenance' and
propose four dierent classes of specication constraints. We also propose
three dierent types of triggers with distinct purposes and show through
the analysis of an example from the literature, the correspondence between
these trigger types and the specication classes. Finally, we briey introduce the notion of k-maintenance that is important from the perspective
of a reactive (active database) system.

1 Introduction and Motivation

Many commercial database systems (such as Oracle, Sybase, IBM's DB2-V2,
etc.) and the database standard SQL3 incorporate active features { namely
constraints (also referred to as integrity constraints) and triggers. Due to these
active features explicit update requests to the database may have several consequences from the request being refused (as it may violate `integrity constraints'),
to the request being fullled with slight changes (as modied through `before
triggers'), to additional changes triggered by cascade deletes and inserts used in
the processing of some constraints and/or ring of `after triggers'.
Although originally, integrity constraints were thought of as declarative constraints about database states and dened which database states were valid and
which were not, with the presence of cascade operations in the SQL3 constraints
and the use of after triggers to maintain the integrity of the data, there is currently little tradition (except in [CF97] and few other cases) of using or following
standard software engineering practices of separating specication from implementation when designing and developing active databases. This means that
1

often active database developers do not even specify what the purpose of the
active features of their database are. Thus there is no way to verify the correctness of the active features. We believe this is one of the reasons why many
companies balk at using the active features of a database.
Our goal in this paper is to take steps towards developing a systematic approach
to the design of active databases. In the process we will develop several language
constructs that can be used in specifying the purpose of an active database;
formulate the correctness of the procedural triggers with respect to declarative
specications; and develop guidelines that match the procedural aspects with
the declarative aspects.
One major hindrance in this pursuit has been the multitude of syntax and semantics (and their complexity) associated with the various dierent implementation of active rules [WC96, Pat98] and the complexity of their semantics. In
this paper we will follow the SQL3 standard (and the DB2-V2 implementation)
to some extent and make certain simplications.

1.1 The declarative notions

The basic goal of the active features of a database is to constrain the evolution
of the database. Based on analyzing a large class of active database examples,
we have identied four kind of constraints: state invariance constraints; state
maintenance constraints (or quiescent state constraints); trajectory invariance
constraints; and trajectory maintenance constraints.
In the above constraints there are two dimensions: (i) state vs trajectory (ii)
invariance vs maintenance. Intuitively, in state constraints we are concerned
about the integrity about particular states, while the trajectory constraints
focus on the trajectory of evolution of the database. On the other hand, invariance constraints worry about all states of the database, while the maintenance
constraints focus only on the quiescent states.
Denition 1 (State Constraints) [ADA93] A state constraint s on a database
scheme R, is a function that associates with each database r of R a boolean value
s (r). A database r of R is said to satisfy s if s (r) is true and is said to violate s if s (r) is false. In the former case, it is also said that s holds in r. A
database r is said to satisfy a set of state constraints if it satises each element
of the set.
2
Denition 2 (Trajectory Constraints) A trajectory constraint t on a database
scheme R, is a function that associates with each database sequence  of R a
boolean value t (). A database sequence  of R is said to satisfy t if t () is
true and is said to violate t if t () is false. In the former case, it is also said
that t holds in . A database sequence  is said to satisfy a set of trajectory
constraints if it satises each element of the set.
2
Often static integrity constraints are expressed through sentences in propositional logic or rst-order predicate calculus while we need temporal operators
to express trajectory constraints. We further discuss this in Section 3.
2

1.2 The procedural features of an active database

In SQL3 (and DB2-V2) the active features are: Constraints; Before triggers;
and After triggers.
The constraints in DB2-V2 are of the kinds: NOT NULL constraints, column
defaults, unique indexes, check constraints, primary key constraints, and foreign key constraints. Among these, the NOT NULL constraints, unique indexes, check constraints, primary key constraints and some of the foreign key
constraints (with NO ACTION or RESTRICT in the action part) refuse updates that violate the constraints. These correspond to the state invariance
constraints mentioned in the previous section.
On the other hand column default constraints and the foreign key constraints
with CASCADE or SET NULL in the action part accept the updates but make
additional changes. The former correspond to the state invariance constraints,
while the later correspond to the state maintenance constraints.
The before triggers act on the update request directly (instead of the updated
database) and modify it if necessary while the after triggers are triggered by
the update request and can either refuse the update (through a rollback) or
force additional changes. Here, the former can implement state and trajectory
invariance constraints, while the later can implement any of the four types of
constraints.
From the above analysis, it seems that certain specications such as a state
maintenance constraint can be implemented in multiple ways, through a DB2V2 constraint or through after triggers. But the trigger processing architecture
treats DB2-V2 constraints very dierently from after triggers. Thus it becomes
very dicult to formulate and verify the correctness of the DB2-V2 (or SQL3)
active features with respect to specications mentioned in Section 1.1.
We propose a dierent class of active features that are close to the SQL3 features, but that are distinct in terms of their goals. Our class consists of three
kind of procedural features (triggers): refusal triggers, wrapper triggers, and
maintenance triggers.
Intuitively, the refusal triggers when triggered refuse the update that caused the
triggering. Thus refusal triggers can express not only after triggers with refuse
actions, but also NOT NULL constraints, unique indexes, check constraints,
primary key constraints, and foreign key constraints with NO ACTION or RESTRICT in the action part. The wrapper triggers, wrap the update request by
additional changes and thus can express both before triggers and column default
constraints. The maintenance triggers1 trigger additional updates and thus can
express both after triggers with similar purpose, and foreign key constraints
with CASCADE or SET NULL in the action part.

1 In Section 4 we will further divide maintenance triggers to two classes: short-term and
long-term. This becomes necessary when we need to worry about reactive response to update
requests.

3

Our division of the triggers into the above three classes makes them distinct in
terms of what they set out to achieve. This is dierent from the active features
in DB2-V2 and SQL3 where there is overlapping of goals making it dicult in
designing active databases and formulating their correctness.

2 Actions, Events and Triggers

In this section we describe the necessary mechanism for reasoning about actions
and events which we will then use to formulate correctness of triggers with
respect to declarative specications.

2.1 Actions and eects

Intuitively, an action when executed in a world changes the state of the world.
In databases, an action can take several meanings; from the basic insert, delete
and update actions to SQL update statements. In this paper by an action we
will usually refer to an uninterruptable transaction.
To specify the eects of an action on a database we borrow constructs from the
specication language A [GL93] and our earlier work in [BL96, BLT97]. In the
following by a uent we will mean a database fact, and by a uent literal we
will mean either a database fact or its negation. Eects of actions are specied
through eect axioms of the following form:

a(X ) causes f (Y ) if p1 (X1 ); : : : ; pn (Xn )
(2.1)
where a(X ) is an action and f (Y ); p1 (X1 ); : : : ; pn (Xn ) are uent literals (n  0).
p1 (X1 ); : : : ; pn (Xn ) are called preconditions. The intuitive meaning of (2.1) is
that in any state of the active database execution in which p1 (X1 ); : : : ; pn(Xn )
are true, the execution of the action a(X ) causes f (Y ) to be true in the resulting

state. A word of caution is needed regarding the safeness [Ull88] of variables
in the causal law . The preconditions p1 (X1 ); : : : ; pn (Xn ) will be evaluated as
regular queries in the database and a(X ) is an action that could be invoked
by a user or an active rule. Thus, variables appearing in Y or in any negated
uent in the preconditions must also appear in one of the positive uents in
the precondition. If there are variables in X that do not appear in any of the
positive uents in the preconditions these arguments must be ground at the time
of the invocation of the action, otherwise there will be an error in the execution.
Moreover, the variables are schema variables, and intuitively an eect axiom
with variables represents the set of ground eect axioms where the variables are
replaced by ground terms in the domain.
Two eect axioms with preconditions p1 ; : : : ; pn and q1 ; : : : ; qm respectively are
said to be contradictory if they describe the eect of the same action a on
complementary f s, and fp1; : : : ; pn g \ fq1 ; : : : ; qm g = ;
A state is a set of uent names. Given a uent name f and a state , we say
that f holds in  if f 2 ; :f holds in  if f 62 . A transition function is a
4

mapping  of the set of pairs (a; ), where a is an action name and  is a state,
into the set of states.
A collection of eect axioms (EA) for various actions in our world { with no
contradictory eect axioms in them, dene a transition function from the set of
actions and the set of database states to the set of database states.
For every action a and every state ,
(a; ) = ( [ 0 ) n 00 ;
where 0 (00 ) is the set of uent names f such that EA includes an eect
proposition describing the eect of action a on f (respectively, :f ) whose preconditions hold in .
We now show how the eect of simple actions such as insert, delete and update
can be specied using eect axioms.

insert(R(t)) causes R(t)
delete(R(t)) causes :R(t)
update(R(t); R(t0)) causes R(t0 ) if R(t)
update(R(t); R(t0)) causes :R(t) if R(t)

(2.2)
(2.3)
(2.4)
(2.5)

We now show how we can specify the eect of actions corresponding to more
complex transactions:

Example 1 Consider another transaction a2 from [Cha96]:

UPDATE parts
SET qonorder = qonhand,
qonhand = qonorder
WHERE partno = `P207';
Its eects can be described in our language through the following eect propositions:
a2 causes parts(P 207; Descr; qonhand; qonorder) if
parts(P 207; Descr; qonorder; qonhand)
a2 causes :parts(P 207; Descr; qonhand; qonorder) if
parts(P 207; Descr; qonhand; qonorder)
2

To reason about the eect of a sequence of actions on a database , we need to
extend the function , to allow sequence of actions as its rst parameter. This
extension is dened as follows:

 ([]; ) = , and
 ([ja]; ) = (a; (; )).
5

2.2 Events and ECA rules

Triggers (or active rules) in active databases are normally [WC96] represented
as a triple consisting of events, conditions and actions. In most active database
architectures, the sequence of actions that have been executed since the last evaluation point are evaluated to decide on what events have taken place. These
events together with the valuation of the condition with respect to the current database state determine whether a particular ECA active rule should be
triggered or not.
Dierent active databases allow dierent event sets and have dierent ways of
evaluating the events. In the simplest case, the events can be the set of inserts
and deletes explicitly performed by the last action. On the other hand, in
Starburst [Wid96] events are dened in terms of the net eects of a sequence
of transitions. To allow the exibility of dening a set of events and computing
them from a sequence of actions we use the notion of event denitions from
[BLT97].
An event denition proposition is an expression of the form:

e(X ) after a(W ) if e1(Y1 ); : : : ; em (Ym ); q1 (Z1 ); : : : ; qn (Zn )

(2.6)

where e(X ); e1 (Y1 ); : : : ; em (Ym ) are event literals2 and q1 (Z1 ); : : : ; qn (Zn ) are
uent literals. This proposition says that the execution of the action a(W )
ordered in a state in which each of the uent literals qi (Zi ) is true and each
of the event literals ej (Yj ) is true generates the event literal e(X ) if the event
literal is positive, or removes the event from the set of current events if the event
literal e(X ) is negative. If the execution is ordered in a state in which some of
the qi (Zi ) or ej (Yj ) does not hold then (2.6) has no eect. Each of the (schema)
variables appearing in X or in a negated event or uent literals, has to appear
either in W or in a positive event/uent literal.
The default assumption is that the event persists from one state to another,
with two possible exceptions: either the event is consumed by an active rule
(see below), or the event is removed by an action based on the specication
of an event denition. For example, if we have an expression :e1 after a1 ,
the execution of the action a1 will cause the event e1 not to be present in the
resulting state. Hence, the meaning of \an event is true in a given state" is: the
event was induced (i.e. generated) in some state prior to the given one and the
event persisted, or the event was induced by an execution of an action in the
previous state.

Example 2 (Events in Starburst) In Starburst net eects (or events) are
expressed in words through the following conditions:
 If a tuple is inserted and then updated, it is considered an insertion of the
updated tuple.
2

Like uent literals, an event literal is an event or its negation.

6

 If a tuple is updated and then deleted, it is considered as a deletion of the

original tuple.
 If a tuple is updated more than once, it is considered as an update from
the original value to the newest value.
 If a tuple is inserted and then deleted, it is not considered in the net eect
at all.
These four premises can be encoded through event denitions as follows:

e add(H )

:e add(G)

e del(G)
:e upd(G; F )
e upd(G; I )
:e upd(G; H )
:e add(G)

after upd(G; H ) if e add(G)
after upd(G; H ) if e add(G)
after del(F ) if e upd(G; F )
after del(F ) if e upd(G; F )
after upd(H; I ) if e upd(G; H )
after upd(H; I ) if e upd(G; H )
after del(G) if e add(G)

(2.7)

In the above example, at the rst glance it appears that our notation is more
verbose than the original rules. For each of the rst three rules we needed two
event denition propositions. This is because we assume that events have inertia. This assumption actually cuts down in writing individual event denition
propositions encoding the persistence of each event due to actions that do not
aect it. For example we do not need to explicitly write:

e add(H ) after del(G) if e add(H ); H 6= G
We characterize events using the function  whose input is a set of events,
a state, and an action and the output is a set of events. More formally,
let E + (E; ; a) = f e : there is an event denition proposition of the form
e after a if e1 ; : : : em; q1 ; : : : ; qn where e1 ; : : : ; em hold in E and q1 ; : : : ; qn
hold in  g; and let E ? (E; ; a) = f e : there is an event denition proposition
of the form :e after a if e1 ; : : : em ; q1 ; : : : ; qn where e1 ; : : : ; em hold in E and
q1 ; : : : ; qn hold in  g. (E; ; a) is then dened as follows:
(E; ; a) = (E [ E + (E; ; a)) n E ? (E; ; a)
To be able to compute events with respect to a sequence of actions we extend
 as follows:

 (E; ; []) = E , and
 (E; ; [ja]) = ((E; ; ); (; ); a).
7

2.3 Characterizing database evolution due to ECA rules

As mentioned in Section 1.2, we have three kinds of triggers: wrapper triggers,
refusal triggers and maintenance triggers. We represent each of them through
ECA rules but distinguish them by the action part. In wrapper triggers the
action part is a wrapping function ! which maps an action sequence and a
database state to an action sequence. Intuitively, for a single action a, by
!(a; ) = a0 we mean that a0 is the action obtained by wrapping a with ! in
state . In refusal triggers the action part is the special action REFUSE and in
maintenance triggers the action part could be an arbitrary sequence of actions.
Thus an ECA rule is a triple he; c; i, where e is an event in our language, c
is a temporal formula about the database history, and  is either a wrapping
function, the special action REFUSE, or a sequence of actions. Often we will
represent a single action as the ECA rule h;; True; ai.
In this subsection our goal is to give a formal characterization of the evolution
of a database due to a sequence of actions in presence of a set of ECA rules.
In our characterization we strive to keep a balance between not making the
semantics too complicated and at not losing expressibility. We now give an
intuitive description of our characterization.
Intuitively, after the action sequence (with necessary modications due to wrapper triggers) is executed the set of events corresponding to that sequence of
actions are evaluated. Then the ECA rules that match with the events are
identied. We assume (as in many implemented systems [Cha96]) that there is
a total ordering among the ECA rules with the condition that refusal triggers
have higher priority than maintenance triggers. Using this total ordering a priority list of the identied ECA rules is created. Then the condition parts of the
ECA rules in the priority list are evaluated in the order of their priority and if
the condition evaluates to be true, the action part is executed. Since the action
part may trigger additional ECA rules, an important concern is how these ECA
rules are assimilated into the already existing prioritized list of ECA rules. Two
straightforward approaches are to view the list as a stack where newly triggered
ECA rules are pushed onto the top of the stack, or to view the list as a queue
where newly triggered ECA rules are put at the end of the queue. In both cases,
among the newly added rules, the wrapper triggers have the highest priority, the
refusal triggers have the second highest priority and the maintenance triggers
have the lowest priority.
So after the execution of the action part of the currently considered ECA rule,
the newly triggered ECA rules are put into the priority list and the evaluation of
the ECA rules in the modied list are again done based on their priority. This
loop of executing the action part of the currently chosen ECA rule, updating the
list of ECA rules, and evaluating the list to nd the next ECA rule, continues
until the list is empty. During the execution when faced with a trigger whose
action part is REFUSE, the database is rolled back.
We now formally dene the function 	(; ; List), where  is a database state,
 is a sequence of actions and List is a prioritized list of ECA rules that are
8

yet to be processed, and the output of the function is a sequence of database
states. Once we dene this function, the evolution of a database state  due to
an action sequence , can then be expressed by 	(; ; [ ]). (For lack of space
we only consider the simple case where there are no triggers with REFUSE in
their action part.)

Denition 3 [Evolution due to actions and triggers]
1. 	(; ; List) =  if  is a state,  is an empty sequence, and List = [ ].
2. 	(; ; List) is an empty list if  is undened.
3. 	(; ; List) =    if
(a) 0 = (!(); ), where ! is the composition of the wrapping functions of the before triggers triggered by the events in (;; ; ). (If
there are no before triggers triggered by the events in (;; ; ) then
! is the identity function; i.e., 8:!() = ).
(b) List1 is the list obtained by adding the new ECA rules triggered by
the events in (;; ; !()) to List and adjusting the priorities,
(c) eca is the ECA rule with the highest priority in the priority list List1,
(d) 0 is the action part in eca,
(e) List2 = List1 n fecag, and
(f) 	(0 ; 0 ; List2) = .
2
Because of the second condition above, when (!(); ) is undened we obtain
 as an empty list, and then 	(; ; List) is a sequence of length one with 
as the only element. Rollbacks can be accounted for by having an additional
parameter in 	 which stores the initial state, where the database should be
rolled back to when a trigger with REFUSE in its action part is triggered.

2.4 Correctness of ECA rules

Our next step is to formally dene when a set of ECA rules are correct with
respect to invariant and maintenance constraints. For state maintenance constraints, intuitively, the correctness means that the ECA rules force the database
to evolve in such a way that the nal state that is reached is a state where all the
state maintenance constraints are satised. For state invariant constraints, intuitively, the correctness means that the ECA rules force the database to evolve
in such a way that the state invariance constraints are satised in all states of
the trajectory.
Since our ultimate goal is to be able to use this denition to verify the correctness, we add another dimension to the denition: the class of exogenous actions
that we consider; where exogenous actions are the actions that outside users are
9

allowed to execute on the database. It should be noted that the action part of
the ECA rules may have actions other than the exogenous actions.
We now formally dene correctness with respect to state invariant and maintenance constraints.

Denition 4 Let ?si be a set of state invariant constraints, ?sm be a set of
state maintenance constraints, A be a set of exogenous actions, and T be a set
of ECA rules. We say T is correct with respect to ?si [ ?sm and A, if for all

database states  where the constraints in ?si and ?sm hold, and for all action
sequences  consisting of exogenous actions from A,

 all the states in the sequence 	(; ; [ ]) satisfy the constraints in ?si ; and
 the last state of the evolution given by 	(; ; [ ]) satises the constraints
2

in ?sm .

To expand the Denition 4 to dene correctness with respect to trajectory
constraints we need to consider a larger evolution window where the database
evolves through several exogenous requests each consisting of a sequence of (exogenous) actions. For this we use the notation  to denote the last state of the
evolution given by 	(; ; [ ]). We use the notation (1 ;2 ) to denote the last
state of the evolution given by 	(1 ; 2 ; [ ]), and similarly dene (1 ;:::;i ) .

Denition 5 Let ?si be a set of state invariant constraints, ?sm be a set of

state maintenance constraints, ?ti be a set of trajectory invariant constraints,
?tm be a set of trajectory maintenance constraints, A be a set of exogenous
actions, and T be a set of ECA rules. We say T is correct with respect to
?si [ ?sm [ ?ti [ ?tm and A, if for all database states  where the constraints in
?si and ?sm hold, and for all action sequences 1 ; : : : ; n consisting of exogenous
actions from A,

 all the states in the sequences

	(; 1 ; [ ]), 	(1 ; 2 ; [ ]), . . . , 	((1 ;:::;n?1 ) ; n ; [ ]) satisfy the constraints in ?si ;
 all the states 1 ; : : : ; (1 ;:::;n ) satisfy the constraints in ?sm ;
 the trajectory obtained by concatenating 	(; 1 ; [ ]) with 	(1 ; 2 ; [ ]),
. . . , 	((1 ;:::;n?1 ) ; n ; [ ]) satisfy the constraints in ?ti ; and
 the trajectory ; 1 ; : : : ; (1 ;:::;n ) satises the constraints in ?tm . 2
Example 3 Consider the relational Schema:
Employee(Emp#; Name; Salary; Dept#)
Dept(Dept#; Mgr#)
We have two state maintenance constraints:
(i) If (e; n; s; d) is a tuple in Employee then there must be a tuple (d0 ; m0 ) in
10

Dept such that d = d0 .
(ii) If (d; m) is a tuple in Dept, then there must be a tuple (e0 ; n0 ; s0 ; d0 ) in
Employee such that d = d0 and m = e0
The only allowable exogenous action is del(Employee(E; N; S; D)).

The set of maintenance triggers that can be shown to be correct with respect
to the above maintenance constraints and exogenous actions consists of the
following trigger.
 For any Delete (e; n; s; d) from Employee, if (d; e) is a tuple in Dept, delete that
tuple from Dept and delete all tuples of the form (e0 ; n0 ; s0 ; d0 ) from Employee,
where d = d0 .
2
We can now make the formal claim that the above maintenance triggers are
correct with respect to the above mentioned state maintenance constraints and
exogenous actions.

3 Elaborating on our abstractions

In Section 1.1 we dened state constraints and trajectory constraints as boolean
functions on database states and sequences of database states respectively. Our
next concern is how to represent such functions parsimoniously. One approach is
to use logical constructs. In this section we introduce several language constructs
that we proposed to use in specifying state and trajectory constraints and show
their use through examples.
We start with a description of the mail order business active database from
[Cha96]. To save space and to make it readable without knowing the syntax of
triggers in DB2-V2, we describe the triggers of this active database in words,
and not in the syntax of DB2-V2.

3.1 The tables

The ve tables that are mentioned in the database in [Cha96] and their attributes are:
Cust(C#, Cname, Caddr, Baldue, Creditlmt)
Suppl(S#, Sname, Saddr, Amtowed)
Inv(It#, Iname, S#, Qonhand, Unitsalpr, Qonorder, Unitorderpr, Orderthreshold, Minorder)
Purch(Orddate, Ordtime, S#, It#, Qordered, Dtrecvd, Qrcvd, Unitpr)
Sales(Sldate, Sltime, C#, It#, Qsold, Unitpr, Totalsale)

3.2 A subset of the triggers

Due to lack of space we only consider two of the eight triggers given in [Cha96],
and identify the state and trajectory constraints corresponding to these triggers.

 (PT1: a wrapper trigger)

When inserting into the Purch table modify the tuples (to be inserted)
11

so that for any It#, the values for S# and Unitpr are the values for S#
and Unitorderpr for that It# in the Inv table. (Note that because of
the constraints associated with the Purch table that allow Orddate and
Ordtime to get the current date and time by default, It# and Qordered
are the only pieces of information required to do insertions into the Purch
table.)
 (PT2 { a maintenance trigger)
After inserting an order for an It# to Purch, update the Inv table by
increasing the Qonorder (in the tuple with that It#) by Qordered.

3.2.1 The corresponding constraints

We rst list the constraints in a high level language that we developed and then
explain the meaning of the constructs in this language.

 (C1) ForAll It#: Inv:S # = Purch:S # is invariant
 (C2) ForAll It#: Inv:Unitorderpr = Purch:Unitpr is invariant
 (C3) newtuple Purch requires Orddate = Currentdate and Ordtime
= Currenttime
 (C4) ForAll It#: Purch:Sum(Qordered) ? Purch:Sum(Qrcvd)
= Inv:Qonorder is maintained

Among the above constraints, the rst two are state invariant constraints, the
second is a trajectory invariant constraint, and the third is a state maintenance
constraint. These constraints can be specied in rst-order logic with temporal
and aggregate constructs. We specify them using such constructs below with
the assumption that all free variables are universally quantied and all the
existentially quantied variables are denoted by underscores \ ".

 (C1') (Inv(It#; ; S1 ; ; ; ; ; ; ) ^ Purch( ; ; S2 ; It#; ; ; ; ))
) (S1 = S2 )
 (C2') (Inv(It#; ; ; ; ; ; UOP1 ; ; ) ^ Purch( ; ; ; It#; ; ; ; UP2 ))
) (UOP1 = UP2 )
 (C3') (:Purch(OD; OT; S #; It#; ; ; ; )^
nexttime (Purch(OD; OT; S #; It#; ; ; ; ))) )
nexttime (OD = date ^ OT = time)
 (C4.1') R1 (It#; Sum Qord) = It# GSum Qordered(Purch)
(C4.2') R2 (It#; Sum Qrcvd) = It# GSum Qrcvd(Purch)
(C4') (quiescent ^ R1 (It#; Sum Qord) ^ R2 (It#; Sum Qrcvd) ^
Inv(It#; ; ; ; ; Qonorder; ; ; )) ) (Sum Qord?Sum Qrcvd = Qonorder)
12

The rst order formulas (C1') and (C2') are low level representations of the
state invariant constraints (C1) and (C2) respectively. The temporal formula
(C3') is a low level representation of the trajectory invariant constraints (C3)
and the temporal operator nexttime in (C3') has the usual FTL (future
temporal logic) [CT95] meaning. Next we have the formulas (C4.1'), (C4.2')
containing grouping aggregation expressions using the notation3 from the text
book [SKS96], and (C4') which are a low level representation of the state maintenance constraint (C4). Note the dierence between (C4') and (C1'-C2'). Since
the former is a maintenance constraint, we use the proposition quiescent in the
left hand side of the implication, meaning that the implication only holds in
quiescent states. On the other hand the implications in (C1'-C2') must hold in
all states.

Proposition 1 Let DB be the schema declaration in Section 3.1, and the only
allowable exogenous action is `Insert into Purch with Dtrecvd and Qrcvd as
null, and Qordered as a positive value'. Then in the context of DB the set of
triggers fPT1,PT2g, is correct w.r.t. the set of constraints fC1, C2, C3, C4g,
and the above mentioned exogenous action.
2

4 Interrupting exogenous updates
So far we have (implicitly) assumed that if new exogenous update requests come
in when the active database system is in the midst of processing ECA rules due
to a previous exogenous update, the new requests are kept in hold until the
processing (due to the previous update) comes to an end. Such an assumption
is perhaps acceptable when the exogenous updates are not that frequent and/or
trigger processing is not that time consuming, and there is no guaranteed quality
of service requirement.
With the popularity of e-commerce where updates to the database would often
be due to e-transactions over the web, companies may require a guaranteed quality of service requirement. In particular, they may require immediate response
to requests. In such a case, it may be a good idea to partition maintenance triggers to two kinds short term and long term, with the idea that in order to give
reactive response to new update requests, processing of long term maintenance
triggers may be postponed in favor of processing the new update request.
3 In this notation the general form is:
G1 ;G2 ;:::;Gn GF1 A1 ;F2 A2 ;:::;Fm Am (E ), where E
is any relational-algebra expression, G1 ; : : : ; Gn constitute a list of attributes on which to
group, each Fi is an aggregate function, and each Ai is an attribute name. The meaning of
the operation is dened as follows. The tuples in the result of expression E are partitioned
into groups such that:
(i) All tuples in a group have the same values for G1 ; : : : ; Gn .
(ii) Tuples in dierent groups have dierent values for G1 ; : : : ; Gn .
The groups now can be identied by the values of the attributes G1 ; : : : ; Gn of the relation,
and for each group (g1 ; : : : ; gn ), the result has a tuple (g1 ; : : : ; gn ; a1 ; : : : ; am ) where, for each
i, ai is the result of applying the aggregate function Fi on the multi-set of values for the
attribute Ai in the group.

13

The formulation of correctness in such a case becomes tricky, and we have made a
small start in that direction. In this we only consider condition-action triggers,
and consider all triggers to be long term. Before we get to our denition of
correctness in such cases, we have the following notation. Let T be a set of
condition-action triggers, and  be a database state. By T () we denote the
action of the trigger which has the highest priority among the triggers whose
conditions are satised in . We also have the following additional notations:
 0T () = T () and T0 = .
 k+1 () = T (k+1 ) and k+1 = (K (); k ).
T

T

T

T

T

Denition 6 (k-maintenance) Let T be a set of condition-action triggers, ?

be a set of long term maintenance constraints, S be a set of states, and A be a
set of allowable exogenous actions.
By Closure(S; T; A) we denote the smallest set of states that is a superset of S
and that satises the properties that if  2 S , then for an exogenous action a
from A, (a; ) 2 S , and (T (); )) 2 S .
We say T k-maintains the maintenance constraints ? from S and A, if for each
state  in S , the sequence T0 ; : : : ; Tk satises ?.
2

Intuitively, the notion of k-maintenance means that the active database system
will get back to consistency (with respect to ?) if it is given a window of opportunity of processing k triggers without any outside interference in terms of new
update requests.
An important aspect of such a notion of k-maintainability is that in reactive
(active database) systems, if we know that our system is k-maintainable, and
each transition takes say t time units, then we can implement a transaction
mechanism that will regulate the number of exogenous actions allowed per unit
time to be k1 t . On the other hand, given a requirement that we must allow m
requests (exogenous actions) per unit time, we can work backwards to determine
the value of k, and then nd a set of triggers to make the system k-maintainable.

5 Conclusion and future work

In this paper we have taken several steps towards the systematic design of
active features in an active database. The main steps that we have taken are
identifying a few constructs for specication, classifying triggers into distinct
classes based on their purpose, linking the trigger classes with the specication
classes, formulating correctness of triggers with respect to a given specication,
elaborating our formulation through examples and briey introducing the notion
of k-maintainability.
Due to space limitations we were not able to detail our formulation (especially,
the prioritization used in dening 	 and the dierentiation between row and
statement triggers) and show the design methodology with respect to a large
14

example. In the full version we will show how our formulation in this paper can
be used in systematically developing the triggers for the complete example in
[Cha96], starting from a specication which is not given in [Cha96]. Our main
future work will be to develop composition methods and theorems so that given
sets of triggers T1 and T2 that are correct with respect to specications S1 and
S2 respectively, we can construct triggers that are correct with respect to S1 [S2 .
We also plan to identify additional specication constructs with matching trigger
sub-classes, and further elaborate on our notion of k-maintainability.

References
[ADA93] P. Atzeni and V. De Antonellis. Relational database theory. The
Benjamin/Cummings publishing company, 1993.
[BL96] C. Baral and J. Lobo. Formal characterization of active databases.
In Proc. of International Workshop on Logic in Databases { LID'96
(LNCS 1154), pages 175{195, 1996.
[BLT97] C. Baral, J. Lobo, and G. Trajcevski. Formal characterization of active
databases: Part II. In DOOD 97, 1997.
[CF97] S. Ceri and P. Fraternali. Designing database applications with objects
and rules { the IDEA methodology. Addison-Wesley, 1997.
[Cha96] D. Chamberlin. Using the new DB2: IBM's Object-relational database
system. Morgan Kaufmann, 1996.
[CT95] J. Chomicki and D. Toman. Implementing temporal integrity constraints using an active dbms. IEEE transactions on knowledge and
data engineering, 1995.
[GL93] M. Gelfond and V. Lifschitz. Representing actions and change by logic
programs. Journal of Logic Programming, 17(2,3,4):301{323, 1993.
[Pat98] N. Paton. Active rules in database systems. Springer-Verlag, 1998.
[SKS96] A. Silberschatz, H. Korth, and S. Sudershan. Database System Concepts. McGraw Hill, 3rd edition, 1996.
[Ull88] J. Ullman. Principles of Database and Knowledge-base Systems, volume I. Computer Science Press, 1988.
[WC96] J. Widom and S Ceri, editors. Active Database Systems - Triggers and
Rules for advanced database processing. Morgan Kaufmann, 1996.
[Wid96] J. Widom. The Starbust rule system. In J. Widom and S Ceri, editors,
Active Database Systems, pages 87{110. Morgan Kaufmann, 1996.

15

