A GPU-based Correlator X-engine Implemented on the CHIME Pathfinder
Nolan Denman, Mandana Amiri,§ Kevin Bandura, Jean-Franc ¸ ois Cliche, Liam Connor,¶  § § § Matt Dobbs, Mateus Fandino, Mark Halpern, Adam Hincks, Gary Hinshaw,§ Carolin H¨ ofer,§  §    Peter Klages, Kiyoshi Masui, Juan Mena Parra, Laura Newburgh, Andre Recnik, J. Richard Shaw,¶ Kris Sigurdson,§ Kendrick Smith, and Keith Vanderlinde

arXiv:1503.06202v2 [astro-ph.IM] 11 Jun 2015

Dunlap Institute, University of Toronto Department of Astronomy and Astrophysics, University of Toronto § Department of Physics and Astronomy, University of British Columbia  Department of Physics, McGill University ¶ Canadian Institute for Theoretical Astrophysics Canadian Institute for Advanced Research, CIFAR Program in Cosmology and Gravity  Perimeter Institute for Theoretical Physics Contact E-Mail: denman@astro.utoronto.ca




Abstract--We present the design and implementation of a custom GPU-based compute cluster that provides the correlation X-engine of the CHIME Pathfinder radio telescope. It is among the largest such systems in operation, correlating 32,896 baselines (256 inputs) over 400 MHz of radio bandwidth. Making heavy use of consumer-grade parts and a custom software stack, the system was developed at a small fraction of the cost of comparable installations. Unlike existing GPU backends, this system is built around OpenCL kernels running on consumer-level AMD GPUs, taking advantage of low-cost hardware and leveraging packed integer operations to double algorithmic efficiency. The system achieves the required 105 TOPS in a 10 kW power envelope, making it one of the most power-efficient X-engines in use today.

the system achieves high performance at a small fraction of the hardware cost of comparable installations. This paper focuses on the system architecture and implementation, while two companion papers describe the custom software stacks, one focusing on an innovative OpenCL-based X-engine GPU kernel [2], and one on the handling of the vast data volume flowing through the system [3]. The paper is structured as follows: design considerations and constraints are discussed in §II; the hardware components of the system are described in §III, and the software in §IV; the scaling of the X-engine to the full-size CHIME telescope is described in §V, and a summary and conclusion follow in §VI. II. D ESIGN C ONSIDERATIONS

I.

I NTRODUCTION While most components in CHIME scale linearly with number of inputs N , the computational cost of pairwise correlation scales as N 2 , making efficiency in the X-engine a primary concern. There are correlation techniques which rely on the redundancy of CHIME feed separations to scale as N log N , but the real-time calibrations these require for precision observations remain largely unproven in an astrophysical context. Design decisions were guided by the need to produce an inexpensive system capable of scaling to support full CHIME, and which would support rapid development and deployment of new data processing algorithms. These requirements of computational power and ease of development drove the decision to build the X-engine around GPUs rather than Application-Specific Integrated Circuits (ASICs) or FPGAs. The computational cost  of pairwise element correlation for N elements across a bandwidth of  is  =  · N · (N + 1)/2 (1)

The Canadian Hydrogen Intensity Mapping Experiment (CHIME) is an interferometric radio telescope, presently under construction at the Dominion Radio Astrophysical Observatory (DRAO) in British Columbia, Canada, which will map the northern sky over a radio band from 400 to 800 MHz. With over 2000 inputs and a 400 MHz bandwidth, the correlation task (measured as the bandwidth-baselines product) on CHIME will be an order-of-magnitude larger than on any currently existing telescope array. The correlator follows an FX split design, with a first stage Field Programmable Gate Array (FPGA)-based F-engine which digitizes, Fourier transforms (channelizes), and bundles the data into independent frequency bands, followed by a second-stage Graphics Processing Unit (GPU)-based X-engine which produces a spatial correlation matrix consisting of the integrated pairwise products of all the inputs at each frequency. The CHIME Pathfinder instrument [1] features 128 dualpolarization feeds and a reduced-scale prototype of the full CHIME correlator. This paper describes the X-engine of the Pathfinder's 256-input hybrid FPGA/GPU FX correlator, among the largest such systems in operation. Through extensive use of off-the-shelf consumer-grade hardware and heavy optimization of custom data handling and processing software,

measured in complex multiply-accumulate (cMAC) operations per second; for the CHIME Pathfinder,  = 13 TcMAC/s. For large N this dominates the cost of any other processing proposed for the X-engine. Top-end GPUs in 2014 provided of

Fig. 4. Screenshot showing the correlator status webpage. The monitoring system displays the status of each FPGA and GPU node, and of the correlator software; per-GPU temperatures and per-node power consumption are also available.

Fig. 3. A diagram showing the liquid-cooling structure in the CHIME Pathfinder, with red and blue indicating hot and cold coolant, respectively. The heat exchanger uses a large fan to cool the liquid using ambient outside air. The object marked `M' is a temperature-controlled mixing valve, which regulates the temperature of the `cold' sections of the loop.

kotekan4 software pipeline manages the data flow and processing within GPU nodes. Due to the high I/O demands (820 Gb/s in total), the system must make maximally efficient use of the available bandwidth at each stage. A packetized and loss-tolerant data handling system, similar to that in operation in the PAPER [6] correlator [7] ensures that momentary faults do not impede long-term data gathering. Recnik et. al. [3] discuss the data handling in detail; a brief description follows. Data arrive as UDP packets and are buffered by the host CPU in system memory for inspection and staging prior to transfer into the GPUs for processing. Packet loss, though rare, is tracked along with other flags from the F-engine from e.g. saturation of the ADCs or from FFT channelizing. The count of missing or saturated data is used to renormalize the postintegration correlation matrices. A series of OpenCL kernels are executed on the GPUs; these pre-condition the data, compute and integrate correlation matrices, and post-process the data if necessary (see [2] for more details). Computed correlation matrices are assembled by the CPU and forwarded to gamelan, which stitches the full 400 MHz band back together using data from all active nodes. This reassembly is robust against individual node failures or outages; they simply result in loss of data from the inactive nodes. Integrated correlation matrices are recorded onto an array of disks in gamelan, and these data are asynchronously copied to a remote archive server hosting a much larger array of drives, and then copied off-site for scientific analyses.

Fig. 5. Screenshot showing the live view webpage. The triangle is the full correlation matrix for a particular frequency, with colour indicating the complex value's phase; the website may be queried for any of the associated data.

B. Monitoring and Control The X-engine software pipeline (composed of the kotekan instances on each node, along with the collection server software) is launched and controlled through scripts run on gamelan. The nodes run CentOS Linux 6.5 and can be accessed by remote shell login, while the PDUs allow remote power cycling to aid in recovery of crashed systems. The status of each of the GPU nodes is tracked by the gamelan control node, and made available via a web interface; see Figure 4 for an example of the tracking display. In addition, the last few hours of data are streamed over TCP to a second server, where it is available for live analysis and monitoring. An example of the live-monitoring webpage is shown in Figure 5. C. GPU Data Processing Tasks The most computationally expensive operation performed on the GPU nodes is the mission-critical pairwise feed correlation. In parallel with this, the Pathfinder correlator will explore alternate correlation methods which leverage the redundant layout of the CHIME baselines. Supplemental tasks include beamforming, gating, time-shifting of inputs, and RFI excision. Brief descriptions of these tasks follow.

4 A style of playing fast interlocking parts in Balinese Gamelan music; see http://en.wikipedia.org/wiki/Kotekan

1) Full Correlation: The primary responsibility of the Xengine is to calculate and integrate the correlation matrix of all the spatial inputs. This involves accumulation of 32,896 pairwise products for each of 1024 frequency bands. The default integration period is 223 samples, corresponding to 21.47 s, much faster than the 2.5 minute beam-crossing time from sky rotation. The computational requirements of the full X-engine system are dominated by this correlation operation, such that all other processes constitute an insignificant additional burden. The current implementation achieves nearmaximum-theoretical throughput; for details, see Klages et. al. [2] 2) Alternate Correlation Techniques: Interferometric arrays with highly redundant baselines can take advantage of correlation techniques that are more efficient than the na¨ ive pairwise method. In the case of feeds which are evenly spaced, FFT-based transformations can be used to increase the efficiency of the correlation to N log N , at the cost of strict calibration requirements. [8][9][10] These correlation strategies will be tested in parallel with the pairwise N 2 correlation; additionally, they may be used in hybrid form with some N 2 and some N log N stages. 3) Discrete Beamforming: The CHIME Pathfinder is a stationary telescope that cannot physically point at a specific source or location on the sky. When observing localized sources, it is desirable to form one or more beams, `pointing' the telescope digitally to an arbitrary location within the main beam. This is accomplished in the GPUs by phase-shifting and summing the data from all antennas, so that signals originating in one region of the sky interfere constructively. This signal is then written out at very high cadence, allowing examination of a localized source with very fine time resolution. 4) Output Gating: The CHIME Pathfinder will observe periodic sources such as astronomical pulsars and injected calibration signals. These sources generally vary faster than the default 21 s integration period, but high-cadence gating may be used to observe sub-integration signal structure. Gating consists of partitioning the output into a set of sub-buffers based on the time relative to the period of the source, so that independent `on' and `off' signals may be constructed. 5) Time Shifting: Signals from outlying telescope stations can be fed into the correlator. Large spatial separations introduce decorrelation between inputs, which can be corrected for by time-shifting samples within the GPUs. The current implementation permits the correction of any input by up to 168 ms, and has been tested with the nearby John A. Galt 26m radio telescope at DRAO. 6) RFI Cleaning: Anthropogenic radio frequency interference (RFI) introduces a significant source of additional noise to the astronomical signal. These signals are generally narrow-band and intermittent, coming and going on timescales much shorter than the default 21 s integration period, but with relatively low duty cycles. High-cadence identification and excision of RFI can be performed within the GPUs, and a variety of algorithms are under development including robust outlier and higher-moment statistical tests. [11][12]

V.

X- ENGINE S CALABILITY

The X-engine described here was designed for the CHIME Pathfinder, and must be scaled up significantly for the full CHIME instrument. Given a scaled F-engine providing channelized data, the X-engine's design allows it to scale straightforwardly to a broader band or larger-N arrays. Additional radio bandwidth is trivially added through additional nodes; increasing the number of inputs adds to the computational demand on each node, and can be addressed through newer, more powerful GPUs. At the time of writing, the computational power per node could be roughly tripled by simply replacing the GPUs. To support larger N 2 requirements, the bandwidth handled in each node can be reduced, in exchange for proportionally more nodes. The bandwidth fed to each GPU can similarly be reduced, and for very large N , when even a single frequency band is beyond the capacity of a single processing node, data can be time-multiplexed across multiple GPUs. The expansion to full CHIME (N = 2048) yields an N 2 computational requirement  an order-of-magnitude greater than any system currently in existence. Using current technology, a straightforward scaling of the current system -- 256 nodes each containing 2 dual-chip R9 295X2 GPUs -- could handle the entire pairwise correlation task, without additional software development. This density of processors is easily achievable with the liquid cooling demonstrated, and would occupy a modest physical footprint, at a very low hardware cost of $1M. However, it is not expected that the full CHIME instrument will rely on a complete N 2 correlation, instead pursuing a fast alternate correlation technique as discussed in §IV-C2. VI. C ONCLUSION

We have implemented a low-cost, high-efficiency GPUbased correlator X-engine for the CHIME Pathfinder. Capable of correlating 32,896 baselines over 400 MHz of radio bandwidth, it makes efficient use of consumer-grade parts and executes a highly optimized software stack. Measured by the computational requirement of a na¨ ive N 2 correlation ­ the bandwidth-baseline product  defined by Equation 1 ­ the CHIME Pathfinder correlator is among the largest in the world. Aspects of the system such as the cooling systems have been substantially modified, optimizing the X-engine's efficiency and ensuring economical scaling to the full-size CHIME instrument. ACKNOWLEDGEMENTS We are very grateful for the warm reception and skillful help we have received from the staff of the Dominion Radio Astrophysical Observatory, which is operated by the National Research Council of Canada. We acknowledge support from the Canada Foundation for Innovation, the Natural Sciences and Engineering Research Council of Canada, the B.C. Knowledge Development Fund, le Cofinancement gouvernement du Qu´ ebec-FCI, the Ontario Research Fund, the CIFAR Cosmology and Gravity program, the Canada Research Chairs program, and the National Research Council of Canada. PK thanks IBM Canada for funding

his research and work through the Southern Ontario Smart Computing Innovation Platform (SOSCIP). We thank Xilinx University Programs for their generous support of the CHIME project, and AMD for donation of test units. R EFERENCES
[1] K. Bandura et al., "Canadian Hydrogen Intensity Mapping Experiment (CHIME) Pathfinder," in Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series, ser. Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series, vol. 9145, Jul. 2014, p. 22. P. Klages et al., "Data Packing for High-Speed 4-Bit GPU Correlators," 2015, In press; accepted to IEEE ASAP 2015. A. Recnik et al., "An Efficient Real-time Data Pipeline for the CHIME Pathfinder Radio Telescope X-Engine," 2015, In press; accepted to IEEE ASAP 2015. M. A. Clark, P. C. La Plante, and L. J. Greenhill, "Accelerating Radio Astronomy Cross-Correlation with Graphics Processing Units," ArXiv e-prints, Jul. 2011. Khronos Group: The OpenCL Specification. [Online]. Available: khronos.org/opencl A. R. Parsons et al., "New Limits on 21 cm Epoch of Reionization from PAPER-32 Consistent with an X-Ray Heated Intergalactic Medium at z = 7.7," The Astrophysical Journal, vol. 788, p. 106, Jun. 2014. A. Parsons et al., "A Scalable Correlator Architecture Based on Modular FPGA Hardware, Reuseable Gateware, and Data Packetization," Publications of the Astronomical Society of the Pacific, vol. 120, pp. 1207­1221, Nov. 2008. J. D. Bunton, "Antenna Array Geometries to Reduce the Compute Load in Radio Telescopes," IEEE Transactions on Antennas and Propagation, vol. 59, pp. 2041­2046, Jun. 2011. M. Tegmark and M. Zaldarriaga, "Fast Fourier transform telescope," Physical Review D, vol. 79, no. 8, p. 083530, Apr. 2009. ----, "Omniscopes: Large area telescope arrays with only NlogN computational cost," Physical Review D, vol. 82, no. 10, p. 103501, Nov. 2010. G. M. Nita, D. E. Gary, Z. Liu, G. J. Hurford, and S. M. White, "Radio Frequency Interference Excision Using Spectral-Domain Statistics," Publications of the Astronomical Society of the Pacific, vol. 119, pp. 805­827, Jul. 2007. G. M. Nita and D. E. Gary, "Statistics of the Spectral Kurtosis Estimator," Publications of the Astronomical Society of the Pacific, vol. 122, pp. 595­607, May 2010.

[2] [3]

[4]

[5] [6]

[7]

[8]

[9] [10]

[11]

[12]

