iPhone Application Development
Javier Gonzalez-Sanchez

Maria Elena Chavez-Echeagaray

Arizona State University
University Drive and Mill Avenue
Tempe, AZ. 85281

Arizona State University
University Drive and Mill Avenue
Tempe, AZ. 85281

javiergs@asu.edu

helenchavez@asu.edu

Abstract
Apple's mobile handheld devices have been a huge success, beginning with the launching of the iPhone in 2007 and continuing
until the present with the launching of the iPad in 2010. There are
now more than 85,000 apps available for more than 50 million
iPhone and iPod touch customers worldwide and over 125,000
developers registered in Apple’s iPhone Developer Program.
iPhone is a new and widely extended platform for developing
object-oriented applications. The iPhone platform involves several
unique technologies that makes developing applications both a
challenging and an engaging activity for experienced programmers willing to learn about a mobile device, and a great option for
students or novices to learn foundational programming skills.
Both novices and experts will find the power of the iPhone libraries and development tools helpful for quickly building powerful
iPhone apps. In this tutorial, we will be using Xcode under Mac
OS X as our integrated development environment (IDE), and Objective-C and iPhone API as our programming tools to create
basic to medium level iPhone applications. We’ll start with the
classic “Hello World” sample application and continue to develop
more advanced applications using graphical user interfaces, handling multi-touch and motion detection, communication interfaces, and integrating different media.
Categories and Subject Descriptors D.3.2 [Programming
Languages]: Language classifications --- Object-oriented languages, Specialized applications languages, D.1.5 [Programming
Techniques]: Object-oriented programming.
General Terms Design, Languages, Theory.
Keywords iPhone SDK; Xcode; Objective-C; Mobile applications
development; Apple technology.

1.

Introduction

iPhone is a device that incorporates several technologies including: phone, multi-touch interface, sensors, video camera, video
and audio player, a high resolution small screen, and several
methods of wireless communication. The iPhone has received

Copyright is held by the author/owner(s).
SPLASH’10 October 17–21, 2010, Reno/Tahoe, Nevada, USA.
ACM 978-1-4503-0240-1/10/10.

several awards such as the best device in 2007 (Times Magazine),
and it was the big winner in the 2008 British Technology Awards.
It also claimed the award for Gadget of the Year, won the Best
Mobile Technology, Most Stylish Technology, and Technological
Innovation awards in 2009.
iPhone has captivated the interest of different types of users and
created emerging markets in various environments. Today, thousands of programmers want to provide applications for the iPhone
and take advantages of the device’s numerous features.

2.

Tutorial Presentation History

This tutorial has been presented in OOPSLA 2008 and OOPSLA
2009. In addition, this material has been presented in other forums
such as Tecnologico de Monterrey (in Mexico) and Arizona State
University (in USA). This has helped to improve the content,
activities and time management of the tutorial. The slides and
examples that we have been using during these years are available
on the web, and can be found at http://iphone.javiergs.com.

3.

Tutorial Objectives

Through this tutorial, the attendee will:
•
•
•
•
•

•

4.

Learn about iPhone software architecture.
Learn about iPhone Development tools and Objective-C
programming language.
Learn about the iPhone Application Framework.
Learn about the User Interface Design and key practices for
iPhone applications.
Learn how to take advantage of the capabilities for
measuring location, acceleration, orientation and using multitouching in applications.
See an overview about the construction of rich graphics and
media applications.

Tutorial Content

This is a three-hour tutorial, during which, after a brief
introduction about iPhone software architecture and iPhone SDK
developing tools, our intention is that participants work on handson activities. Attendees will develop applications and test them on
an iPhone simulator or on an iPhone physical device. Throughout
the tutorial, we will alternate between lecture and hands-on
activities.

In order to take the most advantage of this tutorial, it is desirable
that attendees work using their own laptops with the iPhone SDK
installed in advance.
4.1

Kick Off

Even though the iPhone’s size is small, its power and potential are
not. As we get ready to create applications for this platform, it is
good to have in mind its characteristics and limitations so that we
can maximize its benefits, thus we begin the tutorial discussing:
•
•
•
•
•
•
•
•
4.2

iPhone physical specifications.
Detailed description of hardware features.
Multi-threading characteristics (differences between iOS 4
and previous versions).
Graphical User Interface guideline design.
The screen size.
The five seconds rule.
File and data management.
Memory management and lack of garbage collection.
Getting Started with the Development Tools

Once we have everything installed and ready, we can start working with the development tools. In order to develop an iPhone
application, we will need to use the following development tools:
•

•

•

Xcode. This is Apple's Integrated Development Environment
(IDE) and it includes all tools we need to create and manage
our iPhone projects and source files, build our code into an
executable, and run and debug our code either on the iPhone
simulator or on a device.
Interface Builder. This is the tool we use to visually assemble
our application’s user interface. Using Interface Builder, we
assemble our application’s window by dragging and dropping pre-configured components onto it. The components include standard system controls such as switches, text fields,
and buttons, and also custom views to represent the views
our application provides. After we have placed the components on the window’s surface, we can position them by
dragging them around, configure their attributes using the inspector, and establish the relationships between those objects
and our code.
iPhone simulator. When we build our application in Xcode,
we have a choice of building it for iPhone simulator or for a
device. The simulator provides a local environment for testing our applications to make sure they behave essentially the
way we want. After we are satisfied with our application’s
basic behavior, we can tell Xcode to build it and run it on an
iPhone or iPod touch connected to our computer.

These tools are free, however they do not allow us to upload our
applications to our iPhone (or iPod Touch, or iPad) or distribute
our software in Apple's iPhone App Store. In order to do this, we
have to sign up for the iPhone Developer Program.
4.3

Reviewing iOS Framework and Architecture

The iOS comprises the operating system and technologies that we
use to run applications natively on iPhone and iPod touch devices.

Although it shares a common heritage and many underlying
technologies with Mac OS X, iOS was designed to meet the needs
of a mobile environment. Existing Mac OS X developers will find
many familiar technologies, but they will also find technologies
that are available only on iOS supported hardware.
We will present here the iOS framework architecture and explore
the four layers of its architecture: Cocoa Touch, Media, Core Services, and Core OS.
4.4

Learning About Objective-C

Objective-C is a reflective, object-oriented programming language
that adds Smalltalk-style messaging to the standard ANSI C language. The use of objects and object-oriented constructs is fundamental to the design of iPhone applications, and understanding
how they interact is critical to creating our applications, so it helps
if attendees have previous experience with object-oriented languages.
The goal of this part of the tutorial is to quickly review the syntax
of Objective-C, and be sure that the attendee feels comfortable
creating classes, methods, protocols, and delegates using this language.
4.5

Creating an iPhone Application

After reviewing all the concepts mentioned above and learning
about all the tools we need, we will describe a step-by-step
procedure to create a simple “Hello World” application. Later, we
will extend this application. We are going to:
•
•
•

•

•

4.6

Add labels, buttons, and work with event process.
Become familiar with and used to working with Xcode and
Interface Builder.
Talk about Software Design Patterns and how they are
fundamental in Phone application development; in particular
we will need to review the Model View Controller (MVC),
Singleton and Delegate patterns.
Learn about and make relationships with IBAction and
IBOutlet keywords, as well as understand how these are
used to connect our code with the graphical user interfaces.
Work with the View-based template and the Navigationbased template for projects in Xcode.
Process Multi-Touch Events

One of the unique features of the iPhone is its ability to handle
touch events. The multi-touch interface of the iOS provides an
application with the ability to recognize and react to different
events triggered when one or multiple fingers touching the iPhone
screen. When a finger touches the screen a touch event is created.
When a finger moves across the screen, new touch events are
created in order to track the new position of the finger. When the
finger loses its contact with the screen, the system creates another
touch event to capture that. The system tracks all these events and
reacts. Every time that a touch event is created, it includes
information regarding the current state of each finger in contact
with the screen (either touching the screen or when it looses
contact with the screen). This allows the system to keep track of
all the finger actions. Working with this characteristic requires the

developer to know and work with the UIResponder class and its
methods.
4.7

fidelity regardless of display or printing device. Quartz is
resolution and device independent; we do not need to think
about the final destination when we use the Quartz application-programming interface (API) for drawing. The Quartz
2D API is easy to use and provides access to powerful features such as transparency layers, path-based drawing, offscreen rendering, advanced color management, anti-aliased
and rendering.

Sensors

To learn about sensors we are mainly going to spend time
reviewing the Accelerometer and the Core Location Framework:
•

•

Accelerometer. iPhone has a three-axes accelerometer to
detect motion in any direction. It can detect the physical orientation of the device in a 3D space. We can then apply this
orientation and its changes as inputs to our application. In
order to do that, UIViewController class provides the infrastructure needed to rotate our interface and adjust the position of views automatically in response to orientation
changes. The UIAccelerometer object in UIKit provides us
with direct access to the raw accelerometer data. We can also
use the data to detect the device's orientation or to detect other types of instantaneous motion, such as the user shaking the
device back and forth.
Core Location. The Core Location framework uses the available hardware (GPS, Cellular triangulation or Wi-Fi) to determine the user’s position and heading. We will use the
classes and protocols in this framework to configure and
schedule the delivery of location and heading events.

At this point we will be reviewing and using the CLLocationManager and CLLocationManagerDelegate classes in our applications.
4.8

•

4.9

Data Manipulation and More Examples

We will play with different examples that involve data
manipulation, from arrays of objects to examples of the use of the
Core Data framework which provides solutions to common tasks
associated with object life-cycle including persistence. Remember
that we are working in an object-oriented environment so most of
our data will be related and organized in objects that have
attributes and methods.
One way to achieve persistence with CoreData is based upon
SQLite. SQLite is a library that implements a self-contained,
server-less, zero-configuration, and transactional-SQL database
engine. We are going to spend some time talking about this. For
this part of the tutorial it will be useful—although not essential—
to have at least a superficial understanding of the SQL language.

Graphics and Media

At this point in the tutorial, all attendees will have a solid
foundation for developing iPhone apps. Thus, this will be a good
point to move forward and take a look at computer graphics. This
will be a really basic introduction; this tutorial is not about how to
create videogames or similar applications, but we will review
some basics, so if someone is interested in learning more, they
will know where to search. We will talk about:
•

Quartz API is part of the Core Graphics framework that we will
review in this part of the tutorial.

OpenGL ES. Open Graphics Library (OpenGL) is a crossplatform C-based interface used for visualizing 2D and 3D
data. OpenGL functions send graphics commands to the underlying hardware, where they are then rendered. Because
this underlying hardware is dedicated to processing graphics
commands, OpenGL drawing is typically very fast. OpenGL
for Embedded Systems (OpenGL ES) is a version of
OpenGL designed for mobile devices and takes advantage of
modern graphics hardware.
Quartz. It is a two-dimensional drawing engine available for
iOS application development and to all Mac OS X application environments outside of the kernel. Quartz provides
low-level lightweight 2D rendering with unmatched output

This is the last topic on our agenda, so if time permits, we will
show examples and give references to motivate attendees to continue learning on their own after leaving the session.

5.

Audience

This tutorial is open to researchers, practitioners, and educators.
We assume that attendees have some programming skills but are
not required to know any specific programming language or
development tools. As described above, the tutorial starts with a
brief description of the language, the tools, the architecture of the
apps and after that we show, through different examples, how to
build apps that take advantage of many of the different qualities
and features of Apple’s mobile devices.

References
Apple: iPhone Dev Center, 2010. Retrieved August 25, 2010,
from Apple Developer – iPhone Dev Center:
http://developer.apple.com/iphone.

37

Evaluation of a meta-tutor for constructing models of
dynamic systems
Lishan Zhang, Winslow Burleson, Maria Elena Chavez-Echeagaray, Sylvie Girard,
Javier Gonzalez-Sanchez, Yoalli Hidalgo-Pontet, Kurt VanLehn
Arizona State University, Computing, Informatics, and Decision Systems Engineering, Tempe,
AZ, 85281, U.S.A.
{lishan.zhang, winslow.burleson, mchaveze, sylvie.girard, javiergs, yhidalgo,
kurt.vanlehn}@asu.edu

Abstract. While modeling dynamic systems in an efficient manner is an important skill to acquire for a scientist, it is a difficult skill to acquire. A simple
step-based tutoring system, called AMT, was designed to help students learn
how to construct models of dynamic systems using deep modeling practices. In
order to increase the frequency of deep modeling and reduce the amount of
guessing/gaming, a meta-tutor coaching students to follow a deep modeling
strategy was added to the original modeling tool. This paper presents the results
of two experiments investigating the effectiveness of the meta-tutor when compared to the original software. The results indicate that students who studied
with the meta-tutor did indeed engage more in deep modeling practices.
Keywords: meta-tutor , intelligent tutoring systems, empirical evaluation

1

Introduction

Modeling is both an important cognitive skill [1] and a potentially powerful means of
learning many topics [5]. The AMT system teaches students how to construct system
dynamics models. Such models are widely used in professions, often taught in universities and sometimes taught in high schools.
1.1

The modeling language, development tool and tutoring system

In our modeling language, a model is a directed graph with one type of link. Each
node represents both a variable and the computation that determines the variable’s
value. Links represent inputs to the calculations. As in illustration, Figure 1 shows a
model for the following system:
The initial population of bacteria is 100. The number of bacteria born each
hour is 10% of the population. Thus, as the population increases, the number
of births increases, too. Model the system and graph the population over 20
hours.
Clicking on a node opens an editor with these tabs (and 2 others not described here):

38

x

Description: The student enters a
description of the quantity represented
by the node.
x Inputs: The student selects inputs to
the calculation of the node’s value.
x Calculation: The student enters a
formula for computing the node’s
value in terms of the inputs.
There are three types of nodes in models:
x A fixed value node represents a constant value that is directly specified in
Fig. 1. A simple model.
the problem. A fixed value node has a
diamond shape, never contains incoming links, and its calculation is just a single
number. For instance, “growth rate” has 0.1 as the calculation of its value.
x An accumulator node accumulates the values of its inputs. That is, its current value is the sum of its previous value plus or minus its inputs. An accumulator node
has a rectangular shape and always has at least one incoming link. For instance,
the calculation tab of “population” states that its initial value is 100 and its next
value is its current value + births.
x A function node’s value is an algebraic function of its inputs. A function node has
a circular shape and at least one incoming link. For instance, “births” has as its
calculation “population * growth rate.”

The students’ task is to develop a model that represents a system described by a
short text. They can create, edit and delete nodes using the node editor. When all the
nodes have calculations, students can click the Run Model button, which performs
calculations and draws graphs of each nodes’ values over time. The system described
so far is just a model development tool.
AMT has a simple tutoring capability. Each tab of the node editor has a Check
button which turns its fields red if they are incorrect and green if they are correct.
Each tab also has a Give up button that fills out the tab correctly. Thus, the system
described so far is just a simple step-based tutoring system with minimal feedback on
demand and only one kind of hint: a bottom-out hint.
1.2

The meta-tutor

Unfortunately, it is a rare for students to think semantically in terms of what the
nodes, inputs and calculations mean actually mean. Students prefer to think of model
elements syntactically, like puzzle pieces that need to be fit together. This shows up
in a variety of ways, including rapid guessing, nonsensical constructions and the use
of syntactic rather than semantic language to refer to model elements. The literature
on model construction (reviewed in [5]) sometimes refers to these two extremes as
Deep vs. Shallow modeling. The objective of the AMT system is to increase the relative frequency of Deep modeling.

39

A variety of methods for increasing the frequency of Deep modeling have been
tried [5]. For instance, nodes can bear pictures of the quantities they represent, or
students can be required to type explanations for their calculations. One of the most
promising methods is procedural scaffolding, wherein students are temporarily required to follow a procedure; the requirement is removed as they become competent.
This technique was used by Pyrenees [2], where it caused large effect sizes.
We adapted Pyrenees’ procedure to our modeling language and called it the Target
Node Strategy. The strategy requires students to focus on one node, called the target
node, and completely define it before working on any other node. This decomposes
the whole modeling problem into a series of atomic modeling problems, one per node.
The atomic modeling problem is this: Given a quantity, find a simple calculation that
will compute its values in terms of other quantities without worrying about how those
other quantities values will be calculated. This is a much smaller problem than the
overall challenge of seeing how the overall model can be constructed.
As an illustration, let us continue the bacteria population example and suppose that
the target node is “number of bacteria born per hour.” The ideal student might think:
“It says births are 10% of the population, so if I knew population, then I could figure out the number of births. In fact, I could define a node to hold the 10%, and
then the calculation would multiply it and population. But do I need initial population or current population? Oh. The number of bacteria born is increasing, so I
must need current population, because it is also increasing.”
This is one form of deep modeling. By requiring students to finish one node before
working on another, the Target Variable Strategy encourages students to examine the
system description closely because it is the only resource that provides relevant information. When they are allowed to work on any tab on any node, then they jump
around trying to find a tab that can be easily filled in. This is a common form of shallow modeling, and the Target Node Strategy discourages it.
In addition to requiring the students to follow the Target Node Strategy, the metatutor nags students to avoid guessing and abuse of the Give Up button, just as the
Help-Tutor [3] did. Because neither the strategy nor the advice on help seeking are
specific to the domain (e.g., population dynamics), we consider them to be metacognitive instruction.

2

Evaluation

2.1

Experiment Design

The experiment was designed as a between-subject single treatment experiment with a
control condition, where the meta-tutor was off, and an experiment condition, where
the meta-tutor was on. The difference between the conditions occurred only during a
training phase where students learned how to solve model construction problems. In
order to assess how much students learned, a transfer phase followed the training
phase. During the transfer phase, all students solved model construction problems
with almost no help: the meta-tutor, the Check button and the Give-up button were all
turned off, except in the Description tab where the Check button remained enabled to

40

facilitate grounding. Because system dynamics is rarely taught in high school, no pretest was included in the procedure. We conducted two experiments with 44 students
participating in the first experiment and 34 students in the second experiment.
2.2

Hypotheses and Measures

Hypothesis 1 is that the meta-tutored students will use deep modeling more frequently than the control students during the transfer phase. We used the three measures
below to assess it.
x The number of the Run Model button presses per problem.
x The number of extra nodes created, where extra nodes are defined as the nodes that
can be legally created for the problem but are not required for solving the problem.
x The number of problems completed during the 30 minute transfer period.
Hypothesis 2 is that meta-tutored students will use deep modeling more frequently
than the control group students during the training phase. The three dependent
measures used to evaluate this hypothesis are described below:
x

x
x

Help button usage: was calculated as (nwc+3ngu)/nrn, where nwc is the number of
Check button presses that yielded red, ngu is the number of Give-up button presses, and nrn is the number of nodes required by the problem.
The percentage of times the first Check was correct.
Training efficiency: was calculated as 3ncn – ngu where ncn is the number of
nodes the student completed correctly (3ncn is the number of tabs), and ngu is the
number of Give-up buttons presses.

Hypothesis 3 is that the experimental group students, who were required to follow the
Target Node Strategy during training, would seldom use it during the transfer phase.
To evaluate this hypothesis, we calculated the proportion of student steps consistent
with the target node strategy.
2.3

Results

Table 1 summarizes the results of experiment 1 and experiment 2.

3

Conclusion and future work

Although we achieved some success in encouraging students to engage in deep modeling, there is much room for improvement. If the meta-tutor had been a complete
success at teaching deep modeling, we would expect to see students supported by the
meta-tutor working faster than the control students. The stage is now set for the last
phase of our project, where we add an affective agent to the system [4], in order to
encourage engagement and more frequent deep modeling.

41

Measure (predicted dir.)

Experiment 1 (N=44)

Experiment 2 (N=33)

Transfer phase (Hypothesis 1)
Run model button usage (E<C)

E<C (p=0.31, d=0.32)

E§C (p=0.98, d=-0.0093)

Extra nodes (E<C)
Probs completed (E>C)

E<C (p=0.02, d=0.80)
E§C (p=0.65, d=0.04)

E<C (p=0.47, d=0.26)
E<C (p=0.09, d=í0.57)

Training phase (Hypothesis 2)
E<C (p=0.04, d=0.68)
E<C (p=0.02, d=0.89)
Missing data
E>C (p=0.015, d=0.98)
E>C (p=0.59, d=0.19)
E<C (p=0.05, d=0.70)
Transfer phase use of Target Node Strategy (Hypothesis 3)
Usage (E=C)
Missing data
E§C (p=0.59, d=í0.19).
Help button usage (E<C)
Correct on 1st Check (E>C)
Efficiency (E>C)

Table 1. Results of Experiment 1 and 2: E stands for the meta-tutor group, and C stands for
the control group. Reliable results are bold.

Acknowledgements
This material is based upon work supported by the National Science Foundation under Grant No. 0910221.

References:
1. CCSSO.: The Common Core State Standards for Mathematics, Downloaded from
www.corestandards.org on October 31 (2011)
2. Chi, Min, & VanLehn, K.: Meta-cognitive strategy instruction in intelligent tutoring systems: How, when and why. Journal of Educational Technology and Society, 13(1). 25-39
(2010)
3. Roll, I., Aleven, V., McLaren, Bruce, Ryu, Eunjeong, Baker, R.S.J.d., & Koedinger, K. R.:
The Help Tutor: Does metacognitive feedback improve student's help-seeking actions,
skills and learning. In M. Ikeda, K. Ashley & T.-W. Chan (Eds.), Intelligent Tutoring Systems: 8th International Conference, pp. 360-369. Berlin: Springer (2006)
4. Girard, S., Chavez-Echeagaray, M. E., Gonzalez-Sanchez, J., Hidalgo-Pontet, Y., Zhange,
L., Burleson, W. & VanLehn, K.: Defining the behavior of an affective learning companion in the Affective Meta-Tutor project. In Proceedings of AI in Education (2013)
5. Treagust, David F., Chittleborough, Gail, & Mamiala, Thapelo.: Students' understanding of
the role of scientific models in learning science. International Journal of Science Education, 24(4), 357-368 (2002)
6. VanLehn, K. (in press). Model construction as a learning activity: A design space and review. Interactive Learning Environments.

From	
  Behavioral	
  Description	
  to	
  	
  
A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems	
   	
  
JAVIER	
  GONZALEZ-­‐SANCHEZ,	
  Arizona	
  State	
  University	
  	
  
MARIA	
  ELENA	
  CHAVEZ-­‐ECHEAGARAY,	
  Arizona	
  State	
  University	
  	
  
KURT	
  VANLEHN,	
  Arizona	
  State	
  University	
  	
  
WINSLOW	
  BURLESON,	
  Arizona	
  State	
  University	
  	
  

Intelligent	
  Tutoring	
  Systems	
  are	
  software	
  applications	
  capable	
  of	
  complementing	
  and	
  enhancing	
  the	
  learning	
  process	
  by	
  providing	
  direct	
  
customized	
  instruction	
  and	
  feedback	
  to	
  students	
  in	
  various	
  disciplines.	
  Although	
  Intelligent	
  Tutoring	
  Systems	
  could	
  differ	
  widely	
  in	
  their	
  
attached	
   knowledge	
   bases	
   and	
   user	
   interfaces	
   (including	
   interaction	
   mechanisms),	
   their	
   behaviors	
   are	
   quite	
   similar.	
   Therefore,	
   it	
   must	
   be	
  
possible	
   to	
   establish	
   a	
   common	
   software	
   model	
   for	
   them.	
   A	
   common	
   software	
   model	
   is	
   a	
   step	
   forward	
   to	
   move	
   these	
   systems	
   from	
   proof-­‐
of-­‐concepts	
  and	
  academic	
  research	
  tools	
  to	
  widely	
  available	
  tools	
  in	
  schools	
  and	
  homes.	
  	
  The	
  work	
  reported	
  here	
  addresses:	
  (1)	
  the	
  use	
  of	
  
Design	
   Patterns	
   to	
   create	
   an	
   object-­‐oriented	
   software	
   model	
   for	
   Intelligent	
   Tutoring	
   Systems;	
   (2)	
   our	
   experience	
   using	
   this	
   model	
   in	
   a	
  
three-­‐year	
   development	
   project	
   and	
   its	
   impact	
   on	
   facets	
   such	
   as	
   creating	
   a	
   common	
   language	
   among	
   stakeholders,	
   supporting	
   an	
  
incremental	
  development,	
  and	
  adjustment	
  to	
  a	
  highly	
  shifting	
  development	
  team;	
  and	
  (3)	
  the	
  qualities	
  achieved	
  and	
  trade-­‐offs	
  made.	
  	
  
Categories	
   and	
   Subject	
   Descriptors:	
   D.2.10	
   [Software	
   Engineering]:	
   Design;	
   D.2.11	
   [Software	
   Engineering]:	
   Software	
   Architecture;	
  
D.2.13	
  [Software	
  Engineering]:	
  Reusable	
  Software.	
  
General	
  Terms:	
  Design.	
  
Additional	
  Key	
  Words	
  and	
  Phrases:	
  Design	
  patterns,	
  component	
  model,	
  intelligent	
  tutoring	
  systems,	
  behavioral	
  description.	
  
ACM	
  Reference	
  Format:	
  	
  
Gonzalez-­‐Sanchez,	
  J.,	
  Chavez-­‐Echeagaray,	
  M.E.,	
  VanLehn,	
  K.	
  and	
  Burleson,	
  W.	
  2011.	
  From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  
for	
   Intelligent	
   Tutoring	
   Systems.	
   18th	
   Conference	
   on	
   Pattern	
   Languages	
   of	
   Programs	
   (PLoP),	
   Portland,	
   Oregon,	
   USA	
   (October	
   2011),	
   12	
  
pages.	
  
	
  

1. INTRODUCTION	
  
Intelligent	
   Tutoring	
   Systems	
   (ITS)	
   complements	
   and	
   enhances	
   the	
   learning	
   process	
   by	
   offering	
   support	
   for	
  
students	
   and	
   complementing	
   the	
   teacher’s	
   labor.	
   There	
   are	
   many	
   discussions	
   about	
   ITS	
   pedagogical	
   and	
  
instructional	
   design,	
   such	
   as	
   (Anderson	
   et	
   al.	
   1995,	
   Baker	
   et	
   al.	
   2009,	
   and	
   Nelson	
   2007),	
   but	
   not	
   about	
   their	
  
technical	
  implementation.	
  	
  
	
  
The	
   work	
   described	
   here	
   is	
   part	
   of	
   the	
   technical	
   implementation	
   of	
   an	
   ITS,	
   named	
   Affective	
   Meta	
   Tutor	
  
(AMT).	
   The	
   AMT	
   project	
   aims	
   to	
   use	
   an	
   affective	
   learning	
   companion	
   to	
   motivate	
   students	
   to	
   permanently	
  
adopt	
   effective	
   meta-­‐cognitive	
   strategies	
   (AMT	
   2012).	
   The	
   AMT	
   project	
   looks	
   to	
   improve	
   ITS	
   not	
   only	
   by	
  
adding	
   those	
   new	
   elements	
   (meta-­‐tutoring	
   strategies	
   and	
   affective	
   learning	
   companions),	
   but	
   also	
   by	
   taking	
  
advantage	
   of	
   previous	
   experiences	
   with	
   ITS	
   implementations	
   from	
   the	
   ITS	
   community	
   to	
   provide	
   a	
   software	
  
framework	
   for	
   designing	
   ITS	
   based	
   on	
   a	
   behavioral	
   description;	
   modeling	
   meta-­‐tutoring	
   capabilities	
   and	
  
learning	
  companions	
  modules	
  is	
  not	
  part	
  of	
  this	
  paper	
  and	
  is	
  left	
  as	
  future	
  work.	
  
	
  
An	
  analysis	
  and	
  comparison	
  of	
  existing	
  ITS	
  was	
  made	
  in	
  (VanLehn	
  2006).	
  The	
  analysis	
  included	
  a	
  diverse	
  
set	
   of	
   ITS	
   such	
   as	
   an	
   ITS	
   for	
   Algebra	
   in	
   High	
   School	
   (Anderson	
   et	
   al.	
   1995);	
   a	
   tutor	
   for	
   physics	
   in	
   College	
  
We	
   are	
   grateful	
   to	
   Hironori	
   Washizaki	
   for	
   his	
   support	
   during	
   the	
   writing	
   process	
   of	
   this	
   paper.	
   This	
   work	
   is	
   supported	
   by	
   the	
   National	
  
Science	
  Foundation,	
  including	
  the	
  following	
  grants:	
  (1)	
  IIS/HCC	
  Affective	
  Learning	
  Companions:	
  Modeling	
  and	
  supporting	
  emotion	
   during	
  
learning	
  (#0705883);	
  and	
  (2)	
  Deeper	
  Modeling	
  via	
  Affective	
  Meta-­‐tutoring	
  (DRL-­‐	
  0910221).	
  
Author's	
  address:	
  Javier	
  Gonzalez-­‐Sanchez,	
  University	
  Drive	
  and	
  Mill	
  Avenue,	
  Tempe	
  AZ	
  85287;	
  email:	
  javiergs@asu.edu;	
  Author’s	
  address:	
  
Maria-­‐Elena	
  Chavez-­‐Echeagaray,	
  University	
  Drive	
  and	
  Mill	
  Avenue,	
  Tempe	
  AZ	
  85287;	
  email:	
  helenchavez@asu.edu;	
  Author's	
  address:	
  Kurt	
  
VanLehn,	
   University	
   Drive	
   and	
   Mill	
   Avenue,	
   Tempe	
   AZ	
   85287;	
   email:	
   kurthvanlen@asu.edu;	
   Author’s	
   address:	
   Winslow	
   Burleson,	
  
University	
  Drive	
  and	
  Mill	
  Avenue,	
  Tempe	
  AZ	
  85287;	
  email:	
  winslow.burleson@asu.edu	
  	
  
Permission	
  to	
  make	
  digital	
  or	
  hard	
  copies	
  of	
  all	
  or	
  part	
  of	
  this	
  work	
  for	
  personal	
  or	
  classroom	
  use	
  is	
  granted	
  without	
  fee	
  provided	
  that	
  
copies	
  are	
  not	
  made	
  or	
  distributed	
  for	
  profit	
  or	
  commercial	
  advantage	
  and	
  that	
  copies	
  bear	
  this	
  notice	
  and	
  the	
  full	
  citation	
  on	
  the	
  first	
  page.	
  
To	
  copy	
  otherwise,	
  to	
  republish,	
  to	
  post	
  on	
  servers	
  or	
  to	
  redistribute	
  to	
  lists,	
  requires	
  prior	
  specific	
  permission.	
  A	
  preliminary	
  version	
  of	
  
this	
  paper	
  was	
  presented	
  in	
  a	
  writers'	
  workshop	
  at	
  the	
  18th	
  Conference	
  on	
  Pattern	
  Languages	
  of	
  Programs	
  (PLoP).	
  PLoP'11,	
  October	
  21-­‐
23,	
  Portland,	
  Oregon,	
  USA.	
  Copyright	
  2011	
  is	
  held	
  by	
  the	
  author(s).	
  ACM	
  978-­‐1-­‐4503-­‐1283-­‐7

(VanLehn	
   et	
   al.	
   2005);	
   a	
   tutor	
   for	
   qualitative	
   reasoning	
   in	
   natural	
   language	
   (Graesser	
   et	
   al.	
   2004);	
   a	
   simulated-­‐
based	
   tutor	
   for	
   repairing	
   avionic	
   electronic	
   equipment	
   (Katz	
   et	
   al.	
   1998);	
   and	
   an	
   ITS	
   to	
   teach	
   SQL	
   language	
  
(Mitrovic	
   2003).	
   The	
   analysis	
   and	
   comparison	
   concluded	
   that	
   only	
   a	
   few	
   pedagogical	
   features	
   have	
   been	
  
invented	
   and	
   that	
   existing	
   ITS	
   offered	
   different	
   combinations	
   of	
   those	
   features.	
   	
   It	
   also	
   claimed	
   that	
   ITS	
  
behaviors	
  are	
  similar	
  but	
  the	
  ITS	
  differ	
  widely	
  in	
  their	
  software	
  implementation.	
  
	
  
From	
  a	
  software	
  engineering	
  perspective,	
  this	
  variety	
  in	
  software	
  implementation	
  shows	
  a	
  lack	
  of	
  the	
  use	
  of	
  
software	
   engineering	
   techniques	
   and	
   methodologies	
   in	
   the	
   development	
   of	
   this	
   kind	
   of	
   systems,	
   because	
   the	
  
same	
  specifications	
  are	
  creating	
  different	
  products.	
  Subsequently,	
  it	
  will	
  be	
  valuable	
  to	
  establish	
  a	
  model	
  that	
  
moves	
  from	
  the	
  ITS	
  behavior	
  description	
  to	
  the	
  system	
  implementation.	
  An	
  optimal	
  model	
  should	
  be	
  capable	
  of	
  
satisfying	
  the	
  requirements	
  of	
  ITS	
  and	
  providing	
  desired	
  software	
  qualities.	
  This	
  paper	
  describes	
  our	
  approach	
  
to	
  address	
  the	
  design	
  of	
  this	
  model	
  within	
  a	
  context	
  driven	
  by	
  three	
  key	
  elements:	
  
	
  
• Incremental	
   requirements.	
   AMT	
   required	
   incremental	
   evolution	
   along	
   three-­‐years;	
   developing	
   an	
   ITS	
  
the	
  first	
  year,	
  adding	
  meta-­‐tutoring	
  support	
  the	
  second	
  year,	
  and	
  including	
  affective	
  learning	
  companions	
  
the	
  third	
  year.	
  Research	
  results	
  and	
  user	
  experience	
  reports	
  drove	
  new	
  requirements.	
  	
  	
  	
  
• Changing	
   requirements.	
   Several	
   and	
   diverse	
   research	
   approaches	
   were	
   tested	
   as	
   part	
   of	
   the	
   project	
  
implementation.	
   For	
   each	
   approach	
   a	
   solid	
   system	
   was	
   released	
   and	
   tested	
   with	
   students.	
   Research	
  
findings	
  were	
  translated	
  into	
  changes	
  in	
  the	
  system.	
  
• Shifting	
   development	
   team.	
   The	
   development	
   team,	
   composed	
   of	
   undergraduate	
   students,	
   shifted	
  
constantly	
  -­‐	
  every	
  4	
  to	
  6	
  months.	
  
	
  
In	
   this	
   context,	
   we	
   chose	
   to	
   incorporate	
   design	
   patterns	
   to	
   standardize	
   an	
   object-­‐oriented	
   model	
   for	
   ITS	
  
functionality	
   that	
  drives	
  the	
  way	
  in	
  which	
  software	
  is	
  developed.	
  We	
  mapped	
  the	
  functional	
  description	
  of	
  ITS	
  
behavior	
   given	
   in	
   (VanLehn	
   2006)	
   into	
   a	
   software	
   model	
   using	
   some	
   of	
   the	
   “Gang	
   of	
   Four”	
   (GoF)	
   design	
  
patterns	
   (Gamma	
   et	
   al.	
   1995);	
   GoF	
   design	
   patterns	
   were	
   chosen	
   because	
   they	
   are	
   classic	
   patterns	
   often	
  
considered	
  the	
  foundation	
  for	
  all	
  other	
  patterns.	
  Using	
  GoF	
  design	
  patterns	
  we	
  addressed	
  the	
  creation	
  of	
  the	
  
model	
  and	
  sought	
  to	
  incorporate	
  on	
  it	
  non-­‐functional	
  requirements	
  (i.e.	
  software	
  quality	
  factors)	
  particularly	
  
reusability,	
   extensibility,	
   and	
   adaptability	
   (IEEE	
   1999).	
   These	
   qualities	
   help	
   us	
   to	
   address	
   the	
   contextual	
  
elements	
   mentioned	
   above:	
   incremental	
   requirements,	
   changing	
   requirements,	
   and	
   a	
   shifting	
   development	
  
team.	
   With	
   this	
   approach	
   we	
   seek	
   to	
   contribute	
   moving	
   ITS	
   construction	
   from	
   software	
   development	
   as	
   a	
   one-­‐
of-­‐a-­‐kind	
   endeavor	
   to	
   software	
   development	
   as	
   a	
   system	
   of	
   components	
   that	
   are	
   widely	
   used	
   and	
   highly	
  
adaptable	
  (Jacobson	
  1997).	
  	
  
	
  
This	
   paper	
   is	
   organized	
   as	
   follows:	
   Section	
   2	
   provides	
   some	
   terminology	
   and	
   background	
   about	
   ITS,	
  
patterns,	
   and	
   software	
   qualities;	
   Section	
   3	
   explores	
   ITS	
   functional	
   specification	
   and	
   the	
   design	
   process	
   using	
  
patterns	
   to	
   model	
   ITS	
   software	
   components;	
   Section	
   4	
   describes	
   our	
   experience	
   using	
   design	
   patterns	
   into	
   the	
  
AMT	
  project	
  and	
  evaluates	
  pros	
  and	
  cons;	
  finally,	
  Section	
  5	
  concludes	
  the	
  paper	
  and	
  describes	
  ongoing	
  work.	
  
We	
  expect	
  developers	
  in	
  ITS	
  and	
  education	
  technology	
  communities	
  to	
  find	
  this	
  paper	
  useful	
  as	
  a	
  reference	
  and	
  
as	
   an	
   example	
   of	
   the	
   use	
   and	
   advantages	
   of	
   design	
   patterns	
   for	
   developing	
   software	
   systems;	
   for	
   software	
  
design	
   community,	
   this	
   is	
   an	
   experience	
   report	
   of	
   a	
   research	
   group	
   using	
   design	
   patterns	
   to	
   improve	
   its	
  
software	
  process.	
  
	
  
2. BACKGROUND	
  
This	
  section	
  provides	
  background	
  about	
  ITS	
  structure	
  and	
  clarifies	
  some	
  related	
  terminology	
  used	
  within	
  this	
  
paper.	
   It	
   also	
   provides	
   background	
   information	
   about	
   design	
   patterns,	
   and	
   the	
   definition	
   of	
   the	
   software	
  
qualities	
  expected	
  for	
  the	
  proposed	
  model.	
  	
  
	
  
2.1 ITS	
  Structure	
  
ITS	
  refers	
  to	
  a	
  computer	
  system	
  that	
  acts	
  as	
  a	
  tutor	
  showing	
  an	
  intelligent	
  way	
  to	
  provide	
  feedback	
  and	
  hints	
  to	
  
support	
   student	
   achievement	
   while	
   solving	
   tasks.	
   A	
   task	
   refers	
   to	
   a	
   multi-­‐minute	
   activity	
   assigned	
   to	
   the	
  
student	
  by	
  the	
  ITS.	
  Tasks	
  can	
  be	
  skipped	
  or	
  interchanged	
  with	
  other	
  tasks.	
  Each	
  of	
  the	
  actions	
  taken	
  to	
  achieve	
  
From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  2	
  

a	
  task	
  is	
  called	
  a	
  step.	
  Each	
  task	
  consists	
  of	
  multiple	
  steps	
  and	
  each	
  step	
  involves	
  events	
  with	
  a	
  User	
  Interface	
  
(either	
  through	
  a	
  tool	
  or	
  an	
  environment).	
  	
  Each	
  task	
  requires	
  the	
  use	
  of	
  one	
  or	
  more	
  knowledge	
  components	
  
to	
  be	
  accomplished.	
  Knowledge	
  components	
  are	
  fragments	
  of	
  persistent	
  domain-­‐specific	
  information	
  that	
  the	
  
student	
  is	
  expected	
  to	
  learn.	
  Knowledge	
  components	
  are	
  contained	
  in	
  a	
  knowledge	
  base.	
  
	
  
ITS	
   structure	
  is	
  a	
   three-­‐layer	
  model,	
   as	
   shown	
   in	
   Figure	
   1,	
   that	
   decouples	
  the	
   Knowledge	
   Base	
   and	
   the	
   User	
  
Interfaces	
  from	
  the	
  Core	
  of	
  the	
  ITS.	
  The	
  description	
  of	
  each	
  layer	
  is	
  as	
  follow:	
  
	
  
• Knowledge	
  Base	
  (KB)	
  includes	
  data	
  structures	
  and	
  databases	
  for	
  storing	
  and	
  organizing	
  the	
  information	
  
instructed	
   by	
   the	
   ITS.	
   The	
   process	
   of	
   putting	
   data	
   into	
   the	
   KB	
   is	
   called	
   authoring.	
   Authoring	
   involves	
   a	
  
human	
   expert	
   interacting	
   with	
   an	
   authoring	
   tool	
   to	
   provide	
   this	
   data.	
   Occasionally,	
   machine-­‐learning	
  
algorithms	
  have	
  been	
  used	
  to	
  create	
  this	
  expertise.	
  Authoring	
  and	
  KB	
  representation	
  are	
  topics	
  outside	
  of	
  
this	
  paper.	
  
• User	
   Interfaces	
   (UI)	
   include	
   graphical	
   interfaces	
   (windows,	
   buttons,	
   text,	
   and	
   so	
   on)	
   and	
   interaction	
  
mechanisms	
   (from	
   single	
   keyboard	
   events	
   to	
   more	
   complex	
   interfaces	
   such	
   as	
   motion	
   capture,	
   voice	
  
recognition,	
  brain-­‐computer	
  interface,	
  and	
  so	
  on).	
  
• Core	
   implements	
   the	
   ITS	
   behavior.	
   While	
   Knowledge	
   Base	
   and	
   User	
   Interfaces	
   are	
   highly	
   different	
   from	
  
one	
   ITS	
   to	
   another,	
   the	
   behavior	
   of	
   all	
   of	
   them	
   is	
   quite	
   similar.	
   The	
   Core	
   is	
   composed	
   of:	
   (1)	
   Task	
   Selector,	
  
which	
  provides	
  a	
  Task	
  (problem	
  or	
  activity)	
  that	
  the	
  student	
  must	
  solve;	
  (2)	
  Tool	
  or	
  Environment,	
  which	
  
models	
   and	
   presents	
   the	
   information	
   that	
   the	
   student	
   must	
   know	
   to	
   complete	
   the	
  Task;	
   (3)	
   Step	
   Analyzer,	
  
which	
  methodically	
  examines	
  and	
  measures	
  the	
  performance	
  of	
  the	
  student	
  and	
  provides	
  that	
  information	
  
to	
  the	
  Assessor	
  and	
  the	
  Pedagogical	
  Module;	
  (4)	
  Pedagogical	
  Module,	
  which	
  provides	
  support	
  (hints	
  and	
  
feedback)	
  to	
  make	
  the	
  student	
  successfully	
  complete	
  the	
  Task;	
  support	
  is	
  related	
  with	
  the	
  performance	
  of	
  
the	
  student	
  in	
  the	
  current	
  Step	
  and	
  the	
  information	
  from	
  the	
  student’s	
  Learner	
  Model;	
  and	
  (5)	
  Assessor,	
  
which	
  learns	
  from	
  the	
  student	
  (how	
  many	
  hints	
  he	
  needed,	
  how	
  skilled	
  he	
  was	
  in	
  the	
  topic,	
  how	
  much	
  time	
  
he	
  used	
  to	
  go	
  from	
  one	
  step	
  to	
  another	
  in	
  order	
  to	
  solve	
  the	
  task,	
  etc.)	
  and	
  then	
  stores	
  this	
  information	
  in	
  
what	
   is	
   known	
   as	
   a	
   Learner	
   Model.	
   The	
   connections	
   between	
   the	
   Core’s	
   components	
   are	
   described	
   in	
  
Section	
  3.	
  
	
  

	
  

Fig.	
  1.	
  ITS	
  layered	
  structure:	
  User	
  Interface	
  (and	
  interaction	
  mechanisms),	
  Functionality	
  (Core),	
  and	
  Data	
  (Knowledge	
  Base)	
  are	
  decoupled.	
  

	
  

From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  3	
  

The	
  rest	
  of	
  this	
  paper	
  is	
  devoted	
  to	
  modeling	
  the	
  Core,	
  the	
  layer	
  that	
  implements	
  the	
  behavioral	
  response	
  of	
  
the	
  ITS.	
  Modeling	
  Knowledge	
  Base,	
  User	
  Interfaces,	
  and	
  the	
  connection	
  between	
  them	
  and	
  the	
  Core	
  is	
  out	
  of	
  the	
  
scope	
   of	
   this	
   paper.	
   However,	
   the	
   connection	
   between	
   User	
   Interfaces	
   and	
   Core	
   can	
   be	
   easily	
   figured	
   out	
   as	
   an	
  
MVC	
   pattern	
   application	
   (Buschmann	
   et	
   al.	
   1996),	
   where	
   Core	
   acts	
   as	
   the	
   Model	
   part.	
   The	
   connection	
   between	
  
Core	
  and	
  Knowledge	
  Base	
  can	
  be	
  realized	
  using	
  diverse	
  data	
  access	
  approaches.	
  
	
  

2.2

Why	
  Design	
  Patterns?	
  

Software	
  design	
  patterns	
  are	
  used	
  as	
  a	
  general	
  reusable	
  solution	
  to	
  a	
  commonly	
  occurring	
  problem	
  in	
  software	
  
design,	
   to	
   show	
   relationships	
   and	
   interactions	
   between	
   components	
   and	
   provide	
   a	
   skeleton	
   for	
   the	
  
implementation	
   (Gamma	
   et	
   al.	
   1995).	
   Even	
   though	
   the	
   concept	
   of	
   patterns	
   has	
   received	
   relatively	
   little	
  
attention	
  in	
  the	
  field	
  of	
  ITS,	
  Devedzic	
  and	
  Harrer	
  (2005)	
  mention	
  that	
  many	
  ITS	
  designers	
  and	
  developers	
  use	
  
their	
   own	
   solutions	
   when	
   faced	
   with	
   design	
   problems	
   that	
   are	
   common	
   to	
   different	
   systems,	
   models,	
   and	
  
paradigms;	
   even	
   when	
   a	
   closer	
   look	
   into	
   that	
   solutions	
   and	
   their	
   comparison	
   often	
   shows	
   that	
   different	
  
solutions	
  and	
  the	
  contexts	
  in	
  which	
  they	
  are	
  applied	
  have	
  much	
  in	
  common.	
  
	
  
In	
  that	
  context,	
  our	
  choice	
  about	
  using	
  design	
  patterns	
  in	
  this	
  project	
  was	
  driven	
  by	
  our	
  interest	
  in:	
  
	
  
• Communication.	
   Since	
   patterns’	
   names	
   closely	
   match	
   their	
   objective	
   and	
   the	
   problem	
   they	
   solve,	
   we	
   used	
  
them	
  as	
  a	
  common	
  vocabulary	
  among	
  diverse	
  stakeholders	
  aiming	
  to	
  improve	
  the	
  communication	
  process.	
  
Patterns	
   provide	
   us	
   with	
   a	
   standard	
   vocabulary	
   to	
   describe	
   the	
   topology	
   of	
   the	
   system,	
   the	
   structural	
  
hierarchy	
  of	
  the	
  subsystems,	
  and	
  their	
  interfaces	
  and	
  connections.	
  
• Collaboration.	
   Patterns	
   support	
   the	
   sharing	
   of	
   constructions	
   between	
   developers	
   or	
   either	
   use	
   other’s	
  
constructions	
  to	
  enhance	
  our	
  own.	
  No	
  matter	
  what	
  is	
  been	
  built	
  or	
  what	
  others	
  built,	
  it	
  is	
  always	
  known	
  
which	
  are	
  going	
  to	
  be	
  the	
  relations	
  (connections)	
  among	
  different	
  constructions.	
  	
  
• Productivity.	
   Patterns	
   help	
   to	
   create	
   components,	
   and	
   components	
   support	
   the	
   creation	
   of	
   families	
   of	
  
products	
  and/or	
  several	
  versions	
  of	
  the	
  same	
  product	
  to	
  prototype	
  and	
  test	
  new	
  options	
  of	
  functionality.	
  
• Abstraction.	
   Patterns	
   are	
   more	
   abstract	
   than	
   just	
   a	
   technical	
   model,	
   but	
   more	
   technical	
   than	
   a	
   conceptual	
  
model.	
  Patterns	
  make	
  it	
  possible	
  to	
  provide	
  a	
  “controlled”	
  freedom	
  to	
  the	
  programmers	
  because	
  they	
  can	
  
develop	
  functionality	
  in	
  their	
  own	
  creative	
  way,	
  but	
  they	
  follow	
  and	
  preserve	
  the	
  guidelines	
  of	
  a	
  defined	
  
design.	
  	
  
	
  
These	
   benefits	
   of	
   using	
   patterns	
   (communication,	
   collaboration,	
   productivity,	
   and	
   abstraction)	
   help	
   us	
   to	
  
overcome	
   the	
   challenging	
   contextual	
   elements	
   of	
   the	
   project	
   (incremental	
   requirements,	
   changing	
  
requirements,	
  and	
  a	
  shifting	
  development	
  team).	
  
	
  
2.3

ITS	
  Qualities	
  

ITS	
  are	
  pieces	
  of	
  software,	
  hence	
  they	
  are	
  expected	
  to	
  meet	
  some	
  software	
  quality	
  criteria.	
  Therefore,	
  modeling	
  
ITS	
   behavior	
   is	
   also	
   about	
   accomplishing	
   quality	
   considerations	
   that	
   drive	
   their	
   design.	
   Software	
   quality	
  
criteria	
   are	
   specified	
   as	
   non-­‐functional	
   requirements.	
   Accomplishing	
   non-­‐functional	
   requirements	
   is	
   one	
  
additional	
   reason	
   to	
   use	
   design	
   patterns.	
   Design	
   patterns	
   let	
   us	
   take	
   advantage	
   of	
   previous	
   experiences	
   to	
  
implement	
   non-­‐functional	
   requirements	
   and	
   to	
   avoid,	
   when	
   properly	
   used,	
   accidental	
   complexity.	
   The	
   non-­‐
functional	
  requirements	
  addressed	
  in	
  the	
  project	
  were:	
  
	
  
• Reusability.	
   Reusability	
   refers	
   to	
   the	
   degree	
   to	
   which	
   a	
   software	
   module	
   or	
   other	
   work	
   product	
   can	
   be	
  
used	
  in	
  more	
  than	
  one	
  computer	
  program	
  or	
  software	
  system	
  (IEEE	
  1999).	
  ITS	
  components	
  must	
  be	
  able	
  
to	
  be	
  used	
  again	
  with	
  slight	
  or	
  no	
  modification	
  for	
  the	
  implementation	
  of	
  other	
  products	
  or	
  versions	
  of	
  the	
  
same	
  project.	
  	
  
• Extensibility.	
   Extensibility	
   is	
   the	
   degree	
   to	
   which	
   a	
   system	
   or	
   component	
   can	
   be	
   easily	
   modified	
   to	
  
increase	
   its	
   storage	
   or	
   functional	
   capacity	
   (IEEE	
   1999).	
   ITS	
   components	
   in	
   the	
   model	
   must	
   be	
   able	
   to	
  
incorporate	
  new	
  functionalities	
  or	
  modify	
  existing	
  functionalities	
  (e.g.,	
  assessment	
  strategies,	
  task-­‐creation	
  
strategies,	
  learning	
  algorithms	
  to	
  mining	
  learner	
  model,	
  etc.).	
  

From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  4	
  

•
•

•

Adaptability.	
   Adaptability	
   refers	
   to	
   the	
   ease	
   with	
   which	
   a	
   system	
   or	
   component	
   can	
   be	
   modified	
   for	
   using	
  
it	
  in	
  applications	
  or	
  environments	
  other	
  than	
  those	
  for	
  which	
  it	
  was	
  specifically	
  designed	
  (IEEE	
  1999).	
  	
  
Robustness.	
   Robustness	
   is	
   the	
   degree	
   to	
   which	
   a	
   system	
   or	
   component	
   can	
   function	
   correctly	
   in	
   the	
  
presence	
   of	
   invalid	
   inputs	
   or	
   stressful	
   environmental	
   conditions	
   (IEEE	
   1999).	
   Students	
   expect	
   to	
   get	
  
effective	
   and	
   efficient	
   support	
   from	
   the	
   ITS,	
   as	
   if	
   it	
   was	
   a	
   human	
   tutor;	
   interruptions	
   in	
   the	
   teaching-­‐
learning	
  process	
  due	
  to	
  software	
  failures	
  are	
  highly	
  undesirable.	
  	
  
Performance.	
   Performance	
   refers	
   to	
   the	
   degree	
   to	
   which	
   a	
   system	
   or	
   component	
   accomplishes	
   its	
  
designated	
  functions	
  within	
  given	
  constraints,	
  such	
  as	
  speed,	
  accuracy,	
  or	
  memory	
  usage	
  (IEEE	
  1999).	
  The	
  
ITS	
  must	
  emulate	
  real-­‐time	
  responses	
  from	
  a	
  human	
  tutor;	
  delays	
  must	
  be	
  avoided	
  and	
  latency	
  reduced.	
  

	
  
The	
  use	
  of	
  patterns	
  becomes	
  the	
  keystone	
  to	
  satisfy	
  the	
  first	
  three	
  qualities	
  enumerated	
  above.	
  Satisfaction	
  of	
  
the	
  last	
  two	
  requirements	
  (robustness	
  and	
  performance)	
  is	
  related	
  to	
  the	
  implementation	
  of	
  the	
  model	
  and	
  not	
  
with	
  the	
  model	
  per	
  se.	
  However,	
  in	
  our	
  experience	
  communication,	
  collaboration,	
  productivity,	
  and	
  abstraction	
  
impact	
  performance	
  and	
  robustness.	
  
	
  
2.4 Unified	
  Modeling	
  Language	
  
Unified	
   Modelling	
   Language	
   (UML)	
   notation	
   is	
   used	
   as	
   modelling	
   language,	
   specifically	
   UML	
   class	
   diagrams.	
   To	
  
facilitate	
  the	
  understanding	
  of	
  the	
  diagrams	
  offered	
  in	
  this	
  paper	
  (see	
  Figures	
  2,	
  3,	
  and	
  4)	
  this	
  section	
  provides	
  
a	
  brief	
  description	
  of	
  the	
  elements	
  (boxes	
  and	
  arrows)	
  within	
  a	
  UML	
  diagram.	
  
	
  
• Boxes	
  represent	
  components	
  or	
  classes.	
  
• Arrows	
   represent	
   association	
   relationships;	
   the	
   arrows	
   go	
   from	
   the	
   component	
   that	
   requests	
   functionality	
  
to	
  the	
  component	
  that	
  provides	
  that	
  functionality.	
  	
  
• Arrows	
   with	
   dashed	
   lines	
   represent	
   dependency	
   relationships;	
   in	
   the	
   model	
   we	
   are	
   showing	
   the	
  
dependency	
  between	
  functional	
  components	
  and	
  the	
  data	
  component	
  they	
  require	
  to	
  access	
  them.	
  
• Arrows	
  with	
  a	
  triangular	
  shape	
  in	
  the	
  arrowhead	
  represent	
  inheritance	
  relationships.	
  
• Arrows	
   starting	
   with	
   a	
   diamond	
   shape	
   represent	
   composition	
   relationships;	
   they	
   are	
   used	
   to	
   represent	
  
that	
  a	
  component	
  is	
  formed	
  by	
  a	
  conjunction	
  of	
  other	
  components.	
  	
  	
  	
  
	
  
3. MODELING	
  THE	
  ITS	
  BEHAVIOR	
  
This	
   section	
   uses	
   the	
   ITS	
   behavior	
   described	
   in	
   (VanLehn	
   2006)	
   to	
   create	
   a	
   conceptual	
   model	
   for	
   the	
   Core	
  
layer.	
   The	
   ITS	
   behavior,	
   stated	
   in	
   (VanLehn	
   2006),	
   is	
   summarized	
   in	
   a	
   list	
   of	
   statements	
   that	
   identifies	
   the	
  
involved	
  components,	
  responsibilities	
  for	
  each	
  component,	
  and	
  relationships	
  between	
  components.	
  In	
  the	
  list,	
  
components’	
   names	
   were	
   marked	
   in	
   bold	
   and	
   relationships	
   between	
   components	
   are	
   explained.	
   Complex	
  
components	
   were	
   split	
   into	
   simple	
   ones,	
   identifying	
   specific	
   responsibilities	
   and	
   assigning	
   them	
   to	
   new	
  
components.	
  The	
  list	
  of	
  statements	
  is	
  as	
  follows:	
  
	
  
• Students	
  interact	
   with	
   the	
   ITS	
   through	
   the	
  User	
   Interface.	
   The	
   events	
   triggered	
   by	
   the	
   User	
   Interface	
  are	
  
handled	
   by	
   the	
   Tool	
   component.	
   The	
   Tool	
   is	
   the	
   component	
   responsible	
   for	
   creating	
   and	
   managing	
   the	
  
environment	
  in	
  which	
  the	
  student	
  works.	
  	
  
• The	
  ITS	
  provides	
  students	
  with	
  tasks	
  to	
  be	
  solved	
  and	
  helps	
  them	
  in	
  the	
  process.	
  A	
  Task	
  is	
  a	
  set	
  of	
  steps.	
  	
  
For	
  simplicity,	
  this	
  report	
  assumes	
  that	
  the	
  set	
  of	
  steps	
  is	
  static	
  and	
  pre-­‐enumerated.	
  	
  In	
  principle,	
  a	
  Task	
  
could	
   be	
   a	
   step	
   generator,	
   which	
   means	
   steps	
   could	
   be	
   dynamically	
   generated.	
   	
   The	
   ITS	
   literature	
   refers	
   to	
  
tutors	
   using	
   a	
   static,	
   pre-­‐enumerated	
   set	
   of	
   steps	
   as	
   “example	
   tracing	
   tutors”	
   whereas	
   those	
   using	
   steps	
  
generators	
  are	
  called	
  “model	
  tracing	
  tutors”	
  (VanLehn,	
  2006).	
  	
  	
  Each	
  Step	
  is	
  related	
  to	
  events	
  in	
  the	
  User	
  
Interface.	
   Steps	
   include	
   Assessment	
   and	
   Help.	
   Help	
   could	
   be	
   Hints	
   before	
   completing	
   the	
   Step	
   or	
  
Feedback	
  after	
  completing	
  the	
  Step.	
  Each	
  Task	
  is	
  related	
  to	
  a	
  set	
  of	
  Knowledge	
  Components	
  that	
  are	
  the	
  
information	
   and	
   skills	
   that	
   a	
   student	
   needs	
   to	
   apply	
   in	
   order	
   to	
   solve	
   the	
   Task	
   successfully.	
   The	
  
Knowledge	
  Base	
  is	
  a	
  set	
  of	
  Tasks	
  and	
  Knowledge	
  Components	
  and	
  the	
  mapping	
  between	
  them.	
  
• The	
   ITS	
   behavior	
   starts	
   when	
   the	
   Task	
   Selector	
   selects	
   the	
   next	
   Task	
   that	
   the	
   student	
   must	
   solve	
   and	
  
places	
   the	
   Task	
   into	
   the	
   Tool	
   in	
   order	
   to	
   be	
   solved	
   by	
   the	
   student.	
   The	
   four	
   basic	
   methods	
   to	
   do	
   “task	
  
From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  5	
  

•

•

selection”	
   are	
   described	
   in	
   (VanLehn	
   2006).	
   The	
   Task	
   Selector	
   needs	
   to	
   have	
   access	
   to	
   a	
   source	
   of	
  Tasks.	
  
The	
   Task	
   Factory	
   is	
   the	
   source	
   of	
   Tasks.	
   It	
   either	
   reads	
   Tasks	
   stored	
   in	
  the	
   Knowledge	
   Base	
   (reading	
  
previously	
  human-­‐authored	
  tasks)	
  or	
  creates	
  tasks	
  in	
  real-­‐time.	
  
The	
   Step	
   Analyzer	
   compares	
   the	
   student’s	
   UI	
   behavior	
   to	
   the	
   correct	
   Steps	
   of	
   the	
   Task	
   and	
   provides	
   that	
  
information	
   to	
   the	
   Assessor	
   and	
   the	
   Pedagogical	
   Module.	
   The	
   Step	
   Analyzer	
   typically	
   determines	
  
whether	
  the	
  student’s	
  step	
  is	
  correct	
  or	
  incorrect,	
  and	
  which	
  of	
  the	
  task’s	
  steps	
  most	
  closely	
  matches	
  the	
  
student’s	
  step.	
  	
   The	
  Assessor	
  updates	
  the	
  Learner	
  Model.	
  The	
  Pedagogical	
  Module	
  provides	
  Help	
  using	
  
different	
   strategies	
   such	
   as	
   providing	
   immediate	
   or	
   delayed	
   help	
   or	
   providing	
   requested	
   or	
   unsolicited	
  
help.	
  
The	
   Learner	
   Model	
   represents	
   the	
   knowledge,	
   difficulties,	
   and	
   misconceptions	
   of	
   the	
   student.	
   The	
  
Learner	
   Model	
   lists	
   Tasks	
   assigned	
   to	
   the	
   student,	
   measures	
   of	
   the	
   time	
   spent	
   to	
   complete	
   the	
   Task,	
   and	
  
the	
  status	
  of	
  the	
  Task.	
  For	
  each	
  Step	
  in	
  the	
  Task	
  a	
  counter	
  of	
  the	
  Hints	
  requested	
  and	
  Feedback	
  (errors	
  
made)	
  is	
  kept.	
  	
  Most	
  importantly,	
  for	
  each	
  Knowledge	
  Component,	
  a	
  mastery	
  measure	
  is	
  also	
  kept.	
  	
  The	
  
Task	
  Selector	
  relies	
  on	
  the	
  Learner	
  Model’s	
  measures	
  of	
  Knowledge	
  Component	
  mastery	
  to	
  choose	
  a	
  
Task	
   that	
   is	
   neither	
   too	
   hard	
   (too	
   many	
   unmastered	
   knowledge	
   components)	
   nor	
   too	
   easy	
   (too	
   many	
  
mastered	
  knowledge	
  components).	
  

	
  
Figure	
  2	
  extends	
  the	
  ITS	
  structure	
  shown	
  in	
  Figure	
  1	
  in	
  order	
  to	
  identify	
  components	
  (functional	
  and	
  data)	
  and	
  
their	
  relationships.	
  UML	
  notation	
  is	
  used	
  inside	
  the	
  Core	
  block	
  to	
  create	
  a	
  first	
  attempt	
  of	
  the	
  object-­‐oriented	
  
model.	
  The	
  next	
  section	
  shows	
  the	
  details	
  of	
  this	
  model	
  using	
  a	
  pattern-­‐based	
  approach.	
  	
  
	
  
	
  

Fig.	
  2.	
  ITS	
  model.	
  White	
  boxes	
  represent	
  functional	
  components	
  and	
  gray	
  boxes	
  represent	
  data	
  components.	
  Relationships	
  of	
  association,	
  
dependency,	
  composition,	
  and	
  inheritance	
  are	
  shown	
  using	
  UML	
  notation.	
  

From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  6	
  

3.1 Pattern-­‐Based	
  Modeling	
  
The	
   model	
   in	
   Figure	
   2	
   represents	
   a	
   conceptual	
   description	
   of	
   who	
   is	
   doing	
   what	
   and	
   corresponds	
   to	
   an	
  
abstraction	
   of	
   the	
   expected	
   functionality	
   of	
   each	
   internal	
   component	
   in	
   Core.	
   Even	
   though	
   the	
   conceptual	
  
model	
   can	
   be	
   a	
   starting	
   point	
   to	
   implement	
   ITS	
   functionality,	
   it	
   is	
   still	
   too	
   abstract	
   to	
   be	
   a	
   software	
   design	
   and	
  
therefore	
  there	
  are	
  diverse	
  options	
  to	
  implement	
  it.	
  The	
  next	
  step	
  in	
  our	
  process	
  was	
  to	
  evolve	
  this	
  model	
  by	
  
defining	
   more	
   specific	
   relationships	
   between	
   components	
   using	
   design	
   patterns;	
   this	
   provided	
   us	
   with	
   a	
  
template	
   for	
   the	
   software	
   design	
   and	
   therefore	
   for	
   the	
   implementation.	
   Table	
   1	
   shows	
   the	
   relationship	
  
between	
  components	
  previously	
  defined	
  matched	
  with	
  a	
  pattern	
  name	
  with	
  a	
  description	
  of	
  the	
  meaning	
  of	
  the	
  
relationship.	
  
	
  
Table	
  1.	
  Relationships	
  between	
  ITS	
  components	
  and	
  design	
  patterns	
  
Components	
  
	
  
Tool	
  

Pattern
FACADE

TaskSelector	
  

STRATEGY

TaskSelector	
  
and	
  
Assessor	
  

OBSERVER

TaskFactory	
  

ABSTRACT FACTORY

TaskFactory	
  

STRATEGY

StepAnalyzer	
  

CHAIN OF
RESPONSIBILITIES

Assessor	
  

STRATEGY

Pedagogical	
  
Module	
  

STRATEGY

Step	
  

COMPOSITE

Assessor	
  
and	
  
StepAnalyzer	
  

OBSERVER

Pedagogical	
  
Module	
  
and	
  
StepAnalyzer	
  

OBSERVER

Description	
  
	
  
Tool	
  is	
  a	
  high-­‐level	
  interface	
  for	
  the	
  set	
  of	
  ITS	
  subsystems.	
  	
  
	
  
TaskSelector	
   is	
   implemented	
   using	
   STRATEGY	
   pattern	
   to	
   deal	
   with	
   the	
   fact	
   that	
  
selecting	
   the	
   next	
   Task	
   for	
   the	
   student	
   is	
   done	
   with	
   different	
   algorithms	
  
(methodologies)	
  described	
  in	
  (VanLehn	
  2006).	
  
	
  
The	
  relationship	
  between	
  TaskSelector	
  and	
  Assessor	
  can	
  be	
  described	
  by	
   OBSERVER	
  
pattern.	
   TaskSelector	
   needs	
   information	
   about	
   changes	
   in	
   the	
   LearnerModel	
  
(performance	
  of	
  the	
  student)	
  maintained	
  by	
  Assessor,	
  in	
  order	
  to	
  adjust	
  the	
  level	
  of	
  the	
  
next	
  Task.	
  
	
  
TaskFactory	
   creates	
   Task	
   objects.	
   The	
   relationship	
   between	
   TaskFactory	
   and	
   Task	
  
corresponds	
   to	
   the	
   relationship	
   between	
   a	
   factory	
   and	
   a	
   product	
   in	
   ABSTRACT	
  
FACTORY	
  pattern.	
  	
  
	
  
TaskFactory	
   implements	
   STRATEGY	
   to	
   create	
   Tasks,	
   due	
   to	
   the	
   fact	
   that	
   ITS	
   could	
  
implement	
   either	
   particular	
   algorithms	
   to	
   create	
   Tasks	
   in	
   real-­‐time	
   or	
   create	
   Tasks	
  
recovering	
  them	
  from	
  a	
  data	
  repository.	
  
	
  
CHAIN	
   OF RESPONSIBILITIES	
   is	
   a	
   design	
   pattern	
   that	
   avoids	
   coupling	
   the	
  
sender	
  of	
  a	
  request	
  to	
  its	
  receiver	
  by	
  giving	
  more	
  than	
  one	
  object	
  a	
  chance	
  to	
  handle	
  the	
  
request.	
   StepAnalyzer	
   chains	
   the	
   receiving	
   objects,	
   which	
   are	
   the	
   task’s	
   steps,	
   and	
  
passes	
  the	
  request	
  along	
  the	
  chain	
  until	
  one	
  object	
  handles	
  it.	
  Handling	
  a	
  request	
  means	
  
recognizing	
  a	
  student’s	
  UI	
  event	
  as	
  a	
  step	
  that	
  is	
  either	
  correct	
  or	
  incorrect.	
  	
  	
  
	
  
Assessor	
   implements	
   STRATEGY	
   to	
   maintain	
   the	
   LearnerModel.	
   Diverse	
   strategies	
  
could	
   be	
   tried	
   to	
   store	
   and	
   recover	
   the	
   LearnerModel	
   information.	
   	
   A	
   typical	
   strategy	
  
consists	
   of	
   associating	
   each	
   step	
   with	
   a	
   set	
   of	
   knowledge	
   components	
   that	
   represents	
  
what	
   the	
   student	
   would	
   need	
   to	
   know	
   in	
   order	
   to	
   get	
   that	
   step	
   correct.	
   	
   When	
   the	
  
Assessor	
  is	
  informed	
  that	
  a	
  particular	
  Step	
  is	
  correct,	
  it	
  increments	
  the	
  mastery	
  of	
  the	
  
associated	
   knowledge	
   components.	
   On	
   the	
   other	
   hand,	
   if	
   the	
   student	
   got	
   the	
   Step	
  
wrong,	
  then	
  Assessor	
  reduces	
  the	
  mastery	
  of	
  the	
  associated	
  knowledge	
  components.	
  	
  
	
  
PedagogicalModule	
   implements	
   STRATEGY	
   to	
   provide	
   support	
   to	
   the	
   student	
   in	
  
solving	
  the	
  current	
  Step.	
  Options	
  to	
  provide	
  Help	
  go	
  from	
  pressing	
  a	
  button	
  asking	
  for	
  a	
  
Hint	
   to	
   the	
   implementation	
   of	
   intelligent	
   algorithms	
   that	
   provide	
   support	
   to	
   maintain	
  
the	
   student	
   in	
   the	
   "zone	
   of	
   proximal	
   development"	
   (Vygotsky	
   1978),	
   where	
   tasks	
   are	
  
neither	
  boringly	
  easy	
  nor	
  frustratingly	
  difficult,	
  but	
  instead	
  these	
  tasks	
  afford	
  maximal	
  
learning	
  and	
  motivating	
  challenges.	
  
	
  
COMPOSITE	
   pattern	
   allows	
   us	
   to	
   compose	
   Steps	
   into	
   tree	
   structures	
   to	
   represent	
  
part-­‐whole	
   hierarchies.	
   COMPOSITE	
   pattern	
   lets	
   us	
   treat	
   individual	
   Steps	
   and	
  
hierarchies	
  of	
  Steps	
  (and	
  sub-­‐Steps)	
  uniformly.	
  
	
  
The	
   relationship	
   between	
   Assessor	
   and	
   StepAnalyzer	
   is	
   described	
   by	
   OBSERVER	
  
pattern.	
   Assessor	
   needs	
   information	
   about	
   student	
   performance	
   in	
   each	
   Step.	
   That	
  
information	
  is	
  obtained	
  from	
  StepAnalyzer.	
  
	
  
The	
   relationship	
   between	
   PedagogicalModule	
   and	
   StepAnalyzer	
   can	
   be	
   described	
   by	
  
OBSERVER	
   pattern.	
   PedagogicalModule	
   needs	
   information	
   about	
   student	
  
performance	
  in	
  each	
  Step.	
  That	
  information	
  is	
  obtained	
  from	
  StepAnalyzer.	
  

From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  7	
  

Finding	
   the	
   appropriate	
   pattern	
   to	
   be	
   applied	
   to	
   each	
   component	
   and	
   relationship	
   was	
   a	
   process	
   based	
   on	
  
experience	
   and	
   literature	
   research	
   (Buschmann	
   et	
   al.	
   1996,	
   Gamma	
   et	
   al.	
   1995).	
   	
   There	
   is	
   no	
   set	
   of	
   rules	
   on	
  
how	
  to	
  choose	
  a	
  pattern;	
  instead,	
  a	
  firm	
  knowledge	
  of	
  existing	
  patterns	
  as	
  well	
  as	
  the	
  problems	
  they	
  solve	
  is	
  
required	
   in	
   order	
   to	
   effectively	
   use	
   patterns	
   to	
   describe	
   what	
   happens	
   within	
   a	
   given	
   system.	
   Our	
   approach	
  
consists	
  of	
  using	
  the	
  pattern	
  that	
  most	
  closely	
  matches	
  the	
  semantic	
  description	
  of	
  the	
  requirement	
  or	
  group	
  of	
  
requirements.	
   From	
   the	
   “GoF”	
   design	
   patterns	
   documented	
   in	
   (Buschmann	
   et	
   al.	
   1996)	
   and	
   (Gamma	
   et	
   al.	
  
1995),	
   we	
   took	
   the	
   keywords	
   observer,	
   abstract	
   factory,	
   builder,	
   chain	
   of	
   responsibilities,	
   strategy,	
  
communicator,	
  facade,	
  composite,	
  and	
  singleton;	
  each	
  pattern	
  is	
  fairly	
  close	
  to	
  implementing	
  the	
  task	
  that	
  its	
  
name	
   means	
   and	
   what	
   each	
   component	
   is	
   supposed	
   to	
   do;	
   for	
   example,	
   TaskFactory	
   is	
   an	
   ABSTRACT
FACTORY	
  of	
  Tasks.	
  	
  
	
  
3.2 Putting	
  All	
  The	
  Patterns	
  Together	
  	
  
With	
   the	
   relationships	
   expressed	
   as	
   pattern	
   equivalences,	
   as	
   listed	
   in	
   the	
   previous	
   section,	
   creating	
   a	
   software	
  
design	
  is	
  fairly	
  straightforward.	
  Each	
  pattern	
  has	
  a	
  unique	
  equivalence	
  in	
  UML	
  (as	
  a	
  class	
  diagram).	
  Then,	
  our	
  
development	
  team	
  would	
  be	
  able	
  to	
  focus	
  on	
  the	
  detailed	
  implementation	
  of	
  the	
  desired	
  functionality,	
  filling	
  in	
  
specific	
  places	
  inside	
  of	
  specific	
  files,	
  methods,	
  and	
  attributes	
  (Booch	
  et	
  al.	
  2007).	
  The	
  UML	
  class	
  diagram	
  for	
  
the	
  Core	
  layer	
  is	
  shown	
  in	
  Figure	
  3.	
  
	
  

	
  
Fig.	
  3.	
  UML	
  class	
  diagram	
  showing	
  the	
  pattern-­‐based	
  model	
  for	
  the	
  “Core”	
  layer.	
  

It	
  is	
  important	
  to	
  note	
  the	
  following	
  relationships	
  in	
  the	
  diagram	
  shown	
  in	
  Figure	
  3:	
  
	
  
• The	
   implementation	
   of	
   Step	
   as	
   a	
   COMPOSITE	
   is	
   highly	
   useful;	
   it	
   provides	
   the	
   capability	
   of	
   managing	
   Steps	
  
as	
  one	
  or	
  as	
  a	
  hierarchy	
  of	
  several	
  hierarchical	
  Steps.	
  
From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  8	
  

•

•

TaskSelector,	
   TaskFactory,	
   Assessor,	
   and	
   PedagogicalModule	
   implement	
   the	
   STRATEGY	
   pattern	
   that	
  
permit	
   us	
   to	
   define	
   algorithms,	
   encapsulate	
   them,	
   and	
   make	
   them	
   interchangeable.	
   	
   STRATEGY	
   pattern	
  
lets	
  the	
  algorithm	
  vary	
  independently	
  of	
  the	
  classes	
  that	
  use	
  it.	
  Implementing	
  a	
  new	
  way	
  to	
  select	
  a	
  Task,	
  
create	
  a	
  Task,	
  manage	
  the	
  LearnerModel,	
  or	
  provide	
  Help	
  to	
  the	
  student	
  can	
  be	
  done	
  by	
  one	
  developer	
  who	
  
needs	
   no	
   knowledge	
   about	
   the	
   project	
   at	
   all;	
   the	
   developer	
   just	
   needs	
   to	
   follow	
   the	
   pattern	
   to:	
   (1)	
   create	
   a	
  
new	
  class	
  that	
  implements	
  the	
  corresponding	
  interface;	
  (2)	
  implement	
  at	
  least	
  the	
  algorithm	
  method;	
  and	
  
(3)	
  create	
  as	
  many	
  additional	
  methods	
  and/or	
  attributes	
  as	
  needed.	
  
TaskSelector	
  obtains	
  information	
  from	
  Assessor,	
  which	
  as	
  well	
  as	
  PedagogicalModule	
  obtains	
  information	
  
from	
   StepAnalyzer.	
   The	
   concept	
   of	
   “observing”	
   describes	
   the	
   relationship	
   and	
   clearly	
   identifies	
   how	
   the	
  
structure	
   of	
   communication	
   must	
   be	
   implemented	
   (methods	
   and	
   attributes).	
   	
   It	
   is	
   easy	
   to	
   notice	
   which	
  
component	
  needs	
  information	
  from	
  which	
  other	
  component.	
  

	
  
3.3.	
  Implementation	
  
Including	
   structure	
   and	
   functionality	
   the	
   current	
   system,	
   developed	
   in	
   Java,	
   is	
   formed	
   by:	
   10	
   packages;	
   62	
  
classes;	
   746	
   methods;	
   738	
   attributes;	
   22,434	
   lines	
   of	
   code;	
   1,150	
   revisions	
   maintained	
   in	
   a	
   revision	
   control	
  
system	
  (SVN)	
  created	
  between	
  July	
  2009	
  and	
  July	
  2011	
  with	
  a	
  shifting	
  development	
  team	
  of	
  nine	
  programmers	
  
(maintaining	
   a	
   team	
   of	
   two	
   programmers	
   at	
   a	
   time,	
   with	
   an	
   average	
   of	
   six	
   months	
   of	
   permanency)	
   and	
   two	
  
resident	
  software	
  engineers;	
  8	
  versions	
  released	
  to	
  clients;	
  and	
  140	
  users	
  working	
  with	
  the	
  system,	
  who	
  have	
  
been	
   high	
   school	
   students	
   and	
   undergraduate	
   students	
   participating	
   in	
   four	
   summer-­‐camp	
   courses	
   and	
   two	
  
university	
  courses	
  at	
  Arizona	
  State	
  University.	
  
	
  
The	
  implementation	
  of	
  the	
  Strategy	
  classes	
  included:	
  
	
  
• StrategyTaskSelector	
  interface	
  implemented	
  in	
  SequencialTaskSelection	
  class.	
  	
  SequencialTaskSelection	
  
class	
  defines	
  a	
  strategy	
  that	
  presents	
  Tasks	
  to	
  the	
  student	
  in	
  a	
  predefined	
  sequential	
  order.	
  
• StrategyTaskFactory	
  interface	
  implemented	
  in	
  TaskFromRepository	
  class.	
  TaskFromRepository	
  class	
  
defines	
  a	
  strategy	
  that	
  recovers	
  Tasks	
  from	
  text	
  files.	
  
• No	
  strategy	
  implemented	
  for	
  Assessor,	
  this	
  component	
  is	
  still	
  an	
  ongoing	
  part	
  of	
  the	
  project.	
  
• StrategyPedagogicalModule	
  interface	
  implemented	
  in	
  ConditionalPedagogicalStrategy	
  class.	
  
ConditionalPedagogicalStrategy	
  class	
  defines	
  a	
  strategy	
  in	
  which,	
  conditionally,	
  the	
  presence	
  of	
  certain	
  
events	
  or	
  actions	
  from	
  the	
  student	
  launches	
  pre-­‐established	
  responses.	
  	
  
	
  
These	
  classes,	
  which	
  implement	
  Strategy	
  interfaces,	
  are	
  not	
  shown	
  in	
  Figure	
  3	
  due	
  to	
  space	
  limitations.	
  
	
  
Regarding	
   the	
   Tool	
   component,	
   Tool	
   is	
   a	
   facade	
   for	
   an	
   environment	
   in	
   which	
   the	
   student	
   is	
   able	
   to	
   learn	
  
about	
  systems	
  dynamic	
  modeling,	
  using	
  a	
  graphical	
  representation.	
  Each	
  model	
  is	
  a	
  directed	
  graph	
  formed	
  by	
  
nodes	
   and	
   edges.	
   The	
   edges	
   indicate	
   flow	
   of	
   numeric	
   information	
   between	
   nodes	
   and	
   the	
   nodes	
   represent	
  
variables.	
  A	
  node	
  encapsulates	
  a	
  variable’s	
  value	
  as	
  an	
  algebraic	
  combination	
  of	
  the	
  numbers	
  coming	
  into	
  or	
  
going	
   out	
   of	
   it	
   via	
   edges.	
   Students	
   read	
   text	
   describing	
   the	
   problem,	
   and	
   then	
   define	
   nodes	
   and	
   edges,	
   enter	
  
values	
  or	
  equations	
  in	
  each	
  node,	
  run	
  the	
  model	
  and	
  compare	
  its	
  predictions	
  to	
  given	
  facts.	
  If	
  any	
  of	
  the	
  model’s	
  
predictions	
  is	
  false	
  (represented	
  with	
  red	
  colors	
  as	
  feedback),	
  students	
  must	
  debug	
  the	
  model.	
  Students	
  also	
  
can	
  ask	
  for	
  feedback	
  by	
  checking	
  their	
  model	
  at	
  each	
  step	
  before	
  running	
  the	
  model	
  (VanLehn	
  2011).	
  Figure	
  4	
  
shows	
  the	
  implementation	
  of	
  the	
  Tool	
  component.	
  Tool	
  component	
  consists	
  on	
  a	
  Canvas	
  in	
  which	
  a	
  Graph	
  is	
  
drawn.	
   A	
   Graph	
   is	
   composed	
   by	
   nodes	
   (Vertexes)	
   and	
   links	
   (Edges)	
   that	
   connect	
   the	
   nodes.	
   Each	
   Vertex	
  
maintains	
  a	
  register	
  of	
  all	
  vertexes	
  going	
  out	
  and	
  in.	
  Each	
  Edge	
  maintains	
  data	
  of	
  the	
  Vertex	
  in	
  which	
  it	
  starts	
  
and	
   ends.	
   Vertexes,	
   Edges,	
   and	
   Graph	
   can	
   be	
   selected	
   from	
   the	
   Canvas	
   and	
   be	
   manipulated	
   (drag	
   and	
   drop,	
  
deleted,	
  and	
  so	
  on).	
  	
  
	
  

From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  9	
  

Fig.	
  4.	
  UML	
  class	
  diagram	
  showing	
  the	
  Tool	
  component	
  encapsulated	
  in	
  the	
  model	
  as	
  Tool.	
  
	
  

4. EXPERIENCE	
  REPORT	
  AND	
  EVALUATION	
  
In	
   this	
   section	
   we	
   will	
   describe	
   our	
   experience	
   using	
   design	
   patterns	
   to	
   create	
   an	
   ITS	
   model	
   and	
   implementing	
  
it	
  to	
  create	
  the	
  AMT	
  software	
  project.	
  	
  
	
  
Stakeholders	
  mentioned	
  the	
  following	
  favorable	
  qualities:	
  	
  
	
  
• Incremental	
   development.	
   Building	
   the	
   AMT	
   project	
   in	
   an	
   incremental	
   way	
   over	
   the	
   course	
   of	
   three	
  
years	
  allowed	
  us	
  to	
  partition	
  the	
  implementation	
  of	
  new	
  functionality	
  into	
  discrete	
  tasks	
  that	
  were	
  worked	
  
on	
   independently	
   from	
   others,	
   therefore,	
   reducing	
   the	
   time	
   of	
   deployment	
   adding	
   programmers	
   in	
  
particular	
  moments	
  of	
  the	
  project.	
  Incremental	
  development	
  allows	
  us	
  to	
  provide	
  a	
  new	
  functionality	
  or	
  a	
  
new	
  version	
  of	
  a	
  current	
  functionality	
  in	
  a	
  window	
  time	
  of	
  two	
  or	
  three	
  weeks.	
  
• Shifting	
  development	
  team.	
  Programmers,	
  even	
  without	
  knowledge	
  of	
  patterns,	
  were	
  able	
  to	
  focus	
  their	
  
attention	
   on	
   the	
   requirements	
   assigned	
   to	
   them;	
   each	
   programmer	
   worked	
   on	
   completing	
   a	
   specific	
  
module	
  or	
  set	
  of	
  components	
  (defined	
  as	
  a	
  pattern	
  section)	
  and	
  relationships	
  between	
  components	
  were	
  
almost	
   entirely	
   defined	
   by	
   patterns.	
   We	
   used	
   Subversion	
   (Collins-­‐Sussman	
   2004)	
   to	
   maintain	
   a	
   common	
  
repository	
  of	
  the	
  project	
  as	
  a	
  tool	
  to	
  support	
  branching	
  and	
  merging	
  processes.	
  
• Communication.	
   Since	
   diverse	
   stakeholders	
   such	
   as	
   researchers	
   in	
   education	
   technology,	
   computer	
  
scientists,	
  developers,	
  and	
  instructional	
  designers	
  were	
  involved,	
  design	
  patterns	
  helped	
  us	
  agree	
  on	
  the	
  
structure	
   of	
   the	
   system	
   and	
   communicate	
   it	
   to	
   the	
   programmers	
   for	
   each	
   individual	
   component	
   in	
   the	
  
project.	
  The	
  use	
  of	
  pattern	
  names	
  such	
  as	
  FACTORY	
  and	
  STRATEGY	
  has	
  been	
  adopted	
  as	
  an	
  abstract	
  way	
  
to	
   refer	
   functionalities	
   between	
   stakeholders.	
   The	
   names	
   hide	
   complexity	
   from	
   non-­‐developers.	
   Non-­‐
developers	
  assume	
  an	
  easy	
  thing	
  must	
  be	
  done,	
  and	
  programmers	
  have	
  a	
  better	
  idea	
  about	
  the	
  boundaries	
  
of	
  changes,	
  bugs,	
  and	
  new	
  requirements.	
  
	
  
However,	
  some	
  disputes	
  emerged	
  with	
  stakeholders	
  regarding	
  the	
  following:	
  
	
  
• Size.	
   Stakeholders	
   point	
   to	
   the	
   increase	
   in	
   size	
   of	
   code	
   while	
   using	
   patterns	
   as	
   an	
   issue.	
   While	
   using	
  
patterns	
   generates	
   more	
   code	
   in	
   our	
   project,	
   this	
   is	
   not	
   only	
   due	
   to	
   patterns	
   (interfaces	
   and	
   abstract	
  
classes	
  declarations),	
  but	
  also	
  because	
  we	
  decided	
  to	
  maintain	
  the	
  cyclomatic	
  complexity	
  (McCabe	
  1976)	
  

From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  10	
  

•

for	
   every	
   method	
   under	
   10,	
   which	
   means	
   applying	
   a	
   “divide	
   and	
   conquer”	
   strategy	
   that	
   generates	
   more	
  
methods	
  in	
  the	
  system.	
  
Deployment	
   Time.	
   Since	
   in	
   each	
   iteration	
   our	
   first	
   step	
   focused	
   on	
   the	
   design	
   definition	
   (patterns),	
  
software	
  prototypes	
  delayed	
  its	
  appearance.	
  But	
  once	
  the	
  first	
  prototype	
  was	
  presented,	
  new	
  prototypes	
  
emerged	
  quicker	
  that	
  in	
  previous	
  projects.	
  	
  

	
  
Finally,	
  developers	
  mentioned	
  the	
  following	
  favorable	
  qualities:	
  
	
  
• Collaboration.	
  Sharing	
  constructions	
  between	
  developers	
  was	
  a	
  key	
  element	
  to	
  counterbalance	
  the	
  effect	
  
of	
  a	
  constant	
  shift	
  in	
  the	
  people	
  in	
  the	
  development	
  team.	
  	
  
• Productivity.	
  Several	
  prototype	
  versions	
  of	
  the	
  project	
  were	
  created	
  to	
  test	
  new	
  options	
  of	
  functionality	
  as	
  
well	
  as	
  new	
  pedagogical	
  approaches.	
  	
  
• Abstraction.	
   Providing	
   a	
   “controlled”	
   freedom	
   to	
   the	
   programmers	
   using	
   patterns	
   as	
   the	
   guidelines	
   of	
   a	
  
defined	
  design	
  was	
  highly	
  relevant	
  to	
  handle	
  changing	
  and	
  incremental	
  requirements.	
  
	
  
5. CONCLUSIONS	
  AND	
  ONGOING	
  WORK	
  
Many	
   authors	
   claim	
   that	
   their	
   ITS	
   follow	
   a	
   software	
   architecture	
   because	
   they	
   can	
   identify	
   components	
   and	
  
relationships	
  among	
  these	
  components	
  inside	
  their	
  systems.	
  However,	
  this	
  does	
  not	
  mean	
  that	
  standard	
  and	
  
good	
  practices,	
  such	
  as	
  design	
  patterns,	
  have	
  been	
  followed.	
  We	
  took	
  advantage	
  of	
  the	
  growing	
  experience	
  in	
  
the	
  field	
  of	
  software	
  design	
  patterns	
  to	
  both	
  design	
  and	
  implement	
  an	
  ITS	
  model	
  in	
  a	
  pattern-­‐based	
  approach.	
  
Applying	
   design	
   patterns	
   was	
   useful	
   to	
   create	
   a	
   high-­‐quality	
   software	
   solution	
   that	
   is	
   easy	
   to	
   maintain	
   and	
  
extend.	
   Designing	
   with	
   quality	
   attributes	
   as	
   drivers	
   has	
   resulted	
   in	
   a	
   design	
   that	
   has	
   proven	
   to	
   be	
   more	
  
reusable,	
   extensible,	
   and	
   adaptable.	
   Using	
   design	
   patterns	
   improved	
   our	
   communication,	
   collaboration,	
   and	
  
productivity.	
  Design	
  patterns	
  facilitate	
  the	
  knowledge	
  transfer	
  across	
  a	
  highly	
  shifting	
  development	
  team	
  and	
  
thus	
   the	
   development	
   of	
   the	
   system,	
   where	
   the	
   creation	
   of	
   new	
   versions	
   or	
   variants	
   of	
   the	
   software	
   was	
  
relatively	
   easy	
   in	
   terms	
   of	
   time	
   and	
   effort.	
   Adding	
   design	
   patterns	
   in	
   the	
   development	
   of	
   ITS	
   allowed	
   us	
   to	
  
create	
  a	
  common	
  vocabulary	
  among	
  stakeholders,	
  making	
  the	
  process	
  more	
  accurate	
  and	
  effective	
  design-­‐wise.	
  
We	
  applied	
  our	
  model	
  to	
  build	
  several	
  variants	
  of	
  the	
  AMT	
  system	
  in	
  three	
  years	
  of	
  work,	
  with	
  a	
  high	
  rate	
  of	
  
changes	
  in	
  requirements	
  for	
  the	
  product	
  and	
  a	
  high	
  shifting	
  development	
  team.	
  In	
  other	
  words,	
  we	
  have	
  been	
  
able	
  to	
  create	
  a	
  family	
  of	
  AMTs	
  around	
  the	
  same	
  design.	
  	
  
Future	
  research	
  will	
  focus	
  on	
  two	
  additions:	
  the	
  first	
  one	
  will	
  be	
  the	
  inclusion	
  of	
  a	
  module	
  for	
  companions	
  to	
  
provide	
   support	
   for	
   the	
   student	
   such	
   as	
   learning	
   companions,	
   affective	
   companions,	
   and	
   teachable	
   agents,	
   and	
  
the	
  second	
  one	
  will	
  be	
  the	
  inclusion	
  of	
  meta-­‐tutoring	
  components.	
  
	
  
REFERENCES	
  
AMT	
  -­‐	
  Affective	
  Meta	
  Tutor.	
  2012.	
  Arizona	
  State	
  University.	
  http://amt.asu.edu.	
  
	
  
Anderson,	
  J.	
  R.,	
  Corbett,	
  A.	
  T.,	
  Koedinger,	
  K.	
  R.,	
  and	
  Pelletier,	
  R.	
  1995.	
  Cognitive	
  Tutors:	
  Lessons	
  Learned.	
  Journal	
  of	
  the	
  Learning	
  Sciences,	
  
4(2),	
  167-­‐207.	
  
	
  
Baker,	
   R.	
   S.	
   J.	
   D.,	
   de	
   Carvalho,	
   A.,	
   Raspat,	
   J.,	
   Aleven,	
   V.,	
   Corbett,	
   A.	
   T.,	
   and	
   Koedinger,	
   K.	
   R.	
   2009.	
   	
   Educational	
   software	
   features	
   that	
  
encourages	
  and	
  discourage	
  “gaming	
  the	
  system”.	
  In	
  Proceedings	
  of	
  the	
  International	
  Conference	
  on	
  Artificial	
  Intelligence	
  in	
  Education.	
  IOS	
  
Press.	
  
	
  
Booch,	
  G.,	
  Maksimchuk,	
  R.,	
  Engle,	
  M.,	
  Young,	
  B.,	
  Conallen,	
  J.,	
  and	
  Houston,	
  K.	
  2007.	
  Object-­‐Oriented	
  Analysis	
  and	
  Design	
  with	
  Applications,	
  
Third	
  Edition.	
  Addison-­‐Wesley	
  Professional.	
  
	
  
Buschmann,	
   F.,	
   Meunier,	
   R.,	
   Rohnert,	
   H.,	
   Sommerlad,	
   P.,	
   and	
   Stal,	
   M.	
   1996.	
   A	
   system	
   of	
   patterns:	
   Pattern-­‐oriented	
   software	
   architecture.	
  
Wiley.	
  
	
  
Collins-­‐Sussman,	
  B.,	
  Fitzpatrick,	
  B.	
  W.,	
  and	
  Pilato,	
  C.	
  M.	
  2004.	
  Version	
  control	
  with	
  subversion.	
  O’Reilly	
  Media,	
  Inc.	
  	
  
	
  
Devedzic,	
  V.	
  and	
  Harrer,	
  A.	
  2005.	
  Software	
  Patterns	
  in	
  ITS	
  Architectures.	
  International	
  Journal	
  of	
  Artificial	
  Intelligence	
  in	
  Education,	
  15,	
  2	
  
(April	
  2005),	
  63-­‐94.	
  
	
  
From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  11	
  

Gamma,	
   E.,	
   Helm,	
   R.,	
   Johnson,	
   R.,	
   and	
   Vlissides,	
   J.	
   1995.	
   Design	
   Patterns:	
   Elements	
   of	
   Reusable	
   Object-­‐Oriented	
   Software.	
   Addison-­‐Wesley	
  
Longman	
  Publishing	
  Co.,	
  Inc.,	
  Boston,	
  MA,	
  USA.	
  
	
  
Gamma,	
   E.,	
   Helm,	
   R.,	
   Johnson,	
   R.,	
   and	
   Vlissides,	
   J.	
   2002.	
   Design	
   Patterns:	
   abstraction	
   and	
   reuse	
   of	
   object-­‐oriented	
   design.	
   In	
   Software	
  
pioneers.	
  Manfred	
  Broy	
  and	
  Ernst	
  Denert	
  (Eds.).	
  Springer-­‐Verlag	
  New	
  York,	
  Inc.,	
  New	
  York,	
  NY,	
  USA	
  701-­‐717.	
  
	
  
Graesser,	
  A.	
  C.,	
  Lu,	
  S.,	
  Jackson,	
  G.	
  T.,	
  Mitchell,	
  H.	
  H.,	
  Ventura,	
  and	
  M.,	
  Olney,	
  A.,	
  Louwerse,	
  M.M.	
  2004.	
  AutoTutor:	
  A	
  tutor	
  with	
  dialogue	
  in	
  
natural	
  language.	
  Behavioral	
  Research	
  Methods,	
  Instruments	
  and	
  Computers,	
  36,	
  180-­‐193.	
  
	
  
IEEE.	
  1999.	
  Standard	
  Glossary	
  of	
  Software	
  Engineering	
  Terminology.	
  610.12-­‐1990,	
  Vol.1.	
  IEEE	
  Press.	
  
	
  
Jacobson,	
  I.	
  1997.	
  Software	
  Reuse:	
  Architecture,	
  Process	
  and	
  Organization	
  for	
  Business	
  Success.	
  Addison-­‐Wesley	
  Professional.	
  	
  
	
  
Katz,	
  S.,	
  Lesgold,	
  A.,	
  Hughes,	
  E.,	
  Peters,	
  D.,	
  Eggan,	
  G.,	
  Gordin,	
  M.,	
   and	
  Greenberg.,	
  L.	
  1998.	
  Sherlock	
  2:	
  An	
  intelligent	
  tutoring	
  system	
  built	
  
upon	
   the	
   LRDC	
   Tutor	
   Framework.	
   In	
   C.	
   P.	
   Bloom	
   &	
   R.	
   B.	
   Loftin	
   (Eds.),	
   Facilitating	
   the	
   development	
   and	
   use	
   of	
   interactive	
   learning	
  
environments.	
  227-­‐	
  258.	
  
	
  
McCabe,	
  T.	
  1976.	
  A	
  complexity	
  measure.	
  IEEE	
  Trans.	
  Software	
  Engineering,	
  5,	
  45–50.	
  
	
  
Mitrovic,	
  A.	
  2003.	
  An	
  intelligent	
  SQL	
  tutor	
  on	
  the	
  web.	
  International	
  Journal	
  of	
  Artificial	
  Intelligence	
  in	
  Education,	
  13(2-­‐4),	
  197-­‐243.	
  
	
  
Nelson,	
   B.	
   C.	
   2007.	
   	
   Exploring	
   the	
   use	
   of	
   individualized,	
   reflective	
   guidance	
   in	
   an	
   educational	
   multi-­‐user	
   virtual	
   environment.	
   Journal	
   of	
  
Science	
  Education	
  and	
  Technology,	
  16(1),	
  83-­‐97.	
  
	
  
VanLehn,	
   K.	
   2006.	
   The	
   Behavior	
   of	
   Tutoring	
   Systems.	
  International	
   Journal	
   of	
   Artificial	
   Intelligence	
   in	
   Education.	
   Volume	
   16,	
  Issue	
   3,	
   Pages	
  
227-­‐265.	
  IOS	
  Press.	
  
	
  
VanLehn,	
   K.,	
   Lynch,	
   C.,	
   Schultz,	
   K.,	
   Shapiro,	
   J.	
   A.,	
   Shelby,	
   R.	
   H.,	
   Taylor,	
   L.,	
   	
   Treacy,	
   D.,	
   Weinstein,	
   A.,	
   and	
   Wintersgill,	
   M..	
   2005.	
   The	
   Andes	
  
physics	
  tutoring	
  system:	
  Lessons	
  learned.	
  International	
  Journal	
  of	
  Artificial	
  Intelligence	
  in	
  Education,	
  15(3),	
  147-­‐204.	
  	
  
	
  
VanLehn,	
  K.,	
  Burleson,	
  W.,	
  Chavez-­‐Echeagaray,	
   M.E.,	
   Christopherson,	
   R.,	
   Gonzalez-­‐Sanchez,	
  J.,	
  Hastings,	
  J.,	
  Hidalgo-­‐Pontet,	
  Y.,	
  and	
  Zhang,	
  L..	
  
2011.	
  The	
  Affective	
  Meta-­‐Tutoring	
  Project:	
  How	
  to	
  motivate	
  students	
  to	
  use	
  effective	
  meta-­‐cognitive	
  strategies.	
  T.	
  Hirashima	
  et	
  al.	
  (Eds.).	
  
In	
   Proceedings	
   of	
   the	
   19th	
   International	
   Conference	
   on	
   Computers	
   in	
   Education.	
   Chiang	
   Mai,	
   Thailand:	
   Asia-­‐Pacific	
   Society	
   for	
   Computers	
   in	
  
Education.	
  
	
  
Vygotsky,	
  L.	
  S.	
  1978.	
  Mind	
  in	
  Society:	
  The	
  Development	
  of	
  Higher	
  Psychological	
  Processes.	
  Cambridge,	
  MA:	
  Harvard	
  University	
  Press.	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
	
  
PLoP'11,	
  October	
  21-­‐23,	
  Portland,	
  Oregon,	
  USA.	
  Copyright	
  2011	
  is	
  held	
  by	
  the	
  author(s).	
  ACM	
  978-­‐1-­‐4503-­‐1283-­‐7	
  
From	
  Behavioral	
  Description	
  to	
  A	
  Pattern-­‐Based	
  Model	
  for	
  Intelligent	
  Tutoring	
  Systems:	
  Page	
  -­‐	
  12	
  

Lost in the Dark: Emotion Adaption
Ryan Bernays, Jeremy Mone, Patty Yau, Michael Murcia, Javier Gonzalez-Sanchez, Maria
Elena Chavez-Echeagaray, Robert Christopherson, Robert Atkinson, Yoshihiro Kobayashi
Arizona State University
University Drive and Mill Avenue, Tempe, AZ 85281,USA
{rbernays, jeremy.mone, patty.yau, michael.murcia, javiergs,
helenchavez, robert.christopherson, robert.atkinson, ykobaya@asu.edu}@asu.edu
ABSTRACT

Having environments that are able to adjust accordingly
with the user has been sought in the last years particularly
in the area of Human Computer Interfaces. Environments
able to recognize the user emotions and react in
consequence have been of interest on the area of Affective
Computing. This work presents a project – an adaptable 3D
video game, Lost in the Dark: Emotion Adaption, which
uses user’s emotions as input to alter and adjust the gaming
environment. To achieve this, an interface that is capable of
reading brain waves, facial expressions, and head motion
was used, an Emotiv® EPOC headset. For our purposes we
read emotions such as meditation, excitement, and
engagement into the game, altering the lighting, music,
gates, colors, and other elements that would appeal to the
user emotional state. With this, we achieve closing the loop
of using the emotions as inputs, adjusting a system
accordingly as a result, and elicit emotions.
Author Keywords

Emotion recognition; affective states; EEG; 3D videogames
ACM Classification Keywords

H.5.2 [Information interfaces and presentation]: User
Interfaces --- interaction styles, input devices and
strategies.

to take control of his emotions and use them to progress.
Like recent developments in game design in which user
movements are used to make him feel more part of the
game, using a user’s emotions can open up entirely new
levels of gameplay and research, and increase games’
ability to adapt to an input as complicated as human
emotions.
BACKGROUND

This section provides information about the technology
behind the game including hardware and software.
Emotiv® EPOC Headset

Our research uses the Emotiv ® EPOC headset [2]. This
device has non-invasive electrodes that are used to capture
brain-wave signals. It measures voltage fluctuations
resulting from ionic current flows within the neurons of the
brain, which occur differentially in the presence of diverse
emotions. This device uses pattern detection analysis to
infer emotional states and reports affective states such as:
excitement, engagement, meditation, calmness, boredom,
and frustration.
Emotiv SDK

Design, Human Factors

The Emotiv® EPOC headset comes with a Software
Develop Kit (SDK). This SDK in conjunction and based on
the ABE system [3] allows developers to get data from the
device in real time, by introducing its functionality into
game-developing environments.

INTRODUCTION

XNA + Visual Studio

In games, immersion has always been a long sought goal of
the designing process. Feeling more connected with the
game through interactivity, wealth of sensory information,
or an environment that demands your full attention always
makes it more enjoyable. An adaptive environment helps to
enhance immersion. With our game’s unique emotion
controls, we hope to enhance it more to create a fun and
helpful experience for players. Our game uses the
Emotiv® EPOC headset to read brain waves that indicate
user’s current levels of excitement, engagement, and
meditation. Using these as game variables, we have the
game either adapt or adjust to match the player’s current
emotional state, or provide obstacles that require the player

XNA Game Studio 4.0 [5] is a game-developing
environment that allows the use of Visual Studio 2010 [4],
an integrated development environment (IDE) from
Microsoft used to develop console and graphical user
interface (GUI) applications. It supports XNA’s
Framework 4.0, a set of libraries for game development.

General terms

Copyright is held by the author/owner(s).
UIST ’12, October 7–10, 2012, Cambridge, Massachusetts, USA.
ACM 978-1-4503-1582-1/12/10. 	
  

THE GAME

The game offers a 3D maze enhanced with emotional
components as inputs that are mapped with features in the
game, allowing an adaptive maze in terms of light, sound,
play time, and access to different sections and levels.
The 3D Maze

The maze takes place on the inside of a gigantic cylinder,
gravity forces players downward from the center so that
they can walk along the inside of it. The maze walls are
generated to also stretch across the walls, providing the

player with a view of other parts of the maze that they can
look up at to discern where to go next. The walls are
colored (red, yellow, and green) indicating how far or near
is the exit. The player starts at one end of the cylinder, must
unlock and cross through diverse gates, and make his way
to the other side where an elevator takes him into the next
level. There are keyboards’ controls (WASD keys) for
movement, an Xbox 360 controller to control movements
and the camera, and a mouse for looking around. The
players are also provided with a mini-map for navigation.
The Components based on Emotion Inputs

We use three emotions from the ones the Emotiv® EPOC
headset picks up: excitement, engagement, and meditation.
Excitement determines the color of the Light Bot, a floating
sphere that projects all of the light within the maze (see
Figure 1). Light Bot has colors that run along the sides,
matching up to a certain level of excitement. Ranging from
black to red to yellow to green to teal to blue to purple to
white (from calmest to most excited), a bar to the left
demonstrates the spectrum and user’s current level, so that
he knows how to reacts if he needs the Light Bot to change
its color. There are also gates within the maze that range in
the same color spectrum, and they will open and allow the
player to continue if he can match the Light Bot’s color to
that of the gate. This forces players to take control of their
excitement by calming or invigorating themselves.
Engagement controls music. When the player is relaxed
and unconcerned, the music changes volume to a softer
tone to reflect the player’s relaxed state, but when the
player becomes more interested or agitated, the music
increases in volume to match the new manic state. This
helps set the mood for the game according to the player’s
emotional status.
For meditation, we added in the ever-increasing danger of
the player’s sole light source giving out. As time passes in
the game, the Light Bot will lose light, forcing the player to
hurry to the exit before it goes out. However, by focusing
on the meditation, players are able to expand their field of
vision and keep the darkness at bay, and keeping this level
of focus while playing makes the game easier (see Figure
1). This forces players to learn to play with a cool,
concentrated head under stressful situations. As the
meditation level increases, the current level of light
increases, and as it decreases, so does the light.
Implementation

The game’s mazes are generated by reading commaseparated-values (csv) text files that use characters to
represent wall pieces, gates, or elevators. After reading the
file, the game automatically generates the maze. Mazes
could be created or edited with ease by altering the text file.
Graphics were made using the Maya 3D Animation
Software [1]. We created the shapes for the wall pieces,
gates, the cylinder, elevators, and the Light Bot.

Figure 1. A screen shown from gameplay, as the light level is
closing in due to a lack of meditation upon the part of the
player, as the player is attempting to change his excitement
level to match the colors of the gate and ball.

This environment was used to create textures that would fit
over all of the game objects: the floor tiles, wall graphics,
and the lights that make up the gates and Light Bot.
Music for the game was not specifically made, but is
simply the song “Self Esteem Fund” from the popular game
Portal, mainly to create the feeling of lonely suspense.
CONCLUSION AND FUTURE WORK

Adjusting an environment according to emotions is
complex, and it’s difficult to find mechanics for each
emotion that feels natural to be connected to. However, we
consider our game to have done a great job in creating a
complete experience for players to use their emotions as a
tool to play the game, and we consider it provides a world
of opportunities in the future where emotions patterns can
be used for much more integrated controls, and changing of
an environment. Not only is it entertaining, but it could be
transferred to education and learning areas, allowing people
to practice controlling their emotions, and discerning what
elements on an environment trigger what emotions.
ACKNOWLEDGMENTS

The project was developed as a course work of CPI441
(Gaming Capstone) at ASU collaborating with the research
group supported by Office of Naval Research under Grant
N00014-10-1-0143 awarded to Dr. Robert Atkinson.
REFERENCES

1. Autodesk Maya. 3D Animation Software.
http://usa.autodesk.com/maya
2. Emotiv. Brain Computer Interface Technology.
http://www.emotiv.com
3. Gonzalez-Sanchez, J., Chavez-Echeagaray, M.E.,
Atkinson, R. and Burleson, W. 2011, ABE: An AgentBased Software Architecture for a Multimodal Emotion
Recognition Framework. In Proc. of Ninth Working
IEEE/IFIP Conference on Software Architecture, 2011,
187-193.
4. Visual Studios 2010. Microsoft.
http://www.microsoft.com/visualstudio/enus/products/2010-editions
5. XNA Game Studio 4.0. Microsoft.
http://www.microsoft.com/enus/download/details.aspx?id=23714

2013 IEEE 13th International Conference on Advanced Learning Technologies

Affect Recognition in Learning Scenarios: Matching Facial- and BCI-Based Values
Javier Gonzalez-Sanchez1, Maria Elena Chavez-Echeagaray1, Lijia Lin2, Mustafa Baydogan1,
Robert Christopherson1, David Gibson3, Robert Atkinson1, Winslow Burleson1
1

Arizona State University, AZ, USA, 2East China Normal University, Shanghai, China, 3Curtin University, Perth, Australia
javiergs@asu.edu, helenchavez@asu.edu, ljlin@psy.ecnu.edu.cn, mbaydoga@asu.edu,
robert.christopherson@asu.edu, david.gibson@curveshift.com, robert.atkinson@asu.edu, winslow.burleson@asu.edu

Abstract— The ability of a learning system to infer a student’s
affects has become highly relevant to be able to adjust its
pedagogical strategies. Several methods have been used to infer
affects. One of the most recognized for its reliability is facebased affect recognition. Another emerging one involves the
use of brain-computer interfaces. In this paper we compare
those strategies and explore if, to a great extent, it is possible to
infer the values of one source from the other source.

III.

To explore the relationships between face-based and
BCI-based approaches, we used data collected from
participants engaged in two studies designed to stimulate
distinct affects. The stimuli, protocol, and participant details
for these studies are presented below.
Study one. The Guitar Hero® video game [7] was used
for this study to generate both deep engagement and, at
times, frustration [6]. The goal of the game is to press one or
more colored buttons at the same time as moving target
lights of the same color cross a line on the screen. The study
consisted of a one-hour session, with the first 15 minutes
allocated to practice, followed by a 45-minute session in
which participants played four songs of their choice, one of
each level: easy, medium, hard, and expert. Data was
collected from six participants.
Study two. Text from an educational psychology
textbook was used for this study. This text was presented in
two ways: one with off-task images and captions (nonessential content) and the other containing only essential
content. Having these two presentations allowed the
evaluation of how the presence or absence of off-task images
could impact the engagement of the reader and therefore the
understanding of the reading. The study consisted of a onehour session in which participants were presented with 10
pages and asked to read for understanding. Each participant
was asked to complete a pre- and post-test. Data was
collected from 27 participants.

Keywords-brain computer interfaces; affect recognition;
random forest

I.

INTRODUCTION

Several approaches have been used for affect recognition
and researchers have explored how these approaches
complement or supplement each other in learning scenarios
[1]. Affect recognition using facial expression as input has
been regarded as the most accurate measurement [2].
However, brain-computer interfaces (BCI) have not yet been
incorporated. In this paper we describe our results correlating
face-based and BCI-based values toward the verification of
the interchangeability of these approaches in learning
contexts. We have explored if, to a great extent, it is possible
to infer the values of one source from the other source.
II.

BACKGROUND

The face-based approach uses as input sequences of head
and facial images. It performs best when the user stays
within the camera’s viewing angle and avoids abrupt
movements (e.g., reading on the screen or selecting with the
mouse). In cases where the user is not quietly sitting (e.g.,
playing an active video game or participating in an active
environment), the loss of data becomes problematic. Our
research uses MindReader, face-based affect recognition
software [3], which provides measurements for agreement,
disagreement, concentrating, interest, thinking, and
unsureness.
The BCI-based approach uses non-invasive electrodes to
capture brain-wave signals and uses pattern detection
analysis of these signals to infer affective states [4]. The BCI
allows the user to move freely and is able to provide accurate
inferences; however, it is susceptible to electromagnetic
interference and its setup encounters some difficulties (e.g.,
moisturizing the electrodes and maintaining their contact)
that can cause missing or noisy data. Our research uses the
Emotiv® EPOC headset [5], which reports measurements for
excitement, engagement, meditation, and frustration.
978-0-7695-5009-1/13 $26.00 © 2013 IEEE
DOI 10.1109/ICALT.2013.26

CASE STUDIES

IV.

MATCHING VALUES AND DISCUSSION

The values collected from both approaches are in the
range of 0 to 1 and represent the level of each affect. The
sampling rate from the face-based approach is 10Hz while
the sampling rate from the BCI-based approach is 8Hz;
hence, the data needed to be synchronized. The data
synchronization was done using a state-machine technique,
in which it is assumed that an input value is “alive” until a
new one arrives. The resulting dataset was composed of 10
rows per second (the higher sampling rate) and each row has
the attributes of both approaches (ten values).
Random Forest (RF) [8] was used to model the relations
between both approaches. RF uses a random selection of
features and provides a ranking of the feature’s importance
as a predictor. This makes RF a good choice for our
multidimensional exploratory factor analysis. We built two
RF models, the first one to predict each face-based inferred
70

affect using the BCI-based inferred affect and the second one
to do the opposite, predicting each BCI-based inferred affect
using the face-based inferred affect. The performance
measure considered in our study is the correlation of the
predicted values with the actual values. The obtained
correlation values are as given in Table 1.

engagement, meditation, and frustration (factor>0.60). High
values of frustration increase the assumption of interest;
however, a detailed interpretation of the other variables is
part of the ongoing work.
5) Thinking is inferred with excitement and meditation
as the variables with most importance (factor>0.90)
followed by engagement and frustration (factor>0.75).
Higher values of engagement and low values of frustration
and excitement increase the assumption of thinking.
6) Unsure is inferred with engagement and excitement
as the variable with most importance (factor>0.90) followed
by meditation and frustration (factor>0.75). High values of
engagement and meditation and low excitement and
frustration are related to unsureness.

TABLE I. CORRELATION BETWEEN BCI-BASED AND FACE-BASED VALUES
USING RF MODELS
BCI-based values
Excitement
Engagement
Meditation
Frustration
Face-based values
Agreement
Concentrating
Dissagreement
Interested
Thinking
Unsure

Correlation with predicted
values using face-based values
0.284
0.282
0.188
0.275
Correlation with predicted
values using BCI-based values
0.760
0.765
0.794
0.774
0.780
0.828

V.

CONCLUSIONS

According to our results, it is fairly reliable to infer affect
measurements obtained from a face-based affect recognition
system using a BCI. In the inverse case, inferring the BCI
values using the values from the face-based affect
recognition system generates models with low correlation;
therefore, they are not reliable.

The correlation values are not good for the models in
which BCI-based inferred affects are predicted by the facebased inferred affects. But the reverse task, predicting facebased infered affect by BCI-based infered affect, provides
reasonable correlational values. We expect this lack of
symmetry because face-based detections are dependent
outcomes of a person in some mental state, while the reverse
is not true. We do not expect facial expressions to
significantly drive the internal mental state of the person
being studied; therefore, low correlations do not surprise us.
A low correlation implies a poor model; analysis over that
model is not valuable and may mislead. Consequently, we
realize an analysis in terms of interpretability only for the
models built for prediction of face-based inferred affects
using BCI values as follows:
1) Agreement is inferred with excitement as the variable
with most importance (factor>0.90) followed by
engagement, frustration, and meditation (factor>0.75).
Medium or high values of excitement increase the
assumption of agreement, and meditation levels appear to
proportionally affect the agreement level.
2) Concentrating is inferred with excitement and
meditation as the variables with most importance
(factor>0.90) followed by engagement and frustration
(factor>0.80). High values of engagement and low
excitement are related to concentration. Frustation and
meditation do not show consistant dependence.
3) Disagreement is inferred with excitement as the
variable with most importance (factor>0.90) followed by
meditation, engagement, and frustration (factor>0.80). Low
values of excitement and frustration but high engagement
and meditation are related to disagreement.
4) Interested is inferred with excitement as the variable
with most importance (factor>0.90) followed by

ACKNOWLEDGMENT
This research was supported by the Office of Naval
Research under Grant N00014-10-1-0143 awarded to Dr.
Robert Atkinson.
REFERENCES
[1] I. Arroyo, D. G. Cooper, W. Burleson, B. P. Woolf, K.
Muldner, and R. M. Christopherson, “Emotion Sensors Go To
School,” presented at the Proceedings of the 2009 conference
on Artificial Intelligence in Education: Building Learning
Systems that Care: From Knowledge Representation to
Affective Modeling, Amsterdam, The Netherlands, The
Netherlands, 2009, pp. 17–24.
[2] D. G. Cooper, I. Arroyo, B. P. Woolf, K. Muldner, W.
Burleson, and R. M. Christopherson, “Sensors Model Student
Self Concept in the Classroom,” presented at the Proceedings
of the 17th International Conference on User Modeling,
Adaptation, and Personalization, Berlin, Heidelberg, 2009, pp.
30–41.
[3] P. Michel and R. El Kaliouby, “Real time facial expression
recognition in video using support vector machines,”
presented at the Proceedings of the 5th international
conference on Multimodal interfaces, 2003, pp. 258–264.
[4] D. S. Tan and A. Nijholt, Brain-Computer Interfaces:
Applying Our Minds to Human-Computer Interaction.
Springer London, Limited, 2010.
[5] Emotiv EPOC Headset. [Online]. Available:
http://www.emotiv.com. [Accessed: 10-Apr-2013].
[6] P. G. Schrader and M. McCreery, “The Acquisition of Skill
and Expertise in Massively Multiplayer Online Games,”
Educational Technology Research and Development, vol. 56,
no. 5, pp. 557–574, 2007.
[7] Guitar Hero. [Online]. Available:
http://www.guitarhero.com. [Accessed: 10-Apr-2013].
[8] A. Liaw and M. Wiener, “Classification and Regression by
randomForest,” R NEWS, vol. 2, no. 3, pp. 18–22, 2002.

71

Toward a Software Product Line for
Affective-Driven Self-Adaptive Systems
Javier Gonzalez-Sanchez
School of Computing, Informatics, and Decision Systems Engineering
Arizona State University
Tempe, AZ, USA
javiergs@asu.edu
Abstract—One expected characteristic in modern systems is
self-adaptation, the capability of monitoring and reacting to
changes into the environment. A particular case of selfadaptation is affective-driven self-adaptation. Affective-driven
self-adaptation is about having consciousness of user’s affects
(emotions) and drive self-adaptation reacting to changes in those
affects. Most of the previous work around self-adaptive systems
deals with performance, resources, and error recovery as
variables that trigger a system reaction. Moreover, most effort
around affect recognition has been put towards offline analysis of
affect, and to date only few applications exist that are able to
infer user’s affect in real-time and trigger self-adaptation
mechanisms. In response to this deficit, this work proposes a
software product line approach to jump-start the development of
affect-driven self-adaptive systems by offering the definition of a
domain-specific architecture, a set of components (organized as a
framework), and guidelines to tailor those components. Study
cases with systems for learning and gaming will confirm the
capability of the software product line to provide desired
functionalities and qualities.
Index Terms—Affective Computing, Self-Adaptation, Software
Product Line, Framework, Patterns, Software Architecture

I. MOTIVATION
The computer's ability to recognize human affective states
(emotions), given physiological signals, and to change its
behavior driven by those affective states is gaining popularity;
this is motivated by the realization that emotions are
inextricably bounded to human cognitive processes and express
a lot about human necessities [1]. Emerging systems equipped
with those abilities can be called “affect-driven self-adaptive”
systems. Affective-driven self-adaptive systems aim to take
advantage of sensing devices to perceive signals of user’s
affective state changes, understand the meaning of those
changes, learn from them, and react in consequence to improve
system’s functionality and user experience. Learning
environments, health care systems, and video games are just a
few examples of systems that stand to benefit from affectivedriven self-adaptive capabilities.
II. PROBLEM
Providing affective-driven self-adaptive capabilities to
software systems faces three main challenges.

c 2013 IEEE
978-1-4673-3076-3/13/$31.00 

First, like most self-adaptive systems deployed today,
affective-driven self-adaptive systems implement their selfadaptive capabilities in an application-specific and disperse
"hardwired" way; which make them brittle, difficult to
generalize, and costly and difficult to modify and maintain [2].
Additionally, self-adaptation models are reported mainly for
performance and work balance (resources) issues. Selfadaptability based on human factors, such as affect
measurement, seems to be a different kind of challenge.
Second, although Picard et al. have demonstrated the
feasibility of developing physiological-signal-based emotion
recognition systems [1], studies’ reports indicate that most
work is related with offline affect analysis (creation of models)
not with real-time awareness, i.e. software systems working
with users in real-time, without human supervision, in which
affect recognition trigger self-adaptation.
Third, since affective computing is a relatively young field,
most efforts around it are focused on specific systems as oneof-a-kind endeavors; efforts around manufacturing in great
scale affect-driven self-adaptive software are rare and moving
craftsmanship of proof-of-concept systems to manufacturing is
something that has not been successfully done.
The goal of this work is to approach these challenges by
standardizing a feasible and cost-effective way to add affectivedriven self-adaptive capabilities, either into new or existing
systems, enabling systematic reuse and achieving the adequate
software qualities.
III. RELATED WORK
Existing approaches limit their applicability to support the
creation of one product instead of a common product platform
(i.e. product families). Developing a product is useful to solve
one problem, but massive production of affective-driven selfadaptive systems or even just affective-aware systems requires
involving expertise centered on the assets and procedures
associated with affect and self-adaptation domains. The
following paragraph summarizes some milestone works.
Burleson et al. developed a platform for multimodal sensing
and interpretation of affective information, which is able to
provide a response in real-time through an expressive agent [3].
Showing that affect can be used as a control variable is the
main contribution of this work. Burleson et al. platform aims to
help end-users (researchers) to run investigations and
specifically to test theories about affect responses in learning.

1381

ICSE 2013, San Francisco, CA, USA
Doctoral Symposium

Therefore, the scope is not an intentional and concerted effort
to create and apply multi-use software artifacts, throughout, to
support developers to create affective-driven adaptation.
Garlan et al. recognize that adaptation mechanisms highly
specific to one application and tightly bounded to the code are
costly to build and difficult to modify. Therefore, they
proposed a middleware for supporting adaptation [4]. The
middleware leverages a framework, called Rainbow, and
guidelines to work with it. Their goal is to be able to add selfadaptation capabilities to a wide variety of systems adding
external control mechanisms and using a reusable
infrastructure. However, their study cases address selfadaptation driven by performance and work balance (resources)
issues; dealing with affect measurements is not in their scope.
Clay et al. proposed an architecture pattern, named emotion
recognition branch, as a guide for the engineering of affective
systems with three piped components for capturing, analyzing
and interpreting data [5]. Clay et al. work is related to
engineering affect systems in general, i.e. what the system does
with the information about the affective state of the user is not
supported.
Hussain and Calvo proposed a framework for multimodal
affect recognition targeted for learning systems but flexible to
other applications [6]. Hussain and Calvo framework, like
Burleson et al. platform, aims to support end-users
(researchers) to run investigations and specifically to test
theories about affect responses. There is not an intentional and
concerted effort to create and apply multi-use software
artifacts, throughout, to support developers to create affectivedriven adaptation.
Several others’ efforts exists; most of them are similar to
one of the previously described (therefore present similar
limitations), such as: (a) multimodal affective user interface by
[7]; (b) agent-based intelligent tutoring system using facial
recognition system by [8]; (c) a framework for affective
intelligent tutor system: Emilie-1 and Emile-2 by [9]; (d)
SEMAINE framework by [10]; and (e) multimodal emotion
recognition by [11].
IV. APPROACH
My hypothesis is that it is possible to support a broad
creation and integration of affective-driven self-adaptation as
core capability inside new and existing systems by (1)
extending and adapting self-adaptive software fundamentals
(such as the ones described in [4] for performance-driven and
resource-driven self-adaptation) to support the creation of
systems that use affect as a control variable, and (2)
implementing a software engineering manufacturing approach,
such as software product lines. Software product lines (SPL)
adopt a manufacturing vision encoding proved practices and
capturing knowledge of how to produce applications that share
common characteristics and make that knowledge available in
the form of assets (architecture models, patterns, frameworks,
and tools) within a package of integrated guidance to
systematically apply them. Developing products using a
suitable SPL aims to improve productivity (reducing cost and
time), quality, and evolution capability.

V. CONTRIBUTIONS
There are three assets to consider outlining a SPL approach:
a) An architectural model that defines how systems must
be built and how that architectural model can be applied to
different class of systems; the architectural model advances
common problems in affective-driven self-adaptive software
design and generalizes them to different kinds of systems
holding a promise for cost-effectiveness and dynamicity (realtime operation).
b) A framework, as a collection of tailorable parts that
allows developers to target the infrastructure to specific classes
of systems. It is a reusable infrastructure that systematically
defines interfaces and components. The framework will enable
systems’ developers (software engineers) to add affectivedriven self-adaptive capabilities to their systems. The goal of
the framework development will not be to invent any new
fusion or classification methods, but rather to facilitate
researchers using the existing ones.
c) Guidelines to combine proprietary and framework
components while creating new systems. The underlying
principle here is to separate the system from adaptation and
adaptation from affect recognition following a divide-andconquer method to confront the problem. Guidelines are
documented to specify objectives, properties of interest,
conditions for change, and strategies for adaptation.
The assets (architecture, components and guidelines) to be
implemented in this proposal have their origins in the phases
documented in [2] for engineering self-adaptation (monitoring,
modeling, and controlling) as well as in the categories proposed
in [12] for dynamically adaptive systems (monitoring, decisionmaking, and reconfiguration infrastructure). Having these
works as a starting point we (my team and I) harvested
common functionalities among some documented affective
systems. The common functionalities detected in our
exploration are summarized as follows: (a) sensing - measuring
signals from hardware devices; (b) perception - parsing a
binary stream of raw data to obtain a measure of an affective
state; (c) emotional intelligence - when systems are conformed
of several sensors (therefore, measure several signals) it is
necessary to fusion that data to infer an affective state; (d)
synapsis - communicating the affective state with other systems
or subsystems of the current system; (e) introspection gathering information about the task that the user is doing and
the status of the task (such as UI events and system failure) to
make system aware of the context related with the current
affective state; (f) rapport - executing a behavior accordingly
with the detected affective state while the user is doing a
specific task; and (g) behavior repository - defining rules and
policies to be applied for a specific affective state while doing a
specific task (these rules and policies define the behavior of the
system).
In my dissertation proposal, I present a research agenda to
create or adapt an architectural model for affective-driven selfadaptive systems, implement domain-specific components
(organized as a framework), and explore the use of design
patterns as templates that document the required guidelines

1382

(besides the use of object-oriented common documentation
techniques).
VI. PROGRESS
Preliminary work demonstrates the feasibility of the overall
approach while partially addressing the challenges related with
affect recognition, usage of patterns to document guidelines
related with affect, and designing of a framework that provides
coarse-grained components for affect recognition (a first step
on the road to affective-driven self-adaptation). The following
paragraphs present a list of publications and developments
done that represent advances of the work proposed here.
Working with colleagues, I have tackled the issue of
detection of affective states. Detecting affective states requires
that the computer senses information that is complex and
diverse, it can range from brain-waves signals and biofeedback
readings to face-based and gesture emotion recognition to
posture and pressure sensing. Obtaining, processing, and
understanding that information requires the use of several
sensing devices, algorithms, and tools. I have already
researched and present work about multimodal emotion
recognition showing my understanding of methodologies and
tools in [13].
Additionally, I led into the development of an agent-based
software architecture for a multimodal emotion recognition
framework. This work offered a first step to provide structural
reference (architecture) and components (framework) to
develop affective-driven self-adaptive systems. This previous
work addressed: the modeling of an agent-driven componentbased architecture for multimodal emotion recognition, called
ABE, and the use of ABE to implement a multimodal emotion
recognition framework to support affect recognition [14]. So
far, I have successfully prototyped the framework and
demonstrated its functionality within a first iteration of
implementation. Also, I addressed in [15] this shortcoming in
models and developer’s guidelines by proposing the use of
software design patterns for modeling a multimodal emotion
recognition framework. The design of the framework offers to:
(a) integrate existing sensing devices and SDK platforms, (b)
include diverse inference algorithms, and (c) help to correlate
measurements from diverse sources. We (my team and I)
described our experience using this model and its impact on
facets, such as creating a common language among
stakeholders, supporting an incremental development, and
adjusting to a highly shifting development team, as well as the
qualities achieved and trade-offs made. To fulfill my
dissertation, I will need to complete the design and perform
subsequent iterations of implementation to include selfadaptation assets and moving from affect recognition to
affective-driven self-adaptation.
Finally, a preliminary set of assets was tested with
undergraduate student developing an adaptable 3D video game,
which uses user’s affective states as input to alter and adjust the
gaming environment; brain waves were used as input to infer
meditation, excitement, and engagement into the game; lighting
and colors were altered according with the inferred user’s
affective state [16].

VII. EVALUATION
Each of the challenges and, therefore, the results need to be
validated and evaluated in a different way, involving formal
analysis of software assets, empirical evaluation, and user study
cases. For study cases with users, two kinds of users are
considered for different evaluation: developers and system
users. I plan to perform evaluation as follows:
a) Framework test bed. Cheng et al. [2] used for their selfadaptive framework evaluation a dedicated test bed with study
cases of systems with different concerns, and they qualitatively
demonstrated how self-adaptive frameworks could be
generalized across different styles of systems and concerns.
The main goal of their experiments was to test whether the
framework provides all desired functionalities in a fairly
convenient way. The experiments needed to confirm that the
framework easily adapts to input data available; allows to
flexibly combine feature-level, class-level, and decision-level
fusion methods; allows to reason data along timeline; and to
select the appropriate classifier in real time. I propose to follow
their approach for qualitative analysis.
b) Framework and patterns in action. This aims to
evaluate that developers understand the architecture, and are
able to use the framework components following the
guidelines. These users could be undergraduate students
involved in capstone projects, or undergraduate research
assistants participating in the creation of systems. This will
include gathering and interpreting data from developers’
experience and run case studies that apply the SPL on learning
and gamming systems to demonstrate generality and
composability. I plan to assess the cost-effectiveness based on
measurement of effort and informal user studies. As part of my
dissertation, I will evaluate how well such framework supports
modular application of patterns as guidelines.
c) User case studies. An affective-driven self-adaptive
system is a unique and site-specific mixture of program,
computer, hardware, software, and computational architecture.
The evaluation of programs and hardware is important, as well
as the architecture structure and models, but also the HCI
component. This proposal will be used as a basis to built
affective-driven systems; testing the fundamentals from the
software point of view requires, as described before, formal
methodologies or empirical studies with developers. But that
does not evaluate users’ (other than developers) experience
with what the SPL provides. Thus, I propose a complementary
evaluation of that as follows: having understood that running
user studies cannot be done with the SPL assets but can be
done with products created using the SPL approach. The results
of the evaluation of the product will need to be analyzed
carefully, since the user’s experience per se will be in part due
to the internal functionality of the product, and in part due to
the qualities and operation of the assets provided by the SPL
approach. The assets of this proposal are essential to the
realization of appropriately emotionally adaptive experiences;
therefore, I believe that to test the accuracy of my proposal it is
also important to evaluate users operating those systems.
Moreover, as claimed by Mark Weiser “the best computer is a
quiet, invisible servant”, it is important to the goal of this thesis

1383

to demonstrate that SPL assets have the qualities to be those
servants inside applications. Without matter, this evaluation
can be ambiguous because it is related with user experience
with the application itself, with the SPL assets, and with the
accurately application of process and guidelines by the
developers involved. Several factors are involved but it is fair
to run case studies around it.
d) Formal evaluation of the architecture. It has not been
concluded if the architectural model will be created or adapted.
If it is adapted, the evaluation of the architectural model could
be part of what was previously described. If a new architectural
model will be required, then it could be necessary a formal
evaluation of the architecture to make sure it is the one that will
do the job. A new architecture must be evaluated because so
much is riding on it. Architecture evaluation provides a
relatively low-cost risk mitigation capability. The evaluation of
the architecture could be conducted using Architecture
Tradeoff Analysis Method (ATAM) [17]. ATAM’s purpose is
to help choosing a suitable architecture for a software system
by discovering trade-offs and sensitivity points.
ACKNOWLEDGE
This research was supported by the Office of Naval
Research under Grant N00014-10-1-0143 awarded to Dr.
Robert Atkinson and by the National Science Foundation,
Award 0705554, IIS/HCC Affective Learning Companions:
Modeling and supporting emotion during teaching Dr. Beverly
Woolf and Dr. Winslow Burleson.
REFERENCES
[1] R. W. Picard, Affective computing. MIT, 1997.
[2] S.-W. Cheng, D. Garlan, and B. Schmerl, “Making selfadaptation an engineering reality,” Self-star Properties in
Complex Information Systems, pp. 349–349, 2005.
[3] W. Burleson, R. W. Picard, K. Perlin, and J. Lippincott, “A
platform for affective agent research,” Workshop on Empathetic
Agents, International Conference on Autonomous Agents and
Multiagent Systems, 2004.
[4] D. Garlan, S.-W. Cheng, A. C. Huang, B. Schmerl, and P.
Steenkiste, “Rainbow: Architecture-based self-adaptation with
reusable infrastructure,” Computer, vol. 37, no. 10, pp. 46–54,
2004.

[5] A. Clay, N. Couture, and L. Nigay, “Engineering affective
computing: a unifying software architecture,” presented at the
ACII, 2009, pp. 1–6.
[6] S. Hussain and R. Calvo, “A Framework for Multimodal Affect
Recognition,” presented at the HCS, 2009, pp. 8–9.
[7] C. L. Lisetti and F. Nasoz, “MAUI: a multimodal affective user
interface,” presented at the Proceedings of the tenth ACM
international conference on Multimedia, New York, NY, USA,
2002, pp. 161–170.
[8] R. Gowri, S. Kanmani, R. Induja, A. Hemalatha, and M. Devi,
“A Secure Agent Based Intelligent Tutoring System Using
FRS,” presented at the ICETET, 2010.
[9] R. Nkambou, “A framework for affective intelligent tutoring
systems,” presented at the Information Technology Based
Higher Education and Training, 2006. ITHET'06. 7th
International Conference on, 2006.
[10] M. Schroder, “The SEMAINE API: towards a standards-based
framework for building emotion-oriented systems,” Advances in
Human-Computer Interaction, vol. 2010, Jan. 2010.
[11] N. Sebe, I. Cohen, and T. S. Huang, “Multimodal emotion
recognition,” Handbook of Pattern Recognition and Computer
Vision, pp. 981–256, 2005.
[12] A. Ramirez and B. Cheng, “Design patterns for developing
dynamically adaptive systems,” ICSE, pp. 49–58, 2010.
[13] J. Gonzalez-Sanchez, R. M. Christopherson, M. E. ChavezEcheagaray, D. C. Gibson, R. Atkinson, and W. Burleson, “How
to Do Multimodal Detection of Affective States?,” ICALT, pp.
654–655, 2011.
[14] J. Gonzalez-Sanchez, M. E. Chavez-Echeagaray, R. Atkinson,
and W. Burleson, “ABE: An Agent-Based Software Architecture
for a Multimodal Emotion Recognition Framework,” WICSA,
2011.
[15] J. Gonzalez-Sanchez, M. E. Chavez-Echeagaray, R. Atkinson,
and W. Burleson, “Affective Computing Meets Design Patterns:
A Pattern-Based Model for a Multimodal Emotion Recognition
Framework,” EUROPLoP, pp. 1–11, 2011.
[16] R. Bernays, J. Mone, P. Yau, M. Murcia, J. Gonzalez-Sanchez,
M. E. Chavez-Echeagaray, R. M. Christopherson, and R.
Atkinson, “Lost in the dark: emotion adaption,” presented at the
UIST Adjunct Proceedings '12: Adjunct proceedings of the 25th
annual ACM symposium on User interface software and
technology, 2012.
[17] L. Bass, P. Clements, and R. Kazman, Software architecture in
practice. Addison-Wesley, 2003.

1384

Using HCI Task Modeling Techniques to Measure How
Deeply Students Model

Sylvie Girard, Lishan Zhang, Yoalli Hidalgo-Pontet, Kurt VanLehn,
Winslow Burleson, Maria Elena Chavez-Echeagary, Javier Gonzalez-Sanchez
Arizona State University, Computing, Informatics, and Decision Systems Engineering, Tempe,
AZ, 85281, U.S.A.

{sylvie.girard, lzhang90, yhidalgo, kurt.vanlehn, winslow.burleson, helenchavez, javiergs}@asu.edu

Abstract: User modeling in AIED has been extended in the past decades to
include affective and motivational aspects of learner’s interaction in intelligent
tutoring systems. An issue in such systems is researchers’ ability to understand
and detect students’ cognitive and meta-cognitive processes while they learn. In
order to study those factors, various detectors have been created that classify
episodes in log data as gaming, high/low effort on task, robust learning, etc.
When simulating students’ learning processes in an ITS, a question remains as
to how to create those detectors, and how reliable their simulation of the user’s
learning processes can be. In this article, we present our method for creating a
detector of shallow modeling practices within a meta-tutor instructional system.
The detector was defined using HCI (human-computer interaction) task modeling as well as a coding scheme defined by human coders from past users’
screen recordings of software use. The detector produced classifications of student behavior that were highly similar to classifications produced by human
coders with a kappa of .925.
Keywords: intelligent tutoring system, shallow learning, robust learning, human-computer interaction, task modeling

1

Introduction

Advances in student modeling in the past two decades enabled the detection of
various cognitive [3, 4, 8, 11, 13, 16, 17], meta-cognitive [1,6], and affective [2, 9]
processes during learning based on classification of episodes in log data. Steps have
been taken toward detecting when learning occurs [4] and to predict how much of the
acquired knowledge students can apply to other situations [5, 6]. However, an obstacle in such research is how to gain an understanding of the user’s cognitive or metacognitive processes while learning. While some of the indicators used in the literature

are common to any intelligent tutoring system, others are closely linked to the activities and pedagogical goals of a specific application. The adaptation of such indicators
to the design of a new system often necessitates a detailed analysis of the new domain
and how the tutoring system guides learners to acquire its skills and knowledge. In
particular, an issue within this process is the ability to reach common ground between
learner scientists that perform an analysis of learners (meta-)cognitive actions at a
high level - via video or log analysis of student’s past actions for example – and the
definition of the indicators by software engineers, related to how the system was implemented, that can be used to simulate such processes in agreement with the constraints and functionalities of software. We view the specificity of detectors as unavoidable, so the best solution is to develop good methods for analyzing the new tutoring system and designing the detectors. This short article describes our method
and its application to out project, AMT. In the AMT project, a choice was made to use
HCI (human computer interaction) task modeling - a method for formally representing human activity, and by extension, the behavior of an interactive system -, as well
as video coding schemes from human coders, to develop the detectors. The detectors
aim to evaluate student’s use of shallow and deep modeling practices with and without being guided by a meta-tutor, on the domain of dynamic systems modeling.
In Section 2, the AMT learning environment, for which the detectors were created,
is introduced. In a third section, the task model of the user’s activity in AMT is described. Next, the process of defining a coding scheme for the detector with human
coders is presented, followed by the definition of the different classifications that
define the value, the implementation and empirical evaluation of the detector. The
final section summarizes the uses of task modeling within this work, and how it could
be applied in future to other applications.

2

AMT software: a meta-tutor to teach deep modeling of
dynamic systems.

AMT software teaches students how to create and test a model of a dynamic system. In our modeling language, a model is a directed graph with one type of link, as
illustrated in Figure 1. Each node represents both a variable and the computation that
determines the variable’s value. There are three types of nodes.
• A fixed value node represents a constant value that is directly specified in the problem. A fixed value node has a diamond shape and never contains incoming links.
• An accumulator node accumulates the values of its inputs. That is, its current
value is the sum of its previous value plus or minus its inputs. An accumulator
node has a rectangular shape and always has at least one incoming link.
• A function node’s value is an algebraic function of its inputs. A function node has
a circular shape and at least one incoming link.

The students’ learning objective is to draw a model representing a situation that is
described in the form of a relatively short text. In the example of Figure 1, the description of the problem was “ Rust destroys steel and can spread quickly. Suppose
you take a large sheet of steel, such as one that might be used as the roof of the boxcar on a train, and you put it outside in the weather. Suppose it starts with a spot of
rust that is 10 square inches in area. However, each week the rust spot gets bigger, as
it grows by 30%. Therefore at the end of the first week, the rust spot is 13 square
inches in area.” and the objective of the problem was to “Graph the size of the rust
spot over 10 weeks.”

Fig. 1. The left image is the example of model, with gray callouts added to explain the
contents of nodes. The right image is the example of a node editor.

The student constructs the model node by node, by filling in all information within
each node in the form of four interactive tabs (description, plan, inputs, and calculations). During construction, students can use the Check button to evaluate the correctness of the current tab, or the Solve it for me button to ask the system to fill out the tab
automatically.
The instruction is divided into three phases: (1) an introduction phase where students learn basic concepts of dynamic system model construction and how to use the
interface; (2) a training phase where students are guided by a tutor and a meta-tutor to
create several models; and (3) a transfer phase where all scaffolding is removed from
soft-ware and students are free to model as they wish. The tutor gives feedback and
corrections on domain mistakes.
The meta-tutor requires students to follow a goal-reduction problem solving strategy, the Target Node Strategy [18]. The basic idea is to focus on one node at a time
(the target node) and completely define it before working on any other node. This
process decomposes the whole problem of modeling a system into a series of atomic
modeling problems, one per node. Like Pyrenees [2], it teaches students that if they
just master this one difficult but small skill, then the rest of the problem solving will
be straight-forward. In addition, the meta-tutor complains if students appear to be
guessing too much or giving up too early, just as the Help Tutor did [3].
While students learn, their motivation, attention to details, and modeling depth can
fluctuate. To assess students, the project needed detectors that detect shallow and
deep modeling practices both with and without the meta-tutor. The measure should be
usable in the transfer phase of the experiment as a dependent variable, because deep

modeling is the skill/knowledge that AMT teaches. The depth measure should also
apply to student’s behavior during the training phase so that we can check whether the
instructional manipulations done during that phase have their intended effects (i.e.,
the measure serves as a manipulation check). The detector should further operate in
real time (i.e., it doesn’t require to know future actions or states in order to interpret
the current action) so that it can be eventually be used by the system itself to condition its behavior.

3

Task Modeling: analysis of user’s actions on software

A task model is a formal representation of the user’s activity. It is represented by a
hierarchical task tree to express all sub-activity that enables the user to perform the
planned activity. The tasks need to be achieved in a specific order, defined in the task
tree by the ordering operators. In AMT, every modeling activity follows the same
procedure involving the same help features, task flow, and meta-tutor interventions.
With a single task model of a prototypical modeling task, it is therefore possible to
account for all of the user’s activity in software. Due to the complexity of the final
model, only one sub-activity will be described in this paper, illustrated in Figure 2.
Only part of the model is deployed in the figure, and some subtasks will not be detailed here. In this part of the model the sub-activity the learner wishes to perform is
to create a new node for the dynamic system s/he is currently modeling. We will first
describe the task tree, and then insert the iterations and conditions that enable a formal
verification of the flow of the task within the task model.
Figure 2: Sub-task “Creating a Node” in the AMT activity task model using K-MADe

Short description of the sub-task to model:
In order for a node to be created, the description tab of the node editor needs to be
completed by selecting a node description, which corresponds to a valid quantity in
the system to model. Each node is unique and cannot be created more than once. The
user can engage in the task only if at least one node still needs to be created for the
model to be complete.
Task tree and order of the tasks:
At the top level of the task tree “Creating a node”, the learner can either attempt to
create the node (task 1) or give up on the creation (task 2). The second task is represented in software by the user closing the node editor window, and can be done at any
time during the task. The task “Creating a node” is over when a good description has
been found and validated. The system can then try to initialize the selection and create
the node.
In the first level of the task “Attempting”, the learner first needs to select a node
description (task 1.1), i.e.: what quantity the node will represent. S/he is then allowed
to finish the creation of the node by validating the selection (task 1.2).
In order to select a node description, the user first needs to choose a node description (task 1.1.1) among the set of node descriptions offered by the system. This process involves the user choosing mentally one description (task 1.1.1.1), exploring the
help features offered by software (task 1.1.1.2) and exploring the set of node descriptions displayed (task 1.1.1.3). S/he can then select the node (task 1.1.2). This subtask
is not described in Figure 1 for a lack of space.
In order to validate the selection, the learner can choose to go back to the description of the problem to verify the correctness of his solution according to the problem
to be simulated (task 1.2.1), and then has to validate the selection (task 1.2.1.2). When
the user checks the validity of the selection, it can either be performed by checking
the solution against the set of nodes still remaining to be modeled (task 1.2.1.2.1) or
asking software to produce the solution (task 1.2.1.2.2). The user is allowed to ask for
the solution only when a description has been checked at least once.
Now that the different actions of the learner are defined, the iterations and conditions will help represent the flow of the activity on the subtask “Selecting a node description” (task 1.1).
Iterative and Optional tasks
• Task 1.1 is iterative: it is possible to make several selections before trying
to finish the description by validating.
• Task 1.1.1.2 is optional: The learner is not forced to explore the help features to choose a description, this is merely a choice on the learner’s part.
• The main task, “creating a node”, is iterative until the node is created or
the activity is abandoned. The later is represented in the task model by an
interruptible task: the learner can stop his/her creation of node activity any
time by choosing to close the node editor window.
Conditions on tasks:
• Main task 1 has a pre-condition attached to it: the software only allows the
user to engage in a creation of a new node if there is at least one node re-

lated to the modeling of the dynamic system that still remains to be created.
A first task model was created to represent learner’s activity on software without
the presence of the meta-tutor. This corresponds to the first version of software, which
was evaluated against the interface including the meta-tutor in [18]. This second software interface includes a text-based agent that intervenes as the students engage in
modeling to help them achieve deeper modeling behaviors, by applying constraints to
the user’s actions and giving meta-cognitive feedback. The meta-tutor was therefore
added to the task model under the type “system” and the model was completed to
include the constraints and interventions of the meta-tutor.
The final task model produced represented all possible actions of the learner on
software in order to model a dynamic system. Next, a study of these actions, which
led to the definition of the depth detectors, is detailed.

4

Detecting when students are modeling using shallow practices

The task model developed with K-MADe was used to define the episode structure.
The first step in creating a coding scheme is to define a unit of measurement for the
user’s modeling actions. The task model clearly highlighted the different subactivities the learner could engage in, referred to as goals. All goals are interruptible
tasks in favor to accessing the help features1 or abandoning the completion of the
current goal for a new one. After a brainstorming session where researchers studied
how students’ actions fell in line with those goals, the following unit of depth, called
“segment”, was defined. This established the unit of coding to be used in the next
phase.
Screen videos representing the learners’ use of the AMT software with and without
the meta-tutor were recorded during an experimental study described in [6]. These
videos were studied to determine how much shallow vs. deep modeling occurred and
the contexts, which tended to produce each type. A coding system was then created
for video recordings of the learners’ behavior. Three iterations of design for this coding scheme were performed, ending with a coding scheme that reached a multi-rater
pairwise kappa of .902. The final coding scheme mapped learners’ behavior to six
classifications, which were implemented as the following depth detectors[AIED short
paper]
• GOOD_METHOD: The students followed a deep method in their modeling. They used the help tools appropriately, including the one for planning
each part of the model.
• VERIFY_INFO: Before checking their step for correctness, students
looked back at the problem description, the information provided by the instruction slides, or the meta-tutor agent.
1

It is to be noted that two help systems are available to users: (1) referring back to the instructions always available for viewing, and (2) looking at the problem situation where all details
of the dynamic system to model are described.

• SINGLE_ANSWER: The student’s initial response for this step was correct, and the student did not change it.
• SEVERAL_ANSWERS: The student made more than one attempt at
completing the step. This includes guessing and gaming the system:
o The user guessed the answer, either by clicking on the correct answer by mistake or luck, or by entering a loop of click and guessing to find
the answer.
o The user “games the system” by using the immediate feedback
given to guess the answer: series of checks on wrong answers that help deduce the right answer.
• UNDO_GOOD_WORK: This action suggests a modeling misconception
on the students’ part. One example is when students try to run the model
when not all of the nodes are fully defined.
• GIVEUP: The student gave up on finding how to do a step and clicked on
the “give up” button.
Another detector was defined as a linear function of the six episode detectors. It
was intended to measure the overall depth of the students’ modeling, therefore providing an outcome measure in the transfer phase in future experimental studies. It considered two measures (GOOD_ANSWER, VERIFY_INFO) to indicate deep modeling, one measure (SINGLE_ANSWER) to be neutral, and three measures
(SEVERAL_ANSWERS, UNDO_GOOD_WORK, and GIVE_UP) to indicate shallow modeling.
Once the coding scheme reached a sufficient level of agreement between coders,
the task model was used to adapt the coding to students’ actions on the software. The
episodes that were coded for depth by human analysts in the sample video were analyzed by creating scenarios from the task model within K-MADe. The validation of
six detectors’ implementation involved three human coders, who watched a sample of
50 episodes, paying attention to the depth of modeling exhibited by the student’s actions, and chose the classification that best represented the depth of the learner modeling at the time of the detected value. A multi-rater and pairwise kappa was then performed, reaching a level of inter-reliance of .925.

5

The different uses of the Task Model

The task modeling language K-MAD and its task model creation and simulation
environment, K-MADe [7] were chosen for the following reasons: the environment
enables the creation and replay of scenarios of student’s actions, a set of functionalities not described here enable a formal verification of the model. Additionally the
associated simulation environment ProtoTask [14] allows non-specialists in task modeling to visualize the flow of the task model, via scenarios in a clear and simple manner.
The use of K-MAD helped in the creation of the detectors and are a first step in offering an alternative technique to simulated learners, by tackling the following problems:

•

Breaching the gap between learner scientists’ understanding of how the
learning process works and programmers’ definition of the application
flow, functionalities, and indicators.
• Enabling a formal validation of software flow, understandable by all.
• Using simulated learners scenarios to define the detectors.
A researcher in educational technology - expert in teaching modeling and part of the
AMT project - and an HCI practitioner, realized the task model. The former was an
expert on how AMT software was designed in terms of pedagogical content and task
flow. His expertise focused in particular on the actions the students were allowed/incited/forbidden to do within software at each moment of the modeling task.
The HCI practitioner was not familiar with intelligent tutoring systems or meta-tutors.
She was involved in the creation of the task model in a consulting capacity, in regards
to her expertise in task modeling of interactive systems.
The task model could be defined at the level of the user’s planning of actions and
system flow, with iterations and conditions alone. However, the objects in K-MADe
enable us to represent the constraints of the learner’s actions concretely and to apply a
formal verification of task flow. It was therefore possible to represent the set of descriptions as either valid or invalid, to detect when a node has been checked and the
result of that check, and to add constraints on the checking procedure such as to avoid
node duplication. This enabled a formal verification of software flow prior to validate
its fidelity to learner scientists’ ideas about possible actions on software and the underlying processes involved.
Once the model was constructed, the use of ProtoTask to visualize software flow
and follow learners’ possible sets of actions allowed by software enabled the ability to
simulate learners by creating scenarios of use that could be played and replayed at
will, focusing on the cognitive and meta-cognitive levels of learner’s experience on
software. In the process of creating our detectors, a video analysis of learner’s past
actions was performed. The model could be used to check the possible actions of
users with what the designer of the system wanted to offer as functionalities and software flow. During this analysis, the task model could be used once again to define
scenarios that simulated learner’s pertinent behaviors using ProtoTask. Once those
scenarios were formed, the task analyst came back to the original K-MAD modeling
language and studied the similarities and contrasts between scenarios to define the
rules that govern the detection of shallow and deep modeling practices within AMT.
Once the task model identified points of detection of such practices, it became easy
for programmers to go back to software and implement the rules.

6

Conclusion and Future Work

In this paper, a method to create a detector of deep modeling within a meta-tutor
using HCI task modeling and video coding schemes was described. The main outcome of this process was the creation of detectors inferring the depth of students’
modeling practices while they learn on a meta-tutoring system, reaching a multi-rater
and pairwise kappa score of .925. We believe the use of the task model to define shal-

low and deep modeling practices by helping to create the detectors to be of value for
any simulated learning environments, in particular for indicators that a common to all
learning tasks present in a tutoring system.
In interdisciplinary teams, the design of indicators can lead to communication issues due to misunderstandings and a lack of common ground between analysis made
at a high level of learners’ cognitive and meta-cognitive processes, and the representation of those behaviors within software. In particular, video-coding processes can
become costly when the coders’ understanding of the details of how the system works
differs from how the system actually works. Our experience using K-MADe and ProtoTask highlighted an ease in this project in gaining a better view of the tutoring system and the detection of deep modeling within the interface. In particular, the use of
ProtoTask by the non-specialists in task modeling helped clarify issues of task flow
and the definition of the set of user’s actions at each moment of interaction.
A limitation of the method is the applicability to different types of tutoring systems. In AMT, a single task model was able to represent the entirety of a users’ learning activity. In tutoring systems that teach a set of skills through different pedagogical
approaches for diverse types of learning tasks, the creation of such task models might
prove more costly and may not be completely adapted to the creation of detectors that
need to be adapted to each task specifically.

Acknowledgements
This material is based upon work supported by the National Science Foundation
under Grant No. 0910221. We would like to thank Sybille Caffiau for consulting in
the project and sharing her expertise in task modeling of interactive systems.

References
1. Aleven, V., McLaren, B.M., Roll, I., Koedinger, K.R.(2006): Toward meta-cognitive tutoring: A model of help seeking with a Cognitive Tutor. International Journal of Artificial Intelligence and Education 16, 101–128
2. Arroyo, I., and Woolf, B.P., 2005. Inferring learning and attitudes from a Bayesian Network of log file data. In Proceedings of the 2005 conference on Artificial Intelligence in
Education: Supporting Learning through Intelligent and Socially Informed Technology,
Chee-Kit Looi, Gord McCalla, Bert Bredeweg, and Joost Breuker (Eds.). IOS Press, Amsterdam, The Netherlands, The Netherlands, 33-40.
3. Baker, R. S. J. d., Corbett, A. T., Koedinger, K. R., Evenson, S., Roll, I., Wagner, A. Z., …
Beck, J. E. (2006). Adapting to when students game an intelligent tutoring system, Proceedings of the 8th international conference on Intelligent Tutoring Systems, Jhongli, Taiwan Berlin, Heidelberg.
4. Baker, R.S.J.d., Goldstein, A.B., Heffernan, N.T.: Detecting the Moment of Learning. In:
Aleven, V., Kay, J., Mostow, J. (eds.) ITS 2010. LNCS, vol. 6094, pp. 25–34. Springer,
Heidelberg (2010)
5. Baker, R. S. J. D., Gowda, S. M., & Corbett, A. T. (2011). Towards predicting future
transfer of learning, Proceedings of the 15th international conference on Artificial intelli-

6.

7.

8.

9.

10.

11.

12.

13.
14.

15.

16.

17.

18.

gence in education. Proceedings from AIED’11, Auckland, New Zealand Berlin, Heidelberg.
Baker, R. S. J. D., Gowda, S. M., Corbett, A. T., & Ocumpaugh, J. (2012). Towards automatically detecting whether student learning is shallow., Proceedings of the 11th international conference on Intelligent Tutoring Systems, Chania, Crete, Greece Berlin, Heidelberg.
Caffiau, S., Scapin, D., Girard, P., Baron, M., & Jambon, F. (2010). Increasing the expressive power of task analysis: Systematic comparison and empirical assessment of toolsupported
task
models.
Interacting
with
Computers,
22(6),
569–593.
doi:10.1016/j.intcom.2010.06.003
Corbett, A.T., MacLaren, B., Kauffman, L., Wagner, A., Jones, E.A.: Cognitive Tutor for
Genetics Problem Solving: Learning Gains and Student Modeling. Journal of Educational
Computing Research 42(2), 219–239 (2010)
D’Mello, S. K., Lehman, B., & Person, N. (2010). Monitoring affect states during effortful
problem solving activities. International Journal of Artificial Intelligence in Education,
20(4), 361–389., doi:10.3233/JAI-2010-012
Girard, S., Chavez-Echeagary, H., Gonzalez-Sanchez, J., Hildalgo-Pontet, Y., Zhang, L.,
Burleson, W., and VanLehn, K., (2013), Defining the behavior of an affective learning
companion in the affective meta-tutor project, in K. Yacef et al. (Eds.): Proceedings of the
16th international conference on Artificial Intelligence in EDucation (AIED’13), LNAI
7926, pp. 21--30. Springer-Verlag, Berlin, Heidelberg.
Gowda, S.M., Pardos, Z.A., and Baker, R. S. J. D. 2012. Content learning analysis using
the moment-by-moment learning detector. In Proceedings of the 11th international conference on Intelligent Tutoring Systems (ITS'12), Stefano A. Cerri, William J. Clancey, Giorgos Papadourakis, and Kitty Panourgia (Eds.). Springer-Verlag, Berlin, Heidelberg, 434443. DOI=10.1007/978-3-642-30950-2_56
Koedinger, K.R., Corbett, A.T., Perfetti, C. (2010): The Knowledge-Learning-Instruction
(KLI) Framework: Toward Bridging the Science-Practice Chasm to Enhance Robust Student Learning. Carnegie Mellon University Technical Report, June, 2010
Martin, J., VanLehn, K.: Student assessment using Bayesian nets. International Journal of
Human-Computer Studies 42, 575–591 (1995)
Lachaume, T., Girard, P., Guittet, L., & Fousse, A. (2012). ProtoTask, new task model
simulator. In M. Winckler, P. Forbrig, & R. Bernhaupt (Eds.), Human-Centered Software
Engineering (Vol. 7623, pp. 323– 330). Berlin, Heidelberg: Springer Berlin Heidelberg.
doi:10.1007/978-3-642-34347-6
Muldner, K., Burleson, W., Van, D. S., Brett, & Vanlehn, K. (2011). An analysis of students’ gaming behaviors in an intelligent tutoring system: predictors and impacts. User
Modeling and User-Adapted Interaction, April 2011, 21(1-2), 99–135m
doi:10.1007/s11257-010-9086-0
Shih, B., Koedinger, K.R., Scheines, R.: A response time model for bottom-out hints as
worked examples. In: Proceedings of the 1st International Conference on Educational Data
Mining, pp. 117–126 (2008)
Walonoski, J. A., & Heffernan, N. T. (2006). Prevention of off-task gaming behavior in intelligent tutoring systems Proceedings of the 8th international conference on Intelligent
Tutoring Systems. Jhongli, Taiwan Berlin, Heidelberg.
Zhang, L., Burleson, W., Chavez-Echeagary, H., Girard, S., Gonzalez-Sanchez, J., Hildalgo-Pontet, Y., and VanLehn, K., (2013), Evaluation of a meta-tutor for constructing
models of dynamic systems, in K. Yacef et al. (Eds.): AIED’13, LNAI 7926, pp. 666--669.
Springer-Verlag, Berlin, Heidelberg.

Computers & Education 75 (2014) 196–217

Contents lists available at ScienceDirect

Computers & Education
journal homepage: www.elsevier.com/locate/compedu

Evaluation of a meta-tutor for constructing models of
dynamic systems
Lishan Zhang*, Kurt VanLehn, Sylvie Girard, Winslow Burleson,
Maria Elena Chavez-Echeagaray, Javier Gonzalez-Sanchez, Yoalli Hidalgo-Pontet
Arizona State University, Computing, Informatics, and Decision Systems Engineering, Tempe, AZ 85281, USA

a r t i c l e i n f o

a b s t r a c t

Article history:
Received 5 September 2013
Received in revised form
17 February 2014
Accepted 25 February 2014
Available online 13 March 2014

Modelling is an important skill to acquire, but it is not an easy one for students to learn. Existing
instructional technology has had limited success in teaching modelling. We have applied a recently
developed technology, meta-tutoring, to address the important problem of teaching model construction.
More speciﬁcally, we have developed and evaluated a system that has two parts, a tutor and a meta-tutor.
The tutor is a simple step-based tutoring system that can give correct/incorrect feedback on student’s
steps and can demonstrate steps for students when asked. Because deep modelling requires difﬁcult
analyses of the quantitative relationships in a given system, we expected, and found, that students
tended to avoid deep modelling by abusing the tutor’s help. In order to increase the frequency of deep
modelling, we added a meta-tutor that coached students to follow a learning strategy that decomposed
the overall modelling problem into a series of “atomic” modelling problems. We conducted three experiments to test the effectiveness of the meta-tutor. The results indicate that students who studied with
meta-tutor did indeed engage in more deep modelling practices. However, when the meta-tutor and
tutor were turned off, students tended to revert to shallow modelling. Thus, the next stage of the
research is to add an affective agent that will try to persuade students to persist in using the taught
strategies even when the meta-tutoring and tutoring have ceased.
Ó 2014 Elsevier Ltd. All rights reserved.

Keywords:
Meta-tutor
Gaming the system
Intelligent tutoring systems
Modelling
Learning strategies

1. Introduction
This paper reports progress on two research problems: (1) teaching students how to construct mathematical models of dynamic systems,
and (2) teaching students to use effective learning strategies. Both research problems have long histories, which are covered in the next few
sections.
1.1. A brief history of educational uses of system dynamics modelling
There are two distinct reasons why students should learn model construction. First, modelling is an important cognitive skill in itself. The
Common Core State Standards for Mathematics (CCSSO, 2011) considers modelling to be one of 7 essential mathematical practices that
should be taught at all grade levels. The Next Gen standards for science instruction (National, 2012) also have 7 strands that are threaded
throughout the standards, and modelling is one of them.
Second, modelling is widely believed to be an important method for learning domain knowledge. For instance, modelling has been
claimed to help in achieving a deep understanding of scientiﬁc systems, economic systems and other systems (Chin et al., 2010; Metcalf,
Krajcik, & Soloway, 2000; Stratford, 1997), removing misconceptions and making of conceptual changes (Booth Sweeney & Sterman,
2000; Bredeweg & Forbus, 2003; Hestenes, 2007; Lee, Jonassen, & Teo, 2011; Mandinach & Cline, 1994b; Wilensky, 2003; Wilensky &
* Corresponding author.
E-mail addresses: lishan.zhang@asu.edu (L. Zhang), kurt.vanlehn@asu.edu (K. VanLehn), sylvie.girard@asu.edu (S. Girard), winslow.burleson@asu.edu (W. Burleson),
mchaveze@asu.edu (M.E. Chavez-Echeagaray), javiergs@asu.edu (J. Gonzalez-Sanchez), yhidalgo@asu.edu (Y. Hidalgo-Pontet).
http://dx.doi.org/10.1016/j.compedu.2014.02.015
0360-1315/Ó 2014 Elsevier Ltd. All rights reserved.

L. Zhang et al. / Computers & Education 75 (2014) 196–217

197

Reisman, 2006), understanding the epistemology of models in science (Treagust, Chittleborough, & Mamiala, 2002), and developing intuitions, predilections and skills at understanding complex phenomena in general (Hogan & Thomas, 2001; Mandinach & Cline, 1994a;
Schecker, 1993; Steed, 1992).
In short, modelling is both an important cognitive skill and a potentially powerful means of learning many topics. That is, it is both an end
goal and a means to other end goals.
The modelling activity addressed here is traditionally called system dynamics modelling (see Collins and Ferguson (1993) for a particularly comprehensive taxonomy of modelling). The model is comprised of real-valued variables that are constrained by temporal differential
equations. The variables denote quantities in the system whose values change over time. The job of the model is to predict those changing
values as accurately as parsimony allows.
There is a long history of using system dynamics model construction as in instructional activity. According to the oral history of the
System Dynamics Society (http://www.systemdynamics.org/oral-history/), system dynamics began to be used for university instruction
around 1957 with Jay Forrester’s formulation of system dynamics for teaching management. When a graphical language, Stella, became
available (Richmond, 1985), instructional usage dramatically increased and extended to high school. Many early Stella projects trained
teachers in modelling and let them invent activities (Mandinach & Cline, 1994a; Zaraza & Fisher, 1997).
After years of experience by hundreds of teachers, observers began to report that getting students to actually construct models took so
much class time that most teachers used Stella only for model exploration activities, wherein students were given a model and were asked
to observe how graphs of the variables values changed as the students manipulated parameters of the model (Alessi, 2000; Doerr, 1996;
Mandinach & Cline, 1994b; Stratford, 1997).
Laboratory studies conﬁrmed the observers’ reports about both the length of time required for model construction and the importance of
model construction. For example, Hashem and Mioduser (2011) found that students who constructed NetLogo models learned more about
emergence, self-organization and other complex system concepts than students who explored NetLogo models that were given to them. The
comparison took place during two 90-min lessons on complex systems, which were ﬂanked by a pre-test and a post-test. However, prior to
the pre-test, it took only 2 h to train the model exploration group whereas it took 48 h to train the model construction group. In a review of
the modelling literature, VanLehn (2013) found that the only experiments that produced reliable positive results for model construction also
devoted at least 5 h to training the students before the main lessons.
This history motivates the speciﬁc research problem addressed here: How can we speed up students’ acquisition of skill in constructing
system dynamics models?
Many methods for accelerating the acquisition of skill in model construction have been implemented, but only a few have been
compared to baseline versions of the model construction activity in order to test their effectiveness (see VanLehn, 2013, for a review). Of
those that have been evaluated, one form of scaffolding has shown considerable promise: The use of feedback and hints on student’s
steps in constructing the model. A whole model is usually composed of many parts (e.g., nodes, links, equations, labels, icons, numbers,
etc.) which the student enters one at a time. Entering such a part is called a “step”. Systems that give feedback and hints on steps are
called step-based tutoring systems (VanLehn, 2006). Step-based tutoring systems have been used for a wide variety of tasks besides
model construction, and appear to be almost as effective as human tutors (VanLehn et al., 2011). Thus, this project decided early on to
build a step-based tutoring system for system dynamics modelling in the hope that it would accelerate students’ acquisition of
modelling skill.
1.2. Learning strategies research
A learning strategy is a process, procedure or method that meets two criteria (Donker, de Boer, Kostons, Dignath van Ewijk, & van der
Werf, 2014): (1) Students can use the strategy when studying, but it is not required by the material that they are studying. (2) Using the
learning strategy is believed to affect the student’s learning. A good learning strategy is thought to improve students’ learning, while a poor
learning strategy is thought to harm the students’ learning. When used without modiﬁcation, “learning strategy” generally means a good
learning strategy. Some examples are:
 When memorizing facts, a good learning strategy is to construct a mental image and associate each fact with a part of the image.
 When studying an example, a good learning strategy (called self-explanation) is to explain each step in the example to yourself, asking
“Why is this true? Why did the author include this step?”
 When reading a text, a good learning strategy is to reﬂect afterwards on what you have learned.
 When reading a text, a poor learning strategy is to ignore words or passages that you don’t understand.
Learning strategies have been studied for decades, and comprehensive meta-analytic reviews exist (Donker et al., 2014; Hattie, Biggs, &
Purdie, 1996). Some of the main ﬁndings are:
A. Students often exhibit poor learning strategies.
B. Good learning strategies can be taught, often with little difﬁculty.
C. When students use the taught learning strategies, their domain learning often increases compared to students who are not taught to use
the learning strategies.
D. When instruction in the learning strategy includes meta-cognitive and motivational components, students can often be prevented from
reverting to poor learning strategies when the instruction ceases.
E. Speciﬁc learning strategies often have larger effect sizes than general purpose ones.
These ﬁndings mean that research on learning strategies is intimately linked to advances in instruction. Whenever a new instructional
method or subject matter is developed, there are likely to be poor learning strategies that are speciﬁc to it (ﬁnding A) as well as speciﬁc
good learning strategies that are likely to be effective (ﬁnding E) and easily taught (B). The key question is whether they are effective for

198

L. Zhang et al. / Computers & Education 75 (2014) 196–217

domain learning (C) and students can be persuaded to continue using them after being taught (D). We have developed a step-based
tutoring system for teaching students how to construct models, so it is likely that for this new form of instruction, students tend to
exhibit poor learning strategies, but that good strategies can be easily taught; the main questions are whether the good strategies really
are effective at increasing domain learning and whether students can be taught to persist in using them. These are the main research
questions addressed here.
The next introductory section focuses on reviewing projects that are similar to the one described here. However, their relationship to
learning strategies can be a bit hard to see, so a few prefatory remarks may be helpful.
Because this paper is concerned with teaching students how to construct models, and constructing a model is a kind of problem solving,
it is worth clarifying how learning strategies differ from problem solving strategies. When students are taught an effective strategy for
solving problems, the strategy qualiﬁes as either a learning strategy, a problem solving strategy or both depending on the instructional
objectives.
 If the objective is for students to solve problems well, then a strategy for solving problems counts as domain knowledge and is called a
problem solving strategy. In the jargon of students, it’s on the test.
 On the other hand, when problem solving is done only to give student practice in applying certain concepts and principles and the
problem solving itself is not an instructional objective, then the strategy counts as a learning strategy because it is optional and yet it
probably impacts the students’ learning of the concepts and principles. In the jargon of students, it is not on the test.
 As pointed out earlier, the process of constructing models is both an instructional objective (especially in math classes) and a means for
acquiring domain knowledge (especially in science classes). Thus, an effective strategy for constructing models counts as both a problem
solving strategy in some cases (it’s on the test) and a learning strategy in other cases (it’s not on the test).
For example, suppose the instructional objective is to learn which botanical features go with which plants, and the instruction involves
arranging cards labelled with plants and features. If this matching activity does not appear on the exams, then teaching students a
methodical method for arranging the cards counts as a learning strategy even though it is also a problem solving strategy. From the students’
point of view, what matters is whether the strategy is “on the test.” That is, if a problem solving strategy is an instructional objective and is
part of a test or other assessment, then students have a different attitude towards it than a strategy that is merely helpful for learning the
material that will be on the test. As we discuss various methods for teaching model construction, it is important to note whether students
believe a taught strategy is required or merely helpful.
Interactive instructional systems, such as the tutoring system described herein, have their own unique learning strategies. Here are some
examples:
1. Teachers often complain that their students would rather click than think. Actuating buttons, menus, etc. without thinking or even
reading the rest of the screen is a poor learning strategy.
2. When a tutoring system gives immediate feedback on the correctness of a student’s entry, then students often guess instead of think.
That is, they rapidly revise and resubmit an incorrect entry until the tutoring system says that it is correct.
3. If the tutoring system gives a sequence of hints that get gradually mores speciﬁc until they tell the student exactly what to do,
then students abuse the hint sequences by clicking rapidly on the Hint button until they get the ﬁnal hint that tells them what
to do.
4. A good learning strategy for tutoring systems is to ask for a hint only when you need one (Aleven, McLaren, Roll, & Koedinger, 2004).
5. After asking for hints from a tutoring system and ﬁnally making a correct entry, a good learning strategy is to reﬂect on why it is correct
(self-explanation) and whether the hint makes sense (Shih, Koedinger, & Scheines, 2008).
6. Examples 2, 3 and 4 are help-seeking strategies (Aleven, Stahl, Schworm, Fischer, & Wallace, 2003). Examples 2 and 3 are often referred
to as “gaming the system” (Baker, Corbett, Koedinger, & Wagner, 2004).
Feedback and hints are the signature methods of tutoring, but several projects have used feedback and hints for two distinct purposes, so
let us distinguish them as follows:
 Let domain knowledge refer to what students are supposed to learn. It is typically measured with a post-test and sometimes a pre-test.
 When the hints address the domain and the feedback indicates whether the domain knowledge has been correctly applied, the system
is said to be tutoring and the module responsible for it is called the tutor.
 A learning strategy is an optional method for using the system (i.e., it is not domain knowledge) that is believed to increase student’s
learning of domain knowledge.
 When the feedback and hints refer only to the learning strategy and whether it is being applied correctly, the system is said to be metatutoring and the module responsible for it is called the meta-tutor.
In this paper, meta-tutoring will only means a method for teaching students a learning strategy. However, in the tutoring literature,
“meta-tutoring” is used more broadly to mean using feedback and hints to teach anything other than domain knowledge. For instance,
meta-tutoring is sometimes used to increase motivation or change beliefs about self-efﬁcacy. Du Boulay, Avramides, Luckin, MartinezMiron, and Rebolledo-Mendez (2010) propose a framework that includes many types of meta-tutoring.
Now we can turn to reviewing prior work on using learning strategies to help students learn how to construct models.
1.3. Prior work on learning strategies for model construction
Betty’s Brain (Leelawong & Biswas, 2008) was a step-based tutoring system for constructing models that also taught a learning strategy. It
could give feedback and hints on the student’s model (tutoring) or it could give feedback and hints on the way that the student was using the

L. Zhang et al. / Computers & Education 75 (2014) 196–217

199

system to create the model (meta-tutoring).1 For instance, sometimes it would not permit the student to evaluate the model with an
instructor-provide test suite (called a “quiz”) until the student had ﬁrst examined speciﬁc predictions of their model (e.g., if air temperature
goes down, what does body temperature do?). The system included some multimedia resources on the task domain, so another part of the
learning strategy was encouraging students to read them. As these examples indicate, the learning strategy was speciﬁc to the particular
instructional features provided by system. This is consistent with the ﬁndings in the learning strategies literature, which suggest that such
speciﬁcity provides better results than general learning strategies.
Three evaluations of the effectiveness of Betty’s meta-tutor were conducted (Biswas, Leelawong, Schwartz, & Vye, 2005, study 2;
Leelawong & Biswas, 2008; Tan, Biswas, & Schwartz, 2006). Their methods will be described fully here, as the experiments to be reported
later used similar methods. The Betty’s Brain experiments all had two phases, called the training phase and the transfer phase here. During
the training phase, ﬁfth-grade students worked with Betty for approximately seven 45-min sessions on constructing a model of a river
system. One group of students used Betty’s Brain with the meta-tutor turned on, and another group used the same system with the metatutor turned off. Two months later the transfer phase occurred, where all the students used Betty’s Brain with the meta-tutor turned off to
create models for the nitrogen cycle. This transfer phase was used to assess their modelling skill.
The results were roughly the same in all three studies. Using the general results on learning strategy mentioned above as a framework,
the results from the Betty’s Brain studies were:
A. Students often exhibit poor learning strategies. True of the control conditions in all three studies.
B. Good learning strategies can be taught, often with little difﬁculty. In the training phase of all three studies, meta-tutored students’
behaviour was consistent with the learning strategies.
C. When students use the taught learning strategies, their domain learning increases compared to students who are not taught to use the
learning strategies. Unfortunately, using conventional science tests of ecology concepts, there were few signiﬁcant differences between
the meta-tutored students and the students who used Betty’s Brain without meta-tutoring.2 Using four measures of model quality,
meta-tutored students’ models were better than control students’ models on only one measure.
D. When instruction in the learning strategy includes meta-cognitive and motivational components, students can often be prevented from
reverting to poor learning strategies when the instruction ceases. Students who received meta-tutoring during the training phase tended to
continue using the learning strategy in the transfer phase when the meta-tutoring was turned off.
E. Speciﬁc learning strategies often have larger effect sizes than general purpose ones. Not tested.
In short, although the meta-tutor in Betty’s Brain was successful at teaching the learning strategy and persuading students to continue
using it, the learning strategy had little impact on domain learning. More recent work has focused on ﬁnding out what behaviours
distinguish good learners from poor learners (Segedy, Kinnebrew, & Biswas, 2012a, 2012b).
The Help Tutor (Aleven et al., 2004; Roll, Aleven, McLaren, & Koedinger, 2007a, 2007b; Roll, Aleven, McLaren, & Koedinger,
2011; Roll et al., 2006) was a meta-tutor that augmented an existing step-based tutoring system, the Cognitive Geometry Tutor
(www.carnegielearning.com). Although the tutoring system did not teach students to construct models, it is included in this review of
past work because it is an often-cited representative of using meta-tutoring to improve students’ learning from step-based tutoring.
The Geometry Cognitive Tutor allowed students to ask for a hint. The ﬁrst hint was rather general, but if the student kept asking for hints,
then the last hint told the student exactly what to do. This was called the “bottom-out” hint. Students sometimes clicked rapidly on the Help
button so that they could get to the bottom-out hint. As mentioned earlier, this abuse of the help system is a kind of “gaming the system”
(Baker, Corbett, Koedinger, et al., 2004). In order to reduce the frequency of gaming the system, the Help Tutor gave students feedback and
hints on their use of the help system.
Two studies evaluated the Help Tutor. As in the Betty’s Brain studies, the Help Tutor studies had both a training phase where the metatutor was used by half the students and a transfer phase where none of the students used the meta-tutor. Using the general ﬁndings
mentioned above as a framework, the results were:
A. Students often exhibit poor learning strategies. True of the control conditions in all both studies.
B. Good learning strategies can be taught, often with little difﬁculty. In the training phase of both studies, meta-tutored students’ behaviour
was consistent with the taught strategies.
C. When students use the taught learning strategies, their domain learning increases compared to students who are not taught to use the
learning strategies. Unfortunately, students taught the learning strategy did not differ from the control group in their acquisition of
geometry knowledge.
D. When instruction in the learning strategy includes meta-cognitive and motivational components, students can often be prevented from
reverting to poor learning strategies when the instruction ceases. Students who received meta-tutoring during the training phase tended to
continue using the learning strategy in the transfer phase when the meta-tutoring was turned off, albeit with less frequency.
E. Speciﬁc learning strategies often have larger effect sizes than general purpose ones. Not tested.
Betty’s Brain and the Help Tutor provided most of their instruction via feedback and hints. A somewhat more didactic approach is to
provide forms and phases that constrain students’ modelling behaviour. For instance, the ﬁnal version of Model-It (Metcalf et al., 2000) had

1
Those familiar with Betty’s Brain might be surprised to see it described as a tutoring system because the students see the system as two agents: Betty (a teachable agent)
and Mr. Davis (a mentor). Students were told that the model they were constructing comprised the knowledge of Betty, so editing the model comprised “teaching Betty.”
When they ask Betty take a quiz, Mr. Davis gives the student feedback on the correctness of the model’s predictions which would sometimes include unsolicited hints about
ﬁsh, algae, carbon dioxide and other domain entities. Mr. Davis personiﬁes the system’s tutoring. On the other hand, meta-tutoring was done by both agents. For instance,
Betty would sometimes refuse to take a quiz, and Mr. Davis would discourage students from using trial-and-error methods.
2
In a fourth study, the meta-tutored students produced slightly better river system models than the control students (Tan, Wagster, Wu, & Biswas, 2007; Wagster, Tan,
Biswas, & Schwartz, 2007; Wagster, Tan, Wu, Biswas, & Schwartz, 2007). However, results on the other measures were not reported.

200

L. Zhang et al. / Computers & Education 75 (2014) 196–217

4 phases, which were selected by clicking on one of four buttons labelled Plan, Build, Test and Evaluate. The Build mode was the actual model
editor. The other phases presented forms to be ﬁlled in by the student. Fig. 1 shows the form for the Test phase. Students were given feedback
and hints, which they could suppress if they desired, when they attempted to bypass a suggested activity. The Carnegie Learning’s Algebra
Cognitive Tutor (www.carnegielearning.com) and the Word Problem Solving Tutor (Wheeler & Regian, 1999) also scaffolded problem
solving strategies via lightweight constraints, implemented with phases and forms. None of these meta-tutors were evaluated separately
from the rest of the system.
On the other hand, Mulder, Lazonder, de Jong, Anjewierden, and Bollen (2011) did assess the effects of a phase-based learning strategy.
The experiments used Co-Lab, a system that taught system dynamics modelling. Co-Lab was not a step-based tutoring. Instead, students
received feedback only on the accuracy of the model’s predictions. The learning strategy was to encourage students to do their model
construction in three stages. In Stage 1, they deﬁned variables and drew undirected links between variables that directly affected each other
somehow. In Stage 2, they added qualitative labels to the links indicating whether an increase in one variable caused an increase or decrease
in the other variable. In Stage 3, they added equations to the model that further speciﬁed the relationships between variables. Three versions
of the learning strategy were compared to a control version of Co-Lab that lacked phases. The three versions differed in how strictly they
enforced the learning strategy. The restricted strategy required students to achieve a certain level of success in one stage before moving to
the next. The semi-restricted version of the strategy allowed students to move from one stage to the next at will, but they were not allowed
to move backwards. The unrestricted version allowed students to move at will between stages. Compared to the control version, all three
versions of the learning strategy increased the number of correct model elements generated by students as they used the system. The three
versions were not signiﬁcantly different in productivity from each other, but there was a trend for the semi-restricted version to be better
than the other two. However, this experiment included only a training phase and not a transfer phase, and it did not assess students’ domain
knowledge with pre- and post-testing. Thus, its consistency with the 5 general ﬁndings mentioned above (A through F) cannot be determined. Nonetheless, this work is interesting because the learning strategy was taught without using a meta-tutor, and the system was not a
step-based tutoring system.
The meta-tutoring of Betty’s Brain and the Help Tutor placed only weak constraints on students’ behaviour. The phases and forms of CoLab, Model-It, the Cognitive Tutors and the Algebra Word Problem tutor placed somewhat stronger constraints on students’ behaviour. At
the far end of this progression is procedural scaffolding, which places very strong constraints on student behaviour. The basic idea of procedural scaffolding is to require students to temporarily follow a speciﬁc procedure for constructing a model. Although the procedure is not
required by the task and there are many other ways to successfully construct models, the procedure is used as a temporary scaffolding to
guide students who might otherwise be quite lost.

Fig. 1. Scaffolding for the Test mode of Model-It (Metcalf, 1999).

L. Zhang et al. / Computers & Education 75 (2014) 196–217

201

Although procedural scaffolding was ﬁrst used by (Marshall, Barthuli, Brewer, & Rose, 1989) to scaffold arithmetic story problem solving,
its beneﬁts were not evaluated. Procedural scaffolding was ﬁrst evaluated with Pyrenees (Chi & VanLehn, 2010; Vanlehn & Chi, 2012), which
required students to construct models using a version of goal reduction, which is a well-known general purpose reasoning strategy used in
artiﬁcial intelligence applications (Russell & Norvig, 2009).
Pyrenees’ procedural scaffolding was evaluated in a two-phase experiment. In the training phase, students learned to construct model of
probabilistic systems. In the transfer phase, student learned to construct models of mechanical energy systems. Using the framework
mentioned earlier, the ﬁndings were:
A. Students often exhibit poor learning strategies. True of the control conditions in both phases.
B. Good learning strategies can be taught, often with little difﬁculty. This could not be determined, because Pyrenees required students in the
experimental condition to follow the learning strategy during the training phase.
C. When students use the taught learning strategies, their domain learning increases compared to students who are not taught to use the
learning strategies. In both the training phase and the transfer phase, the experimental group acquired more domain knowledge than
control group. The effect sizes were large (d z 1.0).
D. When instruction in the learning strategy includes meta-cognitive and motivational components, students can often be prevented from
reverting to poor learning strategies when the instruction ceases. The experimental group tended to use the learning strategy during the
transfer phase on difﬁcult problems, but not on simple problems. However, even on simple problems, they did not use poor learning
strategies.
E. Speciﬁc learning strategies often have larger effect sizes than general purpose ones. Not tested.
In summary, Betty’s Brain and the Help Tutor used the standard methods of hints and feedback and their meta-tutoring succeeded in
improving students’ behaviour, but there were only weak improvements at best in their learning of the domain. Co-Lab’s learning strategy
increased performance, but the effect on learning was not measured. Pyrenees used procedural scaffolding, and its meta-tutoring caused
large improvements in both behaviour and domain learning.
1.4. Our research questions
Our research questions are the same 4 questions that our predecessors have focused one:
A. Without instruction in good learning strategies, do students often exhibit poor learning strategies?
B. Can good learning strategies be easily taught?
C. When students use the taught learning strategies, does their domain learning increase compared to students who are not taught to use
the learning strategies?
D. When instruction in the learning strategy ceases, do students revert to poor learning strategies?
Although these 4 questions about learning strategies are the central focus of the research, we are also interested in seeing if the time
required to achieve adequate competence in model construction can be reduced from 5 or more hours to 2 for fewer hours.
Because Pyrenees was arguably more successful than the other methods, we chose to use procedural scaffolding as the basic method of
teaching learning strategies. However, there is a major difference between our research problem and the one addressed by Pyrenees.
Pyrenees assumed that students had already been taught all the relevant domain principles. Indeed, the students repeatedly selected
principles from a menu. In contrast, when students construct system dynamics models, they are seldom taught domain principles in
advance. They are instead asked to infer domain relationships from multimedia resources, common sense and/or experimentation. They do
this while constructing the model. This allows modelling to be used as part of enquiry-based instruction where students construct the
domain knowledge themselves. Having to infer domain relationships while learning to model may be one of the reasons why it takes
students so long to master system dynamics model construction. Nonetheless, inferring quantities and their relationships is exactly the skill
we want students to learn.
This suggests that if we require students to follow a procedure, as Pyrenees did, then they will learn that the key to modelling is a
single non-mechanical step: ﬁguring out the mathematical relationship among a set of directly related quantities. Once they have
mastered that step, we expect that they will be able to construct models well, even if they don’t follow the procedure. Thus, our research
question is whether applying the Pyrenees approach of heavy-handed procedural scaffolding to the cognitive skill of model construction
will cause deeper, more effective modelling skills to develop during the training phase. If the tutor does work in the training phase, our
next question is whether the beneﬁts will persist in the transfer phase. To answer these two questions, we developed an instructional
system, called AMT, and conducted experiments to evaluate it. The following sections described the system, how it was implemented, and
the evaluation at last.
The name “AMT” is an acronym for the overall project, which is called the Affective Meta-Tutoring project. The ﬁrst objective of the
project is to develop and test a meta-tutor that improves student’s learning of modelling by using procedural scaffolding as well as the
traditional feedback and hints. The results of that phase of the project are reported here. The second phase of the project will be to add an
affective learning companion to the AMT system; hence the term “affective” in the project name. The second phase will be described further
in the discussion section.
2. The AMT system’s design and behaviour
This section has three parts. The ﬁrst describes the student’s task, and in particular, the graphical language in which they write models.
The second section describes the tutoring system. The third section describes the meta-tutor and the strategy that it teaches students to use.

202

L. Zhang et al. / Computers & Education 75 (2014) 196–217

2.1. Constructing models in the AMT modelling language
In order to decrease the difﬁculty of learning how to construct system dynamics models, most prior work has used graphical modelling
languages where a model consists of several types of nodes and links. These graphical languages are easier to learn than text-based languages (Löhner, Van Joolingen, & Savelsbergh, 2003). The traditional “stock and ﬂow” language has two types of links, and one of them (the
ﬂow links) acts somewhat like nodes. In pilot studies, our high school students found this confusing, so we removed the confusing type of
link.
In our modelling language, a model is a directed graph with one type of link. Each node represents both a variable and the computation
that determines the variable’s value. The inputs of that computation, which are themselves variables, are indicated by incoming links. In
Fig. 2 for example, the computation for “births” requires the values of “growth rate” and “population.” The value of a variable is a real
number that can change over time, where time is represented discretely.
There are three types of nodes:
 A ﬁxed value node represents a constant value that is directly speciﬁed in the problem. A ﬁxed value node has a diamond shape. It never
has incoming links.
 An accumulator node accumulates the values of its inputs. That is, its current value is the sum of its previous value plus its inputs. An
accumulator node has a rectangular shape and always has at least one incoming link.
 A function node’s value is an algebraic function of its inputs. A function node has a circular shape and at least one incoming link.
The students’ task is to draw a model that represents a situation that is completely described by a relatively short text. For instance, Fig. 2
is a correct model for the following problem:
Rust destroys steel and can spread quickly. Suppose that you take a large sheet of steel, such as one that might be used as the roof of the boxcar
on a train, and you put it outside in the weather. Suppose it starts with a spot of rust that is 10 square inches in area. However, each week the
rust spot gets bigger, as it grows by 30%. Therefore at the end of the ﬁrst week, the rust spot is 13 square inches in area. Graph the size of the rust
spot over 10 weeks.
Such a text contains all the information that students need. However, it sometimes contains extra quantities (e.g., the rust spot at the end
of the ﬁrst week) that are not needed in the model. Students are asked to draw only the necessary nodes, so drawing a node for the rust spot
at the end of the ﬁrst week is an indication of shallow modelling.
2.2. The tutoring system
Many tutoring systems have a sequence of feedback and hints (VanLehn, 2006). When the student makes an entry, the tutoring system
ﬁrst just tells the student whether the entry is correct or incorrect. If the student asks for help again, the system gives a general hint.
Subsequent requests for help on the same entry generate increasingly speciﬁc hints. Eventually, the ﬁnal hint (called the “bottom-out hint”)
tells the student what the correct entry is. There is some evidence that the mid-level hints are not pedagogically useful (Muldner, Burleson,
van de Sande, & VanLehn, 2011; Timms, 2007), so our tutoring system does not use them. Instead, it generates just the ﬁrst and last members
of the typical hint sequence. More speciﬁcally, it has a Check and a Give-up button. Clicking on the Check button causes the tutoring system
to give minimal feedback: It colours entries red if they are incorrect and green if they are correct. Clicking on the Give-up button causes the
tutoring system to ﬁll in entries correctly, that is, to give a bottom-out hint. This section describes the AMT model editor, pointing out where
the Check and Give-up buttons appear.
The system presents itself to the student as a large tabbed window (Fig. 3). The Model tab (shown in the ﬁgure) is for drawing models.
The Situation tab shows a textual representation of the problem, and is illustrated by a static picture. The Instructions tab contains a slide
deck that teaches students the basics of the modelling language, the user interface, the modelling process and the learning strategy. Students can access the Introduction and Situation tab at any moment during the construction of the model (cf. Section 4.4).
The Model tab has three buttons: Create Node, Run Model and Done. The Done button is disabled (grey) until the student has completed a
problem successfully (i.e. created an accurate model of the system), at which time clicking on the Done button advances the system to the
next problem.

Fig. 2. A model. The grey bubbles have been added to this ﬁgure in order to show how the value of each variable is calculated.

L. Zhang et al. / Computers & Education 75 (2014) 196–217

203

Fig. 3. The tutoring system’s screen.

The Create Node button creates a new node symbol in the model area and opens the Node Editor on it. The Node Editor (Fig. 4) is divided
into ﬁve tabs: Description, Plan, Inputs, Calculations and Graph. Students can edit all tabs with the exception of the Graph tab, where a graph
showing the evolution of the node’s value over time is generated by the tutoring system once the model is run. To create a node, the student
ﬁlls out the four tabs in order, left to right. Students can also change the information within a node by double clicking on the node shape
within the model area, which opens the Node Editor, and then selecting the tab they wish to modify.
The Description tab was engineered to facilitate grounding, where “grounding” is the process of negotiating mutual understanding of the
meaning of a term between two participants in a conversation (Clark & Brennan, 1991). In system dynamics model editors that are not used
for tutoring, such as Stella, Vensim and Powersim, users merely type in the name of the node that they want. This allows them to use names
such as “x” that do not match anything in the problem. While this is unproblematic for such editors, it makes it difﬁcult or impossible for a

Fig. 4. The node editor, showing the Description tab.

204

L. Zhang et al. / Computers & Education 75 (2014) 196–217

tutoring system to determine what quantity the student’s node denotes, and hence the tutoring system cannot determine whether the node
is deﬁned correctly. Urging the students to choose adequately precise names is only partially successful. In one study, only 78% of the node
names could be identiﬁed by the tutoring system (Bravo, van Joolingen, & de Jong, 2009). This is a case of bad grounding: the tutoring system
did not understand the meaning of 22% of the students’ terms.
On the other hand, some tutoring systems for system dynamics modelling, including the ﬁrst version of this system, provide students
with nodes that already have names but are otherwise undeﬁned (VanLehn et al., 2011). Unfortunately, students often do not pay enough
attention to the names, which can be rather similar. Students sometimes create models that are correct except that the names of two nodes,
such as “rust growth factor” and “new rust area per week”, have been switched. This is also a case of bad grounding: the student did not
understand the meaning of the system’s terms.
The Description tab of AMT, illustrated in Fig. 4, is intended to prevent bad grounding. First, the student walks through the tree in the
Description tab located in the large box at the top of the window. Clicking on a leaf in the displayed tree selects both a description and a
name for the node. Each problem has a different tree, and the tree’s contents are engineered to make the student select among subtly
different descriptions. After selecting a leaf, the student clicks on the Check button. If the selected description denotes a quantity that the
system understands, and that quantity does not already have a node deﬁned for it, then clicking on the Check button turns some boxes
green, as shown in Fig. 4. Otherwise, the boxes turn red. Students may also click on the Give-up button that ﬁlls out the tab correctly but
colours the boxes yellow. When the student exits the node editor, the node’s name, which is shown beneath the node, is highlighted by the
colour of the Description tab’s boxes. Thus, a student who had given up on the Description tab would forever see yellow highlighting on the
node’s name. This feature is intended to discourage giving up.
When the Description tab is completed correctly and its boxes are either green or yellow, then students can go on to the Plan tab. The Plan
tab lets students choose among 7 different plans (Fig. 5). The Instruction tab describes the meaning of these plans and gives an example of
each plan. After a selection is made, students may click on the Check button and see their selection coloured green (correct) or red
(incorrect). Clicking on the Give-up button causes the correct plan to be selected and coloured yellow. Unlike the other tabs, ﬁlling out the
Plan tab correctly is optional. Students can go to the Inputs tab regardless of how their plan selection is coloured, and they can skip the Plan
tab entirely if they want.
The Inputs tab (Fig. 6) allows students to indicate whether the node’s value is a ﬁxed, given constant or if it is computed from other nodes’
values. In the latter case, they click on “Inputs:” and choose some of the existing nodes as inputs, which causes links are drawn between
those nodes and the current node. When students see that the input they want is not in the list because they have not yet created a node for
it, they can click on the convenient “Create a new node” button, deﬁne the desired node using a pop-up version of the Description tab, then

Fig. 5. The plan tab.

L. Zhang et al. / Computers & Education 75 (2014) 196–217

205

Fig. 6. The Inputs tab.

return to this Input tab by closing the pop-up. As always, the Check and Give-up buttons colour the student’s choices in either red (incorrect),
green (correct) or yellow (gave up). While red choices can be revised later on, green or yellow choices cannot be changed.
When the Inputs tab is ﬁlled out correctly, students can go to the Calculation tab (Fig. 7). If they had selected “Fixed Value” on the Inputs
tab, then “has a ﬁxed value” is checked here on the Calculation tab, and so all they need to do here is enter the number that is the value of the
Fixed Value node. On the other hand, if they had selected “Inputs:” on the Inputs tab, then they must click either the “accumulates the values
of its inputs” button or the “is a function of its inputs” button. This selection determines which form appears in the lower part of the tab.
Fig. 7 shows the tab to ﬁll for the Accumulator node type on the left, and the Function node type on the right. For both the Function and
Accumulator nodes, the inputs appear initially in the “Available inputs:” box, and then move rightward into the calculation box as they are
clicked. In this fashion, students enter a calculation.
As a model is being constructed, the state of the node’s deﬁnition is indicated by little circular indicators (“i” for input, “c” for calculation
and “g” for graph) and the node’s outline (see Fig. 8). A dotted border indicates that the type of the node hasn’t been deﬁned yet. A blue
border means that the node’s deﬁnition is complete.
When all the nodes have blue borders, the student can click on the Run Model button. If there are syntactic errors in the model that
prevent running it, a pop-up window describes them. Otherwise, Run Model colours the “g” indicators on every node either green or red,
depending on whether the node’s graph is correct or not. Opening the Graph tab of a node displays both the user’s model’s graph and the
expected graph (see Fig. 9). Students can use the difference in the graphs as a clue to where the bug in the model could be found.
A model is considered completely correct when all the graphs match, in which case all the “g” indicators are green. At this point, students
can click on the Done button and go to the next problem.
This is a step-based tutoring system (VanLehn, 2006) because it can give feedback on every step taken by the student. It only gives such
feedback when the student clicks on the Check button. The feedback is minimal: just correct vs. incorrect. Absent are the usual sequences of
hints that many step-based tutoring systems have. However, the “Give-up” button implements the bottom-out hint in that it gives away
exactly what step the student should do at this point.
The AMT system has a mode, called test mode, which is used to assess students’ skill at modelling. Although students can still debug their
model by running it and seeing which graphs are correct, they cannot use the Check and Give-up buttons on any of the tabs that they ﬁll out,
with one exception. The Check button is always enabled on the Description tab. This is because the system and the student must agree on the
meaning of nodes. If the system doesn’t know which quantity is denoted by the student’s node, then it can’t know which graph is correct and
can’t colour the “g” indicators. In test mode, the Check button is enabled only on the Description tab, whereas in training mode, it is enabled
everywhere. In test mode, the Give-up button is never enabled.

206

L. Zhang et al. / Computers & Education 75 (2014) 196–217

Fig. 7. The Calculations tab.

2.3. The meta-tutor
So far, only the tutoring system has been described. It is essentially just a model editor with Check and Give-up buttons. This section
described the meta-tutor, which is the remaining module of the AMT system. This section begins by describing and motivating the learning
strategy that the meta-tutor teaches, then describes how it teaches that strategy.
Like Pyrenees (Chi & VanLehn, 2010), the meta-tutor teaches students a simple, goal reduction procedure for constructing models called
the Target Node Strategy. The basic idea is to focus on one node at a time (the target node) and complete all the tabs for this node before
working on other nodes. As students complete the target node, they may create new nodes as a side effect, but the new nodes will only be
named and not fully deﬁned. These nodes are displayed with dotted borders. Thus, when students have ﬁnished the target node, they can
pick any node that has a dotted border as the next target node, and begin working on deﬁning it. When there are no more nodes with dotted
borders, the model is complete.
There are sound reasons to think that the Target Node Strategy might help students learn more effectively, but it will take several
paragraphs to describe them. These paragraphs also illustrate the distinction between deep and shallow modelling practices.
The key steps in the Target Node Strategy are ﬁlling out the Inputs tab and the Calculation tab. These steps correspond to the moment
where students must analyze the given system information and determine the quantitative relationships between the target node’s
quantity and other quantities in the problem. That is, given a particular target quantity, students must ﬁnd a set of quantities such that the

Fig. 8. An incomplete model.

L. Zhang et al. / Computers & Education 75 (2014) 196–217

207

Fig. 9. The Graphs tab.

target quantity’s value can be computed as a simple function of their values. The whole problem of constructing a model of a system can be
decomposed into making a series of decisions like this one. One might call these decisions “atomic modelling problems”, as they cannot be
easily decomposed further.
For example, consider the system described earlier:
“Rust destroys steel and can spread quickly. Suppose that you take a large sheet of steel, such as one that might be used as the roof of the boxcar
on a train, and you put it outside in the weather. Suppose it starts with a spot of rust that is 10 square inches in area. However, each week the
rust spot gets bigger, as it grows by 30%. Therefore at the end of the ﬁrst week, the rust spot is 13 square inches in area. Graph the size of the rust
spot over 10 weeks.”
Suppose students are following the Target Node Strategy and have decided that the ﬁrst target node is the size of the rust spot. They
create a node and select “rust spot area” as its description. Now they face an atomic modelling problem. How to determine the value of rust
spot area? What we want students to think is something like, “I know the rust spot area is changing, and the value increases every week”.
This reasoning sufﬁces for ﬁlling out the Plan tab correctly. Next the students need to ﬁll out the Input tab, so they should think, “The rust
spot area is increased by the rust produced during the week”. There are no other nodes at the moment, so the student must click on “Create a
new node.” The student browses the available descriptions, and chooses the one that comes closest to the student’s idea of “rust produced
during the week.” Clicking on this description deﬁnes the node new rust area per week. The student can then select this node as an input for
the node rust spot area. Next comes the Calculation tab, which requires for the student to turn his/her qualitative understanding of the
relationship into a formal, mathematical one: the student should decide that the next value of rust spot area is its current value plus new rust
per week. This illustrates how the user interface decomposes the key reasoning into three major steps, corresponding to the Plan, Input and
Calculation tabs. These correspond roughly to the phases of Co-Lab (Mulder et al., 2011) and Model-It (Metcalf et al., 2000). This paragraph
also illustrates how the key reasoning should be done: by thinking hard about the system, its quantities and their interrelationships, and
then abstracting the mathematical relationships from them. This is the “deep” way to solve an atomic modelling problem.
However, there are shallow ways to solve the atomic modelling problem as well. When students need to create nodes in order to ﬁll out
the Inputs tab, there are only a ﬁnite number of choices: the leaves in the tree of descriptions on the Description tab. Thus, they can work
through all combinations until they have found the appropriate inputs. When the Check button is available and the problem is simple, this
can be done rapidly. For instance, the rust spot area problem’s Description tab has 7 possible descriptions, of which only 4 are legal
quantities in the problem (1 is an extra node; 3 are necessary for the model). It will not take the student long to create all the legal nodes, and

208

L. Zhang et al. / Computers & Education 75 (2014) 196–217

then test each one to see if it turns the Inputs tab green. Such extensive guessing is one “shallow” method for solving atomic modelling
problems. The Give-up button is another. Other methods involve looking for keywords (e.g., “initially”) or patterns.
Many of our students’ shallow modelling methods involve abusing the Check button or the Run Model button, so their behaviour is a
form of gaming the system (Baker et al., 2006; Baker, Corbett, & Koedinger, 2004), which is what the Help Tutor (Roll et al., 2011), Scooter the
Tutor (Baker et al., 2006), and other tutoring systems have tried to address. However, studies of modelling that did not use tutoring systems
have also noted this propensity of students to do shallow modelling (Alessi, 2000; Booth Sweeney & Sterman, 2000; Doerr, 1996; Mandinach
& Cline, 1994b; Nathan, 1998; Zaraza & Fisher, 1999). Thus, we prefer to refer to the phenomenon as “shallow modelling” rather than
“gaming the system.”
Teaching the Target Node Strategy does not require that student do deep modelling, so one might wonder why we think it could help
students model better. However, it does decompose the whole problem of modelling a system into a series of atomic modelling problems,
and even decomposes an atomic modelling problem into three major steps. Like Pyrenees, it teaches students that if they just master this
one difﬁcult but small skill (deep modelling applied to atomic modelling problems), then the rest of the problem solving is purely
mechanical.
Having described and motivated the Target Node Strategy, it is ﬁnally time to describe how the meta-tutor teaches it. First, the Introduction slides describe the strategy brieﬂy. Even students who use AMT with the meta-tutor turned off see this presentation of the strategy.
Also when the meta-tutor is turned off, students can edit any node at any time. Moreover, they can ﬁll out some of a node’s tab, then quit
editing the node and come back to it later. This freedom is removed when the meta-tutor is turned on. Students are required to correctly ﬁll
out each tab before moving on to the next, and they must ﬁll out all tabs before closing the node editor. When they are on the Description tab
and choosing which quantity to create a node for, if they choose one that would not be selected by Target Node Strategy and yet it will
eventually be include in the model, then the selection turns blue and a pop-up window says, “That quantity is in the correct model, but it is
too early to deﬁne it now.” This message is typical of others that pop up when students stray from the Target Node Strategy. In short, the
main job of the meta-tutor is simply to keep students on the one of the paths that are consistent with the Target Node Strategy.
In addition to requiring students to follow the Target Node Strategy, the meta-tutor enacts a bit more scaffolding. For completeness, this
section describes the remaining forms of help.
When the meta-tutor is turned on, it complains if students appear to be guessing too much or giving up too early, just as the Help Tutor
did. When a student clicks on the Check button on the same tab twice within 3 s and gets red both times, the meta-tutor complains that the
student is guessing. If the student clicks on the Give-up button without ﬁlling out anything and checking it, the meta-tutor complains that
the student is giving up too early.
Some of the training problems let students practice debugging an incorrect model. They present a model that will run but generates
incorrect graphs. This kind of situation occurs frequently when the system is in test model (the tutor and meta-tutor are turned off). When
the model has been run, students see that some nodes have red “g” indicators and some have green ones. They face a decision of where to
start looking for an error in the model. The Introduction slides teach all students two heuristics:
 When possible, start by examining a node that has a red “g” indicator and no incoming links from nodes with red “g” indicators. Such a
node is guaranteed to have an error inside it.
 Avoid editing nodes that have green “g” indicators, because if the graph is correct, the node’s deﬁnition is probably correct.
When the meta-tutor is on and students are working on a debugging problem, it constrains them to obey these two heuristics.
In summary, the meta-tutor actually uses three types of scaffolding: (1) it requires students to follow the Target Variable Strategy; (2) it
complains when they abuse the Check or Give-up buttons; and (3) it teaches some heuristics for locating errors in buggy models. Although
(1) is procedural scaffolding, for convenience, we refer to this collection as “the meta-strategy.”

3. System architecture and implementation
The AMT system can be divided into two parts: the tutor and the meta-tutor. The tutor’s main functionalities included drawing a model,
checking correctness and running the model. It is an example-tracing tutor (VanLehn, 2006) in that an author must provide a correct model
with each problem; the students’ work is checked against that model. On the other hand, the meta-tutor is driven by algorithms (e.g., the
Target Node Strategy) that work for any problem. The student’s actions are check against the actions selected by the meta-strategy.
Although the meta-tutor and the tutor belong to the same Java project, they don’t share objects in the memory. This made it possible to
develop the tutor and meta-tutor programme independently. It also facilitates data analysis as will be explained later. More details about the
tutor’s architecture and implementation are presented in (Gonzalez-Sanchez, Chavez-Echeagaray, VanLehn, & Burleson, 2011). This section
describes the meta-tutor only.
Between the tutor and meta-tutor, there are three kinds of communication, each with its own channel as shown in Fig. 10:
(1) Every action made by student is sent to the meta-tutor via the activity channel.
(2) Before executing certain user actions, such as closing a node, the tutor sends a message to the meta-tutor via the block channel and
meta-tutor responds to the tutor, indicating whether the action should be blocked or not.
(3) Whenever the meta-tutor detects that the student needs an unsolicited hint, it sends a command to the tutor via the message channel to
tell it to initialize the tutorial dialogue. The tutor sends back the student’s response. Based on the response, the meta-tutor tells the tutor
either to display another dialogue box or to close the dialogue.
The meta-tutor is a production system, implemented in Java using Drools Expert (http://www.jboss.org/drools/drools-expert.html). The
production system implements two major functionalities: requiring the student to follow the Target Node Strategy and discouraging
gaming. The following sections describe the implementations of each function.

L. Zhang et al. / Computers & Education 75 (2014) 196–217

Tutor

Activity
channel

Student’s actions
Query at student’s actions

Message Block
channel channel

Response[block or not]

Activity
channel

209

Metatutor

Block Message
channel channel

Tutorial dialog
Student’s answer to dialog
Fig. 10. How the tutor and meta-tutor communicate with each other.

3.1. Constraining students to follow the Target Node Strategy
One main function of the meta-tutor is to constrain the student to follow the Target Node Strategy. In order to do so, it implements the
algorithm shown in Fig. 11. Aside from a little bookkeeping, the procedure’s actions are either “Prompt and constrain the student to do
<step>,” or “Constrain the student to do <step>”.
Prompting means that as soon as the problem state allows a step to be done, the meta-tutor gives the student an unsolicited hint about
the step. Here are examples of production rules that implement prompting:
 IF the activity channel reports that the student’s action is “closed a node”
AND there are at least two nodes that can become the next target node
THEN
send a command via the message channel to show a dialogue box that lists the nodes and ask which one the student wants to choose
as the target node.
 IF the context is that the node editor is open and the current tab is the plan tab,
AND the activity channel reports that the student’s action is “clicked on the Check”
AND the correct plan of this node is “a ﬁxed, given number”
AND the student has selected this plan
THEN
send a command via the message channel to show a message that says that the next step is to ﬁll in the Inputs tab by clicking on
“Value is ﬁxed, so no inputs.”
Constraining the student to do a step means that if the problem state is such that the student should do a certain action, and the student
tries to do another action instead, then the meta-tutor blocks the student’s action from occurring and pops up a message indicating the right
action to do. Some examples of production rules that implement constraining are:
 IF the context is that the student is in the model tab and the node editor is not open
AND the student’s action is clicking on a node in order to open it in the node editor
AND the node that student is trying to open is not the target node
THEN
send via the block channel the message “Please focus on your target node, <target node name>” and block opening the clicked-on
node.
 IF the context is that the node editor is open
AND the student’s action is closing the node
AND the node’s calculation tab is not ﬁnished yet
THEN
Send via the block channel the message “Please ﬁnish the target node, <target node name>, before leaving the editor” and block
closing of the node editor.
In order for the meta-tutor to track the student’s progress and respond appropriately, its rules need to have up-to-date information about
the state of the problem. Using the activity channel, the tutoring system sends all student actions to the meta-tutor, which converts some of
them (e.g., not node movements) into elements in the production system’s working memory. The working memory is also used to store the
identity of the target node, the contents of the sought set and other bookkeeping information that is kept updated via production rules.
3.2. Discouraging gaming
As mentioned earlier, the Give-up and Check buttons can be easily misused by students to construct models without thinking deeply or
learning, e.g., “gaming the system” (Baker et al., 2006; Baker, Corbett, Koedinger, et al., 2004). Although constraining students to follow the
Target Node Strategy may discourage gaming, the meta-tutor also looks for patterns of student actions that indicate gaming is occurring.
When it sees such a pattern, it pops up a warning message but does not block the student’s actions.
Detecting and responding to gaming of the Check button is implemented by the ﬁnite state machine shown in Fig. 12. The students are
always in one of 5 states. When they start working on a problem, they start in state S1 (the node editor is not open). Clicking on a node opens
the node editor and moves to state S2 (no check yet). Edits to the contents of the open tab can occur in any of the states except S1, and are not
shown in Fig. 12, as they merely add a loop from a state back to itself. The arc label “Wrong check” means that the student clicked on the
Check button and got red, indicating the tab was not ﬁlled out correctly. The arc label “Got the answer right” means the student either

210

L. Zhang et al. / Computers & Education 75 (2014) 196–217

1. Initialize the target node to the top level goal (i.e., the quantity the problem wants graphed).
Initialize the sought set to null.
2. Constrain the student to create a node and fill out its Description tab to correspond to the top level
goal quantity.
3. Constrain the student to fill out the Plan tab correctly.
4. Prompt and constrain the student to fill out the Input tab correctly. Add any newly created nodes
to the sought set.
5. Prompt and constrain the student to fill out the Calculation tab correctly.
6. Constrain the student to close the node editor.
7. If there are no nodes in the sought set, then prompt and constrain student to run the model.
If there is just one node in the sought set, then set it as the target node and tell the student.
If there are two or more nodes in the sought set, ask the student which one should be the target
node and set it to be the target node.
8. Remove the target node from the sought set.
9. Prompt and constrain the student to create a node and fill out its Description tab to correspond to
the target node.
10. Go to step 3 above.
Fig. 11. The Target Node Strategy implemented by the meta-tutor.

clicked on the Check button and got green, or clicked on the Give-up button. Whenever the student enters state S4 (gaming detected), the
meta-tutor sends a randomly chosen message such as, “Guessing so quickly wastes the opportunity to learn.”
In short, because the main job of the meta-tutor was to teach students to stay on a certain path deﬁned by the meta-strategy by blocking
off-path actions, and the meta-strategy was simple and easily deﬁned, the only signiﬁcant technical challenge was integrating the metatutor with the tutor. The tutor was implemented with a standard model-view-controller architecture, and the meta-tutor essentially was
given a chance to intervene after the user’s actions had actuated the control and before the model was updated.
At this point, the design and implementation of the AMT system have been deﬁned, so it is time to consider whether it works. That is,
does meta-tutoring improve students’ learning compared to tutoring without meta-tutoring?
4. Evaluating the meta-tutor
So far, we have conducted 5 studies of the AMT system. In the ﬁrst two studies, which were conducted in the summer of 2010, students
used the tutoring system without the meta-tutor. This led to signiﬁcant changes in the design of the tutoring system (VanLehn et al., 2011),
the materials and the experimental procedure (VanLehn et al., 2011). The two studies also produced data revealing students’ deep and
shallow modelling practices, and thus allowed us to design the meta-tutor. This article presents the results of the next three studies. There
were slight changes to the tutor and the experimental procedure in between the studies 3 and 4, which were conducted in summer 2011.
Analysis of the data from these two studies over the next year led to signiﬁcant changes to the AMT system, such as adding the Plan tab,
which led to study 5, which was conducted in summer 2012.
All the three studies had two phases, training and transfer, as did most of the studies reviewed earlier. During the training phase, a metatutor taught students both to use a good learning strategy (adapted from Pyrenee’s) and to avoid using poor learning strategies. During the
transfer phase, the meta-tutor and the tutor were turned off, thus allowing us to measure both domain learning and spontaneous use of the
learning strategy.
4.1. Research hypotheses
Recall that our framework, adopted from the literature on learning strategies, poses four research questions:
A. Without instruction in good learning strategies, do students often exhibit poor learning strategies?
B. Can good learning strategies be easily taught?
C. When students use the taught learning strategies, does their domain learning increase compared to students who are not taught to use
the learning strategies?
Close the node
/leave the tab

Close the node
/leave the tab

S1

Wrong check
& interval > 3s
Wrong check

Open a node
Get to the input tab

S2

S3

Got the answer Got the answer right
right

Interval
>3s

Wrong check
& interval < 3 sec

Close the node
/leave the tab

S5

Got the answer right

Close the node
/leave the tab

S4
Wrong check
& interval < 3s

S1: no opened node editor
S2: no check
S3: one wrong check
S4: gaming
S5: got right

Fig. 12. Finite state machine for gaming the Check button.

L. Zhang et al. / Computers & Education 75 (2014) 196–217

211

D. After instruction in the learning strategy ceases, do students revert to poor learning strategies?
Our observations during studies 1 and 2 answered question A by demonstrating that our students often use poor learning strategies
when they are not taught good ones. Moreover, because the meta-tutor requires students to follow the Target Node Strategy during the
training phase, question B cannot be addressed by our studies. This leaves us to focus on C and D.
Addressing question C requires that we clearly deﬁne the expected domain learning. As mentioned earlier, two entirely different
instructional objectives are associated with model construction: Using model construction to learn domain concepts and principles (usually
in a science classes) and learning how to construct models (usually in math classes). In these studies, we focus only on the second objective,
so “domain learning” in question C means learning how to do deep model construction. Moreover, question C can be asked of both the
training phase, where the learning strategy is taught, and the transfer phase, when the meta-tutor and tutor are turned off. Thus, the speciﬁc
hypotheses we tested in studies 3, 4 and 5 are:
1. In the transfer phase, do meta-tutored students display deep modelling more frequently than students who were not meta-tutored?
2. In the training phase, do meta-tutored students display deep modelling more frequently than students who do not receive metatutoring?
3. In the transfer phase, do meta-tutored students follow the Target Node Strategy more frequently than students who were not metatutored?
Although we predict positive answers for all three questions, there is a caveat concerning the third hypothesis. The instruction used in
studies 3, 4 and 5 did not provide much meta-cognitive and motivational encouragement to use the learning strategy, because we are
developing that part of the instruction for use in later studies. Thus, we have low expectations for hypothesis 3.
4.2. Method
Students were randomly assigned to one of two conditions: with and without meta-tutoring. The difference between the conditions
occurred only during a training phase where students learned how to solve model construction problems. The meta-tutor group solved
problems with the meta-tutor turned on, while the control group solved the same problems with the meta-tutor turned off. During the
training phase, all students could use the Check and Give-up buttons at any time.
In order to assess how much students learned, a transfer phase followed the training phase. During the transfer phase, all students solved
model construction problems with almost no help. That is, the meta-tutor and the Give-up button were turned off, and the Check button was
turned off everywhere except on the Description tab where it remained enabled in order to facilitate grounding, as mentioned earlier.
Because system dynamics is rarely taught in high school, the procedure did not include a pre-test in modelling dynamic systems.
In order to provide a motivation similar to that which occurs in school, we told students that prizes would be awarded to students who
solved the most problems during the transfer phase. In particular, we repeatedly told them to use the Check and Give-up buttons judiciously
during the training, trying always to learn as much as possible, so that they could rapidly solve problems during the transfer phase when the
Check and Give-up buttons would not be available.
4.3. Participants
There were 34 student participants in the ﬁrst experiment, 44 students participated in the second experiment, and 34 students in the
third experiment. No person participated in more than one experiment. All were high school students who were participating in summer
camps at our university.
4.4. Procedure
The three experiments followed the same procedure. Each lasted two and a half hours and had two main phases, training and transfer.
Sensors recorded students’ physiological states throughout both the training and transfer phases. The sensors were: wireless skin
conductance bracelets, facial expression cameras, posture-sensing chairs, and pressure sensitive mice. Periodically, a window would pop up
and ask students to report their affective state. These data are being used to develop algorithms for affect detection, and will not be discussed further here. Also in the ﬁrst two experiments, but not the third, students were asked to speak their thoughts aloud into a headset
microphone, and their verbal protocols were recorded by screen-capture software.
The summer camp students were available for only a ﬁxed period of time and all needed to be kept occupied productively during that
period. Thus, each phase of the experiment lasted a ﬁxed period of time, and students solved as many problems as they could during that time.
We obtained parental consent for minors prior to the experiment. During the experiment, student gave informed consent, ﬁlled out a
background questionnaire, donned sensors and started the training phase. The training phase lasted a total of 75 min. It consisted of ﬁrst
studying a sequence of PowerPoint slides that introduced them to the user interface, model construction and the Target Node Strategy, and
then solving a sequence of model construction problems. The introduction slides remained available while students were solving problems.
During pilot testing, we noticed that some students spent a long time studying the introduction then rarely referred back to it, whereas
other studied the introduction brieﬂy and referred back to it frequently as they solved problems. Thus, we let students decide how to allocate
their 75 min between the studying introduction and solving the training problems. The training phase was followed by a 15-min break
where students went to another room and had a snack. After the break, all the students began the transfer phase, where both conditions
were identical. The transfer phase lasted for 30 min, and a debrieﬁng of the students followed.
Students in both conditions solved the same problems in the same order. Except for a few debugging problems during the training phase,
where student were asked to correct a given faulty model, both training and transfer problems required students to construct a correct

212

L. Zhang et al. / Computers & Education 75 (2014) 196–217

model, which is deﬁned as a model whose graphs match graphs of correct values. When the model was correct, students were allowed to go
on to the next problem. This procedure was followed for both the training and transfer phases.
The only procedural difference between the training and transfer phases was the amount of scaffolding available. During the training
phase, the Check and Give-up buttons were enabled, and the meta-tutor was active for students in the meta-tutor condition. During the
transfer phase, the Check button was enabled only on the Description tab because it was necessary for grounding, as discussed earlier. None
of the other scaffolding was available during the transfer phase.
4.5. Measures
To test the hypotheses and answer the research questions, 7 measures were deﬁned by extracting information about student’s interaction with software from students’ log ﬁles. The measures are described in this section.
Hypothesis 1 is that the meta-tutored students will use deep modelling more frequently than the control students during the transfer
phase. Deep modelling is not easy to measure directly, so we used three indirect indicators:
 The number of the “Run model” button presses for completing one problem in the transfer phase indicates how much help the student needs
from the system. Deep modellers should be able to complete problems using the Run model button only a couple of times per model.
 Another measure was the number of extra nodes created during the transfer phase, where extra nodes are deﬁned as the nodes that can
be legally created for the problem but are not required for solving the problem. Deep modellers should realize that these quantities are
irrelevant and therefore avoid modelling them.
 The number of problems completed during the 30 min transfer period was considered to be an indicator of deep modelling with the
assumption that it would be faster for students to solve atomic modelling problems deeply than shallowly.
Hypothesis 2 is that meta-tutored students should use deep modelling more frequently than the control group students during the
training phase. The three dependent measures used to evaluate this hypothesis are described next.
 Help button usage: Ideally, a deep modeller would ﬁll out a tab, click on the Check button and the tab’s ﬁelds would turn green (correct).
A student who is trying to do deep modelling but hasn’t mastered the skill might have to click the Check button twice, thinking hard
before each attempt, in order to get them right. On the other hand, shallow modellers might click on the Check button repeatedly as they
guess or use the Give-up button. To measure usage of the help buttons, the following measure was calculated:

Help usage ¼ nwc þ 3ngu



nrn

where nwc is the number of Check button presses that yielded red, ngu is the number of Give-up buttons the student clicked, and nrn is the
number of nodes required by the problem. The “3” here is a weight to make ngu be roughly comparable to nwc. The denominator represents
the number of nodes required for a correct, minimal solution rather than the actual number of nodes the student completed. Should the
prediction for Hypothesis 2 hold true, meta-tutored students’ usage of the help button should be lower than the control students’ one.
 Correct on ﬁrst Check: This measure for Hypothesis 2 is a traditional one in tutoring system research. It represents how frequently
students succeed on their ﬁrst attempt at ﬁlling out a tab. That is, what proportion of the tabs turned green when students ﬁrst clicked
on the Check button? Deep modellers should get almost everything right the ﬁrst time, whereas a student who is confused or guessing
might rarely get elements right on the ﬁrst try. Unfortunately, this measure could only be applied to experiment 5, as insufﬁcient log
data was kept during the 2011 experiments.
 Training efﬁciency: This measure is based on the (now dubious) assumption that deep modelling is faster than shallow modelling. Speed
is often measured by counting the number of problems solved during a ﬁxed training period. However, our problems’ solutions varied in
their complexity. Some had many nodes and some had few nodes. Moreover, students could always use the Give-up button, which does
part of the problem solving for them. There was one Give-up button per tab, and completing a node requires ﬁlling out three tabs, so
clicking on three Give-up buttons per node would solve the problem. Thus, a better measure of the amount of problem solving
accomplished than “problems completed” is the number of tabs the student completed without using the Give-up button, which is
given by:

Training efficiency ¼ 3ncn  ngu
where ncn is the number of nodes that the student completed correctly (so 3ncn is the number of tabs), and ngu is the number of Give-up
buttons the student clicked. The prediction for Hypothesis 2 is that the training efﬁciency of meta-tutored students should be higher than
the training efﬁciency of control students.
Hypothesis 3 is that the experimental group, which was required to follow the Target Node Strategy during training, would continue to
use it during the transfer phase. To evaluate this hypothesis, we calculated the proportion of student steps consistent with the target node
strategy. The algorithm of Fig. 12 describes how it is calculated.
5. Results
Experiments 1 and 2 found, as expected, that students often exhibit shallow learning strategies (VanLehn et al., 2011a). They also led to
many revisions in the software and the experimental procedure (VanLehn et al., 2011b). However, both experiments had only one condition,
and it did not include the meta-tutor. This section reports on comparisons of the system with the meta-tutor turned on and turned off.

L. Zhang et al. / Computers & Education 75 (2014) 196–217

213

5.1. Experiment 3 results
Experiment 3 was conducted in June 2011. Of the 34 participants, some students’ data needed to be omitted. Probably because there were
too many introduction slides (101 in total), 11 out of 34 students were still in the introduction phase at the break, and thus had no time in the
training phase where the manipulation occurred. These 11 students were omitted from the analyses. Two students, one in each condition,
performed much better than others. Both students’ training measures and test measures were greater than three standard deviations from
the means. These two students were also excluded from the analyses. The ﬁnal number of students left for each group was 11 (control) and
12 (meta-tutor). All the analyses below were computed based on these 23 students.
5.1.1. Hypothesis 1 (transfer phase deep modelling)
Run Model button usage: Of the 23 students, there were only 9 Meta-tutored students and 4 control students that ﬁnished the ﬁrst
problem in the transfer phase. Among the 13 students, meta-tutored students used the Run Model button 4.88 times per problem, while
students in control group used it 6.67 times. Due to the limited number of subjects, it is not surprising that the difference is not signiﬁcant
(p ¼ 0.72, d ¼ 0.12). This T-test, and all other tests reported here, are two-tailed.
Extra nodes: The ﬁrst problem of the transfer phase allowed 2 extra nodes, thus allowing us to measure the number of extra nodes created
by students who completed that problem. Meta-tutor students deﬁned 0.44 (SD ¼ 0.8) extra nodes vs. 0.75 (SD ¼ 0.96) extra nodes for the
control students. The difference was not reliable (p ¼ 0.61, d ¼ 0.58) although it was in the expected direction.
Number of problems completed: The average number of problems completed during the transfer phase was 0.82 (SD ¼ 0.60) for the metatutor students vs. 0.35 (SD ¼ 0.52) for the control students. The difference was marginally signiﬁcant (p ¼ 0.057) even though the effect size
was large (d ¼ 0.88) and in the expected direction. These ﬁgures show that on average, students completed less than one problem. More
speciﬁcally, 9 meta-tutored and 4 control students ﬁnished one or more problems, which was a marginally reliable difference (c2 ¼ 3.486,
p ¼ 0.06).
In short, trends in the data support Hypothesis 1 but the differences were not reliable, probably due to the small sample size.
5.1.2. Hypothesis 2 (training phase deep modelling)
Help button usage: This measure is a weighted sum of help button uses divided by the total number of nodes completed. On this measure,
the meta-tutor students averaged 4.78 (SD ¼ 2.25) vs. 7.03 (SD ¼ 3.44) for the control students. The difference was marginally signiﬁcant
according with a large effect size (p ¼ 0.08, d ¼ 0.82).
Training efﬁciency: The average training efﬁciency measure the amount of correct work done by the student during the ﬁxed-length
training period. For the meta-tutor group, training efﬁciency was 13.00 (SD ¼ 6.94) vs. 11.45 (SD ¼ 6.77) for the control group. The difference was not signiﬁcant (p ¼ 0.30; d ¼ 0.23).
Thus, although there was a trend in the data supporting Hypothesis 2, the reliability was poor, perhaps due to the small sample size.
5.1.3. Hypothesis 3 (meta-strategy usage)
Hypothesis 3 was that meta-tutored students would voluntary the Target Node Strategy during the transfer phase more frequently than
the student who was not meta-tutored. During the transfer phase, 0.39 (SD ¼ 0.35) of the meta-tutor students’ steps matched the Target
Node Strategy’s steps, vs. 0.34 (SD ¼ 0.30) for the control students. This difference was quite small (p ¼ 0.70, d ¼ 0.16), suggesting that
hypothesis 3 may be false for this study.
5.1.4. Summary of results and next step forward
Although there were some trends in the expected directions, the students in both conditions performed quite poorly. This was probably
due to the large number of slides in the introduction phase as well as the difﬁculty of the tasks themselves.
In order to increase the number of training and transfer problems solved by students, thus allowing us to differentiate their performance
statistically, we reduced the number of slides from 101 to 64, and simpliﬁed some of the tasks. As the second experiment conﬁrmed, these
changes led to an improvement on the performance students in both phases.

5.2. Experiment 4 results
Experiment 4 took place in July 2011. Data from all 44 participants (22 in each condition) were used in the analyses here.
5.2.1. Hypothesis 1 (transfer phase deep modelling)
Run Model button usage: To complete the ﬁrst problem in the transfer phase, meta-tutored students used the Run model button 3.05
times on average. In comparison, students in the control group used the Run model button 5.13 times. However, the difference was not
signiﬁcant (p ¼ 0.31, d ¼ 0.32). Because the standard deviation was high (SD ¼ 6.77) due to extreme values, we divided all the students into
two types with the threshold being 2, which is the median. The students who used the run model button once or twice were considered
deep modellers. The rest of the students were considered shallow modellers. Chi-square test is then used to compare the number of deep
modellers in meta-tutored group to the number in control group. There was a trend in the expected direction, but the signiﬁcance was
marginal (c2 ¼ 3.36, p ¼ 0.067).
Extra nodes: Because most of the students ﬁnished at least two tasks in the transfer phase (only 3 students in the control group did not)
and the second task allowed up to two extra nodes, we used the second task to count extra nodes. As predicted by Hypothesis 1, metatutored students produced fewer extra nodes (0.27, SD ¼ 0.70) than control students (0.95, SD ¼ 1.03). The difference was signiﬁcant
with a large effect size (p ¼ 0.02, d ¼ 0.80).
Problems completed: The meta-tutor students solved 3.27 (SD ¼ 1.03) transfer problems vs. 3.23 (SD ¼ 1.57) for the control students. The
difference was small and not signiﬁcant (p ¼ 0.65, d ¼ 0.04).

214

L. Zhang et al. / Computers & Education 75 (2014) 196–217

5.2.2. Hypothesis 2 (training phase deep modelling)
Help button usage: Consistent with Hypothesis 2, meta-tutor students’ help button usage averaged 2.35 (SD ¼ 1.75) vs. 3.55 (SD ¼ 1.85)
for the control students. The difference was signiﬁcant (p ¼ 0.04, d ¼ 0.68).
Training efﬁciency: Contrary to Hypothesis 2, the control students had higher training efﬁciency 72.77 (SD ¼ 32.12) than the meta-tutor
students, 54.36 (20.17), and the difference was marginally signiﬁcant (p ¼ 0.05, d ¼ 0.70).
These results suggest that meta-tutor students did increase deep modelling in the training phase than the control students, but they also
moved slower than control students.
5.2.3. Hypothesis 3 (use of Target Node Strategy)
Missing data precluded testing this hypothesis in experiment 4.
5.2.4. Summary of results, revisions and the next iteration
Both hypothesis 1 (transfer) and hypothesis 2 (training) were supported, albeit by one measure each. We were not satisﬁed with the pace
of the students in the training phase, especially the meta-tutored students. Watching the screen-capture video suggested that meta-tutored
students spent a lot of time in reading and answering the tutorial pop-ups. Students also became “stuck” (Burleson & Picard, 2007) when
ﬁlling out the current Inputs tab and needing to create new nodes. In order to do so, students had to close the node editor and click on the
Create Node button on the canvas in the Model tab. However, many students could not realize that they had to close the node editor. They
complained that no button in the Inputs tab could help them get out of the stuck state. Thus, we spent several months reﬁning both the
tutoring system and the meta-tutor. We installed the Plan tab in order to reduce the time spent reading the meta-tutor’s pop-ups. We also
improved the interface, adding a “create a new node,” button on the Input tab with the goal of reducing students’ state of stuck in this stage.
The transfer phase proved to be extremely challenging for the students. This was evident in the relatively small number of problems
solved as well as direct observation of the students. The null result on our productivity measure, number of problems solved in the transfer
phase, might be due to students in both conditions becoming discouraged and ceasing to try hard. Thus, we modiﬁed the transfer phase so
that besides colouring the “g” indicator, the system coloured the “i” indicator and “c” indicator as well to show the correctness of the
corresponding tabs. This was intended to make it easier to locate errors while leaving unchanged the logic required for ﬁxing the errors, and
thus allowing students to make faster progress through the test problems while still allowing us to assess their skill.
5.3. Experiment 5 results
Experiment 5 was conducted in June 2012. Of the 34 participants, data from 33 were used in the analyses below (16 in the control group
and 17 in meta-tutor group). One student was excluded due to his extraordinary performance. He ﬁnished all 7 problems in the transfer
phase well before the end of the transfer phase, while the second fastest person only completed 4 problems.
5.3.1. Hypothesis 1 (transfer phase deep modelling)
Run Model button usage: On average, students in the control group used the Run model button 7.76 times, while meta-tutored students
used the Run model button 7.82 times. So they almost had the same performance (p ¼ 0.98, d ¼ 0.0093).
Extra nodes: Most of the students ﬁnished at least two tasks in the transfer phase (one in each group didn’t), so we again used the second
task to measure extra nodes. As predicted by Hypothesis 1, the meta-tutor students produced fewer extra nodes (0.88, SD ¼ 0.96) than the
control students (1.13, SD ¼ 0.99). However, the difference was not reliable (p ¼ 0.47, d ¼ 0.26).
Problems solved: Contrary to Hypothesis 1, the meta-tutor students solved 2.18 (SD ¼ 0.53) transfer problems vs. 2.56 (SD ¼ 0.78) for the
control students. Students in the control group outperformed meta-tutored student with marginal signiﬁcance (p ¼ 0.094, d ¼ 0.57).
Once again, the meta-tutor students tended to work more slowly than the control students. This time, there was only a trend to show that
they might be doing more deep modelling than the control students.
5.3.2. Hypothesis 2 (training phase deep modelling)
Help button usage: As expected, meta-tutored students’ help button usage averaged 3.92 (SD ¼ 2.19) vs. 6.13 (SD ¼ 2.73) for the control
students. The difference was signiﬁcant with a large effect size (p ¼ 0.016, d ¼ 0.89).
Correct on ﬁrst attempt: To provide an additional test of Hypothesis 2, we calculated the percentage of time that the ﬁrst Check on a tab
was correct. Meta-tutored students achieved a higher percentage (0.77, SD ¼ 0.068) than control students (0.68, SD ¼ 0.11), and the difference was signiﬁcant with a large effect size (p ¼ 0.015, d ¼ 0.98).
Training efﬁciency: Meta-tutor students scored 73.18 (SD ¼ 27.53), a little bit higher in training efﬁciency than control students, 68.88
(SD ¼ 17.16), but the difference was not reliable (p ¼ 0.59, d ¼ 0.19).
So students in both groups kept the same pace in the training session this time, and there was strong evidence that the meta-tutor
students were engaged in deeper modelling than the control students.
5.3.3. Hypothesis 3 (use of Target Node Strategy)
Contrary to hypothesis 3, the meta-tutored students had nearly the same level of Target Node Strategy usage (0.66, SD ¼ 0.23) as control
students (0.70, SD ¼ 0.19), and the difference is not reliable (p ¼ 0.59, d ¼ 0.19).
6. Discussion
Our results are summarized in Table 1. This section discusses our interpretation of them.
As mentioned in the introduction, whenever a new kind of instruction is developed, there are four classic questions to ask about learning
strategies that are speciﬁc to it:

L. Zhang et al. / Computers & Education 75 (2014) 196–217

215

Table 1
Summary of the results.
Measure (predicted dir.)

Experiment 3 (N ¼ 23)

Experiment 4 (N ¼ 44)

Experiment 5 (N ¼ 33)

Transfer phase (Hypothesis 1)
Run model button usage (E < C)
Extra nodes (E < C)
Probs completed (E > C)

Not available
E < C (p ¼ 0.61, d ¼ 0.58)
E > C (p ¼ 0.06, d ¼ 0.88)

E < C (p ¼ 0.31, d ¼ 0.32)
E < C (p [ 0.02, d [ 0.80)
E z C (p ¼ 0.65, d ¼ 0.04)

E z C (p ¼ 0.98, d ¼ 0.0093)
E < C (p ¼ 0.47, d ¼ 0.26)
E < C (p ¼ 0.09, d ¼ 0.57)

Training phase (Hypothesis 2)
Help button usage (E < C)
Correct on 1st Chk (E > C)
Efﬁciency (E > C)

E < C (p ¼ 0.08, d ¼ 0.82)
Missing data
E > C (p ¼ 0.30, d ¼ 0.23)

E < C (p [ 0.04, d [ 0.68)
Missing data
E < C (p ¼ 0.05, d ¼ 0.70)

E < C (p [ 0.02, d [ 0.89)
E > C (p [ 0.015, d [ 0.98)
E > C (p ¼ 0.59, d ¼ 0.19)

Missing data

E z C (p ¼ 0.59, d ¼ 0.19).

Transfer phase use of Target Node Strategy (Hypothesis 3)
Usage (E ¼ C)
E z C (p ¼ 0.70, d ¼ 0.16)

E stands for the meta-tutor group, and C stands for the control group. Reliable results are bold.

A. Without instruction in good learning strategies, do students often exhibit poor learning strategies?
B. Can good learning strategies be easily taught?
C. When students use the taught learning strategies, does their domain learning increase compared to students who are not taught to use
the learning strategies?
D. When instruction in the learning strategy ceases, do students revert to poor learning strategies?
After we developed a step-based tutoring system for model construction, experiments 1 and 2 answered question A by ﬁnding that
student did indeed exhibit poor learning strategies when using it. This led us to develop a meta-tutor that taught students a meta-strategy
that we hoped would increase their acquisition of skill in model construction.
Answering question B requires that even during the training phase, students have the freedom to choose between following or not
following the learning strategy. This freedom allows experimenters to measure the growth in compliance during the training phase. Of the
four systems reviewed earlier (Betty’s Brain, the Help Tutor, Co-Lab and Pyrenees; see Table 2), Betty’s Brain and the Help Tutor provide such
freedom, and thus were able to show that while students were being meta-tutored, their behaviours were more often consistent with the
learning strategy than the behaviours of students who were not being meta-tutored. This suggests that their meta-tutoring was effective at
getting students to use the taught learning strategy. AMT, Co-Lab and Pyrenees all required students to follow the taught learning strategy
during the training phase, so they could not answer question B.
Given a learning strategy that designers think is good, question C asks whether it really does increase domain learning. Of the four
systems reviewed earlier, only Pyrenees’ learning strategy increased domain learning. Thus, we adapted its learning strategy for use in AMT.
Because the goal of our system is teach students to construct models properly, most of the measures addressed the frequency of deep
modelling. During the training phase, on the measures “help button usage” and “correct on ﬁrst check” meta-tutored students scored
reliably higher than students who were not meta-tutored, except on experiment 3, which appears to have been underpowered. Moreover,
the effect sizes were large (d ¼ 0.89; d ¼ 0.98) or moderately larger (d ¼ 0.68). Thus, the AMT results for domain learning in the training
phase were nearly as good as those from Pyrenees, and substantially better than the other three meta-tutoring systems.
Unfortunately, neither the Target Node Strategy nor the domain learning advantages transferred. During the transfer phase, on the
measures “Run model button usage”, “extra nodes” and “Target Node Strategy usage”, the meta-tutored students were no better than the
students who had not been meta-tutored earlier, with one exception. On the measure “extra nodes” in experiment 4, meta-tutored students
outscored the control students. It is always difﬁcult to get learning to transfer from a supported context to an unsupported one, so this lack of
transfer should perhaps not be surprising. However, it does appear to be a bit weaker than the transfer obtained by Pyrenees, Betty’s Brain
and the Help Tutor.
In both the training and transfer phases, we attempted to measure deep modelling using efﬁciency: the amount of modelling done in a
ﬁxed period of time. This measurement made the tacit assumption that deep modelling is faster than shallow modelling. That is, thinking
hard to solve an atomic modelling problem should take less time than guessing, overusing the Give-up button, overusing the Run button,
scanning the problem statement for keywords and other shallow model construction tactics. However, the efﬁciency measures all produced
null results. If anything, there was trend for non-meta-tutored students to get more done than the meta-tutored students. This is consistent
with our informal analyses of the log data. It appears that guessing was actually quite a bit faster than thinking, especially in the training
phase when the Check button was enabled. Even when students could only use the Run Model button for feedback in the transfer phase,
guessing was fast because the models were so small for the ﬁrst few problems. After that, guessing became must less efﬁcient, but few
students got that far.
As the experience with Betty’s Brain and the Help Tutor shows, not every supposedly good learning strategy actually turns out to increase
domain learning. In the case of AMT, we have found a learning strategy that does increase domain learning, and thus deserves to be taught.
On the other hand, our method of teaching the learning strategy appears not to have had enough meta-cognitive or motivational impact
on students, because their gains while being meta-tutor did not persist when the meta-tutoring was turned off.
Thus, the next stage of the AMT project is to augment the instruction with an affective learning companion. Its job will be to persuade
students of the beneﬁts of using the Target Node Strategy and of not abusing the Check and Give-up buttons. The agent cannot use the
argument that the learning strategy and deep modelling will speed up the students’ work, because we have found that shallow modelling
strategies are actually faster at least on these simple problems. Thus, we plan on having the agent use Dweck’s well-known argument
(Dweck & Leggett, 1988) that the “mind is a muscle; the harder you exercise it, the stronger it becomes.” Our summer school students
presumably want stronger minds, so if they believe the agent, they should more often use both the learning strategy and deep modelling. In
order to make the agent easier to believe, we plan to use attribution shifting, empathy, rapport-building chit-chat, and other non-cognitive

216

L. Zhang et al. / Computers & Education 75 (2014) 196–217

Table 2
Comparison of four meta-tutors of model construction.
Meta-tutor

AMT
Pyrenees
Help Tutor
Betty’s Brain
Co-Lab

Training phase

Transfer phase

Knowledge/skill

Meta-strategy

Knowledge/skill

Meta-strategy

þ
þþ
NS
NS
NS

Required
Required
þ
þ
Required

þ
þþ
NS
þ

NS
NS
þ
þ

NS ¼ non-signiﬁcant difference, two-tailed. þ ¼ Signiﬁcant but weak. þþ ¼ Signiﬁcant and strong. Required ¼ meta-tutor required student to follow the learning strategy.

techniques. In order to optimize the timing and selection of these non-cognitive interventions, we plan to monitor the students’ affective
state using physiological sensors.
Lastly, by experiment 5, students seem to be acquiring decent amounts of competence in system dynamics modelling in only 1 h and
15 min total. This is a considerable reduction from the 5 or more hours required of Model-It students and others. Although we have no way
to actually compare our results to the early ones, because the systems, students, domains and almost everything else were quite different,
we nonetheless are quite encouraged. The combination of tutoring and meta-tutoring may be the key to getting model construction out into
the classrooms at last.
Acknowledgements
This material is based upon work supported by the National Science Foundation, United States (_100000001) under Grant No. 0910221.
References
Alessi, S. M.. (December 2000). The application of system dynamics modeling in elementary and secondary school curricula. In Paper presented at the RIBIE 2000 – The ﬁfth
Iberoamerican conference on informatics in education. Viña del Mar, Chile.
Aleven, V., McLaren, B., Roll, I., & Koedinger, K. (2004). Toward tutoring help seeking (applying cognitive modeling to help-seeking skills). In J. C. Lester, R. M. Vicari, &
F. Paraguacu (Eds.), Intelligent tutoring systems: Seventh international conference: ITS 2005 (pp. 227–239). Berlin: Springer.
Aleven, V., Stahl, E., Schworm, S., Fischer, F., & Wallace, R. M. (2003). Help seeking and help design in interactive learning environments. Review of Educational Research, 73(2),
277–320.
Baker, R. S. J. d., Corbett, A., & Koedinger, K. R. (2004). Detecting student misuse of intelligent tutoring systems. In Proceedings of the 7th international conference on intelligent
tutoring systems (pp. 531–540).
Baker, R. S., Corbett, A., Koedinger, K. R., Evenson, S., Roll, I., Wagner, A. Z., et al. (2006). Adapting to when students game an intelligent tutoring system. In Intelligent tutoring
systems (pp. 392–401). Berlin: Springer.
Baker, R. S. J. d., Corbett, A., Koedinger, K. R., & Wagner, A. Z. (2004). Off-task behavior in the cognitive tutor classroom: when students “game the system”. In E. DykstraErickson, & M. Tscheligi (Eds.), Proceedings of the SIGCHI conference on human factors in computing systems (pp. 383–390). New York, NY: ACM.
Biswas, G., Leelawong, K., Schwartz, D. L., & Vye, N. J. (2005). Learning by teaching: a new agent paradigm for educational software. Applied Artiﬁcial Intelligence, 19, 363–392.
Booth Sweeney, L., & Sterman, J. D. (2000). Bathtub dynamics: initial results of a systems thinking inventory. System Dynamics Review, 16(4), 249–286.
Bravo, C., van Joolingen, W. R., & de Jong, T. (2009). Using Co-Lab to build system dynamics models: students’ actions and on-line tutorial advice. Computer and Education, 53,
243–251.
Bredeweg, B., & Forbus, K. D. (2003). Qualitative modeling in education. AI Magazine, 24(4), 35–46.
Burleson, W., & Picard, R. W. (2007). Affective learning companions. Educational Technology, Special Issue on Pedagogical Agents, Saddle Brook, N.J., 47(1), 28–32.
CCSSO. (2011). The Common Core State Standards for mathematics. Downloaded from www.corestandards.org. on 31.10.11.
Chi, M., & VanLehn, K. (2010). Meta-cognitive strategy instruction in intelligent tutoring systems: how, when and why. Journal of Educational Technology and Society, 13(1), 25–
39.
Chin, D., Dohmen, I. I. M., Cheng, B. H., Oppezzo, M., Chase, C. C., & Schwartz, D. L. (2010). Preparing students for future learning with teachable agents. Educational Technology
Research and Development, 58, 649–669.
Clark, H. H., & Brennan, S. E. (1991). Grounding in communication. In L. B. Resnick, J. M. Levine, & S. D. Teasley (Eds.), Perspectives on socially shared cognition (pp. 127–149).
Washington, DC: American Psychological Association.
Collins, A., & Ferguson, W. (1993). Epistemic forms and epistemic games: structures and strategies to guide inquiry. Educational Psychologist, 28(1), 25–42.
Doerr, H. M. (1996). Stella ten-years later: a review of the literature. International Journal of Computers for Mathematical Learning, 1, 201–224.
Donker, A. S., de Boer, H., Kostons, D., Dignath van Ewijk, C. C., & van der Werf, M. P. C. (2014). Effectiveness of learning strategy instruction on academic performance: a metaanalysis. Educational Research Review, 11, 1–26.
Du Boulay, B., Avramides, K., Luckin, R., Martínez-Mirón, E., & Rebolledo-Méndez, G. (2010). Towards systems that care: a conceptual framework based on motivation,
metacognition and affect. International Journal of Artiﬁcial Intelligence in Education, 20(3), 197–229.
Dweck, C. S., & Leggett, E. L. (1988). A social-cognitive approach to motivation and personality. Psychological Review, 95(2), 256–273.
Gonzalez-Sanchez, J., Chavez-Echeagaray, M.-E., VanLehn, K., & Burleson, W. (2011). From behavioral description to a pattern-based model for intelligent tutoring systems. In
Paper presented at the Proceedings of the 18th international conference on pattern languages of programs (PLoP). Portland, OR.
Hashem, K., & Mioduser, D. (2011). The contribution of learning by modeling (LbM) to students’ understanding of complexity concepts. International Journal of e-Education, eBusiness, e-Management and e-Learning, 1(2), 151–157.
Hattie, J., Biggs, J., & Purdie, N. (1996). Effects of learning skills interventions on student learning: a meta-analysis of ﬁndings. Review of Educational Research, 66, 99–136.
Hestenes, D. (2007). Modeling theory for math and science education. In Paper presented at the ICTMA-13: The international community of teachers of mathematical modelling
and applications. Indiana, IL.
Hogan, K., & Thomas, D. (2001). Cognitive comparisons of students’ systems modeling in ecology. Journal of Science Education and Technology, 10(4), 319–345.
Lee, C. B., Jonassen, D., & Teo, T. (2011). The role of model building in problem solving and conceptual change. Interactive Learning Environments, 19(3), 247–265.
Leelawong, K., & Biswas, G. (2008). Designing learning by teaching agents: the Betty’s brain system. International Journal of Artiﬁcial Intelligence and Education, 18(3), 181–208.
Löhner, S., Van Joolingen, W. R., & Savelsbergh, E. R. (2003). The effect of external representation on constructing computer models of complex phenomena. Instructional
Science, 31, 395–418.
Mandinach, E. B., & Cline, H. F. (1994a). Classroom dynamics: Implementing a technology-based learning environment. Mahwah, NJ: Erlbaum.
Mandinach, E. B., & Cline, H. F. (1994b). Modeling and simulation in the secondary school curriculum: the impact on teachers. Interactive Learning Environments, 4(3), 271–289.
Marshall, S. P., Barthuli, K. E., Brewer, M. A., & Rose, F. E. (1989). Story problem solver: A schema-based system of instruction. San Diego, CA: Center for Research in Mathematics
and Science Education, San Diego State University.
Metcalf, S. J. (1999). The design of guided learner-adaptable scaffolding in interactive learning environment (Doctoral Dissertation). University of Michigan.
Metcalf, S. J., Krajcik, J., & Soloway, E. (2000). Model-It: a design retrospective. In M. J. Jacobson, & R. B. Kozma (Eds.), Innovations in science and mathematics education:
Advanced designs for technologies of learning (pp. 77–115).

L. Zhang et al. / Computers & Education 75 (2014) 196–217

217

Mulder, Y. G., Lazonder, A. W., de Jong, T., Anjewierden, A., & Bollen, L. (2011). Validating and optimizing the effects of model progression in simulation-based inquiry learning.
Journal of Science Education and Technology, 21, 722–729.
Muldner, K., Burleson, W., van de Sande, B., & VanLehn, K. (2011). An analysis of students’ gaming behaviors in an intelligent tutoring system: predictors and impacts. User
Modeling and User-Adapted Interaction, 21(1–2), 99–135.
Nathan, M. J. (1998). Knowledge and situational feedback in a learning environment for algebra story problem solving. Interactive Learning Environments, 5, 135–159.
National Research Council. (2012). A framework for K–12 science education: Practices, crosscutting concepts, and core ideas. Washington, DC: National Academies Press.
Richmond, B. M. (1985). STELLA: software for bringing system dynamics modeling to the other 98%. In Paper presented at the Proceedings of the 1985 international conference of
the System Dynamics Society: 1985 International system dynamics conference.
Roll, I., Aleven, V., McLaren, B., & Koedinger, K. R. (2007a). Can help seeking be tutored? Searching for the secret sauce of metacognitive tutoring. In Proceedings of the international conference on artiﬁcial intelligence in education (pp. 203–210). Amsterdam: IOS Press.
Roll, I., Aleven, V., McLaren, B., & Koedinger, K. R. (2007b). Designing for metacognition – applying cognitive tutor principles to the tutoring of help seeking. Metacognition and
Learning, 2(2).
Roll, I., Aleven, V., McLaren, B., & Koedinger, K. R. (2011). Improving students’ help-seeking skills using metacognitive feedback in an intelligent tutoring system. Learning and
Instruction, 267–280.
Roll, I., Aleven, V., McLaren, B., Ryu, E., Baker, R. S. J. d., & Koedinger, K. R. (2006). The Help Tutor: does metacognitive feedback improve student’s help-seeking actions, skills
and learning. In M. Ikeda, K. Ashley, & T.-W. Chan (Eds.), Intelligent tutoring systems: 8th International conference, its 2006 (pp. 360–369). Berlin: Springer.
Russell, S., & Norvig, P. (2009). Artiﬁcial intelligence: A modern approach (2nd ed.). Upper Saddle River, NJ: Prentice Hall.
Schecker, H. (1993). Learning physics by making models. Physics Education, 28, 102–106.
Segedy, J. R., Kinnebrew, J. S., & Biswas, G. (2012a). Relating student performance to action outcomes and context in a choice-rich learning environment. In S. A. Cerri,
W. J. Clancey, & G. Papadourakis (Eds.), Intelligent tutoring systems: 11th International conference its 2012 (pp. 505–510). Berlin: Springer-Verlag.
Segedy, J. R., Kinnebrew, J. S., & Biswas, G. (2012b). Supporting student learning using conversational agents in a teachable agent environment. In Paper presented at the
Proceedings of the 10th international conference of the learning sciences. Sydney, Australia.
Shih, B., Koedinger, K. R., & Scheines, R. (2008). A response time model for bottom-out hints as worked examples. In C. Romero, S. Ventura, M. Pechenizkiy, & R. S. J. d Baker
(Eds.), Handbook of educational data mining (pp. 201–211). Boca Raton, FL: Taylor & Francis.
Steed, M. (1992). Stella, a simulation construction kit: cognitive process and educational implications. Journal of Computers in Mathematics and Science Teaching, 11, 39–52.
Stratford, S. J. (1997). A review of computer-based model research in precollege science classroom. Journal of Computers in Mathematics and Science Teaching, 16(1), 3–23.
Tan, J., Biswas, G., & Schwartz, D. L. (2006). Feedback for metacognitive support in learning by teaching environments. In Proceedings of the twenty-eighth annual meeting of the
Cognitive Science Society. Mahwah, NJ: Erlbaum.
Tan, J., Wagster, J., Wu, Y., & Biswas, G. (2007). Effect of metacognitive support on student behaviors in learning by teaching environments. In R. Luckin, K. R. Koedinger, &
J. Greer (Eds.), Proceedings of the 13th international conference on artiﬁcial intelligence in education (pp. 650–652). Amsterdam: IOS Press.
Timms, M. J. (2007). Using item response theory (IRT) to select hints in an ITS. In R. Luckin, K. R. Koedinger, & J. Greer (Eds.), Artiﬁcial intelligence in education (pp. 213–221).
Amsterdam: IOS Press.
Treagust, D. F., Chittleborough, G., & Mamiala, T. (2002). Students’ understanding of the role of scientiﬁc models in learning science. International Journal of Science Education,
24(4), 357–368.
VanLehn, K. (2006). The behavior of tutoring systems. International Journal of Artiﬁcial Intelligence and Education, 16, 227–265.
VanLehn, K. (2013). Model construction as a learning activity: a design space and review. Interactive Learning Environments, 21(4), 371–413.
VanLehn, K., Burleson, W., Chavez-Echeagaray, M.-E., Christopherson, R., Gonzalez-Sanchez, J., Hastings, J., et al. (2011a). The level up procedure: how to measure learning
gains without pre- and post-testing. In T. Hirashima (Ed.), Proceedings of the 19th international conference on computers in education (pp. 96–100). Chiang-Mai, Thailand:
Asia-Paciﬁc Society for Computers in Education.
VanLehn, K., Burleson, W., Chavez-Echeagaray, M.-E., Christopherson, R., Gonzalez-Sanchez, J., Hastings, J., et al. (2011b). The affective meta-tutoring project: how to motivate
students to use effective meta-cognitive strategies. In Paper presented at the 19th International conference on computers in education. Chiang Mai, Thailand.
Vanlehn, K., & Chi, M. (2012). Adaptive expertise as acceleration of future learning: a case study. In P. J. Durlach, & A. Lesgold (Eds.), Adaptive technologies for training and
education. Cambridge: Cambridge University Press.
Wagster, J., Tan, J., Biswas, G., & Schwartz, D. L. (2007). How metacognitive feedback affects behavior in learning and transfer. In Paper presented at the 13th International
conference on artiﬁcial intelligence in education: Workshop on metacognition and self-regulated learning in ITSs. Marina del Rey, CA.
Wagster, J., Tan, J., Wu, Y., Biswas, G., & Schwartz, D. L. (2007). Do learning by teaching environments with metacognitive support help students develop better learning
behaviors?. In Proceedings of the twenty-sixth annual meeting of the Cognitive Science Society. Mahwah, NJ: Erlbaum.
Wheeler, J. L., & Regian, J. W. (1999). The use of a cognitive tutoring system in the improvement of the abstract reasoning component of word problem solving. Computers in
Human Behavior, 15, 243–254.
Wilensky, U. (2003). Statistical mechanics for secondary school: the GasLab multi-agent modeling toolkit. International Journal of Computers for Mathematical Learning, 8(1),
1–41.
Wilensky, U., & Reisman, K. (2006). Thinking like a wolf, a sheep, or a ﬁreﬂy: learning biology through constructing and testing computational theories – an embodied
modeling approach. Cognition and Instruction, 24(2), 171–209.
Zaraza, R., & Fisher, D. (1997). Introducing system dynamics into the traditional secondary curriculum: the CC-STADUS project’s search for leverage points. In Paper presented
at the 15th International system dynamics conference. Istanbul, Turkey.
Zaraza, R., & Fisher, D. (1999). Training system modelers: the NSF CC-STADUS and CC-SUSTAIN projects. In W. Feurzeig, & N. Roberts (Eds.), Modeling and simulation in science and
mathematics education (Vol. 1); (pp. 38–69). New York, NY: Springer.

2011 11th IEEE International Conference on Advanced Learning Technologies

How to Do Multimodal Detection of Affective States?
1

Javier Gonzalez-Sanchez1, Robert M. Christopherson1, Maria Elena Chavez-Echeagaray1,
David C. Gibson2, Robert Atkinson1, Winslow Burleson1

School of Computing, Informatics, and Decision Systems Engineering, 2School of Social Transformation
Arizona State University
Tempe, AZ USA
{javiergs, robert.christopherson, helenchavez, david.c.gibson, robert.atkinson, winslow.burleson}@asu.edu
Whether it is an empathetic attentive machine or trained
human tutor, any additional insight into how an individual is
feeling through the use of sensing devices can then be used
to improve their interactions with learners.

Abstract— The human-element is crucial for designing and
implementing interactive intelligent systems, and therefore on
instructional design. This tutorial provides a description and
hands-on demonstration for detection of affective states and a
description of devices, methodologies and tools necessary for
automatic detection of affective states. Automatic detection of
affective states requires that the computer sense information
that is complex and diverse, it can range from brain-waves
signals, and biofeedback readings to face-based and gesture
emotion recognition to posture and pressure sensing.
Obtaining, processing and understanding that information, to
create systems that improve learning, requires the use of
several sensing devices (and their perceiving algorithms) and
the application of software tools.

II.

This tutorial will provide its attendees with the
knowledge and clear understanding of some of the available
technologies, and how to use them to provide the computer
with the ability to sense and perceive affective states. It will
also provide information about data processing tools that can
be applied to work with that data. To conclude, some case
examples of the use of these technologies will be shown,
e.g., for data collection in research studies and for the
creation of affective tutoring systems.

Keywords- affective state; sensors; physiological activity;
student affect inference; empathetic systems; multimodal

I.

A. Sensing Devices
During the first part of the tutorial a hands-on
demonstration using inexpensive, easy to install, and widely
available devices will be demonstrate how to work with
different categories of sensing sources:

INTRODUCTION

One important way for systems to adapt to their
individual users is related with their ability to show empathy.
Being empathetic implies that the computer is able to
recognize user’s mental states and understand the implication
of those states. Empathy is related to and is influenced by
affective states. Detection of affective states is a step forward
to provide machines with the necessary intelligence to
identify and understand human emotions and then
appropriately interact with humans. This does not mean that
it is necessary to make machines feel these emotions, but
rather that machines can be equipped with hardware and
software to enable them to perceive users’ affective states
and then use this understanding to create more harmonic
interactions between humans and machines [1].
Within the context of educational environments, there is
a great deal of research showing that learning is more than
just a cognitive process [2]. In particular, the act of learning
is as much a motivational and affective task as it is a
demonstration of mental ability. Often the goal of a human
tutor is to not only help the learner gain knowledge, but to
help the learner identify how they feel and to continue
learning when frustrated [3]. Many computer-based tutors or
intelligent tutoring systems (ITS) have adopted models that
include both cognitive and affective capabilities. Until
recently much of the affective data gathered by ITS have
relied heavily on learner’s self-report of their affective state,
observation, or software data logs [4], but now many ITS
have started to include data from the physical manifestations
of affective states through the use of sensing devices [5].
978-0-7695-4346-8/11 $26.00 © 2011 IEEE
DOI 10.1109/ICALT.2011.206

TUTORIAL CONTENT

1) Physiological sensors: These are instruments that
provide information on the activity of physiological
functions. Arousal detection is shown as an example, using
a wireless and wearable device created by MIT and ASU
researchers.
2) Brain-computer interfaces: These are a particular
type of a physiological instrument that uses brainwaves as
information sources (electrical activity along the scalp
produced by the firing of neurons within the brain).
Emotiv© EPOC headset [6] device will be used to show
how to collect and work with this kind of data.
3) Face-based emotion recognition systems: These
systems infer affective states by capturing images of the
user’s facial expressions and head movements. The
capabilities of face-based emotion recognition systems are
showed using a simple 30 fps USB webcam and
MindReader [7], a MIT Media Lab software.
4) Eye-tracking systems: These are instruments that
measure eye positions and eye movement in order to detect
zones in which the user has particular interest in a specific
time and moment. Examples using Tobii© Eye Tracking
System [8] will be shown.
Using the information provided by these devices and
systems as input it is possible to measure in a quantitative
way the user experience.
654

data, the tutorial will describe the basis of a multimodal
approach that attendees can use to launch their own research
efforts.

B. Gathering Data: Filtering and Integration
The second part of the tutorial is a practical presentation
and discussion about software, techniques and
methodologies that are used to combine and integrate
information from the different categories of sensing sources.
This part provides an overview about: (a) approaches to filter
and integrate data (such as sampling rate unification); (b)
using ABE emotion recognition framework [9] to do filtering
and data integration; (c) integrating ABE framework to
support third-party systems becoming empathetic.

ACKNOWLEDGMENT
This research was supported by the Office of Naval
Research under Grant N00014-10-1-0143 awarded to Dr.
Robert Atkinson and by the National Science Foundation,
Award 0705554, IIS/HCC Affective Learning Companions:
Modeling and supporting emotion during teaching Dr.
Beverly Woolf and Dr. Winslow Burleson.

C. Analyzing Data
The third part of the tutorial is about data analysis, which
involves a variety of quantitative approaches, including
automated reverse engineering of dynamic systems,
clustering and classification. For reverse engineering
searches of the data, the Eureqa tool [10] is used to discover
mathematical expressions of the structural relationships in
the data records. For example, if a record holds information
about the physical and emotional behavior of an individual
who was engaged in a single experimental setting, Eureqa
could take all the available sources of data and reveal both
how the measure of engagement is calculated from specific
data streams as well as how other sensors may influence the
proposed emotional construct. For clustering and
classification approaches Weka [11], a tool that implements a
collection of machine learning algorithms for data mining
tasks, is used to explore the data composition and
relationships and derive useful knowledge from data records.

REFERENCES
[1]
[2]

R. W. Picard, Affective Computing, MIT Press, 1997.
B. du Boulay, “Towards a Motivationally-Intelligent Pedagogy: How
should an intelligent tutor respond to the unmotivated or the
demotivated?,” Proc. New Perspectives on Affect and Learning
Technologies, R. A. Calvo & S. D'Mello (Eds.), Springer-Verlag, in
press.
[3] M. R. Lepper, L.G. Aspinwall, D.L. Mumme and R.W. Chabay, “Self
perception and social-perception processes in tutoring: Subtle social
control strategies of expert tutors,” Proc. Self-Inference Processes:
The Ontario Symposium, J. M. Olson & M. P. Zanna (Eds.),
Lawrence Erlbaum Associates, 1990, Vol. 6, pp. 217-237.
[4] R.S.J. Baker, M.M.T Rodrigo and U.E. Xolocotzin, “The Dynamics
of Affective Transitions in Simulation Problem-solving
Environments,” Proc. Affective Computing and Intelligent
Interaction: Second International Conference (ACII ’07), A. Paiva, R.
Prada & R. W. Picard (Eds.), Springer-Verlag, Vol. Lecture Notes in
Computer Science 4738, pp. 666-677.
[5] I. Arroyo, D. G. Cooper, W. Burleson, F. P. Woolf, K. Muldner, and
R. Christopherson, “Emotion Sensors Go to School,” Proc. Artificial
Intelligence in Education: Building Learning Systems that Care: from
Knowledge Representation to Affective Modelling, (AIED 09), V.
Dimitrova, R. Mizoguchi, B. du Boulay & A. Grasser (Eds.), IOS
Press, July 2009, vol. Frontiers in Artificial Intelligence and
Applications 200, pp. 17-24.
[6] Emotiv - Brain Computer Interface Technology. Retrieved April 26,
2011, from http://www.emotiv.com.
[7] R. E. Kaliouby and P. Robinson, “Real-Time Inference of Complex
Mental States from Facial Expressions and Head Gestures,” Proc.
Conference on Computer Vision and Pattern Recognition Workshop
(CVPRW ‘04), IEEE Computer Society, June 2004, Volume 10, p.
154.
[8] Tobii Technology - Eye Tracking and Eye Control. Retrieved April
26, 2011, from http://www.tobii.com.
[9] J. Gonzalez-Sanchez, M.E. Chavez-Echeagaray, R. Atkinson, and W.
Burleson, “ABE: An Agent-Based Software Architecture for a
Multimodal Emotion Recognition Framework,” Proc. of 9th Working
IEEE/IFIP Conference on Software Architecture (WICSA ‘11), June
2011, in press.
[10] M. Schmidt, and H. Lipson, "Distilling Free-Form Natural Laws from
Experimental Data," Science, Vol. 324, no. 5923, pp. 81 - 85.
[11] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I.H.
Witten, “The WEKA Data Mining Software: An Update,” Proc.
SIGKDD Explorations, 2009, Volume 11, Issue 1.
[12] K. Avramides, and B. du Boulay, “Motivational Diagnosis in ITSs:
Collaborative, Reflective Self-Report,” Proc. Artificial Intelligence in
Education. Building Learning Systems that Care: From Knowledge
Representation to Affective Modelling, V. Dimitrova, R. Nizoguchi,
B. du Boulay & A. Graesser (Eds.), IOS Press, 2009, Vol. Frontiers in
Artificial Intelligence and Applications 200, pp. 587-589.

D. Usage Examples
The fourth and last part of the tutorial describes examples
of using affective state information to provide real-time and
archival data for both machine and human tutors as well as
their students. While most of the current use of emotion
recognition is within ITS development, there are also many
possible applications outside of computer-driven instruction.
By providing the psychophysiological data to an instructor,
they can improve their understanding of their students and
subsequently adapt instruction or learning materials. Recent
research has suggested that providing learners with access to
the same physiological data may help them monitor and/or
change how they manage their own learning [12].
III.

AUDIENCE

This tutorial is open to researchers, practitioners, and
educators interested in incorporating affective computing as
part of their adaptive and personalized technology toolbox.
IV.

CONCLUSIONS

The goal of this tutorial is to provide the attendees with
enough information and examples to enable them to start
their own investigations of the cognitive-affective elements
of learning [2]. While the tutorial will not present an
exhaustive list of all the methods available for collecting,
manipulating, analyzing and interpreting affective sensor

655

2013 Humaine Association Conference on Affective Computing and Intelligent Interaction

Multimodal Affect Recognition in Virtual Worlds:
Avatars Mirroring Users’ Affect
Javier Gonzalez-Sanchez1, Maria Elena Chavez-Echeagaray1, David Gibson2, Robert Atkinson1
1

Arizona State University, AZ, USA, 2Curtin University, Perth, Australia
javiergs@asu.edu, helenchavez@asu.edu, david.c.gibson@curtin.edu.au, robert.atkinson@asu.edu
bracelet (for arousal detection) [5], a chair with posture
sensing [6], and a mouse with pressure sensing [7]. Each
sensor is handled by an inference mechanism that reports
the following affects: the EEG headset infers excitement,
engagement/boredom, meditation, and frustration; facebased
recognition
infers
agreement/disagreement,
concentration, interest, thinking, and unsureness; the skin
conductance bracelet infers arousal; the chair sensor infers
interest; and mouse sensors infer frustration. Inference
mechanisms report their outputs to the hub, which: (1)
synchronizes them; (2) maps them in a continuous
emotional 3D space, where the axes are Pleasure, Arousal,
and Dominance (PAD) [8]; and (3) combines them in one
affect vector. The foundation of the affect recognition hub is
described in previous work [9], [10]. The PAD model is a
formalism to represent and interpret affect; it has been
previously used in real-time interactive systems because it
supports the representation of diverse and continuous
affective states over time [11].

Abstract— Virtual worlds enable users’ interactions through
avatars. Avatars embody individual characteristics from their
owners and exhibit those characteristics outward to the
community. Motivated by the role of avatars in interpersonal
communication, we integrated a generic real-time multimodal
affect recognition hub as an input within an online virtual
world to make an avatar mirror its owner’s affect. Affect
vectors (determined by pleasure, arousal, and dominance
coordinates) in a continuous affective space are applied to
characterize the user’s affective state in real time.
Keywords- affect recognition; affect mirroring; virtual
worlds; second life; multimodal; framework

I.

PROBLEM

Virtual worlds enable users’ interactions through avatars.
Users operate their avatars to explore the world, meet others,
socialize, participate in individual and group activities, and
even trade virtual goods and services with one another. Users
have a tendency to customize their avatars according to their
own appearance, which influences online interpersonal
communication, allowing more intimate engagement and
conversations with stronger interpersonal bonds [1].
However, as important as the avatar’s customization is to
reflect the owner’s appearance, it is more important to reflect
the owner’s affect (emotions, feeling, and moods). Mirroring
the owner’s affective expressions makes the avatar more
believable, likeable, trustable, and enjoyable, which creates
long-lasting social relationships and provides a suitable
environment where human users feel more comfortable [2].
This work shows the use of a generic, multimodal affect
recognition hub based on the state-of-the-art analysis of user
affective reactions and their interface with an online virtual
world. This demo serves as a test bed for our multimodal
affect recognition hub and allows data collection for
analyzing user experience in virtual worlds as well as the
later exploration of approaches to improve virtual
interactions.
II.

2) Online virtual world (white boxes). We chose to use
Second Life (SL), an online virtual world launched in 2003,
which has an active user base of about 600,000 people. SL
allows avatars to explore and interact. Exploration is similar
to traveling in the real world; avatars either search for places
of interest and then go there or decide to go to a random
place. Individuals can explore alone, but often small groups
explore together. Some exploration is spontaneous, but there
are also organized tours and even travel agents. Interaction

TECHNICAL CONTENT

The system to be demonstrated is composed of three
independent parts: the affect recognition hub, the virtual
world, and an interface between them. The structure of the
system is shown in Fig. 1, from right to left, as follows:
1) Affect recognition hub (gray boxes). Signals of a
user’s affect changes are gathered by diverse sensors. The
sensors included are an EEG headset [3], a web camera (for
face-based affect recognition) [4], a skin conductance
978-0-7695-5048-0/13 $26.00 © 2013 IEEE
DOI 10.1109/ACII.2013.133

Fig. 1. The user interacts with the virtual world by manipulating the avatar
with the keyboard and mouse; the multimodal affect recognition hub gathers
signals of the user’s affect changes, combines them, and projects the
inferred affect on the avatar by means of an interface.

724

occurs via text chat, text instant messaging, or voice, not
unlike the popular Internet applications, except that full 3D
visuals are usually included. Interaction is also behavioral,
such as when friends and acquaintances gather at a club to
dance or play while listening to recorded or live music [12].
Mouse and keyboard controls are used to move the avatar in
the virtual world. The mouse controls the camera and view
perspectives of the avatar, while the keyboard is used to
control the avatar’s movements and gestures.
3) Interface (dash pattern box). An interface module
connects the multimodal affect recognition hub and the
virtual world. The interface triggers native system input
events that change the avatar according to the affect vector
value. To simplify the demonstration, continuous 3D
affective vectors are discretized in four categories, not
including neutral, as shown in Fig. 2: frustrated (low
pleasure, high arousal, and low dominance), engaged (high
pleasure, high arousal, and high dominance), bored (low
pleasure, low arousal, and low dominance), and concentrated
(high pleasure, low arousal, and high dominance).
III.

Fig. 2. Affective vectors are discretized in four categories, besides neutral:
frustrated, engaged, bored, and concentrated. The avatar mirrors those
affects as showed.

EXPERIMENT

REFERENCES

Our exploratory study with avatars mirroring a user’s
affect while exploring and interacting in a virtual world aims
to answer three main questions: (1) does the user agree with
the emotion reflected by the avatar; (2) during a long session,
how does the user feel about having his or her feelings
uncovered; and (3) do the users agree that having their
avatars mirroring their affects increases the naturalness of the
interactions compared with traditional scenarios? In this
study, users will explore the virtual world by looking around
and interacting under two conditions: using an avatar with
affect connection and using an avatar without affect
connection. Users will fill out a post survey about the overall
experience. This research looks forward to potentially
improving human-computer interaction in virtual worlds by
exploring whether the moment-by-moment reflection of
affect is (1) feasible with a reasonable level of accuracy and
(2) usable in embedded, automated feedback to aid, guide, or
simply better understand the user.
IV.

[1]

A. Vasalou, A. N. Joinson, and J. Pitt, “Constructing my online self:
avatars that increase self-focused attention,” CHI 2007, vol. 1, pp.
445–448, Feb. 2007.
[2] T. W. Bickmore and R. W. Picard, “Establishing and maintaining
long-term human-computer relationships,” ACM Transactions on
Computer-Human Interaction (TOCHI), vol. 12, no. 2, pp. 293–327,
2005.
[3] Emotiv EPOC Headset. [Online]. Available: http://www.emotiv.com.
[Accessed: 14-Jul-2013].
[4] R. el Kaliouby and P. Robinson, “Generalization of a vision-based
computational model of mind-reading,” Affective Computing and
Intelligent Interaction, pp. 582–589, 2005.
[5] M. Strauss, C. Reynolds, S. Hughes, K. Park, G. McDarby, and R. W.
Picard, “The handwave bluetooth skin conductance sensor,” presented
at the ACII'05: Proceedings of the First international conference on
Affective Computing and Intelligent Interaction, 2005, pp. 699–706.
[6] S. Mota and R. W. Picard, “Automated Posture Analysis for
Detecting Learner's Interest Level,” Computer Vision and Pattern
Recognition Workshop, 2003. CVPRW'03., vol. 5, pp. 49–49, 2003.
[7] Y. Qi and R. W. Picard, “Context-Sensitive Bayesian Classifiers and
Application to Mouse Pressure Pattern Classification,” presented at
the Proceedings 16th International Conference on Pattern
Recognition, 2012, 2002, vol. 3.
[8] J. A. Russell, “A Circumplex Model of Affect,” Journal of Personality
and Social Psychhology, vol. 39, pp. 1161–1178, 1980.
[9] J. Gonzalez-Sanchez, M. E. Chavez-Echeagaray, R. K. Atkinson, and
W. Burleson, “Towards a Pattern Language for Affective Systems,”
Proceedings of the 19th Conference on Pattern Languages of
Programs, pp. 1–23, 2012.
[10] J. Gonzalez-Sanchez, M. E. Chavez-Echeagaray, R. Atkinson, and W.
Burleson, “Abe: An agent-based software architecture for a
multimodal emotion recognition framework,” pp. 187–193, 2011.
[11] S. W. Gilroy, M. Cavazza, and M. Benayoun, “Using affective
trajectories to describe states of flow in interactive art,” presented at
the Proceedings of the International Conference on Advances in
Computer Enterntainment Technology, New York, New York, USA,
2009, pp. 165–172.
[12] Second Life Official Site. [Online]. Available: http://secondlife.com.
[Accessed: 14-Jul-2013].

FUTURE WORK

This approach has potential implications for the broad
integration of affect recognition as a generic capability in
systems. We intended to make a first step forward to show
how our multimodal affect recognition hub could be adjusted
for diverse projects in a feasible and cost-effective way with
beneficial quality trade-offs.
ACKNOWLEDGMENT
This research was supported by the Office of Naval
Research through Grant N000141310438 awarded to Dr.
Robert Atkinson.

725

Affective	
  Computing	
  Meets	
  Design	
  Patterns:	
  A	
  Pattern-­‐Based	
  
Model	
  for	
  a	
  Multimodal	
  Emotion	
  Recognition	
  Framework	
   	
  
JAVIER	
  GONZALEZ-­‐SANCHEZ,	
  MARIA-­‐ELENA	
  CHAVEZ-­‐ECHEAGARAY,	
  	
  
ROBERT	
  ATKINSON,	
  AND	
  WINSLOW	
  BURLESON	
  
Arizona	
  State	
  University	
  	
  
There	
   is	
   a	
   growing	
   interest	
   in	
   how	
   to	
   leverage	
   information	
   about	
   users’	
   emotions	
   as	
   a	
   mean	
   of	
   personalizing	
   the	
   response	
   of	
   computer	
  
systems.	
   This	
   is	
   particularly	
   useful	
   for	
   computer-­‐aided	
   learning,	
   health,	
   and	
   entertainment	
   systems.	
   However,	
   there	
   are	
   few	
   architectures,	
  
frameworks,	
   libraries,	
   or	
   software	
   tools	
   that	
   allow	
   developers	
   to	
   easily	
   integrate	
   emotion	
   recognition	
   into	
   their	
   software	
   projects.	
   The	
  
work	
   reported	
   in	
   this	
   paper	
   offers	
   a	
   way	
   to	
   address	
   this	
   shortcoming	
   in	
   models	
   by	
   proposing	
   the	
   use	
   of	
   software	
   design	
   patterns	
   for	
  
modeling	
   a	
   multimodal	
   emotion	
   recognition	
   framework.	
   The	
   framework	
   is	
   designed	
   to:	
   (1)	
   integrate	
   existing	
   sensing	
   devices	
   and	
   SDK	
  
platforms,	
   (2)	
   include	
   diverse	
   inference	
   algorithms,	
   and	
   (3)	
   correlate	
   measurements	
   from	
   diverse	
   sources.	
   We	
   describe	
   our	
   experience	
  
using	
   this	
   model	
   and	
   its	
   impact	
   on	
   facets,	
   such	
   as	
   creating	
   a	
   common	
   language	
   among	
   stakeholders,	
   supporting	
   an	
   incremental	
  
development,	
  and	
  adjusting	
  to	
  a	
  highly	
  shifting	
  development	
  team,	
  as	
  well	
  as	
  the	
  qualities	
  achieved	
  and	
  trade-­‐offs	
  made.	
  
Categories	
   and	
   Subject	
   Descriptors:	
   D.2.10	
   [Software	
   Engineering]:	
   Design;	
   D.2.11	
   [Software	
   Engineering]:	
   Software	
   Architecture;	
  
H.1.2	
  [User/Machine	
  Systems]:	
  Human	
  Information	
  Processing;	
  
General	
  Terms:	
  Design,	
  Human	
  Factors	
  
Additional	
  Key	
  Words	
  and	
  Phrases:	
  Design	
  patterns,	
  emotion	
  recognition,	
  multimodal,	
  framework	
  
ACM	
  Reference	
  Format:	
  	
  
Gonzalez-­‐Sanchez,	
   J.,	
   Chavez-­‐Echeagaray,	
   M.E.,	
   Atkinson,	
   R.,	
   and	
   Burleson,	
   W.	
   2011.	
   Affective	
   Computing	
   Meets	
   Design	
   Patterns:	
   A	
  
Patterns-­‐Based	
  Model	
  of	
  a	
  Multimodal	
  Emotion	
  Recognition	
  Framework.	
  In	
  Proceedings	
  of	
  the	
  2011	
  Conference	
  on	
  Pattern	
  Languages	
  of	
  
Programming.	
  ACM	
  Press,	
  2011.	
  Article	
  27.	
  11	
  pages.	
  	
  

1. INTRODUCTION	
  
The	
  goal	
  of	
  affective	
  computing	
  is	
  to	
  enable	
  computer	
  systems	
  to	
  be	
  empathetic,	
  which	
  refers	
  to	
  the	
  ability	
  to	
  
accurately	
  recognize,	
  understand,	
  and	
  respond	
  to	
  human	
  emotions	
  (Picard	
  1997).	
  Enabling	
  computer	
  systems	
  
to	
   be	
   empathetic	
   involves	
   the	
   convergence	
   of	
   hardware	
   (e.g.	
   sensing	
   devices)	
   and	
   the	
   application	
   of	
   novel	
  
machine	
  learning	
  algorithms	
  to	
  deal	
  with	
  the	
  vast	
  amount	
  of	
  data	
  generated	
  by	
  the	
  sensing	
  devices.	
  There	
  are	
  
several	
  examples	
  of	
  research	
  conducted	
  on	
  creating	
  empathetic	
  computer	
  systems	
  to	
  support	
  learning	
  (Arroyo	
  
et	
  al.	
  2009,	
  Woolf	
  et	
  al.	
  2007,	
  D’Mello	
  et	
  al.	
  2007),	
  monitor	
  patient	
  in	
  health	
  care	
  (Chao	
  and	
  Zhiyong	
  2008),	
  and	
  
enhance	
   videogames	
   (Gilleade	
   et	
   al.	
   2005).	
   However,	
   the	
   majority	
   of	
   this	
   research	
   does	
   not	
   focus	
   on	
   the	
  
creation	
  of	
  reusable	
  software,	
  software	
  frameworks,	
  or	
  the	
  best	
  methodological	
  practices	
  for	
  those	
  purposes.	
  
Instead,	
   these	
   approaches	
   are	
   focused	
   on	
   creating	
   proof-­‐of-­‐concept	
   systems	
   to	
   collect	
   data	
   and	
   validate	
  
technology	
  approaches.	
  	
  
Software	
   design	
   patterns	
   are	
   used	
   as	
   a	
   general	
   reusable	
   solution	
   to	
   a	
   commonly	
   occurring	
   problem	
   in	
  
software	
   design	
   to	
   show	
   relationships	
   and	
   interactions	
   between	
   components	
   and	
   provide	
   a	
   skeleton	
   for	
   the	
  
implementation	
  (Gamma	
  et	
  al.	
  1995).	
  The	
  concept	
  of	
  patterns	
  has	
  received	
  relatively	
  little	
  attention	
  in	
  the	
  field	
  
of	
  Affective	
  Computing,	
  different	
  systems	
  and	
  models	
  of	
  emotion	
  recognition	
  systems	
  show	
  diverse	
  solutions	
  
for	
   design	
   problems	
   that	
   are	
   common	
   to	
   all	
   of	
   them;	
   even	
   when	
   a	
   closer	
   look	
   into	
   that	
   solutions	
   and	
   their	
  
comparison	
   often	
   shows	
   that	
   different	
   solutions	
   and	
   the	
   contexts	
   in	
   which	
   they	
   are	
   applied	
   have	
   much	
   in	
  
Author's	
  address:	
  Javier	
  Gonzalez-­‐Sanchez,	
  University	
  Drive	
  and	
  Mill	
  Avenue,	
  Tempe	
  AZ	
  85287;	
  email:	
  javiergs@asu.edu;	
  Author’s	
  address:	
  
Maria-­‐Elena	
   Chavez-­‐Echeagaray,	
   University	
   Drive	
   and	
   Mill	
   Avenue,	
   Tempe	
   AZ	
   85287;	
   email:	
   helenchavez@asu.edu;	
   Author's	
   address:	
  
Robert	
   Atkinson,	
   University	
   Drive	
   and	
   Mill	
   Avenue,	
   Tempe	
   AZ	
   85287;	
   email:	
   robert.atkinson@asu.edu;	
   Author’s	
   address:	
   Winslow	
  
Burleson,	
  University	
  Drive	
  and	
  Mill	
  Avenue,	
  Tempe	
  AZ	
  85287;	
  email:	
  winslow.burleson@asu.edu	
  	
  
	
  
Permission	
  to	
  make	
  digital	
  or	
  hard	
  copies	
  of	
  all	
  or	
  part	
  of	
  this	
  work	
  for	
  personal	
  or	
  classroom	
  use	
  is	
  granted	
  without	
  fee	
  provided	
  that	
  
copies	
  are	
  not	
  made	
  or	
  distributed	
  for	
  profit	
  or	
  commercial	
  advantage	
  and	
  that	
  copies	
  bear	
  this	
  notice	
  and	
  the	
  full	
  citation	
  on	
  the	
  first	
  page.	
  
To	
  copy	
  otherwise,	
  to	
  republish,	
  to	
  post	
  on	
  servers	
  or	
  to	
  redistribute	
  to	
  lists,	
  requires	
  prior	
  specific	
  permission	
  and/or	
  a	
  fee.	
  
	
  
EuroPLoP	
  '11,	
  July	
  13-­‐17,	
  2011,	
  Irsee	
  Monastery,	
  Bavaria,	
  Germany	
  
	
  
Copyright	
  ©	
  2012	
  ACM	
  978-­‐1-­‐4503-­‐1302-­‐5/11/07...	
  $15.00	
  
	
  

common.	
   In	
   that	
   context,	
   we	
   decided	
   to	
   standardize	
   an	
   object-­‐oriented	
   model	
   for	
   a	
   multimodal	
   emotion	
  
recognition	
  framework	
  using	
  design	
  patterns.	
  This	
  model	
  drives	
  the	
  way	
  in	
  which	
  emotion	
  recognition	
  could	
  
be	
   integrated	
   into	
   software	
   projects.	
   Our	
   choice	
   to	
   use	
   design	
   patterns	
   was	
   driven	
   by	
   our	
   interest	
   in:	
   (1)	
  
obtaining	
  a	
  common	
  vocabulary	
  among	
  diverse	
  stakeholders	
  in	
  order	
  to	
  improve	
  the	
  communication	
  process;	
  
(2)	
   sharing	
   of	
   constructions	
   between	
   developers	
   in	
   a	
   way	
   that	
   no	
   matter	
   what	
   is	
   being	
   built	
   or	
   what	
   others	
  
built,	
   everyone	
   is	
   aware	
   of	
   the	
   relationships	
   (connections)	
   among	
   different	
   constructions;	
   (3)	
  creating	
  
components	
  and	
  supporting	
   the	
  creation	
  of	
  families	
  of	
  products	
  for	
  use	
  in	
  prototype	
  and	
  usability	
  testing;	
   and	
  
(4)	
  	
   providing	
  a	
  “controlled”	
  freedom	
  to	
  the	
  programmers	
  because	
  they	
  can	
  develop	
  functionality	
  in	
  their	
  own	
  
creative	
  way,	
  while	
  still	
  following	
  and	
  preserving	
  the	
  guidelines	
  of	
  a	
  defined	
  design.	
  	
  
This	
   work	
   corresponds	
   to	
   the	
   second	
   of	
   three	
   stages	
   in	
   our	
   research	
   on	
   modeling	
   and	
   developing	
   a	
  
multimodal	
  emotion	
  recognition	
  framework:	
  (1)	
  in	
  the	
  first	
  stage,	
  we	
  worked	
  on	
  the	
  definition	
  of	
  a	
  software	
  
architecture	
  model;	
  (2)	
  in	
  the	
  second	
  stage,	
  described	
  in	
  this	
  paper,	
   we	
  shifted	
  from	
  that	
  software	
  architecture	
  
model	
  to	
  a	
  design	
  model	
  using	
  design	
  patterns;	
  and	
  (3)	
  in	
  the	
  third	
  stage,	
  we	
  will	
  be	
  focused	
  on	
  discovering	
  
patterns	
   (for	
   affective-­‐aware	
   systems)	
   either	
   composed	
   or	
   new	
   ones,	
   as	
   occurred	
   with	
   Customer	
   Iteration	
  
Patterns,	
   Pedagogical	
   Patterns,	
   and	
   Security	
   Patterns.	
   With	
   this	
   approach	
   we	
   seek	
   to	
   contribute	
   to	
   the	
   HCI	
  
community	
  by	
  moving	
  the	
  construction	
  of	
  systems	
  that	
  require	
  multimodal	
  emotion	
  recognition	
  from	
  software	
  
development	
   as	
   a	
   one-­‐of-­‐a-­‐kind	
   endeavor	
   to	
   software	
   development	
   as	
   a	
   system	
   of	
   components	
   that	
   are	
   widely	
  
used	
  and	
  highly	
  adaptable	
  (Jacobson	
  1997).	
  
This	
   paper	
   is	
   organized	
   as	
   follows:	
   Section	
   2	
   provides	
   background	
   on	
   the	
   system	
   and	
   software	
   architecture	
  
for	
  multimodal	
  emotion	
  recognition	
  systems;	
  Section	
  3	
  presents	
  a	
  pattern-­‐based	
  model,	
  specifying	
  the	
  design	
  
process	
  and	
  design	
  patterns	
  that	
  were	
  used;	
  Section	
  4	
  elaborates	
  on	
  our	
  experience	
  report,	
  as	
  well	
  as	
  on	
  the	
  
use	
   and	
   evaluation	
   of	
   the	
   framework;	
   finally,	
   Section	
   5	
   concludes	
   the	
   paper.	
   We	
   expect	
   practitioners	
   and	
  
developers	
  with	
  an	
  interest	
  in	
  integrating	
  emotion	
  recognition	
  into	
  their	
  software	
  projects	
  to	
  find	
  this	
  paper	
  
useful	
  as	
  a	
  reference	
  and	
  as	
  an	
  example	
  of	
  the	
  use	
  and	
  advantages	
  of	
  design	
  patterns.	
  For	
  the	
  software	
  design	
  
community,	
   this	
   is	
   an	
   experience	
   report	
   generated	
   by	
   a	
   research	
   group	
   using	
   design	
   patterns	
   to	
   improve	
   its	
  
software	
  process.	
  
	
  
2. BACKGROUND	
  
This	
   section	
   provides	
   background	
   on	
   multimodal	
   emotion	
   recognition	
   systems	
   by	
   describing	
   the	
   subjacent	
  
system	
  architecture,	
  the	
  software	
  architecture,	
  and	
  the	
  quality	
  attributes	
  required	
  from	
  them.	
  
	
  
2.1

System	
  Architecture	
  

The	
   functionality	
   of	
   a	
   multimodal	
   emotion	
   recognition	
   system	
   can	
   be	
   summarized	
   in	
   four	
   statements	
   listed	
  
below,	
   which	
   identify	
   the	
   involved	
   elements	
   and	
   relationships	
   between	
   elements.	
   In	
   the	
   list,	
   components’	
  
names	
   are	
   marked	
   in	
   bold	
   and	
   relationships	
   between	
   components	
   are	
   explained.	
   Figure	
   1	
   shows	
   these	
  
elements	
  and	
  their	
  relationships.	
  The	
  list	
  of	
  statements	
  is	
  as	
  follows:	
  
	
  
(1) Sensing	
  devices	
  obtain	
  data	
  from	
  the	
  user’s	
  physiological	
  responses	
  and	
  body	
  reactions.	
  Sensing	
  devices	
  
are	
   hardware	
   devices	
   that	
   collect	
   quantitative	
   data	
   as	
   measures	
   of	
   physiological	
   signals	
   of	
   emotional	
  
change.	
   We	
   call	
   the	
   measures	
   provided	
   by	
   the	
   sensing	
   devices	
   raw	
   data.	
   Our	
   approach	
   includes	
   the	
   use	
   of:	
  
brain-­‐computer	
  interfaces	
  (Emotiv	
  2011),	
  eye	
  tracking	
  systems	
  (Tobii	
  2011),	
  biofeedback	
  sensors	
   (Strauss	
  
et	
   al.	
   2005,	
   Mota	
   and	
   Picard	
   2003,	
   Qi	
   and	
   Picard	
   2002),	
   and	
   face-­‐based	
   emotion	
   recognition	
   systems	
   (El	
  
Kaliouby	
   and	
   Robinson	
   2005).	
   The	
   use	
   of	
   several	
   sensing	
   devices,	
   either	
   to	
   recognize	
   a	
   broad	
   range	
   of	
  
emotions	
  or	
  to	
  improve	
  the	
  accuracy	
  for	
  recognizing	
  one	
  emotion,	
  is	
  referred	
  to	
  as	
  a	
  multimodal	
  approach.	
  
(2) System	
   elements	
   called	
   data	
   sources	
   read	
   raw	
   data	
   from	
   the	
   sensing	
   devices.	
   The	
   raw	
   data	
   —after	
  
being	
   parsed,	
   filtered,	
   labeled,	
   and	
   time-­‐stamped—	
   becomes	
   sensed	
   values.	
   Table	
   1	
   provides	
   a	
   short	
  
description	
   of	
   each	
   sensing	
   device,	
   related	
   legacy	
   software,	
   related	
   inputs	
   (raw	
   data),	
   and	
   related	
   outputs	
  
(sensed	
  values).	
  
(3) Sensed	
   values	
   are	
   processed	
   by	
   system	
   elements,	
   called	
   specialists,	
   that	
   implement	
   perception	
  
mechanisms.	
   Perception	
   mechanisms	
   are	
   algorithms	
   that	
   infer	
   emotions	
   using	
   sensed	
   values	
   as	
   input	
  
and	
  that	
  provide	
  beliefs	
  about	
  their	
  particular	
  understanding	
  of	
  the	
  user’s	
  emotional	
  change	
  as	
  output.	
  The	
  

perception	
   mechanism	
   could	
   be	
   as	
   general	
   as	
   passing	
   a	
   threshold	
   or	
   as	
   complex	
   as	
   a	
   machine	
   learning	
  
data	
  processing	
  algorithm.	
  	
  
(4) 	
  Each	
   specialist	
   communicates	
   its	
   beliefs	
   to	
   a	
   common	
   control	
   unit,	
   called	
   Centre.	
   Centre	
   creates	
  
emotional	
  states’	
  reports	
  integrating	
  the	
  received	
  beliefs.	
  Emotional	
  states	
  represent	
  the	
  user’s	
  emotion	
  
in	
  a	
  time	
  t.	
  Centre	
  acts	
  as	
  the	
  representative	
  and	
  spokesman	
  of	
  the	
  multimodal	
  emotion	
  recognition	
  system	
  
with	
   third-­‐party	
   systems.	
   These	
   third-­‐party	
   systems	
   could	
   provide	
   functionality	
   to	
   the	
   sensed	
   user	
   (for	
  
example,	
   while	
   using	
   a	
   gaming	
   environment	
   or	
   a	
   tutoring	
   system)	
   or	
   share	
   information	
   with	
   social	
  
networks	
  or	
  other	
  collaborative	
  environments.	
  	
  
	
  

	
  

Fig.	
  1.	
  A	
  multimodal	
  emotion	
  recognition	
  system	
  involves:	
  sensing	
  devices	
  gathering	
  raw	
  data,	
  Data	
  Sources	
  processing	
  raw	
  data	
  into	
  
sensed	
  values,	
  Specialists	
  using	
  sensed	
  values	
  to	
  infer	
  emotions	
  and	
  reporting	
  their	
  beliefs	
  to	
  Centre.	
  
	
  
Table	
  1.	
  The	
  sensing	
  devices	
  and	
  legacy	
  software	
  integrated	
  into	
  the	
  multimodal	
  emotion	
  recognition	
  framework	
  include	
  devices	
  for:	
  brain	
  
waves,	
  eye	
  tracking,	
  physiological	
  signal	
  sensing,	
  and	
  facial	
  expression	
  analysis	
  
Sensing	
  device	
  
(rate	
  in	
  Hz)	
  

Legacy	
  
Software	
  

Emotiv©	
  EEG	
  
headset	
  
	
  (128	
  Hz)	
  

Emotiv©	
  SDK	
  

Sensing	
  
(input	
  or	
  
raw	
  data)	
  
Brain	
  waves	
  
	
  

Physiological	
  responses	
  and/or	
  Emotion	
  reported	
  	
  
(output	
  or	
  sensed	
  values)	
  
EEG	
  activity.	
  Reported	
  in	
  14	
  channels	
  (Sharbrough	
  et	
  al.	
  1991),	
  labeled:	
  AF3,	
  
F7,	
  F3,	
  FC5,	
  T7,	
  P7,	
  O1,	
  O2,	
  P8,	
  T8,	
  FC6,	
  F4,	
  F8,	
  and	
  AF4.	
  	
  
Face	
   activity.	
   Blink,	
   wink	
   (left	
   and	
   right),	
   look	
   (left	
   and	
   right),	
   raise	
   brow,	
  
furrow	
  brow,	
  smile,	
  clench,	
  smirk	
  (left	
  and	
  right),	
  and	
  laugh.	
  
Emotions.	
  Excitement,	
  engagement,	
  boredom,	
  meditation,	
  and	
  frustration.	
  

Standard	
  Webcam	
  
	
  (10	
  Hz)	
  

MIT	
  Media	
  Lab	
  
MindReader	
  
System	
  

Facial	
  
expressions	
  

Emotions.	
   Agreeing,	
   concentrating,	
   disagreeing,	
   interested,	
   thinking,	
   and	
  
unsure.	
  

MIT	
  skin	
  
conductance	
  sensor	
  
	
  (2	
  Hz)	
  
MIT	
  pressure	
  sensor	
  
	
  (6	
  Hz)	
  
Tobii©	
  Eye	
  tracking	
  
	
  (60	
  Hz)	
  
MIT	
  posture	
  sensor	
  
	
  (6	
  Hz)	
  

USB	
  driver	
  

Skin	
  
conductivity	
  

Arousal.	
  

USB	
  driver	
  

Pressure	
  

Tobii©	
  SDK	
  

Eye	
  tracking	
  

USB	
  driver	
  

Pressure	
  

One	
  pressure	
  value	
  per	
  sensor	
  allocated	
  into	
  the	
  input/control	
  device.	
  
Gaze	
  point	
  (x,	
  y).	
  
Pressure	
  values	
  in	
  the	
  back	
  and	
  the	
  seat	
  (in	
  the	
  right,	
  middle,	
  and	
  left	
  zones)	
  
of	
  a	
  cushion	
  chair.	
  

2.2 Software	
  Architecture	
  
The	
  software	
  architecture	
  behind	
  the	
  multimodal	
  emotion	
  recognition	
  system	
  described	
  above	
  was	
  created	
  in	
  
the	
  previous	
  stage	
  (stage	
  1)	
  of	
  this	
  project	
  and	
  is	
  described	
  in	
  a	
  previously	
  published	
  paper	
  (Gonzalez-­‐Sanchez	
  
et	
   al.	
   2011).	
   Due	
   to	
   space	
   limitations	
   only	
   a	
   subset	
   of	
   the	
   original	
   software	
   architecture	
   is	
   modeled	
   in	
   this	
  
paper.	
  As	
  a	
  reference,	
  that	
  subset	
  is	
  summarized	
  in	
  this	
  section.	
  
The	
   software	
   architecture,	
   as	
   shown	
   in	
   Figure	
   2,	
   follows	
   a	
   distributed	
   approach:	
   each	
   sensing	
   device	
   is	
  
connected	
   to	
   a	
   client	
   piece	
   of	
   software	
   (an	
   agent)	
   implemented	
   by	
   two	
   main	
   components	
   DataSource	
   and	
  
Specialist,	
  which	
  communicates	
  with	
  a	
  centralized	
  control	
  unit,	
  implemented	
  by	
  Centre	
  component.	
  
	
  

	
  

Fig.	
  2.	
  DataSource,	
  Specialist,	
  and	
  Centre	
  are	
  the	
  main	
  components	
  in	
  the	
  software	
  architecture	
  of	
  the	
  framework	
  

Data	
   Source.	
   DataSource	
   encapsulates	
   sensing	
   devices	
   or	
   legacy	
   software.	
   One	
   DataSource	
   component	
  
exists	
   for	
   each	
   sensing	
   device	
   and	
   legacy	
   software	
   listed	
   in	
   Table	
   1.	
   DataSource	
   creates	
   SensedValue	
   objects	
  
containing	
  the	
  information	
  gathered	
  from	
  the	
  sensing	
  devices,	
  including:	
  a	
  header,	
  composed	
  by	
  a	
  timestamp	
  
(in	
  milliseconds)	
  and	
  a	
  sensor	
  ID;	
  and	
  a	
  body,	
  composed	
  by	
  an	
  array	
  of	
  rational	
  numbers.	
  
Specialist.	
   Specialist	
   reads	
   SensedValue	
   objects	
   from	
   a	
   DataSource,	
   and	
   uses	
   them	
   to	
   build	
   Belief	
  
objects.	
  Specialist	
  has	
  two	
  responsibilities:	
  (1)	
  encapsulating	
  the	
  perception	
  mechanism	
  used	
  to	
  create	
  Belief	
  
objects;	
   and	
   (2)	
   establishing	
   the	
   communication	
   channel	
   with	
   Centre	
   to	
   send	
   Belief	
   objects	
   and	
   receive	
  
configuration	
   instructions.	
   The	
   communication	
   channel	
   is	
   a	
   TCP/IP	
   connection,	
   therefore	
   Specialist	
   and	
  
Centre	
  can	
  run	
  all	
  together	
  in	
  the	
  same	
  computer	
  or	
  distributed	
  among	
  several	
  computers.	
  
Centre.	
   Centre	
   acts	
   as	
   the	
   head	
   of	
   the	
   system	
   and	
   it	
   has	
   three	
   responsibilities:	
   (1)	
   establishing	
   the	
  
communication	
   channel	
   with	
  Specialist	
  to	
  receive	
   Belief	
  objects	
   and	
   to	
   send	
   configuration	
   instructions;	
   as	
  
said	
   before,	
   the	
   communication	
   channel	
   is	
   a	
   TCP/IP	
   connection;	
   (2)	
   conjugating,	
   in	
   one	
   record,	
   the	
   user’s	
  
emotional	
  state,	
  synchronizing	
  the	
  data	
  provided	
  by	
   Specialist	
  components;	
  (3)	
  implementing	
  the	
  service-­‐
oriented	
  behavior	
  that	
  allow	
  third-­‐party	
  systems	
  (such	
  as	
  loggers,	
  games,	
  and	
  tutoring	
  systems)	
  to	
  be	
  able	
  to	
  
contact	
   Centre	
  and	
  obtain	
  information	
  about	
  emotional	
  changes	
  in	
  the	
  user	
  in	
  a	
  publish-­‐subscribe	
  style.	
  For	
  
third-­‐party	
  systems	
  Centre	
  acts	
  as	
  a	
  facade	
  that	
  hides	
  the	
  internal	
  complexity	
  of	
  the	
  framework.	
  	
  
	
  
2.3

Software	
  Qualities	
  

Before	
  describing	
  the	
  migration	
  from	
  the	
  software	
  architecture	
  to	
  a	
  design	
  for	
  implementation,	
  it	
  is	
  important	
  
to	
  describe	
  the	
  software	
  qualities	
  that	
  drive	
  its	
  design	
  and	
  implementation:	
  	
  
	
  
(1) Reusability.	
  Framework	
  components	
  must	
  be	
  usable	
  for	
  the	
  implementation	
  of	
  other	
  products	
  with	
  slight	
  
or	
  no	
  modification.	
  	
  

(2) Extensibility.	
   Components	
   must	
   be	
   able	
   to	
   extend	
   the	
   framework’s	
   built-­‐in	
   functionality	
   incorporating	
  
new	
   functionalities.	
   The	
   framework	
   must	
   support	
   the	
   incorporation	
   of	
   new	
   sensing	
   devices	
   and	
   the	
  
integration	
  of	
  new	
  inference	
  and	
  data-­‐merging	
  algorithms.	
  	
  
(3) Flexibility.	
   Components	
   must	
   be	
   able	
   to	
   modify	
   existing	
   functionalities	
   and	
   adapt	
   the	
   framework	
   to	
   be	
  
used	
  in	
  applications	
  other	
  than	
  those	
  for	
  which	
  it	
  was	
  specifically	
  designed.	
  
(4) Low	
   latency.	
   The	
   faster	
   the	
   system	
   provides	
   information	
   about	
   user’s	
   emotional	
   state,	
   the	
   better	
   the	
  
provided	
   response	
   or	
   adjustment	
   of	
   the	
   third-­‐party	
   system	
   will	
   be.	
   The	
   user	
   experience	
   highly	
   depends	
   on	
  
allowing	
  unnoticeable	
  delays	
  between	
  reading	
  and	
  processing	
  the	
  sensed	
  data	
  and	
  reporting	
  information	
  
about	
  user’s	
  emotional	
  state.	
  
(5) Performance.	
  The	
  intention	
  is	
  to	
  create	
  the	
  framework	
  as	
  light	
  as	
  possible	
  in	
  order	
  to	
  be	
  able	
  to	
  run	
  in	
  the	
  
background	
   of	
   existing	
   systems.	
   Therefore,	
   the	
   goal	
   is	
   to	
   accomplish	
   functionality	
   constraining	
   memory	
  
and	
  CPU	
  usage.	
  	
  
	
  
Each	
  term	
  above	
  is	
  used	
  according	
  with	
  its	
  definition	
  in	
  the	
  IEEE	
  Standard	
  Glossary	
  of	
  Software	
  Engineering	
  
Terminology	
  (IEEE	
  1999).	
  	
  
The	
   use	
   of	
   patterns	
   becomes	
   the	
   keystone	
   to	
   satisfy	
   the	
   first	
   three	
   qualities	
   enumerated	
   above.	
   Design	
  
patterns	
   aim	
   to	
   take	
   previous	
   experiences	
   to	
   implement	
   non-­‐functional	
   requirements	
   and	
   to	
   avoid,	
   when	
  
properly	
  used,	
  accidental	
  complexity.	
  Satisfaction	
  of	
  the	
  last	
  two	
  requirements	
  (low	
  latency	
  and	
  performance)	
  
is	
  related	
  to	
  the	
  implementation	
  of	
  the	
  model	
  and	
  not	
  with	
  the	
  model	
  per	
  se.	
  	
  
3. PATTERN-­‐BASED	
  MODEL	
  
Finding	
   the	
   appropriate	
   pattern	
   to	
   be	
   applied	
   was	
   a	
   process	
   based	
   on	
   experience	
   and	
   literature	
   research	
  
(Buschmann	
  et	
  al.	
  1996,	
  Gamma	
  et	
  al.	
  1995,	
  Serial	
  2011,	
  Sinha	
  1996).	
  There	
  is	
  no	
  set	
  of	
  rules	
  on	
  how	
  to	
  choose	
  
a	
  pattern;	
  instead,	
  a	
  firm	
  knowledge	
  of	
  existing	
  patterns	
  as	
  well	
  as	
  the	
  problems	
  they	
  solve	
  is	
  required	
  in	
  order	
  
to	
   effectively	
   use	
   patterns	
   to	
   describe	
   what	
   happens	
   within	
   a	
   given	
   system.	
   Our	
   approach	
   consists	
   of	
   using	
   the	
  
pattern	
   that	
   most	
   closely	
   matches	
   the	
   semantic	
   description	
   of	
   the	
   requirement	
   or	
   group	
   of	
   requirements.	
  	
  
DataSource,	
  Specialist,	
  and	
  Centre	
  were	
  modeled	
  as	
  a	
  combination	
  of	
  design	
  patterns;	
  we	
  identified	
  the	
  parts	
  
that	
  would	
  be	
  variable	
  and	
  defined	
  if	
  they	
  were	
  related	
  with	
  the	
  structure	
  of	
  the	
  component,	
  the	
  behavior	
  or	
  
the	
  functionality	
  that	
  the	
  component	
  would	
  provide,	
  or	
  established	
  how	
  new	
  objects	
  would	
  be	
  created.	
  Table	
  2	
  
summarizes	
  the	
  patterns	
  we	
  used	
  to	
  implement	
  the	
  responsibilities	
  of	
  each	
  component,	
  as	
  described	
  in	
  section	
  
2.2.	
  	
  
	
  
Table	
  2.	
  Design	
  patterns	
  used	
  in	
  each	
  component	
  
Component	
  
DataSource	
  

Specialist	
  

Centre	
  

Responsibilities	
  
1.	
  Wrapping	
  legacy	
  software	
  
	
  
2.	
  Reading	
  sensing	
  devices	
  
	
  
1.	
  Encapsulating	
  perception	
  mechanism	
  
	
  
2.	
  Communicating	
  information	
  to	
  Centre	
  
	
  
1.	
  Receiving	
  information	
  from	
  Specialist	
  

Used	
  Design	
  Patterns	
  
ADAPTER	
  
	
  

SERIAL-PORT, DELEGATE
	
  

STRATEGY, ABSTRACT FACTORY
	
  

CLIENT-SERVER
	
  

CLIENT-SERVER
	
  

2.	
  Conjugating,	
  in	
  one	
  record,	
  the	
  user’s	
  emotional	
  state	
  
synchronizing	
  the	
  data	
  provided	
  by	
  the	
  Specialist.	
  
	
  
3.	
  Implementing	
  service-­‐oriented	
  behavior.	
  
	
  

BLACKBOARD, STRATEGY
	
  

PUBLISH-SUBSCRIBE, FACADE	
  
	
  

	
  
In	
   the	
   following	
   sections,	
   UML	
   class	
   diagrams	
   are	
  used	
   to	
   show	
   the	
   design	
   of	
   the	
   model.	
   For	
   clarity	
   and	
   due	
  
to	
   space	
   limitations,	
   the	
   diagrams	
   in	
   Figures	
   3,	
   4,	
   and	
   5	
   only	
   show	
   attributes	
   and	
   operations	
   related	
   with	
  
design	
   patterns	
   templates.	
   Attached	
   to	
   each	
   class	
   is	
   a	
   comment	
   (in	
   UML	
   notation)	
   that	
   indicates	
   the	
   role	
   of	
   the	
  
class	
   in	
   its	
   corresponding	
   design	
   pattern,	
   as	
   recommended	
   in	
   (Jing	
   et	
   al.	
   2007).	
   The	
   comment	
   shows	
   the	
   name	
  

of	
  the	
  design	
  pattern	
  and	
  the	
  equivalent	
  name	
  of	
  the	
  class	
  in	
  the	
  design	
  pattern	
  template	
  using	
  the	
  symbol	
  “::”	
  
as	
  delimiter.	
  
	
  
3.1

Data	
  Source	
  Component	
  

DataSource	
   component	
   was	
   compartmentalized	
   in	
   two	
   categories	
   defining	
   DataSource	
   as	
   interface	
   and	
  
specialize	
   DataSourceWrapper	
   and	
   DataSourceDriver	
   from	
   that	
   interface.	
   Figure	
   3	
   shows	
   the	
   UML	
   class	
  
diagram	
  for	
  DataSource	
  component.	
  

	
  

	
  

	
  
Fig.	
  3.	
  UML	
  class	
  diagram	
  for	
  DataSource	
  component.	
  DataSource	
  interface	
  is	
  compartmentalized	
  in	
  two	
  categories:	
  Wrappers	
  and	
  
Drivers.	
  Wrappers	
  use	
  ADAPTER	
  pattern	
  to	
  connect	
  with	
  SDK	
  platforms,	
  and	
  Drivers	
  use	
  SERIAL-PORT	
  and	
  DELEGATE	
  patterns	
  to	
  read	
  
raw	
  data	
  and	
  parse	
  it	
  into	
  sensed	
  values.	
  

DataSourceWrapper	
   class	
   encapsulates	
   legacy	
   software	
   that	
   provides	
   an	
   SDK	
   platform.	
   This	
   is	
   the	
   case	
   for	
  
Emotiv©	
   SDK,	
   Tobii©	
   SDK,	
   and	
   MIT	
   Media	
   Lab	
   MindReader	
   System.	
   To	
   integrate	
   those	
   SDK	
   libraries,	
   we	
  
incorporated	
   the	
   ADAPTER	
   pattern	
   (Gamma	
   et	
   al.	
   1995)	
   into	
   DataSourceWrapper.	
   This	
   creates	
   an	
  
intermediary	
   abstraction	
   that	
   translates	
   the	
   external	
   SDK	
   platform	
   (adaptee)	
   to	
   a	
   DataSourceWrapper	
  
(client).	
   Adapter	
   class	
   does	
   the	
   corresponding	
   calls	
   to	
   the	
   SDK	
   interfaces	
   to	
   obtain	
   sensed	
   values.	
  
Incorporating	
  a	
  new	
  SDK	
  requires	
  creating	
  a	
  new	
  Adapter	
  class	
  and	
  changes	
  into	
  the	
  SDK	
  (like	
  new	
  versions	
  of	
  
it)	
   implies	
   changes	
   only	
   on	
   its	
   corresponding	
   Adapter	
   class.	
   Adapter	
   classes	
   were	
   developed	
   for	
   Emotiv©	
  
SDK,	
  Tobii©	
  SDK,	
  and	
  MIT	
  Media	
  Lab	
  MindReader	
  System.	
  
DataSourceDriver	
   class	
   encapsulates	
   sensing	
   devices	
   that	
   use	
   serial	
   port	
   communication	
   with	
   the	
  
computer	
   (this	
   is	
   the	
   case	
   of	
   pressure,	
   posture,	
   and	
   skin	
   conductance	
   sensors).	
   To	
   handle	
   the	
   sensors’	
  
hardware	
   interface	
   and	
   to	
   read	
   raw	
   data	
   from	
   the	
   serial	
   port,	
   we	
   incorporated	
   the	
   SERIAL-PORT	
   pattern	
  
(Serial	
   2011)	
   into	
   the	
   DataSourceDriver	
   class.	
   Data	
   coming	
   from	
   the	
   serial	
   port	
   is	
   processed	
   by	
   a	
   sensing	
  
engine,	
   which	
   parses	
   the	
   raw	
   data	
   into	
   sensed	
   values.	
   The	
   DELEGATE	
   pattern	
   (Deugo	
   1998)	
   handles	
   the	
  
separation	
   of	
   the	
   perception	
   mechanism	
   from	
   the	
   rest	
   of	
   the	
   component.	
   We	
   developed	
   SensingEngine	
  
classes	
  for	
  the	
  pressure,	
  posture,	
  and	
  skin	
  conductance	
  sensors.	
  

3.2

Specialist	
  Component	
  

Specialist	
  component	
  implements	
  the	
  intelligence	
  of	
  the	
  system,	
  the	
  perception	
  mechanisms	
  that	
  converts	
  
SensedValue	
   objects	
   into	
   inferred	
   Belief	
   objects,	
   and	
   reports	
   them	
   to	
   the	
   central	
   unit,	
   Centre.	
   	
   Figure	
   4	
  
shows	
  the	
  UML	
  class	
  diagram	
  for	
  Specialist	
  component.	
  

	
  

Fig.	
  4.	
  UML	
  class	
  diagram	
  for	
  Specialist	
  component.	
  DataSource	
  component	
  provides	
  SensedValue	
  objects	
  to	
  Modeler	
  class.	
  
Modeler	
  class	
  uses	
  STRATEGY	
  and	
  ABSTRACT	
  FACTORY	
  patterns	
  to	
  create	
  Belief	
  objects.	
  The	
  Communicator	
  class	
  use	
  CLIENTSERVER	
  pattern	
  to	
  communicate	
  this	
  component	
  with	
  Centre	
  component.	
  

	
  

Modeler	
  class	
  is	
  the	
  part	
  of	
  the	
   Specialist	
  component	
  that	
  connects	
  it	
  with	
  the	
   DataSource	
  component	
  
to	
   read	
   SensedValues	
   objects.	
   Modeler	
   class	
   declares	
   a	
   DataSource	
   object.	
   Modeler	
   class	
   uses	
   the	
   class	
  
BeliefFactory	
  that	
  is	
  part	
  of	
  the	
   ABSTRACT	
   FACTORY	
  pattern	
  (Gamma	
  et	
  al.	
  1995)	
  to	
  create	
   Belief	
  objects	
  
from	
   SensedValues	
   objects.	
   The	
   factory	
   implements	
   perception	
   mechanisms	
   as	
   strategies,	
   thus	
   the	
  
PerceptionMechanism	
  class	
  implements	
  the	
  STRATEGY	
  pattern	
  (Gamma	
  et	
  al.	
  1995).	
  
Communicator	
  class	
  implements	
  what	
  is	
  needed	
  to	
  send	
  data	
  to	
   Centre,	
  realizing	
  the	
  client	
  part	
  of	
  client-­‐
server	
  model	
  (Sinha	
  1996)	
  between	
  Specialist	
  and	
  Centre	
  components.	
  	
  

	
  
3.3

Centre	
  Component	
  

Centre	
  component	
  provides	
  a	
  concurrent	
  control	
  mechanism	
  for	
  data	
  collection:	
  a	
  concurrent	
  data	
  structure	
  
in	
   which	
   each	
   Specialist	
   component	
   adds	
   information.	
   In	
   order	
   to	
   provide	
   its	
   functionality,	
   Centre	
  
implements	
   BLACKBOARD	
   pattern	
   (Buschmann	
   et	
   al.	
   1996)	
   under	
   its	
   variant	
   of	
   concurrent	
   access	
   repository.	
  
BLACKBOARD	
  pattern	
  provides	
  the	
  concurrent	
  data	
  structure	
  and	
  defines	
  two	
  elements	
  that	
  have	
  access	
  to	
  it:	
  
SpecialistAdvocate	
   class	
   and	
   Supervisor	
   class.	
   	
   Figure	
   5	
   shows	
   the	
   UML	
   class	
   diagram	
   for	
   Centre	
  
component.	
  	
  
SpecialistAdvocate	
  class	
  assumes	
  the	
  role	
  of	
  a	
  knowledge	
  source	
  in	
  the	
   BLACKBOARD	
  pattern	
  receiving	
  
Belief	
   objects	
   from	
   Specialist	
   components.	
   SpecialistAdvocate	
   class	
   uses	
   an	
   instance	
   of	
  
CommunicatorServer	
  class,	
  which	
  tackles	
  the	
  server	
  part	
  of	
  the	
  client-­‐server	
  model	
  (Sinha	
  1996).	
  

	
  

Fig.	
  5.	
  UML	
  class	
  diagram	
  for	
  Centre	
  component.	
  Centre	
  implements	
  BLACKBOARD	
  pattern	
  to	
  provide	
  a	
  concurrent	
  data	
  repository.	
  
STRATEGY	
  pattern	
  supports	
  the	
  process	
  to	
  convert	
  Belief	
  objects	
  into	
  EmotionalState	
  objects	
  and	
  FACADE	
  pattern	
  hides	
  the	
  
complexity	
  of	
  Centre.	
  PUBLISH-SUBSCRIBE	
  pattern	
  is	
  used	
  to	
  offer	
  a	
  publish-­‐subscribe	
  style	
  service	
  to	
  deliver	
  emotional	
  state	
  
information	
  to	
  third-­‐party	
  systems.	
  
	
  

Supervisor	
   class	
   takes,	
   from	
   the	
   BLACKBOARD,	
   the	
   Belief	
   objects	
   provided	
   by	
   all	
   SpecialistAdvocates	
  
and	
  integrates	
  them	
  into	
   EmotionalState	
  objects.	
   Supervisor	
  class	
  implements	
   STRATEGY	
  pattern	
  (Gamma	
  
et	
  al.	
  1995)	
  to	
  conjugate	
  individual	
   Belief	
  objects	
  in	
   EmotionalState	
  objects.	
   Editor	
  class	
  implements	
  the	
  
concrete	
  strategy;	
  strategies	
  deal	
  with	
  the	
  fact	
  that	
  high	
  rate	
  hardware	
  has	
  high	
  rate	
  of	
  changing	
  values.	
  The	
  
last	
  provided	
  values	
  are	
  used	
  until	
  new	
  ones	
  arrive.	
  	
  
Publisher	
   class	
   implements	
   the	
   publisher	
   part	
   of	
   a	
   PUBLISH-SUBSCRIBE	
   pattern	
   (Buschmann	
   et	
   al.	
   1996)	
  
to	
  provide	
  information	
  to	
  third-­‐party	
  systems	
  that	
  express	
  interest	
  in	
  this	
  information.	
  The	
  pattern	
  works	
  as	
  
an	
   OBSERVER	
  pattern	
  (Gamma	
  et	
  al.	
  1995)	
  but	
  in	
  a	
  distributed	
  environment	
  (publisher	
  and	
  subscriber	
  are	
  like	
  
subject	
   and	
   observers	
   allocated	
   in	
   different	
   places).	
   Publisher	
   class	
   also	
   acts	
   as	
   the	
   FACADE	
   (Gamma	
   et	
   al.	
  
1995)	
  that	
  hides	
  the	
  complexity	
  of	
  Centre	
  to	
  third-­‐party	
  systems.	
  
	
  

4. DISCUSSION	
  
In	
   our	
   modest-­‐sized	
   project,	
   we	
   leveraged	
   the	
   use	
   of	
   design	
   patterns	
   in	
   every	
   aspect	
   of	
   the	
   system	
   without	
  
forcing	
   their	
   use,	
   but	
   incorporated	
   them	
   whenever	
   it	
   seemed	
   prudent.	
   With	
   patterns,	
   we	
   addressed	
   the	
  
creation	
  of	
  the	
  framework	
  and	
  sought	
  to	
  incorporate	
  on	
  it	
  software	
  quality	
  factors	
  that	
  patterns	
  have	
  been	
  said	
  
to	
  have	
  positive	
  impact	
  on	
  (Gamma	
  et	
  al.	
  1995,	
  Khomh	
  and	
  Gueheneuc	
  2008).	
  The	
   particular	
   quality	
  attributes	
  
we	
  were	
  interested	
  in	
  are:	
  reusability,	
  extensibility,	
  and	
  flexibility,	
  as	
  well	
  as	
  understandability. These	
  qualities	
  
were	
   chosen	
   because	
   they	
   help	
   in	
   addressing	
   the	
   contextual	
   elements	
   mentioned	
   above:	
   incremental	
  
requirements,	
  changing	
  requirements,	
  and	
  a	
  shifting	
  development	
  team.	
  
Reusability.	
   Given	
   that	
   our	
   work	
   is	
   a	
   research	
   effort,	
   a	
   key	
   goal	
   in	
   our	
   group	
   was	
   to	
   create	
   reusable	
  
artifacts	
  to	
  use	
  them	
  in	
  future	
  not	
  well-­‐defined	
  projects.	
  Framework	
  components	
  have	
  been	
  used	
  with	
  slight	
  or	
  

no	
  modification	
  in	
  two	
  different	
  kinds	
  of	
  applications:	
  a	
  gaming	
  environment	
  study	
  and	
  an	
  intelligent	
  tutoring	
  
system	
  development	
  project.	
  For	
  the	
  gaming	
  environment	
  study,	
  students	
  were	
  asked	
  to	
  play	
  the	
  Guitar	
  Hero©	
  
videogame	
   (as	
   a	
   learning	
   experience)	
   while	
   their	
   emotional	
   status	
   was	
   measured.	
   The	
   framework	
   was	
   used	
   as	
  
an	
  independent	
  tool	
  where	
  publish-­‐subscribe	
  functionality	
  in	
   Centre	
  was	
  replaced	
  with	
  a	
   Logger	
  component	
  
(developed	
   for	
   this	
   experiment)	
   which	
   responsibility	
   was	
   to	
   store	
   the	
   received	
   information	
   in	
   an	
   online	
  
database	
   for	
   their	
   posterior	
   analysis.	
   This	
   implied	
   replacing	
   Publisher	
   class	
   with	
   a	
   Logger	
   class.	
   For	
   the	
  
intelligent	
   tutoring	
   system	
   development	
   project,	
   we	
   are	
   working	
   on	
   developing	
   an	
   affective	
   meta-­‐tutoring	
  
system,	
   integrating	
   our	
   framework	
   to	
   support	
   its	
   affective	
   part.	
   While	
   the	
   student	
   is	
   working	
   on	
   tasks,	
   the	
  
tutoring	
  system	
  collects	
  emotional	
  state	
  information	
  from	
   Centre	
  with	
  the	
  intention	
  of	
  being	
  able	
  to	
  generate	
  
better	
  and	
  more	
  accurate	
  hints	
  and	
  feedback,	
  as	
  well	
  as	
  affective	
  support	
  for	
  the	
  student,	
  in	
  order	
  to	
  reduce	
  the	
  
frustration	
  and	
  avoid	
  student	
  desertion.	
  	
  
Extensibility.	
   Framework components must be able to extend the framework built-­‐in	
   functionality	
  
incorporating	
   new	
   functionalities.	
   In	
   particular	
   ABSTRACT-FACTORY,	
   ADAPTER,	
   and	
   STRATEGY	
   patterns	
   were	
  
key	
  for	
  this	
  purpose	
  in	
  two	
  ways:	
  (1)	
  to	
  facilitate	
  doing	
  several	
  iterations	
  extending	
  functionality,	
  changing	
  or	
  
complementing	
  the	
  inference	
  or	
  data-­‐merging	
  algorithms	
  and	
  data	
  storage	
  strategies;	
  and	
  (2)	
  to	
  support	
  the	
  
incorporation	
   of	
   new	
   sensing	
   devices	
   and	
   the	
   incorporation	
   of	
   new	
   legacy	
   software.	
   For	
   example,	
   we	
   are	
  
considering	
   adding	
   the	
   BodyMedia	
   FIT	
   armband	
   (BodyMedia	
   2011)	
   to	
   measure	
   physical	
   activity	
   and	
   burned	
  
calories.	
  
Flexibility.	
   Framework	
   components	
   must	
   be	
   able	
   to	
   modify	
   existing	
   functionalities	
   and	
   adapt	
   the	
  
framework	
  to	
  be	
  used	
  in	
  applications	
  other	
  than	
  those	
  for	
  which	
  it	
  was	
  specifically	
  designed.	
  For	
  example,	
  in	
  
the	
   case	
   of	
   the	
   intelligent	
   tutoring	
   system	
   development	
   project,	
   described	
   above,	
   DataSources	
   and	
  
Specialist	
   components	
   were	
   used	
   as	
   they	
   are,	
   while	
   the	
   strategy	
   in	
   the	
   Centre	
   was	
   aimed	
   to	
   be	
  
implemented	
   ad-­‐hoc	
   through	
   a	
   Bayesian	
   Network.	
   Doing	
   so	
   requires	
   a	
   new	
   class	
   implementing	
  
StrategyEditor,	
  which	
  will	
  embed	
  an	
  open-­‐source	
  suite	
  for	
  Bayesian	
  Networks.	
  Another	
  example	
  is	
  a	
  mobile	
  
learning	
  project,	
  where	
  the	
  approach	
  is	
  to	
  replace	
   Centre	
  with	
  a	
  cloud-­‐based	
  solution	
  and	
  modify	
  the	
  agents	
  
(Specialist and DataSource)	
  to	
  become	
  a	
  mobile	
  application.	
  
Understandability.	
   The	
   use	
   of	
   patterns	
   increased	
   understandability	
   for	
   both	
   the	
   development	
   team	
   and	
  
stakeholders.	
   First,	
   for	
   the	
   development	
   team,	
   even	
   though	
   it	
   had	
   a	
   high	
   rotation	
   of	
   members,	
   we	
   were	
   able	
   to	
  
split	
   the	
   work	
   between	
   developers;	
   for	
   example:	
   a	
   given	
   developer	
   was	
   able	
   to	
   focus	
   on	
   implementing	
   one	
  
algorithm	
   even	
   without	
   the	
   knowledge	
   of	
   how	
   the	
   inputs	
   were	
   to	
   be	
   obtained	
   or	
   where	
   the	
   results	
   were	
   going	
  
to	
  be	
  used;	
  the	
  developer	
  then	
  implemented	
  and	
  tested	
  the	
  algorithm	
  into	
  the	
  system	
  by	
  implementing	
  them	
  
from	
  the	
  corresponding	
   ADAPTER	
  interface.	
  Second,	
   stakeholders	
  (researchers)	
  were	
  able	
  to	
  better	
  understand	
  
the	
   system.	
   Stakeholders’	
   concerns	
   were	
   less	
   about	
   programming	
   and	
   more	
   on	
   meeting	
   deadlines	
   for	
   each	
  
successive	
  version.	
  This	
  included	
  an	
  interest	
  in	
  knowing	
  how	
  the	
  work	
  was	
  delegated	
  and	
  how	
  the	
  resources	
  
(programmers	
   and	
   time)	
   would	
   be	
   used.	
   Even	
   when	
   stakeholders	
   were	
   not	
   familiar	
   with	
   design	
   patterns	
   or	
  
patterns	
  in	
  general,	
  the	
  terms	
  and	
  analogies	
  about	
   BLACKBOARD,	
  FACTORY,	
  STRATEGY	
  and	
  PUBLISH-SUBSCRIBE	
  
became	
  a	
  common-­‐ground	
  language	
  for	
  both	
  the	
  development	
  team	
  and	
  the	
  stakeholders.	
  Patterns	
  helped	
  us	
  
to	
  avoid	
  reinventing	
  the	
  wheel	
  on	
  how	
  to	
  modularize	
  our	
  framework.	
  
However,	
  any	
  given	
  dynamic	
  system	
  has	
  tradeoffs,	
  improving	
  one	
  quality	
  may	
  degrade	
  the	
  quality	
  in	
  other	
  
areas.	
   There are studies that note that patterns do not always improve qualities and the risk about using a lot of them
in one system (Khomh	
  and	
  Gueheneuc	
  2008,	
  and	
  Wendorff	
  2001).	
  However,	
  we	
  recognize	
  that	
  using	
  patterns	
  to	
  
model	
   a	
   software	
   design	
   with	
   a	
   well-­‐defined	
   software	
   architecture	
   helps	
   to	
   promote	
   the	
   desired	
   software	
  
qualities	
  with	
  only	
  a	
  modicum	
  of	
  negative	
  tradeoffs	
  in	
  latency	
  and	
  performance.	
  In	
  our	
  case,	
  the	
  decoupling	
  of	
  
components	
   in	
   agents	
   and	
   the	
   communication	
   model	
   between	
   Specialist	
   and	
   Centre,	
   slightly	
   increased	
  
latency	
  and	
  reduced	
  performance.	
  However,	
  they	
  stayed	
  at	
  levels	
  that	
  were	
  acceptable	
  for	
  the	
  purposes	
  of	
  the	
  
projects.	
  
Performance.	
   A	
   first	
   iteration	
   of	
   this	
   pattern-­‐based	
   model	
   was	
   implemented	
   in	
   Java	
   SE	
   6.	
   Five	
  
implementations	
   of	
   Specialist	
   components	
   (one	
   per	
   sensing	
   device)	
   and	
   the	
   Centre	
   component	
   were	
  
implemented	
  and	
  are	
  fully	
  functional.	
  Memory	
  load	
  and	
  CPU	
  usage	
  were	
  measured	
  and	
  used	
  as	
  performance	
  
indicators.	
   Table	
   3	
   shows	
   the	
   result	
   of	
   memory	
   load	
   and	
   processor	
   usage	
   running	
   each	
   of	
   the	
   Specialists	
   in	
  
a	
   system	
   with	
   the	
   following	
   characteristics:	
   Intel	
   Xeon	
   CPU	
   W3520	
   at	
   2.67	
   GHz	
   with	
   4	
   cores,	
   and	
   3.50	
   GB	
   of	
  
RAM	
   at	
   2.67GHz.	
   The	
   system	
   was	
   running	
   Windows	
   XP	
   Professional	
   with	
   Service	
   Pack	
   3.	
   It	
   is	
   important	
   to	
  

mention	
   that	
   for	
   Specialist	
   component	
   for	
   Emotiv©	
   SDK,	
   Tobii©	
   SDK,	
   and	
   MIT	
   Media	
   Lab	
   MindReader	
  
System	
  the	
  values	
  reported	
  in	
  Table	
  3	
  include	
  the	
  load	
  caused	
  by	
  the	
   Specialist	
  and	
  by	
  the	
  underlying	
  SDK	
  
system.	
  	
  
	
  
Table	
  3.	
  System	
  Performance	
  Test	
  Results	
  
Specialist	
  component	
  
Skin	
  

%	
  CPU	
  
8	
  -­‐	
  15	
  

Performance	
  
Memory	
  (Kb)	
  
14,100	
  -­‐	
  15,200	
  

Face	
  

34	
  -­‐	
  43	
  

60,000	
  -­‐	
  110,000	
  

Brain	
  (for	
  emotion)	
  

9	
  -­‐	
  16	
  

8,260	
  -­‐	
  8,500	
  

Brain	
  	
  (for	
  physiological	
  responses)	
  

6	
  -­‐	
  15	
  

7,200	
  -­‐	
  7,800	
  

Pressure	
  

8	
  -­‐	
  14	
  

15,900	
  -­‐	
  16,200	
  

Eye	
  

15	
  -­‐	
  25	
  

169,	
  500	
  -­‐	
  170,000	
  

	
  
Numbers	
  in	
  Table	
  3	
  indicate	
  acceptable	
  operation	
  levels	
  in	
  lab	
  and	
  classroom	
  computers.	
  	
  
An	
   additional	
   dispute	
   emerged	
   with	
   stakeholders	
   regarding	
   size.	
   Stakeholders	
   point	
   to	
   the	
   increase	
   in	
   lines	
  
of	
  code	
  while	
  using	
  patterns	
  as	
  an	
  issue.	
  While	
  using	
  patterns	
  generates	
  more	
  code	
  in	
  our	
  project,	
  this	
  is	
  not	
  
only	
  due	
  to	
  patterns	
  (interfaces	
  and	
  abstract	
  classes	
  declarations),	
  but	
  also	
  because	
  we	
  decided	
  to	
  maintain	
  the	
  
cyclomatic	
   complexity	
   (McCabe	
   1976)	
   for	
   every	
   method	
   under	
   10,	
   which	
   means	
   applying	
   a	
   “divide	
   and	
  
conquer”	
  strategy	
  that	
  generates	
  more	
  methods	
  in	
  the	
  system.	
  
	
  
5. CONCLUSIONS	
  AND	
  ONGOING	
  WORK	
  
This	
  paper	
  is	
  an	
  attempt	
  to	
  increase	
  the	
  affective	
  computing	
  community's	
  awareness	
  of	
  the	
  benefits	
  of	
  using	
  
design	
   patterns	
   for	
   modeling	
   emotional-­‐aware	
   software	
   and	
   developing	
   empathetic	
   systems.	
   This	
   work	
  
represents	
  a	
  significant	
  step	
  forward	
  addressing	
  the	
  lack	
  of	
  models,	
  libraries,	
  and	
  tools	
  to	
  develop	
  multimodal	
  
emotion	
  recognition	
  systems	
  and	
  alleviate	
  some	
  of	
  the	
  complexity	
  in	
  the	
  process.	
  
The	
  proposed	
  framework,	
  designed	
  as	
  a	
  collection	
  of	
  design	
  patterns,	
  offers	
  an	
  option	
  to	
  achieve	
  large-­‐scale	
  
implementation	
   and	
   integration	
   of	
   emotional-­‐aware	
   support	
   for	
   computers	
   systems.	
   It	
   is	
   focused	
   on	
   achieving	
  
the	
  creation	
  of	
  reusable,	
  flexible,	
  and	
  extensible	
  components,	
  although,	
  there	
  are	
  trade-­‐offs	
  between	
  qualities	
  
achieved	
  and	
  the	
  performance,	
  latency,	
  and	
  size	
  of	
  the	
  system.	
  
This	
  experience	
  report	
  demonstrates	
  how	
  design	
  patterns	
  can	
  help	
  to	
  improve	
  understandability	
  between	
  
stakeholders	
   and	
   developers	
   and	
   also	
   the	
   management	
   of	
   work	
   assignment	
   in	
   research-­‐focused	
   projects,	
  
particularly	
   those	
   with	
   the	
   potential	
   for	
   high	
   turnover	
   in	
   developers.	
   Our	
   future	
   efforts	
   will	
   focus	
   on	
   (1)	
  
discovering	
  affective	
  computing	
  design	
  patterns	
  and	
  documenting	
  them	
  in	
  a	
  pattern	
  language	
  for	
  the	
  domain	
  of	
  
affective	
   computing,	
   (2)	
   describing	
   good	
   design	
   models	
   and	
   practices	
   within	
   this	
   field	
   to	
   help	
   designers	
  
building	
   empathetic	
   systems	
   in	
   the	
   future,	
   and	
   (3)	
   supporting	
   the	
   integration	
   of	
   emotional-­‐awareness	
  
capabilities	
  in	
  modern	
  software	
  systems.	
  
	
  
6. ACKNOWLEDGEMENTS	
  
We	
   are	
   grateful	
   to	
   James	
   Siddle	
   for	
   his	
   support	
   during	
   the	
   writing	
   process	
   of	
   this	
   paper.	
   This	
   research	
   was	
  
supported	
  by	
  Office	
  of	
  Naval	
  Research	
  under	
  Grant	
  N00014-­‐10-­‐1-­‐0143	
  awarded	
  to	
  Dr.	
  Robert	
  Atkinson.	
  
	
  
	
  
	
  
	
  

REFERENCES	
  
	
  
ALEXANDER,	
  C.,	
  Ishikawa,	
  S.,	
  Silverstein,	
  M.,	
  et	
  al.	
  1997.	
  A	
  Pattern	
  Language.	
  Oxford	
  University	
  Press.	
  
ARROYO,	
   I.,	
   Cooper,	
   D.	
   G.,	
   Burleson,	
   W.,	
   Woolf,	
   B.	
   P.,	
   Muldner,	
   K.,	
   and	
   Christopherson,	
   R.	
   2009.	
   Emotion	
   Sensors	
   Go	
   to	
   School.	
   In	
   V.	
  
Dimitrova,	
   R.	
   Mizoguchi,	
   B.	
   du	
   Boulay	
   &	
   A.	
   Grasser	
   (Eds.),	
   Artificial	
   Intelligence	
   in	
   Education.	
   Building	
   Learning	
   Systems	
   that	
   Care:	
   from	
  
Knowledge	
  Representation	
  to	
  Affective	
  Modelling	
  (Vol.	
  Frontiers	
  in	
  Artificial	
  Intelligence	
  and	
  Applications	
  200),	
  IOS	
  Press,	
  17—24.	
  
BODYMEDIA	
  FIT.	
  2011.	
  http://www.bodymedia.com/	
  
BUSCHMANN,	
  F.,	
  Meunier,	
  R.,	
  Rohnert,	
  H.,	
  Sommerlad,	
  P.,	
  and	
  Stal,	
  M.	
  1996.	
  A	
  system	
  of	
  patterns:	
  Pattern-­‐oriented	
  software	
  architecture.	
  
Wiley.	
  
CHAO,	
   X.	
   and	
   Zhiyong,	
   F.	
   2008.	
   A	
   Trusted	
   Affective	
   Model	
   Approach	
   to	
   Proactive	
   Health	
   Monitoring	
   System.	
   In	
   Proceedings	
   of	
   the	
   2008	
  
International	
  Seminar	
  on	
  Future	
  BioMedical	
  Information	
  Engineering.	
  FBIE	
  '08,	
  IEEE	
  Computer	
  Society.	
  429—432.	
  
DEUGO,	
  D.	
  1998.	
  Foundation	
  Patterns.	
  In	
  Proceedings	
  of	
  Fifth	
  Pattern	
  Languages	
  of	
  Programs	
  Conference.	
  Allerton	
  Park,	
  Illinois.	
  
D'MELLO,	
  S.,	
  Picard,	
  R.	
  W.,	
  and	
  Graesser,	
  A.	
  2007.	
  Toward	
  an	
  Affect-­‐Sensitive	
  AutoTutor.	
  In	
  IEEE	
  Intelligent	
  Systems,	
  (Vol.	
  22	
  no.	
  4),	
  53—
61.	
  
EL	
   KALIOUBY,	
   R.	
   and	
   Robinson,	
   P.	
   2005.	
   Generalization	
   of	
   a	
   vision-­‐based	
   computational	
   model	
   of	
   mind-­‐reading.	
   In	
   Proceedings	
   of	
   First	
  
International	
  Conference	
  on	
  Affective	
  Computing	
  and	
  Intelligent	
  Interaction.	
  ACII’05,	
  Springer-­‐Verlang,	
  582—589.	
  	
  
EMOTIV	
  -­‐	
  Brain	
  Computer	
  Interface	
  Technology.	
  2011.	
  http://www.emotiv.com.	
  
GAMMA,	
  E.,	
  Helm,	
  R.,	
  Johnson,	
  R.,	
  and	
  Vlissides,	
  J.	
  1995.	
  Design	
  Patterns:	
  Elements	
  of	
  Reusable	
  Object-­‐Oriented	
  Software.	
  Addison-­‐Wesley	
  
Longman	
  Publishing	
  Co.,	
  Inc.,	
  Boston,	
  MA,	
  USA.	
  
GILLEADE,	
  K.,	
  Dix,	
  A.,	
  and	
  Allanson,	
  J.	
  2005.	
  Affective	
  Videogames	
  and	
  Modes	
  of	
  Affective	
  Gaming:	
  Assist	
  Me,	
  Challenge	
  Me,	
  Emote	
  Me.	
  In	
  
Proceedings	
  of	
  Digital	
  Games	
  Research	
  Association.	
  DIGRA'05,	
  16—20.	
  	
  
GONZALEZ-­‐SANCHEZ,	
   J.,	
   Chavez-­‐Echeagaray,	
   M.E.,	
   Atkinson,	
   R.,	
   and	
   Burleson,	
   W.	
   2001.	
   An	
   Agent-­‐Based	
   Software	
   Architecture	
   for	
   a	
  
Multimodal	
  Emotion	
  Recognition	
  Framework.	
  In	
   Proceedings	
  of	
  2011	
  Ninth	
  Working	
  IEEE/IFIP	
  Conference	
  on	
  Software	
  Architecture.	
  
WICSA'11,	
  IEEE	
  Computer	
  Society.	
  187—193.	
  
IEEE:	
  Standard	
  Glossary	
  of	
  Software	
  Engineering	
  Terminology.	
  1999.	
  610.12-­‐1990,	
  (Vol.1).	
  IEEE	
  Press.	
  
JING,	
  D.,	
  Sheng,	
  Y.,	
  and	
  Kang,	
  Z.	
  2007.	
  Visualizing	
  design	
  patterns	
  in	
  their	
  applications	
  and	
  compositions.	
  IEEE	
  Transactions	
  on	
  Software	
  
Engineering,	
  33	
  (7),	
  433—453.	
  
JOHNSON,	
  R.E.	
  1997.	
  Components,	
  frameworks,	
  patterns.	
  Harandi,	
  M.	
  (Ed.).	
  In	
  Proceedings	
  of	
  the	
  1997	
  symposium	
  on	
  Software	
  reusability.	
  
SSR	
  '97,	
  ACM,	
  10—17.	
  
KHOMH,	
   F.,	
   and	
   Gueheneuc,	
   Y.	
   G.	
   2008.	
   Do	
   Design	
   Patterns	
   Impact	
   Software	
   Quality	
   Positively?	
   In	
   Proceedings	
   of	
   12th	
   European	
  
Conference	
  on	
  Software	
  Maintenance	
  and	
  Reengineering.	
  CSMR’08,	
  274—278.	
  
MOTA,	
  S.,	
  and	
  Picard,	
  R.	
  W.	
  2003.	
  Automated	
  Posture	
  Analysis	
  for	
  Detecting	
  Learners	
  Interest	
  Level.	
  In	
   Proceedings	
  of	
  Computer	
  Vision	
  
and	
  Pattern	
  Recognition	
  Workshop.	
  CVPRW‘03,	
  IEEE	
  Press.	
  (Vol.	
  5),	
  49.	
  
PICARD,	
  R.	
  W.	
  1997.	
  Affective	
  Computing,	
  MIT	
  Press.	
  
QI,	
   Y.,	
   and	
   Picard,	
   R.	
   W.	
   2002.	
   Context-­‐Sensitive	
   Bayesian	
   Classifiers	
   and	
   Application	
   to	
   Mouse	
   Pressure	
   Pattern	
   Classification.	
   In	
  
Proceedings	
  of	
  International	
  Conference	
  on	
  Pattern	
  Recognition.	
  ICPR’02,	
  (Vol.	
  3),	
  30448.	
  
SERIAL	
  Port	
  Design	
  Pattern.	
  2011.	
  http://www.eventhelix.com/RealtimeMantra/PatternCatalog/serial_port_design_pattern.htm.	
  
SHARBROUGH	
  F,	
  Chatrian	
  G-­‐E,	
  Lesser	
  RP,	
  Lüders	
  H,	
  Nuwer	
  M,	
  and	
  Picton	
  TW.	
  1991.	
  American	
  Electroencephalographic	
  Society	
  Guidelines	
  
for	
  Standard	
  Electrode	
  Position	
  Nomenclature.	
  In	
  J.	
  Clin.	
  Neurophysiol,	
  (Vol.	
  8),	
  200—202.	
  
SINHA,	
  A.	
  1992.	
  Client-­‐server	
  computing.	
  In	
  Communications	
  of	
  the	
  ACM.	
  (Vol.	
  35),	
  77—98.	
  
STRAUSS,	
   M.,	
   Reynolds,	
   C.,	
   Hughes,	
   S.,	
   Park,	
   K.,	
   McDarby,	
   G.,	
   and	
   Picard,	
   R.W.	
   2005.	
   The	
   HandWave	
   Bluetooth	
   Skin	
   Conductance	
   Sensor.	
   In	
  
Proceedings	
  of	
  First	
  International	
  Conference	
  on	
  Affective	
  Computing	
  and	
  Intelligent	
  Interaction.	
  ACII’05.	
  Springer-­‐Verlang.	
  699—706.	
  	
  
TOBII	
  Technology	
  -­‐	
  Eye	
  Tracking	
  and	
  Eye	
  Control.	
  2011.	
  http://www.tobii.com.	
  
WENDORFF,	
  P.:	
  Assessment	
  of	
  design	
  patterns	
  during	
  software	
  reengineering:	
  Lessons	
  learned	
  from	
  a	
  large	
  commercial	
  project.	
  Sousa,	
  P.	
  
and	
   Ebert,	
   J.	
   (Eds.),	
   In	
   Proceedings	
   of	
   5th	
   Conference	
   on	
   Software	
   Maintenance	
   and	
   Reengineering.	
   IEEE	
   Computer	
   Society	
   Press,	
   77–84	
  
(2001)	
  
WOOLF,	
   B.,	
   Burelson,	
   W.,	
   and	
   Arroyo,	
   I.	
   2007.	
   Emotional	
   Intelligence	
   for	
   Computer	
   Tutors.	
   In	
   Supplementary	
   Proceedings	
   of	
   the	
   13th	
  
International	
  Conference	
  on	
  Artificial	
  Intelligence	
  in	
  Education.	
  AIED	
  ‘07,	
  6—15.	
   	
  

Copyright	
  ©	
  2012	
  ACM	
  978-­‐1-­‐4503-­‐1302-­‐5/11/07...	
  $15.00	
  
	
  

ISWC '14 ADJUNCT, SEPTEMBER 13 - 17, 2014, SEATTLE, WA, USA

Including Affect-Driven Adaptation to
the Pac-Man Video Game
Abstract
Ahbiya Harris

Alyza Villa

Arizona State University

Arizona State University

University Drive and Mill Avenue

University Drive and Mill Avenue

Tempe, AZ 85281, USA
ahharris@asu.edu

Tempe, AZ 85281, USA
agvilla3@asu.edu

Andrew Hoch

Maria Elena Chavez-Echeagaray

Arizona State University

Arizona State University

University Drive and Mill Avenue

University Drive and Mill Avenue

Tempe, AZ 85281, USA

Tempe, AZ 85281, USA

ahoch@asu.edu

helenchavez@asu.edu

Ryan Kral

Javier Gonzalez-Sanchez

Arizona State University

Arizona State University

University Drive and Mill Avenue

University Drive and Mill Avenue

Tempe, AZ 85281, USA

Tempe, AZ 85281, USA

rdkral@asu.edu

javiergs@asu.edu

Michael Teposte

Robert K. Atkinson

Arizona State University

Arizona State University

University Drive and Mill Avenue

University Drive and Mill Avenue

Tempe, AZ 85281, USA

Tempe, AZ 85281, USA

mteposte@asu.edu

Robert.atkinson@asu.edu

Permission to make digital or hard copies of part or all of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that
copies bear this notice and the full citation on the first page. Copyrights
for third-party components of this work must be honored. For all other
uses, contact the Owner/Author.
Copyright is held by the owner/author(s).
ISWC'14 Adjunct, September 13 – 17, 2014, Seattle, WA, USA
ACM 978-1-4503-3048-0/14/09.
http://dx.doi.org/10.1145/2641248.2641360

1

Building affect-driven adaptive environments is a task
geared toward creating environments able to change
based on the affective state of a target user. In our
project, the environment is the well-known game, PacMan. To provide affect-driven adaptive capabilities,
diverse sensors were utilized to gather a user’s
physiological data and an emotion recognition
framework was used to fuse the sensed data and infer
affective states. The game changes driven by those
affective states aim to improve the user experience by
keeping or increasing player’s engagement.

Author Keywords
Affective states, affect recognition, affect-driven
adaptation, video games

ACM Classification Keywords
H.5.2 [Information interfaces and presentation]: User
Interfaces --- interaction styles, input devices and
strategies.

Introduction
Building affect-driven adaptive environments comprises
reading a user’s physiological information through
sensors, inferring the user’s affect, and then using this
information to create a feedback loop: the software
change driven by the affect and its changes aims to
alter the user’s affect. Our project is geared toward

ISWC '14 ADJUNCT, SEPTEMBER 13 - 17, 2014, SEATTLE, WA, USA

altering the well-known game, Pac-Man [1], in order to
elicit affective responses from users. A user is able to
play Pac-Man while wearing various sensors that
communicate with a server application, which then
sends information to the Pac-Man client application.
The server application synchronizes and fuses the data
collected by the sensors and infers the affective state
[2]. The affective state is represented as a pleasure,
arousal, and dominance (PAD) vector. The Pac-Man
client utilizes the PAD vector at regular intervals to
alter the game and ultimately attempts to push the
user into an engaged state.
Figure 1. When the player is meditating,
the speed of ghosts and the music tempo
are increased; the special features (e.g.,
power pellets) are disabled; and when
the game ends, a slightly more difficult
map is loaded.

measured. A frustrated user would press on the
directional keys in an aggressive manner rather than in
a gentle or calm manner.
EEG sensor
Electroencephalographically (EEG) sensors use
brainwaves as an information source; they measure the
electrical activity along the scalp, produced by the firing
of neurons within the brain over a period of time, which
is gathered from multiple electrodes placed on the
scalp. They are able to infer diverse affective constructs
such as engagement, excitement, boredom, meditation,
and frustration.

Technology Background
The technologies, both hardware and software, utilized
for this project are described in [3] and summarized in
the follow paragraphs.
Posture sensor
The project utilizes a chair posture sensor. This device
produces raw data values based on how the user is
positioned on a chair. Values are related with the user’s
interest level: if the user is engaged, he/she would be
more likely to be sitting forward rather than relaxed
and leaning back against the chair; for an engaged
user, the values in the sensor would measure low or
lack of pressure on the back of the chair and high
pressure on the front of the seat.

The affect recognition module
The server application is an affect recognition
framework that we use off-the-shelf [2]. It is a server
application that receives sensor data, synchronizes and
fuses the data, determines an affective state, expresses
the affective state as a PAD vector, and communicates
it with other applications, named client applications.
We feed the server application with the raw values that
posture, pressure, and EEG sensors gather. Then, our
client application (the game) uses the PAD vector,
provided by the server, as an input and adjusts itself
according to the values on the PAD vector.

The Game

Figure 2. While the player is engaged,
the settings of the game stay the same.

Pressure sensor
This device is based on the mouse pressure sensor
described in [3]; however, since Pac-Man uses the
directional keys on the keyboard, the mouse pressure
sensor was modified to put the sensor pads of the
mouse into the fingertips of a glove so that the
pressure sensitivity the user has on the keys can be

2

The game is a highly modified version of an open
source version of the video game Pac-Man [1]. We
chose this game due to its simplicity, which allows a
considerable amount of modifications. The goal of the
game of Pac-Man is to eat all the small pellets in a
certain maze to win the game by avoiding being eaten
by the ghosts. In our game, affective components,

SESSION: DEMOS

expressed in PAD vectors, are taken as inputs to allow
the game to change as discussed further below.

Figure 3. When the player is bored, the
speed of ghosts and the music tempo are
increased; the special features (e.g.,
power pellets) are disabled; and when
the game ends, a very difficult map is
loaded.

Affective state changes
Four affective states were focused on for this game:
meditation, engagement, boredom, and frustration. As
the goal of the affect-driven adaptive version of the
game is to keep or bring the player into the engaged
state, the settings are therefore maintained once the
player reaches this state. Table 1 shows the changes
that the game will undergo when the user reaches each
of the affective states. The features that are adapted
accordingly with the affective state include: the color of
Pac-Man (blue, green, gray, and red); the speed of
Pac-Man, which can increase (+) or decrease (-); the
number of ghosts, which can increase (+) or decrease
(-); the speed of the ghost, which can increase (+) or
decrease (-); the music tempo, which can be faster or
upbeat (+) or slower or ballad (-); the special features
(such as fruits, power pellets, and 1-up component),
which can be enabled (E) or disabled (DE); and the
difficulty level of the next maze, which can increase (+)
or decrease (-).

Implementation

Figure 4. When the player is frustrated, the
speed of ghosts and the music tempo are
decreased; the special features (e.g., power
pellets) are enabled; and when the game
ends, an easier map will be loaded.

The project was developed in Java using Eclipse as IDE.
The development involved the modification of an open
source version of the Pac-Man video game and its
connection to the emotion recognition framework, using
a client/server approach. Documentation, user-guides,
and a configuration file were created. Documentation
and user-guides are available for both developers and
non-developers to easily maneuver through the code
and make changes to the game. The configuration file
allows researchers to set up diverse starting variables
in the game, such as: the base speed of Pac-Man and

3

the ghosts, the poll time of readings (in seconds), and
the affective states to be considered to adjust the
game.
Once the user has begun the game, the PAD vector
readings are polled at the frequency defined by the
researcher in the configuration file and used to
determine the appropriate adjustments. The software
stores all the information about the affective state and
status of all the game features in the log file. The
information in the log file is used to determine what
happens as the user plays the game and serves as key
data for researchers to answer empirical questions
about personalizing game environments based on
affect.

d

Feature \State
Color
Pac-Man speed
Ghosts #
Ghosts speed
Music tempo
Fruits
Power pellets
1-up
Next Level Diff

M

E

B

F

Blue
=
=
+
+
DE
DE
DE
+

Green
=
=
=
=
=
=
=
=

Gray
+
+
+
DE
DE
DE
+

Red
+
E
E
E
-

Table 1. Changes made in the game when the user reaches
each of the affective states: Meditation (M), Engagement (E),
Boredom (B) and Frustration (F). Features can increase (+),
decrease (-), be enabled (E), be disabled (DE), or stay in the
same status (=).

Discussion
An affect-driven adaptive environment was successfully
developed (using an open source version of Pac-Man)

ISWC '14 ADJUNCT, SEPTEMBER 13 - 17, 2014, SEATTLE, WA, USA

to work with the sensor suite developed in a prior
project of the sponsoring research laboratory. The
original open source Pac-Man game allowed us to add,
in a short period of time, extra features, which allowed
the game to adapt based on the user’s affect.
When designing the game adaptation strategy, it was
necessary to figure out the affective states on which to
focus. After a first brief analysis, we ascertained that
changing the speed of Pac Man and the ghost entities
were not enough to manipulate the user’s affective
state, so additional features needed to be manipulated.
Additional testing led to the manipulation of the music,
colors, and special elements (such as fruits and 1-up).
The strategy for keeping the user engaged by
manipulating the described features is defined as
follows: (a) we did not want the player to be bored,
thus we made the game extremely difficult when the
player reached that state by decreasing the speed of
Pac-Man and increasing the number and speed of the
ghosts and the music tempo; (b) we did not want the
user to be frustrated, thus we made the game very
easy in this state by increasing the speed of Pac-Man
and decreasing the number and speed of the ghosts
and the music tempo as well as providing special
features such as power pellets and fruits; (c) finally, we
did not want the player to be in meditation, thus we
made the game slightly more difficult to give the player
a push toward the engaged state by increasing the
speed of Pac-Man and the music tempo.

4

Enabling the Pac-Man game with affective-driven
adaptive settings resulted in a game that became
easier to win, which was more enjoyable to users.
Additional research and testing should be done to
further hone the types of adaptations that guide users
to an optimal state and to explore and test the impacts
on other user outcomes including learning and
performance management.

Acknowledgments
The project was developed as coursework of
CSE423/424 (Systems Capstone) at ASU collaborating
with the Advancing New Generation Learning
Environments Lab and supported by Office of Naval
Research under Grant N000141310438.

References
[1] Open source Pac-Man software.
http://sourceforge.net/projects/javaipacman/
[2] Gonzalez-Sanchez, J., Chavez-Echeagaray, M. E.,
Atkinson, R., and Burleson, W. ABE: an Agent-Based
Software Architecture for a Multimodal Emotion
Recognition Framework. In Proc. Software Architecture
(WICSA), 2011 Ninth Working IEEE/IFIP Conference on,
IEEE (2011), 187–193.
[3] Gonzalez-Sanchez, J., Christopherson, R. M.,
Chavez-Echeagaray, M. E., Gibson, D. C., Atkinson, R.,
and Burleson, W. How to Do Multimodal Detection of
Affective States? In Proc. Advanced Learning
Technologies (ICALT), 2011 11th IEEE International
Conference on, IEEE (2011), 654–655.

2011 2011
NinthNinth
Working
Working
IEEE/IFIP
Conference
Conference
on Software
on Software
Architecture
Architecture

ABE: An Agent-Based Software Architecture
for A Multimodal Emotion Recognition Framework

Javier Gonzalez-Sanchez, Maria Elena Chavez-Echeagaray, Robert Atkinson, Winslow Burleson
School of Computing, Informatics, and Decision Systems Engineering
Arizona State University
Tempe, Arizona, US
e-mail:{javiergs, helenchavez, robert.atkinson, winslow.burleson}@asu.edu
software architecture is not described and the definition of a
framework to enable others to integrate emotion recognition
into their systems was not a goal.
To the best of our knowledge there are no architectures,
frameworks, libraries or generic software tools, that allow
software engineers to easily integrate true multimodal
emotion recognition into their software projects, such as the
ones that exist for computer vision [10], web platforms [11]
or database management [12].
Accordingly, the work reported here offers a first step
toward filling the gap in the lack of frameworks and models,
addressing: (a) the modeling of an agent-driven componentbased architecture for multimodal emotion recognition,
called ABE (for Agent-Based Environment), and (b) the use
of ABE to implement a multimodal emotion recognition
framework, under the paradigm of “highly reusable software
components”, which can be integrated into third-party
systems and provide them with the ability to become an
empathetic system, as needed.
It is important to clarify that the primary contribution of
this work is related to software architecture and it is not
about new algorithms for emotion recognition or new
hardware devices for sensing human signals indicating
emotional changes.
This paper is structured as follows. Section II reviews the
related background about sensing devices and some related
terminology. Section III presents the architecture and
framework. Section IV exemplifies the use of ABE
framework by describing how it was integrated in two demo
systems. Section V presents an evaluation of the framework
in terms of performance while used in the demo systems.
Section VI presents conclusions and ongoing work.

Abstract—The computer's ability to recognize human
emotional states given physiological signals is gaining in
popularity to create empathetic systems such as learning
environments, health care systems and videogames. Despite
that, there are few frameworks, libraries, architectures, or
software tools, which allow systems developers to easily
integrate emotion recognition into their software projects. The
work reported here offers a first step to fill this gap in the lack
of frameworks and models, addressing: (a) the modeling of an
agent-driven component-based architecture for multimodal
emotion recognition, called ABE, and (b) the use of ABE to
implement a multimodal emotion recognition framework to
support third-party systems becoming empathetic systems.
Keywords - affective computing; architecture; framework;
agent-based; multimodal; emotion recognition; empathetic
systems

I.

INTRODUCTION

A key concept in this work is empathy, i.e., to enable a
system to recognize and understand human emotions and
react
appropriately
in
consequence
with
those
understandings. Enabling computers to be empathetic has
implied the convergence of affordable wireless sensors and
the application of novel machine learning and data mining
algorithms to deal with the vast amounts of data generated by
the sensors [1].
On the one hand, there are several examples of research
conducted on creating empathetic systems to support
learning [2][3][4], health care [5] and videogames [6]. But
the majority of the research does not focus on the creation of
reusable software, software frameworks or the best
methodological practices for those purposes [7]. Each
attempt either develops its own system, or uses a legacy
system. They are focused on creating a proof-of-concept
system to collect data and validate technology approaches.
On the other hand, some of the best-known existing
architectures and libraries that provide support for emotion
recognition use monomodal or bimodal approaches. For
example the project described in [8] is an open-source
implementation that combines speech emotion recognition
with facial expressions analysis and head movement
tracking. The multimodal proposal in [9] could be considered
an antecedent of this work due the use of multiple sensors
and their integration in a client-server structure although
978-0-7695-4351-2/11 $26.00 © 2011 IEEE
DOI 10.1109/WICSA.2011.32

II.

BACKGROUND

Because this work is related to emotions and to the
intention of enabling computers with the ability to recognize
them, this section provides background information to clarify
some terminology used within this paper and describes the
sensing devices and perception mechanisms used in this
work.
A. Definitions
In the rest of the paper we use these definitions for the
related concepts.

187

Our multimodal approach includes: brain-computer
interfaces, eye tracking systems, face-based emotion
recognition systems, and sensors to measure other
physiological signals (skin conductivity, posture, and finger
pressure). Fig. 1 shows the elements related to our approach
of a multimodal emotion recognition system. The
description of each element is as follows:

1) Sensing device. These are hardware devices that
collect quantitative data as measures of physiological
signals of emotional change.
2) Raw data. We call the measures provided by the
sensing devices “raw data”. These are data packages that
sensing devices send to the computer.
3) Sensed value. This refers to the raw data after being
parsed into a software data structure. Sensed values are
useful by themselves and also help to infer emotions. For
example, face sensed values are “actions units”; action units
are standard values used to categorize facial expressions and
they have proven being useful to recognition of basic
emotions [13].
4) Perception mechanism. These are algorithms that
infer emotions using sensed values as input. An example of
this is the act of inferring emotions from facial expressions
sensed by a video camera.
5) Belief. Perception mechanisms provide “beliefs”
about their understanding of the user’s emotional change.
6) Multimodal. It refers to combining several sensing
devices (i.e., perception mechanisms), either to recognize a
broad range of emotions or to improve the accuracy of a
process. The multimodal strategy provides more than one
way to recognize an emotion.
7) Emotional state. Represents the user emotion in a
time !"#This is developed from the integration of beliefs in
that time !.

1) Brainwaves. We incorporate the Emotiv© EPOC
headset, an inexpensive wireless hardware device, which
uses EEG technology to sense electroencephalography
activities [14].
2) Eye movement. We incorporate the Tobii© Eye
Tracking System. An eye tracker provides data about a
user’s focus of attention and focus time while the user
performs a task on the computer [15].
3) Facial expressions. We incorporate MindReader, an
inference system developed at MIT Media Lab, which
infers, in real-time, emotions from facial expressions and
head movements [16].
4) Skin conductivity. This sensor measures the electrical
conductance of the skin, which varies with its moisture level
that depends on the sweat glands, which are controlled by
the sympathetic and parasympathetic nervous systems. Skin
conductance is an indicator of psychological or
physiological arousal. We use a wireless Bluetooth skin
conductance device developed at MIT Media Lab [17].

B. Sensing and Perceiving
Several existing systems are able to detect a single
emotion or a reduced set of emotions. One of our goals was
to make significant advances to emotion recognition by
integrating and encapsulating pre-existing software
components into our implementation to sense and recognize
a wide range and diverse set of emotions.

TABLE I.
Sensing
Device
Emotiv©
headset
Webcam and
MindReader
software

Figure 1. Multimodal emotion recognition includes: sensing brainwaves,
eye tracking, facial expression analysis and physiological signals (skin
conductivity, posture, and finger pressure). Beliefs are inferred from raw
data and emotional states correspond to the integration of beliefs from
several sources in a time !.

188

INFERRED EMOTIONS AND SENSED VALUES
Sampling
Rate (in ms)
125
100

Emotiv©
headset

7

Emotiv©
headset

125

Skin
conductance
sensor
Pressure
sensor

500

Tobii©
Eye Tracking
Posture
sensor

16

150

500

Inferred emotions
Excitement, engagement, boredom,
meditation and frustration.
Agreeing, concentrating,
disagreeing, interested, thinking and
unsure.
Sensed values
EEG activity. Reported in 14
channels, labeled: AF3, F7, F3,
FC5, T7, P7, O1, O2, P8, T8, FC6,
F4, F8, and AF4 [18].
Blink, wink (left and right), look
(left and right), raise brow, furrow
brow, smile, clench, smirk (left and
right), and laugh.
Arousal.
One pressure value per sensor
allocated into the input/control
devices.
Gaze point (x, y).
Pressure values in the back pad and
the seat cushion (in the right, middle
and left zones).

5) Posture. We use a low-cost, low-resolution pressure
sensitive seat cushion and back pad with an incorporated
accelerometer to measure elements of users’ posture and
activity, developed at ASU based on experience using a
more expensive high resolution unit from the MIT Media
Lab. The use of this sensing device to recognizing naturally
occurring postures and associated emotional states is
describe in [19].
6) Finger pressure. Based on pressure sensors we detect
the increasing amount of pressure that the user puts on a
mouse, or any other controller (such as a game controller).
These measures are correlated with levels of frustration.
Mouse implementation is described in [20].

head of the federation. Specialist agents are in permanent
communication with Centre, contributing with data. Centre
implements the integration algorithms that convert, in realtime, the beliefs reported by the Specialist agents into
emotional states. For third-party systems Centre acts as a
facade that hides the internal complexity of the federation.
As shown in Fig. 2, third-party systems are able to contact
Centre and subscribe to receive information about the
emotional state of the user.
3) Internal communication. The communication
structure between Specialist agents and Centre is made by
data flows moving messages from one point to another.
Specialist agents encapsulate information in packages with:
(a) a header composed of timestamp, in milliseconds, and an
agent ID, and (b) a body composed of an array of rational
numbers.
4) External communication. The federation, through
Centre, offers a service-oriented behavior using a publishsubscribe style. The underlying concept is that the agent
federation provides a service and other systems can
subscribe to the service and customize which information
they are interested in receiving.

Sensed values, inferred emotions and sampling rates are
listed in Table I. Given this collection of sensing devices
with proven functionality when used independently, the
research question we posed was how to achieve a framework
where all of them work together. We sought to create a
framework that can be used and reused without a
cumbersome installation or adaptation (re-programming)
process.
C. Agents and Agent Federation
Agents are autonomous pieces of software that allow us
to encapsulate sensing devices and their perception
mechanisms into independent, individual and intelligent
components [21] [22].
When several agents need to interact, it is important to
establish an organizational strategy for them, which defines
authority relationships, data flows and coordination
protocols. To articulate the organizational strategy we define
an agent federation. An agent federation is conformed by a
group of agents that cede some amount of autonomy to a
single delegate, which represents the group. The delegate is a
“distinguished” agent that acts as an intermediary between
all the agents in the group and the outside world [23].
III.

Both internal and external communications are achieved
using TCP/IP connections, so agents can run within one
computer or be distributed among several computers.
The elements in Fig. 2 constitute a federation unit. One
federation unit can take care of one user. This means that,
during runtime, there is one agent of each kind related to
each sensing device for each user. Several federation units
can be instantiated and communicated with to establish the
emotional state of a group of users. The following sections
provide a detailed description of the architecture, framework
and data management.

IMPLEMENTATION

We propose an agent-based model as the most
appropriate solution because we need to deal with several
different sources of data flows, where each flow proceeds
along different time intervals, and furthermore, these
multiple highly varying inputs can be used as a whole or as a
subset. Our model takes into account that it may be
necessary, in the future, to add even more sources of sensed
values.
ABE follows the federation organizational strategy as
shown in Fig. 2. The structure is composed of:
1) Specialist agents. These are responsible for: (a)
collecting raw data, (b) parsing it into sensed values and
inferring beliefs, and (c) communicating their beliefs with
the head of their federation.
2) Centre agent or simply Centre. This is the name of
our delegate or “distinguished” agent to which the rest
ceded some amount of autonomy, and which acts as the

Figure 2. ABE follows the organizational strategy of federation. The
federation assigns one Specialist agent to collect raw data from each
sensing device. Specialist agent implements the perception mechanism for
its assigned sensing device to map raw data into beliefs. Beliefs are
reported to Centre, which integrate them into one emotional state report.
Third-party systems are able to obtain emotional state reports from Centre
in a publish-subscribe style.

189

Figure 3. Architecture. Specialist agents (brain, eye, face, skin, pressure and posture) deal with sensing devices and encapsulate parsing, inference, and
communication functionalities. They work as a federation, which implies that they send resources (beliefs) and subordinate their behavior to the head of the
federation. Centre acts as the head of the federation. Centre’s responsibilities include integrating beliefs to create emotional state reports that can be shared
with third-party systems in a publish-subscribe style

serial port communication
corresponding sensors.

A. The Architecture
Fig. 3 shows the macro-level [24] view for the ABE
agent-based multilayer distributed architecture, as it is
currently designed, where all the agents are represented
along with their components and communication channels.
Each component is described below.

to

read

data

from

the

b) Model. Model obtains sensed values from a Data
Source and uses a perception mechanism to infer beliefs.
Model is also responsible for filtering, labeling, time
stamping, packaging beliefs, and sending packages to
Centre.

1) Specialist agent. One Specialist agent is included for
each sensing device listed in Table I, they are labeled as
brain-agent, eye-agent, face-agent, skin-agent, pressureagent, and posture-agent. A Specialist agent is divided into
four components: (a) Data Source, (b) Model, (c) Controller,
and (d) Communicator. Each component implements one
agent responsibility.
a) Data Source. Data Sources access raw data from the
sensing devices, parse the raw data into sensed values, and
provide those sensed values to the component in the next
layer. Two types of Data Sources are defined: Wrappers and
Drivers. On the one hand, Wrappers encapsulate legacy
systems making calls to their SDK methods; Data Sources
for brain-agent, eye-agent and face-agent wrap Emotiv©
SDK, Tobii© SDK and MIT MindReader System
respectively. On the other hand, Drivers communicate with
sensing devices through the computer bus or
communication subsystems (such as serial or USB ports);
skin-agent, pressure-agent, and posture-agent implement

c) Controller. Controller implements a configuration
mechanism. It receives requests from Centre and modifies
the behavior of the Specialist agent according to the
received requested. Configuration parameters include
change sampling rate and change filtering strategy.
d) Communicator. Communicator provides networking
capabilities to send beliefs to Centre.
2) Centre Agent. Centre is divided into four
components, each of them implements one agent
responsibility: (a) Communicator, (b) Supervisor, (c)
Concurrent Data Repository, and (d) Publisher.
a) Communicator. It connects with the communicator
component of the Specialist agent to receive beliefs.
b) Supervisor. It is the component that takes beliefs as
input for its integration algorithms and generates emotional
states. Since sensing devices and their associated Specialist
agents have different sampling rates, part of the

190

responsibility of Supervisor is to standardize the sampling
rates. Thus, Centre is able to report emotional states with
the requested sampling rate.
c) Concurrent Data Repository. The Data repository is
explained in the Data Management section below.
d) Publisher. Publisher is the component that acts as
the facade of the agent federation to the outside world
implementing the publish-subscribe functionality. A thirdparty system can express interest in receiving reports of the
emotional state of the user by sending a “subscribe”
message. The subscription includes the specification of the
periodicity that is desired (starting in 1 millisecond) and the
composition of the data of interest (e.g., all sensors,
emotions and eye tracking, posture and facial expressions,
only positive emotions, only negative emotions). From that
point forward Publisher will be sending reports about the
emotional state of the user to that third-party system.

Figure 4. The Concurrent Data Repository, located in Centre Agent, has
one data-item mapped to each agent.

C. Data Management
Centre provides a concurrent control mechanism for data
collection: a concurrent data repository in which each dataitem is mapped to one of the Specialist agents and stores the
set of sensed values provided by that Specialist agent. Each
data-item stores the most recent information provided by its
Specialist agent without interfering with the information
provided by the others Specialist agents. In this way we
solve the problem of different sampling rates across diverse
sensing devices, Fig 4.
Reading the data repository content in a time t provides
us with the user’s emotional state for t. Data items store the
last provided value until a new one arrives. Table II shows
how this is handled in the data repository across time. Each
row corresponds to the data repository in a time t, and
represents the integration of the beliefs reported by the
Specialist agents into one emotional state. As can be
observed skin conductance remains the same from t1 to t4
since the sensor device related with that information has the
slowest sampling rate (500 ms).

B. The Framework
The definition of the micro-level architecture [24] uses a
pattern-based approach [25]. The use of software design
patterns populated our framework and SDK. The process of
moving from macro-level architecture to the micro-level
architecture is described in detail in [26]. In order to build
upon ABE framework, developers are required to do the
following:
1) Create new Specialist agent. To create new types of
Specialist agents developers are responsible for:
• Implementing the interface Agent in a new class.
• Creating the associated Data Source implementing a
class from $%!%&'()*+,)%--+) interface (to
encapsulate a legacy SDK) or a class from
$%!%&'()*+$)./+) interface (to access a new
sensing device).
• Completing the implementation of an ADAPTER
pattern, for $%!%&'()*+,)%--+), or completing the
implementation of a DELEGATE pattern, for
$%!%&'()*+$)./+).
• Programming the Model component of the agent (i.e.
complete a STRATEGY pattern implementation).
• Using the communicator facilities to send
information to Centre (i.e. implement 0'11(2.*%!')
interface).

IV.

USAGE EXAMPLES

We have evaluated the suitability of ABE to our needs
both at the architectural and runtime levels. The six
Specialist agents and Centre agent have been implemented
and ABE has been tested in two different kinds of scenarios,
in a gaming environment study and in an intelligent tutoring
system development project.
A.

Gaming Environment Study
The purpose of this study was to measure the correlation
of the engagement/boredom of the player (depending on
his/her level of expertise) while playing different difficulty
levels in Guitar Hero© video game.

2) Extend Centre capabilities. Centre’s capabilities can
be extend in order to handle new types of beliefs (coming
from new types of Specialist agents) by:
• Completing the implementation of a STRATEGY
pattern to define new integration algorithms.
• Implementing a new knowledge source in a
BLACKBOARD pattern.
• Using communicator facilities to receive information
from a new Specialist agent.

TABLE II.
Time
t1
t2
t3
t4
t5

191

INTEGRATION OF EMOTIONAL STATES IN TIMES TN

Brain

Eye

Face

Skin

Pressure

Posture

v1
v1
v2
v2
v3

v1
v2
v3
v4
v5

v1
v2
v3
v4
v5

v1
v1
v1
v1
v2

v1
v1
v2
v2
v3

v1
v1
v2
v2
v3

Guitar Hero© is a game in which players use a guitarshaped game controller to simulate playing lead, bass guitar,
and rhythm guitar across numerous rock music songs.
Players match notes that scroll on-screen to colored fret
buttons on the controller, strumming the controller in time to
the music in order to score points, and keep the virtual
audience excited [27].
ABE was applied in a lab setup where 21 students were
asked to play Guitar Hero© (as a learning experience, learn
to play). The scenario involved the user wearing the skin
conductance bracelet and the Emotive© EPOC headset while
being tracked by the MIT MindReader System and by
Tobii© Eye Tracking System. The game controller was
modified by adding a pressure sensor to each of the colored
fret buttons, on the arm of the guitar. Users were asked to
play their choice of a single song at each of four different
levels (easy, medium, hard and expert), from a pre-selected
list of songs. ABE provided access to the sensed data and
provided mixing functionality. Centre sends data to a logger
component (developed for this experiment). Two data
streams were provided to create two dataset files, one with
1/128 s rate and other with 1s rate. Each dataset was
requested for a different data mining approach.
Fig. 5 shows one of the results of this study where Centre
provided integrated data from eye tracking and brainwaves.
The figure shows the Guitar Hero© screen; the superimposed
dots (in black) indicate that at one or more times, throughout
the session, while the user was looking at that location on the
screen frustration was detected by ABE. The Guitar Hero©
screen is composed of an image that resembles the arm (or
frets) of a guitar, in the middle of the image; overlaid on this
image, musical notes scroll down toward the bottom of the
screen. Each note is mapped according to the color of a
physical button that the user should actuate before the note
moves off the screen. The scene is decorated with stage
items, instruments and performers.

The frustration points were the 34#5 coordinates of the
user gaze while feeling frustrated. A circle represents each
frustration point and its size is equivalent to the time spent
by the user staring at that location. Since the subject was a
novice user of this videogame, this data shows how the user
feel frustration looking into the notes while they scroll onscreen.
B. Intelligent Tutoring System
In a second case, we are currently working on the
development of an intelligent tutoring system applying ABE
to generate better and more accurate hints and feedback to
the student with the intention of creating a more empathetic
learning process and environment, reducing student
frustration and avoiding student quitting.
During a pilot test in July 2010, the intelligent tutoring
system [28] was enriched with the sensing devices and
agents related to: (a) skin conductance bracelet, (b) Emotiv©
EPOC headset, (c) the MIT MindReader System, and (d)
pressure sensors on the mouse. Students were asked to
perform a task (about system dynamics modeling) using the
intelligent tutoring system. While the student was working
on this task, the intelligent tutoring system collected data
using ABE. During this study the data was collected for post
analysis and review what information the student reported.
The next step in the project will consist on using this
information to create a student model and adjust the behavior
of the intelligent tutoring system in response to the emotional
state of the student.
V.

PERFORMANCE

ABE framework components were created to be as
lightweight as possible to run in the background of an
existing system. The goal was to avoid creating a dominant,
“star player” system, but rather to provide a platform that
could operate behind the scenes, to improves and
complements other systems. Table III shows the result of
memory load and processor usage running each of the agents
in a system with the following characteristics: Intel Xenon
CPU W3520 at 2.67 GHz with 4 cores, 3.50 GB of RAM,
and running Windows XP professional with Service Pack 3.
It is important to mention that for face, brain and eye
agents the values reported in Table III include the load
caused by the agent and by the underlying system: MIT
MindReader System, Emotiv© EPOC SDK and Tobii© Eye
Tracking SDK, respectively.
TABLE III.

PERFORMANCE OF SPECIALIST AGENTS

Agent

Figure 5. Mixed data from eye tracking system and frustration
measurement for a single novice user playing Guitar Hero©. Black dots
correspond to places where the player was looking while feeling frustrated.
The image was converted to gray scale, the contrast incremented and the
tones inverted to facilitate its print.

192

% CPU

Performance
Memory (Kb)

Skin

8 - 15

14,100 - 15,200

Face

34 - 43

60,000 - 110,000

Brain (for emotion)

9 - 16

8,260 - 8,500

Brain
(For physiological signals)

6 - 15

7,200 - 7,800

Pressure

8 - 14

15,900 - 16,200

Eye

15 - 25

169, 500 - 170,000

VI.

CONCLUSIONS AND ONGOING WORK

[8]

In this paper we have presented ABE as our
architectonical proposal for a multimodal emotion
recognition framework that supports the creation of
empathetic systems. This work is rooted in an agent-based
approach under a multilayer-distributed architecture oriented
to create highly reusable, flexible and extensible software
components. We have achieved the integration of both novel
and well-known sensing devices into ABE including brain
computer interfaces, eye tracking systems, computer vision
systems and physiological sensors. We illustrated the use of
ABE in practice, building software for two different
scenarios: one was a gaming study in which we sensed
emotional status of students while playing a video game, and
a second one into an affective tutoring system development
project. In both scenarios it was seen that the integration of
ABE was a reasonably easy experience with good
performance results. We are excited and encouraged to
continue with the next step in this process and deploy ABE
externally in order to have others research and development
groups using and testing ABE by themselves without support
from our engineering team. The next steps for ABE are
focused on: (a) refactoring components (b) deploy API’s
documentation, (c) adding support agents such as loggers
and visualizers to conform a dashboard interface. Beside
that, looking into test-case scenarios for reactive systems, has
become more relevant to maintain latency in a useful level
for real-time interaction, therefore integration of parallel and
multicore computing models is also in our list of next steps.

[9]

[10]
[11]
[12]
/%+0
/%-0
[15]
[16]

[17]

[18]

[19]

ACKNOWLEDGMENT
This research was supported by Office of Naval Research
under Grant N00014-10-1-0143 awarded to Dr. Robert
Atkinson.

[20]

REFERENCES
[1]
[2]

[3]

[4]
[5]

[6]

[7]

[21]

R. W. Picard, Affective Computing, MIT Press, 1997.
I. Arroyo, D. G. Cooper, W. Burleson, F. P. Woolf, K. Muldner, and
R. Christopherson, “Emotion Sensors Go to School,” Proc. Artificial
Intelligence in Education: Building Learning Systems that Care: from
Knowledge Representation to Affective Modelling, (AIED 09), V.
Dimitrova, R. Mizoguchi, B. du Boulay & A. Grasser (Eds.), IOS
Press, July 2009, vol. Frontiers in Artificial Intelligence and
Applications 200, pp. 17-24, doi: 10.3233/978-1-60750-028-5-17.
B. Woolf, W. Burelson, and I. Arroyo, “Emotional Intelligence for
Computer Tutors,” Supplementary Proc. 13th International
Conference on Artificial Intelligence in Education (AIED 07), July
2007, pp. 6-15.
S. D'Mello, R. W. Picard, and A. Graesser, "Toward an AffectSensitive AutoTutor," IEEE Intelligent Systems, July/August 2007,
vol. 22 no. 4, pp. 53-61, doi:10.1109/MIS.2007.79.
X. Chao, and F. Zhiyong, “A Trusted Affective Model Approach to
Proactive Health Monitoring System,” Proc. International Seminar
on Future BioMedical Information Engineering (FBIE 08). IEEE
Computer Society, 2008, pp. 429-432, doi:10.1109/FBIE.2008.52.
K. Gilleade, A. Dix and J. Allanson, “Affective Videogames and
Modes of Affective Gaming: Assist Me, Challenge Me, Emote Me,”
Proc. Digital Games Research Association, Changing Views –
Worlds in Play (DiGRA 05), June 2005.
R. E. Johnson, “Components, frameworks, patterns,” Proc.
Symposium on Software Reusability (SSR 97), Medhi Harandi (Ed.).
ACM, Feb. 1997, pp. 10-17, doi:10.1145/258366.258378.

[22]

[23]

[24]
[25]

[26]

[27]
[28]

193

M. Schroder, “The SEMAINE API: towards a standards-based
framework for building emotion-oriented systems,” Advances in
Human-Computer Interaction, vol. 2010, 2010,
!"#$%&'%%(()*&%&)+%,-&..
W. Burleson, R. Picard, K. Perlin, and J. Lippincott, “A platform for
affective agent research”, Workshop on Empathetic Agents,
International Conference on Autonomous Agents and Multiagent
Systems, Columbia University, New York, NY, (2004),
ReacTIVision - a toolkit for tangible multi-touch surfaces. Retrieved
April 4, 2011, from http://reactivision.sourceforge.net.
Apache Http Server Project. Retrieved April 4, 2011, from
http://httpd.apache.org.
MySQL – open source database. Retrieved April 4, 2011, from
http://www.mysql.com.
1'2 345672 67!2 8'2 9:#;<;7=2 >96?#6@2 A?B#"72 C"!#7D2 EF<B;5$2 A2
G;?H7#IJ;2K":2BH;2L;6<J:;5;7B2"K296?#6@2L"M;5;7B=N2C"7<J@B#7D2
Psychologists Press, 1978. 2
Emotiv - Brain Computer Interface Technology. Retrieved April 4,
2011, from http://www.emotiv.com.2
Tobii Technology - Eye Tracking and Eye Control. Retrieved April
4, 2011, from http://www.tobii.com.
R. El Kaliouby, and P. Robinson, “Generalization of a vision-based
computational model of mind-reading,” Proc. First International
Conference on Affective Computing and Intelligent Interaction
(ACII 05), Springer-Verlag, Oct. 2005, pp. 582-589,
doi:10.1007/11573548_75.
M. Strauss, C. Reynolds, S. Hughes, K. Park, G. McDarby, and R.
W. Picard, “The HandWave Bluetooth Skin Conductance Sensor,”
Proc. First International Conference on Affective Computing and
Intelligent Interaction (ACII 05), Springer-Verlang, Oct. 2005, pp.
699-706, doi:10.1007/11573548_90.
F. Sharbrough, G. E. Chatrian, R. P. Lesser, H. Luders, M. Nuwer,
and T. W. Picton,
"American electroencephalographic society
guidelines for standard electrode position nomenclature," J. Clin.
Neurophysiol., vol. 8, 1991, pp. 200-202.
S. Mota, and R. W. Picard, "Automated Posture Analysis for
Detecting Learners Interest Level," Proc. Computer Vision and
Pattern Recognition Workshop (CVPRW 03), IEEE Press, June
2003, vol. 5, pp. 49, doi:10.1109/CVPRW.2003.10047.
Y. Qi, and R. W. Picard, "Context-Sensitive Bayesian Classifiers and
Application to Mouse Pressure Pattern Classification," Proc.
International Conference on Pattern Recognition (ICPR 02), Aug.
2002, vol 3, pp. 30448, doi:10.1109/ICPR.2002.1047973.
F. Tuijnman, and H. Afsarmanesh, "Distributed objects in a
federation of autonomous cooperating agents," Proc. International
Conference on Intelligent and Cooperative Information Systems,
May 1993, pp. 256-265, doi:10.1109/ICICIS.1993.291763.
M. Wood, and S. DeLoach, “An overview of the multiagent systems
engineering methodology,” Agent-Oriented Software Engineering,
(AOSE 2000), Springer-Verlag, 2001, pp. 207-221, doi:10.1007/3540-44564-1_14.
B. Horling, and V. Lesser, “A survey of multi-agent organizational
paradigms,” The Knowledge Engineering Review, Cambridge
University Press, 2005, vol. 19, pp. 281-316, doi:
10.1017/S0269888905000317.
J.E. Hollingsworth and B.W. Weide, “Micro-Architecture vs. MacroArchitecture”, Proceedings of the Seventh Annual Workshop on
Software Reuse, (1995),
E. Gamma, R. Helm, R. Johnson, and J. Vlissides. “Design patterns:
Abstraction and reuse of object-oriented design,” Proc. 7th European
Conference on Object-Oriented Programming (ECOOP 93),
Springer-Verlag, July 1993, vol. 707, pp. 406–431.
J. Gonzalez-Sanchez, M.E. Chavez-Echeagaray, R. Atkinson, and W.
Burleson,“ Affective computing meets design patterns: a patternbased modeling of a multimodal emotion recognition framework,” in
submission.
Guitar Hero. Retrieved April 4, 2011, from
http://www.guitarhero.com.
Affective Meta Tutor – Arizona State University. Retrieved April 4,
2011, from http://amt.asu.edu.

Course Overview

CHI 2014, One of a CHInd, Toronto, ON, Canada

Multimodal Detection of Affective
States: A Roadmap Through
Diverse Technologies
Javier Gonzalez-Sanchez

Winslow Burleson

Arizona State University

Arizona State University

699 S Mill Ave.

699 S Mill Ave.

Tempe, AZ 85281 USA

Tempe, AZ 85281 USA

javiergs@asu.edu

winslow.burleson@asu.edu

Maria E. Chavez-Echeagaray

Robert K. Atkinson

Arizona State University

Arizona State University

699 S Mill Ave.

699 S Mill Ave.

Tempe, AZ 85281 USA

Tempe, AZ 85281 USA

helenchavez@asu.edu

robert.atkinson@asu.edu

Abstract
One important way for systems to adapt to their
individual users is related to their ability to show
empathy. Being empathetic implies that the computer is
able to recognize a user’s affective states and
understand the implication of those states. Detection of
affective states is a step forward to provide machines
with the necessary intelligence to appropriately interact
with humans. This course provides a description and
demonstration of tools and methodologies for
automatically detecting affective states with a
multimodal approach.

Author Keywords
emotion recognition; affective states; sensors;
multimodal; affect-driven adaptation

ACM Classification Keywords
Permission to make digital or hard copies of part or all of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for profit or commercial advantage and that copies bear this notice
and the full citation on the first page. Copyrights for third-party components of
this work must be honored. For all other uses, contact the Owner/Author.
Copyright is held by the owner/author(s).
CHI 2014, Apr 26 - May 01, 2014, Toronto, ON, Canada.
ACM 978-1-4503-2474-8/14/04.
http://dx.doi.org/10.1145/2559206.2567820

H.5.m [Information interfaces and presentation (e.g.,
HCI)]: Miscellaneous

Course Content
A multimodal approach for automatic detection of
affective states is a three-step process: (1) gather data
that is complex and diverse, (2) filter and integrate
data from several sources, and (3) apply software

1023

Course Overview

Objectives
Describe the sensing devices
used to detect affective
states including braincomputer interfaces, facebased emotion recognition
systems, eye-tracking
systems, and physiological
sensors. Compare the pros
and cons of the sensing
devices used to detect
affective states.
Describe the data that is
gathered from each sensing
device and its characteristics.
Examine what it takes to
gather, filter, and integrate
affective data.
Present approaches and
algorithms used to analyze
affective data and how it
could be used to drive
computer functionality or
behavior.
Audience
Open to researchers,
practitioners, and educators
interested in incorporating
detection of affective states
as part of their technology
toolbox.

CHI 2014, One of a CHInd, Toronto, ON, Canada

algorithms and data processing tools to understand the
data.
Sensing Devices
The first part of the course is a demonstration using
inexpensive, easy to install, and widely available
sensing devices, described in [3], and summarized in
the follow paragraph. For brain-computer interfaces,
the Emotiv© EPOC headset [1] device is used. A simple
30 fps USB webcam and a software system
implementing a supervised learning model are used to
show the face-based emotion recognition approach.
Examples for eye-tracking systems using Tobii© Eye
Tracking System [5] datasets are shown. Three
examples for physiological sensors are shown: arousal
detection using a wireless skin conductance sensor,
posture detection using a posture chair sensor, and
increasing compression detection (correlated with levels
of frustration) using a pressure sensor on a mouse.

data composition and relationships and extract useful
knowledge from data records. Finally, examples using
collected datasets in research studies are shown.

Conclusions
This course aims to provide the attendees with a
thought-provoking presentation about tools and dataset
exploration. While the course do not present an
exhaustive list of all the methods available for
gathering, processing, analyzing, and interpreting
affective sensor data, the course describes the basis of
a multimodal approach that attendees can use to
launch their own research efforts.

Acknowledgements
This research was supported by the Office of Naval
Research under Grant N00014-10-1-0143 awarded to
Dr. Robert Atkinson.

References
Data Filtering and Integration
The second part of the course is a presentation and
discussion about techniques and methodologies used to
filter and integrate information from the different
sources. This part provides an overview of diverse
approaches, such as sliding window, sparse, and statemachine unification.
Analyzing Data
The third part of the course presents quantitative
approaches for data analysis, including automated
reverse engineering, clustering, and classification. For
reverse engineering searches, the Eureqa tool [2] is
used to discover mathematical models of the structural
relationships in the data records. For clustering and
classification, the Weka tool [4] is used to explore the

[1]

Emotiv | EEG System.
http://www.emotiv.com

[2]

Eureka Desktop.
http://www.nutonian.com/products/eureqa

[3]

Gonzalez-Sanchez, J., Chavez-Echeagaray, M.E.,
Atkinson, R. and Burleson, W. ABE: An AgentBased Software Architecture for a Multimodal
Emotion Recognition Framework. In Proc. WICSA
2011, IEEE Press (2011) 187-193.

[4]

Hall, M., Frank, E., Holmes, G., Pfahringer, B.,
Reutemann, P. and Witten, I.H. The WEKA Data
Mining Software: An Update. In Proc. SIGKDD
Explorations, (2009) vol. 11, Issue 1. 10-18.

[5]

Tobii Technology.
http://www.tobii.com

1024

