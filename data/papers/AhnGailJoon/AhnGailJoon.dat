Position Paper: Towards a Moving Target Defense
Approach for Attribute-based Access Control
Carlos E. Rubio-Medrano, Josephine Lamp, Marthony Taguinod,
Adam Doupé, Ziming Zhao and Gail-Joon Ahn
Arizona State University

{crubiome, jalamp, mtaguino, doupe, zzhao30, gahn}@asu.edu
ABSTRACT
In recent years, attribute-based access control has been recognized as a convenient way to specify access mediation policies that leverage attributes originating from diﬀerent security domains, e.g., independently-run organizations or supporting platforms. However, this new paradigm, while allowing for enhanced ﬂexibility and convenience, may also open
the door to new kinds of attacks based on forging or impersonating attributes, thus potentially allowing for attackers
to gain unintended access to protected resources. In order
to alleviate this problem, we present an ongoing eﬀort based
on moving target defense, an emerging technique for proactively providing security measurements: we aim to analyze
attribute-based data obtained at runtime in order to dynamically change policy conﬁgurations over time. We present
our approach by leveraging a case study based in electronic
health records, another trending methodology widely used
in practice for mediating access to sensitive healthcare information in mission-critical applications.

Keywords
Attribute-based Access Control; Moving Target Defense; Electronic Health Records; Policy Mutation

1. INTRODUCTION
Recently, attribute-based access control (ABAC) [1], has
attracted the interest of both academia and industry as
a convenient means of protecting computer systems from
security-related incidents. As ABAC evolves into a mature paradigm and various implementations are successfully
deployed in practice, attributes originating from diﬀerent
sources may be leveraged for expressing rich policies that
better meet the speciﬁc needs of customized environments
[4]. Such a paradigm, while allowing for enhanced ﬂexibility and convenience, may also introduce non-trivial security
vulnerabilities. As an example, consider an ABAC policy
managed by an organization A that leverages attributes from
an outside independently-run organization B, in such a way
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

ABAC’16, March 11 2016, New Orleans, LA, USA
c 2016 ACM. ISBN 978-1-4503-4079-3/16/03. . . $15.00
⃝
DOI: http://dx.doi.org/10.1145/2875491.2875499

that end-users holding attributes issued by B can safely access the resources being shared by A. In such a setting, the
policy makers in A should somehow trust the way attributes
are created and assigned to end-users in the context of B.
However, as time evolves, such an assumption may not always hold in practice, as organization B may be the subject
of security incidents itself, e.g., hacking, or may not have a
strict control on the way its attributes are created and distributed. This would potentially allow for malicious third
parties to compromise them, for instance, by means of a
well-crafted forgery process.
In this paper, we describe an ongoing eﬀort to alleviate this problem by leveraging an approach inspired from
moving target defense (MTD) [2], a promising paradigm
based on the idea of proactively changing, e.g., moving, system conﬁgurations in an eﬀort to deter potential future attacks. In our approach, we aim to analyze attribute information collected from runtime traces of mission-critical applications, a.k.a., the attribute bag. Taking an ABAC policy
as an input, our approach ﬁrst obtains the list of original attributes listed in such policy and subsequently inspects the
attribute bag in an eﬀort to locate attributes that are correlated to the original ones. Later on, these newly-extracted
attributes are used to enhance the original policy, producing a new policy that is forwarded to the access mediation
infrastructure for enforcement. The intuition behind our
approach is that the entities involved in a given access request, e.g., end-users and protected resources, typically exhibit additional trusted attributes besides the ones listed
in the original policy. This way, if the original attributes
are compromised, the newly-extracted ones, which we assume stay uncompromised, may still deter the unintended
exploitation of the original policy. In addition, we aim to
mitigate the harm to usability, e.g., end-users no longer able
to access previously-available resources, by striving to obtain
a high degree of correlation between the original attributes
and the newly-extracted ones.
We present our approach in the context of an emerging
application domain: electronic health records (EHRs) [3],
which has also become the focus of many implementations
in practice as well as in research endeavors due to its notable beneﬁts of providing better quality of patient care. We
show how attributes belonging to both patients and healthcare providers, e.g., doctors and nurses, collected from both
EHRs and access logs can be leveraged to provide stronger
security guarantees by means of our approach, as it allows
for correlated attributes to be discovered and later used to
provide enhanced policies that can prevent future attacks,

Permissions

without aﬀecting the overall usability of a given EHR system.
This paper is organized as follows: we start by brieﬂy
reviewing some important background topics, along with a
running example and some other key considerations for our
approach in Section 2. Our proposal is later described in
Section 3, and we ﬁnalize this position paper by outlining
the status of our research as well as future work in Section 4.

Operators

Attributes

Attribute
Sources

Targets

Manage

Manage

2. BACKGROUND
Moving target defense (MTD) [2] is an emerging paradigm
for providing security guarantees by proactively changing,
e.g., moving, the conﬁgurations of a protected system. Opposed to traditional approaches, which assume security conﬁgurations remain immutable, MTD strives to reduce the
possibility of a successful attack by negating any advantages
the attacker may have. For instance, complicating the reconnaissance process in which an attacker gathers information about the current conﬁgurations of the victim system;
or by deterring ongoing attacks that were crafted based on
previously-discovered (and later changed) conﬁgurations. In
addition, eﬀects to the usability of the protected system, e.g.,
response time and end-user access patterns, should be minimized, in an eﬀort to prevent runtime inconveniences that
may complicate the adoption of MTD-based techniques.
Attribute-based access control (ABAC) [1] is also a trending technique for mediating access to sensitive resources
within a computer system. Fig. 1 presents a depiction of the
model considered for the purposes of this paper. Besides the
traditional sets of attributes, permissions and access entities
that have been previously discussed in the literature, our approach includes the concept of attribute sources and policy
makers. The former are in charge of deﬁning, creating and
assigning attributes to access entities, whereas the latter are
in charge of crafting policies by establishing a relationship
between attributes and permissions. Our model depicts an
open world scenario where attributes originating from diﬀerent sources may become relevant under the security domain
that is deﬁned by the policy makers. However, despite being
represented as diﬀerent sets in Fig. 1, the sets of attribute
sources and policy makers may not necessarily be mutually
exclusive in practice, as a policy maker may also play the
role of an attribute source when managing attributes deﬁned
within a certain security domain. In order to safely leverage
attributes, policy makers should somehow trust their corresponding sources. As an example, an attribute whose value
can be deliberately modiﬁed by the assigned entity may not
provide strong security guarantees, as such an entity may
be allowed to modify the attribute’s value at will to meet
the requirements deﬁned in a given policy. Therefore, policy makers should have conﬁdence on the attribute creation
and assignment process carried out by the sources. In our
model, we assume such attribute trust score can be modeled
as a binary value in the set {0,1}. This way, only attributes
depicting a trust score of 1 may be safely used for policy
crafting.
Electronic health records (EHRs) [3] increase the eﬃciency
of healthcare organizations by improving communication between clinicians and other health institutions leading to improved continuity and coordination of care. They also support clinician decision making by providing comprehensive
information about patients, thereby increasing quality of patient care. Complete and relevant information must be ac-

PA

AA

Access
Entities

Trust

Policy
Makers

Figure 1: A depiction of an ABAC model: attributes
are related to access entities (e.g., end-users and
protected resources) by means of the attribute assignment (AA) relation. Access rights (permissions)
are in turn related to access entities by the permission assignment (PA) relation. Policy makers are
in charge of establishing the PA relation by leveraging the attributes provided by the attribute sources,
who are in charge of managing the AA relation.
cessible to clinicians in a timely manner on a need-to-know
only basis within the set of privileges allowed by the patient, while unauthorized accesses to private data must be
prevented.
Table 1 shows an extract of attribute-based and access log
data depicting EHRs from diﬀerent users. As an example,
the entry depicted in the ﬁrst row shows an access request
to the EHR belonging to a user identiﬁed by the attribute
PatientID with a value of 11234. Such an access request
was denied, as shown by the value of the Decision attribute
set to False in the last column. Other attributes are shown
in Table 1 for illustrative purposes, and will be further discussed, along with their corresponding coloring scheme, in
Section 3.

3.

OUR APPROACH

As described in Section 1, we aim to develop an approach
based on MTD theory in such a way attacks to attributebased policies can be eﬀectively prevented. With this in
mind, we ﬁrst describe the attack model we take into consideration, followed by a description of our proposed approach and ﬁnalize with a short discussion on how our solution meets the goals for MTD as described in Section 2.

3.1

Attack Model and Assumptions

In this paper, we assume an attack model where the attributes listed in a given ABAC policy, e.g., in a policy rule
consisting of one or more constraints, become compromised
by an attacker, thus creating an unintended attribute-access
entity assignment, as depicted by the AA relation discussed
in Section 2. Diﬀerent ways an attacker may be able to compromise a given attribute may include, but may not be limited to the following: an unintended software error, forgery
or a hacking incident compromising the infrastructure where
attributes are created and assigned to entities, e.g., a remote
credential server.
In addition, we also assume the following: ﬁrst, the data
containing attribute-based information can be properly collected and is available for analysis. In the context of EHRs,
the application domain used for our running example, data
collection may include a preprocessing step in which data

Table 1: A sample set of attribute-based access log data depicting EHRs.
EHR ID Patient ID Patient Loc Personnel Loc
Role
Certification Decision
A11234
A11234
Surgery
General
Surgeon
MD
FALSE
A43452
A43452
ER
ER
Nurse
RA
TRUE
A83422
A83422
General
General
Physician
MD
TRUE
A56102
A56112
Pediatrics
Lab
Lab Tech
CLIA
FALSE
A23108
A23108
ER
ER
Physician
MD
TRUE
A76313
A77777
General
General
Nurse
RN
FALSE
A89736
A89736
Radiology
Radiology
Nurse
RA
TRUE
A24912
A24912
Surgery
Surgery
Surgeon
MD
TRUE
A87632
A87632
Radiology
Radiology
Physician
MD
TRUE
A34028
A34028
General
Pharmacy
Physician
MD
TRUE
End-Users

EId

PId

1

EHR
Data

EId

PId

Loc

3

2

Original
Policy

PLc

Mutation
Engine

Mutated
Policy

4

Access
Mediation
Module

Figure 2: A graphical depiction of our approach: the
original policy, defining a set of original attributes
(1), is fed to the mutation engine along with data
depicting an attribute bag (2). Such an engine identifies new attributes from users that are correlated
to the original ones (3), producing a mutated policy
that is later used for access mediation (4).
from the access logs is combined with information extracted
from EHRs themselves. As an example, Table 1 shows data
collected for each access request made in the context of an
EHR. For each request, the following items are shown: ﬁrst,
the resource being accessed, the result of evaluating the request, and a description of the attributes (included values)
shown at request time, a.k.a., the attribute bag. Second, we
assume that the software framework handling the speciﬁcation and runtime evaluation of ABAC policies, as well as
the software modules implementing our approach (including
the collection procedure described above), are out of reach
for an attacker. As an example, even when a given ABAC
policy, along with its listed attributes, may be known to the
attacker, he/she has no way to deliberately change its contents, either by removing the policy as a whole or by adding
or removing attribute-based rules at will.

3.2 Correlation-based Policy Mutation
A graphical depiction of our approach is shown in Fig. 2.
Initially, we model an ABAC policy P as a set of constraintbased rules R = {r1 , r2 , r3 , ..., rn } for some n > 0. For each
rule r ∈ R, we introduce the set Sr of attributes that are
listed in it. In addition, we also model the attribute bag as
described before as a set of attributes A such that A ∩ Sr
̸= ∅ for all r ∈ R.
Given the original policy P, our approach then aims to

produce a mutated policy P′ as follows: for each rule r ∈
R, we locate the set of attributes Cr = {c1 , c2 , ... cp } ⊆
A, Cr ̸= Sr , that are correlated to the set of attributes Sr .
Then, r may become a new rule r ′ by randomly choosing an
attribute c ∈ Cr such that Sr′ = Sr ∪ c 1 . Later, the set of
modiﬁed rules R′ = {r′ 1 , r′ 2 , ... r′ n } is combined together
to create the new mutated policy P′ . As shown in Fig. 2, P′
is forwarded to a policy evaluation module for further enforcement. We repeat the above procedure periodically in an
eﬀort to produce many diﬀerent policy mutations. For such
a purpose, an interactive approach may randomly produce
modiﬁed rules as shown above by selecting only a subset
of the set Cr of correlated attributes each time, in such a
way that the resulting rules may vary from time to time.
In addition, as time evolves, new correlated attributes may
be collected in the attribute bag, thus possibly producing
diﬀerent mutated policies as a result.
We reiterate that ﬁnding the set Cr of correlated attributes
is core to our approach. For such a purpose, we aim to ﬁnd
patterns relating the attributes in the attribute bag with
the ones contained in the set Sr of original attributes. For
illustrative purposes, assume a sample original policy based
on the data shown in Table 1, which contains a single rule
granting access to an EHR if the value of attribute EHR ID
is equal to the value depicted by the Patient ID one.
Our attribute correlation process can be then described
as follows: we start by ﬁrst ﬁnding the relationship between
the attributes in the original set Sr , e.g., EHR ID and Patient ID, and the access decision with a value of true, in
an eﬀort to identify within the data records depicting the
attribute bag, the ones that belong to the requested access
being granted according to our original policy. In Table 1,
such relation is represented by the cells colored in green.
Next, we strive to ﬁnd relationships between the original
set Sr (green), as identiﬁed by the previous step, and some
other attributes in the attribute bag. As an example, in
Table 1, the values of attributes Patient Loc and Personnel Loc are the same when the values of the attributes Patient ID, EHR ID are equal as well, and the access decision
depicts the value of true. Such a relationship is displayed
in Table 1 in the orange color. In order for this step to
be meaningful for our approach purposes, this relationship
should be as strong as possible, that is, the vast majority
of the records depicting the original attributes should also
depict the newly-correlated ones. Referring back to Table 1,

1

In case Cr = ∅, then r ′ = r.

the number of cells colored in green and the ones colored in
orange should be the same or stay within a close margin.
In a subsequent step, we also obtain the relationship between the original green attributes, the true access value,
and the inverse of the attributes depicted in orange obtained
from the previous step, e.g., the cells where the values for
the Patient Loc and Personnel Loc are not the same. Such a
relation is shown in the cells colored in purple in Table 1, and
represents the entities having legitimate access according to
the original policy but not holding the correlated attributes
depicted in orange. Following the intuition described for
the orange attributes, the number of cells colored in purple should be minimal with respect to the number of cells
in green and orange, as a large number would imply a potential impact to the usability of our approach, e.g., entities
getting previously-granted access denied as a consequence of
implementing our solution.
Next, we strive to identify the relationship between the
candidate orange attributes and the false access decision
value, in an eﬀort to make sure these newly-discovered correlated attributes are not shared by entities getting the false
access decision in the attribute bag data. The intuition behind this is that the orange attributes should only be assigned to the entities getting legitimate access according to
our original policy. Such a relationship is represented by
cells depicting the yellow coloring in Table 1. Ideally, the
number of cells in yellow should be minimal in respect to
the number of cells depicting the green and orange colorings, e.g., close to zero, as a large number of such yellow
cells would imply a potential security vulnerability.
With all this in mind, our approach should identify the
candidate orange attributes in such a way that their relation to the original ones (green) is strong, whereas the relation with both the yellow and purple ones is kept to a
minimum for safety and usability purposes, respectively. If
such conditions are met, the orange attributes are said to
depict the set Cr as described before, and can be then used
to create mutations of the original policy. Following our running example, the newly mutated policy may include a new
rule adding location of requirement of the values of Patient
Loc and Personnel Loc to be equal along with the previous
constraint relating the values of EHR ID and Patient ID.

3.3 Discussion
Following the discussion on MTD presented in Section 2,
our approach strives to reduce the probability of carrying
on a successful attack based on the model described in Section 3.1, by limiting the amount of time available for an
attacker to exploit a compromised attribute. For such a
purpose, we continuously mutate policies that leverage correlated attributes, such as the orange ones discussed above.
This way, even when an attacker may be able to compromise
an attribute in the original policy, the newly-correlated ones
may be able to deter the attack. Moreover, our approach is
also intended to avoid considerable impact to the usability of
the system being protected. As mentioned before, end-users
should not experience the rejection of previously-granted access requests as a result of the modiﬁcations made following
the MTD paradigm. We achieve this goal by calculating the
purple relation as describe above, and requiring it to be considerably less than the relation represented by the orange
one. Not enforcing such requirement may deviate in mutated policies that may reject previously-granted requests,

thus harming usability in a considerable way. Finally, even
when an attacker may be aware of our proposed approach,
we believe the continuous mutation of policies over time, as
described in Fig. 2, as well as by randomly selecting a subset
of orange attributes to appear on each mutation, may introduce a signiﬁcant level of deterrence against possible attacks,
e.g., predicting the next policy mutation. For such a purpose, we also assume the subset of orange attributes cannot
by compromised by an attacker, at least until the next policy mutation. We base such assumption on the fact that in
case an attacker can potentially modify any attribute at will
at any time (including both the green and orange ones), not
only our approach can be circumvented, but also the original
attribute-based policy (and any other policies) that may be
in place for access mediation purposes.

4.

CONCLUSIONS

In this position paper, we have presented an on-going approach for leveraging MTD in the context of attribute-based
policies. As of today, we are working towards reﬁning the
approach presented in Section 3. Concretely, we are formalizing our intuitions into a series of algorithms that leverage
well-established techniques such as association analysis [5].
In addition, we have started the codiﬁcation and evaluation
process on custom-designed synthetic data based on previous examples found in the literature. We also plan to expand such a process by incorporating data obtained from a
real-life EHR through a partnership with a healthcare organization. Finally, for the sake of eﬃciency, we plan to
perform diﬀerent performance measurements that include a
variety of attack scenarios.

Acknowledgments
This work was partially supported by a grant from the National Science Foundation (NSF-SFS-1129561), by a grant
from the Department of Energy (DE-SC0004308) and by a
grant from the Center for Cybersecurity and Digital Forensics at Arizona State University.

5.

REFERENCES

[1] V. C. Hu, D. Ferraiolo, R. Kuhn, A. Schnitzer,
K. Sandlin, R. Miller, and K. Scarfone. Guide to
attribute based access control (abac) deﬁnition and
considerations. NIST Special Publication, 800:162, 2014.
[2] S. Jajodia, A. K. Ghosh, V. Swarup, C. Wang, and
X. S. Wang. Moving target defense: creating
asymmetric uncertainty for cyber threats, volume 54.
Springer Science & Business Media, 2011.
[3] J. Jin, G.-J. Ahn, H. Hu, M. J. Covington, and
X. Zhang. Patient-centric authorization framework for
electronic healthcare services. Computers & Security,
30(2):116–127, 2011.
[4] C. E. Rubio-Medrano, Z. Zhao, A. Doupe, and G.-J.
Ahn. Federated access management for collaborative
network environments: Framework and case study. In
Proceedings of the 20th ACM Symposium on Access
Control Models and Technologies, SACMAT ’15, pages
125–134. ACM, 2015.
[5] R. Srikant and R. Agrawal. Mining quantitative
association rules in large relational tables. In ACM
SIGMOD Record, volume 25, pages 1–12. ACM, 1996.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
1

Towards Automated Risk Assessment and
Mitigation of Mobile Applications
Yiming Jing, Gail-Joon Ahn, Senior Member, IEEE,
Ziming Zhao, Student Member, IEEE and Hongxin Hu, Member, IEEE
Abstract—Mobile operating systems, such as Apple’s iOS and Google’s Android, have supported a ballooning market of featurerich mobile applications. However, helping users understand and mitigate security risks of mobile applications is still an ongoing
challenge. While recent work has developed various techniques to reveal suspicious behaviors of mobile applications, there exists
little work to answer the following question: are those behaviors necessarily inappropriate? In this paper, we seek an approach to
cope with such a challenge and present a continuous and automated risk assessment framework called R ISK M ON that uses machinelearned ranking to assess risks incurred by users’ mobile applications, especially Android applications. R ISK M ON combines users’
coarse expectations and runtime behaviors of trusted applications to generate a risk assessment baseline that captures appropriate
behaviors of applications. With the baseline, R ISK M ON assigns a risk score on every access attempt on sensitive information and
ranks applications by their cumulative risk scores. Furthermore, we demonstrate how R ISK M ON supports risk mitigation with automated
permission revocation. We also discuss a proof-of-concept implementation of R ISK M ON as an extension of the Android mobile platform
and provide both system evaluation and usability study of our methodology.
Index Terms—Smartphones, Android, Risk Assessment, Risk Mitigation

✦

1

I NTRODUCTION

M

OBILE operating systems, such as Android and
iOS, have tremendously supported an application market over the last few years [2], [3]. Such a
new paradigm drives developers to produce featurerich applications that seamlessly cater towards users’
growing needs of processing their personal information
such as contacts, locations and other credentials on their
mobile devices. Unfortunately, the large installed base
has also attracted attention of unscrupulous developers
who are interested in users’ sensitive information. For
example, spyware tracks users’ locations and reports to
remote controllers, and adware collects users’ identities
for enforcing an aggressive directed marketing.
To defend against such rogue applications, Android
assists users to review them at install time. Primarily,
Android relies on permissions to help users understand
the security and privacy risks of applications. In Android, an application must request permissions to be
allowed to access sensitive resources. In other words,
it is mandatory for Android applications to present its
expected behaviors to users. Even though permissions
outline the resources that an application attempts to
This is an extended and enhanced version of the paper [1] that appeared in
ACM CODASPY 2014.
• Y. Jing, G.-J. Ahn and Z. Zhao are with the Security Engineering for
Future Computing (SEFCOM) Laboratory, and the Ira A. Fulton School
of Engineering, Arizona State University, Tempe, AZ 85287, USA. G.-J.
Ahn is also with GFS Technology, Inc. All correspondence should be
addressed to Dr. Gail-Joon Ahn. Email: {ymjing, gahn, zmzhao}@asu.edu.
• H. Hu is with the Division of Computer Science, School of
Computing, Clemson University, Clemson, SC 29634, USA. Email:
hongxih@clemson.edu.

access, they do not provide fine-grained information
about how such resources will be used. Suppose a user
installs an application and allows it to access her location
information. It is hard for her to determine whether
the application accesses her locations on her demand
or periodically without asking for her explicit consent.
Therefore, it is imperative to continuously monitor the
installed applications so that a user could be informed
when rogue applications abuse her sensitive information. Previous work has proposed real-time monitoring
to reveal potential misbehaviors of third-party applications [4]–[7]. While these techniques partially provide
valuable insights into a user’s installed applications, it
is still critical to answer the following challenge: are the
behaviors in mobile applications necessarily inappropriate?
To answer this question, it is an end-user’s responsibility to conduct risk assessment and make decisions based
on her disposition and perception. Risk assessment is
not a trivial task because it requires the user to digest
diverse contextual and technical information. In addition, the user needs to apprehend expected behaviors of
applications under different contexts prior to addressing
her risk assessment baseline. However, it is impractical
for the normal users to distill such a baseline. Instead,
it is essential to develop an automated approach to
continuously monitor applications and effectively alert
users upon security and privacy violations.
In this paper, we propose an automated and continuous risk assessment framework for mobile platforms,
called R ISK M ON. R ISK M ON requires a user’s coarse
expectations for different types of applications while
user intervention is not required for the subsequent
risk assessment. To this end, R ISK M ON leverages a one-

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
2

time initialization process where a user provides her
selection of trusted applications and her ranking of
permission groups in terms of their relevancy to the
corresponding applications. Then, R ISK M ON builds a
risk assessment baseline based on the runtime behaviors of the user’s selected trusted applications and her
ranking of permission groups. After the baseline is established, R ISK M ON continuously monitors every installed
application’s behaviors, including their interactions with
other applications and system services. The risk of each
interaction is measured by how much it deviates from
the risk assessment baseline. For a better risk perception,
R ISK M ON ranks the installed applications based on the
risk assessment results in a real-time manner. Intuitively,
the user can deem an application as safe if it is less risky
than any of her trusted applications.
To facilitate risk mitigation, we further propose a
decision process to automatically revoke risky permissions. Whereas simply uninstalling risky applications
might disrupt user experiences, our decision process
automatically confines unnecessary privacy-infringing
code and meanwhile retains core functionalities of applications. Tools like R ISK M ON would practically help
raise awareness of security and privacy problems and
lower the sophistication required for concerned users to
better understand and mitigate the risks of third-party
mobile applications.
This paper makes the following contributions:
•

•

•

•

•

We propose a methodology for establishing a risk
assessment baseline from a user’s trusted applications and her coarse expectations;
We propose a machine-learned ranking based
framework that continuously monitors the behaviors of installed applications, automatically measures their risks, and intuitively presents the risks;
We propose an automated decision process that
selectively revokes risky permissions with minimal
impact on an application’s usability;
We implement a proof-of-concept prototype of
R ISK M ON and demonstrate how it can be seamlessly deployed in Android; and
We evaluate R ISK M ON with comprehensive experiments, case studies, and crowd-sourced user surveys. Our experimental results demonstrate the feasibility and practicality of R ISK M ON.

The remainder of this paper proceeds as follows.
Section 2 provides the motivation and background of
this paper. Section 3 provides an overview of R ISK M ON
and illustrates the stages of automated risk assessment.
Section 4 describes how R ISK M ON supports automated
permission revocation. Section 5 presents the prototype
implementation and evaluation. Section 6 discusses limitations of our approach. Section 7 discusses related work
and Section 8 concludes this paper.

2

M OTIVATION AND BACKGROUND

Recent work has proposed mechanisms to extract risk
signals from meta information on application markets
such as permissions [8]–[11], ratings [12], [13], and application descriptions [14]. Their limitation is that such
information is not directly related to how and when
sensitive resources are used. Whereas an application
requests location-related permissions, it may stay in the
background and keep probing a user’s locations and
surroundings. Furthermore, users deserve the rights to
know what is happening on their own devices. Therefore, continuously monitoring applications’ behaviors is
indispensable towards effective risk assessment.
Previous research concerning applications’ runtime
behaviors specifies a set of risk assessment heuristics
tailored to their specific problems. For example, TaintDroid [4] considers a case in which sensitive data is
transmitted over the network. DroidRanger [15] and
RiskRanker [16] assume that dynamically loaded code is
a potential sign of malware. While these techniques provide valuable insights about runtime behaviors of mobile
applications, they do not justify the appropriateness of
the revealed behaviors. We argue that meta information
can provide the necessary operational contexts that justify runtime behaviors for risk assessment. For example,
a location-based application has good reasons to upload
a user’s locations for discovering nearby restaurants. In
contrast, it does not make sense for a video player to use
the locations and such behaviors should be considered
as more risky.
Finally, we need to consider how users participate
in risk assessment. First, different users would have
disparate security requirements. Thus, we should grant
users the capabilities to specify their preferences in terms
of accessing their own sensitive information. Moreover,
normal users do not possess the necessary technical
knowledge for assessing applications’ runtime behaviors and interpret numerical risk scores. Therefore, it is
imperative to automate risk assessment in a way that
requires less sophistication and intervention.
2.1 Background: Android Platform
Permission groups: Permission group is a logical collection of related permissions defined by Android. For example, SOCIAL_INFO includes permissions that access
a user’s contacts and call logs. Most permission groups
are self-descriptive, such as LOCATION and CAMERA.
Android also provides a short description for each permission group to elaborate its corresponding resources.
Binder IPC framework: While APIs enable applications to interact with each other and system services
in their respective process sandboxes, they are implemented based on an underlying inter-process communication framework called Binder. It serializes data objects
as parcels for sender process, and de-serialize parcels for
recipient process. Binder also manages IPC transactions
in which parcels are processed and delivered.

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
3

3.1 Application Intelligence Aggregator

Android Applications
GooglePlay

Device

User

Meta
Information

Binder
Transactions

Security
Requirements

Application Intelligence
Aggregator

Baseline
Learner

Risk
Meter

3.1.1 Features for Binder Transactions

RiskMon

Fig. 1. R ISK M ON Architecture for Android

3

This component aggregates intelligence about a user’s
installed applications, including their runtime behaviors
and operational contexts. As we capture applications’
runtime behaviors by interposing the Binder IPC framework and log the Binder transactions, we propose a set of
features tailored to the peculiarity of Binder IPC. Also,
we derive operational contexts from meta information
available on application markets. We also propose features to represent and characterize them. These features
build a space of application intelligence and enable
subsequent baseline generation and risk measurement.

AUTOMATED R ISK A SSESSMENT

IT risk assessment guidelines, such as NIST SP 80030 [17] and CERT OCTAVE [18], provide a foundation for
the development of effective risk management processes.
They illustrate comprehensive methodologies that enable organizations to understand, assess and address
their information risks. While these guidelines deal with
the infrastructure and organizational risks by security
experts, our framework attempts to adapt and automate
the sophisticated risk assessment tasks for general users.
To this end, R ISK M ON needs to acquire a user’s expected appropriate runtime behaviors, assess the risks
of installed applications, and intuitively present the risks
to the user. There remain several challenges in achieving
these goals. First, suppose users cannot directly specify
runtime behaviors. R ISK M ON addresses this issue by
leveraging a user’s trusted applications to provide her
expected behaviors. For example, Netflix and Pandora
share the same core functionalities such as the streaming personalized media contents from remote servers.
Hence, if a user trusts Netflix and derives a risk assessment baseline from its behaviors, the deviation or
“distance” of the behaviors between Pandora and the
baseline indicates Pandora’s additional risks. However,
a subsequent problem is how to measure the distance
between runtime behaviors. Our proposed solution is
to define a space with features extracted from Binder
transactions and meta information of applications. Finally, a numerical distance does not appeal to users with
respect to effective risk perception. We adopt a ranking
of applications by their risks and a compositional view
of risks for each application to intuitively present the
measured risks.
Figure 1 depicts the R ISK M ON architecture for Android. Our framework consists of three components: an
application intelligence aggregator, a baseline learner,
and a risk meter. The remainder of this section describes
each component in detail.

Android applications’ runtime behaviors are essentially
Binder IPC transactions that interact with system services and other applications. In this work, we only analyze permission-protected Binder transactions, assuming
that a user’s assets are only reachable through these
transactions. Therefore, we need to identify the mappings from permissions to Binder transactions.
Specifically, we adopt existing work [19], [20] to provide the mappings from permissions to APIs. Meanwhile, we parse the AIDL1 files in the AOSP repository to generate the mappings from APIs to Binder
transactions. Connecting these two mappings together,
we derive 1,003 types of permission-protected Binder
transactions. Each of them is identified by a unique
Binder interface name, direction of control flow (synchronous call or asynchronous callback), and a numerical command code. For example, a permission
ACCESS_FINE_LOCATION protects a type of Binder
IPC transaction “ILocationManager-callback-1”.
We note that one permission may protect multiple types
of Binder transactions.
We attempt to represent a Binder transaction with its
internal properties and contents. For a specific Binder
transaction between an application and a system service,
we are interested in its type to identify the corresponding
asset. Also, we need to know the direction of control flow
for determining who initiates the transaction. As users
trust the system services more than applications, R ISK M ON should differentiate Binder transactions initiated
by applications or system services. Thus, we propose
the following Boolean features to capture the internal
properties:
•

•

Type of Binder transaction: 1,003 Boolean features
as a bit array, where one bit is set to 1 for the
corresponding transaction type and the others are
0; and
Direction of control flow: another Boolean feature,
where 0 for transactions initiated from applications
(calls), 1 for transactions initiated from system services (callbacks).

1. Android Interface Definition Language, http://developer.android.
com/guide/components/aidl.html

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
4

In terms of contents, parcels in Binder transactions
are unstructured and highly optimized, and it is hard
to restore the original data objects without the implementation details of the sender and recipient. Therefore,
we use length as one representative feature of parcels.
A motivating example is accesses on contacts. From the
length of a parcel we can infer whether an application
is reading a single entry or dumping the entire contact
database. In summary, we propose the following two
features for parcels:
• Length of received parcel: length of the parcel
received by an application in bytes; and
• Length of sent parcel: length of the parcel sent by
an application in bytes.
These features are scaled and then standardized to zero
mean and unit variance. Note that we empirically choose
0-4KB as the range of parcel lengths. In our experiments,
we found that the parcels larger than 4KB exceeded
the limit of the Binder transaction buffer and were
discarded. However, Android applications sometimes
encapsulate file descriptors in parcels to transfer large
bulks of data. We will deal with this situation in our
future work.
3.1.2

Features for Meta Information

We inspect three application markets, including Apple
App Store, Google Play, and Amazon Appstore. They all
share several common meta properties that reflect users’
and developers’ opinions. We leverage such properties
to propose corresponding features for meta information.
Specifically, we use the following features to represent
users’ opinions:
• Number of installs: a range of total number of
installs since the first release2 . We use logarithmic
value of the lower bound, i.e., log(1+lower bound of
#installs) and scale to [0,1];
• Number of reviews: a number of reviews written
by unique users. We use the logarithmic value, i.e.,
log(1+#reviews) and scale to [0,1]; and
• Rating score: a number indicating the user-rated
quality of the application ranged from 1.0 to 5.0,
scaled to [0,1].
These three features capture an application’s popularity and reputation. The first two features are similar to
number of views or comments in online social networks.
Recent studies [21] demonstrated that online social networks and crowd-sourcing systems expose a long-tailed
distribution. Therefore, we assume they follow the same
distribution and use logarithmic values.
We emphasize that we do not attempt to extract risk
signals from these features. Instead, we adopt these
features to capture the underlying patterns of a user’s
trusted applications as specified by the user and apply
the patterns for the subsequent risk assessment.
2. The number of installs is specified with exponentially increasing
ranges: 1+, 5+, . . . , 1K+, 5K+, . . . , 1M+, 5M+.

Fig. 2. SOM Representation of 13 Categories
Next, we propose a feature to capture developers’
opinions:
• Category: a tuple of two numerical values normalized to [-0.5, 0.5].
An application’s category describes its core functionalities (e.g., “Communication”). Note that each application
market may define its specific application categories. As
we focus on Android applications in this work, we use
the categories defined by Google Play throughout the
remainder of this paper.
We adopt the Self-Organizing Map (SOM) in a previous work by Barrera et al. [22] to derive a twodimensional representation of categories. SOM can produce a discretized representation of permissions requested by different categories of Android applications.
Categories in which applications request similar permissions are clustered together. Therefore, the x and y
coordinates in the map can represent a category, and
categories with similar core functionalities would be
closer to each other. Figure 2 depicts the coordinates of
13 categories as an example. Apparently, some categories
bear underlying similarities, such as “Entertainment”,
“Media and Video” and “Music and Audio”.
An unscrupulous developer can claim an irrelevant
category to disguise an application’s intended core functionalities. However, a user can easily notice the inconsistencies and remove such an application. In addition,
falsifying an application’s meta information violates the
terms of application market’s developer policies and
may lead to immediate takedown.
Finally, based on the scheme defined by these features, the application intelligence aggregator generates
a dataset consisted of feature vectors extracted from
Binder transactions and meta information of each installed application.
3.2 Baseline Learner
The baseline learner is the core module of R ISK M ON.
It takes two types of inputs, which are a user’s expectations and feature vectors extracted by the application
intelligence aggregator. Then the baseline learner generates a risk assessment baseline that is represented as a
predictive model.

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
5

3.2.1

Acquiring Security Requirements

Facebook

It is challenging for most users to express their security
requirements accurately. We aim to find an approach
that could be mostly acceptable by users. Krosnick and
Alwin’s dual path model [23] demonstrated that a satisficing user would rely on salient cues to make a decision.
Based on this model we develop a simple heuristic:

Skype

Relevant
1
Low risk

For a specific application, accesses on resources that
are more irrelevant of a user’s expected core functionalities incur more risks.
Core functionalities of an application are obvious to
most users, and we use such “salient cues” to support
automated risk assessment. Furthermore, the heuristic
captures a user’s expectations by risk aversion, which
implies the reluctance of a user to use a functionality
with an unknown marginal utility [24]. For example,
a user may consider that, microphone is necessary to
a VoIP application such as Skype. But location seems
not because she does not understand the underlying
correlation between disclosing her location and making
a phone call. Thus, microphone is more relevant and less
risky than location in her perception.
Based on this, the risk learner asks a user to specify a
relevancy level for each permission group requested by
her trusted applications. We choose permission groups
to represent resources because it is much easier for
general users to learn 20+ permission groups than 140+
permissions. And recent usability studies demonstrated
the ineffectiveness of permissions due to limited comprehension [25], [26]. Although users tend to overestimate
the scope and risk of permission groups, they are more
intuitive and reduce warning fatigue [25].
The process for users to communicate their security
requirements with R ISK M ON is similar to a short questionnaire. Each permission group requested by a user’s
trusted applications corresponds to a five-point Likert
item. The user specifies the level of relevancy on a symmetric bipolar scale, namely relevant, probably relevant,
neutral, probably irrelevant or irrelevant. Figure 3 shows an
example of relevancy of permission groups for Facebook
and Skype. Permission groups are represented by selfdescriptive icons, which are identical to those shown
in Android Settings. CAMERA preceding LOCATION for
Facebook is possibly due to the user’s preference to
photo sharing compared to check-ins.
Note that the relevancy levels specified by users are
subjective. With that said, users’ biased perception of
applications and resources may affect their specified
relevancy levels. From our user study, a user told us
that PHONE_CALLS is relevant to Google Maps because
he tapped a phone number shown in Google Map and
then the dialer appeared. Although the dialer rather than
Google Map has the capability to make phone calls, the
baseline learner considers it as the security requirements
for inter-application communication.

2

3
Neutral

4

Irrelevant
5
High risk

Camera

Contacts

Phone Calls

Location

Microphone

Network

Fig. 3. An Example of Specifying Relevancy for Permission Groups
We next formalize the problem of acquiring security
requirements as follows:
•

•

•

•

•

A = {a1 , a2 , · · · , an } is a set of a user’s installed
applications;
AT is a set of a user’s trusted and installed applications and AT ⊆ A;
P G = {pg1 , pg2 , · · · , pgm } is a set of permission
groups available in a mobile operating system;
RL = {1, 2, 3, 4, 5} is a set of relevancy levels, where
a larger value indicates higher relevancy and less
risk and vice versa; and
Req is a user’s security requirement, which is essentially a mapping Req : AT × P G → RL.

3.2.2 Compiling Training Set
Next we describe how the baseline learner compiles a
training set. Simply put, it annotates vectorized Binder
transactions with user-specified relevancy levels.
To bridge the gap between permission groups and feature vectors, we extract mappings of permission groups
and permissions from the source code of Android. Meanwhile, existing work has provided mappings between
permissions and APIs [19], [20]. Therefore, we can assign the relevancy level on feature vectors because each
vector represents an API call or callback.
We formalize the problem of compiling a training set:
•

•

•

X is a set of vectorized Binder transactions generated by a user’s installed applications, where the
features are extracted from properties of Binder
transactions (Section 3.1.1) and meta information of
the corresponding applications (Section 3.1.2);
XT is a set of vectorized Binder transactions generated by the user’s trusted and installed applications,
XT = {~x|~x ∈ X, ~x is generated by a, a ∈ AT }; and
T = {(~x1 , rl1 ), (~x2 , rl2 ), · · · , (~xn , rln )} is a training
set of annotated vectors, ~xk ∈ XT , rlk ∈ RL.

We define two helper functions:
•

•

GetA : XT → AT is a function that maps a vector to
its corresponding application; and
GetP G : XT → P G is a function that maps a vector
to its corresponding permission group.

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
6

Algorithm 1 illustrates the process to compile the
training set T , where feature vectors from XT are annotated with relevancy levels specified by a user’s security
requirements.
Algorithm 1: Compiling Training Set
Data: XT , Req
Result: T
T ← ∅;
for ~x ∈ XT do
a ← GetA(~x); pg ← GetP G(~x);
rl ← Req(a, pg);
add (~x, rl) to T;
end
return T

(1)

where ≺ denotes a preferential relationship of risks.
In the simplest form of RSVM, we assume that f is a
linear function:
fw~ (~x) = hw,
~ ~xi,
(2)
where w
~ is a weight vector, and h·, ·i denotes inner
product.
Combing (1) and (2), we have the following:
~xi ≺ ~xj ⇐⇒ hw,
~ ~xi − ~xj i < 0,

(3)

Note that ~xi − ~xj is a new vector that expresses the
relation ~xi ≺ ~xj between ~xi and ~xj . Given the training
set T , we create a new training set T ′ by assigning either
a positive label z = +1 or a negative label z = −1 to each
pair (~xi , ~xj ).

+1
if ri > rj
(~xi , ~xj ) : zi,j =
−1
if ri < rj
(4)
∀(~xi , ri ), (~xj , rj ) ∈ T
To select a ranking function f that fits the training set
T ′ , we construct the SVM model to solve the following
quadratic optimization problem:
X
1
w
~ ·w
~ +C
ξi,j
2
w
~
subject to ∀(~xi , ~xj ) ∈ T ′ : zi,j hw,
~ ~xi − ~xj i ≥ 1 − ξi,j
∀i∀j : ξi,j > 0
(5)
Denoting w
~ ∗ as the weight vector generated by solving
(5), we define the risk scoring function fw~ ∗ , for assigning
minimize

For any ~x ∈ X, the risk scoring function measures
its projection onto w
~ ∗ , or the distance to a hyperplane
whose normal vector is w
~ ∗ . Thus, the hyperplane is
indeed the risk assessment baseline.
3.3 Risk Meter

3.2.3 Generating Risk Assessment Baseline
Duh [27] shows that Ranking Support Vector Machine
(RSVM) [28] performs better than regression with respect
to eliciting human judgement in evaluating machine
translation systems. Next, we explain how we apply
RSVM to derive a risk assessment baseline for assessing
mobile applications.
We assume that a set of ranking functions f ∈ F exists
and satisfies the following:
~xi ≺ ~xj ⇐⇒ f (~xi ) < f (~xj ),

risk scores to the feature vectors (i.e., vectorized Binder
transactions):
~ ∗ , ~xi
(6)
fw~ ∗ (~x) = hw

Risk meter measures the risks incurred by each installed
application, including a user’s trusted application as
well. Note that (6) gives a signed distance. In (7) we use
the absolute value to represent the deviation and risk,
because the sign simply indicates whether ~x is on one
side of the RSVM’s margin or the opposite. The risks
incurred by an application ai are the cumulative risks of
its Binder transactions:
X
(7)
|fw~ ∗ (~x)|, where ~x is generated by ai .

Another goal of the risk meter is to provide supporting
evidences to end-users. To this end, it presents the
measured risks at 3 levels of granularities.
Application: In the simplest form, the risk meter
presents a ranking of installed applications by their risks
as a bar chart. The X axis indicates the applications
and the Y axis indicates the risks. A user can trust an
application if it is less risky than her trusted ones. In
contrast, an application that is significantly risky can also
draw a user’s attention.
Permission group: The ranking of applications may
seem unconvincing sometimes for users. In such a case,
the risk meter can provide risk composition by permission groups that is represented as a pie chart. The
pie chart intuitively reveals the proportion of the risks
incurred by the core functionalities of an application. As
users have basic knowledge of permission groups when
they specify security requirements, they should be able
to interpret the risk composition correctly.
Permission: Considering a user’s limited comprehension of permissions, we do not present general users
with the evidences that are more fine-grained than
permission groups. Evidences presented at this level
are intended for experienced users who would like to
tune up their security requirements. Particularly, our
automated risk mitigation mechanism (Section 4) also
utilizes these evidences for permission revocation.
Moreover, R ISK M ON allows a user to establish and revise her security requirements iteratively. R ISK M ON may
generate biased or unconvincing evidences as a user may
not have clear and accurate security requirements at the
very beginning of using R ISK M ON. Thus, a user can provide her feedback by adjusting her security requirements
and/or adding more trusted applications. R ISK M ON also
periodically updates the security assessment baseline for
observed new runtime behaviors. All of these enable
R ISK M ON to approximate an optimum risk assessment
baseline to help users make better decisions.

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
7

4

AUTOMATED R ISK M ITIGATION

-0.6

-0.4

-0.2

0.0

0.2

0.4

0.6

0.8

0.6

0.6

Based on the proposed risk assessment framework, we
move one step further to address risk mitigation. Specifically, we propose an automated decision process that
assists users to conveniently identify and revoke risky
permissions from installed applications.
A typical permission framework, just like common
access control systems, involves decision processes that
grant and revoke permissions. While permission granting has been widely adopted in modern mobile platforms, permission revocation has not received a commensurate popularity. For example, iOS users could not
deny accesses to their personal information until iOS 6.
Google introduced App Ops as an experimental privacy
control framework in Android 4.3, but later disabled its
management interface in Android 4.4.2 [29].
Permission revocation is necessary because it enables
complete and flexible control over granted capabilities.
To this end, recent work has proposed enhanced middleware mandatory access control (MMAC) frameworks
to support rule-driven permission revocation on Android [30]–[34]. An obvious limitation of such frameworks lies in the definition and maintenance of the
rules [35], which place non-negligible burden on general
users. To say the least, it remains an open question
whether users can accurately cherry-pick the risky permissions that should indeed be revoked.
Intuitively, R ISK M ON could provide the necessary
evidences to support a permission revocation decision
process. However, Android by default only allows users
to mitigate unnecessary risks is removing risky applications. Such an arbitrary approach may disrupt user
experiences. For example, grey applications (e.g., adsupported games) are likely to request excessive permissions for harvesting user information. Revoking all the
granted permissions (i.e., removing application) seems
unnecessary because some permissions are not major
sources of risks and they may support functionalities
that a user needs. Our goal is to selectively revoke
risky permissions and mitigate future risks to a user’s
expected level. Therefore, those grey applications might
still retain necessary functionalities and users could stay
protected from privacy-infringing code.
We identify three key challenges in bridging the gap
between risk assessment and risk mitigation: (1) selecting reference applications; (2) estimating risk budgets; and (3) enforcing decisions with minimal user
intervention. Reference applications implicitly provide a
user’s expected runtime behaviors and upper bounds of
acceptable risks. Risk budgets quantitatively determine
decision thresholds that line up with the user’s risk
mitigation strategies. Moreover, we need to minimize
user intervention in decision enforcement, because general users would be incapable and reluctant to create
and manage security policies. We next describe how we
address these challenges.

1.0

News
0.4

Communication
Social
r=R/2

0.4

Game
0.2

0.2

Entertainment
0.0

R = 0.652

Shopping
Travel

Media
Music

0.0

Tools

-0.2

-0.2

Productivity
-0.4

-0.4

Books
Finance

-0.6
-0.6

-0.4

-0.2

0.0

0.2

0.4

0.6

0.8

-0.6
1.0

Fig. 4. An Example of Selecting Reference Applications
from Close Categories

4.1 Selecting Reference Applications
As we previously assumed, a user’s trusted applications
define her expected appropriate behaviors for similar
applications. To select a set of reference applications for
a target application, we prefer trusted applications that
are under the same or close categories because their core
functionalities tend to be similar. Therefore, we assign
coordinates to all the installed applications according to
their categories in the category SOM. Then, we select the
reference applications by computing a set of k-nearest
trusted applications based on their Euclidean distances.
The best choice of k depends on the category SOM and
the number of the trusted applications. Here we adopt
a conservative approach to avoid over-generalization
that could lead to over-estimation of risk budgets. First,
we start from k ≤ ⌊log2 |AT |⌋. Meanwhile, we need
to filter this set by removing applications that are not
close enough to the target application. To quantitatively
define “close”, we compute the smallest enclosing circle
of the category SOM and its radius R, and choose
R/2 as the threshold of close categories. In summary,
a target application a’s reference application set ARa is
the intersection of the following sets:
1) ⌊log2 |AT |⌋-nearest trusted applications; and
2) the trust applications whose Euclidean distance
from a is no larger than r, where r = R/2.
Figure 4 demonstrates an example of selecting reference
applications for a social application. The result is no
more than ⌊log2 |AT |⌋ applications under the “Social”,
“Communication”, and/or “Entertainment” categories.
Automated risk mitigation is also limited by the same
problem of insufficient trusted applications as automated
risk assessment. ARa could be empty because AT does
not cover sufficient categories. In such a case, reselecting
reference applications is scheduled after a user adds
trusted applications and improves coverage.

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
8

4.2

Estimating Risk Budgets

Risk budgets define decision thresholds used in our
automated decision process. Our goal is to derive a risk
budget for each permission of a target application from
its reference applications.
We next formalize the problem of estimating risk
budgets for a target application a as follows:
• P = {p1 , p2 , · · · , pn } is a set of permissions available
in a mobile operating system;
P
• U sedP : A → 2
is a function that maps an
application to a set of permissions whose usage
patterns have been observed by R ISK M ON;
• P AR : P × A → R is a function that maps a granted
permission of an application to its measured risk
score; and
S
• BIa =
ta∈ARa U sedP (ta) is a set of permissions
that are the budget items for an application a.
We then introduce the following budget estimation
functions to support different risk mitigation strategies,
where p ∈ U sedP (a), a ∈ A, a ∈
/ AT , ARa ⊂ AT :
(
min P AR(p, ta) if p ∈ BIa
ta∈ARa
Stricta (p) =
0
if p ∈
/ BIa
(
avg P AR(p, ta) if p ∈ BIa
ta∈ARa
Averagea (p) =
(8)
0
if p ∈
/ BIa

 max P AR(p, ta) if p ∈ BIa
ta∈ARa
Relaxeda (p) =
/ BIa
 avg P AR(p, ta) if p ∈
ta∈AT

The strict function prefers the most privacypreserving practices of the reference applications. The
average function attempts to reduce the risks below
the average practices. For the permissions not among
the budget items, the strict and average functions
both opt for a zero tolerance strategy. In contrast, the
relaxed function allows such permissions but their
incurred risks should not exceed the average of all the
trusted applications.
4.3

Generating and Enforcing Decisions

To generate a decision for a permission p of an application a, we compute its cumulative risks as Riska (p)
and apply a user-specified budget estimation function,
for example:

Keep
if Riska (p) ≤ Stricta (p)
Decision(a, p) =
Revoke if Riska (p) > Stricta (p)
(9)
Note that an important criterion of our decision process
is revoking by observed behaviors 3 .
Managing security policies for complex information
systems has been a challenging task. It is even harder
for dynamic systems such as the Android middleware,
3. Intuitively, dormant permissions do not incur any risks so we
choose not to revoke them because we have no observed evidence to
prove that such permissions will be abused.

whose security policies have to confine various applications that rapidly update themselves. Enforcing security
decisions for such systems would be unrealistic for
general users because it consumes much user attention
and leads to habituation [36]. This partially implies why
Android community has been careful with integrating
user-oriented and generic permission revocation [29].
We introduce automated policy generation to address
this challenge. Specifically, automated permission revocation and policy generation are activated after (1) a
user installs or updates a new application; (2) a user
updates her risk assessment baseline; or (3) a pre-defined
time period. Note that we do not attempt to implement
our own policy enforcement mechanisms. Instead, our
framework could be easily adapted to support new
middleware MAC frameworks with an intuitive policy
translation module.

5

I MPLEMENTATION AND E VALUATION

In this section we first discuss a proof-of-concept implementation of R ISK M ON. Then, we present the results of
our online user study followed by the case studies of
automated risk assessment and mitigation. We conclude
our evaluation with the usability and performance.
5.1 Implementation and Experimental Setup
We implemented a proof-of-concept prototype of R ISK M ON on the Android mobile platform. In terms of continuous monitoring, we implemented a reference monitor for Binder IPC by inserting hooks inside the Binder
userspace library. The hooks tap into Binder transactions
and log the parcels along with senders’ and recipients’
UIDs4 . In addition, we implemented automated risk
assessment based on SVMLight5 and its built-in Gaussian radial basis function kernel. To tune the SVM for
better performance, we used a grid-search to test an
exponential sequence of C = 10−5 , 10−4 , . . . , 105 , where
C is the penalty parameter. The other parameters kept
their default values as provided by SVMLight.
We conducted a user study of 33 participants to
evaluate the practicality and usability of R ISK M ON. We
hand-picked 10 applications (Table 1) that were most
downloaded from Google Play in their respective categories. We assumed that all the participants trust them.
Then we used participants’ security requirements for
the 10 applications and their application intelligence
to generate the baselines. We also randomly selected 4
target applications from the Top Charts of Google Play
to calculate their risks based on the generated baselines,
including: a) CNN App for Android Phones (abbreviated as CNN); b) MXPlayer; c) Pandora Internet Radio
(abbreviated as Pandora); and d) Walmart. For both
trusted (10) and target (4) applications, we collected their
one-day runtime behaviors on a Samsung Galaxy Nexus
4. Ad libraries are assessed separately in case of ADSplit [37].
5. http://svmlight.joachims.org/

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
9

TABLE 1
Applications Assumed to be Trusted by the Participants
in the User Study
Application
AmazonMobile
BejeweledBlitz
ChaseMobile
Dictionary.com
Dropbox
Google+
GooglePlayMovies&TV
Hangouts(replacesTalk)
MoviesbyFlixster
Yelp

Category
Shopping
Game
Finance
Books & Reference
Productivity
Social
Media & Video
Communication
Entertainment
Travel & Local

(a) Chase Mobile

TABLE 2
Demographics of the Participants

Gender
Age

Education

Category
Male
Female
18-24
25-34
35-54
Graduated high school or equivalent
Some college, no degree
Associate degree
Bachelor’s degree
Post-graduate degree

# of users
29 (87.9%)
4 (12.1%)
15 (45.5%)
16 (48.5%)
2 (6.1%)
3 (9.1%)
6 (18.2%)
1 (3.0%)
11 (33.3%)
12 (36.4%)

phone. In addition, we developed a web-based system 6
that acquires a participant’s security requirements, feeds
them to R ISK M ON and presents the results calculated
by R ISK M ON to the participant. A participant was first
presented with a tutorial page that explains how to
specify relevancy levels as her security requirements.
Then she was required to set relevance levels for each
permission group requested by each trusted application
after reading the application’s descriptions on Google
Play. Afterwards, R ISK M ON generated a risk assessment
baseline for the participant based on her inputs and
runtime behaviors of the 10 trusted applications. Then
R ISK M ON applied the baseline on each of the 14 applications, and displayed a bar chart that illustrates a
ranking of 14 applications by their measured cumulative
risks. Finally, an exit survey was presented to collect the
participant’s perceived usability of R ISK M ON. Our study
protocol was reviewed by our institution’s IRB. And we
recruited participants through university mailing lists
and Amazon MTurk. Table 2 lists the demographics of
the 33 participants.
5.2
5.2.1

Empirical Results
Security Requirements

From our user study on the applications shown in
Table 1, we highlight the results of Chase Mobile and
6. Screenshots are available at http://goo.gl/xIuYp1

(b) Dropbox

Fig. 5. Average Relevancy Levels Specified by the Participants for Chase Mobile and Dropbox

Dropbox because they both request some ambiguous
permission groups that are hard to justify for users.
Figure 5 demonstrates the average relevancy levels set
by the participants for each permission group requested
by Chase Mobile and Dropbox. The error bars indicate
the standard deviation.
Chase Mobile is a banking application with functionalities like depositing a check by taking a picture and
locating nearest branches. Apparently NETWORK is more
relevant than others as participants agree that Chase Mobile needs to access the Internet. Even though Chase Mobile uses LOCATION to find nearby bank branches and
CAMERA to deposit checks, both LOCATION and CAMERA
have lower relevancy levels than NETWORK. We believe it
is because some participants do not have the experiences
of using such functionalities, but the averages are still
higher than neutral. Furthermore, SOCIAL_INFO falls
below “neutral”, showing participants’ concerns of why
Chase Mobile uses such information.
Dropbox is an online file storage and synchronization
service. From its results, we identified an interesting
permission group, APP_INFO, whose description in Android’s official document is: group of permissions that
are related to the other applications installed on the system.
This authoritative description does not provide any cue
of negative impacts, which leads to user confusion as
we can see that APP_INFO has the largest standard
deviation. STORAGE, SYNC_SETTINGS and ACCOUNTS
are all above “probably relevant” possibly due to their
self-descriptive names that are semantically close to
Dropbox’s core functionalities.

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
10

Moreover, we noticed that the participants tend to set
higher relevancy levels for self-descriptive permission
groups, while they tend to be conservative for other
permission groups. We note that this does not affect
R ISK M ON in acquiring a user’s security requirements,
because R ISK M ON captures the precedence of one permission group over another. Thus, the least relevant
permission group always gets the highest risk scores.
5.2.2 Application Risk Ranking
Figure 6 illustrates the ranking of 14 applications by their
average cumulative risk scores as measured by 33 risk
assessment baselines generated for the participants. We
can see that MXPlayer (2.55) and Walmart (12.72) fall
within the trusted applications, while CNN (54.15) and
Pandora (69.22) are ranked with the highest risk scores.
Note that both Pandora and CNN are renowned applications developed by experienced developers. Seemingly, they should use sensitive information appropriately. Hence, we verified them by manually dissecting
their captured Binder transactions. We found that they
kept polling ConnectivityManager for a fine-grained
state of the current network connection, which generated
hundreds of Binder transactions albeit each transaction
was not very risky. This is an unexpected practice with
respect to privacy and performance, because the official Android documents7 suggest developers register
CONNECTIVITY_CHANGE broadcasts to get connectivity
updates instead of polling. On the contrary, Hangouts
incurred almost imperceptible amount of risks, although
it has similar requirements for connectivity. Therefore,
R ISK M ON showed that even popular applications might
use sensitive information in a way that incurs potential
risks for users.
5.3 Case Studies
Note that there is no ground truth of users’ expected
appropriate behaviors. Therefore, we opt for several
case studies to evaluate the effectiveness of our approaches. We handpicked two applications, SogouInput
and PPS.TV, because they both request one or more
sensitive and excessive permissions. We also reused the
target applications that were previously selected for the
user study. To assess these 6 applications, we specified
the relevancy levels for the 10 trusted applications and
generated a risk assessment baseline. We verified their
identified risk composition with manual analysis. Finally, we applied automated permission revocation to
identify and mitigate their unnecessary risks. Table 3
and Table 4 demonstrate the results of automated risk
assessment and mitigation, respectively.
5.3.1 Automated Risk Assessment
SogouInput is an input method based on the pinyin
method of romanization, and PPS.TV is a video streaming application similar to its counterparts such as Hulu
7. http://developer.android.com/training/monitoring-devicestate/connectivity-monitoring.html

and Netflix. Both of them are feature-rich, free and
have accumulated over 5,000,000 installs on Google Play.
We note that PPS.TV and SogouInput request 22 and
29 permissions, respectively. The numbers of requested
permissions make them suspicious over-privileged or
privacy-infringing applications.
The measured cumulative risk scores are 179.0 for
SogouInput and 366.9 for PPS.TV. First, the unusually
large portion of PHONE_CALLS indicates substantial use
of capabilities related to making phone calls and reading
unique identifiers. We verified the corresponding Binder
transactions and revealed that it attempted to read a
user’s subscriber ID and device ID. Second and more notably, SOCIAL_INFO contributed 4.02% of the total risks
incurred by SogouInput. We verified the corresponding
Binder transactions and found that SogouInput accessed
content://com.android.contacts and received a
parcel of 384 bytes. Usually an Android application
queries the contact application and receives only the
entries a user picks, which is several bytes long. On
the contrary, SogouInput attempted to dump the whole
contact repository. Similar to SogouInput, PPS.TV utilized permissions related to PHONE_CALL. In addition
to reading a user’s device ID and subscriber ID, it also
registered a callback to receive events of call states.
We note that this allows PPS.TV to read the number
of incoming calls. To verify which trusted applications
were mostly used in assessing the appropriateness of the
behaviors of SogouInput and PPS.TV, we performed an
exhaustive leave-p-out cross validation on the 10 trusted
applications. The results showed that Google+, MoviesbyFlixter, and Dropbox contributed most in assessing
SogouInput. And Google+, Dictionary.com contributed
most for PPS.TV.
As for the four target applications, three of them
used the APIs related to NETWORK and LOCATION. The
considerable risks of NETWORK incurred by Pandora and
CNN were due to polling ConnectivityManager as we
have discussed in Section 5.2.2. Meanwhile, CNN and
Walmart both continuously tracked a user’s location
through APIs related to LOCATION. MXPlayer could be
deemed as safe due to its low cumulative risks as well as
reasonable risk composition. Moreover, the major source
of risks could imply whether an application abuses a
user’s information. For example, LOCATION contributed
a majority of Walmart’s total risks, which simply does
not make sense for a shopping application.
5.3.2 Automated Risk Mitigation
Based on the measured risks of the 6 applications, we
further applied our automated risk mitigation approach.
In particular, we used Figure 2 to guide our selection
of reference applications out of 10 trusted applications.
Therefore, r = R/2 = 0.326 as shown in Figure 4 and k
was no more than 3. Afterwards, we chose the average
budget estimation function to reduce the incurred risks
of the applications that are below the average level of
their respective reference applications. Table 4 shows the

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
11

Fig. 6. Average Cumulative Risk Scores Measured by the Participants’ Risk Assessment Baselines
revoked permissions and risk reduction of the assessed
applications. In this table, we have denoted the specific
reason for each revoked permission. “(O)” indicates
that the revoked permission was used by one or more
reference applications but exceeded the threshold set
by the budget estimation function. “(N)” means that
the permission was not used by any of the reference
applications. Such permissions were also revoked in
our case studies due to the average function’s zero
tolerance strategy.
The revoked permissions are lined up with the results
as shown in Table 3. In particular, READ_CONTACTS and
VIBRATE were revoked from SogouInput because they
were used but not among the risk budget items. In
contrast, none of permissions related to LOCATION was
revoked, implying that SogouInput used LOCATION in a
reasonable and conservative manner. 4 out of 5 revoked
permissions of PPS.TV were mitigated due to overbudget, demonstrating its notable tendency of abusing
a user’s information. Overall, these applications were
confined to behave like their respective reference trusted
applications.
We enforced the generated decisions through AppOps, and the revoked permissions did not break the
core functionalities. However, we can not guarantee
that permission revocation does not significantly impair
an application’s usability, for two reasons. First, our
framework does not directly enforce decisions. Graceful
enforcement of decisions by access control frameworks
is still an open question that is beyond the scope of
this paper. Second, risky permissions are not always
excessive. Obviously, core functionalities would break if
their abused permissions are revoked.
The results of the case studies leave room for further analysis. How come an input method and a
video streaming application need capabilities related
to PHONE_CALLS, LOCATION and SOCIAL_INFO? Why
does Walmart need to continuously access users’ location? Possibly users could get personalized services
through disclosing private information. However, it
comes with a price. R ISK M ON is a necessary step towards highlighting and mitigating the excessive risks.

TABLE 3
Risk Composition of Applications in Case Studies
Application
SogouInput

PPS.TV

Pandora

CNN
Walmart
MXPlayer

Permission Group
LOCATION
NETWORK
PHONE_CALLS
SOCIAL_INFO
Total:
LOCATION
NETWORK
PHONE_CALLS
Total:
AFFECTS_BATTERY
NETWORK
PHONE_CALLS
Total:
LOCATION
NETWORK
Total:
LOCATION
NETWORK
Total:
NETWORK
Total:

Risk Score
5.6 (3.13%)
104.4 (58.29%)
61.8 (34.56%)
7.2 (4.02%)
179.0 (100%)
26.0 (7.09%)
108.3 (29.52%)
232.6 (63.40%)
366.9 (100%)
0.27 (0.21%)
131.6 (99.49%)
0.4 (0.30%)
132.3 (100%)
26.7 (20.75%)
101.8 (79.25%)
128.5 (100%)
40.8 (72.05%)
15.8 (27.95%)
56.6 (100%)
5.3 (100.00%)
5.3 (100%)

TABLE 4
Revoked Permissions of Applications in Case Studies
Revoked Permissions
Application (O): Over budget
(N): Not in budget
ACCESS_NETWORK_STATE
READ_PHONE_STATE (O)
SogouInput
READ_CONTACTS (N)
VIBRATE (N)
ACCESS_LOCATION (O)
ACCESS_NETWORK_STATE
PPS.TV
ACCESS_WIFI_STATE (O)
CHANGE_WIFI_STATE (N)
READ_PHONE_STATE (O)
Pandora
ACCESS_NETWORK_STATE
ACCESS_LOCATION (N)
CNN
ACCESS_NETWORK_STATE
WAKE_LOCK (N)
ACCESS_LOCATION (O)
Walmart
ACCESS_NETWORK_STATE
MXPlayer

Risk
Reduction
(O)
169.5 (94.7%)

(O)
367.0 (99.8%)
(O)

130.3 (98.5%)

(O)

128.5 (100.0%)

(O)

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

56.6 (100.0%)
0.0 (0.0%)

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
12

TABLE 5
Usability Evaluation Results
Metric

Average

Likeability
Simplicity
Risk perception

0.811
0.674
0.758

Lower bound on 95%
confidence interval
0.797
0.645
0.751

TABLE 6
Microbenchmark Results
Benchmark

Average (s)

Feature extraction
Baseline generation (10 apps)
Risk measurement (per app)

5.4

8.27
289.56
0.55

Standard
Deviation (s)
0.07
235.88
0.17

System Usability

The criteria for usability were split into three areas:
likeability, simplicity and risk perception. Likeability is a
measure of a user’s basic opinion towards automated
risk assessment. This identifies whether users would
like to accept the proposed mechanism. Simplicity is a
measure of how intuitive the concepts and procedures
are, which is useful in evaluating the burden placed on
users. Risk perception is a measure of a user’s perceived
awareness of risks through risk assessment, which evaluates how users interpret the presented risk.
After using R ISK M ON, an exit survey was presented
to collect users’ perceived usability of R ISK M ON. In the
survey, we asked users a set of questions on likeability,
simplicity, and risk perception. Questions were measured
with a five-point Likert scale. A higher score indicates
a positive opinion or agreement and vice versa. Then
scores were adjusted to [0,1] for numerical analysis.
We analyzed a 95% confidence interval for users’
answers. Specifically, we are interested in determining
the average user’s minimum positive opinions. Hence,
we looked at the lower bound of the confidence interval.
Table 5 shows that an average user asserts 79.7% positively on likeability, 64.5% on simplicity and 75.1% on
risk perception. The results show usability of R ISK M ON
with the above-average feedback.
5.5

System Overhead

To understand the performance overhead of R ISK M ON,
we performed several microbenchmarks. The experiments were performed on a Samsung Galaxy Nexus
phone with a 1.2GHz dual-core ARM CPU. The phone
ran Android v4.2.2 and R ISK M ON built on the same
version. Table 6 shows the average results.
Feature extraction: The application intelligence aggregator extracted feature vectors from 33,368,458 Binder
IPC transactions generated by 14 applications in one day.
We measured the CPU-time used by parsing the transactions and generating the feature vectors. The average
time is 8.27 seconds, which is acceptable on a resourceconstrained mobile device.

Baseline generation: We ran baseline generation based
on the input acquired in the online user study. The
processing time varies for different participants, while
the average time is approximately 289.56 seconds due to
the computation complexity of the radial basis function
kernel of SVMLight.
Risk measurement: Applying the risk assessment
baseline is much faster than baseline generation. We
measured the time taken to apply a risk assessment baseline on 14 applications. The average time per application
is 0.55 seconds, which is imperceptible and demonstrates
the feasibility of repeated risk assessment.
Finally, we anecdotally observed that it took 5-10
minutes for the participants to set relevancy levels for
10 applications. This usability overhead is acceptable
compared to the lifetime of a risk assessment baseline.

6

D ISCUSSION

To capture actual risks incurred by applications used
by a user, R ISK M ON fundamentally requires running
them on the user’s device. We note that 48.5% of the
respondents in our user study claimed that they often
test drive applications on their devices. However, R ISK M ON itself does not detect or prevent sensitive data from
leaving users’ devices. We would recommend users use
on-device isolation mechanisms (e.g., Samsung KNOX).
R ISK M ON requires users to specify security requirements through permission groups. However, some permission groups are ambiguous (e.g., APP_INFO). Although we identify permission groups as an appropriate
trade-off between granularity and usability, we admit
that permission groups are still a partial artifact in
representing sensitive resources. As our future work,
we plan to weight the measured risks of each Binder
transaction with protection levels of permissions. These
levels, which pre-classify permissions and Binder transactions, can be considered as a subsidiary source of
user’s security requirements. We also found that several
less sensitive permissions indeed need adjustment to
avoid over-estimation. Moreover, generating a risk assessment baseline is a compute-intensive task that does
not fit resource-constrained mobile devices. Thus, we
plan to offload such a task to trusted third-parties or
users’ public or private clouds in the future.
Regarding our current implementation of R ISK M ON,
it purposely monitors Binder IPC transactions that are
(1) between applications and system services; and (2) between applications and system applications (e.g., Contacts). With that said, R ISK M ON may discard accesses
on assets owned by third-party applications. Meanwhile,
custom permissions defined by third-party applications
are also beyond the scope of R ISK M ON. Furthermore,
R ISK M ON identifies Binder transactions with UIDs and
thus may not assess the risks incurred by a certain
component (e.g., content provider) of an application. For
our future work, we will extend the Android ActivityManagerService and PackageManagerService to address
these limitations.

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
13

7

R ELATED W ORK

Our previous work [1] mainly dealt with risk assessment of mobile applications. The proposed approach
helped reveal high-risk applications. However, it did
not consider practical methods to mitigate the identified
risks. Since the core functionalities of applications might
not be major root causes of risks (e.g., ad-supported
games), risk mitigation through removing applications
may disrupt user experiences. Instead, it is necessary to
seek a novel approach for mitigating risks systematically.
In this paper, we extend our previous work to address
such a gap by connecting two important steps in R ISK M ON: risk assessment and risk mitigation. As we have
discussed in Section 4, we introduce new mechanisms to
automatically select and revoke risky permissions from
installed mobile applications, along with newly designed
case studies for both steps.
In addition, there exist several related work to the
proposed approach in this paper:
Analysis of meta information. Meta information
available on application markets provides general descriptions of applications. Recent work has proposed
techniques to distill risk signals from them. Sarma et
al. [9] propose to analyze permissions alongside with
application categories in two large application datasets.
Peng et al. [10] use probabilistic generative models to
generate risk scoring schemes that assign comparative
risk scores on applications based on their requested
permissions. In addition to analysis on permissions, Chia
et al. [12] and Chen et al. [13] perform large-scale studies on application popularity, user ratings and external
community ratings. However, meta information does not
accurately describe the actual behaviors of applications.
R ISK M ON uses meta information to provide operational
contexts to complement the analysis on the runtime
behaviors for risk assessment.
Static and dynamic analysis. Analysis on execution semantics of applications, such as static analysis
of code and dynamic analysis of runtime behaviors,
can reveal how applications use sensitive information.
CHABADA [38] compares an application’s static API
usage against its description on application markets to
detect API “outliers”. TouchDevelop [39] statically identifies leaked or tampered information flows to suggest
privacy settings for end users. However, malware with
dynamic external code loading [40] could easily evade
static analysis, rendering all existing static assessment
mechanisms ineffective. Regarding dynamic analysis,
TaintDroid [4] uses dynamic information flow tracking
to detect at most 32 types of flows that are leaked to the
network. DroidRanger [15] and RiskRanker [16] combine
both static and dynamic analysis to detect anomalies.
Compared to R ISK M ON, these work do not provide a
baseline that captures diverse operational contexts as
well as a user’s expectation. Moreover, R ISK M ON monitors every permission-protected API and thus provides
better coverage.

Mandatory access control frameworks. R ISK M ON
includes a lightweight reference monitor for Binder IPC.
While it monitors IPC transactions for risk assessment,
several frameworks mediate IPC channels as part of
their approaches to support enhanced mandatory access
control (MAC). SEAndroid [33] brings SELinux kernellevel MAC to Android. It adds new hooks in the Binder
device driver to address Binder IPC. FlaskDroid [34]
provides flexible MAC on multiple layers, which is
tailored the peculiarity of the Android system. Along
these lines, R ISK M ON captures Binder transactions with
a fine-grained scheme to facilitate risk assessment on
applications’ runtime behaviors.

8

C ONCLUSION

In this paper, we have presented R ISK M ON that continuously and automatically measures risks incurred by
a user’s installed applications. R ISK M ON has leveraged
machine-learned ranking to generate a risk assessment
baseline from a user’s coarse expectations and runtime behaviors of her trusted applications. Furthermore,
we have proposed an automated decision process that
utilizes R ISK M ON to support granular permission revocation. Also, we have described a proof-of-concept
implementation of R ISK M ON, along with the extensive
evaluation results of our approach.

R EFERENCES
[1]

Y. Jing, G.-J. Ahn, Z. Zhao, and H. Hu, “Riskmon: Continuous and
automated risk assessment of mobile applications,” in Proceedings
of the 4th ACM Conference on Data and Application Security and
Privacy. ACM, 2014.
[2] M. Panzarino, “Google announces 900 million android activations, 48 billion apps downloaded,” 2013.
[3] A. Robertson, “Apple passes 50 billion app store downloads,”
2013.
[4] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and
A. Sheth, “Taintdroid: An information-flow tracking system for
realtime privacy monitoring on smartphones.” in OSDI, vol. 10,
2010, pp. 255–270.
[5] P. Hornyack, S. Han, J. Jung, S. Schechter, and D. Wetherall,
“These aren’t the droids you’re looking for: retrofitting android
to protect data from imperious applications,” in Proceedings of
the 18th ACM conference on Computer and communications security.
ACM, 2011, pp. 639–652.
[6] L. K. Yan and H. Yin, “Droidscope: seamlessly reconstructing
the os and dalvik semantic views for dynamic android malware
analysis,” in Proceedings of the 21st USENIX Security Symposium,
2012.
[7] V. Rastogi, Y. Chen, and W. Enck, “Appsplayground: automatic
security analysis of smartphone applications,” in Proceedings of the
third ACM conference on Data and application security and privacy.
ACM, 2013, pp. 209–220.
[8] W. Enck, M. Ongtang, and P. McDaniel, “On lightweight mobile
phone application certification,” in Proceedings of the 16th ACM
conference on Computer and communications security. ACM, 2009,
pp. 235–245.
[9] B. P. Sarma, N. Li, C. Gates, R. Potharaju, C. Nita-Rotaru, and
I. Molloy, “Android permissions: a perspective combining risks
and benefits,” in Proceedings of the 17th ACM symposium on Access
Control Models and Technologies. ACM, 2012, pp. 13–22.
[10] H. Peng, C. Gates, B. Sarma, N. Li, Y. Qi, R. Potharaju, C. NitaRotaru, and I. Molloy, “Using probabilistic generative models for
ranking risks of android apps,” in Proceedings of the 2012 ACM
conference on Computer and communications security. ACM, 2012,
pp. 241–252.

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI
10.1109/TDSC.2014.2366457, IEEE Transactions on Dependable and Secure Computing
14

[11] Y. Wang, J. Zheng, C. Sun, and S. Mukkamala, “Quantitative security risk assessment of android permissions and applications,”
in Data and Applications Security and Privacy XXVII. Springer,
2013, pp. 226–241.
[12] P. H. Chia, Y. Yamamoto, and N. Asokan, “Is this app safe?: a
large scale study on application permissions and risk signals,” in
Proceedings of the 21st international conference on World Wide Web.
ACM, 2012, pp. 311–320.
[13] Y. Chen, H. Xu, Y. Zhou, and S. Zhu, “Is this app safe for
children?: a comparison study of maturity ratings on android and
ios applications,” in Proceedings of the 22nd international conference
on World Wide Web. International World Wide Web Conferences
Steering Committee, 2013, pp. 201–212.
[14] R. Pandita, X. Xiao, W. Yang, W. Enck, and T. Xie, “Whyper:
Towards automating risk assessment of mobile applications,” in
Proceedings of the 22nd USENIX conference on Security symposium.
USENIX Association, 2013.
[15] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang, “Hey, you, get off of
my market: Detecting malicious apps in official and alternative
android markets,” in Proceedings of the 19th Annual Network and
Distributed System Security Symposium, 2012.
[16] M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang, “Riskranker:
scalable and accurate zero-day android malware detection,” in
Proceedings of the 10th international conference on Mobile systems,
applications, and services. ACM, 2012, pp. 281–294.
[17] G. Stoneburner, A. Goguen, and A. Feringa, “Risk management
guide for information technology systems,” Nist special publication,
vol. 800, no. 30, pp. 800–30, 2002.
[18] C. Alberts, A. Dorofee, J. Stevens, and C. Woody, “Introduction
to the octave approach,” Pittsburgh, PA, CMU, 2003.
[19] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie, “Pscout: analyzing
the android permission specification,” in Proceedings of the 2012
ACM conference on Computer and communications security. ACM,
2012, pp. 217–228.
[20] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner, “Android
permissions demystified,” in Proceedings of the 18th ACM conference
on Computer and communications security. ACM, 2011, pp. 627–638.
[21] D. M. Wilkinson, “Strong regularities in online peer production,”
in Proceedings of the 9th ACM conference on Electronic commerce.
ACM, 2008, pp. 302–309.
[22] D. Barrera, H. G. Kayacik, P. C. van Oorschot, and A. Somayaji, “A
methodology for empirical analysis of permission-based security
models and its application to android,” in Proceedings of the 17th
ACM conference on Computer and communications security. ACM,
2010, pp. 73–84.
[23] J. A. Krosnick and D. F. Alwin, “An evaluation of a cognitive
theory of response-order effects in survey measurement,” Public
Opinion Quarterly, vol. 51, no. 2, pp. 201–219, 1987.
[24] M. Rabin, “Risk aversion and expected-utility theory: A calibration theorem,” Econometrica, vol. 68, no. 5, pp. 1281–1292, 2000.
[25] A. P. Felt, E. Ha, S. Egelman, A. Haney, E. Chin, and D. Wagner,
“Android permissions: User attention, comprehension, and behavior,” in Proceedings of the Eighth Symposium on Usable Privacy
and Security. ACM, 2012, p. 3.
[26] E. Chin, A. P. Felt, V. Sekar, and D. Wagner, “Measuring user
confidence in smartphone security and privacy,” in Proceedings of
the Eighth Symposium on Usable Privacy and Security. ACM, 2012.
[27] K. Duh, “Ranking vs. regression in machine translation evaluation,” in Proceedings of the Third Workshop on Statistical Machine
Translation. Association for Computational Linguistics, 2008, pp.
191–194.
[28] T. Joachims, “Optimizing search engines using clickthrough data,”
in Proceedings of the eighth ACM SIGKDD international conference on
Knowledge discovery and data mining. ACM, 2002, pp. 133–142.
[29] P. Eckersley, “Google removes vital privacy feature from android,
claiming its release was accidental,” 2013.
[30] M. Nauman, S. Khan, and X. Zhang, “Apex: extending android
permission model and enforcement with user-defined runtime
constraints,” in Proceedings of the 5th ACM Symposium on Information, Computer and Communications Security. ACM, 2010, pp.
328–332.
[31] Y. Zhou, X. Zhang, X. Jiang, and V. W. Freeh, “Taming
information-stealing smartphone applications (on android),” in
Trust and Trustworthy Computing. Springer, 2011, pp. 93–107.
[32] S. Bugiel, L. Davi, A. Dmitrienko, T. Fischer, A. Sadeghi, and
B. Shastry, “Towards taming privilege-escalation attacks on an-

[33]

[34]

[35]
[36]
[37]
[38]
[39]

[40]

droid,” in Proc. of the 19th Network and Distributed System Security
Symposium (NDSS 2012), San Diego, CA, 2012.
S. Smalley and R. Craig, “Security enhanced (se) android: Bringing flexible mac to android,” in Proc. of the 20th Network and
Distributed System Security Symposium (NDSS 2013), San Diego, CA,
2013.
S. Bugiel, S. Heuser, and A.-R. Sadeghi, “Flexible and fine-grained
mandatory access control on android for diverse security and
privacy policies,” in 22nd USENIX Security Symposium (USENIX
Security 2013). USENIX, 2013.
W. Enck, D. Octeau, P. McDaniel, and S. Chaudhuri, “A study of
android application security,” in Proceedings of the 20th USENIX
conference on Security. USENIX Association, 2011, pp. 21–21.
A. P. Felt, S. Egelman, M. Finifter, D. Akhawe, D. Wagner et al.,
“How to ask for permission,” in Proc. USENIX Workshop on Hot
Topics in Security, 2012.
S. Shekhar, M. Dietz, and D. S. Wallach, “Adsplit: Separating
smartphone advertising from applications.” in USENIX Security
Symposium, 2012, pp. 553–567.
A. Gorla, I. Tavecchia, F. Gross, and A. Zeller, “Checking app
behavior against app descriptions.” in ICSE, 2014, pp. 1025–1035.
X. Xiao, N. Tillmann, M. Fahndrich, J. De Halleux, and M. Moskal,
“User-aware privacy control via extended static-information-flow
analysis,” in Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering. ACM, 2012, pp. 80–89.
S. Poeplau, Y. Fratantonio, A. Bianchi, C. Kruegel, and G. Vigna,
“Execute this! analyzing unsafe and malicious dynamic code
loading in android applications,” in Proceedings of the 21st NDSS,
2014.
Yiming Jing received the BS degree from
Shanghai Jiao Tong University, China, in 2010.
He is currently working toward the Ph.D. degree in the School of Computing, Informatics,
and Decision Systems Engineering, Ira A. Fulton
School of Engineering, Arizona State University.
His current research interests include access
control models and mechanisms, security and
privacy in mobile computing, and secure software engineering.

Gail-Joon Ahn is a Professor in the School of
Computing, Informatics, and Decision Systems
Engineering, Ira A. Fulton Schools of Engineering and the Director of Security Engineering
for Future Computing Laboratory, Arizona State
University. His research has been supported by
the U.S. National Science Foundation, National
Security Agency, U.S. Department of Defense,
U.S. Department of Energy, Bank of America,
Hewlett Packard, Microsoft, and Robert Wood
Johnson Foundation. Dr. Ahn is a recipient of the
U.S. Department of Energy CAREER Award and the Educator of the
Year Award from the Federal Information Systems Security Educators
Association. He received the Ph.D. degree in information technology
from George Mason University, Fairfax, VA, in 2000.
Ziming Zhao received the BE and MS degrees from the Beijing University of Posts and
Telecommunications, China, in 2006 and 2009,
respectively. He is currently working toward the
Ph.D. degree in the School of Computing, Informatics, and Decision Systems Engineering, Ira
A. Fulton School of Engineering, Arizona State
University. His research interest include malicious code analysis, web and browser security,
and wireless system security.
Hongxin Hu is an Assistant Professor in the
Division of Computer Science, School of Computing, Clemson University. His current research
interests include access control models and
mechanisms, security and privacy in social networks, security in cloud and mobile computing,
network and system security, and secure software engineering. He received the Ph.D. degree
in computer science from Arizona State University, Tempe, AZ, in 2012.

1545-5971 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See
http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Toward a Moving Target Defense for Web Applications
(Invited Paper)
Marthony Taguinod, Adam Doupé, Ziming Zhao, and Gail-Joon Ahn
Arizona State University
{mtaguino, doupe, zmzhao, gahn}@asu.edu
Abstract—Web applications are a critical component of the
security ecosystem as they are often the “front door” for many
companies; as such, vulnerabilities in web applications allow
hackers access to companies’ private data, which contains
consumers’ private financial information. Web applications
are, by their nature, available to everyone, at anytime, from
anywhere, and this includes attackers. Therefore, attackers
have the opportunity to perform reconnaissance at their leisure,
acquiring information on the layout and technologies of the web
application, before launching an attack. However, the defender
must be prepared for all possible attacks and does not have
the luxury of performing reconnaissance on the attacker.
The idea behind Moving Target Defense (MTD) is to
reduce the information asymmetry between the attacker and
defender, ultimately rendering the reconnaissance information
misleading or useless. In this paper we take the first steps of
applying MTD concepts to web applications in order to create
effective defensive layers. We first analyze the web application
stack to understand where and how MTD can be applied.
The key issue here is that an MTD application must prevent
or disrupt a vulnerability or exploit, while still providing
identical functionality. Then, we discuss our implementation
of two MTD approaches, which can mitigate several classes of
web application vulnerabilities or exploits. We hope that our
discussion will help guide future research in applying the MTD
concepts to the web application stack.

I. I NTRODUCTION
Web applications remain the most popular way for businesses to provide services over the Internet. With more
web applications available, more sensitive business and
user data is managed and processed by web applications.
Consequently, vulnerabilities in web applications put both
businesses and end-users’ security and privacy at risk.
This is not an abstract risk, as the JPMorgan Chase breach
in 2014 affected 76 million US households [1]. Bloomberg
reported that the hackers “exploited an overlooked flaw in
one of the bank’s websites” [2]. Thus, web applications are
the “front door” for many companies, and therefore their
security is of paramount importance.
Many techniques and tools using static analysis (whitebox) or dynamic analysis (black-box) approaches have been
proposed and developed to discover the vulnerabilities of
web applications [3]–[7], so that the vulnerabilities can
be removed before attackers discover and exploit them.
However, the efforts of discovering and fixing vulnerabilities
are not enough to protect web applications for many reasons:
(1) the increasing complexity of modern web applications

brings inevitable risks that cannot be fully mitigated in the
process of web application development and deployment [8],
and (2) attackers can take their time, to understand the
web application’s functionality and technology stack, before
launching an attack.
We believe that a defense-in-depth approach is best to
securing web applications. Therefore, to complement the
aforementioned vulnerability analysis techniques, we propose to use the ideas of Moving Target Defense (MTD) to
create a novel and proactive approach that adds an additional
layer of defense to web applications. At a high level, a
moving target defense dynamically configures and shifts
systems over time to increase the uncertainty and complexity
for attackers to perform probing and attacking [9], [10].
While a system’s availability is preserved to legitimate users,
the system components are changed in unpredictable ways
to the attackers. Therefore, the attacker’s window of attack
opportunities decrease and the costs of attack increase. Even
if an attacker succeeds in finding a vulnerability at one point,
the vulnerability could be unavailable as the result of shifting
the underlying system, which makes the environment more
resilient against attacks.
To best apply the MTD ideas to protect web applications, there are two high-level decisions: (1) choose what
component to move in a web application, and (2) decide
the optimal time and how often to move components. To
assist in answering these questions, we dissect the modern
web application architecture, both client and server, and their
running environments to explore the possibilities of applying
MTD at different layers. We hope our analysis provides
insights into the trade-offs among the different places to
apply MTD to web applications.
We also discuss our first steps in applying MTD techniques to protect web applications. The first technique
changes the server-side language used in a web application by automatically translating server-side web application
code to another language in order to prevent Code Injection
exploits. The second technique shifts the database used in a
web application by transforming the backend SQL database
into different implementations that speak different dialects
in order to prevent SQL Injection exploits.
The main contributions of this paper are the following:
• We discuss the possibilities of applying moving target
defense to different layers of web applications.

•

We propose two novel approaches to changing the
implementation language of a web application and the
database implementation while keeping the functionality.
II. BACKGROUND

In order to properly understand how to apply the ideas
of moving target defense to web applications, we first
describe web application, then the ideas behind moving
target defense.
A. Web Applications
As shown in Figure 1, a web application follows a
distributed application structure, with components running
on the server and the client.
The client first uses the communication channels (typically the protocol HTTP and its derivative protocols, such
as HTTPS, SPDY, and HTTP/2) to issue a request to the
server-side component.
The server side typically includes the following layers
from top to bottom1 :
• The server-side logic layer implements the application business logic using high-level programming languages, such as Java, PHP, or Python.
• The web server layer receives the HTTP request from
then client, parses the HTTP request, and passes the request to the appropriate server-side program. Examples
include Apache web server, Windows IIS, or Nginx.
• The data storage layer that stores the web application state and user data. Popular data storage systems
are traditional SQL databases, which include MySQL,
PostgreSQL, or MSSQL.
• The operating system layer that provides the running
environment for the web server layer and database
storage layer.
• The infrastructure layer that runs the operating systems.
An infrastructure could be a physical machine or a
virtualization platform which manages multiple virtual
machines.
The client receives the HTTP response from the serverside code, and the job of the client is to convert the HTML
contained in the HTTP response into a graphical interface
for the user. The client includes:
• The client-side logic layer that is usually called the
presentation layer. This is written in a combination of
HTML, CSS, and JavaScript, with JavaScript providing
a way for the server-side code to execute application
logic on the client.
• The browser retrieves the presentation layer code from
the server, interprets it, and presents it as a graphical
interface to the user.
1 Of course, modern web application stacks can become increasingly
complex, with caches, external requests, or other services, however in this
paper we restrict our discussion to this abstracted model.

The storage layer that the presentation layer code
uses to store data. Available storage methods include
cookies, localStorage, IndexedDB, and File
APIs.
• The operating system layer, which the browser runs on.
If a layer in Figure 1 is compromised, its upper layers
are not trustworthy. For instance, if the server’s operating
system is compromised, then the data storage, web server,
and server-side logic are all compromised. Because the
presentation layer is created by the server and sent across
the communication channel, a compromise of the server or
the communication channel compromises the presentation
layer. Adversaries can attack a layer in Figure 1 through its
interfaces exposed to the upper layers.
For example, in a heap spraying attack on the client
browser layer [11], an attacker allocates malicious objects
using JavaScript in the presentation layer to coerce the
browser to spray objects in the heap, increasing the success
rate of an exploit that jumps to a location within the heap.
In this case, the attacker uses the presentation layer to
exploit a vulnerability in the browser layer that leads to
arbitrary code execution in the browser’s address space. The
injected arbitrary code can in turn exploit a vulnerability
in the client operating system to escalate its privilege and
further infect the client machine. Furthermore, the malicious
JavaScript code might be delivered by an attacker exploiting
a vulnerability in the server-side logic layer, using a reflected
or stored cross-site scripting (XSS) vulnerability.
•

B. Moving Target Defense
The basic idea of moving target defense (MTD) is to
continually shift and change system configurations over time
to increase complexity and cost for attackers. MTD does not
remove vulnerabilities directly but limits the exposure of
vulnerabilities, so opportunities for attack can be decreased.
In this way, MTD acts as part of a defense-in-depth strategy.
The effectiveness of an MTD approach depends on how
many components are moved (what-to-move) and the frequency of movement (when-to-move).
The widely adopted address space layout randomization
(ASLR) [12] in modern operating systems is an instance
of MTD. Existing ASLR mechanisms randomly arrange the
address space positions of key data areas (what-to-move)
of a process when it is launched (when-to-move), including
the base of the executable and the positions of the stack,
heap, and libraries. In this way, even if attackers are able
to exploit a memory corruption vulnerability in a binary
(such as the classic buffer overflow), it is difficult for them
to transfer control flow to their injected shellcode, as they
cannot predict the memory layout of the process.
MTD mechanisms for programs can be categorized into
two classes depending on if a program is running (dynamic)
or not (static) at the time when moving happens. For
example, existing ASLR approaches are static, because the

Client side

Server side

Presentation Layer

Logic Layer

Web Server Layer

Browser

Storage Layer
Local Storage

Communication
Channel

Cookies, IndexedDB,
localStorage, File API

Operating System

Application
Layer

Operating System

Infrastructure

HTTP/1.1, HTTP/2

Figure 1.

A Modern Web Application Architecture and Its Running Environments.

positions of code and data areas are only moved at the launch
of a program but not when a program is running. A dynamic
MTD offers more choices for when-to-move, but may be
more difficult to implement.
III. M OVING TARGET D EFENSE FOR W EB
A PPLICATIONS
The core idea of moving target defense (MTD) can be
applied to every layer of web applications and their running
environments. However, the key issue is that the “moving,”
when applied, must either prevent a vulnerability or exploit
while at the same time not alter the application functionality. In this section, we discuss what components that are
available for moving at the web application layers. We
specifically focus on the layers specific to web applications:
the logic layer, storage layer, and presentation layer. For
other layers that are common to other applications, which
include the operating system layer and the infrastructure
layer, we refer the interested reader to research in these
areas [12]–[21].
A. Logic Layer
There are at least two ways to apply MTD at the logic
layer by changing a web application’s implementation. The
first approach uses the idea of software diversity [14], which
is widely used in lower-level languages, to change and
modify the code at the statement, function, or object levels.
This type of diversity is used to combat memory corruption
vulnerabilities, specifically return-oriented programming exploits, which take advantage of previously known codelayouts. This automated diversity MTD technique can be

done statically or dynamically. However, many web applications are written in higher-level languages, such as
Java, Python, and Ruby, which are immune from memory
corruption vulnerabilities. In fact, most web application
vulnerabilities are inherent in the code itself, such as CrossSite Scripting (XSS), where the server-side web application
code creates HTML from unsanitized, untrusted attacker
input. Software diversity does not handle this case, as the
vulnerability is part of the web application’s logic.

Another MTD approach is to switch a web application’s
implementation from one language to another, which could
eliminate some language- or framework-specific vulnerabilities, as some vulnerability classes are specific to certain programming languages. For example, an application that is developed with Ruby on Rails 3.0.5 may introduce executionafter-redirect vulnerabilities, while its counterpart developed
with Python and Django 1.2.5 is impervious to this class of
vulnerabilities due to the different implementations of the
underlying framework [22]. Changing the web application’s
implementation language could be either static or dynamic.
In a static switch, the web server simply launches another
language implementation of the application. To make the
process automated, web application developers only need
to develop the application once using the language they
prefer, and a translator program translates their code into
functionally equivalent code in the other language. The
translation is difficult when the input language has some
features that the output language can not offer. In a dynamic
switch, the states of the running web application would
need to be maintained or transformed for the program in

another language to understand. In Section IV we discuss
our implementation of this idea.
B. Storage Layer
The biggest challenge the storage layer faces are SQL
injection attacks in which data from the logic layer is
interpreted as SQL statements by the database management
systems. In order to perform successful SQL injection attacks, attackers need to carefully craft their input by using
some reversed tokens in the targeted SQL syntax in order to
modify the logic layer developer’s intended SQL statement.
While SQL itself is standard, different SQL database
implementations use slightly different SQL syntaxes (also
called dialects). Taking advantage of the fact that different
databases use slightly different SQL syntaxes, switching the
database used in a web application may defeat some SQL
injection exploits that are targeted at a specific SQL dialect.
For example, both single ('') and double ("") quotes
are used for quoting values in MySQL—while PostgreSQL
uses only single quotes for values, instead reserving double
quotes for identifying field names, table names, etc.
Static MTD for the database can be realized by exporting the data from one database implementation and
then importing it into a different database implementation.
Dynamic MTD for storage layer can also be achieved if
multiple, yet different, database instances are running and
being continually synchronized. In Section V we discuss
our implementation of this idea.
C. Presentation Layer
The presentation layer contains technologies that are
most directly accessible to the user. For instance, clientside JavaScript code running some of the web application’s
logic, the HTML DOM containing form information, and
CSS that enables modification of the web layout. The most
direct threat of the presentation layer are Cross-Site Scripting
(XSS) attacks, where malicious scripts are injected into the
web application in order to steal information from users.
There are techniques related to MTD that have been
proposed to prevent against such attacks. One such technique
is to introduce a degree of randomness to the underlying
HTML form fields by adding tags to each field that hides
their real values [18]. Another approach, targeting a different
technology, is to introduce randomness to the JavaScript
code by mutating tokens in such a way that the attacker
cannot guess the correct token to inject in addition to running
multiple versions of the website that each utilizes varying
JavaScript versions [23].
D. Browsers
Modern web browsers have modularized architectures that
typically include rendering engines, JavaScript interpreters,
and XML parsers [24]. By moving and changing these
components, vulnerabilities in particular components can be

mitigated. In this way, the browser itself and the underlying
operating system can be protected. For example, the Cheetah
browser [25] and the 360 browser [26] can change their
rendering engines between WebKit and Trident.
Besides protecting browsers from exploits, changing
browser configurations can also protect the privacy of web
users. Every browser instance has its unique configurations, therefore web applications can uniquely fingerprint a
browser in order to track users [27]. Diversifying a browser’s
font, plugins, and other configurations can prevent it from
being fingerprinted, hence protecting the privacy of web
users [28]–[30].
IV. S OURCE C ODE L ANGUAGE D IVERSIFICATION
To apply MTD ideas in the logic layer of the serverside, we propose to change the underlying language implementation of the web application; taking care to retain the
main functionalities of the original application. In doing so,
we prevent certain categories of vulnerabilities from being
effectively exploited—remote code injection exploits would
cease to work as code an attacker manages to insert will
not match the web application’s language. In addition, any
unpatched or zero-day vulnerabilities present in the original
language would not be available for exploit during the time
frame of the randomization, as the language is completely
different from what the attacker original perceives it to be.
In this section, we describe our implementation of a
static MTD mechanism for the logic layer. As a first step,
we choose to convert between PHP, a web development
language used by approximately 82% of all web applications [31] and Python, which is used by popular companies
such as Google, YouTube, Pinterest, and Bing [32], [33]. Our
approach is to develop a translator to automatically convert a
Python web application to PHP. We first translate the source
code as-is, resulting in syntactically valid, but semantically
invalid output in the target language.
We approached the problem of translating from Python
to PHP by first exploring the available open source tools.
However, no such tool exists, and we believe that this is
due to the varying web application frameworks available for
Python. While PHP is a programming language that was
built for creating server-side web application logic, Python is
a general-purpose language that can be used to write serverside web application logic. Therefore, there are many different frameworks for building server-side web applications
in Python. For this reason, we focus on Python applications
that utilize cgi-lib, however the our translation concept
is general and can be implemented for other frameworks in
the future.
Our translator is essentially a compiler, and to speed
development we leverage existing functionality in Python
to initiate the first step in translating to PHP—specifically,
the use of Python’s ast module to build an Abstract Syntax
Tree (AST) of a Python program. Then, we use the Python

def

Print ( self , t ):
self . f i l l (” print ”)
do comma = F a l s e
if t . dest :
s e l f . w r i t e ( ”>>” )
self . dispatch ( t . dest )
do comma = T r u e
for e in t . values :
i f do comma : s e l f . w r i t e ( ” , ” )
e l s e : do comma= T r u e
self . dispatch ( e)
i f not t . n l :
self . write ( ” ,” )

Listing 1.

def

public function exit ( $status )
{
exit ( $status )
}
}

Listing 3.

sys Object in PHP

Original Print in unparse to generate Python code.

Print ( self , t ):
s e l f . f i l l ( ” echo ” )
do comma = F a l s e
if t . dest :
s e l f . w r i t e ( ”>>” )
self . dispatch ( t . dest )
do comma = T r u e
for e in t . values :
i f do comma : s e l f . w r i t e ( ” , ” )
e l s e : do comma= T r u e
self . dispatch ( e)
i f not t . n l :
self . write ( ” ,” )
self . write ( ” ; ” )

Listing 2.

c l a s s sys
{
<... c o n s t r u c t o r ... >
<... other f u n c t i o n s ... >

Modified Print in unparse to generate PHP code.

unparse module, which is a module that converts an
AST to Python code. We develop a new library based on
unparse that generates PHP code instead of Python code.
Specifically, we modify the unparse module code by
replacing the print-to-output function for a given
Python statement with the corresponding PHP-specific statement. For instance, when translating a simple print statement from Python to the PHP equivalent of echo, we
modify the _Print function in the unparse module as
shown in Listing 1.
We replace the print Python keyword with the echo
PHP keyword and ensure that the instruction is terminated
with a semicolon as shown in Listing 2.
Once this is done, we have a program that is syntactically
valid PHP, however it does not have the same semantics
as the original Python program. Therefore, the next step is
to make the translated program semantically equivalent to
the original program. This step is necessary because there
may not be a one-to-one translation for every feature in a
language to another. For example, a Python instruction to
terminate and exit the program is done using:
sys . e x i t (0)

After the translation is done and a PHP valid output is
generated:
s y s−>e x i t ( 0 )

However, PHP sees this as a new sys object with a
call to a function exit(0), which does not exist in PHP.

The instruction does however have an equivalent function
call—exit(status) in PHP. Therefore, we implement
Python built-in functions as shims in order to match the
new function calls. To this end, we create a PHP library
that contains an object called sys with a function call to
exit(status) as shown in Listing 3. This PHP library
shim can be included in the translated application in order
for the function call to remain semantically valid.
Using this approach, we recursively run the tool on the
Python functions that the original program calls, and convert
them as well. If, for instance, the original program is written
in C, then we create a function shim for it.
However, in order to achieve the MTD goal, we must
also decide on how frequently to move or randomize the
component in order to be effective while considering the
cost to legitimate users. Furthermore, there may be risk in
the translated application missing critical function calls that
we have not yet created shims. Finally, we anticipate this
approach to be resource and time intensive as it is essentially
creating two implementations of one web application.
V. DATABASE D IALECT D IVERSIFICATION
To enable movement in the server-side storage layer, we
implemented an approach to change the underlying database
implementation, while preserving data and retaining functionality. In doing so, we again protect against certain
categories of vulnerabilities and exploits—SQL injection
exploits would be rendered ineffective due to syntactical
differences between database implementations.
When performing the database translation, no alterations
must be made to the data content—that is, once the translation is completed, the users must see the same information regardless of the underlying database implementation.
Access to the database must be guaranteed and kept transparent to the user during and after the translation process.
Database translations may be costly as well, especially
regarding larger, more established databases—optimizations
in the original implementation may become invalid once
converted. Similar to our source to source approach, by
continuously changing database implementations, we expect
any database-specific exploits as well as unpatched or zeroday vulnerabilities will be ineffective.

As a first step, we choose to convert between MySQL and
PostgreSQL, which are ranked 2nd and 5th in db-engines.com
popularity ranking, respectively [34]. MySQL is used by
well known companies, such as Facebook, Google, Amazon
and Dropbox [35] and PostgreSQL is used by U.S. Dept of
labor, U.S. State Department, and Sun Microsystems [36].
Some differences between the MySQL and PostgreSQL
syntaxes include:
• The # or -- (A space after the -- is required) is
used to begin a comment in MySQL, while PostgreSQL
instead uses -- (the space is not required).
• Single ('') quotes or double ("") quotes are used in
quoting values in MySQL, while PostgreSQL uses only
single quotes for values, reserving double quotes in
identifying field names, table names, etc.
• MySQL is case-insensitive when doing string comparision while PostgreSQL is case-sensitive, i.e.
john != JOHN != John.
All of these differences affect the SQL injection exploits
written to take advantage of an SQL injection vulnerability.
If an attacker assumes that the web application is using a
particular database backend, specifically if the attacker is
searching the entire web for vulnerabilities, the exploit will
fail.
Similar to our source-to-source approach, we developed
a tool that can automate the conversion or migration between databases. In order to convert from PostgreSQL to
MySQL, we modifed an existing open-source tool created
by Lightbox that converts PostgreSQL to MySQL—although
we can simply create a database dump from PostgreSQL,
directly importing to MySQL will not work as there are
differences between syntax and data types, which must
be properly translated. In addition, certain flags need to
be enabled when creating a database dump to allow for
initial compatibility (PostgreSQL db dumps need to have
--inserts enabled to properly include the data stored;
MySQL needs to have --compatible=postgresql
flag to properly include PostgreSQL keywords). To remedy
this situation, our tool processes the original database dump
by parsing the file and replacing any PostgreSQL keywords
and data-types into corresponding MySQL keywords and
data types. Some considerations have to made regarding
conversions between data types, for instance PostgreSQL’s
BYTEA can be converted to any of the MySQL data types
shown in Table I.
The data type chosen needs to be generic enough that it
covers the possible data value that is in the original database,
while attempting to be as performant as possible. When
testing the original implementation of the converter, we observed that the output did not generate a database dump that
is supported by the latest version of MySQL. In addition,
it did not correctly convert the raw database dump from
PostgreSQL, as the final output still contained PostgreSQL
keywords and data-types. To handle conversion in the reverse

MySQL
BINARY(n)
VARBINARY(n)
TINYBLOB
BLOB
MEDIUMBLOB
LONGBLOB

PostgreSQL
BYTEA
BYTEA
BYTEA
BYTEA
BYTEA
BYTEA

Table I
C OMPARISON OF M Y SQL AND P OSTGRE SQL DATA T YPES .

direction, from MySQL to PostgreSQL, we re-purposed the
code by reversing the process—that is, we parse through
the dump file looking for MySQL keywords and data-types
converting them to the corresponding PostgreSQL keywords
and data-types.
VI. R ELATED W ORK
The idea and philosophy of moving target defense, which
is to increase uncertainty and complexity for attackers, has
been proposed and studied for decades [37]–[40]. Okhravi et
al. surveyed techniques that applied the philosophy of moving target defense in different cyber research domains [41].
According to them, existing techniques can be categorized
into five classes based on what-to-move: (1) changing runtime environment [12], [13], (2) changing application’s code
dynamically or diversifying software [14], [15], (3) changing
data representations [38], [42], (4) changing platforms [16],
[17], and (5) changing network configurations [43]–[45].
However, applying the moving target defense concept
to web applications is still new. Huang et al. proposed
to create and rotate among a set of virtual servers, each
of which is configured with a unique software mix, to
move attack surfaces for web surfaces [46]. Their work
also explored the various opportunities of diversification
in the web application software stack, providing a higherlevel overview of the attack surface. Our work builds on
this by further analyzing the components in each layer and
defining what randomization in each layer entails, in addition
to attempting an automated approach to diversification in
the logic and storage layer. Boyd et al. proposed to create
instances of unpredictable database query languages and
to translate them to standard SQL using an intermediary
proxy to prevent SQL injection attacks [47]. Although their
approach also aims to prevent SQL injections, we chose a
different approach in order to prevent a broader range of
vulnerabilities—specifically unpatched vulnerabilities, zero
day exploits, and mass-attacks targeting specific database
implementations. Portner et al. proposed to defend crosssite scripting by mutating the symbols in JavaScript so
that maliciously injected code can be identified [23]. Their
work aims to prevent a different class of vulnerabilities,
specifically located at the presentation layer on the client
side. Our proposed approaches are aimed at applying MTD
ideas on the server side of the web application architecture.

However, we envision techniques such as these, that are in
each layer, to cooperate together to provide a defense-indepth approach to defending web applications.
VII. F UTURE W ORK
As part of our future work, we plan to address the
remaining semantic issues after translating from a Python
application to a syntactically correct PHP application—one
such issue is the translation of Python data structures to their
equivalent in PHP; for instance, Python lists do not have a
direct equivalent in PHP. Another component that we plan
to explore is the possibility of automating the conversion
to other web development languages. Similarly, we plan
to explore the possibility of conversion to other database
implementations. In addition, we will further investigate the
other web application layers that can be moved.
At the heart of any MTD mechanism is the technique
to decide when to move the chosen components. As such,
we also plan to explore the various movement schemes
and its effect on web applications that use our MTD approach. Finally, we will create a modular framework that
can automatically apply our implemented MTD techniques
in each layer of the web application in order to create a vast
number of possible configurations. We will then evaluate
this framework using real web applications deployed on a
real-world network, in order to measure its effectiveness.
VIII. C ONCLUSION
In this paper we explored the feasibility of applying
MTD concepts to web applications in order to create
defensive layers. We analyzed the web application stack
to understand where and how MTD can be applied, as
well as current techniques implemented in each layer. In
addition, we also discussed our implementation of two
MTD approaches, which can mitigate several classes of web
application vulnerabilities or exploits, wherein we change
the language implementation of the web application and the
database implementation while retaining functionality. We
believe that MTD offers an exciting new research area in
defending web applications, and we believe that the future
of web application defense lies in reducing the information
asymmetry inherent in the current web application security
environment.
ACKNOWLEDGMENT
This work was partially supported by the grant from
National Science Foundation (NSF-SFS-1129561).
R EFERENCES
[1] J. Silver-Greenberg, M. Goldstein, and N. Perlroth, “JPMorgan Chase Hacking Affects 76 Million Households,” The New
York Times, Oct. 2014.
[2] J. Robertson and M. Riley, “JPMorgan Hack Said to Span
Months Via Multiple Flaws,” Aug. 2014.

[3] D. Balzarotti, M. Cova, V. Felmetsger, N. Jovanovic, E. Kirda,
C. Kruegel, and G. Vigna, “Saner: Composing static and
dynamic analysis to validate sanitization in web applications,”
in Security and Privacy, 2008. SP 2008. IEEE Symposium on.
IEEE, 2008, pp. 387–401.
[4] V. Felmetsger, L. Cavedon, C. Kruegel, and G. Vigna, “Toward automated detection of logic vulnerabilities in web
applications,” in USENIX Security Symposium, 2010, pp. 143–
160.
[5] N. Jovanovic, C. Kruegel, and E. Kirda, “Static analysis
for detecting taint-style vulnerabilities in web applications,”
Journal of Computer Security, vol. 18, no. 5, pp. 861–907,
2010.
[6] A. Doupé, L. Cavedon, C. Kruegel, and G. Vigna, “Enemy of the State: A State-Aware Black-Box Vulnerability
Scanner,” in Proceedings of the USENIX Security Symposium
(USENIX), Bellevue, WA, August 2012.
[7] A. Doupé, W. Cui, M. H. Jakubowski, M. Peinado,
C. Kruegel, and G. Vigna, “deDacota: Toward Preventing
Server-Side XSS via Automatic Code and Data Separation,”
in Proceedings of the ACM Conference on Computer and
Communications Security (CCS), Berlin, Germany, November
2013.
[8] D. Wichers, “Owasp top-10 2013,” OWASP Foundation,
February, 2013.
[9] A. Cui and S. J. Stolfo, “Symbiotes and defensive mutualism:
Moving target defense,” in Moving Target Defense. Springer,
2011, pp. 99–108.
[10] R. Zhuang, S. A. DeLoach, and X. Ou, “Towards a theory
of moving target defense,” in Proceedings of the First ACM
Workshop on Moving Target Defense, ser. MTD ’14. New
York, NY, USA: ACM, 2014, pp. 31–40. [Online]. Available:
http://doi.acm.org/10.1145/2663474.2663479
[11] P. Ratanaworabhan, V. B. Livshits, and B. G. Zorn, “Nozzle:
A defense against heap-spraying code injection attacks.” in
USENIX Security Symposium, 2009, pp. 169–186.
[12] P. Team, “Address space layout randomization,” Phrack, 2003.
[13] E. G. Barrantes, D. H. Ackley, T. S. Palmer, D. Stefanovic,
and D. D. Zovi, “Randomized instruction set emulation to
disrupt binary code injection attacks,” in Proceedings of the
10th ACM conference on Computer and communications
security. ACM, 2003, pp. 281–289.
[14] P. Larsen, A. Homescu, S. Brunthaler, and M. Franz, “Sok:
Automated software diversity,” in Security and Privacy (SP),
2014 IEEE Symposium on. IEEE, 2014, pp. 276–291.
[15] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin, “Binary
stirring: Self-randomizing instruction addresses of legacy x86
binary code,” in Proceedings of the 2012 ACM conference on
Computer and communications security. ACM, 2012, pp.
157–168.
[16] D. Williams, W. Hu, J. W. Davidson, J. D. Hiser, J. C.
Knight, and A. Nguyen-Tuong, “Security through diversity:
Leveraging virtual machine technology,” Security & Privacy,
IEEE, vol. 7, no. 1, pp. 26–33, 2009.

[17] B. Salamat, T. Jackson, G. Wagner, C. Wimmer, and
M. Franz, “Runtime defense against code injection attacks
using replicated execution,” Dependable and Secure Computing, IEEE Transactions on, vol. 8, no. 4, pp. 588–601, 2011.
[18] S. Vikram, C. Yang, and G. Gu, “Nomad: Towards nonintrusive moving-target defense against web bots,” in Communications and Network Security (CNS), 2013 IEEE Conference on. IEEE, 2013, pp. 55–63.
[19] M. Dunlop, S. Groat, W. Urbanski, R. Marchany, and J. Tront,
“Mt6d: A moving target ipv6 defense,” in MILITARY COMMUNICATIONS CONFERENCE, 2011 - MILCOM 2011,
Nov 2011, pp. 1321–1326.
[20] M. Carvalho and R. Ford, “Moving-target defenses for computer networks,” Security Privacy, IEEE, vol. 12, no. 2, pp.
73–76, Mar 2014.
[21] Y. Li, R. Dai, and J. Zhang, “Morphing communications of
cyber-physical systems towards moving-target defense,” in
Communications (ICC), 2014 IEEE International Conference
on, June 2014, pp. 592–598.
[22] A. Doupé, B. Boe, C. Kruegel, and G. Vigna, “Fear the ear:
discovering and mitigating execution after redirect vulnerabilities,” in Proceedings of the 18th ACM conference on
Computer and communications security. ACM, 2011, pp.
251–262.
[23] J. Portner, J. Kerr, and B. Chu, “Moving target defense against
cross-site scripting attacks (position paper),” in Foundations
and Practice of Security. Springer, 2014, pp. 85–91.
[24] C. Reis, A. Barth, and C. Pizano, “Browser security: lessons
from google chrome,” Queue, vol. 7, no. 5, p. 3, 2009.
[25] Liebao, “Cheetah browser. http://www.liebao.cn/index.html.”
[26] Qihu, “360 browser. http://www.360safe.com/browser.html.”
[27] P. Eckersley, “How unique is your web browser?” in Privacy
Enhancing Technologies. Springer, 2010, pp. 1–18.
[28] P. Laperdrix, W. Rudametkin, and B. Baudry, “Mitigating
browser fingerprint tracking: multi-level reconfiguration and
diversification,” in Proceedings of the International Symposium on Software Engineering for Adaptive and SelfManaging Systems (SEAMS’15), 2015.
[29] N. Nikiforakis, W. Joosen, and B. Livshits, “PriVaricator: Deceiving fingerprinters with Little White Lies,” in Proceedings
of the International World Wide Web Conference (WWW),
2015.
[30] N. Nikiforakis, A. Kapravelos, W. Joosen, C. Kruegel,
F. Piessens, and G. Vigna, “Cookieless Monster: Exploring
the Ecosystem of Web-based Device Fingerprinting,” in Proceedings of the IEEE Symposium on Security and Privacy,
2013.
[31] Ide,
“Php
just
grows
&
grows.
http://news.netcraft.com/archives/2013/01/31/php-justgrows-grows.html.”

[32] Sangster,
“Organizations
using
python.
https://wiki.python.org/moin/organizationsusingpython.”
[33] Donohue,
“Top
15
sites
built
with
python.
http://coderfactory.com/posts/top-sites-built-with-python.”
[34] “Db-engines ranking. http://db-engines.com/en/ranking.”
[35] “Mysql users. https://www.mysql.com/customers/.”
[36] “Postgresql users. http://www.postgresql.org/about/users/.”
[37] A. Avizienis and L. Chen, “On the implementation of nversion programming for software fault tolerance during
execution,” in Proc. IEEE COMPSAC, vol. 77, 1977, pp. 149–
155.
[38] P. E. Ammann and J. C. Knight, “Data diversity: An approach
to software fault tolerance,” Computers, IEEE Transactions
on, vol. 37, no. 4, pp. 418–425, 1988.
[39] K. Pettis and R. C. Hansen, “Profile guided code positioning,”
in ACM SIGPLAN Notices, vol. 25, no. 6. ACM, 1990, pp.
16–27.
[40] S. Forrest, A. Somayaji, and D. H. Ackley, “Building diverse
computer systems,” in Operating Systems, 1997., The Sixth
Workshop on Hot Topics in. IEEE, 1997, pp. 67–72.
[41] H. Okhravi, M. Rabe, T. Mayberry, W. Leonard, T. Hobson,
D. Bigelow, and W. Streilein, “Survey of cyber moving target
techniques,” DTIC Document, Tech. Rep., 2013.
[42] A. Nguyen-Tuong, D. Evans, J. C. Knight, B. Cox, and
J. W. Davidson, “Security through redundant data diversity,”
in Dependable Systems and Networks With FTCS and DCC,
2008. DSN 2008. IEEE International Conference on. IEEE,
2008, pp. 187–196.
[43] R. Zhuang, S. Zhang, A. Bardas, S. DeLoach, X. Ou, and
A. Singhal, “Investigating the application of moving target
defenses to network security,” in Resilient Control Systems
(ISRCS), 2013 6th International Symposium on, Aug 2013,
pp. 162–169.
[44] L. Ge, W. Yu, D. Shen, G. Chen, K. Pham, E. Blasch,
and C. Lu, “Toward effectiveness and agility of network
security situational awareness using moving target defense
(mtd),” vol. 9085, 2014, pp. 90 850Q–90 850Q–9. [Online].
Available: http://dx.doi.org/10.1117/12.2050782
[45] J. H. Jafarian, E. Al-Shaer, and Q. Duan, “Openflow
random host mutation: Transparent moving target defense
using software defined networking,” in Proceedings
of the First Workshop on Hot Topics in Software
Defined Networks, ser. HotSDN ’12. New York, NY,
USA: ACM, 2012, pp. 127–132. [Online]. Available:
http://doi.acm.org/10.1145/2342441.2342467
[46] Y. Huang and A. K. Ghosh, “Introducing diversity and
uncertainty to create moving attack surfaces for web services,”
in Moving Target Defense. Springer, 2011, pp. 131–151.
[47] S. W. Boyd and A. D. Keromytis, “Sqlrand: Preventing sql
injection attacks,” in Applied Cryptography and Network
Security. Springer, 2004, pp. 292–302.

Lucky 13 Strikes Back
Gorka Irazoqui

Mehmet Sinan İnci

Thomas Eisenbarth

Worcester Polytechnic Institute

Worcester Polytechnic Institute

Worcester Polytechnic Institute

girazoki@wpi.edu

msinci@wpi.edu
Berk Sunar

teisenbarth@wpi.edu

Worcester Polytechnic Institute

sunar@wpi.edu
ABSTRACT
In this work we show how the Lucky 13 attack can be resurrected in the cloud by gaining access to a virtual machine
co-located with the target. Our version of the attack exploits
distinguishable cache access times enabled by VM deduplication to detect dummy function calls that only happen in
case of an incorrectly CBC-padded TLS packet. Thereby, we
gain back a new covert channel not considered in the original
paper that enables the Lucky 13 attack. In fact, the new side
channel is significantly more accurate, thus yielding a much
more effective attack. We briefly survey prominent cryptographic libraries for this vulnerability. The attack currently
succeeds to compromise PolarSSL, GnuTLS and CyaSSL on
deduplication enabled platforms while the Lucky 13 patches
in OpenSSL, Mozilla NSS and MatrixSSL are immune to
this vulnerability. We conclude that, any program that follows secret data dependent execution flow is exploitable by
side-channel attacks as shown in (but not limited to) our
version of the Lucky 13 attack.

Keywords
Lucky 13 attack, Cross-VM attacks, virtualization, deduplication

1.

MOTIVATION

The Transport Layer Security (TLS) family of protocols
ensures the security of the entire communications infrastructure by providing confidentiality and integrity services
across untrusted networks. Numerous web applications rely
on TLS to secure client-server data traffic. Similarly distributed applications use TLS to establish a secure channel for transporting application-layer data with centralized
cloud servers. At the higher level TLS uses X.509 certificates along with public key cryptography to authenticate
the exchanged symmetric encryption keys and to authenticate the server. This session key is then used to ensure the
integrity and confidentiality of the data exchanged over a
secure session between the TLS client and server.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ASIA CCS’15, April 14–17, 2015, Singapore..
c 2015 ACM 978-1-4503-3245-3/15/04 ...$15.00.
Copyright 
http://dx.doi.org/10.1145/2714576.2714625.

Starting as Secure Sockets Layer (SSL), after adoption
by the IETF TLS has undergone many changes (SSL 1.0,
2.0, 3.0, TLS 1.0, 1.1, 1.2). Many releases were motivated
by attacks targeting both the protocols and the underlying
cryptographic schemes [38, 8, 7, 17, 29, 5, 16, 41]. In this
work we focus on attacks targeting the padding procedure
in TLS’s MAC-Encode-Encrypt (MEE) primitive.
Implementation Attacks on TLS. Handling CBC IVs,
and paddings in cryptographic algorithms has a long history
of attacks and countermeasures, and is notoriously hard to
get right in implementations. As early as in 1998 Bleichenbacher pointed to vulnerabilities in SSL 3.0 stemming from
leaked error messages due to incorrectly padded plaintexts.
Later Vaudenay [38] presented an attack in the symmetric key setting on SSL/TLS induced by CBC mode padding.
The BEAST chosen plaintext attack (Browser Exploit Against
SSL/TLS) [15] exploited a long-known cipher block chaining
(CBC) mode IV vulnerability in TLS 1.0 [25] to achieve full
plaintext recovery. The exploit is based on the earlier work
in [32, 8, 7]. The padding oracle attack is most commonly
applied to CBC encryption mode, where the server leaks
whether the padding of an encrypted message was correctly
formed or not. Depending on the specifics of the encryption
scheme and the encapsulating protocol, this side-channel
leakage may be escalated to a full message recovery attack.
These are collectively referred to as padding oracle attacks.
A more recent striking application of the aforementioned
padding attacks was given by Bardou et al. [9] where many
cryptographic hardware tokens were determined to be vulnerable. Specifically, Bardou et al. apply Vaudenay’s CBC
attack and improve Bleichenbacher’s attack to significantly
reduce the number of decryption oracle accesses, thereby
making attacks feasible on slow tokens.
Even though in the last years the padding oracle attacks
were considered a fixed vulnerability in the community, in
2013 a new kind of padding oracle attack was presented by
AlFardan et al. [16]. The Lucky 13 attack was proposed
to recover TLS/DTLS encrypted messages by exploiting a
vulnerability in the implementation of HMAC. The attack
works by carefully modifying network packets during transmission, and using network timing information to recover
the plaintext byte-by-byte from TLS encrypted packets. The
attack received significant attention from the media and industry. A great deal of work went into fixing the TLS vulnerability. A widely applied and immediate fix—using RC4
encryption instead of a block cipher in CBC mode—turned
out to be ill-advised: The attack described in [5] exploits
statistical biases in the RC4 key stream to recover parts of

the plaintext using a large number of TLS encryptions. To
fix the popular MEE mode that uses a block cipher in CBC
mode, cryptographic library providers applied various techniques aimed to equalize packet processing times, e.g. by
calling a dummy HMAC function. Since then modifications
are being studied to solve attacks against MEE schemes and
the Lucky 13 issue has been considered closed by the security
community and the industry.
In this work, we revive the Lucky 13 attack on a number of
prominent cryptographic libraries which have been patched
to eliminate the network timing side-channel. We instead
run our attacks in the cross-VM setting using cache access
information to realize the Lucky 13 attack.
Cross-VM Attacks. Cross-VM attacks assume a co-located
process running on the same physical hardware as a target
process (e.g. same machine on different cores) can extract
information from the target in spite of the VM sandboxing.
Many side-channel attacks have been proposed that manage
to recover sensitive data when a spy process is executed in
the same OS as the victim. For instance, the early proposal
by Bernstein [11] (and later in [12, 36, 18]) targets the time
variation due to memory accesses to recover a AES encryption key. These techniques are now being moved to cloud
servers to break sandboxing across virtual machines.
Cross-VM attacks assume the attacker to be able to colocate with the victim. Co-location was considered a major
obstacle until 2009 when Ristenpart et al. [31] demonstrated
that it is possible to co-locate with a potential victim and
extract sensitive data across VMs.This initial result fueled
many other research targeting a co-located victim in a cloud
system.
In 2011, Suzaki et al. [33, 34] exploited a memory saving
OS-optimization called Kernel Samepage Merging (KSM) to
recover data from another user and to identify a co-located
user running in KVM hypervisors. Shortly later, Zhang et
al. [42] used an access driven cache timing attack, namely
Prime and Probe to recover an El Gamal decryption key
from a victim process running in Xen VMs. In order to
cope with multiple sources of microarchitectural noise, the
authors used a hidden Markov model. In contrast to the
work of Ristenpart et al. [31], the authors of [42] were able
to extract fine grain information from a cryptographic implementation across VMs.
Recently the powerful Flush+Reload attack was used by
Yarom et.al in cloud-like environments such as VMware ESXI
and KVM to extract RSA [41, 10] and ECDSA keys, while
Irazoqui et al. used the same detection method to recover
AES keys from co-located VMware VMs [21].

1.1

Our Contribution

In this work we demonstrate that by mounting cache attacks it is possible to revive a modified Lucky 13 attack on
many of the patched TLS libraries. Specifically, we show
that it is possible to recover plaintexts from TLS encrypted
sessions across VM boundaries by applying a flush+reload
cache attack in VMware ESXi VMs. The vulnerability persists even if the VMs are running on different cores in the
same machine. The attack works because some TLS libraries
prevent the Lucky 13 attack by using dummy functions to
ensure constant time executions. By monitoring the instruction cache, we detect accesses to these dummy functions and
hence distinguish valid CBC-paddings, as done in the Lucky
13 attack. While requiring co-location, the cache side chan-

nel is less noisy than the network timing side channel originally exploited in [16], resulting in a more efficient attack.
The effectiveness of the new attack is demonstrated on a
number prominent cryptographic libraries: PolarSSL [30],
GnuTLS [24], and CyaSSL [1]. Fortunately, our results also
indicate that some libraries such as OpenSSL [35], Mozilla’s
NSS [26], and MatrixSSL [3] have been patched well and the
new attack does not apply to them. These libraries feature
carefully crafted constant run time execution while OpenSSL
and Mozilla’s NSS also ensure branch-free handling of MAC
checking.

2.

BACKGROUND

In this work we substitute the network timing channel
with the cache timing channel as experienced in a Cross-VM
setting. There is a very rich literature of cache attacks and
here we only very briefly review cache timing attacks and
focus on a more recent and effective cache attack variant,
e.g the Flush+Reload cache attack.
Cache Architecture. The cache architecture is a set of
components that reside between the CPU and the RAM.
The principal function of the cache is to reduce the average access time to the main memory by exploiting spatial
and temporal locality principles. When the CPU requests a
memory line, the cache will be searched first to see if it is
located there. If so, it is said that a cache hit has occurred
and therefore, the access delay is much smaller. However
when the data is not found in the cache, the CPU will try
to find the memory line in the subsequent levels of cache or
in the memory, which translates to greater delays. In this
case it is said that a cache miss has occurred. When a cache
miss occurs, the data is retrieved from the memory and a
copy is stored in all levels of the cache hierarchy following
both the spatial and temporal locality principles: recently
accessed data and data in nearby locations are likely to be
accessed soon.
Cache Side channel attacks. Cache based side channel
attacks have been widely studied over the last two decades.
It was in 1992 when the cache was first considered as a valid
covert channel to extract sensitive information [20], and this
approach was further studied theoretically later in [23, 28,
37]. In the last decade many implementations of cache based
side channel attacks have been investigated. Bernstein in
2005 [11] recovered an AES keys due to microarchitectural
time differences between different memory lines, whereas
Osvik et al. studied the performance of different spy processes monitoring the data cache like Prime and Probe and
Evict+Time on AES [27]. Only one year later, Bonneau
et al. implemented a cache attack based on table look up
collisions on AES [13].
Shortly later Acıiçmez showed that the instruction cache
also leaks information by mounting an attack targeting RSA
encryptions [4]. In a follow up work, Chen et al. improved
the attack proposed in [4] and applied it in a more realistic
scenario [14]. One year later, cache attacks were moved to
the cloud by Zhang et al. where they managed to recover
an El Gamal encryption key across XEN VMs [42].
Recently Gullasch et al. [19] demonstrated that deduplication features implemented in modern OSs can open a covert
channel to recover sensitive information like AES keys with
the Flush+Reload attack, but assuming to have control over
the CFS. This approach was later followed by Yarom et al.

and Irazoqui et al. to recover RSA and AES keys respectively, even in cloud environments [41, 21]. Finally Benger
et al. also showed that the security of ECDSA encryptions
is compromised when the adversary is able to monitor cache
accesses [10].

OPENSSL
APACHE

2.1

The Flush+Reload attack is a powerful cache-based side
channel attack technique that checks if specific cache lines
have been accessed or not by the code under attack. Gullasch et al. [18] first used this spy process on AES, although
the authors did not brand their attack as Flush+Reload at
the time. Later Yarom et al. [41, 10] used it to target specific functions instead of data. In their studies, they used
the Flush+Reload technique to recover keys from RSA and
ECDSA decryption processes. Here we briefly explain how
Flush+Reload attack works. The attack is carried out in 3
stages:
• Flush step: In this stage, the attacker uses the clflush
instruction to flush the desired memory lines from the
cache and make sure that they go to the main memory.
We have to remark here that the clflush command
does not only flush the memory line from the cache
hierarchy of the corresponding working core, but it
flushes from all the caches of all the cores in the CPU.
This is an important point: if it only flushed from the
corresponding core’s cache hierarchy, the attack would
only work if the attacker and victim’s processes were
running on the same CPU core. This would have required a much stronger assumption than just being on
the same physical machine.
• Victim accessing step: In this stage the attacker
waits until the victim runs a fragment of the targeted
code, which uses the memory lines that have been
flushed in the first stage.
• Reload step: In this stage the attacker reloads the
previously flushed memory lines and measures the time
it takes to reload them. Depending on the reloading
time, the attacker decides whether the victim accessed
the memory line (in which case the memory line would
be present in the cache) or if the victim did not access the corresponding memory line (in which case the
memory line will not be present in the cache.) The
timing difference between a cache hit and a cache miss
makes this difference detectable by the attacker.
The fact that the attacker and the victim processes do not
run on the same core is not a problem here. Even though
there may be isolation at various levels of the cache, in most
systems there is some level of cache that is shared between
all the cores. Therefore, through this shared level of cache
(typically the L3 cache), one can still distinguish between
accesses to the main memory and accesses to the cache.

2.2

OPENSSL

The Flush+Reload Technique

Memory Deduplication

Memory deduplication is an optimization technique that
was originally introduced in Linux as KSM to improve the
memory utilization by merging duplicate memory pages.
KSM first appeared in Linux kernel version 2.6.32 [22, 2].
In this implementation, KSM kernel daemon ksmd, scans
the user memory for potential pages to be shared among

APACHE
APACHE

FIREFOX

FIREFOX

Figure 1: Memory Deduplication Scheme

users [6], creating signatures for these pages. The signatures are kept in the deduplication table for matching and
merging. When two or more pages with the same signature
are found, they are cross-checked completely to determine
if they are identical in which case they are merged with the
copy-on-write tag set.
Deduplication later became a standard technique for improving the memory utilization in VMMs. It is especially effective in virtual machine environments where multiple guest
OSs co-reside on the same physical machine and share the
physical memory. At the more abstract level, deduplication works by recognizing processes (or VMs) that place the
same data in memory. This frequently happens when two
processes use the same shared libraries. The deduplication
scheme eliminates multiple copies from memory and allows
the data to be shared between users and processes. Consequently, variations of memory deduplication techniques are
now implemented in VMware ESXI [39, 40] and others such
as KVM [2, 22] VMMs. Since KVM converts the Linux kernel into a hypervisor, it directly uses KSM as page sharing
technique, whereas VMware uses Transparent Page Sharing
(TPS).
Even though deduplication saves memory and thus allows
more virtual machines to run on the host system, it also
opens a door to side channel attacks. While the data in
the cache cannot be modified or corrupted by an adversary,
parallel access rights can be exploited to reveal secret information about processes executing in the target VM.

3.

THE LUCKY 13 ATTACK

The Lucky 13 attack targets a vulnerability in the TLS
(and DTLS) protocol design. The vulnerability is due to
MAC-then-encrypt mode, in combination with the padding
of the CBC encryption, also referred to as MEE-TLS-CBC.
In the following, our description focuses on this popular
mode. Vaudenay [38] showed how the CBC padding can
be exploited for a message recovery attack. AlFardan et
al. [16] showed—more than 10 years later—that the subsequent MAC verification introduces timing behavior that
makes the message recovery attack feasible in practical settings. In fact, their work includes a comprehensive study of
the vulnerability of several TLS libraries. In this section we
give a brief description of the attack. For a more detailed
description, please refer to the original paper [16].

HDR|SQN

DATA

HMAC

DATA

TAG

PAD

CBC
ENCRYPTION

HDR

CIPHERTEXT

this, we are repeating the example given in [16] as follows.
Assume that the plaintext size is 55 bytes. In this case an
8 byte length field is appended together with a padding of
size 1, so that the total size is 64 bytes. Here in total the
HMAC operation is going to take four compression function
calls. However if the plaintext size is 58, an 8 byte length
field is attached and 62 bytes of padding are appended to
make the total size equal to 128 bytes. In this case, the total
compression function calls are going to be equal to five. Distinguishing the number of performed compression function
calls is the basic idea that enables the Lucky 13 attack.

3.3
Figure 2: Encryption and authentication in the TLS
record protocol when using HMAC and a block cipher in CBC mode.

CBC Encryption & Padding

Until the support of the Galois Counter Mode in TLS
1.2, block ciphers were always used in cipher block chaining
(CBC) mode in TLS. Decryption of each block of a ciphertext Ci is performed as follows:
Pi = Dk (Ci ) ⊕ Ci−1

3.1

The TLS Record Protocol

The TLS record protocol provides encryption and message
authentication for bulk data transmitted in TLS. The basic
operation of the protocol is depicted in Figure 2. When a
payload is sent, a sequence number and a header are attached to it and a MAC tag is generated by any of the available HMAC choices. Once the MAC tag is generated, it is
appended to the payload together with a padding. The payload, tag, and pad are then encrypted using a block cipher
in CBC mode. The final message is formed by the encrypted
ciphertext plus the header.
Upon receiving an encrypted packet, the receiver decrypts
the ciphertext with the session key that was negotiated in
the handshake process. Next, the padding and the MAC
tag need to be removed. For this, first the receiver checks
whether the size of the ciphertext is a multiple of the block
size and makes sure that the ciphertext can accommodate
minimally a zero-length record, a MAC tag, and at least
one byte of padding. After decryption, the receiver checks if
the recovered padding matches one of the allowed patterns.
A standard way to implement this decoding step is to check
the last byte of the plaintext, and to use it to determine how
many of the trailing bytes belong to the padding. Once the
padding is removed, and the plain payload is recovered, the
receiver attaches the header and the sequence number and
performs the HMAC operation. Finally, the computed tag is
compared to the received tag. If they are equal, the contents
of the message are concluded to be securely transmitted.

3.2

HMAC

The TLS record protocol uses the HMAC algorithm to
compute the tag. The HMAC algorithm is based on a hash
function H that performs the following operations:
HMAC(K, m) = H((K ⊕ opad)||H((K ⊕ ipad)||M )
Common choices in TLS 1.2 for H are SHA-1, SHA-256 and
the now defunct MD5. The message M is padded with a
single 1 bit followed by zeros and an 8 byte length field.
The pad aligns the data to a multiple of 64 bytes. K ⊕ opad
already forms a 64 byte field, as well as K ⊕ ipad. Therefore, the minimum number of compression function calls for
a HMAC operation is 4. This means that depending on the
number of bytes of the message, the HMAC operation is going to take more or less compression functions. To illustrate

Here, Pi is the plaintext block and Dk (·) is the decryption
under key k. For the prevalent AES, the block size is 16
bytes. The size of the message to be encrypted in CBC mode
has to be indeed a multiple of the cipher block size. The
TLS protocol specifies a padding as follows: the last padding
byte indicates the length of the padding; the value of the remaining padding bytes is equal to the number of padding
bytes needed. This means that if 3 bytes of padding is
needed, the correct padding has to be 0x02|0x02|0x02. Possible TLS paddings are: 0x00, 0x01|0x01, 0x02|0x02|0x02,
up to 0xff|0xff| . . . |0xff. Note that there are several valid
paddings for each message length.

3.4

An Attack On CBC Encryption

We now discuss the basics of the Lucky 13 attack. For the
purposes of this study the target cipher is going to be AES in
CBC mode, as described above. Again, we are going to use
the same example that AlFardan et al. gave in [16]. Assume
that the sender is sending 4 non-IV blocks of 16 bytes each,
one IV block, and the header number. Let’s further assume
that we are using SHA-1 to compute the MAC tag, in which
case the digest size is 20 bytes. The header has a fixed length
of 5 bytes and the sequence number would have a total size
of 8 bytes. The payload would look like this:
HDR|CIV |C1 |C2 |C3 |C4
Now assume that the attacker masks ∆ in C3 . The decryption of C4 is going to be as follows:
P4∗ = Dk (C4 ) ⊕ C3 ⊕ ∆ = P4 ⊕ ∆
∗
∗
Focusing on the last two bytes P4(14)
|P4(15)
three possible
scenarios emerge:
Invalid padding This is the most probable case, where the
plaintext ends with an invalid padding. Therefore, according
to TLS protocol, this is treated as 0 padding. 20 bytes of
MAC (SHA-1) are removed and the corresponding HMAC
operation in the client side is performed on 44 bytes +13
bytes of header, in total 57 bytes. Therefore the HMAC
evaluates 5 compression function calls.
∗
Valid 0x00 padding If P4(15)
is 0x00, this is considered
as valid padding, and a single byte of padding is removed.
Then the 20 bytes of digest are removed, and the HMAC
operation in client side is done in 43+13 bytes, 56 in total,
which takes 5 compression function calls.

Any other valid padding For instance, if we consider
a valid padding of two bytes, the valid padding would be
0x01|0x01 and 2 bytes of padding are removed. Then 20
bytes of digest are removed, and the HMAC operation is
performed over 42 + 13 = 55 bytes, which means four compression function calls.
The Lucky 13 attack is based on detecting this difference
between 4 and 5 compression function calls. Recall that if an
attacker knows that a valid 0x01|0x01 padding was achieved,
she can directly recover the last two bytes of P4 , since
0x01|0x01 = P4(14) |P4(15) ⊕ ∆(14) |∆(15)
Furthermore, she can keep on trying to recover the remaining bytes once she knows the first 2 bytes. The attacker
needs to perform at most 216 trials for detecting the last
two bytes, and then up to 28 messages for each of the bytes
that she wants to recover.

4.

ANALYSIS OF LUCKY 13 PATCHES

The Lucky 13 attack triggered a series of patches for all
major implementations of TLS [16]. In essence, all libraries
were fixed to remove the timing side channel exploited by
Lucky 13, i.e. implementations were updated to handle different CBC-paddings in constant time. However, different
libraries used different approaches to achieve this:
• Some libraries implement dummy functions or processes,
• Others use dummy data to process the maximum allowed padding length in each MAC checking.
In the following, we discuss these different approaches for
some of the most popular TLS libraries.

4.1

Patches Immune to Flush+Reload

In this section we will analyze those libraries that are secure against the flush and reload technique.
• OpenSSL: The Lucky 13 vulnerability was fixed in
OpenSSL versions 1.0.1, 1.0.0k, and 0.9.8y by February 2013 without the use of a time consuming dummy
function and by using dummy data. Basically, when
a packet is received, the padding variation is considered and the maximum number of HMAC compression function evaluations needed to equalize the time
is calculated. Then each compression function is computed directly, without calling any external function.
For every message, the maximum number of compression functions are executed, so that no information is
leaked through the time channel in case of the incorrect padding. Furthermore, the OpenSSL patch removed any data dependent branches ensuring a fixed
data independent execution flow. This is a generic solution for microarchitectural leakage related attacks,
i.e. cache timing or even branch prediction attacks.
• Mozilla NSS: This library is patched against the
Lucky 13 attack in version 3.14.3 by using a constant
time HMAC processing implementation. This implementation follows the approach of OpenSSL, calculating the number of maximum compression functions
needed for a specific message and then computing the

compression functions directly. This provides not only
a countermeasure for both timing and cache access attacks, but also for branch prediction attacks.
• MatrixSSL: MatrixSSL is fixed against the Lucky 13
with the release of version 3.4.1 by adding timing countermeasures that reduce the effectiveness of the attack.
In the fix, the library authors implemented a decoding
scheme that does a sanity check on the largest possible
block size. In this scheme, when the received message’s
padding length is incorrect, Matrix SSL runs a loop as
if there was a full 256 bytes of padding. When there
are no padding errors, the same operations are executed as in the case of an incorrect padding to sustain a constant time. Since there are no functions
that are specifically called in the successful or unsuccessful padding cases, this library is not vulnerable to
our Flush+Reload attack. In addition, Matrix SSL
keeps track of all errors in the padding decoding and
does the MAC checking regardless of valid or invalid
padding rather than interrupting and finalizing the decoding process at the first error. However, since an if
statement is used when the extra compression function
is called, the library might be a suitable target for a
branch prediction attack.

4.2

Patches Vulnerable to Flush+Reload

There are some patches that ensure constant time execution and therefore are immune to the original Lucky 13
attack [16] which are vulnerable to Flush+Reload. This implies a dummy function call or a different function call tree
for valid and invalid paddings. Furthermore, if these calls
are preceded by branch predictions, these patches might also
be exploitable by branch prediction attacks. Some examples
including code snippets are given below.
• GnuTLS: uses a dummy_wait function that performs
an extra compression function whenever the padding is
incorrect. This function makes the response time constant to fix the original Lucky 13 vulnerability. Since
this function is only called in the case of incorrect
padding, it can be detected by a co-located VM running a Flush+Reload attack.
i f (memcmp ( tag , &c i p h e r t e x t −>data [ l e n g t h ] ,
t a g s i z e ) != 0 | | p a d f a i l e d != 0 )
//HMAC was not t h e same .
{dummy wait(params , compressed , pad failed ,
pad , length+preamble size ) ; }
• PolarSSL: uses a dummy function called md_process
to sustain constant time to fix the original Lucky 13
vulnerability. Basically the number of extra runs for a
specific message is computed and added by md_process.
Whenever this dummy function is called, a co-located
adversary can learn that the last padding was incorrect and use this information to realize the Lucky 13
attack.
f o r ( j = 0 ; j < e x t r a r u n ; j++ )
\\We need an e x t r a run
md process ( &s s l −>transform in−>
md ctx dec , s s l −>in msg ) ; ] ∗

• CyaSSL: was fixed against the Lucky 13 with the release of 2.5.0 on the same day the Lucky 13 vulnerability became public. In the fix, CyaSSL implements a
timing resistant pad/verify check function called TimingPadVerify which uses the Padcheck function with
dummy data for all padding length cases whether or
not the padding length is correct. CyaSSL also does
all the calculations such as the HMAC calculation for
the incorrect padding cases which not only fixes the
original Lucky 13 vulnerability but also prevents the
detection of incorrect padding cases. This is due to the
fact that the Padcheck function is called for both correctly and incorrectly padded messages which makes
it impossible to detect with our Flush+Reload attack.
However, for the correctly padded messages, CyaSSL
calls the CompressRounds function which is detectable
with Flush+Reload .Therefore, we monitor the correct
padding instead of the incorrect padding cases.
Correct padding case:
PadCheck (dummy, ( byte ) padLen ,
MAX PAD SIZE − padLen − 1 ) ;
r e t = s s l −>hmac ( s s l , v e r i f y , input ,
pLen − padLen − 1 − t , c o n t e n t , 1 ) ;
CompressRounds( s s l , GetRounds(pLen ,
padLen , t ) , dummy) ;
ConstantCompare ( v e r i f y , i n p u t +
( pLen − padLen − 1 − t ) , t ) != 0 )
Incorrect padding case:
CYASSL MSG( ”PadCheck f a i l e d ”) ;
PadCheck (dummy, ( byte ) padLen ,
MAX PAD SIZE − padLen − 1 ) ;
s s l −>hmac ( s s l , v e r i f y , input ,
pLen − t , c o n t e n t , 1 ) ;
// s t i l l compare
ConstantCompare ( v e r i f y , i n p u t +
pLen − t , t ) ;

5.

REVIVING LUCKY 13 ON THE CLOUD

As the cross-network timing side channel has been closed
(c.f. Section 4), the Lucky 13 attack as originally proposed
no longer works on the recent releases of most cryptographic
libraries. In this work we revive the Lucky 13 attack to target these (fixed) releases by gaining information through colocated VMs (a leakage channel not considered in the original paper) rather than the network timing exploited in the
original attack.

5.1

Regaining the Timing Channel

Most cryptographic libraries and implementations have
been largely fixed to yield an almost constant time when
the MAC processing time is measured over the network. As
discussed in Section 4, although there are some similarities
in these patches, there are also subtle differences which—as
we shall see—have significant implications on security. Some
of the libraries not only closed the timing channel but also
various cache access channels. In contrast, other libraries left
an open door to implement access driven cache attacks on
the protocol. In this section we analyze how an attacker can
gain information about the number of compression functions

Figure 3: Histogram of network time measured for
sent packages with valid (4 compression functions)
and invalid (5 compression functions) paddings.

performed during the HMAC operation by making use of
leakages due to shared memory hierarchy in VMs located
on the same machine. This is sufficient to re-implement the
Lucky 13 attack.
More precisely, during MAC processing depending on whether
the actual MAC check terminates early or not, some libraries call a dummy function to equalize the processing
time. Knowing if this dummy function is called or not reveals whether the received packet was processed as to either
having a invalid padding, zero length padding or any other
valid padding. In general, any difference in the execution
flow between handling a well padded message, a zero padded
message or an invalid padded message enables the Lucky 13
attack. This information is gained by the Flush+Reload
technique if the cloud system enables deduplication features.
To validate this idea, we ran two experiments:
• In the first experiment we generated encrypted packets
using PolarSSL client with valid and invalid paddings
and measured the network time as shown in Figure 3.
Note that, the network time in the two distributions
obtained for valid and invalid paddings are essentially
indistinguishable as intended by the patches.
• In the second experiment we see a completely different
picture. Using PolarSSL we generated encrypted packets with valid and invalid paddings which were then
sent to a PolarSSL server. Here instead, we measured
the time it takes to load a specifically chosen PolarSSL
library function running inside a co-located VM. Figure 4 shows the probability distributions for a function
reloaded from L3 cache vs. a function reloaded from
the main memory. The two distributions are clearly
distinguishable and the misidentification rate (the area
under the overlapping tails in the middle of the two
distributions) is very small. Note that, this substitute
timing channel provides much more precise timing that
the network time. To see this more clearly, we refer
the reader to Figure 2 in [16] where the network time

in case of TLS as many as 214 trials were necessary to
guess a single byte value.

Disadvantages:.
• Assumption of co-location: To target a specific victim, the attacker has to be co-located with that target. However the attacker could just reside in a physical machine and just wait for some potential random
victim running a TLS operation.
• Other sources of noise: The attacker no longer has to
deal with network channel noise, but still has to deal
with other microarchitectural sources of noise, such
as instruction prefetching. This new source of noise
is translated in more traces needed, but as we will
see, much less than in the original Lucky 13 attack. In
Section 6 we explain how to deal with this new noise.

5.3
Figure 4: Histogram of access time measured for
function calls from the L3 cache vs. a function called
from the main memory.
is measured to obtain two overlapping Gaussians by
measurements with OpenSSL encrypted traffic. This
is not a surprise, since the network channel is significantly more noisy.
In conclusion, we regain a much more precise timing channel,
by exploiting the discrepancy between L3 cache and memory accesses as measured by a co-located attacker. In what
follows, we more concretely define the attack scenario, and
then precisely define the steps of the new attack.

5.2

New Attack Scenario

In our attack scenario, the side channel information will
be gained by monitoring the cache in a co-located VM. In
the same way as in [16] we assume that the adversary captures, modifies, and replaces any message sent to the victim.
However, TLS sessions work in such a way that when the
protocol fails to decrypt a message, the session is closed.
This is the reason why we focus in multi-session attacks
where the same plaintext in the same place is being sent
to the victim e.g. an encrypted password sent during user
authentication.
The fact that we are working with a different method in
a different scenario gives us some advantages and disadvantages over the previous Lucky 13 work:

Advantages:.
• Recent patches in cryptographic libraries mitigate the
old Lucky 13 attack, but are still vulnerable in the new
scenario.
• In the new scenario, no response from the server is
needed. The old Lucky 13 attack needed a response to
measure the time, which yielded a noisier environment
in TLS than DTLS.
• The new attack does not suffer from the network channel noise. This source of noise was painful for the measurements as we can see in the original paper, where

Attack Description

In this section we describe how an attacker uses Flush+Reload
technique to gain access to information about the plaintext
that is being sent to the victim.
• Step 1 Function identification: Identify different
function calls in the TLS record decryption process
to gain knowledge about suitable target functions for
the spy process. The attacker can either calculate the
offset of the function she is trying to monitor in the
library, and then add the corresponding offset when the
Address Space Layout Randomization (ASLR ) moves
her user address space. Another option is to disable
the ASLR in the attackers VM, and use directly the
virtual address corresponding to the function she is
monitoring.
• Step 2 Capture packet, mask and replace: The
attacker captures the packet that is being sent and
masks it in those positions that are useful for the attack. Then she sends the modified packet to the victim.
• Step 3 Flush targeted function from cache: The
flush and reload process starts after the attacker replaces the original version of the packet and sends it.
The co-located VM flushes the function to ensure that
no one but the victim ran the targeted function. Any
subsequent execution of the targeted function will bear
a faster reload time during the reload process.
• Step 4 Reload target function & measure: Reload
the corresponding function memory line again and measure the reload time. According to a threshold that
we set based on experimental measurements, we decide whether the dummy function was loaded from
the cache (implying that the victim has executed the
dummy function earlier) or was loaded from the main
memory (implying the opposite).
Since the attacker has to deal with instruction prefetching,
she will be constantly running Flush+Reload for a specified
period of time. The attacker therefore distinguishes between
functions preloaded and functions preloaded and executed,
since the latter will stay for a longer period of time in the
cache.

6.

EXPERIMENT SETUP AND RESULTS

In this section we present our test environment together
with our detection method in order to deal with different
cache prefetch techniques that affect our measurements. Finally we present the results of our experiments for the PolarSSL, GnuTLS and CyaSSL libraries.

6.1

Experiment Setup

The experiments were run on an Intel i5-650 dual core at
3.2 GHz. Our physical server includes 256 KB per core L2
cache, and a 4 MB L3 cache shared between both cores. We
used VMware ESXI 5.5.0 build number 162338 for virtualization. TPS is enabled with 4 KB pages. In this setting, our
Flush+Reload technique can distinguish between L3 cache
and main memory accesses.
For the TLS connection, we use an echo server which reads
and re-sends the message that it receives, and a client communicating with it. Client and echo server are running in
different virtual machines that use Ubuntu 12.04 guest OS.
We modify the echo server functionality so that it adds a
jitter in the encrypted reply message, modeling the Man
in the Middle Attack. Once the message is sent, the echo
server uses Flush+Reload to detect different function calls
and concludes if the padding was correct or not. For the
TLS connection, we use an echo server which reads and resends the message that it receives, and a client communicating with it. Client and echo server are running in different virtual machines that use Ubuntu 12.04 guest OS. We
modify the echo server functionality so that it adds a jitter
in the encrypted reply message, modeling the Man in the
Middle Attack. Once the message is sent, the echo server
uses Flush+Reload to detect different function calls and concludes if the padding was correct or not.

6.2

Dealing with Cache Prefetching

Modern CPUs implement cache prefetching in a number
of ways. These techniques affect our experiments, since the
monitored function can be prefetched to cache, even if it
was not executed by the victim process. To avoid false positives, it is not sufficient to detect if the monitored functions were loaded to cache, but also for how long they have
resided in the cache. This is achieved by counting the number of subsequent detections for the given function in one
execution. Therefore, the attack process effectively distinguishes between prefetched functions and prefetched and executed functions.
We use experiments to determine a threshold (which differs across the libraries) to distinguish a prefetch and execute
from a mere prefetch. For PolarSSL this threshold is based
on observing three Flush+Reload accesses in a row. Assume
that n is the number of subsequent accesses required to conclude that the function was executed. In the following we
present the required hits for different libraries, i.e. the number of n-accesses required to decide whether the targeted
function was executed or not.

6.3

Attack on PolarSSL1.3.6

Our first attack targets PolarSSL 1.3.6, with TLS 1.1. In
the first scenario the attacker modifies the last two bytes
of the encrypted message until she finds the ∆ that leads
to a 0x01|0x01 padding. Recall that 216 different variations
can be performed in the message. The first plot shows the
success probability of guessing the right ∆ versus L, where

Figure 5: (PolarSSL 1.3.6) Success probability of
recovering P14 and P15 vs. L, for different number of
hits required. L refers to the number of 216 traces
needed, so the total number of messages is 216 ∗ L.

L refers to the number of 216 traces needed. For example
L = 4 means that 216 ∗ 4 messages are needed to detect the
right ∆. Based on experimental results, we set the access
threshold such that we consider a hit whenever the targeted
function gets two accesses in a row.
The measurements were performed for different number
of required hits. Figure 5 shows that requiring a single hit
might not suffice since the attacker gets false positives, or
for small number of messages she may miss the access at
all. However when we require two hits, and if the attacker
has a sufficient number of messages (in this case L = 23 ),
the probability of guessing the right ∆ is comfortably close
to one. If the attacker increases the limit further to ensure
an even lower number of false positives, she will need more
messages to see the required number of hits. In the case of
3 hits, L = 24 is required to have a success probability close
to one.
Figure 6 shows the success probability of correctly recovering P13 , once the attacker has recovered the last two bytes.
Now the attacker is looking for the padding 0x02|0x02|0x02.
We observed a similar behavior with respect to the previous
case where with L = 8 and with a two hits requirement we
will recover the correct byte with high probability. Again if
the attacker increases the requirement to 3 hits, she will need
more measurements; about L = 16 is sufficient in practice.

6.4

CyaSSL 3.0.0

Recall that the attack is much more effective if the attacker knows any of the preceding bytes of the plaintext,
for example the last byte P15 of the plaintext. This would
be the case in a javascript/web setting where adjusting the
length of an initial HTTP request an attacker can ensure
that there is only one unknown byte in the HTTP plaintext. In this case, the attacker would not need to try 216
possible variations but only 28 variations for each byte that
she wants to recover. This is the scenario that we analyzed
in CyaSSL TLS 1.2, where we assumed that the attacker

Figure 6: (PolarSSL 1.3.6) Success probability of recovering P13 assuming P14 , P15 known vs L, for different number of hits required. L refers to the number
of 28 traces needed, so the total number of messages
is 28 ∗ L.

Figure 7: (CyaSSL3.0.0) Success Probability of recovering P14 assuming P15 known vs L, for different
number of hits required. L refers to the number of
28 traces needed, so the total number of messages
would be 28 ∗ L.

knows P15 and she wants to recover P14 . Now the attacker
is again trying to obtain a 0x01|0x01 padding, but unlike in
the previous case, she knows the ∆ to make the last byte
equal to 0x01. The implementation of CyaSSL behaves very
similarly to the one of PolarSSL, where due to the access
threshold, a one hit might lead to false positives. However,
requiring two hits with a sufficient number of measurements
is enough to obtain a success probability very close to one.
The threshold is set as in the previous cases, where a hit is
considered whenever we observe two Flush+Reload accesses
in a row.

6.5

GnuTLS 3.2.0

Finally we present the results confirming that GnuTLS3.2.0
TLS 1.2 is also vulnerable to this kind of attack. Again, the
measurements were taken assuming that the attacker knows
the last byte P15 and she wants to recover P14 , i.e., she wants
to observe the case where she injects a 0x01|0x01 padding.
However GnuTLS’s behavior shows some differences with
respect to the previous cases. For the case of GnuTLS we
find that if we set an access threshold of three accesses in
a row (which would yield our desired hit), the probability
of getting false positives is very low. Based on experimental measurements we observed that only when the dummy
function is executed we observe such a behavior. However
the attacker needs more messages to be able to detect one of
these hits. Observing one hit indicates with high probability
that the function was called, but we also consider the two hit
case in case the attacker wants the probability of having false
positives to be even lower. Based on the measurements we
conclude that the attacker recovers the plaintext with very
high probability, so we did not find it necessary to consider
the three hit case.

Figure 8: (GnuTLS3.2.0) Success Probability of recovering P14 assuming P15 known vs. L, for different
number of hits required. L refers to the number of
28 traces needed, so the total number of messages
would be 28 ∗ L.

7.

COUNTERMEASURES

In this section we present various countermeasures that
would prevent an attacker from implementing our modified
Lucky 13 attack in a cloud environment. We first discuss
software countermeasures, i.e, changes that can be made in
the vulnerable cryptographic libraries to avoid the Lucky 13
attack. Then, we discuss more generic countermeasures to
avoid the usage of Flush+Reload as a side channel technique
to recover information. Note that library patches are less
costly to implement than hardware based countermeasures.

On the downside, the software patches result in sub-optimal
utilization of the memory hierarchy, thus, affecting the execution time performance.
Countermeasures in the cryptographic library: As
our earlier survey of the library patches has revealed, there
are two primary principles one needs to employ to securely
patch cryptographic libraries against the cross-VM Lucky 13
attack:
• Same function for valid/invalid padded cases:
The first pitfall that should be avoided takes place
when a separate function call, e.g. a dummy function,
is made to achieve a constant time implementation.
This was part of the leakage exploited in this work
where we monitor the dummy function calls made by
another victim. In order to prevent it, a single function should be used during the entirety of the MAC
operation of the message, as well as the additionally
needed compression stages.

Algorithm 1: Data independent execution flow for
md process
//M=Message,l=length Message without padding
Input : M,l
//Digest of M
Output: digest(M)
//Assume hash operates on a 16 byte message,
and we have a maximum length of 64
for i = 0 to 4 do
valid=(16*i/l);
md process(M[16*i]*valid + dummy data*valid,
hash);
Append(digest[i],hash*valid);
end
return digest;

a private portion of the cache. In this scenario even
when memory deduplication is enabled, an attacker
could not interfere with the victim’s data in the cache,
and would no longer be able to distinguish whether the
monitored function was used or not.

• Same execution flow for valid/invalid padded
cases: This means that cryptographic library designers should avoid using message or key dependent branches
that can leak information to an adversary monitoring the execution flow. Instead, logical operations like
AND or XOR operations should be used to make the
execution independent of vulnerable inputs. For instance, this solution has been adopted by OpenSSL,
which calculates and always executes the maximum
number of possible compression function calls.
An example algorithm that embodies these principles is
presented in Algorithm 1. In the algorithm we are assuming that the maximum length of the processed message is 64
bytes, and that hash operations take 16 bytes of plaintext
and that l is the length of the message once the padding is
removed (for both correctly and incorrectly padded cases).
The md_process function is used to perform the hash operations over all message blocks. This function puts the output
in the hash variable. However, we use l to decide whether the
output of the hash operation should be appended to the digest or not, depending on whether we are processing dummy
data or the message. Note that the algorithm only uses a
single function for both the valid message and the dummy
data, thereby preventing execution flow distinguishing attacks. The code unifies the two separate execution flows.
Preventing Flush+Reload : Since our version of the Lucky 13
attack uses the Flush+Reload technique to extract timing information, any Flush+Reload countermeasure will also disable our attack. Here we note a few common Flush+Reload
countermeasures.
• Disabling deduplication features: Our detection
method is based on shared memory features that are
offered by VMMs. Although these features have the
advantage of significantly saving memory, they can also
be used as a side channel to snoop sensitive information
from a co-located user. Therefore, disabling deduplication closes the covert channel necessary to perform
the attack presented in this work.
• Cache Partitioning: This countermeasure should be
performed at the hardware level, and consists in splitting the cache into pieces so that each user uses only

• Masking the cache loads: This is a hardware-based
countermeasure as well, where each user has a private
masking value that is used when the data is loaded
into cache and when the data being read from the
cache. Since different users have different masking values, even when memory deduplication is enabled, attacker and victim would access the same data in memory through different cache addresses, preventing the
attack in this work.

8.

CONCLUSION

In this work we demonstrated that the Lucky 13 attack is
still a threat in the cross-VM setting for a number of prominent cryptographic libraries already patched for the Lucky 13
attack. We discussed the different approaches taken by the
major TLS libraries and showed that one class of timing
side channel countermeasure, i.e, using dummy functions
to achieve constant time execution, is vulnerable to crossVM Flush+Reload attacks. With practical experiments we
demonstrated that the side channel enabling Lucky 13 is still
existent in PolarSSL, GnuTLS and CyaSSL if run in a deduplication enabled virtual machine. In fact, the new cache
side channel is actually stronger, since it no longer suffers
from network noise, making the attack succeed with significantly fewer observations than the original Lucky 13 attack
in [16]. We also discussed how various crypto libraries fixed
the Lucky 13 vulnerability in detail to better explain what
makes a crypto library vulnerable to Flush+Reload based
attacks.
In our test setting, we used the VMware ESXi with TPS
enabled. This deduplication feature enabled us to detect
dummy function calls that are implemented by the vulnerable libraries to equalize HMAC execution time in the case
of incorrectly CBC-padded packets in TLS. Unlike in the
case of vulnerable libraries, OpenSSL, Mozilla NSS, and
MatrixSSL applied patches with a constant and paddingindependent program flow to fix the Lucky 13 vulnerability.
Libraries fixed this way are secure against the described attack.

With this study we showed that crypto library designers
and authors should be careful about not implementing any
data dependent execution paths and ensure true constant
execution time. We conclude that, any function or process
in a crypto library whose execution depends on the input
data is exploitable by cache side-channel attacks and that
libraries should be implemented accordingly.

9.

ACKNOWLEDGMENTS

This work is supported by the National Science Foundation, under grant CNS-1318919 and CNS-1314770. We
would like to thank the anonymous reviewers of AsiaCCS
2015 for their helpful comments. We would also like to thank
Craig Shue for his help on understanding memory deduplication features.

10.

REFERENCES

[1] CyaSSL: Embedded SSL library WolfSSL.
http://www.wolfssl.com/yaSSL/Home.html, May
2014.
[2] Kernel samepage merging.
http://kernelnewbies.org/Linux_2_6_32\
#head-d3f32e41df508090810388a57efce73f52660ccb/,
April 2014.
[3] MatrixSSL: Open source embedded SSL. May 2014.
[4] Acıİçmez, O. Yet another microarchitectural attack:
Exploiting i-cache. In Proceedings of the 2007 ACM
Workshop on Computer Security Architecture (New
York, NY, USA, 2007), CSAW ’07, ACM, pp. 11–18.
[5] AlFardan, N. J., Bernstein, D. J., Patterson,
K. G., Poettering, B., and Schuldt, J. C. N. On
the Security of RC4 in TLS. In 22nd USENIX
Security Symposium (2013).
[6] Arcangeli, A., Eidus, I., and Wright, C.
Increasing memory density by using KSM. In
Proceedings of the Linux symposium (2009), pp. 19–28.
[7] Bard, G. A challenging but feasible
blockwise-adaptive chosen-plaintext attack on SSL. In
SECRYPT (2006), pp. 99–109.
[8] Bard, G. V. The vulnerability of SSL to chosen
plaintext attack. IACR Cryptology ePrint Archive
2004:111, 2004.
[9] Bardou, R., Focardi, R., Kawamoto, Y.,
Simionato, L., Steel, G., and Tsay, J.-K. Efficient
padding oracle attacks on cryptographic hardware. In
CRYPTO (2012), R. Safavi-Naini and R. Canetti,
Eds., vol. 7417 of Lecture Notes in Computer Science,
Springer, pp. 608–625.
[10] Benger, N., van de Pol, J., Smart, N. P., and
Yarom, Y. ”ooh aah... just a little bit”: A small
amount of side channel can go a long way. In CHES
(2014), pp. 75–92.
[11] Bernstein, D. J. Cache-timing attacks on AES, 2004.
URL: http://cr.yp.to/papers.html#cachetiming.
[12] Bonneau, J. Robust Final-Round Cache-Trace
Attacks against AES.
[13] Bonneau, J., and Mironov, I. Cache-Collision
Timing Attacks against AES. In Cryptographic
Hardware and Embedded Systems—CHES 2006
(2006), vol. 4249 of Springer LNCS, Springer,
pp. 201–215.

[14] Chen Cai-Sen, Wang Tao, C. X.-C., and Ping, Z.
An improved trace driven instruction cache timing
attack on RSA. Cryptology ePrint Archive, Report
2011/557, 2011. http://eprint.iacr.org/.
[15] Duong, T., and Rizzo, J. Here come the XOR
ninjas.
[16] Fardan, N. J. A., and Paterson, K. G. Lucky
Thirteen: Breaking the TLS and DTLS Record
Protocols. In Security and Privacy (SP), 2013 IEEE
Symposium on (May 2013), pp. 526–540.
[17] Goodin, D. Hackers break SSL encryption used by
millions of sites. http://www.theregister.co.uk/
2011/09/19/beast_exploits_paypal_ssl/, 2011.
[18] Gullasch, D., Bangerter, E., and Krenn, S.
Cache Games – Bringing Access-Based Cache Attacks
on AES to Practice. IEEE Symposium on Security and
Privacy 0 (2011), 490–505.
[19] Gullasch, D., Bangerter, E., and Krenn, S.
Cache Games – Bringing Access-Based Cache Attacks
on AES to Practice. In Proceedings of the 2011 IEEE
Symposium on Security and Privacy (Washington,
DC, USA, 2011), SP ’11, IEEE Computer Society,
pp. 490–505.
[20] Hu, W.-M. Lattice scheduling and covert channels. In
Proceedings of the 1992 IEEE Symposium on Security
and Privacy (Washington, DC, USA, 1992), SP ’92,
IEEE Computer Society, pp. 52–.
[21] Irazoqui, G., İncİ, M. S., Eisenbarth, T., and
Sunar, B. Fine grain Cross-VM Attacks on Xen and
VMware are possible. preprint available at
http://ecewp.ece.wpi.edu/wordpress/vernam/
files/2014/04/main.pdf.
[22] Jones, M. T. Anatomy of Linux kernel shared
memory. http://www.ibm.com/developerworks/
linux/library/l-kernel-shared-memory/
l-kernel-shared-memory-pdf.pdf/, April 2010.
[23] Kelsey, J., Schneier, B., Wagner, D., and Hall,
C. Side channel cryptanalysis of product ciphers. In
Computer SecurityŮESORICS 98. Springer, 1998,
pp. 97–110.
[24] Mavrogiannopoulos, N., and Josefsson, S.
GnuTLS: The GnuTLS Transport Layer Security
Library. May 2014.
[25] Moeller, B. Security of CBC ciphersuites in
SSL/TLS: Problems and countermeasures.
http://www.openssl.org/?bodo/tls-cbc.txt, April
2004.
[26] Mozilla. Mozilla NSS: Network security services.
May 2014.
[27] Osvik, D. A., Shamir, A., and Tromer, E. Cache
Attacks and Countermeasures: The Case of AES. In
Proceedings of the 2006 The Cryptographers’ Track at
the RSA Conference on Topics in Cryptology (Berlin,
Heidelberg, 2006), CT-RSA’06, Springer-Verlag,
pp. 1–20.
[28] Page, D. Theoretical Use of Cache Memory as a
Cryptanalytic Side-Channel, 2002.
[29] Paterson, K. G., Ristenpart, T., and Shrimpton,
T. Tag size does matter: Attacks and proofs for the
TLS record protocol. In Advances in
Cryptology–ASIACRYPT 2011. Springer Berlin
Heidelberg, 2011, pp. 372–389.

[30] PolarSSL. PolarSSL: Straightforward,secure
communication. www.polarssl.org.
[31] Ristenpart, T., Tromer, E., Shacham, H., and
Savage, S. Hey, you, get off of my cloud: Exploring
information leakage in third-party compute clouds. In
Proceedings of the 16th ACM Conference on Computer
and Communications Security (New York, NY, USA,
2009), CCS ’09, ACM, pp. 199–212.
[32] Rogaway, P. Problems with proposed IP
cryptography.
http://www.cs.ucdavis.edu/?rogaway/papers/
draft-rogaway-ipsec-comments-00.txt, 1995.
[33] Suzaki, K., Iijima, K., Yagi, T., and Artho, C.
Memory deduplication as a threat to the guest OS. In
Proceedings of the Fourth European Workshop on
System Security (2011), ACM, p. 1.
[34] Suzaki, K., Iijima, K., Yagi, T., and Artho, C.
Software side channel attack on memory
deduplication. SOSP POSTER (2011).
[35] The OpenSSL Project. OpenSSL: The open source
toolkit for SSL/TLS. www.openssl.org, April 2003.
[36] Tromer, E., Osvik, D., and Shamir, A. Efficient
Cache Attacks on AES, and Countermeasures. Journal
of Cryptology 23, 1 (2010), 37–71.
[37] Tsunoo, Y., Saito, T., Suzaki, T., and Shigeri,
M. Cryptanalysis of DES implemented on computers
with cache. In Proc. of CHES 2003, Springer LNCS
(2003), Springer-Verlag, pp. 62–76.

[38] Vaudenay, S. Security Flaws Induced by CBC
Padding - Applications to SSL, IPSEC, WTLS. In
Proceedings of In Advances in Cryptology EUROCRYPT’02 (2002), Springer-Verlag,
pp. 534–546.
[39] VMWare. Understanding Memory Resource
Management in VMware vSphere 5.0.
http://www.vmware.com/files/pdf/mem_mgmt_perf_
vsphere5.pdf.
[40] Waldspurger, C. A. Memory resource management
in VMware ESX server. ACM SIGOPS Operating
Systems Review 36, SI (2002), 181–194.
[41] Yarom, Y., and Falkner, K. Flush+reload: A high
resolution, low noise, L3 cache side-channel attack. In
23rd USENIX Security Symposium (USENIX Security
14) (San Diego, CA, Aug. 2014), USENIX
Association, pp. 719–732.
[42] Zhang, Y., Juels, A., Reiter, M. K., and
Ristenpart, T. Cross-VM side channels and their use
to extract private keys. In Proceedings of the 2012
ACM Conference on Computer and Communications
Security (New York, NY, USA, 2012), CCS ’12, ACM,
pp. 305–316.

State-aware Network Access Management
for Software-Defined Networks
Wonkyu Han† , Hongxin Hu‡ , Ziming Zhao† , Adam Doupé† ,
Gail-Joon Ahn† , Kuang-Ching Wang‡ , and Juan Deng‡
†
‡
Arizona State University
Clemson University
{whan7, zzhao30, doupe, gahn}@asu.edu, {hongxih, kwang, jdeng}@clemson.edu
ABSTRACT
OpenFlow, as the prevailing technique for Software-Defined Networks (SDNs), introduces significant programmability, granularity,
and flexibility for many network applications to effectively manage and process network flows. However, because OpenFlow attempts to keep the SDN data plane simple and efficient, it focuses
solely on L2/L3 network transport and consequently lacks the fundamental ability of stateful forwarding for the data plane. Also,
OpenFlow provides a very limited access to connection-level information in the SDN controller. In particular, for any network
access management applications on SDNs that require comprehensive network state information, these inherent limitations of OpenFlow pose significant challenges in supporting network services.
To address these challenges, we propose an innovative connection tracking framework called S TATE M ON that introduces a global
state-awareness to provide better access control in SDNs. S TATE M ON is based on a lightweight extension of OpenFlow for programming the stateful SDN data plane, while keeping the underlying network devices as simple as possible. To demonstrate the
practicality and feasibility of S TATE M ON, we implement and evaluate a stateful network firewall and port knocking applications for
SDNs, using the APIs provided by S TATE M ON. Our evaluations
show that S TATE M ON introduces minimal message exchanges for
monitoring active connections in SDNs with manageable overhead
(3.27% throughput degradation).

1.

INTRODUCTION

Over the past few years, Software-Defined Networks (SDNs)
have evolved from purely an idea [12, 13, 18] to a new paradigm
that several networking vendors are not only embracing, but also
pursuing as their model for future enterprise network management.
According to a recent report from Google, SDN-based network
management helped them run their WAN at close to 100% utilization compared to other state-of-the-art network environments with
about 30% to 40% network utilization [22].
As the first widely adopted standard for SDNs, OpenFlow [28]
essentially separates the control plane and the data plane of a network device and enables the network control to become directly
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

SACMAT’16, June 05-08, 2016, Shanghai, China
c 2016 ACM. ISBN 978-1-4503-3802-8/16/06. . . $15.00

DOI: http://dx.doi.org/10.1145/2914642.2914643

programmable as well as the underlying infrastructure to be abstracted for network applications. With OpenFlow, only the data
plane exists in the network device, and all control decisions are
conveyed to the device through a logically-centralized controller.
In this way, OpenFlow can tremendously help administrators access and update configurations of network devices in a timely and
convenient manner and provide this ease of control to SDN applications as well.
While the abstraction of a logically centralized controller, which
is a core principle of SDNs is powerful, a fundamental limitation
of OpenFlow is the lack of capability to enable the maintenance of
network connection states inside both the controller and switches.
First, OpenFlow-enabled switches only forward the first packet of
a new flow to the controller so that the controller can make a centralized routing decision. Because the controller is unaware of subsequent packets of the flow, including those that change the state
of a network connection (e.g., TCP FIN), the controller has no
knowledge of the state of the connections in its network. Second,
OpenFlow-enabled switches are incapable of monitoring network
connection states as well. The “match-action” abstraction of OpenFlow heavily relies on L2/L3 fields (e.g., src_ip and dst_ip) and
the limited L4 fields (only src_port and dst_port), yet essential
information for identifying and maintaining the state of connections is contained in other L4 fields, such as TCP flags and TCP
sequence and acknowledgment numbers.
The lack of knowledge of network connection states in SDNs
brings significant challenges in building state-aware access control
management schemes [30]. In particular, some critical security services, such as stateful network firewalls that perform network-wide
access control, cannot be realized in SDNs. A stateful network firewall, which is a key network access control service in a traditional
network environment [17, 20, 34] and requires state-awareness,
keeps track of the states of connections in the network and makes
a decision for its access (e.g., ALLOW or DENY) according to the
states of connections in networks. However, it is impossibly hard
to realize them in current SDNs due to the inherent limitations of
OpenFlow.
Some recent research efforts [29, 30, 14, 36, 11, 6, 10, 37] extended the OpenFlow data plane abstraction to support stateful network applications. They attempted to let individual switches, rather
than the controller, track the state of connections. We believe that,
not only does this design go against the spirit of SDN (because it
brings the control plane back to switches and makes switches manipulate connection states and performs complex actions beyond a
simple forwarding operation), these existing approaches are only
applicable for designing applications that need only local states
on a single switch [10]. However, such solutions force SDN applications individually access every single switch to collect entire

network states, consequently network-wide monitoring to detect
abnormalities and enforcing network-wide access control of flows
become extremely difficult.
To overcome the limitations of existing approaches, we argue
that utilizing the SDN controller for global tracking connections
is more advantageous than existing solutions in terms of its state
visibility across SDN applications that is crucial to some security
applications such as a stateful network firewall. To bring such a
state-aware network access management in SDNs, we propose a
novel state tracking framework called S TATE M ON. S TATE M ON
models active connections in SDNs and monitors global connection
states in the controller with the help of both a global state table that
records the current state of each active connection and a state management table that governs the state transition of new and existing
connections. S TATE M ON also introduces a lightweight extension
to OpenFlow, called OpenConnection, that programs the data plane
to forward the state-changing packets to the controller. At the same
time, it retains the simple “match-action” programmable feature of
OpenFlow and avoids scalability problems over the communication
channel between the controller and switches. In essence, S TATE M ON follows the general SDN principle of logical-to-physical decoupling and avoids embedding complicated control logic in the
physical devices, therefore, keeping the SDN data plane as simple
as possible.
In addition, to demonstrate the practicality and feasibility of S TATE M ON and state-aware network access management applications in
SDNs, we design a stateful network firewall based on the APIs
provided by S TATE M ON. Our firewall application provides more
in-depth access control than a stateless SDN firewall [21]. It detects and resolves connection disruptions and unauthorized access
attempts targeting active connections in SDNs. To demonstrate
the generality of S TATE M ON, we re-implement a prior work (port
knocking) based on S TATE M ON (Section 5.2.3). Our experimental results show that S TATE M ON and network access management
applications (stateful firewall and port knocking) introduce manageable performance overhead to manage network access control.
Contributions: The contributions are summarized as follows:
• We propose a connection tracking framework called S TATE M ON that enables SDN to support state-aware access control
schemes by leveraging global network states. S TATE M ON
keeps the data plane as simple as possible, thus being compliant with the spirit of SDN’s design principle.
• We propose the OpenConnection protocol, which is a lightweight
extension to OpenFlow and retains the simple “match-action”
programmable feature of OpenFlow to enable a stateful SDN
data plane.
• We implement a prototype of S TATE M ON using Floodlight [1]
and Open vSwitch. Our experiments demonstrate that S TATE M ON introduces a minimal increase of communication messages with manageable performance overhead (3.27% throughput degradation).
• We design a stateful network firewall application, using the
APIs provided by S TATE M ON. Our experiments show that
the stateful firewall provides more control than existing stateless firewalls and it can effectively detect and mitigate certain
connection-related attacks (e.g., connection disruptions and
unauthorized access) in SDNs.
This paper is organized as follows. We overview the motivating problems in Section 2. Section 3 presents the design of state-

SDN Applications
Route
App

Load-balance
App

Firewall
App

SDN Controller
Webserver C

Stateless Policy
B → A ALLOW

Connection
Disruption/
Termination
Forward Flow

Reverse Flow

A→B

Host A

B→A
S1

S2

S3

fe1: A → B forward

fe2: A → B forward

fe3: A → B forward

fe6: B → A forward

fe5: B → A forward

fe4: B → A forward

Webserver B

Figure 1: Standard OpenFlow Operation and its Stateless Property.
aware S TATE M ON. Section 4 describes the design of stateful network firewall supported by S TATE M ON, and the implementation
and evaluation details are in Section 5. Section 6 discusses the related work of this paper, and Section 7 describes several important
issues. In Section 8, we conclude this paper.

2. BACKGROUND AND PROBLEM STATEMENT
To understand our proposed solution to adding state-awareness
to SDNs, we provide an overview of the current OpenFlow operation. When an OpenFlow-enabled switch receives a packet, it first
checks its flow tables to find matching rules. If no such rules exist, this means it is the first packet of a new flow. The switch then
forwards the packet to the controller, and it is the controller’s job
to decide how to handle the flow and to install flow table rules in
the appropriate switches. Specifically, the packet is encapsulated
in an OFPT_PACKET_IN message sent to the controller, and the
controller then installs corresponding rules called flow entries into
the switches along the controller’s intended path for the flow. Once
these flow entries are installed, all subsequent packets of this flow
are automatically forwarded by the switches, without sending the
packet to the controller.
For example, in Figure 1, host A wants to initiate a TCP connection with web server B. The first packet (TCP SYN) sent by host A
is checked by the ingress switch S1 and forwarded to the controller
because S1 has no flow table entry for the packet. The controller
allows the flow from host A to server B by installing flow entries
f e1 , f e2 , and f e3 , into switches S1, S2, and S3, respectively. The
flow from host A to server B is called a forward flow. Using the
same process, the response packet (TCP SYNACK) generated by
server B will trigger the controller to install f e4 , f e5 , and f e6 into
S3, S2, and S1, respectively. The flow from server B to host A is
called a reverse flow.
As can be seen from Figure 1, neither the OpenFlow-enabled
switch nor the controller has the ability to track and maintain connection states, which makes it impossible to directly develop stateful access control based on OpenFlow in SDNs. As a result, existing SDN controllers (e.g., Floodlight) only have a stateless firewall
application that enforces ACL (Access Control List) rules to monitor all OFPT_PACKET_IN behaviors.
Using Figure 1 as an example, these stateless firewall applications can only specify simple rules, such as “packets from server B
to host A are allowed.” In contrast, a stateful firewall is a critical component in traditional systems and networks which provides
more control over whether a packet is allowed or denied based on

Table 1: Existing Stateful Inspection and Management Methodologies for SDNs (D = data plane, C = control plane, A = application plane).
Solution
App-aware [29]
FAST [30]
FlowTags [14, 15]
OpenNF [16]
UMON [36]
P4 [11]
Conntrack [6]
OpenState [10]
SDPA [37]
S TATE M ON

Inspection
D C A
X
X
X
X
X X
X
X
X
X
X
X X

D
X
X

Storage
C A

X
X
X
X
X
X
X
X

X

Implementation
FW, LB
FW
Proxy cache
IDS, Net-Monitor
SW Switch
SW Switch
SW Switch
FW, HW Switch
FW, Port-Knock

Description
Maintain App-table in a switch; A switch performs handshaking on behalf of servers.
Controller compiles the state machine and installs it into switches.
Add tags to in-flight packets for keeping middleboxes’ state rather than checking state via switches or the controller.
OpenNF enables dynamic migration of middlebox states from one to another by supporting some operations (e.g., move, copy and share).
Put UMON tables in the middle of OpenvSwitch pipelines to perform anomaly detection.
A proposal for embedding programmable parser inside of switches to allow administrators to flexibly configure and define the data plane.
Build the conntrack module on top of existing OpenvSwitch implementation to enable stateful tracking of flows.
Perform state checking using the state table in conjunction with an extended finite state machine that is directly programmable by the controller.
Insert the forwarding processor in packet processing pipeline to enable stateful forwarding scheme; It also includes hardware-based design.
Using OpenConnection protocol, the controller centrally manages network states and provides them to SDN applications via APIs.

connection state information. For example, a stateful firewall rule
could specify “packets from server B to host A are allowed, if and
only if host A initiates the connection to server B.” These stateful rules are incredibly useful for security purposes, for instance to
specify that a web server should be able to accept incoming connections but never initiate an outgoing connection. However, despite
the great security benefit of these stateful policies, it is challenging to build a stateful firewall in SDNs without the full support of
stateful packet inspection [21], which is critical to provide effective
network access control management.
In addition to the development of a stateful firewall application,
the knowledge of connection states in SDNs can also help maintain the network’s availability. The SDN controller and applications can install, update, or delete flow entries for their own purposes. However, these actions may interrupt established connections, which may consequently damage the availability of services
in the network. Consider the case of a load balancer application,
which switches flows between two web servers (Servers B and C
in Figure 1). If the flows are changed while a network connection
is still in progress, the availability of the service would be affected.
Also, attackers, who are able to perform a man-in-the-middle attack
on OpenFlow-enabled switches [9], can also disrupt existing connections in the network by intentionally updating flow entries. The
root cause of these issues is that the controller and the SDN applications have no knowledge of the connection states, which results
in creating potential chances of unauthorized access into existing
connections by attackers. We argue that a critical functionality of
OpenFlow or any other SDN implementation is that the controller
should be able to identify the conflicts between active connections
and any pending flow entry update and provide network administrators with an early warning before a conflicting flow entry takes
effect. Existing verification tools [23, 24, 25, 27] cannot detect
and address such conflicts, because they are unaware of connection states in the network. By tracking global connection states in
the network, the controller will be able to deal with such conflicts
and help maintain the availability of the services in the network.
We summarize existing solutions in Table 1 that are mostly applicable only for designing applications that need states locally.
Among those solutions, only OpenNF [16] and P4 [11] attempt to
utilize the control plane of SDNs for state checking and consolidating network states. OpenNF focuses on collecting states of network
middleboxes (e.g., IDS, Net-Monitor) to support dynamic middlebox migration, and P4 is a proposal for next generation of OpenFlow to support state inspections. However, the former is not applicable for collecting generic network states (e.g., connection state),
and the latter does not include a workable implementation. Thus,
we argue that a global connection monitoring framework, which
can be aggregated by the controller, is imperative for network-wide
connection monitoring and access management. Such a global connection awareness not only enables stateful firewall applications to
detect indirect policy violations considering dynamic packet modi-

State-aware Access Control Applications
Other Applications
(e.g., port knocking)

Stateful Network Firewall

STATEMON
APIs

Controller
Flow
Programming
Module

Topology
Manager

...

...

Connection
Tracking
Module

OpenFlow
Messages

Global State
Table
State
Management
Table

OpenConnection
Messages

OpenFlow Channel

OpenConnection Channel

Control Channel

Port
Port

Port
Flow
Table
(1)

...

Flow
Table
(n)

OpenConnection
Table

Port

Pipeline

OpenConnection-enabled Switch

Figure 2:

S TATE M ON Architecture Overview

fication in SDNs, but also helps identify connection disruptions and
unauthorized access occurred in existing connections.

3.

S TATE M ON DESIGN

In this section, we first present the key design goals of our S TATE M ON framework. Then, we illustrate the overall architecture and
working modules of S TATE M ON and further show how they meet
our design goals.

3.1 Design Goals
To enable stateful access management applications and overcome
the limitations of existing approaches, we propose a novel stateaware connection tracking framework called S TATE M ON to support building stateful network firewall for SDNs. S TATE M ON is
designed with the following goals in mind:
• Centralization: S TATE M ON should, in adhering to the principles of SDN, manage a global view of all network connection states in a centralized manner at the control plane.
• Generalization: S TATE M ON should support any state-based
protocols and provide state information to SDN applications.
• High Scalability: S TATE M ON should minimize message exchanges between the controller and switches so that the control channel will not be the performance bottleneck when
monitoring all network connection states.

Connection Match Fields
OpenFlow Fields

Flags

SEQ

ACK

Actions

...

OC_CON_SIG Match Fields
OpenFlow Fields

Extended Fields

Flags

SEQ

ACK

...

Extended Fields

Packet In

OpenFlow-based
packet process

OpenConnection-based packet process
Direct packet to
OpenConn table?
NO

Figure 3: Structure of An Entry in An OpenConnection Table.

YES

Match signal
entry?

YES

Send OC_CON_SIG
message

NO

3.2

Match connection
entry?

S TATE M ON Architecture Overview

Figure 2 shows an overview of the S TATE M ON architecture, which
adds new modules in both the control plane (controller) and the data
plane (switches) of the OpenFlow system architecture.
To achieve the centralization goal, S TATE M ON modules in switches
use only the match-action abstraction to perform packet lookups,
forwarding, and other actions based on the OpenConnection table
(Section 3.3), whereas modules in the controller track a global view
of states (Section 3.4). A controller uses the OpenConnection protocol to program OpenConnection tables, which are added to the
OpenFlow processing pipeline by introducing a “Goto OpenConnection Table” instruction (Goto-OCT) in OpenFlow action set.
To achieve the generality goal, S TATE M ON maintains a pair of
global state table and state management table for each state-aware
application. A state-aware application initializes those tables and
registers callback functions using the APIs provided by S TATE M ON. The global state table records network-wide connection state
information. Each entry in this table represents an active connection by specifying the flow entries that govern the active connection (e.g., f e1 , · · · , f e6 in Figure 1) and its connection state (e.g.,
ESTABLISHED in TCP). The state management table keeps state
transition rules and actions that should be performed on each state
(e.g., send an OpenConnection message to the controller).
S TATE M ON uses three methods to minimize the communication
overhead between the controller and switches to meet the high scalability design goal. First, S TATE M ON leverages existing OpenFlow protocols such as OFPT_PACKET_IN message for monitoring connection states. For example, the first packet of a new flow
delivered by OFPT_PACKET_IN message would not trigger a separate OpenConnection message. Second, S TATE M ON identifies
ingress and egress switches for each connection and only installs
necessary OpenConnection entries into those switches to perform a
state-based inspection. Thus, S TATE M ON minimizes the increase
of additional table entries and avoids the potential overhead that
can be generated by other intermediate switches on the path. Third,
the OpenConnection protocol sends only expected state-changing
packets from switches to the controller.

3.3 OpenConnection Protocol
On receipt of a packet, an OpenConnection-enabled switch starts
with the OpenFlow-based packet process. For any new flow, the
first packet of this flow is forwarded to the controller via an OFPT_
PACKET_IN message. Then, the controller determines whether
that packet should be sent. If so, the controller will install new
flow entries into corresponding switches to handle future packets of
the same flow. S TATE M ON also listens to the OFPT_PACKET_IN
message. If this message carries a packet that any state-aware application wants to monitor (Section 3.5), S TATE M ON will install
OpenConnection entries in OpenConnection tables (Section 3.3.1)
of corresponding switches using OpenConnection messages (Section 3.3.2) and add a Goto-OCT instruction in the flow entries to
start OpenConnection processing pipeline.

3.3.1 OpenConnection Table
Before illustrating how OpenConnection-enabled switches process packets, we first explain the structure of the OpenConnection

NO

Drop packet

YES
Update SEQ/ACK
numbers of signal/
connection entries

Excute
action set

Figure 4: Flowchart for OpenConnection Packet Processing.
Table 2: OpenConnection Messages (C: controller, S: switch)
Message Name

Direction

OC_CON_SIG

S→C

OC_ADD
OC_UPDATE
OC_REMOVE

C→S
C→S
C→S

Description
Encapsulate entire packet (including payload)
and forward it to connection tracking module
Install a new entry in an OpenConnection table
Update an OpenConnection entry
Remove an OpenConnection entry

table. An OpenConnection entry, which is shown in Figure 3,
has (1) connection match fields, (2) actions for a decision of forward, drop, and update fields, etc., and (3) OC_CON_SIG match
fields that triggers switches to send OC_CON_SIG message when
matched. To achieve generality, both connection and OC_CON_SIG
match fields are directly programmable by state-aware SDN applications (Section 3.5).
If and only if a packet matches connection match fields, the
packet will be processed by both the OpenFlow and OpenConnection pipeline as shown in Figure 4. In case the packet also
matches the OC_CON_SIG match fields, which means the packet
is a state changing packet, such as FIN in TCP, it will be encapsulated in an OC_CON_SIG message and forwarded to the connection tracking module of S TATE M ON in the controller. The connection tracking module will maintain the state and manage associated
switches accordingly. Upon completion of these OpenConnectionbased packet process, the action set that includes the rest of the
OpenFlow actions will be executed.
The design of the OpenConnection table is aligned in spirit to the
design of the flow table, so that the data plane can process packets
using the simple “match-action” paradigm. However, OpenConnection tables are more scalable than OpenFlow tables, because
OpenConnection table entries are only installed in the OpenConnection tables of the two endpoint switches that directly connect
the initiating host and the receiving host of a connection. In contrast, using OpenFlow for each new flow, corresponding flow entries must be installed in all flow tables of switches that the flow
traverses.

3.3.2 OpenConnection Message Exchanging Format
We define four OpenConnection messages to enable state-based
connection monitoring. OpenConnection messages help the connection tracking module of S TATE M ON monitor the overall process
of connection establishment and tear-down behaviors occurring in
the data plane. Table 2 summarizes the four OpenConnection messages with a brief description of each.
The OC_CON_SIG message is used to encapsulate the statechanging packet and conveying it to the controller (switch-to-controller
direction). The main difference from OpenFlow OFPT_PACKET_IN

Table 3: State Management Table Example for TCP connection. (A (or B) refers a pair of hIP, porti.)
State
INIT
SYN_SENT
SYNACK_SENT
ESTABLISHED
FIN_WAIT
CLOSED

Transition Conditions
Message Type
Source
Match Fields
OFPT_PACKET_IN Ingress
A→B, TCP, Flag=SYN
OFPT_PACKET_IN Egress B→A, TCP, Flag=SYNACK
OC_CON_SIG
Ingress
A→B, TCP, Flag=ACK
Ingress
A→B, TCP, Flag=FIN
OC_CON_SIG
Egress
B→A, TCP, Flag=FIN
Egress
B→A, TCP, Flag=FIN
OC_CON_SIG
Ingress
A→B, TCP, Flag=FIN
-

-

-

is that the OC_ CON_SIG message is only for S TATE M ON (so
that it will not be effective to other SDN applications), and it also
contains a randomly generated unique identifier for the connection
to distinguish the affiliation of the message. The other messages
are sent from the controller to the switches to program an OpenConnection table. The connection tracking module generates a
OC_ADD message to install a new entry in an OpenConnection table. For instance, to monitor a TCP connection, it installs an entry
to match TCP ACK packet at its ingress switch of the flow path.
OC_UPDATE is used for updating an OpenConnection table entry.
If a connection is terminated (or by timeout mechanism), the connection tracking module sends an OC_REMOVE message to remove
all associated entries. Compared with OpenFlow, which exchanges
messages between the controller and multiple switches, OpenConnection introduces only a constant number of message exchanges
between the controller and two endpoint switches for handling a
specific state-based connection. Using TCP as an example, OpenConnection uses eight messages in total for a TCP connection (see
Table 5): (1) three OC_CON_SIG messages, (2) two OC_ADD messages, (3) one OC_UPDATE message, and (4) two OC_REMOVE
messages.

3.4 Tracking Connection States
For generality, S TATE M ON maintains a pair of global state table
and state management table for each state-aware application. The
connection tracking module listens to OFPT_PACKET_IN messages to initialize an entry in the global state table for a connection
and listens to OC_CON_SIG messages to update the states of the
connection based on state transition rules in the state management
table provided by the application.

3.4.1 Global State Table
The global state table records network-wide connection state information. However, simply extracting a connection’s state from a
specific switch is not sufficient to account for the overall global
state of a connection. Because OpenFlow-enabled switches are
able to rewrite packets’ headers at any point using the Set-Field
action, a packet’s header may look different at its ingress and egress
switches. This poses a challenge for the controller to identify which
packets belong to the same connection. To solve this problem,
S TATE M ON bonds a connection’s state (e.g., ESTABLISHED) with
its associated network rules (i.e.,the forward and reverse flow entries) to effectively monitor and track an active connection.
We design the entry in the global state table as a 5-tuple entry denoted hCI , CE , σF , σR , Sa i. Connection information at the
ingress switch (CI ) contains a set of packet header fields along
with its incoming physical switch port, pi . Connection information at the egress switch (CE ) contains the same elements, except
po which refers to the outgoing physical switch port. For instance,
CI for a TCP connection can be defined as hsrc_ip, src_port, dst_ip,
dst_port, network_protocol, pi i. Note that some fields in CI and CE
(e.g., src_ip, src_port, dst_ip, dst_port) might not be identical

Next State
SYN_SENT
SYNACK_SENT
ESTABLISHED

Message Type
OC_ADD
OC_ADD
OC_UPDATE

OpenConnection Events
Destination OC_CON_SIG Match Fields
Ingress
A→B, TCP, Flag=ACK
Egress
B→A, TCP, Flag=FIN
Ingress
A→B, TCP, Flag=FIN

FIN_WAIT

∞
5
5
1800

CLOSED
INIT

Timeout

60
OC_REMOVE
OC_REMOVE

Ingress
Egress

0

due to dynamic packet modification (Set-Field action) in SDNs.
σF is a series of identifiers of flow entries that enable the forward
flow, and σR is also a series of identifiers for the reverse flow. For
example, the forward flow and the reverse flow in Figure 1 would
be σF = hf e1 , f e2 , f e3 i and σR = hf e4 , f e5 , f e6 i, respectively.
The last element, Sa , denotes the state of a connection and it will
be further elaborated in Section 3.4.2.
The elements in a global state table entry have several properties.
The relation between CI and CE is to be determined by σF or σR
σ
−1
−1 σR
−−→ CI−1 . CI−1 and CE
are
such that CI −−F→ CE and CE
directly derived from CI and CE by replacing the source with the
destination and changing the incoming port (pi ) to the outgoing
port (po ). For example, if CI =hsrc_ip: 10.0.0.1, src_port: 3333,
dst_ip: 10.0.0.2, dst_port: 80, network_protocol: tcp, pi : 2i then
CI−1 =hsrc_ip: 10.0.0.2, src_port: 80, dst_ip: 10.0.0.1, dst_port:
3333, network_protocol: tcp, po : 2i.

3.4.2 State Management Table
An entry in the state management table is a 5-tuple denoted as
hState, Transition Conditions, Next State, OpenConnection Events,
Timeouti. When an OFPT_PACKET_IN or OC_CON_SIG message is received, the connection tracking module compares its originated location and header of the encapsulated packet with the Source
and Match Fields of the current state in the state management table. If the packet meets the Transition Conditions of the current
state, the state will be updated to the Next State and OpenConnection Events will be triggered. OpenConnection events instruct
the connection tracking module to send OC_ADD, OC_UPDATE,
or OC_REMOVE to corresponding switches. The Match Fields in
OpenConnection Events will configure the OpenConnection table
entries in corresponding switches to initialize connection and OC_
CON_SIG match fields. Timeout allows S TATE M ON to automatically close a connection.
Table 3 shows how a state-aware application can use the state
management table for the TCP state transitions. A TCP connection
starts with INIT state that transitions to SYN_SENT when it receives an OFPT_PACKET_IN message that contains a TCP SYN
flag. S TATE M ON identifies the location of the ingress switch (I)
from the message, and it sends an OC_ADD message back to I
with its match fields. S TATE M ON locates the egress switch (E)
as well by listening for the second OFPT_PACKET_IN message.
OC_CON_SIG messages collected from I or E are then used to
update the connection states. CLOSED is a temporary state only
used for sending OC_REMOVE messages and removing the associated entries. Note that one state can transition to multiple Next
States based on matching conditions and generate a variety of
actions as defined by SDN applications.

3.5

S TATE M ON APIs

S TATE M ON provides three types of application programming interfaces (APIs) for SDN applications so that the applications only
need to implement their business logic. The APIs can be used (1)

Table 4: S TATE M ON APIs
Category

API Name
InitGST()

Type I

InitSMT()
SetInterest()
SearchEntry()

Type II

Key Parameters
Match fields in
CI and/or CE
5-tuple of state
management table
Range of match
fields with wildcard
Raw packet or
ConnectionID

GetConnState()

ConnectionID

DeleteEntry()

ConnectionID
Type of message
and raw packet
ConnectionID and
next state

ConnAttempt()
Type III
StateChange()

Description
Initialize the global
state table
Initialize the state
management table
Search an associated
global state entry
Obtain current state
of a connection
Delete a connection
Callback function:
return one of actions
(allow or drop)

to configure both the global state table and the state management
table (Type I), (2) to retrieve state information from the global
state table (Type II), and (3) to register callback functions in
S TATE M ON to subscribe specific state-based events (Type III).
The APIs are summarized as follows:
• Type I is used to configure the two state-specific tables in
S TATE M ON: the global state table and the state management
table. To customize the global state table, SDN applications
can specify match fields for CI or CE (e.g., IP and port number) to distinguish one connection from another. Applications can also define a state set for the connection along with
its transition rules for the state management table.
• Type II APIs are built for sending queries (applications to
S TATE M ON) to retrieve network states, which SDN applications are interested in. Because all connection information is
recorded in the global state table, those queries are directly
conveyed to the global state table.
• Type III APIs are used to register callback functions in
S TATE M ON. For example, when a global state entry is updated, S TATE M ON can call this function to subscribing applications to allow them to execute their own business logic.

4.

STATEFUL FIREWALL DESIGN

In this section, to demonstrate the practicality and feasibility of
S TATE M ON and state-aware network access management applications in SDNs, we illustrate how a stateful firewall can take advantage of S TATE M ON to implement its state-aware access control
logic in SDNs.
The stateful firewall application first calls Type I APIs to initialize its global state table and state management table. We focus on TCP connections as a state-based protocol for this application. To enforce a stateful firewall policy such as “host B can
communicate with host A if and only if host A initiates the connection,” our firewall uses the state management table shown in
Table 3. Then, S TATE M ON calls the registered callback function
(Type III) when a state changing event occurs. The application only needs to implement the logic in the callback function: (1)
a packet (or flow) heading from host B to host A should be denied when its state is in INIT or SYNACK_SENT and (2) a packet
(or flow) heading from host B to host A should be allowed when
its state is in SYN_SENT or ESTABLISHED. Thus, the connection attempt (e.g., TCP SYN) initiated from host B cannot be made
whereas the attempt from host A will pass.
To show some benefits of our stateful firewall, we focus on following features: (1) state-aware firewall policy enforcement, (2)

Algorithm 1: Obtaining Affected Entry Set (AES)
Input: New (or Updated) flow entry (nf ) and existing flow entries
(F E = {e1 , e2 , ...}) at the same switch.
Output: Affected entry set AES = {a1 , a2 , ...} such that ai ∈ F E.
/* First, append the new flow entry (nf ) to AES
*/
AES.append(nf );
/* F Et : a set of flow entries installed in table t
*/
F Et ←− retrieveEntries(nf.getSwitchID, nf.getT ableID);
foreach e ∈ F Et do
/* Check if nf has higher priority than e and is
dependent with e
*/
if nf .priority ≥ e.priority and nf .match ∩ e.match 6= ∅ then
AES.append(e);
/* Recursively perform identical operation if e
has Goto-OCT instruction
*/
if e.getInstruction contains GotoT able then
temp_e.match ←− e.applyActions();
temp_e.setT ableID(e.getInstruction.getT ableID);
AES_child = self.(temp_e, E);
AES.append(AES_child);
return AES;

connection disruption prevention, and (3) unauthorized access prevention against active connections.

4.1 State-aware Firewall Policy Enforcement
Since S TATE M ON provides global network states to the firewall,
our firewall application utilizes the state information for the following scenarios: (1) a host attempts to establish a new connection, (2)
the state of an active connection has been updated, and (3) the firewall application updates the firewall policy.
First, when host A attempts to open a new connection to host
B, both host A and host B exchange initiating signal packets to
establish the connection. As soon as S TATE M ON receives these attempts, the firewall would get relevant information via the Type
III callback function defined when it called ConnAttempt(). If
this attempt violates the pre-defined stateful firewall policy, the initiating packet is immediately denied and the firewall stops the controller from executing the rest of the OFPT_PACKET_IN handling
process so that no flow entry is sent to the switches.
Second, if a global state entry is updated, the stateful firewall will
also be notified via Type III callback function, StateChange().
Our firewall application performs pair-wise comparison, the current
state of the connection against existing stateful firewall policies.
The firewall searches the associated global state entry by calling
SearchEntry() and acquires the connection information from the
entry. To consider Set-Field actions, it retrieves tracked space
denoted T (I, E), getting hsrc_ip, src_porti from I and hdst_ip,
dst_porti from E. By putting them together, we obtain T (I, E) =
hI.src_ip, I.src_port, E.dst_ip, E.dst_porti. Using the combination of T (I, E) and its current state, the firewall checks for rule
compliance with firewall policies. If the update of the state is not
allowed by the policy, the application raises an alarm to network
administrators and the update is denied by setting the return value
of StateChange() to drop. In case the stateful firewall application
wants to remove the connection, it may invoke DeleteEntry() function to remove the associated entries from the OpenConnection and
flow tables.
The final scenario deals with the case of updating firewall policies. When the firewall application updates a stateful rule in its
policy set, all active connections are examined against the new rule
to identify potential violations. Because each firewall policy has a
priority, computing dependency relations of firewall rules after the

Table 5: Additional State Management Table Entries for Unauthorized Access Prevention
State
SYNACK_SENT
SYNACK_SENT
ESTABLISHED
ESTABLISHED
DETECTED

Message Type
OC_CON_SIG
OC_CON_SIG
OC_CON_SIG
OC_CON_SIG
-

Transition Conditions
Source
Match Fields
Ingress A→B, TCP, Flag=ACK
Ingress A→B, TCP, Flag=ACK
Egress
A→B, TCP, Flag=FIN
Ingress B→A, TCP, Flag=FIN
-

Next State
ESTABLISHED
ESTABLISHED
DETECTED
DETECTED
ESTABLISHED

updates are vital for identifying overlaps between rules. All violating connections are to be deleted from the network by calling
the API DeleteEntry(). As a result, the associated OpenConnection
and flow entries will be flushed from the OpenConnection tables
and flow tables.

4.2 Connection Disruption Prevention
A malicious SDN application can manipulate existing flow entries or install new flow entries to disrupt active connections that
consequently damage the availability of services in the network.
To prevent this type of attack, detecting these attempts before they
take effect in the network is mandatory, so our firewall application
proactively analyzes the expected impact of updates on active connections. To this end, the application computes the Affected Entry
Set (AES) as described in Algorithm 1. When a new flow entry is
to be inserted into the network or an existing flow entry is about to
be updated, the application computes its dependencies with existing flow entries in the same switch. To this end, it first retrieves all
flow entries F E from a specific switch and computes affected flow
entries by new (or updated) flow entry nf . The application next
selects the exact flow table affected by nf and builds F Et which is
a subset of F E. Then, it compares the priority and matching conditions between e and nf , to decide whether e is affected. If nf is
dependent on e and has higher priority than e, the application adds
e into AES. If e has a goto instruction, the application further visits
the specified flow table to find AESchild . Considering Set-Field
actions e may have, the actions will be applied first in advance before pipelining to another flow table. The firewall makes use of
AES to detect the connection disruption attacks.
Detection of connection disruption attacks: Newly installed (or
updated) flow entry nf triggers the application to compute AES
and check AES against active connections obtained from S TATE M ON. The application then compares AES with σF and σR of each
of active connections and invokes the connection tracking module
′
to re-calculate σF′ and σR
. The updated σF′ may change the reσ′

′
′
lation between CI and CE i.e., CI −−F→ CE
. If CE 6= CE
, the
firewall concludes that the candidate flow entry nf will disrupt an
active connection. nf may also disrupt the reverse flow of the conσ′

−1
nection. If CE
−−R
→ CI′−1 and CI−1 6= CI′−1 , the firewall also
concludes nf will disrupt an active connection.
Countermeasure: When the controller receives the request of installation of a new flow entry nf which may cause a connection
disruption or interruption, S TATE M ON treats it as a candidate flow
entry and holds it until S TATE M ON evaluates its impact on the net′
work. Upon completion of computing AES and σF′ (or σR
), if the
′
firewall detects any error such as CE 6= CE
or CI−1 6= CI′−1 , it
raises an alarm to the administrator about the attempt. The administrator can decide whether it is legitimate and an intended request.
If it turns out nf is valid, S TATE M ON allows it to be installed in
the network. Otherwise, the firewall rejects the installation of nf .

4.3 Unauthorized Access Prevention
An attacker can attempt unauthorized access into an active connection by performing a man-in-the-middle attack such as TCP se-

Message Type
OC_ADD
OC_ADD

OpenConnection Events
Destination OC_CON_SIG Match Fields
Egress
A→B, TCP, Flag=FIN
Ingress
B→A, TCP, Flag=FIN

Timeout
5
5
1800
1800
0

quence inference attack to spoof packets. TCP protocol is inherently vulnerable to sequence inference attacks [33, 32]. We do not
fundamentally solve these known vulnerabilities but can partially
prevent specific types of unauthorized access to an active connection (e.g., TCP termination attacks). If an attacker successively
infers the sequence number of the next packet, he/she will be able
to create a spoofed termination packet by setting the TCP flags with
FIN (i.e., man-in-the middle attack [9]). Our firewall can leverage
S TATE M ON to detect such an attack by customizing the state management table and adding OpenConnection entries.
Detection of connection termination attacks: The key idea of
the detection mechanism is to add additional checking logic in the
egress switch for the forward flow (or the ingress switch for the
reverse flow) by installing new OpenConnection entries. In addition to the state management table described in Table 3, the firewall
adds additional transition rules (Table 5) to install OpenConnection entries and detect connection termination attacks. The firewall
first creates a new OpenConnection Events (the first line in Table 5)
for the SYNACK_SENT state that instructs the egress switch to install a new OpenConnection entry that matches the forward flow.
OC_CON_SIG match fields of this entry will match the TCP FIN
packet that belongs to the forward flow. Benign TCP FIN requests
sent from the initiating host will be checked at its ingress switch by
Table 3, so S TATE M ON transitions the state of the connection to the
ESTABLISHED state. Hence, OC_CON_SIG fields of the third entry in Table 5 will not match the packet. However, attacking packet
which is forged by an attacker in the middle of the flow path will
match the OC_CON_SIG conditions of the third entry at the egress
switch which results the state to be DETECTED. DETECTED state
defined in the fifth line in Table 5 is a temporary state that is used
to inform the existence of a TCP termination attack to the firewall.
In the case of the reverse flow, the firewall leverages the second
and the fourth entry for detecting connection termination attacks.
In such a way, the firewall can capture this type of attack with the
help of S TATE M ON.
Countermeasure: To protect the network from the aforementioned unauthorized access (e.g., TCP termination attack), the firewall can take two countermeasures: (1) return actions in the Type
III callback function with drop to drop the spoofed packet and
(2) rollback the connection state (DETECTED to ESTABLISHED)
to maintain the connectivity between end hosts. In addition, the
firewall may add complementary business logic in a Type III
callback function to implement post processing behaviors such as
sending warning messages to the network administrator.

5. IMPLEMENTATION AND EVALUATION
5.1 Implementation
To implement S TATE M ON, we chose a widely used controller,
Floodlight, and a reference OpenFlow software switch implementation, Open vSwitch (ovswitch). The routing module and link discovery modules in Floodlight are used to provide network topology information to the connection tracking module. To track existing flow entries in the network and build its reachability graph,
we used header space analysis [24] which translates each flow en-

5.2 Evaluation
To manage the state of a connection, existing solutions add the
transition logic of the connection in the data plane (Table 3). The
fundamental question, therefore, is how many additional messages
and/or performance overhead are introduced to achieve the same
goal in S TATE M ON. To this end, we conducted experiments using
three virtual machines, each of which had a quad-core CPU and
8GB memory and ran a Linux operating system (Ubuntu). One
virtual machine was used to run the Floodlight controller and each
of another ran Mininet [3] to simulate two networks. After we built
two separated networks, we connected them using a GRE tunnel to
flexibly add new hosts and links in one network without impacting
the other network. We also modified the size of the network by
changing the number of intermediaries (i.e., network switches).

5.2.1

S TATE M ON

To measure the worst-case performance of S TATE M ON, it was
configured to monitor every connection in the network. However,
in a real-world deployment, S TATE M ON only needs to monitor
connections specified by state-aware applications, which will only
improve the performance.
We first conducted experiments on an OpenConnection-enabled
switch to test the overhead created by S TATE M ON in the data plane.
OpenConnection enabled-switch spent less than 1µ for checking
the affiliation of incoming traffic in an OpenConnection table when
the table is set to have 100 entries. Creating and updating the corresponding entries in the OpenConnection table have been completed
within 2µs on average.
In the controller side, the connection tracking module is in charge
of installing/deleting an entry in the global state table and computing next state using the state management table. This module spent
less than 3µs on average to complete those two tasks when there

20
OpenConnection
OpenFlow

Messages per connection

18
16
14
12
10
8
6
4
2
0

VoIP

Bot

DoS

FTP

Web

(a) Messages per connection of each PCAP file.
4

3

x 10

OpenFlow
OpenConnection

2.5

Sent Messages

try into a transition function that consists of a set of binaries, 0,
1, and x (for wildcard), to represent its matching conditions and
actions. We also added OFPT_PACKET_IN listener within the
controller along with an OpenConnection message handler to receive the state changing packets and program OpenConnection tables. Each global state entry has a unique identifier to distinguish it
from other entries for ease of maintenance. The connection tracking module leverages the OFPT_FLOW_MOD OpenFlow message
to construct controller-to-switch OpenConnection messages.
In the data plane, we implemented the OpenConnection table
along with OpenConnection message handler. Because current versions of ovswitch can only support OpenFlow up to version 1.3.0,
which cannot inspect TCP flags and sequence/acknowledgment numbers, we implemented a parsing module to additionally retrieve
TCP flags and sequence/acknowledgment numbers. Then, we modified the legacy OpenFlow pipelining logic to enable OpenConnectionbased packet processing. In total, less than 500 lines of C code were
added to the ovswitch code base.
To implement the stateful firewall we leveraged a built-in firewall application in Floodlight to add a stateful checking module.
A stateful checking module in the firewall is able to access the
global state table by using S TATE M ON APIs for checking and enforcing its stateful firewall policy. We added the state parameter
to REST interface methods provided by the built-in firewall so that
users can define a stateful policy using REST requests. To prevent
connection disruption and unauthorized access, we added a listener
in the Static Flow Pusher module in Floodlight, so the application
is able to intercept potentially malicious or accidentally harmful
flow entry update requests and analyze their impacts on active connections before they become effective.

2

1.5

1

0.5

2

4

6

8

10

12

14

16

18

20

22

24

26

28

30

Number of Switches

(b) Message exchanges with different number of switches.
Figure 5: Message Exchanges in S TATE M ON
exist 100 connections in the network. To evaluate how much of the
delay can be attributed to network latency, we compared the numbers of message exchanges generated by both OpenFlow protocol
and OpenConnection protocol. We collected real network traffics
(five PCAP files) from different sources (available at [4, 7]) to generate real network traffic. Our testing framework (1) automatically
identifies source and destination IP addresses of each packet in a
PCAP file, (2) dynamically generates hosts for those IP addresses
in a network, and (3) sends the packet through their network interfaces. Figure 5(a) shows the number of message exchanges.
The first traffic is collected from VoIP traffic and consists of 32
connection attempts and 29 successful establishments. Network
traffic generated by this file caused the controller to generate 324
OpenFlow messages along with 215 OpenConnection messages,
which mean 10 OpenFlow messages and 7 OpenConnection Messages per connection on average. For counting OpenFlow messages, we excluded unrelated messages, such as OFPT_HELLO,
OFPT_ECHO_REQUEST, and FEATURE_ REPLY, and filtered out
unrelated OFPT_PACKET_IN messages used to handle connectionless packets, such as LLDP, ARP, and DNS. Therefore, OpenConnection protocol actually generated much fewer messages than
OpenFlow protocol. To account for theoretical number of OpenFlow messages, we develop the equation (1). For one way flow, we
need one OFPT_PACKET_IN message and n number of OFPT_
FLOW_MOD messages where n is the number of switches on the
path. Because a connection requires bi-directional flows, it is computed by 2 ∗ (1 + n).
BOF (n) = 2 ∗ (1 + n)

(1)

However, the number of OpenConnection messages does not depend on n. Because S TATE M ON requires eight messages for monitoring a connection, every PCAP type in Figure 5(a) creates ≤ 8

20

State−aware Policy Enforcement
Connection Disruption Prevention
Unauthorized Access Prevention

16

2.5

14
12
10
8
6
4
2
0

0

20

40

60

80

100

N−th Execution

Completion Time (milli sec)

Bandwidth(Gbits/sec)

3

Pure vSwitch w/ Floodlight
State−aware StateMon

18

2

1.5

1

Figure 6: Throughput between End Hosts
0.5

OpenConnection messages per connection. Considering the third
traffic that contains DoS attacks, it has generated a large number of
OpenFlow messages due to substantial connection attempts, while
the count of OpenConnection messages remained unchanged. This
results clearly show S TATE M ON creates minimal message exchanges
under any circumstances. Figure 5(b) shows how S TATE M ON scales
with respect to increasing the number of switches in the network.
To stress an overhead, we maintained 300 connections when measuring Figure 5(b). As expected, OpenFlow message count was linearly increased in accordance with the growing number of switches
while S TATE M ON maintains a constant number of message exchanges no matter how many switches exist in the network.
To discover overall overhead of S TATE M ON including network
latency, we first measured the time for establishing a connection
using a TCP handshake with and without S TATE M ON. As defined in Table 3, S TATE M ON exchanges 4 messages to monitor a
TCP handshake. While a TCP handshake took 3.356ms on average without S TATE M ON, it took 3.651ms on average with S TATE M ON. This means S TATE M ON only introduced a 0.295ms delay,
which is 8.79% overhead for a TCP handshake. To evaluate the
overall performance degradation caused by S TATE M ON, we used
the throughput between hosts as another metric. We used Iperf [2]
for this experiment. Iperf client (host in network A) initiated a new
connection with Iperf server (host in network B) and exchanged a
set of packets to measure the throughput. In an Open vSwitch and
Floodlight setting without S TATE M ON, the throughput scored an
average of 10.74 Gbits/sec (100 runs). With S TATE M ON enabled,
the throughput scored 10.40 Gbits/sec on average, with only 3.27%
throughput degradation.

5.2.2 Stateful Network Firewall
We configured the number of firewall policies to be 1k and fixed
the size of global state entries with 10k to measure the overhead of
our stateful firewall.
For performing state-aware firewall policy enforcement, the firewall spent 1.02ms on average. When a host attempts to establish a
new connection, it took 0.83ms to complete the searches with existing firewall policies, and the attempt was immediately denied in
real-time (0.01ms). Whenever a global state entry is updated, the
firewall performed a pair-wise comparison of the update with existing state-based rules within 1.16ms, and it took 0.26ms to delete
the violating connection from the network. In case of firewall policy updates, the firewall finished its dependency checking mostly
within 0.5ms, and spent a similar time (0.31ms) for deleting the
conflicting connection from the network.
Preventing connection disruptions in the network is another key
feature in our firewall. To this end, the firewall computes the Affected Entry Set (AES), and generating AES took less than 0.35ms
on average. In addition to AES, the firewall computes updated flow
′
′
′
entries, namely σF′ or σR
, to further compute CE and CI , respec′
tively. By comparing the relation the old CE and the updated CE ,

0

20k

40k

60k
80k
Number of connections

100K

Figure 7: Scalability Analysis of Stateful Firewall
the firewall draw a conclusion of potential connection disruption iff
′
CE 6= CE
. All these tasks were completed in 0.49ms on average.
To detect/prevent unauthorized access into active connections,
the firewall manipulates the state management table as described in
Section 4.3. As shown in Table 5, the firewall proactively installs
necessary rules in the state management table. Once a connection
has successively been established between two end hosts, the firewall asks S TATE M ON to install an additional OpenConnection entry to monitor the terminating packet at its egress switch. Since the
firewall will be directly notified by S TATE M ON when a connection
termination attack is detected, the firewall only implements a logic
to drop the attack packet. The firewall drops this packet and recovers the connection’s state to its previous one, ESTABLISHED.
Duration time for handling this type of unauthorized access took
around 0.44ms in total.
We also checked the scalability of the stateful firewall application by measuring the duration time for completing three types of
strategies. We gradually increased the number of existing connections from 20k to 100k. As shown in Figure 7, state-aware policy
enforcement took almost constant time (≈ 1ms) no matter how
many connections exist in the network. The firewall spent more
time in preventing connection disruptions than that of unauthorized
access prevention due to the computation overhead incurred by Algorithm 1. However, overall duration time for both cases linearly
increased with respect to increasing number of connections and
took less than 3 milliseconds at 100k connections, which is manageable.

5.2.3 Other Application: Port Knocking
Even though we mainly focused on TCP connection in this paper,
a key design goal is that S TATE M ON can support different statebased protocols, such as port knocking. Port knocking is a method
to open a closed port by checking a unique knock sequence, a series
of connection attempts destined to different ports [26]. Thus, we
developed this application to demonstrate how other network access management schemes can be also implemented using S TATE M ON in SDNs.
For example, an application may want to allow a connection iff
a series of requests matches a specific port order of A, B, C, and
D. By modifying the state management table in S TATE M ON, the
application can receive state-changing packets by listening OFPT_
PACKET_IN messages. In other words, the initial state can transition to the first knock state (e.g., PORT_KNOCK1) when the packet
is destined to port A, waiting for the subsequent knocking sequence
(port B). Such a way, the application opens the closed port of a
server if the state becomes the OPEN state.

To evaluate the overhead incurred by S TATE M ON-based application, we re-implemented the port knocking that has been demonstrated in prior work [26], which performs the same functions but
locally maintains the state in the switch. We installed the state
transition rules for the port knocking in the switch. To complete
the knocking sequence, it took 104.96ms without S TATE M ON,
and S TATE M ON-based application spent 113.83ms in total (8.45%
overhead).

6.

RELATED WORK

As explained in Table 3, majority of existing solutions are focused on performing stateful inspection in the data plane [29, 30,
14, 36, 11, 6, 10, 37]. There is some debate as to whether this
design goes against the spirit of SDN’s control and data plane separation. In addition, none of these approaches give much attention on how to leverage the logically centralized controller for providing a global state visibility of the network to applications. In
contrast, the unique contribution of S TATE M ON comes from its
consolidated state checking mechanism enabled by OpenConnection protocol and the connection tracking module. Specifically,
S TATE M ON can provide global state-based connection information to SDN applications along with several APIs that allows them
to define application-specific states. Even though OpenNF [16] attempts to achieve a similar state sharing, it mainly collects a state of
middleboxes (e.g., firewall, proxy, and load-balancer), not generic
network states.
A number of verification tools [31, 21, 27, 25, 23, 24] for checking network invariants and policy correctness in SDNs have been
recently proposed. FortNOX [31] was proposed as a software extension to provide security constraint enforcement for OpenFlowbased controllers. However, the conflict detection algorithm provided by FortNOX is incapable of analyzing stateful security policies. FlowGuard [21] was recently introduced to facilitate not only
an accurate detection but also a flexible resolution of firewall policy violations in dynamic OpenFlow-based networks. However, the
design of FlowGuard fully relies on flow-based rules in the data
plane and is only capable of building a stateless firewall application for SDNs. Anteater [27] is indeed an offline system and cannot be applied for a real-time flow tracking. VeriFlow [25] and
NetPlumber [23] are able to check the compliance of network updates with specified invariants in real time. VeriFlow uses graph
search techniques to verify network-wide invariants and deals with
dynamic changes. NetPlumber utilizes Header Space Analysis [24]
in an incremental manner to ensure real-time response for checking
network policies through building a dependency graph. Nevertheless, none of those tools are capable of checking stateful network
properties in SDNs.

7.

DISCUSSIONS

The OpenFlow protocol is evolving continuously, and the latest
version (v1.5.0) has been recently released [8]. The newest version
of OpenFlow attempts to add TCP flags for the extended matching
criteria to address the problem of insufficient L4 header inspection
capability as we have discussed.
However, the newest version of OpenFlow could not answer critical questions related to the maintenance and manipulation of network connection states. Especially, it does not articulate how to
leverage TCP flags to monitor states in both the switch and controller. We expect that our design of OpenConnection in S TATE M ON could provide an inspirational solution for OpenFlow to build
and enable its future stateful inspection scheme.

While we took great efforts to realize state-aware applications
for SDNs, the deployment of S TATE M ON to real-world production
networks requires additional considerations in terms of network security. For example, defense mechanisms against DDoS attacks
discussed in [35] may need to be considered in S TATE M ON. In addition, the current design and implementation of S TATE M ON utilize OpenFlow-based controller and switch modules, hence it only
works in the context of an OpenFlow-based environment. However,
the main idea of S TATE M ON, which is to provide state tracking
framework for various network applications, can be also realized in
other network paradigms, such as Network Function Virtualization
(NFV) [5, 19] .

8. CONCLUSION
In this paper, we have articulated network access control issues
in SDNs and presented a state-aware connection tracking framework called S TATE M ON that facilitates the control and data planes
of SDN to enable stateful inspection schemes. In the control plane,
we have designed a novel connection tracking mechanism using
a global state table and a state management table to track active
connections. To enable a state-aware data plane, we have introduced a new OpenConnection protocol, which defines four message formats and a state-aware OpenConnection table. We have implemented S TATE M ON using Floodlight and Open vSwitch along
with two access management applications (i.e., a stateful network
firewall application and a port knocking application) for SDNs, to
demonstrate the flexibility of S TATE M ON. Our experimental results have demonstrated that S TATE M ON and two state-aware network access management applications showed manageable performance overhead to enable critical state-aware protection of SDNs.

Acknowledgments
This work was partially supported by grants from National Science
Foundation (NSF-IIS-1527421, NSF-CNS-1537924 and NSF-CNS1531127), Intel corporation and Center for Cybersecurity and Digital Forensics at Arizona State University.

9. REFERENCES
[1] Floodlight: Open SDN Controller.
http://www.projectfloodlight.org.
[2] Iperf. https://iperf.fr/.
[3] Mininet: An Instant Virtual Network on Your Laptop.
http://mininet.org.
[4] Public PCAP Files for download.
http://www.netresec.com/?page=PcapFiles.
[5] Service Function Chaining (SFC) Architecture.
https://tools.ietf.org/html/draft-ietf-sfc-architecture-02.
[6] Stateful Connection Tracking & Stateful NAT.
http://openvswitch.org/support/ovscon2014/17/
1030-conntrack_nat.pdf.
[7] The Internet Traffic Archive. http://ita.ee.lbl.gov/.
[8] OpenFlow Switch Specification Version 1.5.1 (Protocol
version 0x06), December, 2014.
https://www.opennetworking.org/images/stories/downloads/
sdn-resources/onf-specifications/openflow/
openflow-switch-v1.5.1.pdf.
[9] K. Benton, L. J. Camp, and C. Small. Openflow vulnerability
assessment (poster). In Proceedings of ACM SIGCOMM
workshop on Hot topics in software defined networking
(HotSDN’13), pages 151–152. ACM, 2013.
[10] G. Bianchi, M. Bonola, A. Capone, and C. Cascone.
Openstate: programming platform-independent stateful

[11]

[12]

[13]

[14]

[15]

[16]

[17]

[18]

[19]

[20]

[21]

[22]

[23]

openflow applications inside the switch. ACM SIGCOMM
Computer Communication Review, 44(2):44–51, 2014.
P. Bosshart, D. Daly, G. Gibb, M. Izzard, N. McKeown,
J. Rexford, C. Schlesinger, D. Talayco, A. Vahdat,
G. Varghese, et al. P4: Programming protocol-independent
packet processors. ACM SIGCOMM Computer
Communication Review, 44(3):87–95, 2014.
M. Casado, M. J. Freedman, J. Pettit, J. Luo, N. McKeown,
and S. Shenker. Ethane: Taking control of the enterprise. In
Proceedings of the ACM SIGCOMM 2007 conference. ACM,
2007.
M. Casado, T. Garfinkel, A. Akella, M. J. Freedman,
D. Boneh, N. McKeown, and S. Shenker. Sane: a protection
architecture for enterprise networks. In Proceedings of the
15th conference on USENIX Security Symposium. USENIX
Association, 2006.
S. Fayazbakhsh, V. Sekar, M. Yu, and J. Mogul. Flowtags:
Enforcing network-wide policies in the presence of dynamic
middlebox actions. In Proceedings of ACM SIGCOMM
Workshop on Hot Topics in Software Defined Networking
(HotSDN’13), August 2013.
S. K. Fayazbakhsh, L. Chiang, V. Sekar, M. Yu, and J. C.
Mogul. Enforcing network-wide policies in the presence of
dynamic middlebox actions using flowtags. In Proceedings
of the 11th USENIX Conference on Networked Systems
Design and Implementation, pages 533–546. USENIX
Association, 2014.
A. Gember-Jacobson, R. Viswanathan, C. Prakash,
R. Grandl, J. Khalid, S. Das, and A. Akella. Opennf:
Enabling innovation in network function control. In
Proceedings of the 2014 ACM Conference on SIGCOMM,
pages 163–174. ACM, 2014.
M. G. Gouda and A. X. Liu. A Model of Stateful Firewalls
and its Properties. In International Conference on
Dependable Systems and Networks (DSN), pages 128–137.
IEEE, 2005.
A. Greenberg, G. Hjalmtysson, D. A. Maltz, A. Myers,
J. Rexford, G. Xie, H. Yan, J. Zhan, and H. Zhang. A clean
slate 4d approach to network control and management. ACM
SIGCOMM Computer Communication Review, 35(5):41–54,
2005.
R. Guerzoni et al. Network functions virtualisation: an
introduction, benefits, enablers, challenges and call for
action, introductory white paper. In SDN and OpenFlow
World Congress, 2012.
D. Hartmeier and A. Systor. Design and Performance of the
OpenBSD Stateful Packet Filter (pf). In USENIX Annual
Technical Conference, FREENIX Track, pages 171–180,
2002.
H. Hu, W. Han, G.-J. Ahn, and Z. Zhao. Flowguard: building
robust firewalls for software-defined networks. In
Proceedings of ACM SIGCOMM Workshop on Hot Topics in
Software Defined Networking (HotSDN’14), pages 97–102.
ACM, 2014.
S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski,
A. Singh, S. Venkata, J. Wanderer, J. Zhou, M. Zhu, et al.
B4: Experience with a globally-deployed software defined
wan. In ACM SIGCOMM Computer Communication Review,
volume 43, pages 3–14. ACM, 2013.
P. Kazemian, M. Chang, H. Zeng, G. Varghese,
N. McKeown, and S. Whyte. Real time network policy
checking using header space analysis. In Proceedings of the

[24]

[25]

[26]
[27]

[28]

[29]

[30]

[31]

[32]

[33]

[34]
[35]

[36]

[37]

10th USENIX conference on Networked Systems Design and
Implementation, pages 99–112. USENIX Association, 2013.
P. Kazemian, G. Varghese, and N. McKeown. Header space
analysis: static checking for networks. In Proceedings of the
9th USENIX conference on Networked Systems Design and
Implementation. USENIX Association, 2012.
A. Khurshid, X. Zou, W. Zhou, M. Caesar, and P. B.
Godfrey. Veriflow: verifying network-wide invariants in real
time. In Proceedings of the 10th USENIX conference on
Networked Systems Design and Implementation, pages
15–28. USENIX Association, 2013.
M. Krzywinski. Port knocking from the inside out. SysAdmin
Magazine, 12(6):12–17, 2003.
H. Mai, A. Khurshid, R. Agarwal, M. Caesar, P. Godfrey, and
S. T. King. Debugging the data plane with anteater. In
Proceedings of the ACM SIGCOMM 2011 conference, pages
290–301, 2011.
N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar,
L. Peterson, J. Rexford, S. Shenker, and J. Turner. Openflow:
enabling innovation in campus networks. ACM SIGCOMM
Computer Communication Review, 38(2):69–74, 2008.
H. Mekky, F. Hao, S. Mukherjee, Z.-L. Zhang, and
T. Lakshman. Application-aware data plane processing in
sdn. In Proceedings of ACM SIGCOMM Workshop on Hot
Topics in Software Defined Networking (HotSDN’14), pages
13–18. ACM, 2014.
M. Moshref, A. Bhargava, A. Gupta, M. Yu, and
R. Govindan. Flow-level state transition as a new switch
primitive for sdn. In Proceedings of ACM SIGCOMM
Workshop on Hot Topics in Software Defined Networking
(HotSDN’14), pages 61–66. ACM, 2014.
P. Porras, S. Shin, V. Yegneswaran, M. Fong, M. Tyson, and
G. Gu. A security enforcement kernel for openflow networks.
In Proceedings of ACM SIGCOMM Workshop on Hot Topics
in Software Defined Networking (HotSDN’12), August 2012.
Z. Qian and Z. M. Mao. Off-path tcp sequence number
inference attack-how firewall middleboxes reduce security.
In Security and Privacy (SP), 2012 IEEE Symposium on,
pages 347–361. IEEE, 2012.
Z. Qian, Z. M. Mao, and Y. Xie. Collaborative tcp sequence
number inference attack: how to crack sequence number
under a second. In Proceedings of the 2012 ACM conference
on Computer and communications security, pages 593–604.
ACM, 2012.
C. Roeckl and C. M. Director. Stateful inspection firewalls.
Juniper Networks White Paper, 2004.
S. Shin, V. Yegneswaran, P. Porras, and G. Gu. Avant-guard:
scalable and vigilant switch flow management in
software-defined networks. In Proceedings of the 20th ACM
conference on Computer and communications security
(CCS’13), pages 413–424. ACM, 2013.
A. Wang, Y. Guo, F. Hao, T. Lakshman, and S. Chen. Umon:
Flexible and fine grained traffic monitoring in open vswitch.
In Proceedings of the 11th International Conference on
emerging Networking EXperiments and Technologies
(CoNEXT’15), December 2015.
S. Zhu, J. Bi, C. Sun, C. Wu, and H. Hu. Sdpa: Enhancing
stateful forwarding for software-defined networking. In
Proceedings of the 23rd IEEE International Conference on
Network Protocols (ICNP 2015), pages 10–13.

HoneyMix: Toward SDN-based Intelligent Honeynet
Wonkyu Han, Ziming Zhao, Adam Doupé, and Gail-Joon Ahn
Arizona State University
{whan7, zzhao30, doupe, gahn}@asu.edu

ABSTRACT

Kojoney [9], which also offers an SSH service, only needs
a slightly different detection method, since it returns the
timestamp when Kojoney was installed. Using such detection techniques, attackers can easily identify honeypots and
behave differently afterwards. Therefore, techniques that
prevent attackers from detecting the existence of emulated
system and services are imperative in building effective honeypots.
Honeynet [23, 30], which is a network of honeypots, inevitably poses the same problem of honeypots themselves.
Moreover, honeynets must control incoming and outgoing
data in the network and aggregate captured data from different honeypots. For example, the third generation (Gen-III)
honeynet [28, 13] employs a customized firewall called honeywall as the gateway of the network to realize better control on inbound/outbound traffic. Honeywall runs in layer-2
bridge mode to hide its existence and monitors all incoming
and outgoing traffic. It is also used to contain and limit the
large volume of outbound traffic generated by compromised
honeypots (e.g., when used in a DDoS attack). However,
Gen-III architecture cannot fully support today’s heterogeneous services in honeynet due to its coarse-grained data
control. For example, let us assume that honeypot A exposes XSS vulnerability while running a fake HTTP service,
and we want to deploy a new honeypot B that emulates
SQL injection vulnerability over HTTP. Since conventional
architecture only allows one service to interact with attackers at any given time, opportunity for collecting SQL injection attack (or XSS attack) is inevitably restricted. We can
also consider that the honeypot B emulates the HTTP service and XSS vulnerability in a different level of interaction.
Current architecture is still failing in combining both honeypots to attract as many attacks as possible. Existing data
control mechanisms in Gen-III architecture are not sufficient
to accommodate such cases.
To defeat honeypot fingerprinting techniques and to provide fine-grained data control for honeynet, we propose to
leverage the emerging software-defined networking (SDN)
architecture and techniques [24]. SDN provides a flexible
and programmable network environment along with enhanced
control of the network by separating the control plane from
the data plane. In SDN, a network administrator (or a program operating on their behalf) can centrally program data
control logic via specific APIs (i.e., OpenFlow [12]). Because
an SDN switch can dynamically control network traffic by
applying various actions, data control in honeynet can centrally be managed with the help of SDN.

Honeynet is a collection of honeypots that are set up to attract as many attackers as possible to learn about their patterns, tactics, and behaviors. However, existing honeypots
suffer from a variety of fingerprinting techniques, and the
current honeynet architecture does not fully utilize features
of residing honeypots due to its coarse-grained data control
mechanisms. To address these challenges, we propose an
SDN-based intelligent honeynet called HoneyMix. HoneyMix leverages the rich programmability of SDN to circumvent attackers’ detection mechanisms and enables finegrained data control for honeynet. To do this, HoneyMix
simultaneously establishes multiple connections with a set
of honeypots and selects the most desirable connection to
inspire attackers to remain connected. In this paper, we
present the HoneyMix architecture and a description of its
core components.

Keywords
Software-defined Networking; Network Function Virtualization; Honeynet; Honeypot

1.

INTRODUCTION

Honeypots [29], as a form of electronic baits, are built
to intentionally expose vulnerable resources to attackers so
as to encourage probing and exploiting. Because the key
objective of honeypots is to learn about attackers’ behaviors and capture new types of malware, honeypots do not
have to implement all functionalities of a production system. Consequently, honeypots usually emulate or simulate
certain systems and services to reduce the computational
and maintenance cost.
However, emulator-based honeypots, including operating
system and services, can be easily fingerprinted. For example, recent research efforts [1] revealed that an SSH honeypot called Kippo [7] always returns a hardcoded timestamp
when attackers access its system information using the simple Linux command uname -r. Another honeypot called
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

SDN-NFVSec’16, March 11, 2016, New Orleans, LA, USA.
c 2016 ACM. ISBN 978-1-4503-4078-6/16/03. . . $15.00

DOI: http://dx.doi.org/10.1145/2876019.2876022

1

1
2
3

class c o m m a n d _ u n a m e( H o n e y P o t C o m m a n d) :
def call ( self ) :
if len ( self . args ) and self . args [0]. strip () in
( ‘ -a ’ , ‘-- all ’) :
self . writeln ( ‘ Linux % s 2.6.26 -2 -686 #1 SMP
Wed Nov 4 20:45:37 UTC 2009 i686 GNU /
Linux ’ % self . honeypot . hostname )
else :
self . writeln ( ‘ Linux ’)
commands [ ‘/ bin / uname ’] = c o m m a n d _ u n a m e

4
5
6
7

Table 1: Overlapping services of honeypots.
Provided Service
Honeypot Level of Interaction
HTTP SSH FTP
Dionaea [3]
Low-Interaction
X
X
Valhala [11]
Low-Interaction
X
X
Glastopf [4]
Low-Interaction
X
HIHIT [25]
High-Interaction
X
Kojoney [9]
Low-Interaction
X
Kippo [7]
Low-Interaction
X
Honssh [5]
High-Interaction
X

Figure 1: Hardcoded Linux Version in Kippo Honeypot Source Code.
1
2
3
4

this timestamp in (ii) is a strong indicator of Kippo. Another SSH honeypot named Kojoney [9] uses a timestamp
generated at installation time as shown in Figure 2. Even
though the timestamp is not hardcoded, attackers can easily compare the timestamp with the time of attack to detect
Kojoney-based SSH honeypots.
In addition, Holz et al. [18] introduced other techniques
that help attackers detect honeypots by checking for suspicious environments. Because the majority of honeypots run
in virtualized environments, attackers can infer the presence
of honeypots by checking their environmental variables. For
example, user-mode Linux and physical device information
(video card or network interface card) are used to identify
virtual environments of honeypots.

def p r o c e s s _ u n a m e( self ) :
self . t r a n s p o r t. write ( FAKE_OS + ‘\ r \n ’)
...
FQDN = " f q d n _ p l a c e h o l d e r" # fake domain name
( i . e . , www . example . com )
F A K E _ K E R N E L _ V E R S I O N = "2.6.9 -5. ELsmp #1 SMP "
T I M E S T A M P = datetime . now () . strftime ("% b % d % H
:% M :% S % Z % Y ")
FAKE_OS =" Linux "+ FQDN +" "+ F A K E _ K E R N E L _ V E R S I O N
+" "+ T I M E S T A M P+" i386 GNU / Linux "

5
6
7

Figure 2: Timestamp Generation in Kojoney Honeypot Source Code.
To take advantage of SDN in building such a honeynet, we
propose an SDN-enabled intelligent honeynet called HoneyMix. HoneyMix keeps a map of all available services in
the network and generates data control rules in a centralized manner. To maximize the use of every honeypot, HoneyMix adopts group communication methods (multicast) to
distribute incoming traffic to a set of associated honeypots.
Then, HoneyMix selects the most desirable connection that
might induce attackers further behaviors, and it replies back
to attackers while associated honeypots collecting malicious
data. To do this, HoneyMix has five core components: (1)
Response Scrubber module, (2) Forwarding Decision Engine
(FDE), (3) Connection Selection Engine (CSE), (4) Behavior Learner module, and (5) SDN switch (es).
This paper is organized as follows. We discuss the limitations of existing honeynet architecture in Section 2. To
solve the problems, We present the design of HoneyMix
along with its core components in Section 3. In Section 4,
we discuss related work. Section 5 concludes this paper.

2.

2.2 Coarse-grained Data Control in Honeynet
A honeynet is a network of honeypots that is intended
to attract as many attackers as possible to collect data and
learn about the patterns, behaviors, and tactics of attackers [2, 28]. The third generation (Gen-III) honeynet [16, 23]
adopts a customized firewall called honeywall to realize two
important honeynet functionalities: data control and data
capture.
• Data control: honeywall runs in layer-2 bridge mode
to enable transparent monitoring of network traffic
without revealing its presence. More importantly, it
is used to contain the attacker’s actions against external networks. Of particular worry is Denial of Service
attacks, so honeywall limits the outbound connections
that are generated from compromised honeypots.
• Data capture: to capture malicious payloads and
behaviors, Gen-III honeynet integrates built-in logging
tools and IDS utilities such as iptables [27], snort [10],
and sebek [8].

PROBLEM STATEMENT

In this section we overview two limitations of existing honeynets: (1) most honeypots can be easily fingerprinted and
(2) Gen-III honeynets only provide coarse-grained data control.

However, the layer-2 bridge in Gen-III honeynet is not sufficient to dynamically convey data to honeypots where it can
properly be handled. A set of honeypots offering the same
fake services in the network (e.g., Kippo and Kojoney) need
to receive the same copy of relevant packets to maximize the
use of them while existing honeywall cannot support those
architecture. As shown in Table 1, there exist various honeypots that emulate the same service in terms of SSH and
HTTP (web) services. In particular, when we put a lowinteraction honeypot and a high-interaction honeypot together, which is categorized by different level of interaction,
in the network, determining the flow path of data for distribution becomes more complex. Because low-interaction
honeypots are usually effective in only the early stage of
attacks, in-depth data collection are mostly performed by
high-interaction honeypots.

2.1 Honeypot Detection Techniques
A wide range of fingerprinting techniques have been devised to detect the existence of honeypots. Some efforts [1,
22] focused on finding a group of invariants that indicates the
operating system (or the service) is emulated. For example,
Dean et al. [1] revealed that the Kippo honeypot [7], when
emulating a fake SSH service, always returns the same string
when attackers access its system information. As shown in
Figure 1, the default system information emulated in Kippo
is hard-coded so that it prints out in two ways: (i) Linux
(line 6); or (ii) Linux hhostnamei 2.6.26-2-686 #1 SMP Wed
Nov 4 20:45:37 UTC 2009 i686 GNU/Linux (line 4). Thus,
2

There are few efforts to address this issue such as Honeybrid [6]. To facilitate the use of both honeypots, Honeybrid
forwards initial attack traffic to low-interaction honeypot
and migrates the connection to a high-interaction honeypot
if needed. However, this approach does not fully utilize both
honeypots since it allows only one connection at a time, and
it would not work if the pair of honeypots consists of lowinteraction (or high-interaction) honeypots.
Moreover, Gen-III honeynet is only concerned about containing the outbound traffic, however an attack is also likely
to be dangerous to internal network. If a compromised honeypot attempts to infect another honeypot in the same network, honeywall cannot provide protection because malicious traffic is not destined to the external network.

HoneyMix-enabled Controller
Forwarding
Decision
Engine

Response
Scrubber

Connection
Selection
Engine

Honeypot A
(ssh)

Behavior
Learner

 con selection
 service mapping
Honeywall

 request
 reply

Attacker

Honeypot B
(ssh&http)

Honeypot C
(http)

SDN switch(es)

...

HONEYMIX ARCHITECTURE
In this Section we illustrate the five core components of
HoneyMix in detail. In particular, we focus on how HoneyMix achieves better data control than existing Gen-III
honeynet using Software-defined Networking (SDN).
3.

Figure 3: HoneyMix Architecture.
and checksums is necessary. Behavior Learner is responsible for computing weights, which CSE uses to
select the connection.

3.1 Overview of HoneyMix

• Behavior Learner computes a weight for each connection between SDN switch(es) and honeypots. This
weight acts as a score that indicates the activity of a
specific attacker’s connection. Based on the duration
time (δt) of the active connection and the frequency
of modification (#n) counted by Response Scrubber,
this module assigns a weight to each connection. The
longer the connection continues and the fewer modifications are made, the higher the connection weight
has.

HoneyMix is based on traditional Gen-III architecture
that includes a honeywall for controlling network traffic and
capturing malicious data. Behind the honeywall, we construct an SDN-enabled network to accomplish fine-grained
data control. By doing this, we not only take advantage of
Gen-III architecture but also enhance security of honeynet
with the help of SDN.
HoneyMix architecture consists of five components:
• Response Scrubber takes known fingerprinting techniques into account to reduce the possibility of exposure by scrubbing the response. Recall the example in
Section 2.1, network operators manually define existing detection mechanisms with their countermeasures
to perform sanitization. Response Scrubber first inspects attackers’ requests and selectively scrubs corresponding response that reveals the existence of honeypots.

• SDN switch(es) connects with HoneyMix-enabled controller to receive an instruction for steering data flow
and modifying network traffic in flight. SDN switch
can dynamically quarantine a compromised honeypot
and establish a new data stream for the newly instantiated honeypot using Network Function Virtualization
(NFV [17, 32]). The switch is mainly controlled by
FDE.

• Forwarding Decision Engine (FDE) creates a “service
map” that represents the services offered by the honeynet (heterogeneity) and overlapping services (redundancy) across honeypots. Based on the service map,
FDE centrally determines where network traffic should
be forwarded and pings each service running on every honeypot to ensure consistent and up-to-date honeynet status. To maximize the use of the honeypots,
FDE leverages SDN switches to forward malicious requests to all associated honeypots. To contain the malicious traffic and deliver seamless service, FDE quarantines the compromised honeypot and instantiates an
identical honeypot using Network Function Virtualization (NFV) technique.

To illustrate how HoneyMix works, we walk through a
use case as shown in Figure 3. When an attacker initiates a
connection, HoneyMix inspects the IP addresses and port
numbers to decide which services are associated with the
connection. If the connection attempt is destined to an SSH
service (default port: 22), FDE searches valid honeypots in
the network using the service map and installs forwarding
rules into corresponding SDN switches. At the same time,
CSE establishes a connection with an attacker on behalf
of honeypots. Upon a successful handshake, CSE creates
multiple connections with relevant honeypots. HoneyMix
performs selective traffic distribution using group communication (multicast). The conveyed request will trigger honeypots to generate multiple responses. Behavior Learner returns the weight of each connection so that CSE will choose
one of them and pipeline it to the connection which is established by FDE. If Response Scrubber detects the attempt of
fingerprinting, it sanitizes the response to make sure there
exists no clear evidence that indicates the system (or the
service) is emulated.
HoneyMix architecture has several strengths in data control when compared to the traditional Gen-III architecture.
First, every honeypot that offers the same service can receive

• Connection Selection Engine (CSE) establishes an
end-to-end connection between an attacker and a honeypot. HoneyMix maintains one connection between
an attacker and SDN switch and a number of connections between SDN switch (es) and honeypots. CSE
selects one of the connections from the latter area and
pipes it to the connection of the former area. Because HoneyMix basically breaks end-to-end connection, rewriting several header fields such as SEQ/ACK
3

honeypot1: service1, service3
Host
A

honeypot2: service2, service4
honeypot3: service1, service4, service7

Host
B

honeypot4: service2, service3
honeypot5: service5, service6, service7

Host
C

honeypot8: service1, service2, service7
honeypot9: service3

honeypot6: service3, service5
honeypot7: service1

Figure 4: Heterogeneous and Redundant Service Distribution in Honeynet.
malicious traffic by means of multicast while only one honeypot can be accessed at any given time in the traditional
honeynet. This help us maximize the use of multiple honeypots in the network. Second, it dynamically selects the
connection to send back with the most desirable response.
This response, of course, is immune to known fingerprinting
techniques when it is delivered to attackers (thanks to Response Scrubber). Third, SDN-enabled network can realize
flexible incident response by isolating a compromised honeypot. With the combination of NFV and SDN, HoneyMix
also activates a new honeypot and dynamically enable data
communication to deliver seamless service. In addition to
that, network reconfiguration techniques such as Moving
Target Defense (MTD [20]) are also possible in HoneyMix
architecture. Section 4.3 discusses this issue in detail.

• SM is the ‘service map’ constructed in an (m × n)
~hp1 ,
matrix form in which each row corresponds to S
~hpm .
~hp2 , · · · , and S
S
~ h and SM , we first compute service distribution
With H
k
−→
SD hk on a host hk such that 1 ≤ k ≤ l.
−→
~ h · SM
SD hk = H
k

(1)

−→
SD hk is an n-dimensional vector that shows heterogeneity
and redundancy of services on hk . For example, the list of
~ h = (1, 1, 1, 0, 0, 0, 0, 0, 0).
honeypots on Host A in Figure 4 is H
A
SM would be as below:

1 0
0 1
1 0

0 1

SM = 0 0
0 0

1 0


1
0
0
1
0
1
0
1 1 0
0 0 1

3.2 Centralized Data Control
3.2.1 Network Rule Computation
Hosting honeypots in honeynet requires significant manual configuration (e.g., adding ACL and routing rules). In
particular, honeypots co-existing on the same host may offer
a set of redundant services. As shown in Figure 4, we consider a honeynet that consists of three hosts, running nine
honeypots with seven vulnerable services1 in total. Each
honeypot may emulate multiple services (heterogeneity). In
addition, several services are necessarily redundant (redundancy) because the number of services is less than the number of honeypots. For example, honeypot1 provides two services (service1 , service3 ) and service1 is provided by two
honeypots (honeypot1 , honeypot3 ) on Host A.
Due to the heterogeneity and redundancy of provided services, generating network rules needs to consider the relations among host, honeypot, and service. We formalize this
problem using aforementioned elements as follows:

0
1
1
0
0
0
0
0
0

0
0
0
0
1
1
0
0
0

0
0
0
0
1
0
0
0
0

0
0
1

0

1
0

0

1
0



−→
~ h · SM = (2, 1, 1, 2, 0, 0, 1) refers to
Therefore, SD hA = H
A
the distribution of redundant services
on
−−−
→Host A. We next
compute entire service distribution (SDH) in honeynet via
−→
−→
−→
the addition of SDh1 , SD h2 , · · · , and SD hl .
l

−−−→ X −→
SDH =
SD hk

(2)

k=1

Therefore, entire service distribution in honeynet (Figure 4)
−−−→
−−−→
is SDH = (4, 3, 4, 2, 2, 1, 3). Note that SDH can also be
computed by a sum of row vectors of SM .
Based on above observations, Forwarding Decision Engine
−−−→
(FDE) translates the entire service distribution (SDH) into
corresponding network rules. FDE generates network rules
for each service and assigns different port numbers to differentiate redundant services on the same host if necessary.

• HN = {h1 , h2 , · · · , hl } is a set of hosts in the honeynet;
• HP = {hp1 , hp2 , · · · , hpm } is a set of honeypots in the
honeynet;
• SV C = {svc1 , svc2 , · · · , svcn } is a set of provided services in the honeynet;
~ h = hrh1 , rh2 , · · · , rhm i is an m-dimensional vector
• H
l
that corresponds to running honeypots on a specific
host hl . rhm equals to ‘1’ when hpm is installed on
host hl , otherwise ‘0’;
~hpm = has1 , as2 , · · · , asn i is an n-dimensional vector
• S
that represents active services on a particular honeypot hpm . asn equals to ‘1’ when svcn is active on
honeypot hpm , otherwise ‘0’;

3.2.2 Incident Response
For the best use of the centralized architecture of HoneyMix, we detect abnormalities in honeypots and reactively
cope with incidents. HoneyMix takes advantage of Gen-III
architecture that only limits a large volume of outbound
traffic (rate limiting). In addition to this, we dynamically
re-configure network rules to quarantine a compromised honeypot by leveraging the programmability of SDN. Based on
the logs collected from honeywall, FDE in HoneyMix removes existing network rules associated with the compromised honeypot and installs a new rule to block outbound
traffic from it. However, existing services provided by the
compromised honeypot would remain damaged until we fin-

1

Here, a service roughly means any type of program which
is occupying a specific network port to provide a communication channel.
4

ish the investigation (e.g., forensic) and recover the honeypot.
To remedy this limitation, HoneyMix embraces network
function virtualization (NFV) technique. Some efforts [26,
13] to build existing honeypots into a set of virtual instances
would also help us realize this approach. HoneyMix periodically snapshots each honeypot, and dynamically activates it
when an infected honeypot is detected. In such a way, HoneyMix ensures that every service in the network is always
up and running.

the modification ratio which is the number of unsanitized
response (#N − #n) divided by the number of successful
responses (#N ), where #n is the number of modifications
performed by Response Scrubber. Based on these two criteria, the weight of a connection a (Wa ) is computed as below:

3.3 Dynamic Connection Selection

4. RELATED WORK AND DISCUSSION

Wa = ts · δta ·

#N − #n
#N

(3)

We add a threshold (ts ) to prioritize a connection for the
quality of service.

To realize the architecture of HoneyMix, the importance
of connection selection in SDN switch(es)–honeypots area
cannot be stressed enough. However there exist many kinds
of obstacles in enabling this. First, dynamically hopping one
connection to another essentially breaks end-to-end connection between an attacker and a particular service. Modification of several packet headers, especially in the TCP
protocol, must be considered (e.g., rewriting of SEQ/ACK
numbers). Moreover, this may bring new chances for attackers to fingerprint the existence of NAT functions by checking
RTT delays. Second, selecting the most desirable connection
that could encourage attackers to launch subsequent attacks
is not trivial. Because there exists no clue to judge about
the suitability of connections, we need to develop a set of criteria to evaluate them in a reasonable way. Third, choosing
the right time for connection selection is also challenging.
For example, we do not want to transfer the connection in
the middle of transmitting a big file.
To accommodate the aforementioned challenges, we devise Connection Selection Engine (CSE) as a core building
block for connection selection. To enable seamless connection between an attacker and an emulated service in honeypot, CSE leverages existing SDN features that allows us to
perform network address translation (NAT). For data transmission over TCP protocol, HoneyMix maintains the state
tracking table in CSE that keeps track of sequence (SEQ)
and acknowledgement (ACK) numbers of connections. In
this table, CSE also inserts additional information for the
higher layers in the OSI reference model to handle a lot of
nonce which are dynamically generated by a specific service.
For example, HTTP service independently keeps cookie, referer, and authorization information to maintain the state of
users. Moreover, CSE records a set of key-pairs that are
used for encrypting/decrypting messages for SSH/HTTPS
service. Some additional header fields such as TCP checksum field are dynamically updated by CSE.
As discussed in Section 2.1, HoneyMix might circumvent
existing fingerprinting techniques just by hopping one connection to another. To achieve this, selecting the most realistic and desirable connection from multiple connections is
critical in building HoneyMix. Note that Response Scrubber module is also provisioning partial remedy for this in an
ad-hoc manner by fixing apparent indicators, but we want
to even avoid unknown fingerprinting techniques by dynamically hopping connections.
Behavior Learner module in HoneyMix determines the
weight of each connection based on two criteria: (1) the
duration time (δt) of a connection and (2) the number of
modifications (#n) made by Response Scrubber. To account
for attackers’ duration of session, the module measures continuing time of an active connection (δta ). It next obtains

4.1 Software-defined Networking (SDN)
SDN is an emerging network paradigm that separates the
control plane from the data plane [24]. Legacy network devices embed complex control logics to process network traffic
whereas SDN switches only perform simple “match-action”
based processing. By simplifying the data plane, SDN abstracts the control plane and consolidates those control logic
into a centralized controller. Because SDN enables logically
centralized network environment, SDN supports significant
programmability and flexibility that could help improve the
security of honeynet.
As the prevalent and widely adopted SDN protocol, OpenFlow [12] realizes such an SDN paradigm. To dynamically
program network traffic, the OpenFlow protocol supports
“Set-Field” operation in the data plane that allows us to
rewrite packet headers. Therefore, OpenFlow-enabled network implements network address translation (NAT) feature without employing additional network box. HoneyMix
makes the best use of OpenFlow-enabled network for realizing connection selection, which helps build more flexible
and robust honeynet.

4.2 Honeynet Architecture
The first generation (Gen-I) of honeynet, which was devised in 1999 [28], employs a firewall that mainly performs
data control at OSI layer-3. Although Gen-I architecture
successfully proved its ability in collecting attacks, it can be
easily detected by attackers. It could not properly handle
outgoing traffic either. The cornerstone of the second generation (Gen-II) and the third generation (Gen-III) honeynets
is a layer-2 based firewall called honeywall. Honeywall has
been devised to enable transparent network monitoring by
provisioning layer-2 bridging, which is difficult for attackers
to detect. Gen-II and Gen-III have the same architecture
except several additional functionalities [13]. Having Gen-II
components as the basis, Gen-III utilizes honeypot monitoring tools (e.g., sebek [8]) to check abnormalities and implements easier deployment of the honeywall. As cloud infrastructure is widely adopted in today’s networks, deploying
Gen-III honeynet in a virtual environment becomes more
popular since it brings many benefits (e.g., maintenance)
that deployment in a physical machine cannot provide [26].

4.3 Discussion
HoneyMix uses some ideas that have been presented in
moving target defense (MTD) [15, 31]. To increase uncertainty, MTD adopts several randomization techniques to reconfigure a set of properties of operating systems or network
interfaces [14]. Jafarian et al. [20] proposed to use the SDN
controller to randomize host information (i.e., MAC and IP
5

addresses) in order not to allow attackers to obtain the real
host information. Panos et al. [21] also proposed other randomization mechanisms to hide service version and OSes by
utilizing an SDN application to generate traffic that resembles a fake service or OS.
To prevent honeypot fingerprinting HoneyMix currently
adopts a connection selection engine that transfers from one
connection to another. This scheme helps increase anonymity
of existing honeypots by changing active connections. Moreover, Response Scrubber is designed to sanitize specific payloads that reveal information of honeypots. HoneyMix
could adopt aforementioned MTD techniques to further minimize the possibility of exposing network infrastructure (OS,
service, and host). For example, random host mutation
techniques introduced in MTD can also be considered in
HoneyMix-enabled controller to hide honeypots. In addition, we may consider to generate virtual IP and MAC
addresses to dynamically create corresponding DNS information to hide our network configurations.

5.

[14]

[15]
[16]

[17]

[18]

[19]

CONCLUSION

[20]

In this paper, we introduced HoneyMix architecture along
with its five components to build SDN-enabled intelligent
honeynet. To defeat existing honeypot fingerprinting techniques, HoneyMix dynamically selects the most desirable
connection among multiple connections and reactively sanitizes the response if it contains a known indicator of honeypots. To fix coarse-grained data control in traditional
Gen-III honeynet architecture, HoneyMix centrally computes service distribution in the network to enable finegrained data control and deploys corresponding rules via
SDN switches. Moreover, HoneyMix conducts a security
incident response including quarantine and recovery using
SDN and NFV. We are currently implementing HoneyMix
and planning to evaluate the architecture in real-world deployments.

[21]

[22]
[23]

[24]

Acknowledgments
[25]

This work was partially supported by the grants from Center
for Cybersecurity and Digital Forensics at ASU.

6.

[26]

REFERENCES

[1] Black Hat USA 2015 - Breaking Honeypots For Fun And Profit.
https://www.youtube.com/watch?v=Pjvr25lMKSY.
[2] Blogs|The Honeynet Project. https://www.honeynet.org/.
[3] Dionaea - carnivore. https://github.com/rep/dionaea.
[4] Glastopf Honeypot Project Page. http://glastopf.org/.
[5] Honssh Honeypot. https://github.com/tnich/honssh.
[6] Hybrid Honeypot Framework.
http://honeybrid.sourceforge.net/.
[7] Kippo SSH Honeypot. https://github.com/desaster/kippo.
[8] Know Your Enemy: Sebek (A kernel based data capture tool).
http://old.honeynet.org/papers/sebek.pdf.
[9] Kojoney2 SSH Honeypot.
https://github.com/madirish/kojoney2.
[10] Snort.Org. https://www.snort.org/.
[11] Valhalahoneypot Honeypot.
http://sourceforge.net/projects/valhalahoneypot/.
[12] OpenFlow Switch Specification Version 1.5.1 (Protocol version
0x06), December, 2014. https://www.opennetworking.org/
images/stories/downloads/sdn-resources/onf-specifications/
openflow/openflow-switch-v1.5.1.pdf.
[13] F. H. Abbasi and R. Harris. Experiences with a generation iii
virtual honeynet. In Telecommunication Networks and

[27]
[28]
[29]

[30]

[31]

[32]

6

Applications Conference (ATNAC), 2009 Australasian, pages
1–6. IEEE, 2009.
E. Al-Shaer. Toward network configuration randomization for
moving target defense. In Moving Target Defense, pages
153–159. Springer, 2011.
M. Carvalho and R. Ford. Moving-target defenses for computer
networks. IEEE Security & Privacy, (2):73–76, 2014.
M. Dornseif, F. C. Freiling, N. Gedicke, and T. Holz. Design
and implementation of the honey-dvd. In Information
Assurance Workshop, 2006 IEEE, pages 231–238. IEEE, 2006.
R. Guerzoni et al. Network functions virtualisation: an
introduction, benefits, enablers, challenges and call for action,
introductory white paper. In SDN and OpenFlow World
Congress, 2012.
T. Holz and F. Raynal. Detecting honeypots and other
suspicious environments. In Information Assurance Workshop,
2005. IAW’05. Proceedings from the Sixth Annual IEEE
SMC, pages 29–36. IEEE, 2005.
J. H. Jafarian, E. Al-Shaer, and Q. Duan. Openflow random
host mutation: transparent moving target defense using
software defined networking. In Proceedings of the first
workshop on Hot topics in software defined networks, pages
127–132. ACM, 2012.
J. H. Jafarian, E. Al-Shaer, and Q. Duan. Openflow random
host mutation: transparent moving target defense using
software defined networking. In Proceedings of ACM
SIGCOMM Workshop on Hot Topics in Software Defined
Networking (HotSDN’12), pages 127–132. ACM, 2012.
P. Kampanakis, H. Perros, and T. Beyene. Sdn-based solutions
for moving target defense network protection. In A World of
Wireless, Mobile and Multimedia Networks (WoWMoM),
2014 IEEE 15th International Symposium on, pages 1–6.
IEEE, 2014.
N. Krawetz. Anti-honeypot technology. Security & Privacy,
IEEE, 2(1):76–79, 2004.
J. Levine, R. LaBella, H. Owen, D. Contis, and B. Culver. The
use of honeynets to detect exploited systems across large
enterprise networks. In Information Assurance Workshop,
2003. IEEE Systems, Man and Cybernetics Society, pages
92–99. IEEE, 2003.
N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar,
L. Peterson, J. Rexford, S. Shenker, and J. Turner. Openflow:
enabling innovation in campus networks. ACM SIGCOMM
Computer Communication Review, 38(2):69–74, 2008.
M. Mueter, F. Freiling, T. Holz, and J. Matthews. A generic
toolkit for converting web applications into high-interaction
honeypots. University of Mannheim, 280, 2008.
N. Provos et al. A virtual honeypot framework. In USENIX
Security Symposium, volume 173, 2004.
M. Rash. Linux Firewalls: Attack Detection and Response
with iptables, psad, and fwsnort. No Starch Press, 2007.
L. Spitzner. The honeynet project: Trapping the hackers. IEEE
Security & Privacy, (2):15–23, 2003.
L. Spitzner. Honeypots: Catching the insider threat. In
Computer Security Applications Conference, 2003.
Proceedings. 19th Annual, pages 170–179. IEEE, 2003.
D. Watson and J. Riden. The honeynet project: Data collection
tools, infrastructure, archives and analysis. In WOMBAT
Workshop on Information Security Threats Data Collection
and Sharing, pages 24–30. IEEE, 2008.
R. Zhuang, S. A. DeLoach, and X. Ou. Towards a theory of
moving target defense. In Proceedings of the First ACM
Workshop on Moving Target Defense, pages 31–40. ACM,
2014.
M. Zimmerman, D. Allan, M. Cohn, N. Damouny, C. Kolias,
J. Maguire, S. Manning, D. McDysan, E. Roch, and
M. Shirazipour. Openflow-enabled sdn and network functions
virtualization. Solution Brief, ONF, Solution Brief
sbsdn-nvf-solution. pdf, 2014.

Write-Optimized Consistency Verification in Cloud Storage with Minimal Trust
Yuzhe Tang

Ju Chen

Dept. of EECS, Syracuse University, Syracuse, NY, USA
Email: {ytang100, jchen133@}syr.edu

Abstract—Today, data outsourcing to the clouds is a popular
computing paradigm, and enabling efficient and trustworthy
outsourcing becomes critically important as many emerging
cloud applications are increasingly security-sensitive, such as
healthcare, finance, etc. One of the promising techniques is
authentication data structure (ADS). Most existing ADSs are
not log-structured, yet cloud storage systems that work beneath
the ADSs are log-structured – this structural mismatch leads to
significant performance overhead.
We propose log-structured ADSs for lightweight verification in
cloud outsourcing. Our approach is leveraging recently available
commercial TEE (trusted execution environment, such as Intel
SGX). For security, only two functionalities are placed inside a
TEE, that is, frontend consistency checking and backend maintenance computations, yielding a small TCB (trusted codebase). For
performance efficiency, the ADS layer follows the log-structured
design, resulting in small overhead. We implemented a working
log-structured ADS system on LevelDB, and demonstrated a
small TCB and small performance overhead (6 ∼ 12% in IOintensive workloads) through extensive performance studies.

I. I NTRODUCTION
Today, outsourcing data storage to the public cloud becomes
a popular computing paradigm, due to cost-effectiveness,
efficiency, availability/accessibility, etc. This is evidenced by
various cloud-storage services on the market [9], [1], [4], [3].
In the presence of potentially malicious clouds (e.g. driven
by profit or compromised by external hackers), the trust to
the cloud providers becomes crucial to the client’s decisionmaking on cloud adoption. Ideally, cloud clients want the data
outsourcing to be:
1) trustworthy in that all interactions to the outsourced cloud
storage come with assurance (from some authority) that the
cloud behaves honestly. Any operation properties that might be
exploited must be verified in their correctness, such as queryresult integrity, freshness, etc.
2) practically efficient in that the cloud’s efficiency in
processing a large volume of data is the main incentive for
outsourcing and should not be sacrificed by the extra work to
enforce security.
One of the most promising techniques to achieve these goals
is the authenticated data structure (ADS), a cryptographic protocol that enables the verifiability essentially by computation
hardness (e.g. hash collision resistance), yet is relatively efficient (in an asymptotic sense). Despite the extensive researches
in this domain (e.g. tree-based ADS [77], [48], [60], [61], [90],
[32], [57], [46], [59], [87], [88], signature-based ADS [52],
[54], [53], [56], [30], [58]), existing ADS techniques fall
short on close systems integration and enabling systems-level
efficiency. This is especially the case when existing ADSs
are update-in-place structures while the underlying storage

systems follow a different philosophy – log-structured design
with append-only updates (e.g. log-structured merge trees or
LSM trees [55] used in various cloud storage systems [29],
[8], [6]). When placing the update-in-place ADS over the logstructured storage substrates, the structural mismatch causes
severe performance problems, such as slow-down by orders
of magnitude (presented in § VI-B). Briefly, the cause of the
slowdown is that the update-in-place ADS shifts the workload
to be more read intensive (by adding reads to the write path),
making the underlying log-structured storage less effective.
The lack of log-structured ADS is not by accident: The
difficulty comes from supporting verifiable maintenance with
practical performance. Deferred maintenance is observed by
log-structured systems, and typically requires a linear or
superlinear computation with the input of a large amount
of the stored dataset (e.g. merging datasets in the case of
an LSM tree). With a fully untrusted cloud, verifying the
maintenance correctness efficiently and securely requires the
client running a sublinear checking algorithm. And this is
where existing theory-oriented approaches (e.g. proof-based
verifiable computations [21], [62], [69], [28], [83], homomorphic digests/signatures [15], [27]) do not (yet) provide
a practically efficient solution (e.g. with constant-sized data
transfer between the cloud and client).1
We resort to systems-oriented solutions and relax the untrusted cloud model by considering a small trusted entity at the
cloud side. The presence of a trusted entity in close proximity
to the cloud is necessary, as it makes possible not only
verifiable maintenance on the backend, but also the immediate
verification of strong consistency on the frontend (detailed
in § II-B). The cloud-side trust is make practically possible
by the recent support of trusted execution environment (TEE)
in commercial hardware, such as Intel Safe Guard Extension
(SGX [11]). SGX allows a client to set up a security-isolated
“world”, called enclave, in the otherwise untrusted cloud; the
client only trusts the CPU and trusted codebase (TCB) in the
enclave.
We propose a protocol, called LPAD, for outsourcing
log-structured storage with lightweight verification of data
freshness. We model an LSM tree by multiple ordered lists
supporting two operations, data reads/writes on the frontend
and maintenance on the backend. The ordered lists are digested
by a forest of Merkle trees [51], and data reads/writes are made
verifiable by Merkle proofs. The maintenance is trustworthy
1 In theory, the problem of efficient verifiable maintenance can be solved
by a “merge”-homomorphic digest. For standard Merkle tree, such homomorphism is impossible [78], and for other digest structures, we believe the merge
homomorphism is a theoretically open problem [78].

due to in-enclave execution. Our system architecture is designed with the goal of minimal user-space TCB and proven
security; we demonstrate (in § VI-A) our system design has a
TCB smaller than alternative state-of-the-art designs [25] by
two orders of magnitude.
We build a working system materializing the LPAD design,
on a real LSM storage system (Google’s LevelDB [7]) and
with Intel SGX CPU. At the systems level, the verifiable
freshness is naturally extended to enable verifiable read/write consistency under concurrent execution. To strongly
consistent stores, such as LevelDB, we build a checker to
verify the linearizability [39] in real-time. The consistency
checker has lightweight overhead as its implementation has
few synchronization points and is tailored to LevelDB’s singlewriter-multi-reader concurrency model. We explore the “codepartitioning” problem – data maintenance code is systemservice intensive (due to the needs of data persistence) while
SGX prohibits system services in its enclave [11]. We tackle
the problem by “partitioning” the maintenance code-path at
a place close to system calls while avoiding excessive world
switches at runtime. This partitioning strategy improves performance efficiency by up to 6 times in our evaluation.
The contributions of this work consist of the following:
1) We identify the structural gap between existing updatein-place ADS protocols and log-structured storage systems
underneath. This gap results in severe performance slow-down.
2) To bridge the gap, we propose LPAD, a formal protocol
for log-structured ADS. We formally present a construction
of LPAD using Merkle trees and hardware TEE features
(trusted execution environments). We analyze the security
and correctness of protocol construction. To the best of our
knowledge, this is the first time to make Merkle tree scheme
write-optimized by following an LSM design.
3) We build a working system of LPAD based on Intel SGX
and atop LevelDB. We partition the codebase to minimize
world-switches and runtime overhead. We build a lightweight
consistency checker with minimal synchronization points. The
built prototype system demonstrates a smaller user-space
TCB2 (by two orders of magnitude) than state-of-the-art SGX
systems.
4) We conduct extensive performance evaluation and characterize the overhead of LPAD protocol and the consistency
checker: In a disk IO intensive workload, the overhead is
small and practically acceptable (6% ∼ 12% slowdown to
an ideal non-secure system), which is significantly smaller
than that of existing ADS implementation (24X slowdown).
This is the first time to demonstrate the immediate consistency
verification with practical overhead.

A. Why Combine ADS with LSM Trees
Preliminary: Merkle hash tree [51]: is a method of
collectively authenticating a list of objects (that is, a set of
objects with fixed ordering). We denote it by MHT. In an
MHT, each leaf node is the hash of an object (or a key-value
record), and an intermediate tree node is the hash digest of
the concatenation of its direct children’s hash digests. The root
node digests the entire list and can further be signed. We call
the root hash by Merkle hash. The authenticity of an object
and its position in the tree can be verified by the digests of
the siblings of the nodes that lie in the path from the root to
the object’s leaf node, a.k.a. the authentication path or Merkle
proof.
Preliminary: ADSs: An ADS or authenticated data structure [77], [48], [60], [61], [90], [32], [57], [46], [59], [87],
[88] is a protocol that formally describes interactions between
a trusted verifier and untrusted prover. The goal of an ADS is
to make certain properties (e.g. consistency) of the interaction
verifiable to the verifier. A specific ADS can be characterized
by the type of interactions supported. For instance, a hashchain is an ADS that supports reads and writes only on the tail
of the chain. A PAD or persistent authenticated dictionary [18],
[37], using MHT, supports random access, that is, reads and
writes at an arbitrary position of the dataset. Other ADSs
support more complicated queries than point reads. In this
work, we might use ADS to refer to PAD.
Update-in-place ADSs: All existing ADSs (PADs) [73],
[36], [65] perform updates in place. That is, between a prover
and a verifier, an ADS, say a remote MHT, updates itself
by the verifier requesting a Merkle proof from the prover,
modifying the proof and updating the MHT with a new root
hash sent to the prover – In essence, this process updates
the MHT “in-place.” There are variants of ADSs, such as
replicated ADS [46], [48], [51], [90] and cached ADS [33];
they replicate a certain part of the ADS on the verifier for
better update performance. These optimizations do not change
the nature of in-place updates. In addition, the update-in-place
ADSs have been used in building verifiable systems, such as
SUNDR [47] and MBTree [46] where a single MHT is used
to digest the outsourced dataset and is updated in place. It
is noteworthy that the client-synchronization based systems,
including CloudProof [66], CONIKS [50], Caelus [43], etc.,
digest recent (after the last synchronization) updates by a
log of hash-chain favoring write performance. However, the
hash-chain is temporary and can not be used for immediate
verification. Their permanent digest is still a single MHT
updated in place.
The design of read-optimized ADS is fundamentally different from various write-optimized storage systems adopted well
in the cloud: While read-optimized design features a single
list updated in place, the write-optimized structure features
append-only updates and multi-list data storage. This structural
mismatch could result in severe performance slowdown when
putting them into a single system (for verifiable storage). Our
performance study demonstrates that the slowdown can be up
to several orders of magnitude.

II. M OTIVATIONS
In this section, we present further details of the motivations
for this work.
2 We stress our software design minimizes the user-space TCB. Note the
use of SGX keeps OS kernel codebase out of TCB, but does not necessarily
mean a small TCB overall; an counterexample is Haven [25] which results
in a large user-space TCB.

2

Initial performance observation: Our initial performance
study (for motivation purposes) is designed to understand how
much the storage IO is skewed by the presence of ADS? In
write-only workloads, the storage IO would be skewed by the
update-in-place ADS to include 50% reads and 50% writes
(essentially every application-level write is translated into a
read-modify-write sequence). In our study, we drive a writeonly workload and half-read-half-write workload (representing
the read-modify-write workload by existing ADSs) into an
LSM store, LevelDB [7] from Google. Under certain experimental settings, the measured latency difference between the
two workloads can be up to several orders of magnitude,
for instance, 4.564 micro-second per operation for the writeonly workload versus 604.302 for the half-read-half-write
workload. More detailed and extensive studies are presented
in § VI-B.

difficult as the repository grows large, which is the target
application for our system.
There are many other use cases such as serving web app to
ad-hoc mobile social users [41]. In general, our proposed systems achieve two features desirable to these new applications:
1) write-intensive workloads (e.g. social users constantly post
new updates, and developers constantly push new commits),
2) strong consistency verification (e.g. needed to prevent
duplicated effort attack instead of just detecting them).
The remainder of this paper is organized in the following
way: We present a formal model of an LSM tree (§ III), formally describe the LPAD protocol and its construction (§ IV),
and then present the LPAD system in an outsourced storage
scenario (§ V). In each of these design layers, we describe
the system frontend and backend. The paper organization for
describing the LPAD technique is illustrated in Table I.
TABLE I: Paper organization describing the LPAD technique

ADS
layer

Datastorage
layer

Existing
PADs

Design layer
LSM storage modeling
LPAD protocol
LPAD construction
LPAD system

LPAD*

B-tree

LSM-tree

Update-inplace

Append-only
updates

Frontend Backend
§ III
§ IV-A
§ IV-B1
§ IV-B2
§ V-A
§ V-B

III. M ODELING LSM T REES

Fig. 1: Comparing ADS update protocols “*”: note we only con-

Frontend verifier

sider PAD or ADS protocols supporting random reads. Thus, hashchain which does not support random reads is excluded, although a
hash-chain is log-structured.

Prover

Backend verifier

LSM tree
Level C0

Sign

Put

A 9

Update
Ack

Level C1
Key Time
6
Z

Prove

Get

B. Global Consistency Verification w.o. Client Comm.

Level C2

VerifyM
Merge

Verify

A 2

Consistency in a cloud storage is about whether storage
writes can be serialized and whether reads return the latest
writes on the serialized order. Existing researches on verifying
strong multi-client consistency (strong in the sense of stronger
than fork consistency) all rely on client communication to
synchronize their views and to establish a consistency ground
truth [43], [66], [50]. This paradigm requires all the clients to
be available at scheduled time, which may render it unfeasible
to many application scenarios where clients are asynchronous
in nature and can not be coordinated to be available at the
same time. The following is one example:
Cross-organizational Git repository: Git repository allows multiple developers to concurrently make changes to
a shared project. Known consistency-oriented attacks (e.g.
duplicated-effort attack [82]) on the git repository can be
detected at the time of merging branches, by enforcing fork
consistency [82], [47]. With strong consistency verification,
it can prevent the attack in the first place (at the pull time).
Existing strong-consistency solutions rely on client-view synchronization, which is feasible only to the case of a small
repository with all the developers in one organization [43].
However, in a public repository (e.g. hosted in Github.com)
where developers are organized in an ad-hoc fashion and
from different organizations, it becomes unfeasible to schedule times for view synchronization. This becomes especially

T 0

Z 3
Z 1

Maintain

SignM

Fig. 2: LPAD construction with a three-level LSM tree
An LSM tree exposes two interfaces: A frontend interface
for serving online reads/writes, and a backend interface for
serving maintenance. An LSM tree supports key-value data
model where each record consists of a key, a value and a
timestamp; records are accessed by keys. The internal of an
LSM tree is a series of key-ordered lists: All lists have their
records sorted by the keys. To an online write or Put, only
the very first list is updated-in-place, while all the other lists
are immutable to the Put and are asynchronously updated
in batch through a maintenance process, called compaction.
Given multiple ordered lists, a compaction “merges” them into
a single list; this improves future operation efficiency.
To an online read or Get, the LSM tree needs to check
all the lists in the worst case, (although reading individual
lists can be facilitated by binary search or primary index). For
instance, in Figure 2, a Get needs to check on all three lists.
By this arrangement, an LSM tree has three performance
characteristics: 1) optimized write performance because online
writes do not cause random disk IO (the first list updated inplace resides in memory), 2) de-optimized read performance
as a read checks multiple lists and causes multiple random disk
3

Definition 3.5: A record, hk, v, tsw i, is key-fresh w.r.t.
timestamp tsr in an LSM tree C, if and only if there is no
record hk, v ′ , ts′w i ∈ C ∪ tsr ≤ ts′w < tsw .
Theorem 3.6: A record at level Ci , say hk, v, tsw i@Ci , is
key-fresh w.r.t. timestamp tsr in an n-level LSM tree C =
C0 ∪ C1 . . . Cn−1 , if and only if hk, v, tsw i@Ci is fresh in a
level Cj , ∀j ∈ [0, n).

IO, 3) maintenance improves the performance of future writes
as a compaction job merges a lower-numbered list (assuming
the LSM tree’s lists are numbered by their arrival order as
will soon be described) into a higher-numbered list, clearing
the way for future compaction.
Formally, an LSM tree is specified by the following invariant:
Invariant 3.1 (Intra-level key-ordering): An LSM tree lays
out its data storage in multiple lists (i.e., so-called levels3 ),
C0 , C1 , . . . , Cn . In each list, records are sorted by key.
For instance, Figure 2 illustrates an LSM tree of three levels:
C0 , C1 and C2 , and at any level, say C2 , records are sorted
by key, say from A to T to Z.
A compaction is formulated in the following format:
Invariant 3.2 (Two-level compaction): A compaction takes
as inputs two key-complete lists4 in two consecutive levels,
′
say Ci , Ci+1 , and produces as output a merged list Ci+1
replacing the higher-numbered input list Ci+1 , and an empty
list replacing Ci .
For an LSM tree with Invariant 3.1 and 3.2, we have the
property that records of the same key across different levels
are sorted by timestamp. For instance, in Figure 2, an older
record of key A, with smaller timestamp 2, resides on highernumbered level C2 , while a more recent record with timestamp
9 resides on a lower-numbered level C0 . Formally,
Theorem 3.3 (Inter-level time-ordering): In an LSM tree
under compaction (specified by Invariant 3.2), given any two
records of the same key, the one in the lower-numbered list,
say hk, tsi in list Ci , must be younger than the one in the
higher-numbered list, say hk, ts′ i in list Cj . That is, given
hk, tsi@Ci and hk, ts′ i@Cj , i > j ⇒ ts < ts′ .5

Proof We prove if hk, v, tsw i@Ci is fresh in a level Cj ,
then it is fresh in C. We prove by contradiction. Assume
if hk, v, tsw i@Ci is fresh ∀Ci , hk, v, tsw i is not fresh. By
definition, there must exist hk, v ′ , ts′w i ∈ C∧tsr ≤ ts′w < tsw .
Because C = C0 ∪ C1 . . . Cn−1 , there must exist Cj s.t.
hk, v ′ , ts′w i ∈ Cj . By definition, hk, v, tsw i is not fresh in
Cj . Thus contradiction.
It can be similarly proved that if hk, v, tsw i is fresh in C,
it is fresh in ∀Ci ∈ C.
IV. LPAD P ROTOCOL & C ONSTRUCTION
A. LPAD Protocol
Based on the LSM tree model, we describe our LPAD
protocol. In the universe of an LPAD, there are three parties:
a prover p, a frontend verifier v, and a backend verifier v’. The
prover is untrusted (playing the role of untrusted LSM-based
storage) while both verifiers are trusted. By convention, all
parties are assumed to be reliable under system failures (or
assuming no failures). Note our setting is slightly different
from the standard ADS setting in that it considers an extra
verifier v’ for modeling the backend procedure of an LSM
tree.
In this setting, an LPAD protocol formally describes the interactions between the prover and both verifiers, including the
frontend interface (between p and v), and backend interface
(between p and v’).
On the frontend for writes, the verifier submits request
vPut (k, v) and receives from the verifier a timestamp tsw
associated with the record written. vPut is a verifiable variant
of regular Put request. As formally described in Figure 3, it
produces an attestation that helps keep the record of this vPut
operation. Timestamp tsw dictates the position of the record in
the global operation history and is useful to specify freshness.
Note in this section, we only consider serial execution of
Put/Get without concurrency, that is, the frontend verifier
does not submit another operation until the current operation
completes its execution.
On the frontend for reads, a verifier submits a read
request, vGet(k, tsr ) with properly assigned timestamp tsr
and receives the result hv, tsrw i from the prover. The correctness properties she wants to verify are two: 1) result
integrity, which requires that record hk, v, tsrw i is indeed a
record written by a legitimate vPut before, 2) result freshness,
which requires that record hk, v, tsrw i is the latest among all
matching records of key k and with timestamp before tsr .
Integrity can be verified easily by attaching each record a
digest (e.g. a hash) and thus this work focuses on the freshness
verification. As will be discussed in systems building (§ V),
freshness verification is crucial to consistency verification (e.g.

Proof (Sketch) We present the proof sketch and leave the full
proof in Appendix A. Theorem 3.3 is implied by Invariant 3.2.
The state of the overall system can only be mutated by two
operations: 1) a Put that only mutates the first list, 2) a
compaction that, due to Invariant 3.2, only moves records from
a lower-numbered list to a higher-numbered list. Consider an
initial system state satisfying Theorem 3.3. The two statemutating operations do not violate the theorem in the end
state: Operation 1) inserts the latest record to C0 so that
previous older records still reside on levels higher than level
0. Operation 2) moves a key-complete range of records from a
lower-numbered level to a higher-numbered one. Such a range
does not create any non-consecutive range of records in one
of these levels.
Now, we specify record freshness in an LSM tree. A record
is fresh w.r.t. its key if and only if its timestamp is the largest
among all records of the same key. Formally,
Definition 3.4: A record, hk, v, tsw i, is key-fresh w.r.t.
timestamp tsr in a level Ci , if and only if there is no record
hk, v ′ , ts′w i ∈ Ci ∧ tsr ≤ ts′w < tsw .
3 In

this paper, we use lists and levels interchangeably.
key-complete list in a level cover either all or none of the versions of
a given key.
5 Here, it assumes timestamps increase along with time, and a younger
record has a larger timestamp.
4A

4

staleness-based consistency [31], [22], linearizability [39]) and
can be naturally extended to verify key-completeness [46] of
range search in a multi-key setting.
On the backend, a maintenance job merges two lists
′
Ci , Ci+1 into one, Ci+1
. In the verifiable maintenance, the
prover p and verifier v’ interactively run vMerge that takes
as p’s input two ordered lists Ci , Ci+1 and as v’’s input the
digests of the two lists δi , δi+1 . At the end, the output state
is that prover and backend verifier have the merged result,
′
′
p.Ci+1
and v’.δi+1
.
The detailed LPAD protocol is formally presented in Figure 3.
In the following, we describe a construction of the LPAD
protocol using Merkle trees and TEE.

•

•

•

B. LPAD Construction by Merkle Tree & TEE
An LSM tree, held by the prover, is digested by a forest
of Merkle hash trees (MHTs), each digesting one list in the
LSM tree. Figure 2 illustrates a three-level LSM tree digested
by a forest of three per-level MHTs (in red triangles). Given
an LSM tree of dataset C = {C0 , C1 . . . }, the LPAD cone = {C
f0 , C
f1 , . . . }
struction converts it into a digested dataset C
fi is a Merkle tree) and a digest consisting of Merkle
(where C
hashes at different levels, δ = {δ0 , δ1 , . . . } (where δi is the
fi ). Digested dataset C
e is stored by
root hash of Merkle tree C
the prover and digest δ is stored and shared by both verifiers.
In the following, we describe the construction of frontend
and backend procedures as formulated in Figure 3.
1) Frontend Construction: On the write path, v.Sign runs
on standard public-key encryption algorithms, and p.Update
e
verifies the record hk, vi using signature s and inserts it to C.
It uses C0 ’s Merkle proof on key k to instantiate PU (C0 , k).
Then v.Ack verifies the Merkle proof PU (C0 , k), and updates
digest δ by the hash of tsw concatenated with hk, vi.
On the read path, the major design issue is about the
construction of freshness proof P[F ]. Here, we present two
types of proofs with the same security, yet with different
performance traits.
Definition 4.1 (All-level proof): Given vGet(k, tsr ) →
hv, tsrw i, an all-level proof for freshness, P1 [F ], consists of
Merkle proofs for key k at all levels in an LSM tree.
Definition 4.2 (Selected-level proof): Given vGet(k, tsr ) →
hv, tsrw i@Ci (that is, the result resides in level Ci ), a selectedlevel proof for freshness, P2 [F ], consists of Merkle proofs for
key k at levels C0 , C1 , . . . , Ci in an LSM tree.
For instance, in Figure 2, vGet(Z, 10) → hv, 6i and the
result resides on level C1 . P1 [F ] consists of Merkle proofs
on all three levels, while P2 [F ] consists of those on levels C0
and C1 , excluding C2 .
A selected-level proof results in smaller-sized proofs yet
an all-level proof enables parallel processing. In many real
LSM storage systems (e.g. LevelDB), the selected-level proof
matches their natural way of processing a Get request, that is,
it checks levels from C0 , C1 . . . in order, until it reaches the
level of a record matching key k.

•

•

v.Init(1λ ) → sk, pk: Init, run by v, takes as input security
parameter 1λ , and outputs a secret key sk and a public key pk.
The public key is implicitly used in all the algorithms below.
e Setup, run by v, takes as input
v.Setup(C, sk) → δ, C:
dataset C and the secret key sk, and outputs a digest δ and
e
authenticated dataset C.
vPut (k, v) → tsw , AT T (tsw ): vPut submitted by verifier v
takes as input a record hk, vi and produces a timestamp tsw
and attestation AT T (tsw ). The attestation enables the logging
of this vPut operation at timestamp tsw .
– v.Signsk (hk, vi) → s: Verifier v, using its secret key sk,
Sign the record hk, vi and produces signature s as output.
e
f′ , tsw , PU (C0 , k):
– p.Update(s, hk, vi, C)
→ {0, 1}, C
Prover p takes as input record hk, vi, signature s, and its
e and produces a binary indicating
authenticated dataset C,
if the update is executed successfully, a timestamp tsw
f′ ,
associated with the record, updated authenticated dataset C
and a proof about the pre-Update state of C0 on key k,
namely PU (C0 , k). Note only level C0 is mutable.
– v.Ack(tsw , hk, vi, PU (C0 , k), δ) → δ ′ , tsw : The verifier associates the received timestamp tsw with hk, vi, and updates
the digest δ based on PU (C0 , k).
vGet(k, tsr ) → hv, tsrw i, C[F ](tsr , tsrw ): vGet, submitted
by verifier v, takes as input queried key k and read timestamp
tsr , and produces as output result record with value v and
its own timestamp tsrw , as well as a certificate for freshness
C[F ](k, v, tsr , tsrw ).
e hk, v, tsrw i) → P[F ]: p.Prove takes as input
– p.Prove (C,
e and result record hk, v, tsrw and
authenticated dataset C
produces as output the freshness proof P[F ].
– v.Verify (δ, hk, v, tsrw i, P[F ](tsr , tsrw )) → {0, 1}:
v.Verify run by verifier v takes as input verifier’s digest δ,
result record hk, v, tsrw i, read timestamp tsr and freshness
proof P[F ] and produces a binary indicating whether the
verification passes.
vMerge
(p.Ci , p.Cj , v’.δi , v’.δj )
→
f′ , p.C
f′ , v’.δi′ , v’.δj′ (assuming j > i): vMerge
{0, 1}, p.C
i
j
takes as input the prover’s two lists Ci , Cj and backend
verifier’s digests δi , δj , and produces as output a binary
indicating if the vMerge is successfully executed and the
final state p.Ci′ , p.Cj′ , v ′ .v’.δi′ , v’.δj′ . If the binary is 1, then
p.Ci′ = ∅, v’.δi′ = ∅ and p.Cj′ is the merged list from the
two input lists, and v’.δj′ is the digest of the merged list. This
internally runs as an interactive process between prover and
backend verifier:
– v’.CheckSel(Ci, Cj ) → {0, 1}: CheckSel takes as input
the two lists Ci , Cj and produces a binary indicating if the
selected two lists conform to Invariant 3.2.
– v’.VerkfyM(Cl , δl ) → {0, 1}, (l ∈ {i, j}): VerifyM takes as
input one of the two lists Cl (l = i or l = j) and its digest
δl , and produces a binary indicating if the content of the list
matches the digest.
– v’.MergeSignsk(Ci , Cj ) → Cj′ , δj′ , s′ : v’.MergeSign takes
as input the two lists Ci , Cj and produces merged list Cj′ ,
its digest δj′ , and a signature s′ .
f′ , C
f′ : p.UpdateM
– p.UpdateM(Ci′, Cj′ , s′ ) → {0, 1}, C
i
j
takes as input two lists Cj′ and Cj′ , and a signature s′ . It
produces as output a binary indicating if the execution is
f′ and C
f′ .
success, the digested version of the two lists, C
i
j

Fig. 3: LPAD protocol

5

In other words, given levels Ci and Ci+1 , the lower-numbered
sublist on Ci must not overlap in key ranges any part of Ci+1
that is not in the selected higher-numbered sublist.
For instance, it is illegal to merge sublist {hZ, 6i} with
sublist {hA, 2i} in Figure 2, but legal to merge {hZ, 6i} with
sublist {hZ, 1i, hZ, 3i}.
For compaction under Invariant 3.2 and 4.3, the property
of inter-level time ordering (Invariant 3.3) still holds. Because
for a single key, the data migration between levels is still from
lower-numbered to higher-numbered. We formally prove it in
the technical report [14].
Under partitioned LSM tree, the CheckSel is slightly
modified to be CheckSelp (sublist1 @Ci , sublist2 @Cj ), and
the checking logic is based on Invariant 3.2 and Invariant 4.3.
Verifiable-compaction security: There are two possible
attacks by the prover, that is, selecting wrong lists/sublists that
are not supposed to be compacted, and providing list/sublist
contents that are modified from the original records. Both
attacks are mitigated because of the Invariant enforcement
(v’.CheckSel) and the unforgeability of MHT (v’.VerifyM).

Correctness: The correctness of LPAD is about wether
the proof can be used to correctly verify a Get result is fresh,
as defined in Definition 3.5. To proof P1 [F ], the correctness
is straightforward, as Merkle proofs at all levels are included
and each Merkle proof in a key-ordered list can prove the
non-membership and freshness of a record at that level (Theorem 3.6). To proof P2 [F ], the correctness is similarly proved
except that the excluded Merkle proofs in Ci+1 , . . . , Cn can
be implied by Theorem 3.3 – all levels higher-numbered than
Ci cannot have records fresher/younger than the records in
Ci .
Figure 2 illustrates the intuition: Record hZ, 6i from level
C1 is the freshest (with the largest timestamp 7) in the entire
dataset, and this can be proved by three facts: F1) The record
is the freshest in its resident level C1 , F2) there is no record
of key Z in level C0 , and F3) the record is fresher than any
record of Z in the higher levels C2 , i,e., hZ, 3i and hZ, 1i.
Security & Unforgeability: We analyse the security of
frontend construction by considering stale-read attacks from
the untrusted prover. In the attack, prover presents a stale Get
result and tries to forge a freshness proof. The attack succeeds
if the forged freshness proof can pass v.Verify by the verifier.
For instance, in an operation sequence, vPut(k, v1 ) → tsw =
11, vPut(k, v2 ) → 12, vGet(k, 14) → hv1 , 11i, the vGet
result is stale. The attack aims at forging P[F ](k, v1 , 14, 11)
to pass the verification.
The unforgeability of the freshness proof is provided by
the collision-resistance of hashes in the Merkle proofs. The
unforgeability of per-level Merkle proofs can be naturally
extended to that of an overall freshness proof. For instance,
in the previous example in Figure 2, F1 is unforgeable due to
the Merkle proof on C1 and the key ordering in C1 implied
by Invariant 3.1. F2 is unforgeable because of similar reasons
(Merkle proof on C0 ). F3 is unforgeable by Invariant 3.3.
Generalizing this case gives us a formal proof presented in
the technical report [14].
2) Backend Construction in TCB: We construct the verifiable merge with linear (and theoretically optimal) cost.
In the basic construction for vMerge (formulated in Figure 3), v’.CheckSel(Ci , Cj ) checks if j = i + 1 or j =
i − 1 in a way to check the satisfiability of Invariant 3.2.
v’.VerifyM(Cl , δl ) reconstructs the Merkle tree of Cl and its
root hash, and compares it with δl to result in the binary
output. p.UpdateM updates the prover’s LSM-tree layout from
f′ , if the update is successful.
f′ = ∅, C
fi , C
fj to C
C
j
i
Partitioned LSM Tree: In real LSM stores, the data
storage in a level is partitioned into sublists and a compaction
occurs at the fine granularity of the sublists. A sublist is an
arbitrary, consecutive range of records in a list.
In vMerge on sublists, the input selection is parameterized
by a policy that dictates what input sublists are allowed.
In addition to requiring that sublists must reside on two
consecutive levels (Invariant 3.2), another requirement is keycompleteness, described as below:
Invariant 4.3 (Key completeness): Given a compaction with
two sublists, the key-range of the lower-numbered sublist must
be fully covered by the range of the higher-numbered sublist.

V. LPAD S YSTEMS
End users

App/DB
servers*

Put/Get

Storage engine
(LPAD protocol)
Enclave

Enclave

Consistency Frontend
verifier
checker

Prover
(Storage)

Backend
verifier

Cloud

Fig. 4: LPAD systems in cloud data-outsourcing: means that
application and database servers can be optionally added to the userstorage interaction.

This section describes an overall data-outsourcing system
where the LPAD can be deployed.
We consider data-outsourcing to the public cloud. A data
owner, for instance, a small-business company in a rapid
growth (increasing customer base yet with limited computing
budget), wants to outsource its customer data-storage to the
cloud for cost effectiveness. The public cloud provisions machine instances through an infrastructure-as-a-service model
(IaaS). The owner deploys the key-value store software on
the instance to serve its data user. The deployed system
architecture is illustrated in Figure 4. In particular, the data
user can interact with the cloud store, either directly or through
intermediate layers (e.g. application servers and database
servers). What is exposed by the storage server is a trustworthy
Put/Get interface:
vPutc (key k, value v)
vGetc (k)

→ Attestation AT T put

(1)

→ hvi, Certificate CRT get (2)

vPutc /vGetc is a variant of vPut/vGet that allows for
concurrent invocation and offers certified consistency (by SGX
authority described below). In this work, we consider the
strong consistency level, Linearizability [39]. To a vPutc call,
6

attestation AT T put states that the store has committed the
storage of the record and serialized it at a fixed position
(that will not change later on). To a vGetc call, certificate
CRT get states the result is correct in the sense of integrity and
freshness (on the serialized total-order). Below, we introduce
our trust model based on SGX.
Preliminary: SGX: We assume a cloud server is equipped
with Intel SGX. Intel SGX is a security-oriented extension for
x86-64 ISA on the Intel Skylake CPU, released in 2016. SGX
provides a “security-isolated world” for trustworthy program
execution on an otherwise untrusted hardware platform. At
the hardware level, the SGX secure world includes a tamperproof SGX CPU which automatically encrypts memory pages
(in the so-called enclave region) upon cache-line write-back.
Instructions executed outside the SGX secure world that attempt to read/write enclave pages only get to see the ciphertext
and can not succeed. SGX’s software TCB includes only userspace program and excludes any OS kernel code, by explicitly
prohibiting system services (e.g. system calls) inside enclave.
To use the technology, a client initializes an enclave by
uploading the in-enclave program and uses SGX’s seal and
attestation mechanism [19] to verify the correct setup of the
execution environment (e.g. by a digest of enclave memory
content). During the program execution, the enclave is entered
and exited proactively (by SGX instructions, e.g. EENTER
and EEXIT) or passively (by interruptions or traps). These
world-switch events trigger the context saving/loading in both
hardware and software levels. Comparing prior TEE solutions [12], [13], [2], [10], SGX is unique in supporting multicore concurrent execution and dynamic paging for runtime
efficiency.
Trust model: We assume clients are trusted, and there
is mutual trust among them (e.g. owner-and-user, and userand-user). A client normally does not need to communicate
with other clients, except for initial key-exchange during the
setup. A client trusts nothing on a cloud machine except for
the initialized enclave; the trusted computing base includes
at the hardware level, the SGX CPU, and at the software
level, the enclave program. The untrusted part on the server
includes hardware, such as the non-secure memory pages
outside enclave and all the peripherals, and software, such as
operating systems and user-space processes running outside
enclave. The untrusted host can mount a replay attack and
answer to a Get operation with properly signed but stale
version. We assume a secure channel is established over the
untrusted Internet between the client and cloud server and is
resilient to standard network attacks (e.g. man-in-the-middle
attacks, etc. [42]).
Scope: This work does not address out-of-scope issues
which are addressed by orthogonal work, including denial-ofservice attacks, proven deletion [34] under Sybil attacks [84],
TEE state-continuity under replay or rollback attacks [74],
enclave side-channel attacks [85], and design flaws of an
enclave program.

Timeline

w1

Alice

Clients
(trusted)

Consistency
checker
(trusted)

r2=w1

Bob

prePut()

preGet(tsr2)
postGet(tsr2w=tsw1)

postPut(tsw1)

Cloud storage
(untrusted)

Key-value store

(a) Consistency checker thru. pre-/post- Put/Get hook: r2 = w1

means read r2 returns the record written by w1 .
Write
serialization

w2

w1

Read
freshness

tsw1 tsw2 Satisfiable
101 102
102 101

r3=w?

w1
w2

tsw1
101
101
102
102

tsw2
102
102
101
101

Satisfiable
ts r3w
101 (r3=w1)
102 (r3=w2)
101 (r3=w2)
102 (r3=w1)

(b) Consistency specification

Fig. 5: Consistency checker: Write serialization: the total-order
must be consistent with the real-time order of w1 and w2 (in the
right figure), due to Linearizability requirement on real-time. For
instance, write serialization does not allow the timestamp assignment
of 102, 101 to w1 , w2 because this would place w1 after w2 which is
different from the real-time order that w1 executes before w2 . Read
freshness: the read must return the latest write on the total-order
dictated by tsw1 and tsw2 , due to Linearizability requirement on
freshness. r3 = w2 means read r3 returns the record written by w2 .

linearizability [39] is about the existence of a serialization
total-order that conforms to two conditions: real-time requirement (denoted by L1) and freshness (by L2): L1 requires
that the total-order reflects the real-time partial-order of the
reads/writes execution (“operation A completes before the
beginning of operation B requires that A is placed before
B on the total order”). Freshness L2 requires that any read
returns the latest write on the total-order. L2 is specified in
Definition 3.5.
Figure 5b illustrates the consistency specification in a (incomplete) list of different cases. In this work, a key assumption
we make is that the untrusted store that claims to have strong
consistency (linearizability) promises to provide a globally
unique timestamp that represents the total-order, i.e., tsw . In
many real consistent-store systems, this assumed timestamp is
already present. Note that this assumption considers that both
violation of strong consistency and failure to present correct
timestamp as malicious behavior that should be detected.
Under this assumption, the consistency verification is reduced
to checking whether conditions L1 and L2 are met on the
total-order represented by the timestamp.

A. Frontend Consistency Checking
Preliminary: Linearizability specification: We focus on
the strong consistency level, linearizability. Conceptually, the

Following the precise specification above, we propose an
7

algorithm to immediately verify the linearizability. The algorithm considers concurrent operations that may complete
out of order, that is, operation completion order is different
from the assigned total-order by tsw . This is illustrated by
dark boxes in Figure 5b. Unlike the previous work based on
periodical scheduling of verification [43], [66], the proposed
algorithm achieves the theoretic lower bound in the delay
between the verification time and completion time. Briefly,
the technique proposed is to consider any completed operation
be in one of two states, serialized and non-serialized,6 and to
verify linearizability only on the serialized operations.
The frontend system architecture is illustrated in Figure 4
where a consistency check is added in front of the frontend
verifier. The consistency checker takes as input the concurrent
execution of reads/writes and outputs a binary satisfiability
decision upon the completion of each read (or write). Figure 5b illustrates the details of consistency checker which takes
actions to respond to four events: pre-Get, pre-Put, post-Get,
and post-Put. Internally, the checker transits an operation (Put
or Get) among three states: pending (operation started and not
yet completed), completed, and serialized (an operation is serialized when all operations with write timestamp smaller/older
than the operation are completed).
A key design is the interaction between the consistency
checker and frontend verifier. The consistency checker relies 1
on the frontend verifier to present the freshness verification, 2
3
and it does so only when a completed operation transitions to 4
the serialized state. In our implementation, a synchronization 5
6
point is confined within the scope of a single event; no locks 7
are held across events. Consistency conditions (e.g. serialized 8
9
writes and read freshness as illustrated in Figure 5b) are10
11
checked upon post-Put/Get events. The pre-Put/Get events
12
initiate the bookkeeping of operation states.
13
The state maintained by consistency checker may need to14
15
ensure state-continuity upon system crash; and we assume16
a reliable monotonic counter (e.g. Memoir [63] and Ari-17
18
adne [75]) exists in enclave.
19
Note our assumption that untrusted store returns a global20
21
timestamp can be realized in strongly consistent stores, such as22
LevelDB. A strongly consistent store takes a single writer7 and23
24
persists the written record in a log before completing the write25
– The write timestamp tsw is assigned in the logging process
and is used to dictate the position of the written record in the
log.8 The pseudo-code of the frontend consistency verifier is
in the technical report [14].
Frontend security: The untrusted prover interacts with the
frontend verifier through vPut/vGet interface. The prover can
forge a vGet result that is stale or incorrect. The verification
by v would not pass as these results do not match the current
digest held by the verifier.
6 An operation occupying the serialized state means all the operations before
this one in the assigned total-order have completed. An operation occupying
the non-serialized state means there are some operations before this operation
in the total-order that are not completed.
7 Currently, our implementation is specific to this strongly consistent and
single-writer stores. Extensions for concurrent writers in key-value stores are
addressed in related work, such as cLSM [35].
8 We don’t consider the semantics of transactional isolation in this work.

8

The untrusted store interacting with the end users (or upperlayer systems) might mount consistency/concurrency attacks,
of which the replay attack (presented earlier in § III) can be
treated as a special case. In the concurrency attack, the store
equivocate on concurrent Put/Get calls. For instance, Figure 5b
illustrates a replay attack on concurrent writes, that is, read
r3 returns the data written by w2 whose execution overlaps
w1 . This is a violation of freshness, because the untrusted
store has claimed w1 happens before w2 (tsw1 < tsw2 ),
even though they are concurrent in real execution. The replay
attack is mitigated because of the LPAD’s freshness and the
consistency checker. Similarly, the untrusted store can mount
realtime-order attack where the claimed write timestamps of
two writes are inconsistent with their real-time order. For instance, in Figure 5b, w1 occurs before w2 in real-time, yet their
assigned timestamps are in the reversed order, tsw1 > tsw2 .
The realtime-order attack is mitigated by the bookkeeping of
the consistency checker (i.e. the checker maintains the realtime ordering in pending and completed operations).
Note global linearizability is stronger than fork consistency [49], [47], thus our security layer mitigates forking
attacks.
B. Backend Maintenance
void vCompact(C_i,C_j){//assume i<j
if(!CheckSel(C_i,C_j)) abort();
do{
if(record_i < record_j){
output = record_i;
rebuilt_digest_Ci.update(output);
digest_mergedCj.update(output);
eof = inputKV(C_i.next(), record_i);
}else{
output = record_j;
rebuilt_digest_Cj.update(output);
digest_mergedCj.update(output);
eof = inputKV(C_j.next(), record_j);
}
if (filterout_policy(output) == FALSE)
outputKV(output);
} while (!eof);
//output pending list
if(VerifyM(rebuilt_digest_Ci, delta_i)
&& VerifyM(rebuilt_digest_Cj, delta_j)){
s = Sign(mergedCj);
return s;
} else abort();
}
}

Listing 1: One-pass program for verifiable compaction in
Enclave
One naive approach to implementing the LPAD’s verifiable
compaction is to run the related constructs separately, that is,
implementing v’.CheckSel, v’.VerifyM, and v’.MergeSign as
separate iterations over the merging lists.
A more efficient implementation is a one-pass algorithm
that iterates through all the lists without any repeated access.
The algorithm is illustrated in List 1 which embeds all the
related constructs in a single merge-sort-style loop. In each
iteration of the loop, it might trigger two cross-boundary calls
to switch the execution out of enclave: inputKV which reads
one record into the enclave from the untrusted world (memory
or disk), and outputKV which stores the output data to the
untrusted world. By the end of the loop, the enclave endorses

(by signing) the merged list only when both v’.CheckSel
and v’.VerifyM are satisfied. Figure 6 illustrates the system
workflow of compacting two sublists or files9 in two levels
with an enclave. In particular, we address three systems-level
issues below:
Memory-efficient MHT construction: Recall the input verification works by reconstructing the MHT from
inputKV(), and checking its root hash (upon completion)
against the previous digest. Our system limits the Merkle root
hash construction by consuming log n memory footprint (n is
the number of MHT leaf nodes or the number of records in a
file), because it only needs to maintain a tree “frontier” (i.e.
the path from the current leaf node to the root) bounded by
the tree height [79]. The output stream is digested by similarly
constructing an MHT upon outputKV() calls.
Versioning policies: Applications may have different
policies in managing versions. For instance, an application
may explicitly require the ”update” semantic for its write,
which states the write should overwrite all previous versions
and requires the system to maintain a single, latest version for
the written key. Other applications may prefer treat the update
as an insert, allowing for multi-versioned data. A common
policy is to keep the latest k (e.g. k = 3) versions and delete
any version older than them.
Policies can be implemented as a filter plugin on the onepass vCompact program in enclave. For instance, retaining
the latest k versions is implemented by maintaining a single per-key counter counting the number of versions of the
current key visited. One thing noteworthy about the one-pass
compaction is that the data records are emitted in the key
order (tie broken by timestamps) so that different versions
of the same key are visited together and a newer version is
always visited before an older version. This order allows the
versioning policies to be implemented as an add-on filter on
the pass.
Handling delete: Similar to original LSM stores (e.g.
LevelDB [7]), we treat a delete request as a special data record,
a.k.a, tombstone write. The semantic of the delete record w.r.t.
key k is to delete all the versions of k preceding (in arrival time
or timestamp) the delete record. We implement this semantic
in vCompact by the deleting policy. The deleting policy is
very similar to the overwriting policy with the only exception
that the delete record itself will be dropped if the compaction
reaches the last/highest-numbered level (that is when it can
assure all possible data records before it are deleted).
Implementation with SGX: By the SGX hardware design,
system services are prohibited inside enclave and have to be
executed outside. The compaction interacts with input/output
data resident on disk. It is thus essential to coordinate the
scheduling of in-enclave merge computation and outsideenclave disk-accesses.
From programming perspective, the problem boils down
to “partitioning” the code path of interface functions,
inputKV()/outputKV(), to the parts that are run in and

Enclave

CPU

inputKV

MergeSign

outputKV

inputKV
VerifyM

Memory
Disk

Buffer

Buffer

Buffer

C1

C1
f11

f12

f13

f12

f13

C2

C2
f21

f22

f23

f24

f'21

f'22

f23

f24

Fig. 6: In-enclave compaction: three selected files or sublists,
′
′
f11 , f12 , f21 , are merged into two or more files in C2 , e.g., f21
, f22
.
It shows the workflow of in-enclave compaction; the white triangles
inside the enclave refer to the frontier built to construct input/output
MHT root hash.

outside enclave. A naive partitioning is directly on the interface function, which results in a world-switch (i.e. the switch
of program execution between the enclave and untrusted host)
upon every individual call to inputKV()/outputKV().
That is, a world switch is triggered to read and write each
key-value record. This design results in significant runtime
overhead in our experiments. A better design is to result in
less frequent world-switches. We partition the code at a level
close to the system-calls so that a world-switch is triggered
only when it becomes necessary. Specifically, we maintain a
buffer in the untrusted world to hold input/output data, and
when the buffer runs out of space, our partitioned code starts
to switch out enclave and performs system calls to read/write
files in the untrusted world.
In our implementation, we maintain the Merkle root hashes
of all the per-level MHTs in enclave to simulate the “signing”.
Because in-enclave signing by digital signatures would unnecessarily increase the enclave codebase. Normally, an LSM tree
does not have too many levels (e.g. fewer than 20), making it
feasible for storing Merkle root hashes.
1) Security Analysis: A local attacker is a party who fully
controls the server’s software/hardware stacks except that the
attacker can not physically break into the enclave world: The
SGX CPU is tamper resistant and the enclave memory pages
are encrypted and protected under a computationally bounded
attacker.
By design, an enclave execution allows two possible channels for boundary-crossing, 1) switching control out of enclave (through SGX instruction, EEXIT [11]), and 2) direct
untrusted-memory access from enclave. To a local attacker,
this constitutes the attack surface of an enclave program
execution.10
Through the attack surface, we consider two attacks by 1)
injecting incorrect input data (data exploit), and 2) exploiting
in-enclave program integrity for control-flow hijacking attacks.
The first attack has been analyzed in § IV. To attack 2), we
assume a trustworthy enclave program with program integrity.

9 In a partitioned LSM tree, a sublist is materialized as a file. Hence, we
use file and sublist interchangeably hereafter.

10 We don’t consider the denial of service attacks mounted by malicious OS
or the side-channel attacks [85] targeting on confidentiality of an enclave.

9

TABLE II: TCB size

In our implementation, we leverage Control-Pointer Integrity
(CPI [44]) in the recent LLVM compiler that ensures (in a
certain degree) the program integrity.

LoC
Module
LoC

merge
118

SHA
339

T RUSTKV
1025
MHT
checker
40
134

misc.
394

All in enclave [25]
> 19567
LevelDB
19567

VI. E VALUATION
In this section, we evaluate our design to answer the
following questions:
2

2

•

Latency(usec)

•

10

10

What is the TCB size? (§ VI-A)
What is overall performance benefit of LPAD comparing
existing ADSs (§ VI-B)?
What is the detailed performance overhead of LPAD on the
frontend (§ VI-D) and backend (§ VI-C)?

Latency(usec)

•

1

10

1

10

Raw LevelDB (Ideal)

0

10

Raw LevelDB (Ideal)

LPAD

0

10

Single-MHT (Naive)

0

A. Implementation & Enclave Size

0

20

50
80
ReadPercenrage

(a) SHA-3

We implemented our LPAD systems design and built the
system of LPAD, a trustworthy key-value store based on
LevelDB, Intel SGX SDK and Crypto++ SHA code. The
system implementation involves writing programs for the
execution in two worlds.
The program in the untrusted world is taken out of the
LevelDB codebase [7] with several changes: 1. hooking our
enclave program (described below) to the LevelDB operations,
2. implementation for storing and serving MHT digests; we
here reuse several LevelDB persistence utilities and format the
MHT digests in a key-value format for that purpose. We also
implemented the proof construction (p.Prove) for processing
Get in the untrusted world. We modified the LevelDB codebase to return the write timestamp upon Put. This change is
not significant (e.g. leaving the original codebase as it is) and
does not cause high overhead.
The enclave program consists of four modules, 1) merge,
which performs the compaction computation, 2) MHT operations, which include MHT construction and Merkle proof
verification, 3) SHA which is taken from Crypto++ library
with the modification to get rid of system calls for the use
in enclave, 4) consistency checker, and 5) misc. functionality
which includes the world-switch glue code generated by Intel
SGX SDK (alpha on Linux), various condition checking,
thread synchronization support, etc. The four modules enable
enclave-entry points for all the constructs from verifiers (v or
v’) in Figure 3. The enclave program is written in C.
We report the size (by lines of code, LoC) of each enclave
module in Table II. The total enclave code line is 1025.
We compare it with the Haven [25] approach which would
put into the enclave the entire codebase of LevelDB, among
other facilities (hence TCB size is estimated to be larger than
LevelDB’s number of codelines, 19567 LoC). By comparison,
our design results in a TCB size reduction by at least 20 times.
Layered implementation While we did modify the codebase of LevelDB to hook LPAD, it does not have to be
the case. Depending on the API exposed by the storage
system, our implementation might be incremental, that is,
without changing the original storage codebase. For instance,
in HBase, it already exposes hooks for pre-Put/Get/Compact,
post-Put/Get/Compact, as in its CoProcessor API [5].

LPAD
Single-MHT (Naive)

100

0

0

20

50
80
ReadPercenrage

100

(b) SHA-1

Fig. 8: Memory intensive workloads
B. Overall Performance
1) LPAD vs ADS: This set of experiment aims at studying
the performance advantage (or disadvantage) of an LPAD
over the existing ADS when running on an LSM storage.
We choose a single MHT over the entire dataset to represent the update-in-place ADS. Note the single-Merkle tree
approach is used in many verifiable storage systems including
SUNDR [47], and is representative.
The experimental setup is on a laptop with an Intel 8-core
i7-6820HK CPU of 2.70GHz and 8MB cache, 32 GB Ram and
1TB Disk. This is one of the Skylake CPUs with SGX features
on. We generated a base dataset with uniformly distributed
keys; our base dataset includes 200 million records (22GB
without compression) with uniformly distributed keys;the keys
are generated sequentially in order. The overall number of
read/write requests are less than 1% of the entire dataset. For
a key-value record, the key size is 16 bytes and value size is
100 bytes.
We performed the experiment by running LevelDB’s builtin benchmark with the modification to drive workloads of
different read-write ratios to the target system. We varied
the read percentage from 0% (i.e. write-only workload),
20%, 50%, 80% to 100%. We tested different storage system
settings, such as compaction turned on/off, different record
sizes, use of different hash algorithms (e.g. SHA1 or SHA3).
We run each experiment at least three times, and report the
results in two metrics. As LPAD is designed for singlethreaded case, the experiments are conducted under singlethreaded workloads.
The performance result is presented in Figure 7a. The
performance difference between LPAD and the single MHT
can be up to three orders of magnitude, and it is clear that
LPAD’s curve is very similar to the “Ideal” performance
where the raw LevelDB is tested. In both LPAD and raw
LevelDB, the latency increases as the workload moves from
write-only to more read-intensive, both reflecting the writeoptimized performance nature of LSM storage design. By
contrast, in the single-MHT, the write-only workloads result in
the largest latency. The performance result can be explained
10

440

8 threads

8 threads

450

420

4000

3000

4000
3000
2000

2500
2000
1500

Raw LevelDB (Ideal)

Raw LevelDB (Ideal)

1000
Single-MHT (Naive)

20

50
80
ReadPercentage

380

360

4 threads

2 threads
1 thread
2 threads

340

TrustKV
Ideal

8 threads
4 threads

350

300

4 threads
2 threads

250

200

1 thread

2 threads

TrustKV
Ideal

LPAD

1000
0

400

320

LPAD

0

Throughput (ops per sec)

3500

5000

latency(usec)

latency(usec)

4 threads

6000

400

8 threads
Throughput (ops per sec)

7000

100

500
0

TrustKV

300

1 thread
2k

0

(a) LPAD vs ideal (single-threaded) (b) LPAD
threaded)

20

50
80
ReadPercentage

vs

T RUST KV

100

150

4k

6k

8k

10k

12k

14k

16k

Latency (micro sec)

(single-

(c) Concurrent readers

18k

20k

1 thread
4k

6k

8k

10k

12k

14k

16k

18k

20k

Latency (micro sec)

(d)
Concurrent
single-writer-multireaders (number of threads in the figures
is that of readers)

Fig. 7: Disk IO intensive workloads
by the following: In our setting, most of the read requests
are cold and served from disks, rendering the disk seek the
dominant factor. The LPAD design introduces no extra disk
seeks, while the naive Single-MHT design incurs a lot of extra
disk seeks due to its update-in-place nature.
We perform similar experiments with a much smaller
dataset (with all records fit in memory). In this memoryintensive workload, as disk IO is stripped away from the
critical path, the overhead of LPAD becomes more significant:
as in Figure 8, the LPAD overhead is up to 50% of the
raw LevelDB when SHA3 is used to construct the Merkle
trees. When SHA1 is used, the overhead reduces significantly,
despite its lower security.
2) Cost of Consistency Checker: This experiment aims at
studying how much performance overhead is caused by our
front-end consistency checker. We add the consistency checker
to the LPAD and call the overall system by T RUST KV.
We first conduct experiments in a single-thread setting. The
number of queries for each workload is one million. We report
the execution latency in Figure 7b.
Both the LPAD and T RUST KV system preserves the performance of ideal LSM storage, with small performance overhead
(less than 12 percent). Specifically, the performance trend
is a hill-shaped curve; the latency reaches the highest point
for the read-write workload mixed at certain rate. This is
consistent with LSM storage’s performance as it is not as good
serving read-write workloads as serving write-only (or readonly) workloads.
Multi-Threaded Execution: This experiment studies the
performance of T RUST KV under multi-threaded workloads.
Note LPAD can only run for single-threaded execution, and
is thus excluded here. We run LevelDB’s built-in workloads
(read-random and read-while-writing) on top of both variants.
The number of queries for each workload is one million,
which are evenly distributed among read threads. We report the
latency and throughput in Figure 7c and Figure 7d. From both
figures, the T RUST KV reduces raw LevelDB’s throughput
by about 10%. As target throughput increases, the latency
increases (almost linearly) with the throughput.

partitioning that decides the frequency of context switches,
as discussed in § V, and 2) whether the context switch
copies the untrusted buffer to enclave; when the buffer is
not copied, it is the pointer to the buffer that is passed into
the enclave for direct access. We design the experiments to
understand the performance impact of these implementation
options. We consider 5 variants with different combinations
of these options: copy, copy (no MHT), non-copy, noncopy (no MHT) and naive-partition. The first four variants
perform one context-switch per syscall, while the last one,
naive-partition, incurs the most context switches (one per
read and write). non-copy does not make data copy upon
context switch; and no MHT means MHT was disabled in
experiments. We also consider the baseline (unsecured) ,
which measures the original LevelDB performance without
any security.
In experiments, we change compaction configurations, including file size, the number of input files, buffer size, and
record size. We measure the execution time; for each result, we
conducted three runs of experiments and report average result.
We use a buffer size to hold about 1000 records and measure
the execution time under different settings: We use 5 input files
and vary the file size from 4 million records to 12 million, and
report the result in Figure 9a. We fix at 31.5 million records
and evenly distribute them to varying number of files from 3
to 9. We report the result in Figure 9b. From these two figures,
it can be seen: 1. the execution time grows linearly with the
number of records, and is insensitive to number of files, 2. the
memory copies do not cause significant overhead, 3. with a
large buffer, the context switch overhead is negligible (except
for naive-partition), 4. the hash computation (by SHA) incurs
about 45%−115% more execution time, 5. the naive-partition
approach results in the highest execution time, caused mainly
by an excessive amount of context switches.
The impact of the context switches can be seen more clearly
from Figure 9c where we vary the buffer size. With a large
buffer size (e.g. > 2 KB), the overhead of context switches
is small. When the buffer size is smaller than 2 KB, the
performance overhead is significantly increased by context
switches.
In the last experiment, we vary the record size, more
specifically, the size of value in a key-value record. We report

C. Compaction Performance
1) Micro-benchmark: In our implementation of in-enclave
compaction, there are two options: 1) the level of code11

the experiment result in Figure 9d. The difference in execution
time can be attributed to the disk IO costs: A larger record
costs longer disk-memory transfer time and all the series
converge at a large record size in Figure 9d.
2) LevelDB benchmark: We used the built-in benchmark of
LevelDB to study the impact of longer compactions to other
store operations. The built-in benchmark tests multiple workloads in a sequence: “fillseq, fillsync, fillrandom, readrandom,
readrandom, compact, readrandom.” In particular, “fillseq”,
“fillsync”, and “fillrandom” are write-only workloads, and
“readrandom” is a read-only workload; they both may trigger
the execution of compaction. In addition, “compact” is a workload where compactions are explicitly triggered. “fillseq” and
“fillsync” would clear the storage so that the next workload
can start from a freshly new store. We consider 3 variants in
this experiment, copy (no MHT), copy and naive-partition.
Other settings are the same to our micro-benchmark. We report
the result in Table III; in addition to the raw latency readings,
we also report the normalized latencies by the baseline approach. We highlight the largest normalized latencies: They
all belong to the “compact” workload. The slowdowns by
copy(no MHT), copy and naive-partition are respectively
1.3, 3 and 9.3, which are consistent with the micro-benchmark
results, except for that the absolute performance difference is
smaller due to the interference of front-end query operations.

level time ordering in saving read overhead. Without the time
ordering, the slowdown of All-Level is up to 51.44; it is more
than 3 times larger than that of LPAD.
TABLE IV: Latencies of online queries (the unit is micro seconds
except for “compact” with seconds, and the number in the parenthesis
is normalized latencies by baseline)

is micro seconds except for “compact” with seconds, and the number
in the parenthesis is normalized latencies by baseline)
fillseq
fillsync

copy(no MHT)
29(1.00)
39854(1.05)

copy
30.9(1.06)
38330(1.01)

naive-partition
28.8(0.99)
38454(1.01)

fillrandom
readrandom
readrandom
compact(×106 )
readrandom

71.3
9.55
5.02
5.02
3.599

85.0(1.19)
11.6(1.22)
5.73(1.14)
6.82(1.36)
3.553(0.99)

127(1.79)
14.5(1.52)
7.08(1.41)
15.43(3.07)
3.611(1)

257(3.61)
17.8(1.86)
10.3(2.05)
47.06(9.37)
3.647(1.01)

baseline
29.2
37895

LPAD
63.9(2.19)
34792(0.92)

All-Level
64.1(2.20)
38149(1.01)

No MHT
30.3(1.04)
35493(0.94)

fillrandom
readrandom
readrandom
compact(×106 )

71.3
9.55
5.02
5.02

130(1.83)
88.2(9.24)
77.1(15.3)
12.20(2.43)

134(1.88)
266(27.8)
260.6(51.8)
12.51(2.49)

129(1.82)
22.7(2.38)
11.9(2.37)
12.21(2.43)

We conclude our performance study of LPAD: Comparing
update-in-place ADS, LPAD improves the performance by
up to two orders of magnitude. LPAD becomes less disk-IO
intensive. Among various LPAD configuration options, the
use of MHT/SHA stands out to be the most significant in
performance impact. The SGX/Enclave hardware, if properly
used, can be lightweight with less than 3X slowdown for
online query processing, and less than 1.4X slowdown for
compaction jobs. MHT/SHA causes relatively high runtime
overhead, but it comes with the benefit of higher security
levels. In practice, clients who are more concerned about
performance should use more efficient but less secure hash
primitives (e.g. SHA-256). We leave it to the future work to
study the performance optimization problem.

TABLE III: Compaction latencies with online queries (the unit

baseline
29.2
378951

fillseq
fillsync

VII. R ELATED WORK
A. Systems & Databases on TEE
Existing
TEE
solutions
include
Intel
SGX,
TXT [12]/TPM [13], ARM TrustZone [2], IBM SCPU [10],
etc. Prior to SGX, there are TEE-based software systems
for database systems [24], [23], [20], key-management [76],
etc. Intel SGX adds architectural supports for more generic
execution in the secure world; these new features include
dynamical memory allocation, paging, and multi-core
execution. There are recently software systems built
on SGX, for big-data analytics [67], supporting legacy
applications [25], network management [70], distributed
multi-party computations [38]. A formal verification
technique is proposed to strengthen the security of enclave
programs [72].
In particular, Haven [25] supports generic legacy applications using SGX. The support is done by loading the entire
application software stack into enclave, and redirecting system
calls to the untrusted world. This design, while enabling
software compatibility, increases the in-enclave codebase to
a size (hundreds of thousands or millions of codelines) that it
can not be formally verified in an efficient way.
VC3 [67] supports MapReduce style big-data analytics on
SGX. It partitions the Hadoop software stack and places
only the user-defined mapper/reducer functions inside enclave,
thus resulting in a small and trusted codebase. However,
this approach to partitioning is specific to the MapReduce
framework and is not readily applicable to partitioning a keyvalue store system. Furthermore, VC3’s in-enclave verification

D. Frontend Performance
In this section, we characterize the performance of frontend query verification. One factor affecting performance is
the size of the proof. We consider the use of selected-level
proof (in Definition 4.2) as default in LPAD, and compare
the performance using it with that using the all-level proof (in
Definition 4.1). We also evaluate the performance of front-end
query processing without running any digest computations. It
allows studying the performance impact of world-switches to
online query performance. We use the unsecured LevelDB as
the same baseline. We re-run the LevelDB built-in benchmark
under the same configuration, and report the result in Table IV.
The trends are similar: All-Level always has the highest
normalized latency in all workloads, and the last workload
(“readrandom”) has the largest normalized latency in all tested
approaches. Compare approaches No MHT and LPAD: In
No MHT whose overhead is only introduced by SGX has a
less than 3X slowdown, while LPAD has a slowdown up to
15X. We suspect the use of MHT/SHA is the main culprit of
performance slowdown.
The result also shows the effectiveness of using the inter12

copy

baseline(unsecured)

1000

1000

copy
copy (no MHT)

800

non-copy
non-copy (no MHT)

600

naive-partition

400

baseline(unsecured)

1000
copy

800

copy (no MHT)
non-copy (no MHT)

600

naive-partition
baseline(unsecured)

400

Execution time (sec)

naive-partition

Execution time (sec)

Execution time (sec)

2

10

non-copy
non-copy (no MHT)

1500

1200

1200

copy (no MHT)

2000

Execution time (sec)

2500

copy

1

10

copy (no MHT)
non-copy
non-copy (no MHT)

500

200

200

naive-partition

0

10
0

4

0

6
8
10
12
Number of records per file (million)

(a) 5-way compaction and 8k buffer

3

5
7
Number of files

0

9

0.25

0.5

1
4
2
Buffer size (kbyte)

8

32

baseline(unsecured)

0

1

10
100
Record size (byte)

1000

(b) 63 million records and 8k buffer (c) 5-way compaction and 10 million(d) 5-way compaction and 600M data
records
size

Fig. 9: LPAD
works mainly for stateless batched computation, while our
work complements the VC3’s approach in supporting stateful
computations with storage.
CorrectDB [23] is a trusted database system that enables
correctness-verifiable SQL processing on IBM SCPU [10]. It
partitions an SQL query plan to the two worlds; the query
executed in the non-secure world is protected by using MHT,
and the query executed inside the secure world involves multidimensional data where the MHT can not handle efficiently.
Our T RUST KV shares the similar goal with CorrectDB in
placing code to the secure world only when it is necessary.
However, the target applications and systems are different, and
the techniques are orthogonal.
B. Storage Consistency Verification
Our system uses the notion of strong consistency to specify
the correctness of storage queries. Given the limited space, we
cannot completely survey the extensive body of consistency
research; instead, we focus on cloud storage consistency and
verification.
In the context of cloud storage, query linearizability [39]
requires the total order among reads and writes on a single
object (or a single key in a key-value store). Transactional
serializability [26] requires the same but for reads and writes
on different objects. Relaxed consistency levels [80], [64],
[81] and eventual consistency [31], have been proposed for
large-scale distributed storage in the cloud. In the eventual
consistency, the read can return an arbitrarily stale write
result as long as it “eventually” returns fresh data. In the
presence of multiple clients, a forking attack is the one that the
cloud can present different results to different clients, hence
“forking” client views. Fork consistency [49] specifies that
a client’s view can only be forked once. Without client-toclient communications, the fork consistency is the strongest
consistency level achievable in theory.
There is a body of research work on secure verification
of storage consistency under various specifications [66], [73],
[36], [43]. CloudProof [66] verifies the strong consistency in
both write-write linearizability and read-after-write freshness.
Caelus [43] verifies the weaker consistency models, such as
time-bounded eventual consistency. To verify the consistency
specification, the commonly adopted mechanism is by logging
the operation history by the hash chain and periodically auditing it. While it is effective in amortizing the verification cost, it
does not detect consistency violation in real-time. In addition,

execution time
it also assumes a trusted, third-party auditor collecting the
operation history from both the clients and the cloud. This
requires the client availability for auditing which might not
be realistic, particularly for ad-hoc mobile users. By contrast,
our work enables real-time consistency verification, does not
assume a client to be online other than the query time, and
can securely verify query consistency with efficiency.
Alternatively, read-after-write freshness can be verified by
MHTs [36], [73], [79] (with a trusted timestamp oracle). In
these approaches, the owner stores the root hash digesting
the remote MHT in the cloud [36], [73]. Upon data writes,
the owner needs to update the MHT by reading back relevant
authenticated information from the cloud before producing the
new root hash. Our work avoids the inefficiency of reading
digest upon writes, and inspired by the log-structured system
we apply the idea of append-only writes to the updating-MHT
problem.
Prior work based on trusted hardware [86], [45] addresses
the freshness verification problem. They tackle reliability
under faulty hardware and their approaches are complementary
to our work.
Venus [71] supports verifiable causal and eventual (strong)
consistency on untrusted storage. Venus assumes honest
clients, and for the purpose of setting up the ground truth of
consistency verification, a subset of clients that are always online. The put/get operations are concurrent and non-blocking,
with online causal consistency; an asynchronous callback is
needed to verify the (eventually) strong consistency through
client-to-client communication.
C. Log-Structured Merge Storage Systems
Given the recently renewed interest in LSM storage systems,
there is a body of researches on improving and applying
the LSM structures. To improve read performance on logstructured stores, bLSM [68] systematically model the LSM
tree performance, and organizes data into row-based storage
for serving row-based queries with less disk access. The compaction process is decomposed at finer granularity and is run
with costs carefully amortized to each write. Prior work [40]
partitions the LSM tree storage by keys to accommodate
the skewed key access popularity. The level sizes follow an
exponentially growing sequence, in a way to minimize write
amplification. In distributed key-value stores, compaction jobs
among multiple nodes are scheduled and coordinated for
better performance [16]. The LSM tree structure is applied

13

beyond disk-based storage: With a clear separation between
mutable and immutable structures, an LSM tree minimizes
storage overhead of dynamic data. This advantage enables
the memory-efficient design of LSM tree based main-memory
databases [89]. The LSM tree has also been applied to spatial
databases in the AsterixDB project [17]. cLSM [35] is an LSM
store supporting concurrent executions of put, get, snapshotscan and conditional-updates. Running with concurrent merge,
it supports non-blocking get and minimizes the blocking on
put using readers-write block. It is implemented as an addon to an LSM store by hooking among the three typical
components of the store (i.e. in-memory, on-disk and merge
components).

[17] S. Alsubaiee, A. Behm, V. R. Borkar, Z. Heilbron, Y. Kim, M. J. Carey,
M. Dreseler, and C. Li. Storage management in asterixdb. PVLDB,
7(10):841–852, 2014.
[18] A. Anagnostopoulos, M. T. Goodrich, and R. Tamassia. Persistent
authenticated dictionaries and their applications. In Information Security
ISC 2001, pages 379–393, 2001.
[19] I. Anati, S. Gueron, S. P. Johnson, and V. R. Scarlata. Innovative
technology for cpu based attestation and sealing.
[20] A. Arasu, S. Blanas, K. Eguro, R. Kaushik, D. Kossmann, R. Ramamurthy, and R. Venkatesan. Orthogonal security with cipherbase. In
CIDR 2013, Sixth Biennial Conference on Innovative Data Systems
Research, Asilomar, CA, USA, January 6-9, 2013, Online Proceedings,
2013.
[21] S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. Proof
verification and the hardness of approximation problems. J. ACM,
45(3):501–555, 1998.
[22] P. Bailis, S. Venkataraman, M. J. Franklin, J. M. Hellerstein, and
I. Stoica. Probabilistically bounded staleness for practical partial
quorums. PVLDB, 5(8):776–787, 2012.
VIII. C ONCLUSION
[23] S. Bajaj and R. Sion. Correctdb: SQL engine with practical query
We build a trustworthy key-value store with pragmatic
authentication. PVLDB, 6(7):529–540, 2013.
performance, for the data outsourcing to the public cloud. We [24] S. Bajaj and R. Sion. Trusteddb: A trusted hardware-based database
with privacy and data confidentiality. IEEE Trans. Knowl. Data Eng.,
specify the correctness of an LSM-tree based storage system
26(3):752–765, 2014.
by strong consistency on the frontend and the compaction [25] A. Baumann, M. Peinado, and G. C. Hunt. Shielding applications
from an untrusted cloud with haven. In 11th USENIX Symposium on
specification on the backend for data maintenance. Against
Operating Systems Design and Implementation, OSDI ’14, Broomfield,
the local attacks in the cloud, these properties are made
CO, USA, October 6-8, 2014., pages 267–283, 2014.
securely verifiable by the combined use of Merkle hash tree [26] P. A. Bernstein, V. Hadzilacos, and N. Goodman. Concurrency Control
and Intel SGX. The Merkle hash tree is used for verifiable
and Recovery in Database Systems. Addison-Wesley, 1987.
freshness and strong-consistency of query serving. Intel SGX, [27] D. Boneh and D. M. Freeman. Homomorphic signatures for polynomial
functions. In Advances in Cryptology - EUROCRYPT 2011 - 30th
the first commodity hardware for trusted execution, is used for
Annual International Conference on the Theory and Applications of
the verifiable data-maintenance jobs with close proximity to
Cryptographic Techniques, Tallinn, Estonia, May 15-19, 2011. Proceedings, pages 149–168, 2011.
data. The use of trusted execution environment for verifiable
[28] B. Braun, A. J. Feldman, Z. Ren, S. T. V. Setty, A. J. Blumberg, and
maintenance is necessary, and we made our trusted codebase
M. Walfish. Verifying computations with state. In ACM SIGOPS 24th
small and likely to be minimal. We analyze the security of
Symposium on Operating Systems Principles, SOSP ’13, Farmington,
PA, USA, November 3-6, 2013, pages 341–357, 2013.
our design and implement it on LevelDB with SHA1/3 for
[29] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A. Wallach, M. BurMerkle hash tree. We evaluate the performance overhead and
rows, T. Chandra, A. Fikes, and R. Gruber. Bigtable: A distributed
demonstrate near-practical efficiency.
storage system for structured data (awarded best paper!). In OSDI,
pages 205–218, 2006.
[30] W. Cheng, H. Pang, and K.-L. Tan. Authenticating multi-dimensional
ACKNOWLEDGEMENT
query results in data publishing. In Proceedings of the 20th IFIP
The authors would like to thank Dr. Heng Yin, Scott D.
WG 11.3 Working Conference on Data and Applications Security,
DBSEC’06, pages 60–73, Berlin, Heidelberg, 2006. Springer-Verlag.
Constable, Amin Fallahi for the helpful discussion to this
[31] G. DeCandia, D. Hastorun, M. Jampani, G. Kakulapati, A. Lakshman,
work.
A. Pilchin, S. Sivasubramanian, P. Vosshall, and W. Vogels. Dynamo:
amazon’s highly available key-value store. In Proceedings of the 21st
R EFERENCES
ACM Symposium on Operating Systems Principles 2007, SOSP 2007,
Stevenson, Washington, USA, October 14-17, 2007, pages 205–220,
[1] Apple icloud: www.apple.com/icloud/.
[2] Arm trustzone, http://www.arm.com/products/processors/technologies/trustzone/. 2007.
[32] P. Devanbu, M. Gertz, C. Martel, and S. G. Stubblebine. Authentic data
[3] Dropbox: www.dropbox.com.
publication over the internet. Journal of Computer Security, 11:2003,
[4] Google cloud storage: cloud.google.com/storage.
2003.
[5] Hbase coprocessor: blogs.apache.org/hbase/entry/coprocessor introduction.
[33] R. Elbaz, D. Champagne, C. H. Gebotys, R. B. Lee, N. R. Potlapally, and
[6] http://cassandra.apache.org/.
L. Torres. Hardware mechanisms for memory authentication: A survey
[7] http://code.google.com/p/leveldb/.
of existing techniques and engines. Trans. Computational Science, 4:1–
[8] http://hbase.apache.org/.
22, 2009.
[9] https://aws.amazon.com/s3/.
[34] R. Geambasu, T. Kohno, A. A. Levy, and H. M. Levy. Vanish: Increasing
[10] Ibm scpu, http://www-03.ibm.com/security/cryptocards/.
data privacy with self-destructing data. In 18th USENIX Security
[11] Intel corp. software guard extensions programming reference, 2014 no.
Symposium, Montreal, Canada, August 10-14, 2009, Proceedings, pages
329298-002.
299–316, 2009.
[12] Intel txt, http://www.intel.com/technology/security/ downloads/trust[35] G. Golan-Gueta, E. Bortnikov, E. Hillel, and I. Keidar. Scaling
edexec overview.pdf.
concurrent log-structured data stores. In Proceedings of the Tenth
[13] Tpm, http://www.trustedcomputinggroup.org/tpm-main-specification/.
European Conference on Computer Systems, EuroSys 2015, Bordeaux,
[14] Write-optimized
consistency
verification
in
France, April 21-24, 2015, pages 32:1–32:14, 2015.
cloud
storage
with
minimal
trust,
full
version,
https://drive.google.com/open?id=0B749HX0RkgQHLVRSczA0dEtvRUk . [36] M. T. Goodrich, C. Papamanthou, R. Tamassia, and N. Triandopoulos.
Athos: Efficient authentication of outsourced file systems. In ISC, pages
[15] S. Agrawal and D. Boneh. Homomorphic macs: Mac-based integrity
80–96, 2008.
for network coding. In Applied Cryptography and Network Security,
7th International Conference, ACNS 2009, Paris-Rocquencourt, France,
[37] M. T. Goodrich, R. Tamassia, and A. Schwerin. Implementation of an
June 2-5, 2009. Proceedings, pages 292–305, 2009.
authenticated dictionary with skip lists and commutative hashing. In
[16] M. Y. Ahmad and B. Kemme. Compaction management in distributed
DARPA Information Survivability Conference & Exposition II, 2001.
key-value datastores. PVLDB, 8(8):850–861, 2015.
DISCEX’01. Proceedings, volume 2, pages 68–82. IEEE, 2001.

14

[61] C. Papamanthou, R. Tamassia, and N. Triandopoulos. Authenticated hash tables based on cryptographic accumulators. Algorithmica,
74(2):664–712, 2016.
[62] B. Parno, J. Howell, C. Gentry, and M. Raykova. Pinocchio: Nearly
practical verifiable computation. In 2013 IEEE Symposium on Security
and Privacy, SP 2013, Berkeley, CA, USA, May 19-22, 2013, pages
238–252, 2013.
[63] B. Parno, J. R. Lorch, J. R. Douceur, J. W. Mickens, and J. M. McCune.
Memoir: Practical state continuity for protected modules. In 32nd
IEEE Symposium on Security and Privacy, S&P 2011, 22-25 May 2011,
Berkeley, California, USA, pages 379–394, 2011.
[64] K. Petersen, M. Spreitzer, D. B. Terry, M. Theimer, and A. J. Demers.
Flexible update propagation for weakly consistent replication. In
Proceedings of the Sixteenth ACM Symposium on Operating System
Principles, SOSP 1997, St. Malo, France, October 5-8, 1997, pages
288–301, 1997.
[65] R. A. Popa, F. H. Li, and N. Zeldovich. An ideal-security protocol for
order-preserving encoding. In 2013 IEEE Symposium on Security and
Privacy, SP 2013, Berkeley, CA, USA, May 19-22, 2013, pages 463–477,
2013.
[66] R. A. Popa, J. R. Lorch, D. Molnar, H. J. Wang, and L. Zhuang. Enabling
security in cloud storage slas with cloudproof. In Proceedings of the
2011 USENIX Conference on USENIX Annual Technical Conference,
USENIXATC’11, pages 31–31, Berkeley, CA, USA, 2011. USENIX
Association.
[67] F. Schuster, M. Costa, C. Fournet, C. Gkantsidis, M. Peinado, G. MainarRuiz, and M. Russinovich. VC3: trustworthy data analytics in the cloud
using SGX. In 2015 IEEE Symposium on Security and Privacy, SP
2015, San Jose, CA, USA, May 17-21, 2015, pages 38–54, 2015.
[68] R. Sears and R. Ramakrishnan. blsm: a general purpose log structured
merge tree. In K. S. Candan, Y. Chen, R. T. Snodgrass, L. Gravano, and
A. Fuxman, editors, Proceedings of the ACM SIGMOD International
Conference on Management of Data, SIGMOD 2012, Scottsdale, AZ,
USA, May 20-24, 2012, pages 217–228. ACM, 2012.
[69] S. T. V. Setty, B. Braun, V. Vu, A. J. Blumberg, B. Parno, and
M. Walfish. Resolving the conflict between generality and plausibility
in verified computation. In Eighth Eurosys Conference 2013, EuroSys
’13, Prague, Czech Republic, April 14-17, 2013, pages 71–84, 2013.
[70] M. Shih, M. Kumar, T. Kim, and A. Gavrilovska. S-NFV: securing
NFV states by using SGX. In Proceedings of the 2016 ACM International Workshop on Security in Software Defined Networks & Network
Function Virtualization, SDN-NFV@CODASPY 2016, New Orleans, LA,
USA, March 11, 2016, pages 45–48, 2016.
[71] A. Shraer, C. Cachin, A. Cidon, I. Keidar, Y. Michalevsky, and
D. Shaket. Venus: verification for untrusted cloud storage. In Proceedings of the 2nd ACM Cloud Computing Security Workshop, CCSW
2010, Chicago, IL, USA, October 8, 2010, pages 19–30, 2010.
[72] R. Sinha, S. K. Rajamani, S. A. Seshia, and K. Vaswani. Moat:
Verifying confidentiality of enclave programs. In Proceedings of the
22nd ACM SIGSAC Conference on Computer and Communications
Security, Denver, CO, USA, October 12-6, 2015, pages 1169–1184,
2015.
[73] E. Stefanov, M. van Dijk, A. Juels, and A. Oprea. Iris: a scalable cloud
file system with efficient integrity checks. In ACSAC, pages 229–238,
2012.
[74] R. Strackx, B. Jacobs, and F. Piessens. ICE: a passive, high-speed,
state-continuity scheme. In Proceedings of the 30th Annual Computer
Security Applications Conference, ACSAC 2014, New Orleans, LA, USA,
December 8-12, 2014, pages 106–115, 2014.
[75] R. Strackx and F. Piessens. Ariadne: A minimal approach to state
continuity. In 25th USENIX Security Symposium, USENIX Security 16,
Austin, TX, USA, August 10-12, 2016., pages 875–892, 2016.
[76] H. Sun, K. Sun, Y. Wang, and J. Jing. Trustotp: Transforming
smartphones into secure one-time password tokens. In Proceedings of
the 22nd ACM SIGSAC Conference on Computer and Communications
Security, Denver, CO, USA, October 12-6, 2015, pages 976–988, 2015.
[77] R. Tamassia. Authenticated data structures. In Algorithms - ESA 2003,
11th Annual European Symposium, Budapest, Hungary, September 1619, 2003, Proceedings, pages 2–5, 2003.
[78] Y. Tang. On the impossibility of merkle merge homomorphism. IACR
Cryptology ePrint Archive, 2016:617, 2016.
[79] Y. Tang, T. Wang, L. Liu, X. Hu, and J. Jang. Lightweight authentication
of freshness in outsourced key-value stores. In Proceedings of the 30th
Annual Computer Security Applications Conference, ACSAC 2014, New
Orleans, LA, USA, December 8-12, 2014, pages 176–185, 2014.

[38] D. Gupta, B. Mood, J. Feigenbaum, K. Butler, and P. Traynor. Using
intel software guard extensions for efficient two-party secure function
evaluation. In Financial Cryptography and Data Security, 2016.
[39] M. Herlihy and J. M. Wing. Linearizability: A correctness condition for
concurrent objects. ACM Trans. Program. Lang. Syst., 12(3):463–492,
1990.
[40] C. M. Jermaine, E. Omiecinski, and W. G. Yee. The partitioned
exponential file for database storage management. VLDB J., 16(4):417–
437, 2007.
[41] N. Karapanos, A. Filios, R. A. Popa, and S. Capkun. Verena: End-toend integrity protection for web applications. In IEEE Symposium on
Security and Privacy, SP 2016, San Jose, CA, USA, May 22-26, 2016,
pages 895–913, 2016.
[42] J. Katz and Y. Lindell. Introduction to Modern Cryptography. Chapman
and Hall/CRC Press, 2007.
[43] B. H. Kim and D. Lie. Caelus: Verifying the consistency of cloud
services with battery-powered devices. In 2015 IEEE Symposium on
Security and Privacy, SP 2015, San Jose, CA, USA, May 17-21, 2015,
pages 880–896, 2015.
[44] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song.
Code-pointer integrity. In 11th USENIX Symposium on Operating
Systems Design and Implementation, OSDI ’14, Broomfield, CO, USA,
October 6-8, 2014., pages 147–163, 2014.
[45] D. Levin, J. R. Douceur, J. R. Lorch, and T. Moscibroda. Trinc: Small
trusted hardware for large distributed systems. In Proceedings of the 6th
USENIX Symposium on Networked Systems Design and Implementation,
NSDI 2009, April 22-24, 2009, Boston, MA, USA, pages 1–14, 2009.
[46] F. Li, M. Hadjieleftheriou, G. Kollios, and L. Reyzin. Dynamic
authenticated index structures for outsourced databases. In SIGMOD
Conference, pages 121–132, 2006.
[47] J. Li, M. N. Krohn, D. Mazières, and D. Shasha. Secure untrusted data
repository (sundr). In OSDI, pages 121–136, 2004.
[48] C. Martel, G. Nuckolls, P. Devanbu, M. Gertz, A. Kwong, and S. G.
Stubblebine. A general model for authenticated data structures. Algorithmica, 39(1):21–41, Jan. 2004.
[49] D. Mazières and D. Shasha. Building secure file systems out of byantine
storage. In Proceedings of the Twenty-First Annual ACM Symposium on
Principles of Distributed Computing, PODC 2002, Monterey, California,
USA, July 21-24, 2002, pages 108–117, 2002.
[50] M. S. Melara, A. Blankstein, J. Bonneau, E. W. Felten, and M. J.
Freedman. CONIKS: bringing key transparency to end users. In 24th
USENIX Security Symposium, USENIX Security 15, Washington, D.C.,
USA, August 12-14, 2015., pages 383–398, 2015.
[51] R. C. Merkle. A certified digital signature. In Proceedings on Advances
in Cryptology, CRYPTO ’89, 1989.
[52] E. Mykletun, M. Narasimha, and G. Tsudik. Signature bouquets:
Immutability for aggregated/condensed signatures. In Computer Security
- ESORICS 2004, 9th European Symposium on Research Computer
Security, Sophia Antipolis, France, September 13-15, 2004, Proceedings,
pages 160–176, 2004.
[53] E. Mykletun, M. Narasimha, and G. Tsudik. Authentication and integrity
in outsourced databases. Trans. Storage, 2(2):107–138, May 2006.
[54] M. Narasimha and G. Tsudik. Dsac: integrity for outsourced databases
with signature aggregation and chaining. In Proceedings of the 14th
ACM international conference on Information and knowledge management, CIKM 2005, pages 235–236, New York, NY, USA, 2005. ACM.
[55] P. E. O’Neil, E. Cheng, D. Gawlick, and E. J. O’Neil. The log-structured
merge-tree (lsm-tree). Acta Inf., 33(4):351–385, 1996.
[56] H. Pang, A. Jain, K. Ramamritham, and K. Tan. Verifying completeness
of relational query results in data publishing. In Proceedings of the ACM
SIGMOD International Conference on Management of Data, Baltimore,
Maryland, USA, June 14-16, 2005, pages 407–418, 2005.
[57] H. Pang and K.-L. Tan. Authenticating query results in edge computing. In Proceedings of the 20th International Conference on Data
Engineering, ICDE ’04, pages 560–, Washington, DC, USA, 2004. IEEE
Computer Society.
[58] H. Pang, J. Zhang, and K. Mouratidis. Scalable verification for
outsourced dynamic databases. PVLDB, 2(1):802–813, 2009.
[59] S. Papadopoulos, Y. Yang, and D. Papadias. Cads: Continuous authentication on data streams. In VLDB, pages 135–146, 2007.
[60] C. Papamanthou, R. Tamassia, and N. Triandopoulos. Authenticated
hash tables. In Proceedings of the 2008 ACM Conference on Computer
and Communications Security, CCS 2008, Alexandria, Virginia, USA,
October 27-31, 2008, pages 437–448, 2008.

15

[80] D. B. Terry, V. Prabhakaran, R. Kotla, M. Balakrishnan, M. K. Aguilera,
Operation 2) does not violate the invariant in Theorem 3.3.
and H. Abu-Libdeh. Consistency-based service level agreements for
As by Invariant 3.2, a compaction moves records in a concloud storage. In ACM SIGOPS 24th Symposium on Operating Systems
secutive time range from a lower-numbered level to a higherPrinciples, SOSP ’13, Farmington, PA, USA, November 3-6, 2013, pages
309–324, 2013.
numbered one. W.l.o.g., consider the records (of key k) being
[81] D. B. Terry, M. Theimer, K. Petersen, A. J. Demers, M. Spreitzer, and
moved are hk, v0 , tsi, hk, v1 , tsi, . . . , hk, vl , tsi, . . . . They are
C. Hauser. Managing update conflicts in bayou, a weakly connected
moved from level Ci to level Ci+1 . Now ∀hk, v, tsi@Cj from
replicated storage system. In Proceedings of the Fifteenth ACM Symthe overall dataset but the moved records, and ∀hk, v, ts′ i@Ci
posium on Operating System Principles, SOSP 1995, Copper Mountain
Resort, Colorado, USA, December 3-6, 1995, pages 172–183, 1995.
in the prestate. Consider two cases: A) j = i. In this case,
[82] S. Torres-Arias, A. K. Ammula, R. Curtmola, and J. Cappos. On
the record hk, v, tsi will stay after in Ci after the compaction
omitting commits and committing omissions: Preventing git metadata
tampering that (re)introduces software vulnerabilities. In 25th USENIX only when its timestamp falls outside the consecutive range
Security Symposium, USENIX Security 16, Austin, TX, USA, August 10of those moved records, that is, ts smaller than the timestamp
12, 2016., pages 379–395, 2016.
of any moving records, hence ts < ts′ . B) j 6= i. In this case,
[83] R. S. Wahby, S. T. V. Setty, Z. Ren, A. J. Blumberg, and M. Walfish.
if j = i + 1, then it is irrelevant to Theorem 3.3 after the
Efficient RAM and control flow in verifiable outsourced computation.
In 22nd Annual Network and Distributed System Security Symposium,
compaction. If j < i or j > i + 1, then the moving has no
NDSS 2015, San Diego, California, USA, February 8-11, 2014, 2015.
effect on their level ordering before/after compaction, that is,
[84] S. Wolchok, O. S. Hofmann, N. Heninger, E. W. Felten, J. A. Halderman,
if j < i before compaction, then j < i + 1 after compaction.
C. J. Rossbach, B. Waters, and E. Witchel. Defeating vanish with lowcost sybil attacks against large dhts. In Proceedings of the Network
If j > i + 1 > i before compaction, then j > i + 1 after
and Distributed System Security Symposium, NDSS 2010, San Diego,
compaction. Therefore, the theorem always holds.
California, USA, 28th February - 3rd March 2010, 2010.
[85] Y. Xu, W. Cui, and M. Peinado. Controlled-channel attacks: DeterA PPENDIX B
ministic side channels for untrusted operating systems. In 2015 IEEE
Symposium on Security and Privacy, SP 2015, San Jose, CA, USA, May
C ONSISTENCY C HECKING
17-21, 2015, pages 640–656, 2015.
[86] H.-J. Yang, V. Costan, N. Zeldovich, and S. Devadas. Authenticated 1 class store_wrapper{
storage using small trusted hardware. In CCSW, pages 35–46, 2013. 2
Store store;
[87] Y. Yang, D. Papadias, S. Papadopoulos, and P. Kalnis. Authenticated 3
Att Put(key,val){
prePut(key,val);
join processing in outsourced databases. In U. Çetintemel, S. B. Zdonik, 4
att(tsw)=store.dPut(key,val);
D. Kossmann, and N. Tatbul, editors, Proceedings of the ACM SIGMOD 5
return postPut(key,val,att(tsw));
International Conference on Management of Data, SIGMOD 2009, 6
}
Providence, Rhode Island, USA, June 29 - July 2, 2009, pages 5–18. 7
8
Crt Get(key){
ACM, 2009.
9
preGet(<key>);
[88] Y. Yang, S. Papadopoulos, D. Papadias, and G. Kollios. Authenticated 10
<key,val>,pf(tsrw,tsr*)=store.dGet(key);
indexing for outsourced spatial databases. VLDB J., 18(3):631–648, 11
return postGet(<key>,pf(tsrw,tsr*));
12
}
2009.
[89] H. Zhang, D. G. Andersen, A. Pavlo, M. Kaminsky, L. Ma, and R. Shen.13
mutex State pending_wr, completed_wr,history_w;
Reducing the storage overhead of main-memory OLTP databases with14
hybrid indexes. In Proceedings of the 2016 International Conference on15
16
void prePut(<key,val>){
Management of Data, SIGMOD Conference 2016, San Francisco, CA,17
pending_wr.add(<key,val,start_rt=now()>);
USA, June 26 - July 01, 2016, pages 1567–1581, 2016.
18
}
[90] Y. Zhang, J. Katz, and C. Papamanthou. Integridb: Verifiable SQL19
boolean postPut(<key,val>,att(tsw)){
<key,val,start_rt>=pending_wr.remove(key,tsr);
for outsourced databases. In Proceedings of the 22nd ACM SIGSAC20
completed_wr.addW(<key,val,start_rt,end_rt=now(),tsw>);
Conference on Computer and Communications Security, Denver, CO,21
22
ac1 = completed_wr.tryTruncate();
USA, October 12-6, 2015, pages 1480–1491, 2015.

A PPENDIX A
P ROOF OF T HEOREM
We present the proof for Theorem 3.3.

23
24
25
26
27
28
29
30
31
Theo-32
i < j,33
34
by one35

if(ac1 != NULL){
assertC(acl);
if(assertOrdered(acl,history_w))
history_w.merge(acl);
}

}
void preGet(key){
pending_wr.add(<key,start_rt=now()>);
}
boolean postGet(r<key,val,tsrw,tsr,pf(tsrw,tsr*)>){
r<key,start_rt>=pending_wr.remove();
if(r.tsr <= history_w.latest());
assertL2(r<key,val,tsr,tsrw,pf(tsrw,tsr*)>,history_w)
;
else
completed_wr.addR(<key,val,start_rt,end_rt=now(),tsr,
tsrw>);
}

Proof Consider the initial system state satisfying
rem 3.3, that is, ∀hk, tsi@Ci 11 and hk, ts′ i@Cj with
then ts > ts′ . The system state can only be mutated
of the two operations: 1) a Put that mutates list C0 ; and 2) a36
compaction that moves records from a lower-numberd list to37
a higher-numbered one. Since the theorem is about records of38
a single key, all the records we consider is of the same key k.39 }
Operation 1) does not violate the invariant in Theorem 3.3,
Listing 2: Interfaces of verified and verifiable Put/Get
because of the following: After the Put, assume the new record
inserted is hk, v, ts′′ i@C0 . Given it is the newest record with
Our linearizability checking algorithm works by adaptively
largest timestamp ts′′ , for any record picked from non-zero finding the operations that can form a consecutive segment
level, say hk, v, ts′′′ i@Ci>0 , it will hold: i > 0 and ts′′ > ts′′′ . with serialized operations, checking the consistency conditions
Theorem 3.3 holds after Operation 1).
on this segment, and then merging the segment into the serialized operations. The correctness of our algorithm depends
11 We use hk, tsi@C to denote record hk, tsi resides in level C .
on the following intuition: Given two consecutive operation
i
i
16

sets, if L1 holds on both of them, then L holds on the merged
segment from them. Formally,
Definition B.1: Real-time partial-order ≺ is a relation in a
set of operations l. An operation, say o, has two attributes:
invocation time inv(o) and response time resp(o) > inv(o).
Given two operations o1 , o2 ∈ l, o1 ≺ o2 when resp(o1 ) <
inv(o2 ).
Definition B.2 (Linearizability): Given a set of operations,
l, and real-time partial order ≺, if there exist a total order <
among the operations such that:
1. Real-time L1: the real-time partial order is consistent
with total-order, that is, ∀o1 , o2 ∈ l, if o1 ≺ o2 , then o1 < o2 .
We denote it by L1(l, ≺) = T RU E
2. Freshness (or legality as in [39]) L2: any read operation
returns the latest write in the total order.
Definition B.3 (Ordered operation sets): Assuming all operations are defined on a total-order <. Two operation sets, say
l1 and l2 , are ordered when all the operations of l1 are larger
than those of l2 , or when all the operations of l1 are smaller
than those of l2 .
Operation set, say l1 , is smaller than operation set l2 ,
denoted by l1 <′ l2 , if and only if the smallest operation in
l2 (based on the total order < of l2 ) is larger than the largest
operation in l1 .
Theorem B.4: Given two ordered operation sets, if L1 holds
separately on them, then L holds on the merged set from
them. That is, if L1(l1 ) = T U RE&&L1(l2) = T U RE, then
L1(l1 ∪ l2 ) = T U RE.
∀o1 , o2 ∈ l1 ∪ l2 , if o1 ≺ o2 , then o1 < o2 .
Proof We consider the non-trivial case that ∀o1 ∈ l1 , and
∀o2 ∈ l2 . Without loss of generality, assume o1 ≺ o2 .
Then resp(o1 ) < inv(o2 ) < resp(o2 ). If l1 < l2 , it requires
resp(o1 ) > resp(o2 ) which contradicts o1 ≺ o2 . Thus, l1 <′
l2 .
Because l1 <′ l2 , o1 ∈ l1 , and o2 ∈ l2 , we have o1 < o2 .
That is, ∀o1 ≺ o2 , we have o1 , o2 . Thus the theorem holds.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

void assertC(ac1,history_w){
//L1
o0<key,val,ts> = history_w.latest();
o1<key,val,ts> = ac1.oldest();
do {
assertL1pairwise(o0<key,val,ts>,o1<key,val,ts>);
o0=o1; o1=o1.next(ac1);
} while (o1 != NULL)
//L2
for (read r in ac1)
assertL2(r<key,val,tsr,tsrw,pf(tsrw,tsr*)>,history_w);
}
void assertL2(r<key,val,tsr,tsrw,pf(tsrw,tsr*)>,history_w){
assert(r.tsr <= history_w.latest());
assert(verify(pf(tsrw,tsr*))==true);
assert(tsr*==tsr);
}

Listing 3: Linearizability checking

17

Checking Intent-based Communication in Android with
Intent Space Analysis
Yiming Jing† , Gail-Joon Ahn† , Adam Doupé† , and Jeong Hyun Yi‡
†

Arizona State University

‡

Soongsil University

{ymjing,gahn,doupe}@asu.edu, jhyi@ssu.ac.kr

ABSTRACT

A type of messaging objects called intents build a major
and sophisticated inter-application communication mechanism in Android [13]. Intents are flexible as they can carry
simple data and even inter-process communication primitives (e.g. Binder [2] and file descriptors [3]). Moreover, the
intent attributes are rich with Android middleware semantics, which naturally facilitate access control decisions [12,
29]. As a result, the security community proposed plenty
of security extensions that implement policy-driven mandatory access control (MAC) for intent-based communication
[7,10–12,21,26,27,29,32,38]. Indeed, intents are not the only
inter-application mechanism in Android. The recent MAC
implementations [7,12,32] adopt derivations of SELinux kernel MAC to cover the other Android mechanisms such as
files, sockets, and Binder. However, intents are out of the
scope of kernel MAC due to the incompatible semantics of
the kernel and middleware layers [12].
Defining and verifying the policy for each individual security extension that controls intent-based communication
is a complex task for a policy analyst. The recent emerging security requirements, such as “bring your own device”
(BYOD), call for fine-grained and precise policies. For example, a single mobile device may host a doctor’s personal apps
and the apps of several clinics. The doctor and the clinics
would require that the deployed security policies accurately
enforce the boundaries between the apps of the respective
stakeholders. Meanwhile, mitigating existing threats related
to intents such as communication hijacking [13], confused
deputy attacks [10, 19], and accidental data disclosure [26]
requires that policies are tailored to the peculiarities of each
threat and each vulnerable app.
Furthermore, the complexity significantly increases when
intent-based communication is mediated by multiple collaborating security extensions that enforce their respective security polices. First, the security extensions define incompatible schemes, logic, and semantics for their policies. Second, the policies that determine how intents are processed
and forwarded among apps are distributed across multiple
security extensions. Moreover, the policies are stored and
updated in a dynamic manner due to frequent app installs,
uninstalls, and upgrades. As a consequence, a policy analyst
must manually inspect every security extension’s policy, aggregate them into a holistic view, and search for violation of
security properties. Overall, policy verification becomes an
error-prone and tedious task that requires great sophistication from the policy analyst. This leads to slow adoption of
Android security extensions despite that quite a few modern
security extensions have been proposed recently.

Intent-based communication is an inter-application communication mechanism in Android. While its importance has
been proven by plenty of security extensions that protect it
with policy-driven mandatory access control, an overlooked
problem is the verification of the security policies. Checking one security extension’s policy is indeed complex. Furthermore, intent-based communication introduces even more
complexities because it is mediated by multiple security extensions that respectively enforce their own incompatible,
distributed, and dynamic policies.
This paper seeks a systematic approach to address the
complexities involved in checking intent-based communication. To this end, we propose intent space analysis. Intent
space analysis formulates the intent forwarding functionalities of security extensions as transformations on a geometric
intent space. We further introduce a policy checking framework called IntentScope that proactively and automatically
aggregates distributed policies into a holistic and verifiable
view. We evaluate our approach against customized Android OSs and commodity Android devices. In addition, we
further conduct experiments with four security extensions
to demonstrate how our approach helps identify potential
vulnerabilities in each extension.

1. INTRODUCTION
Modern mobile operating systems have shifted into a security architecture that is fundamentally different from those
of traditional desktop OSs. Mobile applications (commonly
referred to as apps) run as unique security principles; they
are isolated in their respective sandboxes and receive few
privileges. Despite that apps are isolated, they interoperate
through inter-application communication. As such, a few
apps, whose workflows are directed by a user, can accomplish complex and diversified tasks. For example, an email
client exports a picture file to a photo editor; the photo editor modifies the picture and posts it online through a social
network client.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

ASIA CCS ’16, May 30-June 03, 2016, Xi’an, China
© 2016 ACM. ISBN 978-1-4503-4233-9/16/05. . . $15.00
DOI: http://dx.doi.org/10.1145/2897845.2897904

1

2.

To effectively address the complexities of checking intentbased communication, we argue for the need of a general,
holistic, and proactive policy checking framework that analyzes the incompatible, distributed, and dynamic intentbased communication policies in Android. In particular, the
framework automatically aggregates the policies and generates a holistic view that lends itself well for formal verification. The tools that currently exist are dependent and
specialized to each security extension. For example, EASEAndroid [33] and SETools [4] are tailored to SEAndroid and
SELinux. To the best of our knowledge, we propose the first
tool to holistically check multiple security extensions.
This paper proposes intent space analysis to address the
complexities in checking intent-based communication. Intent space analysis is built upon a geometric intent space
model. In this model, we propose to represent intents with
a K-dimensional space of regular languages, in which each
dimension corresponds to an intent attribute. As such, an
intent maps to a point in the space, multiple intents map to
a subspace, and security extensions are modeled as transfer
functions that map one subspace to another. For example,
a security extension that denies any intent can be modeled
as a transfer function that maps all K attribute values (denoted as {.∗}K ) to an empty space regardless of source or
destination apps.
We further propose a policy checking framework, called
IntentScope. Given an Android device, IntentScope acquires and parses the live intent forwarding states of each security extension that controls intents. Afterwards, IntentScope automatically instantiates transfer functions from
the acquired states. By composing the transfer functions,
IntentScope constructs a snapshot of the holistic intent
forwarding state as a graph whose vertices correspond to
apps and whose edges correspond to system-allowed intents
(as intent spaces) between apps. The graph supports flexible
queries and facilitates novel security assessment tasks such
as checking domain isolation, enumerating UI workflows [26],
and discovering permission re-delegation paths [19].
This paper makes the following main contributions:

BACKGROUND

In this section, we first discuss the background of intentbased communication in Android. We then present the problem description of this work.

2.1

Intent-based Communication

Components are the basic building blocks of Android apps.
There are four types of components, and each type serves a
specific purpose:
• Activities: An activity represents the user interface.
• Services: A service has no user interface and runs in
the background for time-consuming operations.
• Content providers: A content provider exposes an
app’s data as tables and supports basic operations such
as insert, delete, and update.
• Broadcast receivers: A broadcast receiver is triggered upon system or application events.
A component can be exported to other apps. Each exported component of an app is an entry point for intents
through which the other apps or the Android system can
send intents. Typically, an app exports its components to
other apps by statically declaring the exports in the app’s
manifest1 . However, an app can also dynamically create and
export components in its code. Two system services, PackageManagerService (PMS) and ActivityManagerService (AMS),
maintain the information about each installed app’s components regardless of how the components are exported—either
statically or dynamically.
Intents can connect an app’s component to exported components. An app creates an intent and sets its embedded attributes. The intent is then processed by the Android system
and the security extensions, which automatically resolve an
intent’s recipients based on the following intent attributes:
• Component name: This attribute explicitly specifies
the expected recipient of the intent.
• Action: This attribute describes the general action
to be taken by a recipient component, such as PICK,
VIEW, EDIT, or SHARE.
• Scheme: This attribute describes the protocol that
serves the data, such as http, mailto, or tel.
• Authority: This attribute describes the location of
the data, such as www.google.com or paypal.
• Type: This attribute describes the MIME type of the
data, such as audio/ogg, video/*, or */*. Note that
wildcards are allowed.
• Category: This attribute provides additional information about the data. For example, a category BROWSABLE implies the data that can be opened in a web
browser, such as a link to an image.

• We propose an intent space model for modeling intentbased inter-application communication in Android. Our
intent space model is general and independent of specific security extensions.
• We propose IntentScope, a general, holistic, and proactive policy checking framework for intent-based communication. IntentScope reasons about a holistic
graph derived from the live intent forwarding states
maintained by multiple security extensions in an Android device.
• We implement a prototype of IntentScope and evaluate it against mainstream security extensions, commodity Android devices, and customized Android OSs.
We also showcase a series of novel analysis tasks that
help a policy analyst discover weak points in policies.

Two types of intents exist in Android. Explicit intents
specify the component name only. Android delivers an explicit intent directly to its specified component regardless of
the presence of any other attributes. Implicit intents specify the attributes other than component name. Thus, an
implicit intent’s recipients are implicit and must be resolved
at intent-sending time; Android must search the registered
components to resolve the recipient components.

The remainder of this paper proceeds as follows. Section 2 provides the background and problem description of
our work. Section 3 describes our intent space model. Section 4 introduces IntentScope and describes its system design followed by experimental results in Section 5. Section 6
discusses limitations and future work. Section 7 overviews
related work. Section 8 concludes this paper.

1
The manifest is a required XML file included in the app by
the developer.

2

T1()

2.2 Problem Description
Intent-based inter-application communication has received
much research attention. In general, two aspects are covered: previously unknown security limitations of intents [10,
13, 15, 19, 25] and generic policy-driven security extensions
that remedy the limitations [7, 10–12, 21, 26, 27, 29, 32, 38].
However, there is an overlooked gap between configuring
generic security extensions and securing a specific Android
device. Every app, every device, and every user are different.
A policy analyst needs insights about intent-based communication before she can accurately define how the apps in her
device communicate through intents in her intended ways.
To bridge the gap, we seek a systematic approach for a policy
analyst to conveniently acquire such insights.
Intent-based communication is mediated by multiple security extensions. While multiple security extensions promote the flexibility of controlling intent-based communication, they also introduce new challenges in definition and
verification of their policies.
C-1: Incompatible policies. The security extensions define
their own incompatible schemas and semantics. For example, FlaskDroid [12] inherits SELinux’s policy semantics of
type enforcement. Saint [29] uses an XACML-like schema
customized by the authors. IntentFirewall’s policy is unique
and unlike the other security extensions, however it specifies a critical set of tests on intent attributes. As far as we
know, no existing policy checker can work with every extension’s policy. Therefore, checking such incompatible policies
remain a manual process that requires a policy analyst to
master the details of every security extension.
C-2: Local policies. Each security extension manages a local
view of system-wide policies. For example, IntentFirewall
enforces its centralized policy specified by a policy administrator; intent filters manages policies specified by decentralized apps but enforce the policy in a centralized manner.
Each security extension makes its decision by itself and is
not aware of the other security extensions. No security extension possesses a holistic view of the reachability among
installed apps as controlled by all the security extensions.
Problem Statement. To address the challenges in checking intent-base communication, we seek to build: a) a general policy checker that easily adapts to the policy schema
of any security extension that controls intents; b) a proactive policy checker that keeps monitoring the live intent forwarding states of security extensions; and c) a holistic policy checker that aggregates the policies into a holistic and
verifiable view. With the policy checker, we attempt to systematically answer the following two questions regardless of
specific security extensions, apps, or devices: a) what intents can an app send to a specific app; and b) what intents
can an app receive from a specific app. Meanwhile, we expect the checker to be mostly automated so as to reduce the
burden on policy analysts.
Assumptions. In this work, we assume an Android device is loaded with multiple policy-driven security extensions
that mediate intent-based communication among installed
apps. The apps could be malicious, but they do not seek
to escape from the confinement of the security extensions.
In other words, the policies define apps’ capabilities to send
or receive intents. Threats that compromise the integrity of
the Android system, the security extensions, and the policies
are beyond the scope of our approach.

A

Security
Extension

T2()

Security
Extension

T3()

Security
Extension

B

;ĂͿ

T3(T2(T1()))
A

B
;ďͿ

Figure 1: (a) The intent space from App A to App
B shrinks as it passes security extensions, modeled
here by the T1 , T2 , T3 . (b) Composing transfer functions to model app-to-app transformation.

3.

INTENT SPACE ANALYSIS: MODEL

We believe that creating the right abstraction model is the
first step toward checking intent-based communication. In
this section, we elaborate the intent space model that lays
the foundation for intent space analysis.
Figure 1 demonstrates a motivating example where App A
sends intents to App B. For simplicity of the example, we
consider only actions and categories, and we represent the
actions on the x-axis and the categories on the y-axis. The
initial space of App A is full in both dimensions because
an app can create arbitrary intents before the intents are
processed by any security extension. And because the security extensions only forward the intents that match certain
actions or categories specified in their policies, the space
gradually shrinks as the transformations T1 , T2 , and T3 are
applied to the initial space (Figure 1 (a)). The remaining
space at App B indicates the intents that App A can send to
reach App B. And if no space remains, App A cannot communicate with App B through intents. One step further,
we combine the transfer functions into a composite transfer
function that describes app-to-app space transformation as
illustrated in Figure 1 (b). This composite function captures
all the security extensions. Thus, it describes the holistic intent forwarding state.

3.1

Intent Space

Formally, an intent space is a K-dimensional space of regular languages defined as I = {.∗}K , where “.*” is the regular language that describes all words. The K dimensions
correspond to K intent attributes, which are selected by the
policy analyst based on her requirements. A policy analyst
can set a smaller K if the security extensions to be analyzed
do not inspect every intent attribute. An intent i maps
to a point in the space, such as: {action: SEND,category:
DEFAULT}2 for K = 2. Multiple intents map to a subspace
defined as a hypercube or a union of multiple hypercubes. A
hypercube is represented with exactly K regular languages
at K dimensions, such as {action: SEND|SEND_MULTI, category: ε (the empty string language)}. Any hypercube with
fewer than K dimensions or undefined dimensions is invalid
and considered as an empty space ∅ in the subsequent computations.
2
For clarity in this example we annotate the dimensions with
the attributes.

3

3.2 Intent Space Algebra

3.3

Transfer Function

Algorithms that check intent-based communication between two apps must determine whether an app’s allowed
outgoing intents overlap with the other apps’ allowed incoming intents. To this end, we define the basic set operations
on I: intersection, union, complementation, and difference.
Note that a point in I can be considered as a special hypercube whose regular languages contain only one word; and
a subspace is a union of multiple hypercubes. We therefore
define set operations for hypercubes and carry over the operations to other intent space objects. Throughout the rest of
this paper, we overload the term intent space to refer to all
types of intent space objects including points, hypercubes,
subspaces, as well as the entire intent space.
Intersection. The intersection of two intent spaces is
computed by intersecting the regular languages at each dimension. Formally, given two intent spaces i, j ⊂ I and
their dimension set D = {d1 , d2 , . . . , dk }, their intersection
i ∩ j is {d1 : regexi1 ∩ regexj1 , . . . , dk : regexik ∩ regexjk }. For
example, {A[12], C1} ∩ {ε, C1} is equivalent to {A[12], C1}
and {A[12], C1} ∩ {A3, C1} is equivalent to {∅, C1}. Note
that {∅, C1} is missing a dimension and thus is considered
as an empty space ∅.
Union. A union of intent spaces may not be simplified to
a single intent space. For example, the union of two intent
spaces {A1|A2, C1} and {A3, .*} cannot be represented by
any single hypercube and we simply represent the union as
{A1|A2, C1} ∪ {A3, .*}. We can simplify the result if the
intent spaces are on the same hyperplane. For example,
{A1|A2, C1} ∪ {A3, C1} is equivalent to {A[1-3], C1}.
Complementation. The complement of an intent space
i is the union of all the intent spaces that do not intersect
with i. Recall that the intersection of two intent spaces is an
empty space if the intersection is missing any of the K dimensions. We compute i’s complement i with Algorithm 1,
which finds all non-intersecting intent spaces by replacing
the regular language at one dimension with its complement
if the language is not .* and setting .* at the other dimensions. For example, the complement of {ε} is {.*} and the
complement of {A1, C1} is {A1, .*} ∪ {.*, C1}.

For convenience of analysis, we assume that all security
extensions deny by default. For those security extensions
that accept by default, it is trivial to reduce them into denyby-default extensions with a least-priority rule that accepts
everything. Therefore, apps cannot communicate if the security extensions specify no rule. Conversely, the rules of
a security extension that allow/deny some intents from one
app to another app essentially specify how the security extension forwards or drops intents from the source app to the
destination app. As we represent intents as an intent space,
we model a security extension’s intent forwarding and dropping functionality as intent space transformation and represent a security extension with a transfer function. Given
that the space of all apps is A, a transfer function T is:
T : (a, i) → 2A×I , a ∈ A, i ⊂ I
To aggregate multiple transfer functions into a holistic view,
we iteratively apply each (a, i) tuple of the output of a transfer function to the input of the next transfer function and
build a composite transfer function.
A transfer function captures the transformation that a security extension performs on A, I, or both. Suppose we are
to model a simple security extension that works like a Layer2 network switch: it only supports coarse-grained control
over which app can send intents to another app regardless
of intent attributes. Such an extension can be modeled as a
transfer function that transforms only on A. IntentFirewall
denies an app from sending a specific intent regardless of
the intent’s destination apps. It therefore can be modeled
as a transfer function that only transforms on I. We elaborate more details about how we model security extensions
for intent space analysis in the subsequent section.

4.

INTENT SPACE ANALYSIS: SYSTEM

In this section, we describe our policy analysis framework IntentScope which supports intent space analysis.
To demonstrate its generality, we also discuss how IntentScope works with the security extensions for intents in Android Open Source Project (AOSP) and their policies. We
emphasize that IntentScope is not limited to only the discussed security extensions in this paper.
Figure 2 depicts the workflow of IntentScope. In general, IntentScope starts from acquiring the policies of security extensions, then creates transfer functions, and converts
the composite transfer function into a holistic reachability
graph for subsequent analysis.
Acquiring Policies. The policy of a security extension is
often referred to as a dedicated file stored in the filesystem.
In this work, we opt for a more general definition of policy
and propose to acquire all the states and configurations of
security extensions so long as they specify how the intents
are forwarded. To this end, we create a privileged watchdog app for IntentScope that proactively observes policy
changes and automatically takes a snapshot of the policies.
The implementation of the watchdog app is largely specific
to the analyzed security extensions. For example, intent
filters are registered by apps and maintained by AMS and
PMS. The watchdog app acquires the registered intents filters on an Android device by dumping the internal states of
AMS and PMS after an app registers/unregisters any intent
filter.

Algorithm 1: Computing an intent space’s complement
Data: i
Result: i
i′ ← ∅;
for dimension di ∈ D do
L ← regular language at di ;
if L 6= .∗ then
i′ ← i′ ∪ {d1 : .∗, . . . , di : L, . . . , dk : .∗};
return i′
Difference: The difference (or subtraction) is computed
with intersection and complementation, i.e., i−j = i∩j. For
example, {A1|A2, .*} - {A2, .*} is equivalent to {A1|A2, .*}
∩ {A2, .*}, which is {A1, .*}. A slightly more complicated
example which reuses the complement of {A1, C1} is:
{A1|A2, C1|C2} − {A1, C1}
= {A1|A2, C1|C2} ∩ {A1, C1}
= {A1|A2, C1|C2} ∩ ({A1, .*} ∪ {.*, C1})
= {A2, C1|C2} ∪ {A1|A2, C2}
4

Implicit Intents
Intent
Firewall

Intent
Filters

C

Permissions
Apps

Apps

Protected
Broadcasts

A

B

E

Explicit Intents
Intent
Firewall

D

Permissions

Policies

Transfer Functions

F

Holistic Reachability Graph

Figure 2: IntentScope System Workflow.
As shown on the left side of Figure 2, two chains of security
extensions control implicit and explicit intents. We define
two intent spaces: (1) II as a six-dimensional implicit intent
space over five intent attributes action, category, scheme,
authority, type and one additional attribute permission;
and (2) IE as a two-dimensional explicit intent space over
component name and permission. Note that the permission of an intent is inherited from the app that created the
intent. The chain for implicit intents consists of four security
extensions: protected broadcasts, IntentFirewall, intent filters, and permissions; and we define their transfer functions
I
I
I
over II as TPI B , TIF
W , TIF , and TP ERM . The chain for
explicit intents includes two security extensions: IntentFirewall and permissions; and we define their transfer functions
E
E
over IE as TIF
W and TP ERM .

Creating Transfer Functions. Next, we map the acquired policies onto transfer functions. Given that a security extension makes decisions based on its loaded policy and
implemented policy interpretation logic, a transfer function
that models the intent forwarding state must capture both.
While the policy can be automatically retrieved by IntentScope’s watchdog app, the policy interpretation logic still
requires manual effort to model. IntentScope requires the
security extension’s authors or policy analysts to define a
transfer function for its policy interpretation logic and to
create a policy parser that instantiates the corresponding
transfer function. Note that this logic construction overhead is only performed once as the defined transfer functions
can be reused and the parsers can automatically instantiate
transfer functions. We elaborate our transfer functions for
the AOSP security extensions in Section 4.1.
Building a Holistic Reachability Graph. To facilitate analysis and visualization, we propose to convert the
composite transfer function into a directed graph that represents inter-application reachability. Formally, a holistic
reachability graph is denoted as G = (V, E), where V is a
set of vertices that correspond to the installed apps and E
is a set of edges that correspond to the intent spaces that
an app can send to reach another app. Constructing such a
reachability graph is straightforward. Each app maps to a
vertex in the graph. For each app, we apply the composite
transfer function on its initial intent space (e.g., {.∗}K ) and
add a directed edge if any non-empty intent space remains at
the destination app. We assign the remaining intent spaces
on the edges as their weights, which allows IntentScope
to support flexible queries and graph pruning as a policy
analyst adds constraints on the graph.

4.1.1

I
Intent Filters: TIF

An intent filter specifies the implicit intents that it allows
to be forwarded to the next security extension. Therefore,
an intent filter’s output is the intersection of the input intent space and the intent filter’s corresponding intent space.
Suppose a component dst.c in an app dst has an intent filter f ilter that describes an intent space idst.c
f ilter . Then, an
intent filter transforms (src, i) to (dst, i ∩ idst.c
f ilter ). Note that
the transformation is performed on both A and I. Given
the installed apps on a device as a set A, we combine their
registered intent filters and define TIF as follows:
I
n.c
TIF
(m, i) = {(n, i ∩ in.c
f ilter )|i ∩ if ilter 6= ∅,
∀c is a component of n, ∀n ∈ A, n 6= m; i, in.c
f ilter ⊂ II }

Next we explain how we map an intent filter to its intent
space if ilter . In general, an intent filter accepts an intent
if the intent’s attributes pass a series of tests on the intent filter’s attributes. Therefore, we reduce the problem
of modeling an intent filter to constructing a set of regular
languages which consists of the words that pass each test.
Action Test: An intent passes the action test if the intent’s action matches any action in the intent filter. Therefore, we map the one or more actions of an intent filter onto
a regular expression that concatenates the escaped action
strings and separates them with the vertical bar character
|, such as VIEW|EDIT. There are two corner cases in this
test. First, zero action in a filter fails the test. Second,
zero action in an implicit intent also fails the test. We capture both cases with a regular expression [], which denotes
an empty language whose intersection with any language is
empty. Note that the Android documentation is incorrect
with respect to the second corner case: “if an intent does not
specify an action, it will pass the test as long as the filter contains at least one action”. The reason is that queryIntent()

4.1 Modeling AOSP Security Extensions
Intent filters, IntentFirewall, protected broadcasts, and
permissions are the integral parts of AOSP and therefore
widely deployed in COTS Android devices. They also serve
as reference implementations for other security extensions.
For example, Apex [27] and CRePe [14] extend the permissions; and SEAndroid controls intents with a slightly modified IntentFirewall [5]. Based on these observations, we believe that the AOSP security extensions are a good starting
point to demonstrate that IntentScope is general, because
it can effectively work with their policies. In the remainder
of this section, we share our experiences of modeling these
security extensions for intent space analysis. Although we
are not the first to formally model them, we provide the
most accurate models by covering a complete set of intent
attributes and undocumented logic in the security extensions. Unless stated otherwise, the contents in this section
are based on the kitkat-release branch in AOSP.
5

in the IntentResolver class eventually denies such intents
even though matchAction() in the IntentFilter class allows. Our experiments also confirm this behavior. Interested readers are referred to the source code3 .
Scheme Test: An intent passes the scheme test if the
intent’s scheme matches any scheme in the filter. Therefore,
the regular expression here is constructed in the same way as
the action test, e.g., http|gopher. This test also has unique
cases. First, an intent filter without any scheme still matches
three schemes: content, file, or an empty string. We represent them with a regular expression file|content|, where
the last | matches the empty string. Second, an intent without any scheme passes the scheme test only if the intent filter
does not specify any scheme. We consider such intents as
intent spaces whose scheme is an empty string.
Authority Test: This test is dependent on the scheme
test. If the intent filter does not specify any scheme, this
test automatically passes regardless of the authority. This
test also passes if the filter does not specify any authority.
Thus, we use .* to match any authority in these two cases.
An intent without any authority passes the test only if the
filter has no authority. We represent such intents with an
empty string at the authority dimension. Otherwise, an intent passes the authority test if its authority matches any
authority in the filter.
Type Test: An intent passes the type test if the intent’s
MIME type matches any type in the filter. The challenge
here is the wildcard character * in MIME type strings. For
example, * and */* match any type; and audio/* matches
any subtype of audio. To maintain the semantics of the
wildcard character, we convert * and */* to .*. The slash
character / is a special character in regular expressions so we
escape it as \/. For example, audio\/.*|video\/mp4 represents every audio subtype and a single video type. Moreover,
an intent filter that has no type accepts only the intents that
have no type. Therefore, zero type in either the intent or
the filter maps to an empty string.
Category Test: Unlike the other attributes, an intent
can include more than one category. An intent passes the
category test if every category in the intent matches a category in the filter, i.e., the intent’s category set is the subset
of the filter’s category set. To capture this logic, we construct a regular language for an intent filter’s categories with
three steps: (1) escape the category strings; (2) concatenate
the escaped strings and separate them with |; and (3) surround the concatenated string with ( and )*. For example, the subsets of an intent filter’s category set {DEFAULT,
LAUNCHER, BROWSABLE} are represented with a single regular expression (DEFAULT|LAUNCHER|BROWSABLE)*. This expression also matches zero category and duplicate categories
specified in an intent. The other corner cases are similar to
those of the type test. No specification of category in an
intent or a filter maps to an empty string. An intent filter
with no category accepts only the intents with no category.

4.1.2

subtracts the intent space of each fwfilter from the input
intent space. Suppose a fwfilter that blocks an app src is
I
E
represented with an intent space isrc
f wf ilter . TIF W and TIF W
are defined in the same way as follows:
[ a
[ a
I
TIF
if wf ilter )|i −
if wf ilter 6= ∅,
W (a, i) = {(a, i −
∀f wf ilter that blocks the sender app a; i, iafwf ilter ⊂ II }
[ a
[ a
E
TIF
if wf ilter )|i −
if wf ilter 6= ∅,
W (a, i) = {(a, i −

∀f wf ilter that blocks the sender app a; i, iafwf ilter ⊂ IE }
Next we explain how we construct the intent space if wf ilter
for a fwfilter over the implicit intent space II and the explicit intent space IE , respectively. In general, we construct
if wf ilter according to IntentFirewall’s two-phase intent attribute matching process.
If a fwfilter is for implicit intents, IntentFirewall first considers the fwfilter as an intent filter and tests the intent attributes with the same tests as we discussed in Section 4.1.1.
We skip modeling this phase for brevity. In the second
phase, IntentFirewall tests the intent attributes with common string tests, such as isEqual, isStartsWith, isContained, and matchRegex. Therefore, we model these tests
with their equivalent regular expressions. For example, isStartsWith=abc maps to a regular expression abc.*; isContained=def maps to a regular expression .*def.*. The tests
can be aggregated by computing the intersection of the regular expressions. For example, two tests isEqual=abc and
isStartsWith=ab map to a regular expression abc.
For a fwfilter that filters explicit intents, we also construct
its intent space in two phases. In the first phase, IntentFirewall checks if an explicit intent’s component name matches
the one specified in the fwfilter. Thus, we simply copy
the fwfilter’s escaped component name to the corresponding dimension in if wf ilter . There are two corner cases to
be handled. An explicit intent with no component name is
dropped immediately because it resolves to nowhere. A fwfilter with no component name does not block any explicit
intent. We model the former case with a regular expression [] and model the latter case with a regular expression
.*. In the second phase, Intent Firewall tests the intent’s
component name with the identical string tests so we do not
I
E
rephrase how we model them. Finally, both TIF
W and TIF W
do not transform an intent space at the permission dimension because IntentFirewall does not inspect permissions.
Note that IntentFirewall is a relatively new security extension in AOSP with no official documentation and limited
comments in the code. At first we referred to the unofficial documentation maintained by Yagemann [36] to define the transfer functions. However, we found unexplained
behaviors of IntentFirewall when we tested IntentFirewall’s
sample policies, which led us to the discovery of the overlooked second matching phase. In order to obtain an accurate and comprehensive model, we manually derived the
transfer functions presented in this section from IntentFirewall’s source code4 .

E
I
IntentFirewall: TIF
W and TIF W

IntentFirewall is a policy-driven MAC framework that
block apps from sending specific intents. The policy files,
located at /data/system/ifw/*.xml, specify a list of firewall filters (fwfilters for short) that describe the implicit or
explicit intents to be blocked for a specific sender app. We
model IntentFirewall as a transformation over II or IE that

Permissions constrain an app’s capability to receive intents from other apps. Suppose an app has a sensitive
component that only accepts the intents from authorized
apps. Then, the app can define a permission and assign it

3

4

4.1.3

https://goo.gl/A1auU5 and https://goo.gl/cdzxg8
6

Permissions: TPI ERM and TPEERM

https://goo.gl/e4zzxL

to the component, which requires the component’s callers
to hold the exact same permission. If we treat intents as
if they inherit the permissions of their creator/sender apps,
a permission’s role is to forward only the intents that have
matching permissions. Therefore, a permission’s output is
the intersection of the input intent space and the permission’s own intent space. Note that permissions do not transform on A because the other security extensions have already resolved the destination app/component. Suppose a
component dst.c is protected by a permission p described
by an intent space idst.c
c.p . The transformation is defined as
(dst.c, i) → (dst.c, i ∩ idst.c
c.p ).
We define TPI ERM and TPEERM as follows:

explicit intent space, respectively. To build each chain of
transfer functions, we start from integrating the transfer
functions of those security extensions that restrict an app
from sending intents. Then, the transfer functions of the security extensions that restrict an app from receiving intents
follow. For the transfer functions defined in this section,
their composite transfer function T is defined as:
 I
I
I
I
(TIF
if i ⊂ II
 TP ERM (TIF
W (TP B (a, i))))
T (a, i) =

E
TPEERM (TIF
if i ⊂ IE
W (a, i))

5.

a.c
TPI ERM (a, i) = {(a.c, i ∩ ia.c
c.p )|i ∩ ic.p 6= ∅,

∀c is a component of a;
c is protected by c.p; i, ia.c
c.p ⊂ II }
a.c
TPEERM (a, i) = {(a.c, i ∩ ia.c
c.p )|i ∩ ic.p 6= ∅,
∀c is a component of a;

c is protected by c.p; i, ia.c
c.p ⊂ IE }

5.1

Mapping a permission to an intent space ip is straightforward. The regular language at the permission dimension of
ip is the escaped permission string. A special case is that a
content provider may have separate permissions for reading
and writing. Similar to the action test in intent filters, we
model this case with a regular expression perm_r|perm_w,
based on the fact that an app with either the read or write
permission can access the content provider. The regular
languages at the other dimensions are .*, leaving the intent
space unchanged at these dimensions.

4.1.4

Implementation

IntentScope includes an implementation of the intent
space model, a watchdog app that monitors and incrementally acquires the policies of the AOSP security extensions,
a set of policy parsers that build and compose transfer functions, and a graph builder that converts the composite transfer function into the holistic reachability graph.
The intent space model is built on Augeas Libfa [1], a
native library that supports accurate and fast operations
on regular expressions. In particular, we opt for Hopcroft’s
DFA minimization algorithm [22] to minimize regular expressions. This algorithm runs in O(nlogn) time in the worst
case, where n is the number of states of a regular expression’s
equivalent DFA. The watchdog app runs as a privileged system app. It detects state changes in PMS/AMS triggered
by app installs/uninstalls and re-acquires the intent filters
and permissions, regardless of whether they are statically declared in apps’ manifest or dynamically registered in app’s
code. The watchdog app also fetches the relevant files where
IntentFirewall and protected broadcasts store their policies.
As the operations over intent spaces are both computation
and memory intensive, the parsers and graph builder run on
a dedicated server rather than on the mobile device where
the watchdog app runs.

Protected Broadcasts: TPI B

Protected broadcasts are a set of implicit intents with
special actions that only the apps whose UIDs are SYSTEM,
BLUETOOTH, PHONE, or SHELL can send. The other apps are
prevented from sending such intents. Similar to IntentFirewall, we model protected broadcasts as a space transformation that subtracts the intent spaces of protected broadcasts
from the input intent space if the input app is not a systemapp. Suppose each protected broadcast maps to an intent
space iprotected . Then, we define the transfer function for
protected broadcasts as follows:

(a, i)
if a is an allowed app
S
TPI B (a, i) =
(a, i − iprotected ) otherwise

5.2

i, iprotected ⊂ II

Experimental Setup

We evaluated IntentScope on two Android devices and
four Android-based OSs, as shown in Table 1. The Galaxy
Note ran Samsung’s deeply customized Android (4.4.2), which
pre-installed a large number of Samsung’s apps. The Nexus
4 ran three OSs, including stock Android (5.0), MIUI (4.4.2),
and CyanogenMod (4.4.4). We kept them as they were and
did not install additional apps. In particular, the first two
OSs pre-installed a few proprietary Google-branded apps.
MIUI and CyanogenMod did not include these apps due to
licensing restrictions.
For each OS, we started each installed app and kept it
in the foreground. After the apps were started and IntentScope’s watchdog app did not report any new policy updates
in the latest one minute, we applied IntentScope to generate a reachability graph G and two subgraphs GI and GE
that respectively represent the holistic forwarding state of

A list of actions used by protected broadcasts is available in the Android SDK5 . Thus, we build an intent space
iprotected for each action by assigning the escaped action
string into the action dimension of the space. The other
dimensions do not involve space transformation and remain
with a regular expression .*.

4.1.5

EVALUATION

In this section, we first discuss a prototype implementation of IntentScope. We then present the experiments in
which we apply IntentScope to check intent-based communication mediated by the AOSP security extensions installed
in commodity Android devices and customized Android OSs.
We conclude with an evaluation of the throughput of our
system.

Composite Transfer Function

As we have defined the transfer function for each individual security extension, we combine them together to build
the composite transfer function. The composite function
covers two chains of transfer functions for the implicit and
5
ANDROID SDK ROOT/platforms/android-19/data/
broadcast actions.txt

7

Table 1: Evaluated Android Devices/OSs and Generated Reachability Graphs

1

Device

OS

|V|

Samsung Galaxy Note II

Customized Android

311

Stock Android

108

MIUI v5

104

CyanogenMod 11 M12

85

2
3

LGE Nexus 4

4

|EI |
|EE |
880,456
979,993
155,369
138,651
99,170
118,707
38,606
47,458

Global Clustering
Coefficient
0.986
0.994
0.971
0.990
0.979
0.991
0.974
0.989

Standard
Deviation
0.007
0.006
0.014
0.009
0.013
0.009
0.015
0.011

Table 2: Apps Ranked by PageRank
1

2

3

4

Highest in GI
com.viber.voip
com.android.contacts
com.android.settings
com.google.android.apps.plus
com.android.settings
com.google.android.apps.gms
com.android.mms
com.android.contacts
com.android.settings
com.android.gallery3d
com.android.email
com.android.contacts

Lowest in GI
com.android.proxyhandler
com.monotype.android.font.cooljazz
com.sec.android.provider.badge
com.android.dreams.basic
com.android.providers.userdictionary
com.android.vpndialogs
com.android.pacprocessor
com.android.sharedstoragebackup
com.miui.providers.weather
com.android.nfc
com.android.backupconfirm
com.android.sharedstoragebackup

Highest in GE
com.android.contacts
com.android.phone
com.android.settings
com.google.android.setupwizard
com.google.android.apps.plus
com.android.settings
com.android.email
com.android.mms
com.android.settings
com.android.contacts
com.android.email
com.android.settings

5.3

implicit and explicit intents. Each vertex represents an app
identified by its package name rather than UID6 . Parallel
edges are allowed and prevalent in the graphs to capture the
multiple entry points of an app.
Table 1 lists the number of vertices, the number of edges
(including parallel edges), and the global clustering coefficient (measured without parallel edges) of each GI and GE .
A global clustering coefficient is a measure of the degree to
which vertices in a graph tend to cluster together. We opted
for this measure to get a general idea about how freely the
installed apps on a mobile OS are allowed to communicate
with one another. As the clustering coefficient of a clique is
1, the measured values of CG indicate that the vertices in
all the graphs are densely connected, which is in line with
our observation that most apps have at least one component (the main activity) exposed to other apps. The large
number of edges also implies the complexities of managing
fine-grained policies for intent-based communication.
Given the large number of apps/vertices and edges, prioritizing the apps that expose larger attack surfaces is critical for efficiently analyzing and resolving policy conflicts
and violations. Therefore, we propose to identify such apps
with PageRank [30]. The underlying intuition is that such
apps are more likely to be accessed by other apps and thus
have more incoming edges, and the apps that have direct
incoming edges from such apps are also likely to be attacked. Table 2 lists the apps in the four mobile OSs with
the highest and lowest rankings. Most of the listed apps are
in line with intuition, such as com.android.settings and
com.android.email. Here we discuss two apps which are
displayed in bold in Table 2. The app com.google.android.
setupwizard is highly ranked because it exports 69 components that can be accessed with explicit intents. The app
com.viber.voip is highly ranked because of its 94 intent
filters that expose the components to implicit intents.

Lowest in GE
com.sec.enterprise.permissions
com.samsung.android.mdm
com.samung.android.sdk.spenv10
com.android.dreams.basic
com.android.wallpaper
com.google.android.apps.docs.editors.slides
cm.android.printspooler
com.android.nfc
com.android.noisefield
com.android.nfc
com.android.incallui
com.android.printspooler

Experiments

With IntentScope, checking what intents an app can
send is equivalent to checking the vertex’s outgoing edges
as well as the intent spaces assigned on them. Conversely,
checking what intents an app can receive is equivalent to
checking the incoming edges. In addition, IntentScope
supports flexible queries backed by regular expressions. Next
we elaborate four experiments in which we leverage the insights provided by IntentScope to identify potential vulnerabilities due to errors in security policies of the AOSP
security extensions.

5.3.1

Zero Permission 6= Zero Privilege
Enforcing least privilege is a common practice in mobile
security. While recent work [14, 27, 35] attempts to control
and minimize the set of an app’s granted permissions, we
are interested in another question: what can an app do if
it has no permissions. In this experiment, we created and
installed such a zero-permission app. We then checked what
components this app can reach with its allowed intents. This
experiment helps a policy analyst reveal the exposed components that could possibly be exploited by even a zeropermission app. If any sensitive components are exposed,
the details of the allowed intents that reach these components provide the necessary knowledge for a policy analyst
to create precise policies that protect them. We find that
zero permission does not necessarily mean zero privilege as
users might expect. Table 3 shows the number of the zeropermission app’s reachable apps (i.e. out-neighbors) and its
local clustering coefficient.
The flexible queries supported by IntentScope also allow
a policy analyst to pinpoint the intents that have interesting semantics. In the Galaxy Note, we found that this zeropermission app can send implicit intents that contain an interesting scheme called android_secret_code. For example,
one of the reachable apps is com.sec.android.app.wlantest,
which accepts intents with an action android.provider.
Telephony.SECRET_CODE, an authority of 526, and a scheme

6
Apps with the same UID are considered as separate apps
but share the permissions of one another [9].

8

ministrator to create precise rules that can be enforced by
Aquifer and similar access control systems.
In this experiment, we applied IntentScope to enumerate the workflows in MIUI that match the aforementioned
example. Specifically, we started from an app com.android.
providers.downloads, which manages downloaded files. We
then performed a breath-first search on the reachability graph
for a sequence of implicit intents as follows:

Table 3: Reachability of a Zero-Permission App

1
2
3
4

# Outgoing
Edges
2,767
3,072
1,443
1,280
955
1,142
454
557

# Reachable
Apps
241
263
77
92
79
90
62
72

Local Clustering
Coefficient
0.943
0.968
0.905
0.960
0.927
0.968
0.914
0.961

1. action=android.intent.action.VIEW, scheme=content,
category=android.intent.category.BROWSABLE;
2. action=android.intent.action.EDIT, type=image/*;
3. action=android.intent.action.SEND, type=image/*.

of android_secret_code. Another reachable app com.
wssyncmldm is a sensitive app that can silently download
and install apps. Therefore, an app with no permissions
could exploit a vulnerability in this app in order to download and install apps, thus escalating the privilege of the
zero-permission app without exploiting the underlying OS.
We also found that a recent attack [31] is applicable here,
where a malformed intent sent from a zero-permission app
can exploit and take over the exposed sensitive app.

Figure 3(b) shows the matching workflows that start from
the cyan node. The grey nodes are the first hop; the purple
nodes in the middle are the second hop. Note that the purple
nodes also serve as the first hop because the photo editors
can also handle the VIEW action. The yellow nodes represent
the last hop where data may leave a mobile device via emails,
Bluetooth, or MMS messages.

5.3.4
5.3.2

Fine-grained Domain Isolation

Chin et al. [13] presents a limitation of intent-based communication. Suppose a malicious app Mallory attempts to
attack a legitimate and sensitive app Alice and existing policies prevent their direct communication. The limitation allows Mallory to eavesdrop the intents from Alice to Bob and
allows Mallory to send spoofed intents to Alice. This situation calls for a fine-grained domain isolation model that not
only considers apps but also includes intents. IntentScope
is useful as it provides insights about intents.
Specifically, two apps are not isolated with respect to
eavesdropping attacks if they share in-neighbors and incoming intents in the reachability graph. They are not isolated
with respect to spoofing attacks if they share out-neighbors
and outgoing intents. Thus, IntentScope guarantees intent isolation between two apps if: (1) the apps are not
neighbors of each other; and (2) the intent spaces of their
incoming edges from common in-neighbors do not intersect;
and (3) the intent spaces of their outgoing edges to common
out-neighbors do not intersect.
As a case study, we checked the intent isolation between
two apps in the Galaxy Note: com.android.externalstorage
and com.fmm.dm. The former is an Android system app. The
latter is believed to be bloatware as reported on several online forums. IntentScope reported that the intent spaces
do not intersect, which implies that no app steals any intent
from the other. However, these two apps share 242 common out-neighbors and the intersection of the intent spaces
is not empty (see Figure 3(a)). Therefore, these apps are
still susceptible to spoofing attacks.

5.3.3

Discovering Permission Re-Delegation Paths

A zero-permission app may send an intent to a privileged app, thus delegating the privileged app to perform
permission-protected tasks for it [19]. In other words, permission re-delegation happens when apps with respective
permission sets communicate with each other with intents.
Under this definition, existing work [10,19] detects and mitigates permission re-delegation attempts at runtime. One
step further, we expect to enable a policy analyst to get insights into potential permission re-delegation paths before
apps may execute. Meanwhile, the intents used along redelegation paths provide semantics for the policy analyst to
make informed decisions and take precise actions against the
privileged apps that could be abused.
We propose to use connected subgraphs to represent permission re-delegation paths in a reachability graph. A subgraph is connected if every pair of its vertices has a path
that consists of only the vertices in the subgraph. This is
analogous to the situation where multiple apps collude but
cannot relay their communication via other apps. We define
the problem of discovering re-delegation paths as follows:
given a set of critical permissions denoted as CP , find all
the connected subgraphs of k vertices that satisfy:
• Each app (vertex) holds at least one permission but
not all the permissions in CP ; and
• The union of the apps’ permissions is a superset of CP .
The best algorithm we found to generate connected subgraphs of k vertices is ConSubG(G, k) [24], whose worstcase time complexity is exponential in k. The performance
of this algorithm is generally acceptable because we rarely
encounter cases where more than five apps collude.
We targeted the third-party apps installed on the Galaxy
Note and set k = 3. We attempted to create a synthetic attack where apps collude to drain the battery with a critical
permission set of three permissions: BLUETOOTH_ADMIN, NFC,
and FLASHLIGHT. Our results show 6 groups of apps (triangles) that can possibly collude to cover the critical permissions. In particular, the two apps in the center respectively
hold FLASHLIGHT and NFC, while the surrounding six apps
hold BLUETOOTH_ADMIN (see Figure 3(c)). After the groups

Enumerating Multi-app Workflows

In modern mobile operating systems, it is common for a
user to orchestrate multiple apps for a large and user-defined
task. For example, a user may streamline a workflow of
downloading, viewing, editing, and sending a picture with
a chain of apps. Under the hood of Android, a multi-app
workflow is implemented as a calling sequence of intents.
While controlling such workflows has been well covered by
Aquifer [26], IntentScope provides clues for a policy ad9

Table 4: System Throughput
1
2
3
4
Average

|EI |
800,456
155,369
99,170
38,606

Avg. Time (s)
302.05
70.08
38.69
15.63

StdDev (s)
5.73
3.02
0.92
1.00

# edges/sec
2,915
2,217
2,563
2,469
2,541

com.sec.android.AutoPreconfig
com.samsung.sec.android.application.csc

com.android.stk
com.sec.dsm.phone

com.android.providers.telephony
com.sec.android.app.DataCreate

(a) Common In-neighbors of Two Target Apps

5.4

com.android.bluetooth

com.miui.notes

com.android.contacts
com.android.email

com.android.mms
com.tencent.mm

(b) Workflows for Processing a Picture

com.viber.voip
(5)
(2)
(2)
(3)

com.shazam.android
(3)

(*)

(1)

(1)
com.surpax.ledflashlight.panel
com.vlingo.midas
(4)
(4)

System Throughput

We performed the benchmark in a Xen VM running Ubuntu
14.04 with Intel Xeon E5620 2.4GHz and 8GB of RAM. Only
one core was used during the benchmark. Table 4 shows the
average results of 10 runs. It took approximately 5 minutes
to check the customized Android OS of the Galaxy Note
loaded with 311 apps, and less than 1 minute to check the
others. In general, the processing time is proportional to the
number of edges. As shown in Table 4, IntentScope processed 2,541 implicit intent spaces and 7,225 explicit intent
spaces in a second. While explicit intent spaces were almost
three times faster than implicit intent spaces, we note that
an explicit intent spaces has only two dimensions and an
implicit intent space has six dimensions.

com.pandora.android

me.pou.app

# edges/sec
8,454
6,422
7,014
7,013
7,225

• iI : action=android\.intent\.action\.EDIT,
category=android\.intent\.category\.DEFAULT,
scheme=http, authority=\d+, type=mpeg,
permission=.*;
• iE : component=com\.sec\..*, permission=.*.

com.jeejen.family

(5)

StdDev (s)
2.02
0.74
1.02
0.45

To understand the performance of IntentScope, we performed a microbenchmark to evaluate the number of edges
that IntentScope can check in a second. Given that checking an edge is done by testing whether the intersection of the
edge’s intent space and a given intent space is empty, this
benchmark also implies the throughput of IntentScope in
terms of processing intent spaces. In the benchmark, we
used the following two intent spaces to evaluate the throughput of implicit intents and explicit intents, respectively. Note
that the intersection of an implicit intent space and an explicit intent space is always empty and thus not evaluated.

com.android.fileexplorer

com.android.providers.downloads

Avg. Time (s)
115.57
21.59
16.92
6.77

are identified, a security analyst can further look into the
apps for colluding behaviors with static or dynamic analysis. On the contrary, a user can eliminate colluding attacks
by placing the apps into separate domains.
Even though the discovered eight apps are mostly downloaded and seem to be trusted by general users, they may
carry third-party libraries or vulnerable components that
are exploitable by other apps. In other words, they may not
deliberately collude, but could be exploited by other apps
to acquire privileges. The analysis discussed in this experiment can be combined with the other analyses (e.g. zeropermission apps) to further generate knowledge for a policy
analyst to take precautions before real exploits occur.

com.android.phone
com.sec.android.Preconfig

com.miui.player

|EE |
979,993
138,651
118,707
47,458

(6)
(6)

com.antivirus

6.

com.tencent.mm

DISCUSSION

Policy analysis and app analysis. In terms of providing insights for configuring security extensions, our intent
space based policy analysis complements existing static and
dynamic app analysis. We make this argument based on
the fact that an app’s runtime behaviors on a specific mobile device are shaped by (1) the app whose code specifies

(c) Potentially Colluding Apps (k=3)

Figure 3: Experimental Results

10

its executional semantics; and (2) the security extensions
whose policies specify how the app’s specific behaviors are
restricted. While we admit that app analysis is indispensable, we also note the alarming trend of malware thwarting
app analysis. For example, code obfuscation and encryption
hide an app’s true semantics from static analysis. “Split personalities” in apps [8, 23] make malware appear innocent by
detecting and evading dynamic analysis tools. To get an upper hand against adversaries, we would need policy analysis
to orchestrate security extensions.
Generality of intent space analysis. While we presented intent space analysis for checking intent-based communication, the underlying methodology is beyond the scope
of intents and generally applicable to other security extensions. A promising target is SE Android [32], which controls almost every inter-application communication mechanism other than intent-based communication. Specifically,
it checks an attribute called security context when an app requests to access files, sockets and so on. Given that security
contexts and intent attributes are essentially access control
labels [16], we foresee that our intent space analysis can be
extended to a “context space analysis” for SE Android. We
will extend our framework to reason about SE Android policies and further maximize the coverage of inter-application
communication. However, we also admit the limitation that
the current intent space analysis cannot directly work with
existing context-aware security extensions. As for future
work, we shall map contexts into dynamic policy and provide support for such extensions.
Usability of the holistic reachability graph. As
we focused on developing the intent space model and implementing a prototype of IntentScope, usability of the
reachability graph was not the primary goal. Indeed, policy verification is a complicated task because the number
of apps and the allowed intents among them can be quite
large. However, policy management is inevitable to validate
policy-driven security extensions. IntentScope attempts
to reduce the burden on policy analysts by helping them intuitively perform intent-based communication analysis and
utilize flexible queries. Moreover, we believe that the usability of the graph has a lot of space to improve and indeed this
is an important research challenge to explore. For example,
the more interactive visualization may assist a security analyst in understanding the inter-application communication
and in ultimately developing a robust security policy.

igate unauthorized privilege escalations. QUIRE [15] provides provenance of intents so that a callee can track down
the original caller. XManDroid [10] maintains a systemcentric call graph for the intents that have been sent and
received. TaintDroid [18] and VetDroid [37] track sensitive data shared among apps with dynamic taint analysis.
Along these lines, our intent space analysis assists policy analysts by systematically analyzing how security extensions
confine apps’ behaviors. Its analysis is based on a holistic
call graph and data-flow graph derived from the intent forwarding states of security extensions in an Android device.
Experimental security extensions for Android: Besides intent filters, permissions, IntentFirewall, and protected
broadcasts covered in this work, previous research has proposed a series of experimental security extensions for Android. Saint [29] and TISSA [38] support policy-driven access control for intents. CRePe [14] and APEX [27] enable
context-aware and fine-grained permissions. FlaskDroid [12]
and SE Android [32] are generic and flexible MAC systems
that provide comprehensive protection on both Android’s
middleware and kernel layers. Aquifer [26] enforces distributed information flow control over intent-based UI workflows. Android Security Module (ASM) [21] and Android
Security Framework (ASF) [7] provide programmable interfaces that promote the creation of customized security extensions. IntentScope facilitates defining and verifying security policies for these security extensions. It is especially
useful for ASM and ASF that may host security extensions
from multiple stakeholders.

8.

CONCLUSION

In this paper, we have presented intent space analysis for
intent-based communication. Intent space analysis is based
on an intent space model and a systematic policy checking
framework called IntentScope. The intent space model
maps a security extension’s functionality of forwarding intents as transformation on a geometric space. Based on the
intent space model, IntentScope acquires the live states
of multiple security extensions and further derives a holistic
view that supports formal verification. Also we have described a prototype implementation, along with extensive
evaluation results of our approach.

Acknowledgements
This work was partially supported by the grants from Global
Research Laboratory Project through National Research Foundation (NRF-2014K1A1A2043029) and the Center for Cybersecurity and Digital Forensics at Arizona State University. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors
and do not reflect the views of the funding agencies.

7. RELATED WORK
Static and dynamic app analysis. App-oriented analysis provides insights for a policy analyst to create appropriate security policies. ComDroid [13] is the first work
that discusses the intent-based attack surfaces and discovers vulnerable components mistakenly exported by apps.
CHEX [25] is also built on static analysis that comprehensively discovers vulnerable ICC entry points in addition to
just exported components. Epicc [28] checks ICC vulnerabilities based on a sound and detailed ICC model and scales
well. AmanDroid [34], FlowDroid [6], and DroidSafe [20]
statically discover information flows that potentially leak
sensitive data. Elish et al. [17] statically reconstruct intents among apps to detect collusion. Beyond static analysis, dynamic runtime solutions reveal how apps communicate
through intents in real time. IPC Inspection [19] automatically reduces an intent sender’s effective permissions to mit-

9.

REFERENCES

[1] Finite automata. http://augeas.net/libfa/, 2014. Accessed:
06/2015.
[2] Bound services - Android developers. http://developer.
android.com/guide/components/bound-services.html, 2015.
Accessed: 06/2015.
[3] Requesting a shared file - Android developers. http://
developer.android.com/training/secure-file-sharing/
request-file.html, 2015. Accessed: 06/2015.
[4] Selinux policy analysis tools. https://github.com/
TresysTechnology/setools, 2015. Accessed: 06/2015.

11

[5] Selinux wiki. http://selinuxproject.org/page/NB
SEforAndroid 1, 2015. Accessed: 06/2015.
[6] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel,
J. Klein, Y. Le Traon, D. Octeau, and P. McDaniel.
Flowdroid: Precise context, flow, field, object-sensitive and
lifecycle-aware taint analysis for Android apps. In ACM
SIGPLAN Notices, volume 49, pages 259–269, 2014.
[7] M. Backes, S. Bugiel, S. Gerling, and P. von
Styp-Rekowsky. Android Security Framework: Extensible
multi-layered access control on Android. In Proceedings of
the Annual Computer Security Applications Conference.
ACM, 2014.
[8] D. Balzarotti, M. Cova, C. Karlberger, C. Kruegel,
E. Kirda, and G. Vigna. Efficient detection of split
personalities in malware. In Proceedings of Network and
Distributed System Security Symposium, 2010.
[9] D. Barrera, J. Clark, D. McCarney, and P. C. van
Oorschot. Understanding and improving app installation
security mechanisms through empirical analysis of Android.
In Proceedings of the ACM Workshop on Security and
Privacy in Smartphones and Mobile Devices, pages 81–92.
ACM, 2012.
[10] S. Bugiel, L. Davi, A. Dmitrienko, T. Fischer, A. Sadeghi,
and B. Shastry. Towards taming privilege-escalation attacks
on Android. In Proceedings of the Symposium on Network
and Distributed System Security, 2012.
[11] S. Bugiel, L. Davi, A. Dmitrienko, S. Heuser, A. Sadeghi,
and B. Shastry. Practical and lightweight domain isolation
on Android. In Proceedings of the ACM Workshop on
Security and Privacy in Smartphones and Mobile Devices,
pages 51–62. ACM, 2011.
[12] S. Bugiel, S. Heuser, and A.-R. Sadeghi. Flexible and
fine-grained mandatory access control on Android for
diverse security and privacy policies. In Proceedings of the
USENIX Security Symposium. USENIX Association, 2013.
[13] E. Chin, A. P. Felt, K. Greenwood, and D. Wagner.
Analyzing inter-application communication in Android. In
Proceedings of the 9th International Conference on Mobile
Systems, Applications, and Services (MobiSys), pages
239–252. ACM, 2011.
[14] M. Conti, V. T. N. Nguyen, and B. Crispo. Crepe:
Context-related policy enforcement for Android. In
Information Security, pages 331–345. Springer, 2011.
[15] M. Dietz, S. Shekhar, Y. Pisetsky, A. Shu, and D. S.
Wallach. Quire: Lightweight provenance for smart phone
operating systems. In Proceedings of the USENIX Security
Symposium. USENIX Association, 2011.
[16] P. Efstathopoulos, M. Krohn, S. VanDeBogart, C. Frey,
D. Ziegler, E. Kohler, D. Mazieres, F. Kaashoek, and
R. Morris. Labels and event processes in the asbestos
operating system. In ACM SIGOPS Operating Systems
Review, volume 39, pages 17–30. ACM, 2005.
[17] K. O. Elish, D. D. Yao, and B. G. Ryder. On the need of
precise inter-app icc classification for detecting Android
malware collusions. In Proceedings of IEEE Mobile Security
Technologies (MoST), in conjunction with the IEEE
Symposium on Security and Privacy, 2015.
[18] W. Enck, P. Gilbert, S. Han, V. Tendulkar, B.-G. Chun,
L. P. Cox, J. Jung, P. McDaniel, and A. N. Sheth.
Taintdroid: an information-flow tracking system for
realtime privacy monitoring on smartphones. ACM
Transactions on Computer Systems, 32(2):5, 2014.
[19] A. P. Felt, H. J. Wang, A. Moshchuk, S. Hanna, and
E. Chin. Permission re-delegation: Attacks and defenses. In
Proceedings of the USENIX Security Symposium. USENIX
Association, 2011.
[20] M. I. Gordon, D. Kim, J. Perkins, L. Gilham, N. Nguyen,
and M. Rinard. Information-flow analysis of Android
applications in droidsafe. In Proceedings of the Symposium
on Network and Distributed System Security, 2015.
[21] S. Heuser, A. Nadkarni, W. Enck, and A.-R. Sadeghi. Asm:

[22]
[23]

[24]

[25]

[26]

[27]

[28]

[29]

[30]
[31]

[32]

[33]

[34]

[35]

[36]

[37]

[38]

12

A programmable interface for extending Android security.
In Proceedings of the USENIX Security Symposium.
USENIX Association, 2014.
J. E. Hopcroft. Introduction to automata theory, languages,
and computation. Pearson Education, 1979.
Y. Jing, Z. Zhao, G.-J. Ahn, and H. Hu. Morpheus:
automatically generating heuristics to detect Android
emulators. In Proceedings of the Annual Computer Security
Applications Conference, pages 216–225. ACM, 2014.
S. Karakashian. An Implementation of An Algorithm for
Generating All Connected Subgraphs of a Fixed Size.
Software (Version Oct2010), Constraint Systems
Laboratory, University of Nebraska-Lincoln, Lincoln, NE,
2010.
L. Lu, Z. Li, Z. Wu, W. Lee, and G. Jiang. Chex: statically
vetting Android apps for component hijacking
vulnerabilities. In Proceedings of the ACM Conference on
Computer and Communications Security, pages 229–240.
ACM, 2012.
A. Nadkarni and W. Enck. Preventing accidental data
disclosure in modern operating systems. In Proceedings of
the ACM Conference on Computer and Communications
Security, pages 1029–1042. ACM, 2013.
M. Nauman, S. Khan, and X. Zhang. Apex: extending
Android permission model and enforcement with
user-defined runtime constraints. In Proceedings of the
ACM Symposium on Information, Computer and
Communications Security, pages 328–332. ACM, 2010.
D. Octeau, P. McDaniel, S. Jha, A. Bartel, E. Bodden,
J. Klein, and Y. Le Traon. Effective inter-component
communication mapping in Android with epicc: An
essential step towards holistic security analysis. In
Proceedings of the USENIX Security Symposium. USENIX
Association, 2013.
M. Ongtang, S. McLaughlin, W. Enck, and P. McDaniel.
Semantically rich application-centric security in Android.
Security and Communication Networks, 5(6):658–673, 2012.
L. Page, S. Brin, R. Motwani, and T. Winograd. The
pagerank citation ranking: Bringing order to the web. 1999.
O. Peles and R. Hay. One class to rule them all: 0-day
deserialization vulnerabilities in Android. In 9th USENIX
Workshop on Offensive Technologies (WOOT 15), 2015.
S. Smalley and R. Craig. Security enhanced (se) Android:
Bringing flexible mac to Android. In Proceedings of the
Symposium on Network and Distributed System Security,
2013.
R. Wang, W. Enck, D. Reeves, X. Zhang, P. Ning, D. Xu,
W. Zhou, and A. M. Azab. EaseAndroid: Automatic policy
analysis and refinement for security enhanced Android via
large-scale semi-supervised learning.
F. Wei, S. Roy, X. Ou, et al. AmAndroid: A precise and
general inter-component data flow analysis framework for
security vetting of Android apps. In Proceedings of the
ACM Conference on Computer and Communications
Security, pages 1329–1341. ACM, 2014.
P. Wijesekera, A. Baokar, A. Hosseini, S. Egelman,
D. Wagner, and K. Beznosov. Android permissions
remystified: A field study on contextual integrity. In
Proceedings of the USENIX Security Symposium. USENIX
Association, 2015.
C. Yagemann. Intent firewall. http://www.cis.syr.edu/
˜wedu/android/IntentFirewall/index.html, 2014. Accessed:
06/2015.
Y. Zhang, M. Yang, B. Xu, Z. Yang, G. Gu, P. Ning, X. S.
Wang, and B. Zang. Vetting undesirable behaviors in
Android apps with permission use analysis. In Proceedings
of the ACM Conference on Computer and
Communications Security, pages 611–622. ACM, 2013.
Y. Zhou, X. Zhang, X. Jiang, and V. Freeh. Taming
information-stealing smartphone applications (on Android).
Trust and Trustworthy Computing, pages 93–107, 2011.

Moving Target Defense for Web Applications using
Bayesian Stackelberg Games
Sailik Sengupta, Satya Gautam Vadlamudi, Subbarao Kambhampati
Yochan Group, School of CIDSE
Arizona State University
{sailiks, gautam, rao}@asu.edu

Marthony Taguinod, Adam Doupé, Ziming Zhao, Gail-Joon Ahn
SEFCOM Lab, School of CIDSE
Arizona State University
{mtaguino, doupe, zmzhao, gahn}@asu.edu

ABSTRACT
The present complexity in designing web applications makes software security a difficult goal to achieve. An attacker can explore
a deployed service on the web and attack at his/her own leisure.
Moving Target Defense (MTD) in web applications is an effective
mechanism to nullify this advantage of their reconnaissance but the
framework demands a good switching strategy when switching between multiple configurations for its web-stack. To address this issue, we propose modeling of a real-world MTD web application
as a repeated Bayesian game. We then formulate an optimization
problem that generates an effective switching strategy while considering the cost of switching between different web-stack configurations. To incorporate this model into a developed MTD system,
we develop an automated system for generating attack sets of Common Vulnerabilities and Exposures (CVEs) for input attacker types
with predefined capabilities. Our framework obtains realistic reward values for the players (defenders and attackers) in this game
by using security domain expertise on CVEs obtained from the National Vulnerability Database (NVD). We also address the issue of
prioritizing vulnerabilities that when fixed, improves the security
of the MTD system. Lastly, we demonstrate the robustness of our
proposed model by evaluating its performance when there is uncertainty about input attacker information.

1.

INTRODUCTION

Present day web applications are widely used by businesses to
provide services over the Internet. Oftentimes, sensitive business
and user data are managed by these applications. Vulnerabilities in
these web applications pose serious threats to the confidentiality
and integrity of both businesses and users [16].
There exist numerous static (white-box) and dynamic (blackbox) analysis tools for identifying vulnerabilities in a system [2,
6]. These have become less effective in present times due to the
increasing complexity of web applications, their dependency on
downstream technologies, and the limited development and deployment time [22]. Worse yet, the attackers, with time on their side,
can perform reconnaissance and attack. To address this challenge,
we consider a Moving Target Defense (MTD) based approach [4],

A shorter version of this paper appears in: Proceedings of the
15th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2016), May 9–13, 2016, Singapore.

which complements the existing vulnerability analysis techniques
through a defense-in-depth mechanism.
The MTD based approach dynamically shifts a system over time
to increase the uncertainty and complexity for the attackers to perform probing and attacking [24], while ensuring that the system
is available for legitimate users. As the window of attack opportunities decreases, the effort in finding and successfully executing
an attack increases. Moreover, if an attacker succeeds in finding a
vulnerability at one point in time, it may not be exploitable at another time because of the moving defense system, making the web
application more resilient [18].
Various aspects that support Moving Target Defense approach
such as, using multiple implementation languages, multiple database
instances with synchronization, etc. are considered in different layers of web application architecture, along with ways to switch between them. However, the design of good quality switching strategies itself is left as an open problem. This is key to effectively leverage various move options—thereby maximizing the complexity for
the attacker and minimizing the damage for the defender.
Our aim in this paper is to design effective switching policies for
movement in the MTD system that maximize the security of the
web application, given the set of components and configurations
of the system which can be “moved around”, while simultaneously
considering realistic costs for “moving them around”. In web applications, the defender (leader) deploys a system up-front. The attacker observes (or follows) the system over time before choosing
an attack. These characteristics motivate us to formulate the MTD
system as a repeated Bayesian Stackelberg Game (BSG). For this
formulation to be meaningful in real-world applications, we use
real world attack data for our model. We propose a framework to
define attacker types for our game and automatically generate attack options for each of them by mining and characterizing Common Vulnerabilities and Exposures (CVEs). We develop a system
that leverages the knowledge in public attack databases and expertise of system administrators for obtaining meaningful game utilities and switching costs respectively.
For computing the movement policy for the defender, we initially
expected to be able to use existing solvers developed for physical
security systems [17]. Unfortunately, none of them considered the
cost of switching between strategies. Since this is highly relevant in
cyber-security systems, we had to formulate an optimization problem to consider these costs when generating strategies.
The increased complexity in an MTD systems exacerbates the
difficulty of prioritizing vulnerabilities that need to be fixed next.
We define this problem formally and propose a preliminary solu-

tion. Lastly, we talk about metrics to measure the robustness of
switching strategies generated by various models when the uncertainty about attacker types vary in the real world.
In section 2, we introduce the reader to the different ways people
have tried to address the problem of generating switching strategies for cyber-security systems. We introduce domain terminology
related to MTD systems for web-applications in section 3. In section 4, we develop the Bayesian Game model for this system defining attacker types, attack classification, rewards generated from security databases and strategy switching costs. To find an effective
switching strategy, we propose a solver that maximizes system security while accounting for switching costs in section 5. We empirically study the effectiveness and robustness of the strategy generated by our framework in section 6, comparing it to the stateof-the-art. We also formulate the problem of identifying critical
vulnerabilities and propose a preliminary solution in section 6. We
conclude the paper in section 7, highlighting promising research
directions.

2.

security systems. Unfortunately, these works, to our knowledge, do
not consider the cost the defenders incur when asked to switch from
a particular strategy to another. Hence, we propose a solver that
maximizes the defender’s reward and minimizes the overall cost
of switching between web-application configurations. Our solver
is essentially an extension of the DOBSS solver [13]. Although
there has been furhter development since DOBSS, the more recent solvers for BSGs make additional assumptions about the game
structure—either about the action sets of the defender, or the presence of hierarchical structure among attacker types [1], which do
not hold for the web application domain.
The use of Common Vulnerabilitiy Scoring System (CVSS) for
rating attacks is well studied in security [7]. We describe this metric later. CVSS provides a strong backbone for obtaining utilities
for our game theoretic model. None of the existing works (to our
knowledge) talk about the pragmatic aspect of prioritizing vulnerabilites in MTD systems. Also, there does not seem to be any standard metrics to capture the robustness of strategies generated by a
model. We address both these issues in the upcoming sections.

RELATED WORK

Although there exists prior work on the design of switching strategies for MTD systems, most of it is domain specific. Evaluation of
these strategies on real-world MTD systems for web applications
is scarce. We discuss some of these works, highlighting their limitations in the domain of web applications, thus motivating the need
for our solution. Existing efforts describe the use of randomized
switching strategies, and show its effectiveness for MTD systems
[24]. We empirically demonstrate that our strategy outperforms this
state-of-the-art for web applications, especially when the cost of
switching is negligible.
Attacker-defender scenarios have been modeled earlier as stochastic games for attack-surface shifting [9]. Other works model the
MTD problem as a repeated game where the defender uses uniform
random strategy with the exception that the same defense configuration is not deployed in two consecutive rounds [23]. This work
needs an in-depth analysis of code, which is unrealistic for complex
web applications.
Switching strategies for MTD systems based on detection of probes
by attackers are presented by [15]. Unfortunately, an accurate detection of attacks in web applications is difficult, if not impossible.
Furthermore, such strategies can lead to a detrimental performance
in repeated games if an intelligent attacker biases the system to
switch more towards MTD configurations where the attacker attains higher reward. In [8], the MTD system is modeled as a game
called PLADD, based on FlipIt games [19]. This work assumes
that different agents control the server in different game rounds,
which is impractical for most cyber-seccurity applications, essentially web applications. These techniques also fail to capture the
reconnaissance aspect of the attackers which is shown to be an important aspect in the attack phase [12].
In [3], a game theoretic leader-follower type approach is presented for a dynamic platform defense where the strategies are chosen so as to be diverse, based on statistical analysis rather than
being uniformly distributed. They find similarity among different
configurations of the MTD system, which is difficult in the domain
of web applications. The work fails to consider the uncertainty in
the attacker model and the costs for switching.
These aspects of uncertainty in the attacker model and attacker
reconnaissance are handled effectively via Bayesian Stackelberg
Games (BSG), making it an appropriate choice for modeling the
web applications domain. Our modeling could help us leverage the
existing solution methods in the physical security domains [17]
and provide scalable and optimal switching strategies for cyber-

3.

MOVING TARGET DEFENSE FOR WEB
APPLICATIONS

In this section, we present a brief overview of the web application domain and its functionality which will be useful for understanding the challenges involved in generating solution strategies.

3.1

Configuration

A configuration set for a web application stack is denoted as C =
C1 × C2 · · · × Cn where there are n-technological stacks. Here, Ci
denotes the set of technologies that can be used in the i-th layer
of the application stack. A valid configuration c is an n-tuple that
preserves the system’s operational goals.
Consider a web application that has two layers (n = 2) where
the first layer denotes the coding language the web-application was
coded in and the second layer denotes the database that stores the
data handled by this application. Say, the technologies used in each
layer are C1 = {Python, PHP} and C2 = {MySQL, postgreSQL}.
A valid configuration can be (PHP, MySQL). The diversity of an
MTD system, which is the number of valid configurations, can be
4 (at max) in this case.

3.2

Attack

Software security is defined in terms of three characteristics Confidentiality, Integrity and Availability [10]. In a broad sense, an
attack on a web application is defined as an act that compromises
any of the aforementioned characteristics. The National Vulnerability Database (NVD) is a public directory of known vulnerabilities
and exposures affecting all technologies that can be used in a web
application. The Common Vulnerabilities and Exploits (CVEs) in
this database list vulnerabilities and corresponding attacks that can
be used to compromise an application using the affected technology. As each CVE has an exploit associated with it, we use the
terms vulnerability and attack interchangeably going forward.

3.3

Switching Strategy

This is a decision making process for the defender to select the
next valid system configuration c0 given c as the present system
configuration (where both c, c0 ∈ C). If pc represents the probability that c is chosen in a given deployment cycle through
randomizaP
tion, a switching strategy is f : C → pc where
pc = 1 ∀ p c ∈
c∈C

[0, 1]. To add to the complexity, the cost for switching from a configuration c to another configuration c0 can be nontrivial and non-

uniform. Thus, the aim of a good strategy is to maximize the effectiveness of an MTD system while trying to minimize the cost for
switching. Present state-of-the-art MTD system for web applications use a uniformly distributed switching strategy (pc = 1/|C|)
and assume that switching between configurations incur a uniform
cost [18].
We now develop a game theoretic system to generate switching strategies for the MTD web application that 1) shows a uniformly distributed switching strategy is sub-optimal and 2) considers the non-negative non-uniform costs of switching between different configurations of an MTD system.

4.

GAME THEORETIC MODELING

In this section, we model the setup of MTD systems in as a repeated step Bayesian Game.

4.1

Agents and Agent types

There are (N =) two players in our game, a defender and an attacker. The set θi is the set of types for player i (= {1, 2}). Thus, θ1
and θ2 denotes the set of defender and attacker types respectively.
The j−th attacker type is represented by θ2j .
When an attacker attacks an application, its beliefs about what
(resource/data) is most valuable to the application owner (defender)
remains consistent. Thus, we assume that the attacker knows that
there is only one type of defender when (s)he attacks a particular
web application. Thus, we have |θ1 | = 1.
We consider finite types of attackers. Each attacker type is defined in our model using a 3 tuple,
θ2i = hname, {(expertise, technologies) . . . }, probabilityi
where the second field is a set of two dimentional values that express an attacker’s expertise (∈ [0, 10]) in a technology. The rationale for using values in this range stems from the use of Common
Vulnerability Scoring System (CVSS) described later. Lastly, the
set of attacker types have a discrete probability distribution associated with it. The probability Pθ2j represents the defender’s belief
about the attacker type θ2j attacking their application. Obviously,
the probability values of all attacker types sum up to one.
X
Pθ2j = 1
θ2j ∈θ2

Note that one can define attacker expertise over a ‘category of attacks’ (like ‘BufferOverflowAttacks’) instead of technology specific
attacks. We feel the latter is more realistic for our domain. This definition captures the aspect that an attacker type can have expertise
in a set of technologies. Since, these attacker types and the probability distribution over them are application specific, it is defined by
a domain expert and taken as an input to our proposed model. For
instance, a defender using a no-SQL database in all configurations
of his MTD system, assigns zero probability to an ‘SQL_database’
attacker type because none of their attacks can compromise the security of his present system.
The assumption that the input probability distribution over all
the attacker types can be accurately specified is a strong one. We
later discuss how errors in judgment can affect the effectiveness of
a switching strategy and define a measure to capture the robustness
of the generated policy in such circumstances.

4.2

Agent actions

We define Aθi as a finite set of actions available to player i. The
defender action set, Aθ1 is a switch action to a valid configuration,
c of the web application. The maximum number of actions (or pure

strategies) for the defender can ideally be |C1 | × |C2 | · · · × |Cn |.
This might be lower since a technology used in layer x might not
be compatible when paired with a technology used in layer y (6= x)
rendering that configuration invalid.
For the attacker, Aθ2 represents the set of all attacks used by
atleast one attacker type. A particular attack a belongs to the set
Aθ2 if it affects atleast one of the technologies used in the layers
for our web application (C1 ∪ C2 · · · ∪ Cn ).
We now define a function f : (θ2t , a) → {1, 0} for our model.
The function implies an attack a is a part of the attacker type θ2t ’s
arsenal Aθ2t (⊆ Aθ2 ) if the value of the function is 1. This function value is based on the similarity between (i) the expertise of the
attacker type contrasted with the ‘exploitability’ necessary to execute the attack, and (ii) the attacker’s expertise in the technology for
which the attack can be used. We provide a concrete definition for
the function f after elaborating on what we mean by exploitability
of an attack.
For (almost all) CVEs listed in the NVD database, we have a sixdimensional CVSS v2 vector representing two independent scores
– Impact Score (IS) and Exploitability Score (ES). For an attack action a, ESa (∈ [0, 10]) represents the ease of exploitability (higher
is tougher). For each attack, the database also lists a set of technologies it affects, say T a .
Let us consider the set of technologies an attacker type t has
expertise in is Tt . Now we define the function f as,

1, iff Tt ∩ T a 6= φ ∧ ESa ≤ expertiset
f (θ2t , a) =
0 otherwise

4.3

Reward values for the Game

Now that we have attack sets for each attacker type, the general
reward structure for the proposed game is defined as follows:

 +xa if a ⊂ υ(c)
A
−ya if a can be detected or a ⊂ c0
Ra,θ
=
,c
2i
 0
otherwise

−x
if
a ⊂ υ(c)

d
D
+y
if
a can be detected or a ⊂ c0
Ra,θ
=
d
,c
2i

0
otherwise
A
D
where Ra,θ
and Ra,θ
are the rewards for the attacker type
2i ,c
2i ,c
and the defender respectively, when the attacker type θ2i uses an
attack action a against a configuration c (∈ C). The function υ(c)
represents the set of security vulnerabilities (CVEs) that configuration c has. Also, c0 refers to a honey-net configuration. A honey-net
is a configuration setup with intentional vulnerabilities to invite attackers for catching (or observing) them.
Note that the reward values when a attacker does not attack (NOOP action), is zero. Moreover, a defender gets zero reward for successfully defending a system. We reward him positively only if
he/she is able to reveal some more information or catch the attacker
without impacting operation requirements for the non-malicious
users (or using honey-nets). He gets a negative reward if an attacker
successfully exploits his(/her) system.
To obtain reward values for the variables xa , ya , xd and yd , we
make use of CVSSv2 metric. This metric provides the Impact (IS)
and Exploitability Scores (ES), stated above, which are combined
to calculate a third score called Base Score (BS) [11]. Using these,
we now define the following:

xd
xa

=
=

−1 ∗ IS
BS

Note that BS considers both the impact and the exploitability.
When the IS for two attacks are the same, the one that is easier

to exploit gets the attacker a higher reward value. The ease of an
attack can be interpreted in terms of the resource and effort spent
by an attacker for an attack Vs. the reward (s)he attains by harming
the defender. Although the robustness of our framework provides
provisions for having yd and ya , detecting attacks on a deployed
system or setting up honey-nets is still in its nascent stages. Hence,
there are no actions where values of yd or ya are required in our
present application.
Before we move on, we describe briefly what security dimensions the independent scores (IS and ES) are actually trying to capture in the context of a real world software system. For this purpose,
we first define the 6 independent values that generate these scores.
• Access Vector (AV) is dependent on the amount of access an
attacker needs to exploit a vulnerability. Thus, an attack that
needs physical access to a system will have lower score than
one that can be exploited over the Internet by any machine.
• Access Complexity (AC) represents the complexity of exploiting an attack. A buffer overflow attack on an Internet
service is less complex than an e-mail client vulnerability in
which a user has perform attachment downloads followed by
executing it and hence has lower AC value.
• Authentication (Au) level required to execute the attack. For
example, if no sign-up account is required to exploit the system, this value is high. In contrast, if one needs multiple accounts to exploit the vulnerability, the value is low.
• Confidentiality Impact (C) scores are low if only some (nonrelevant) information gets leaked. Highest impact occurs when
say, the entire database is compromised if the vulnerability is
successfully exploited.
• Integrity Impact (I) refers to the attacker’s power to modify files or behaviour of a system if he executes the exploit
successfully. The more the power– say the attacker is able
to change code or remove arbitrary files in the system– the
higher this value.
• Availability Impact (A) represents the power of a successful
exploit to bring down the availability of a system. A successful Denial of Service (DoS) that brings down an application
server, will have high impact.
From these values, one can obtain the two independent scores using
the following formulas,
20 ∗ (AV ) ∗ (AC) ∗ (Au)

ES

=

IS

= −10.41 ∗ (1 − (1 − C)(1 − I)(1 − A))

A rigorous treatment of assigning these values can be found in [11].
The CVSS values are generated by security experts across the globe
and the database is updated every single day.
Our model takes a time range as input. It then parses all the CVEs
(a) from the NVD in that time range to finally filter out the ones
that can affect atleast one of the configurations in our system (a ⊂
υ(ci )). Note that old CVEs are irrelevant for generating attack sets
for a relatively new MTD system as they either have no effect on the
updated versions of the technologies they can affect or have popular
solutions to prevent them while developing the application. For our
application, we obtain this input range from our security experts.

4.4

Switching Cost

The switching costs can be represented by a K n×n matrix where
the n rows (and columns) denote the n system configurations. The

cell Kij denotes the cost of switching when the defender moves
from configuration i to configuration j. As mentioned earlier, the
values in K are all non-negative. Our security experts, who have
written the code to automatically move from one configuration to
another, hand code these values in each cell of the martix. We provide some guidance in choosing these values here and give a concrete example on how we selected these for our application later.
If there is no common technology between configurations c and
c0 involved in a switch operation, the cost will be large. Also, switching technologies in a specific layer may incur more cost than switching technologies in other layers. In the developed MTD system, we
find that switching between databases incur large costs because the
structure of the data needs to be changed for shifting, and the time
required to copy huge amounts of data from one database to another
must also be accounted for.
The matrix K for our system turns out to be symmetric, i.e.
Kij = Kji ∀ i, j ∈ {1, . . . n}. Also, Kii = 0, which implies
that there is no cost if no configuration switch occurs. Note that
although our security experts think this is the structure of rewards
for the developed system, the modelling is generic enough to allow
for asymmetric costs. Lastly, we choose the values of Kij in the
range [0, 10]. The reason for this upper bound becomes clear in the
upcoming section.

5.

SWITCHING STRATEGY GENERATION

In this section, we first introduce the notion of Stackelberg Equilibrium for our security game, that gives us a defender strategy that
maximizes his reward (and thus the security of the system). We
briefly talk of optimization methods, relevant to our domain, that
can produce this. Finally, we incorporate the costs of switching into
the objective function and propose our solver.

5.1

Stackelberg Equilibrium

The strategy generated for the designed game needs to capture
the reconnaissance aspect. Note that the game starts only after the
defender has deployed the web application, acting as a leader. This
now becomes a repeated game in which an attacker can observe a finite number of switch moves and probabilistically learn the switching strategy (since |C|  ∞) of the defender. Thus, the defender
has to select a strategy that maximizes his reward in this game,
given that the attacker knows his strategy. This is exactly the problem of finding the Stackelberg Equilibrium in a Bayesian Game
[20]. The resulting mixed strategy is the switching strategy for the
defender in our MTD system. Unfortunately, this problem becomes
NP-hard in our case because of multiple attacker types [5].
Before we find a strong Stackelberg Equilibrium for our proposed game, we state a couple of well founded assumptions we
make. Firstly, an attacker chooses a pure strategy, i.e., a single attack action that maximizes his reward value. This assumption is
popular in prior work on security games because for every mixed
strategy for the attacker, there is always a pure strategy in support
for it [14]. Secondly, we assume that the pure strategy of an attacker
type is not influenced by the strategy of other attacker types. This
is not limiting for our web application domain since an attacker
type’s attack selection is independent of the attack action chosen
by another type.
To solve for the optimal mixed strategy, one can use the Decomposed Optimal Bayesian Stackelberg Solver (DOBSS) [13]. This
optimizes the expected reward of the defender over all possible
mixed strategies for the defender (~
x), and pure strategies for each
~θ ). We
attacker type (~nθ2i ) given the attacker type uncertainty (P
2i
now define the objective function of the Mixed Integer Quadratic

Program (MIQP) in Equation 1.
X X X
D
max
Pθ2i Ra,θ
xc naθ2i
2i ,c
x,n,v

Moving Target Defense
Web application

(1)

?

Incorporating Switching Costs

As defined in the last section, the cost for switching from a configuration i to a configuration j can be represented as Kij . The
probability the system is in configuration i and then switches to
configuration j is xi · xj . Thus, the cost incurred by the defender
for a switch action fromP
i toP
j is Kij · xi · xj . The expected cost
Kij · xi · xj .
for any switch action is
i∈C j∈C

To account for cost, we can subtract this from the objective function of Equation 1 with a cost-accountability factor α (≥ 0) to
obtain
X X X
XX
D
Pθ2i Ra,θ
x nθ2i −α·
max
Kij ·xi ·xj
2i ,c c a
c∈C θ2i ∈θ2 a∈Aθ
2i

i∈C j∈C

Unfortunately, this results in a Bilinear Mixed Integer Programming problem, which is not convex. To ameliorate this problem,
we now introduce new variables wij that essentially represent an
approximate value of xi · xj . We first use the piecewise linear McCormick envelopes to design a convex function using these wij s that estimates a good solution to this problem [21]. Along with
these constrains, we introduce further constrains which we describe
after introducing the final MIQP convex optimization problem as
follows,
max

x,n,v

X X

X

D
θ2i
Pθ2i Ra,θ
xc na
− α·
2i ,c

c∈C θ2i ∈θ2 a∈Aθ
2i

XX

Kij wij

i∈C j∈C

(2)

X

s.t.

xc

=

1

(3)

naθ2i

=

1

(4)

c∈C

X
a∈Aθ

0 ≤ v θ2i −

X

2i

A
Ra,θ
x
2i ,c c

Figure 1: A moving target defense web application system
xc ∈ [0 . . . 1], nθa2i ∈ {0, 1}, v θ2i ∈ R
∀ c ∈ C, θ2i ∈ θ2 , a ∈ Aθ2i

i∈C

j∈C

j∈C

constrains (10) and (11).
If we now allow the maximum cost of switching to be 10, we can
see that the values for the cost is comparable in magnitude to the
value of the defenders rewards. This helps us to provide a semantic
meaning for the cost-accountability factor, α.
The first term in the objective function seeks to maximize the
defender’s reward, which in turn maximizes the security of the web
application. The second term on the other hand, seeks to reduce
the expected cost of the switching actions. Thus, α represents how
much importance is given to the cost of switching Vs. the level of
security desired. Consider the extreme cases, when α = 0, we are
producing the most secure strategy (which is the Stackelberg Equilibrium) and considering switching between configurations incur
zero costs. This is the sub-set of solutions that are developed mostly
for physical security systems. In contrast to that, when α = 1, we
are saying that we consider switching costs as important as the security of our MTD application.
Choosing the correct value of α is not trivial and often dependent
on the specific web-application. For example, if a banking system
someday seeks to operate on a MTD system, we hope it puts more
weight on security than switching costs, selecting low α values. To
provide a sense to the reader, we later show in the experimental section, how strategies and reward values are effected with changing
alpha values.

wij
wij

≥ 0 ∀ i, j
≤ xi ∀ i, j

(6)
(7)

wij

≤ xj ∀ i, j

(8)

6.

(9)

The goal of this section is to answer three key questions. Firstly,
does our proposed Bayesian Stackelberg Game (BSG) model generate better strategies that the state-of-the-art? Secondly, can we
effectively compute the set of critical vulnerabilities? Lastly, who
are the sensitive attacker types and how robust is our model?

1 ∀ i, j

wij

=

wij

= xi ∀ i

(10)

wij

= xj ∀ j

(11)

j∈C

X

where M is a large positive number. ~nθ2i and v θ2i give the pure
strategy and its corresponding reward for the attacker type θ2i respectively, and ~
x gives the mixed switching strategy for the defender. (5) solves the dual problem of maximizing rewards for each
attacker type (v θ2i ) given the defender’s strategy. This ensures that
attackers always select the best attack action. The constrains (6), (7)
and (8) represent the McCormick envelope that provides lower and
upper
bounds on each wij . Since we consider all possible switches,
P P
xi · xj = 1. This is enforced by constrain (9). Lastly, for
j∈C i∈C
P
P
xj ) = xi . This is represented by the
xi · xj = xi · (
each i,

(5)

j∈C i∈C

X

Automated Code
converter

𝑐1 = {Python, MySQL}

≤ (1 − naθ2i )M

c∈C

XX

𝑐4 = {php,
postgreSQL}

𝑐3 = {php, MySQL}

2i

x,n,v

𝑐2 = {Python,
postgreSQL}

c∈C θ2i ∈θ2 a∈Aθ
2i

Notice that this does not consider that switching costs between defender strategies. Essentially, this means the formulation assumes
that switching costs are uniform. Before we address this limitation
in the upcoming subsection, we take a little digression.
For our scenario, we have many attack actions. Thus, we observe that solving the MIQP version is more efficient (in computation time and memory usage) than solving the Mixed Integer Linear
Program (MILP) version of the DOBSS. This can be attributed to
the fact that the MILP formulation results in an increase in the dimensions
solution space. Theoretically, the MIQP solves for
P of theP
|C| + θ2i ∈θ2 aj ∈Aθ |aj | variables where as the MILP solves
P
P 2i
for |C| ∗ θ2i ∈θ2 aj ∈Aθ |aj | variables.

5.2

𝑐1 = {Python,
MySQL}

6.1

EMPIRICAL EVALUATION

Test Bed Description

PHP,
MySQL
Python,
MySQL
PHP, postgreSQL
Python,
postgreSQL

PHP,
MySQL

Python,
MySQL

PHP, postgreSQL

Python,
postgreSQL

Name

0

2

6

10

2

0

9

5

6

9

0

2

10

5

2

0

Script Kiddie
(SK)
Database
Hacker (DH)
Mainstream
Hacker (MH)

Table 1: Swithing costs for our system

• Switching between different languages while keeping the same
database dialect incurs minimal cost - workload is primarily
done is primarily on rerouting to the correct server with the
source language
• Switching between different database dialects while keeping
the same language incurs a slightly higher cost due to the
conversion required for the database structure and its contents. One also has to account for copying large amounts of
data to the database used in the current system configuration.
• Switching between different database dialects AND different
languages incur the most cost due to the combination of the
costs of conversion for the database as well as the penalty for
rerouting to the correct server with the source language.
The attacker types along with the attack action set size are defined in Table 2. We mined the NVD for obtaining CVE data from
January, 2013 to August, 2016 to generate these attack sets. If the
stakes of getting caught are too high for an attacker type given an
MTD system, he/she may choose not to attack. Hence, we have a
NO-OP action for each attacker type.
The optimization problems for the experiments were solved using Gurobi on an Intel Xeon E5 2643v3@3.40GHz machine with
6 cores and 64GB of RAM.

6.2

Strategy Evaluation

We evaluate our method using Bayesian Stackelberg Games on
our real life web application against the Uniform Random Strategy (URS), which is the state-of-the-art in such systems [18]. We
plot the values of the objective function in Equation 2 for both the

Prob.

|Aθ2i |

0.15

34

0.35

269

0.5

48

Table 2: Attacker types and attack action counts
BSG
U RS

−4
Obj

To answer the questions mentioned above, we develop a real
world MTD web application (shown in Figure 1) with 2 layers.
The key idea of applying MTD to web applications requires you to
have several versions of the same system, each written in either a
different language, using a different database, etc.
This diversity is not ubiquitous in legacy web applications, due
to cost, time, and resources required to build several versions of the
same web application. To aid this, we developed a framework to
automatically generate the diversity necessary for this web application. The current prototype is able to convert a web application
coded in Python to an equivalent one coded in PHP, and vice versa,
as well as a web application using a MySQL database to an identical version that uses PostgreSQL, and vice versa. In the future,
as more and more variations are developed, the set of defender’s
actions will increase.
The present set of valid configurations for our system is C =
{(PHP, MySQL), (Python, MySQL), (PHP, postgreSQL), (Python,
postgreSQL )}. The costs for switching between configurations is
shown in Table 1. These cost values generated by our system administrators are based on the following considerations:

(Technologies,
Expertise)
(PHP,4),
(MySQL,4)
(MySQL,10),
(postgreSQL,8)
(Python,4),
(PHP,6),
(MySQL,5)

−6
−8

0

0.2

0.4

0.6

0.8

1

α

Figure 2: Objective function values for Uniform Random Strategy Vs. Bayesian Stackelberg Game with switching costs as α
varies from 0 to 1.
strategies as α varies from 0 to 1. For URS, we use the exact values of wij = 0.25 ∗ 0.25 = 0.0625 ∀ i, j. The plot is shown in
Figure 2. Both are straight lines because although the value of α
changes, the strategy for URS is same (by definition) and the one
generated by BSG also remains the same. The latter case came as
a surprise to us initially. On further investigation, we noticed that
in the formulated game for our web-application, the Stackelberg
Equilibrium for our application (luckily) coincides with the least
switching cost strategy.
These attacker and defender strategies is shown in Table 3 alongwith the value of the defender’s reward (i.e. the first term in the objective function in Equation 2). Notice that, not only is the mixed
strategy generated by BSG more secure than URS, it leverages
fewer configurations than all valid configurations |C| = 4 the system has to offer. This result is in unison with previous work in
cyber-security which show that having many configurations does
not necessary imply that all of them have to be used for providing
the best security [3].

6.2.1

Studying the effect of α-values
To empirically show that our solver is actually considering costs
of switching, we change the value for switching from (PHP, postgreSQL ) to (Python, postgreSQL) and vice-versa from 2 (yellow boxes in Table 1) to 10. We plot this scenario in Figure 3. As
soon as α ≥ 0.4, the BSG generates (0.25, 0.25, 0.25, 0.25, 0.25)
(which is URS) as the most optimal strategy. After analysis, we
note that this happens because the most powerful attack actions in
the arsenal of the attacker types are for the systems (PHP, MySQL)
and (Python, MySQL). When, one does not prioritize switching
costs (α ∈ {0, 0.1, 0.2, 0.3}), the system keeps switching between
the more secure configurations nullifying the good attacks of the
attackers. As switching costs start to get more significant (α ∈
{0.4, 0.5, . . . 1.2}), the objective function value reduces if it sticks
to the stronger configurations since switching costs are now high
for these. It switches to the URS in this case. Beyond that, it switches

Method

Mixed Strategy

Defender’s
Reward

Attack sets (SK,
DH, MH)

k

CV sets

URS

(0.25, 0.25, 0.25,
0.25)

-5

1
2

BSG

(0, 0, 0.5, 0.5)

-3.25

CVE-2016-3477,
CVE-2015-3144,
CVE-2016-3477
CVE-2014-0185,
CVE-2014-0067,
CVE-2014-0185

{(CVE-2014-0185)}
{(CVE-2014-0185,
CVE-2015-5652)}

P (configuration= c)

Table 3: Comparison between the strategies generated by Uniform Random Strategy (URS) Vs. Bayesian Stackelberg Game
(BSG)
php_mysql
py_mysql
php_psql
py_psql

0.4

0.2

0
0

0.5

1

1.5

2

2.5

α→
BSG
U RS

Obj

−5
−10
−15

0

0.5

1

1.5

2

2.5

to the strategy (0.25, 0.5, 0, 0.25) as α keeps on increasing. When
α becomes close to 2, it completely ignores the security of the
system and tries to minimize the switching cost by proposing the
strategy (0.5, 0.5, 0, 0) as the cost for switching between (PHP,
MySQL) and (Python, MySQL) is the least (= 2).
In the bottom of Figure 3, we showcase the change in the values of objective function. At the start, the BSG generates a better
strategy when compared to URS. When the BSG strategy becomes
the same as the URS (for 0.4 ≤ α ≤ 1.2), we observe that the
objective function value for BSG is lower than URS. This is not
surprising since BSG is merely trying to estimate the value xi · xj
with the variables wij , whereas URS is using the exact value. As
we increase α further, we are essentially discouraging an MTD system, since now the cost of switching has become so high, whereas
naive URS pays no heed to this.

6.3

Identifying Critical Vulnerabilities

In real-world development teams, it is impossible to solve all the
vulnerabilities, especially in a system with so many technologies.
In current software systems, given a set of vulnerabilities, a challenging question often asked is which vulnerabilities should one fix

CPU Time
3m15s
421m27s

Table 4: Most critical vulnerability in the MTD system and the
time required to generate it.

to improve the security?
For an MTD system, this becomes a tough problem since the defender needs to reason about multiple attacker types– their probabilities and attack actions. For a given k, the set of k vulnerabilities,
which on being fixed, result in the highest gain in defender strategy,
is termed as the k critical vulnerability set (k−CV).
To address this problem, we remove each k-sized attack set from
the set of all attacks (A02 = A2 \ D ∀ D ⊂ A2 & |D| = k)
and evaluate the objective function (Equation 2). The sets A02 that
yield the highest objective values, provide the vulnerabilities D that
should be fixed to improve the defender’s system.
We tried to study this complicated behaviour for some toy examples before applying it to our application. An interesting phenomenon we noticed was that a k-set critical vulnerabilities (k−CV)
is not always a subset of the (k + 1)−CV. Suppose we want to find
3 vulnerabilities that we want to fix. Since it is not just a super-set
of the 2-CV, we need to solve this problem from the scratch with
k = 3. Hence, there is going to be combinatorial explosion here.
As

the value of k increases, we end up solving |A02 | = |Ak2 | MIQP
problems to identify the k−CVs.

6.3.1

α→

Figure 3: Top: Showcases the change in probabilities associated
with a particular configuration. Bottom: Objective function
values for Uniform Random Strategy Vs. Bayesian Stackelberg
Game with switching costs as α varies from 0 to 2.5 when the
cost of switching are as showcased in Table 1 with the values in
the yellow boxes being 10.

Objective
Value
-2.435
-1.973

Finding Critical Vulnerabilities in the Developed System

For our system, we start with k = 1, we increase number of critical vulnerabilities to be found by 1 at each step. The result remains
the same for α ∈ [0, 1] for our system. We do not play around
with α beyond this, mostly because this would be unrealistic for
any practical application. Unfortunately, the brute force approach
and the scalability of algorithms for solving normal extensive form
BSGs proves to be a key limitation.
This is not a surprise since the total number of unique CVEs
spread out among
the attackers is 287. When k = 3, we end up

solving 287
optimization
problems, which fails to scale in both
3
time and memory. Thus, we only show critical vulnerabilities identified up to k = 2 (in Table 4) using α = 0.2.
At present, we are trying to develop a single MIQP formulation
that tries to approximately generate the k-CV set. To reduce the
combinatorial explosion, we plan to use switch variables that can
turn attack actions on and off. This comes at the cost of increasing
the number of variables in the formulated optimization problem.

6.4

Model Robustness & Attacker
Type Sensitivity

It is often the case that a web application administrator (defender)
cannot accurately specify the probability for a particular attacker
type. In this section, we see how this uncertainty affects the optimal rewards generated by the system. We provide a notion for
determining sensitive attacker types and measuring the robustness
of a switching strategy.
For each attacker type i, we vary the probability Pθ2i by ±x%
x
)) where x is the sensitivity factor, which
(Pθnew
= Pθ2i (1 ± 100
2i
can be varied from a low value to a high value as needed. Note that
x
now p = Pθ2i × 100
needs to be adjusted or distributed amongst the

probabilities of the remaining attacker types. To make sure that this
distribution is done such that the sensitivity of attacker i actually
stands out, we propose to distribute p amongst the other attacker
types using a weighted model as per their existing probabilities as
shown below. For attacker j (6= i), its new probability would be:
= Pθ2j (1 ∓

P p
Pθ
k(6=i)

)
2k

NLR(BSG)

Pθnew
2j

M ainstreamHacker(M H)

2

Rn −Ro
Rn

−100

−50

CONCLUSIONS AND FUTURE WORK

In this paper, we propose a method to generate a switching strategy for real-world web application based on the Moving Target Defense (MTD) architecture. To find an effective switching strategy,
we model the system as a repeated Bayesian game. We develop
methods to assign attack actions to attacker types and generate realistic utilities based on expertise of security professionals. For obtaining real-world attack data, we mine vulnerabilities in the National Vulnerability Database (NVD) and obtain utilities based on
the Common Vulnerability Scoring System (CVSS). We formulate
an optimization problem which outputs a switching strategy that
maximizes system security while accounting for switching costs.
The generated strategy is shown to be more effective than the stateof-the-art for a real-world application. We also provide metrics that
can be used to validate the robustness of switching strategies, absent in literature for multi-agent cyber-security systems. Lastly, we
propose the problem of identifying critical vulnerabilities and provide a solution.
The techniques in this paper are not limited to only web applications. The attack actions mined from the security databases relate to

50

100

50

100

NLR(URS)

DatabaseHacker(DH)
ScriptKiddie(SK)

5

0
−100

Evaluation Based on the Developed System

0

M ainstreamHacker(M H)

(13)

We compute the attacker sensitivity for our system varying the
probability of each attacker type from −100% to +100% (of its
modeled probability) with 10% step sizes. We plot the results in
Figure 4 using Equation 13. The Mainstream and Database hacker
(MH & DH) are the least sensitive attacker types. The NLR values
for both these attackers are 0. This is the case since the real world
attack action used by these types remain the same even when their
probabilities change. On the other hand, if the probability associated with the Script Kiddie (SK) is underestimated in our model,
we see that the strategies deviate substantially from the optimal.
For our experiments in this section, we use α = 0.2. The max
NLR for our BSG strategy is 2.35 Vs. 9 for URS. The average of
the 60 NLR values is 0.061 for BSG and 0.88 for URS. These values indicate our model is more robust to variance in attacker type
uncertainty than the present state-of-the-art.

7.

1

0

Note that NLR values are ≥ 0. Higher values of NLR represent
more sensitive attacker types. Inaccurate probability estimates for
the sensitive attackers can be detrimental to the security of our
application. Note that lower NLR values indicate that a generated
strategy is more robust.

6.4.1

ScriptKiddie(SK)

(12)

~θ , then the sign in
When x% is subtracted from the probability P
2i
the above equation becomes positive, and vice-versa.
We now formally define the loss in reward to the defender as the
probability distribution over the attacker types change. Let Ro be
the overall reward for the defender when he uses the mixed strategy
for the assumed (and possibly incorrect) model of attacker type un~θnew ). Let Rn be the defender’s
~θ2 ) on the true model (P
certainty (P
2
optimal reward value for the true model. We compute the Normalized Loss in Rewards (NLR) for the defender’s strategy as follows:
NLR =

DatabaseHacker(DH)

−50

0

Varying sensitivity of attacker types (%)

Figure 4: NLR values for BSG and URS genereated strategies
when attacker types probabilities vary in [−100%, 100%].
all kinds of technologies, like operating systems, coding languages
etc. Hence, the modelling should be relevant to any software applications using the MTD architecture. It would be interesting to see
how effective they are in such scenarios.
Investigating the reward structure for a particular problem has
helped design provably fast solvers in the physical security domains. We believe this direction of research might help in developing faster solvers, alleviating the scalability problem of identifying
critical vulnerabilities, for the cyber-security domain as well.

8.

ACKNOWLEDGMENTS

This work was partially supported by the grants from National
Science Foundation (NSF-SFS-1129561) and the Center for Cybersecurity and Digital Forensics at Arizona State University.

REFERENCES
[1] K. Amin, S. Singh, and M. Wellman. Gradient methods for
stackelberg security games. AAMAS, 2016.
[2] D. Balzarotti, M. Cova, V. Felmetsger, N. Jovanovic,
E. Kirda, C. Kruegel, and G. Vigna. Saner: Composing static
and dynamic analysis to validate sanitization in web
applications. In Security & Privacy 2008. IEEE Symposium,
pages 387–401, 2008.
[3] K. M. Carter, J. F. Riordan, and H. Okhravi. A game
theoretic approach to strategy determination for dynamic
platform defenses. In ACM MTD Workshop, 2014, MTD ’14.
ACM, 2014.
[4] M. Carvalho and R. Ford. Moving-target defenses for
computer networks. Security Privacy, IEEE, 12(2):73–76,
Mar 2014.
[5] V. Conitzer and T. Sandholm. Computing the optimal
strategy to commit to. In Proceedings of the 7th ACM
Conference on Electronic Commerce, EC ’06, pages 82–90,
New York, NY, USA, 2006. ACM.
[6] A. Doupé, L. Cavedon, C. Kruegel, and G. Vigna. Enemy of
the state: A state-aware black-box web vulnerability scanner.
In USENIX Security Symposium, 2012.

[7] S. H. Houmb, V. N. Franqueira, and E. A. Engum.
Quantifying security risk level from cvss estimates of
frequency and impact. JSS, 83(9):1622–1634, 2010.
[8] S. Jones, A. Outkin, J. Gearhart, J. Hobbs, J. Siirola,
C. Phillips, S. Verzi, D. Tauritz, S. Mulder, and A. Naugle.
Evaluating moving target defense with pladd. Technical
report, Sandia National Labs-NM, Albuquerque, 2015.
[9] P. Manadhata. Game theoretic approaches to attack surface
shifting. In Moving Target Defense II, volume 100 of AIS,
pages 1–13. Springer New York, 2013.
[10] J. McCumber. Information systems security: A
comprehensive model. In Proceedings of the 14th National
Computer Security Conference, 1991.
[11] P. Mell, K. Scarfone, and S. Romanosky. Cvss v2 complete
documentation, 2007.
[12] H. Okhravi, T. Hobson, D. Bigelow, and W. Streilein.
Finding focus in the blur of moving-target techniques.
Security & Privacy, IEEE, 12(2):16–26, 2014.
[13] P. Paruchuri, J. P. Pearce, J. Marecki, M. Tambe, F. Ordonez,
and S. Kraus. Playing games for security: An efficient exact
algorithm for solving bayesian stackelberg games. In
AAMAS, 2008, pages 895–902, 2008.
[14] J. Pita, M. Jain, J. Marecki, F. Ordóñez, C. Portway,
M. Tambe, C. Western, P. Paruchuri, and S. Kraus. Deployed
ARMOR protection: the application of a game theoretic
model for security at the los angeles international airport. In
AAMAS 2008, Industry and Applications Track Proceedings,
pages 125–132, 2008.
[15] A. Prakash and M. P. Wellman. Empirical game-theoretic
analysis for moving target defense. In ACM MTD Workshop,
2015, 2015.
[16] J. Silver-Greenberg, M. Goldstein, and N. Perlroth.
JPMorgan Chase Hacking Affects 76 Million Households. In
The New York Times, 2014.
[17] A. Sinha, T. Nguyen, D. Kar, M. Brown, M. Tambe, and
A. X. Jiang. From physical security to cyber security.
Journal of Cybersecurity, 2016.
[18] M. Taguinod, A. Doupé, Z. Zhao, and G.-J. Ahn. Toward a
Moving Target Defense for Web Applications. In
Proceedings of 16th IEEE IC-IRI, 2015.
[19] M. Van Dijk, A. Juels, A. Oprea, and R. L. Rivest. Flipit: The
game of “stealthy takeover”. Journal of Cryptology,
26(4):655–713, 2013.
[20] H. Von Stackelberg. Market structure and equilibrium.
Springer SBM, 2010.
[21] D. S. Wicaksono and I. Karimi. Piecewise milp under-and
overestimators for global optimization of bilinear programs.
AIChE Journal, 54(4):991–1008, 2008.
[22] D. Wichers. Owasp top-10. OWASP, 2013.
[23] M. Winterrose, K. Carter, N. Wagner, and W. Streilein.
Adaptive attacker strategy development against moving
target cyber defenses. arXiv:1407.8540, 2014.
[24] R. Zhuang, S. A. DeLoach, and X. Ou. Towards a theory of
moving target defense. In ACM MTD Workshop, 2014, pages
31–40. ACM, 2014.

Moving Target Defense for Web Applications using
Bayesian Stackelberg Games
Sailik Sengupta, Satya Gautam Vadlamudi, Subbarao Kambhampati
Yochan Group, School of CIDSE
Arizona State University
{sailiks, gautam, rao}@asu.edu

Marthony Taguinod, Adam Doupé, Ziming Zhao, Gail-Joon Ahn
SEFCOM Lab, School of CIDSE
Arizona State University
{mtaguino, doupe, zmzhao, gahn}@asu.edu

ABSTRACT
The present complexity in designing web applications makes software security a difficult goal to achieve. An attacker can explore
a deployed service on the web and attack at his/her own leisure.
Moving Target Defense (MTD) in web applications is an effective
mechanism to nullify this advantage of their reconnaissance but the
framework demands a good switching strategy when switching between multiple configurations for its web-stack. To address this issue, we propose modeling of a real-world MTD web application
as a repeated Bayesian game. We then formulate an optimization
problem that generates an effective switching strategy while considering the cost of switching between different web-stack configurations. To incorporate this model into a developed MTD system,
we develop an automated system for generating attack sets of Common Vulnerabilities and Exposures (CVEs) for input attacker types
with predefined capabilities. Our framework obtains realistic reward values for the players (defenders and attackers) in this game
by using security domain expertise on CVEs obtained from the National Vulnerability Database (NVD). We also address the issue of
prioritizing vulnerabilities that when fixed, improves the security
of the MTD system. Lastly, we demonstrate the robustness of our
proposed model by evaluating its performance when there is uncertainty about input attacker information.

1.

INTRODUCTION

Present day web applications are widely used by businesses to
provide services over the Internet. Oftentimes, sensitive business
and user data are managed by these applications. Vulnerabilities in
these web applications pose serious threats to the confidentiality
and integrity of both businesses and users [16].
There exist numerous static (white-box) and dynamic (blackbox) analysis tools for identifying vulnerabilities in a system [2,
6]. These have become less effective in present times due to the
increasing complexity of web applications, their dependency on
downstream technologies, and the limited development and deployment time [22]. Worse yet, the attackers, with time on their side,
can perform reconnaissance and attack. To address this challenge,
we consider a Moving Target Defense (MTD) based approach [4],

A shorter version of this paper appears in: Proceedings of the
15th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2016), May 9–13, 2016, Singapore.

which complements the existing vulnerability analysis techniques
through a defense-in-depth mechanism.
The MTD based approach dynamically shifts a system over time
to increase the uncertainty and complexity for the attackers to perform probing and attacking [24], while ensuring that the system
is available for legitimate users. As the window of attack opportunities decreases, the effort in finding and successfully executing
an attack increases. Moreover, if an attacker succeeds in finding a
vulnerability at one point in time, it may not be exploitable at another time because of the moving defense system, making the web
application more resilient [18].
Various aspects that support Moving Target Defense approach
such as, using multiple implementation languages, multiple database
instances with synchronization, etc. are considered in different layers of web application architecture, along with ways to switch between them. However, the design of good quality switching strategies itself is left as an open problem. This is key to effectively leverage various move options—thereby maximizing the complexity for
the attacker and minimizing the damage for the defender.
Our aim in this paper is to design effective switching policies for
movement in the MTD system that maximize the security of the
web application, given the set of components and configurations
of the system which can be “moved around”, while simultaneously
considering realistic costs for “moving them around”. In web applications, the defender (leader) deploys a system up-front. The attacker observes (or follows) the system over time before choosing
an attack. These characteristics motivate us to formulate the MTD
system as a repeated Bayesian Stackelberg Game (BSG). For this
formulation to be meaningful in real-world applications, we use
real world attack data for our model. We propose a framework to
define attacker types for our game and automatically generate attack options for each of them by mining and characterizing Common Vulnerabilities and Exposures (CVEs). We develop a system
that leverages the knowledge in public attack databases and expertise of system administrators for obtaining meaningful game utilities and switching costs respectively.
For computing the movement policy for the defender, we initially
expected to be able to use existing solvers developed for physical
security systems [17]. Unfortunately, none of them considered the
cost of switching between strategies. Since this is highly relevant in
cyber-security systems, we had to formulate an optimization problem to consider these costs when generating strategies.
The increased complexity in an MTD systems exacerbates the
difficulty of prioritizing vulnerabilities that need to be fixed next.
We define this problem formally and propose a preliminary solu-

tion. Lastly, we talk about metrics to measure the robustness of
switching strategies generated by various models when the uncertainty about attacker types vary in the real world.
In section 2, we introduce the reader to the different ways people
have tried to address the problem of generating switching strategies for cyber-security systems. We introduce domain terminology
related to MTD systems for web-applications in section 3. In section 4, we develop the Bayesian Game model for this system defining attacker types, attack classification, rewards generated from security databases and strategy switching costs. To find an effective
switching strategy, we propose a solver that maximizes system security while accounting for switching costs in section 5. We empirically study the effectiveness and robustness of the strategy generated by our framework in section 6, comparing it to the stateof-the-art. We also formulate the problem of identifying critical
vulnerabilities and propose a preliminary solution in section 6. We
conclude the paper in section 7, highlighting promising research
directions.

2.

security systems. Unfortunately, these works, to our knowledge, do
not consider the cost the defenders incur when asked to switch from
a particular strategy to another. Hence, we propose a solver that
maximizes the defender’s reward and minimizes the overall cost
of switching between web-application configurations. Our solver
is essentially an extension of the DOBSS solver [13]. Although
there has been furhter development since DOBSS, the more recent solvers for BSGs make additional assumptions about the game
structure—either about the action sets of the defender, or the presence of hierarchical structure among attacker types [1], which do
not hold for the web application domain.
The use of Common Vulnerabilitiy Scoring System (CVSS) for
rating attacks is well studied in security [7]. We describe this metric later. CVSS provides a strong backbone for obtaining utilities
for our game theoretic model. None of the existing works (to our
knowledge) talk about the pragmatic aspect of prioritizing vulnerabilites in MTD systems. Also, there does not seem to be any standard metrics to capture the robustness of strategies generated by a
model. We address both these issues in the upcoming sections.

RELATED WORK

Although there exists prior work on the design of switching strategies for MTD systems, most of it is domain specific. Evaluation of
these strategies on real-world MTD systems for web applications
is scarce. We discuss some of these works, highlighting their limitations in the domain of web applications, thus motivating the need
for our solution. Existing efforts describe the use of randomized
switching strategies, and show its effectiveness for MTD systems
[24]. We empirically demonstrate that our strategy outperforms this
state-of-the-art for web applications, especially when the cost of
switching is negligible.
Attacker-defender scenarios have been modeled earlier as stochastic games for attack-surface shifting [9]. Other works model the
MTD problem as a repeated game where the defender uses uniform
random strategy with the exception that the same defense configuration is not deployed in two consecutive rounds [23]. This work
needs an in-depth analysis of code, which is unrealistic for complex
web applications.
Switching strategies for MTD systems based on detection of probes
by attackers are presented by [15]. Unfortunately, an accurate detection of attacks in web applications is difficult, if not impossible.
Furthermore, such strategies can lead to a detrimental performance
in repeated games if an intelligent attacker biases the system to
switch more towards MTD configurations where the attacker attains higher reward. In [8], the MTD system is modeled as a game
called PLADD, based on FlipIt games [19]. This work assumes
that different agents control the server in different game rounds,
which is impractical for most cyber-seccurity applications, essentially web applications. These techniques also fail to capture the
reconnaissance aspect of the attackers which is shown to be an important aspect in the attack phase [12].
In [3], a game theoretic leader-follower type approach is presented for a dynamic platform defense where the strategies are chosen so as to be diverse, based on statistical analysis rather than
being uniformly distributed. They find similarity among different
configurations of the MTD system, which is difficult in the domain
of web applications. The work fails to consider the uncertainty in
the attacker model and the costs for switching.
These aspects of uncertainty in the attacker model and attacker
reconnaissance are handled effectively via Bayesian Stackelberg
Games (BSG), making it an appropriate choice for modeling the
web applications domain. Our modeling could help us leverage the
existing solution methods in the physical security domains [17]
and provide scalable and optimal switching strategies for cyber-

3.

MOVING TARGET DEFENSE FOR WEB
APPLICATIONS

In this section, we present a brief overview of the web application domain and its functionality which will be useful for understanding the challenges involved in generating solution strategies.

3.1

Configuration

A configuration set for a web application stack is denoted as C =
C1 × C2 · · · × Cn where there are n-technological stacks. Here, Ci
denotes the set of technologies that can be used in the i-th layer
of the application stack. A valid configuration c is an n-tuple that
preserves the system’s operational goals.
Consider a web application that has two layers (n = 2) where
the first layer denotes the coding language the web-application was
coded in and the second layer denotes the database that stores the
data handled by this application. Say, the technologies used in each
layer are C1 = {Python, PHP} and C2 = {MySQL, postgreSQL}.
A valid configuration can be (PHP, MySQL). The diversity of an
MTD system, which is the number of valid configurations, can be
4 (at max) in this case.

3.2

Attack

Software security is defined in terms of three characteristics Confidentiality, Integrity and Availability [10]. In a broad sense, an
attack on a web application is defined as an act that compromises
any of the aforementioned characteristics. The National Vulnerability Database (NVD) is a public directory of known vulnerabilities
and exposures affecting all technologies that can be used in a web
application. The Common Vulnerabilities and Exploits (CVEs) in
this database list vulnerabilities and corresponding attacks that can
be used to compromise an application using the affected technology. As each CVE has an exploit associated with it, we use the
terms vulnerability and attack interchangeably going forward.

3.3

Switching Strategy

This is a decision making process for the defender to select the
next valid system configuration c0 given c as the present system
configuration (where both c, c0 ∈ C). If pc represents the probability that c is chosen in a given deployment cycle through
randomizaP
tion, a switching strategy is f : C → pc where
pc = 1 ∀ p c ∈
c∈C

[0, 1]. To add to the complexity, the cost for switching from a configuration c to another configuration c0 can be nontrivial and non-

uniform. Thus, the aim of a good strategy is to maximize the effectiveness of an MTD system while trying to minimize the cost for
switching. Present state-of-the-art MTD system for web applications use a uniformly distributed switching strategy (pc = 1/|C|)
and assume that switching between configurations incur a uniform
cost [18].
We now develop a game theoretic system to generate switching strategies for the MTD web application that 1) shows a uniformly distributed switching strategy is sub-optimal and 2) considers the non-negative non-uniform costs of switching between different configurations of an MTD system.

4.

GAME THEORETIC MODELING

In this section, we model the setup of MTD systems in as a repeated step Bayesian Game.

4.1

Agents and Agent types

There are (N =) two players in our game, a defender and an attacker. The set θi is the set of types for player i (= {1, 2}). Thus, θ1
and θ2 denotes the set of defender and attacker types respectively.
The j−th attacker type is represented by θ2j .
When an attacker attacks an application, its beliefs about what
(resource/data) is most valuable to the application owner (defender)
remains consistent. Thus, we assume that the attacker knows that
there is only one type of defender when (s)he attacks a particular
web application. Thus, we have |θ1 | = 1.
We consider finite types of attackers. Each attacker type is defined in our model using a 3 tuple,
θ2i = hname, {(expertise, technologies) . . . }, probabilityi
where the second field is a set of two dimentional values that express an attacker’s expertise (∈ [0, 10]) in a technology. The rationale for using values in this range stems from the use of Common
Vulnerability Scoring System (CVSS) described later. Lastly, the
set of attacker types have a discrete probability distribution associated with it. The probability Pθ2j represents the defender’s belief
about the attacker type θ2j attacking their application. Obviously,
the probability values of all attacker types sum up to one.
X
Pθ2j = 1
θ2j ∈θ2

Note that one can define attacker expertise over a ‘category of attacks’ (like ‘BufferOverflowAttacks’) instead of technology specific
attacks. We feel the latter is more realistic for our domain. This definition captures the aspect that an attacker type can have expertise
in a set of technologies. Since, these attacker types and the probability distribution over them are application specific, it is defined by
a domain expert and taken as an input to our proposed model. For
instance, a defender using a no-SQL database in all configurations
of his MTD system, assigns zero probability to an ‘SQL_database’
attacker type because none of their attacks can compromise the security of his present system.
The assumption that the input probability distribution over all
the attacker types can be accurately specified is a strong one. We
later discuss how errors in judgment can affect the effectiveness of
a switching strategy and define a measure to capture the robustness
of the generated policy in such circumstances.

4.2

Agent actions

We define Aθi as a finite set of actions available to player i. The
defender action set, Aθ1 is a switch action to a valid configuration,
c of the web application. The maximum number of actions (or pure

strategies) for the defender can ideally be |C1 | × |C2 | · · · × |Cn |.
This might be lower since a technology used in layer x might not
be compatible when paired with a technology used in layer y (6= x)
rendering that configuration invalid.
For the attacker, Aθ2 represents the set of all attacks used by
atleast one attacker type. A particular attack a belongs to the set
Aθ2 if it affects atleast one of the technologies used in the layers
for our web application (C1 ∪ C2 · · · ∪ Cn ).
We now define a function f : (θ2t , a) → {1, 0} for our model.
The function implies an attack a is a part of the attacker type θ2t ’s
arsenal Aθ2t (⊆ Aθ2 ) if the value of the function is 1. This function value is based on the similarity between (i) the expertise of the
attacker type contrasted with the ‘exploitability’ necessary to execute the attack, and (ii) the attacker’s expertise in the technology for
which the attack can be used. We provide a concrete definition for
the function f after elaborating on what we mean by exploitability
of an attack.
For (almost all) CVEs listed in the NVD database, we have a sixdimensional CVSS v2 vector representing two independent scores
– Impact Score (IS) and Exploitability Score (ES). For an attack action a, ESa (∈ [0, 10]) represents the ease of exploitability (higher
is tougher). For each attack, the database also lists a set of technologies it affects, say T a .
Let us consider the set of technologies an attacker type t has
expertise in is Tt . Now we define the function f as,

1, iff Tt ∩ T a 6= φ ∧ ESa ≤ expertiset
f (θ2t , a) =
0 otherwise

4.3

Reward values for the Game

Now that we have attack sets for each attacker type, the general
reward structure for the proposed game is defined as follows:

 +xa if a ⊂ υ(c)
A
−ya if a can be detected or a ⊂ c0
Ra,θ
=
,c
2i
 0
otherwise

−x
if
a ⊂ υ(c)

d
D
+y
if
a can be detected or a ⊂ c0
Ra,θ
=
d
,c
2i

0
otherwise
A
D
where Ra,θ
and Ra,θ
are the rewards for the attacker type
2i ,c
2i ,c
and the defender respectively, when the attacker type θ2i uses an
attack action a against a configuration c (∈ C). The function υ(c)
represents the set of security vulnerabilities (CVEs) that configuration c has. Also, c0 refers to a honey-net configuration. A honey-net
is a configuration setup with intentional vulnerabilities to invite attackers for catching (or observing) them.
Note that the reward values when a attacker does not attack (NOOP action), is zero. Moreover, a defender gets zero reward for successfully defending a system. We reward him positively only if
he/she is able to reveal some more information or catch the attacker
without impacting operation requirements for the non-malicious
users (or using honey-nets). He gets a negative reward if an attacker
successfully exploits his(/her) system.
To obtain reward values for the variables xa , ya , xd and yd , we
make use of CVSSv2 metric. This metric provides the Impact (IS)
and Exploitability Scores (ES), stated above, which are combined
to calculate a third score called Base Score (BS) [11]. Using these,
we now define the following:

xd
xa

=
=

−1 ∗ IS
BS

Note that BS considers both the impact and the exploitability.
When the IS for two attacks are the same, the one that is easier

to exploit gets the attacker a higher reward value. The ease of an
attack can be interpreted in terms of the resource and effort spent
by an attacker for an attack Vs. the reward (s)he attains by harming
the defender. Although the robustness of our framework provides
provisions for having yd and ya , detecting attacks on a deployed
system or setting up honey-nets is still in its nascent stages. Hence,
there are no actions where values of yd or ya are required in our
present application.
Before we move on, we describe briefly what security dimensions the independent scores (IS and ES) are actually trying to capture in the context of a real world software system. For this purpose,
we first define the 6 independent values that generate these scores.
• Access Vector (AV) is dependent on the amount of access an
attacker needs to exploit a vulnerability. Thus, an attack that
needs physical access to a system will have lower score than
one that can be exploited over the Internet by any machine.
• Access Complexity (AC) represents the complexity of exploiting an attack. A buffer overflow attack on an Internet
service is less complex than an e-mail client vulnerability in
which a user has perform attachment downloads followed by
executing it and hence has lower AC value.
• Authentication (Au) level required to execute the attack. For
example, if no sign-up account is required to exploit the system, this value is high. In contrast, if one needs multiple accounts to exploit the vulnerability, the value is low.
• Confidentiality Impact (C) scores are low if only some (nonrelevant) information gets leaked. Highest impact occurs when
say, the entire database is compromised if the vulnerability is
successfully exploited.
• Integrity Impact (I) refers to the attacker’s power to modify files or behaviour of a system if he executes the exploit
successfully. The more the power– say the attacker is able
to change code or remove arbitrary files in the system– the
higher this value.
• Availability Impact (A) represents the power of a successful
exploit to bring down the availability of a system. A successful Denial of Service (DoS) that brings down an application
server, will have high impact.
From these values, one can obtain the two independent scores using
the following formulas,
20 ∗ (AV ) ∗ (AC) ∗ (Au)

ES

=

IS

= −10.41 ∗ (1 − (1 − C)(1 − I)(1 − A))

A rigorous treatment of assigning these values can be found in [11].
The CVSS values are generated by security experts across the globe
and the database is updated every single day.
Our model takes a time range as input. It then parses all the CVEs
(a) from the NVD in that time range to finally filter out the ones
that can affect atleast one of the configurations in our system (a ⊂
υ(ci )). Note that old CVEs are irrelevant for generating attack sets
for a relatively new MTD system as they either have no effect on the
updated versions of the technologies they can affect or have popular
solutions to prevent them while developing the application. For our
application, we obtain this input range from our security experts.

4.4

Switching Cost

The switching costs can be represented by a K n×n matrix where
the n rows (and columns) denote the n system configurations. The

cell Kij denotes the cost of switching when the defender moves
from configuration i to configuration j. As mentioned earlier, the
values in K are all non-negative. Our security experts, who have
written the code to automatically move from one configuration to
another, hand code these values in each cell of the martix. We provide some guidance in choosing these values here and give a concrete example on how we selected these for our application later.
If there is no common technology between configurations c and
c0 involved in a switch operation, the cost will be large. Also, switching technologies in a specific layer may incur more cost than switching technologies in other layers. In the developed MTD system, we
find that switching between databases incur large costs because the
structure of the data needs to be changed for shifting, and the time
required to copy huge amounts of data from one database to another
must also be accounted for.
The matrix K for our system turns out to be symmetric, i.e.
Kij = Kji ∀ i, j ∈ {1, . . . n}. Also, Kii = 0, which implies
that there is no cost if no configuration switch occurs. Note that
although our security experts think this is the structure of rewards
for the developed system, the modelling is generic enough to allow
for asymmetric costs. Lastly, we choose the values of Kij in the
range [0, 10]. The reason for this upper bound becomes clear in the
upcoming section.

5.

SWITCHING STRATEGY GENERATION

In this section, we first introduce the notion of Stackelberg Equilibrium for our security game, that gives us a defender strategy that
maximizes his reward (and thus the security of the system). We
briefly talk of optimization methods, relevant to our domain, that
can produce this. Finally, we incorporate the costs of switching into
the objective function and propose our solver.

5.1

Stackelberg Equilibrium

The strategy generated for the designed game needs to capture
the reconnaissance aspect. Note that the game starts only after the
defender has deployed the web application, acting as a leader. This
now becomes a repeated game in which an attacker can observe a finite number of switch moves and probabilistically learn the switching strategy (since |C|  ∞) of the defender. Thus, the defender
has to select a strategy that maximizes his reward in this game,
given that the attacker knows his strategy. This is exactly the problem of finding the Stackelberg Equilibrium in a Bayesian Game
[20]. The resulting mixed strategy is the switching strategy for the
defender in our MTD system. Unfortunately, this problem becomes
NP-hard in our case because of multiple attacker types [5].
Before we find a strong Stackelberg Equilibrium for our proposed game, we state a couple of well founded assumptions we
make. Firstly, an attacker chooses a pure strategy, i.e., a single attack action that maximizes his reward value. This assumption is
popular in prior work on security games because for every mixed
strategy for the attacker, there is always a pure strategy in support
for it [14]. Secondly, we assume that the pure strategy of an attacker
type is not influenced by the strategy of other attacker types. This
is not limiting for our web application domain since an attacker
type’s attack selection is independent of the attack action chosen
by another type.
To solve for the optimal mixed strategy, one can use the Decomposed Optimal Bayesian Stackelberg Solver (DOBSS) [13]. This
optimizes the expected reward of the defender over all possible
mixed strategies for the defender (~
x), and pure strategies for each
~θ ). We
attacker type (~nθ2i ) given the attacker type uncertainty (P
2i
now define the objective function of the Mixed Integer Quadratic

Program (MIQP) in Equation 1.
X X X
D
max
Pθ2i Ra,θ
xc naθ2i
2i ,c
x,n,v

Moving Target Defense
Web application

(1)

?

Incorporating Switching Costs

As defined in the last section, the cost for switching from a configuration i to a configuration j can be represented as Kij . The
probability the system is in configuration i and then switches to
configuration j is xi · xj . Thus, the cost incurred by the defender
for a switch action fromP
i toP
j is Kij · xi · xj . The expected cost
Kij · xi · xj .
for any switch action is
i∈C j∈C

To account for cost, we can subtract this from the objective function of Equation 1 with a cost-accountability factor α (≥ 0) to
obtain
X X X
XX
D
Pθ2i Ra,θ
x nθ2i −α·
max
Kij ·xi ·xj
2i ,c c a
c∈C θ2i ∈θ2 a∈Aθ
2i

i∈C j∈C

Unfortunately, this results in a Bilinear Mixed Integer Programming problem, which is not convex. To ameliorate this problem,
we now introduce new variables wij that essentially represent an
approximate value of xi · xj . We first use the piecewise linear McCormick envelopes to design a convex function using these wij s that estimates a good solution to this problem [21]. Along with
these constrains, we introduce further constrains which we describe
after introducing the final MIQP convex optimization problem as
follows,
max

x,n,v

X X

X

D
θ2i
Pθ2i Ra,θ
xc na
− α·
2i ,c

c∈C θ2i ∈θ2 a∈Aθ
2i

XX

Kij wij

i∈C j∈C

(2)

X

s.t.

xc

=

1

(3)

naθ2i

=

1

(4)

c∈C

X
a∈Aθ

0 ≤ v θ2i −

X

2i

A
Ra,θ
x
2i ,c c

Figure 1: A moving target defense web application system
xc ∈ [0 . . . 1], nθa2i ∈ {0, 1}, v θ2i ∈ R
∀ c ∈ C, θ2i ∈ θ2 , a ∈ Aθ2i

i∈C

j∈C

j∈C

constrains (10) and (11).
If we now allow the maximum cost of switching to be 10, we can
see that the values for the cost is comparable in magnitude to the
value of the defenders rewards. This helps us to provide a semantic
meaning for the cost-accountability factor, α.
The first term in the objective function seeks to maximize the
defender’s reward, which in turn maximizes the security of the web
application. The second term on the other hand, seeks to reduce
the expected cost of the switching actions. Thus, α represents how
much importance is given to the cost of switching Vs. the level of
security desired. Consider the extreme cases, when α = 0, we are
producing the most secure strategy (which is the Stackelberg Equilibrium) and considering switching between configurations incur
zero costs. This is the sub-set of solutions that are developed mostly
for physical security systems. In contrast to that, when α = 1, we
are saying that we consider switching costs as important as the security of our MTD application.
Choosing the correct value of α is not trivial and often dependent
on the specific web-application. For example, if a banking system
someday seeks to operate on a MTD system, we hope it puts more
weight on security than switching costs, selecting low α values. To
provide a sense to the reader, we later show in the experimental section, how strategies and reward values are effected with changing
alpha values.

wij
wij

≥ 0 ∀ i, j
≤ xi ∀ i, j

(6)
(7)

wij

≤ xj ∀ i, j

(8)

6.

(9)

The goal of this section is to answer three key questions. Firstly,
does our proposed Bayesian Stackelberg Game (BSG) model generate better strategies that the state-of-the-art? Secondly, can we
effectively compute the set of critical vulnerabilities? Lastly, who
are the sensitive attacker types and how robust is our model?

1 ∀ i, j

wij

=

wij

= xi ∀ i

(10)

wij

= xj ∀ j

(11)

j∈C

X

where M is a large positive number. ~nθ2i and v θ2i give the pure
strategy and its corresponding reward for the attacker type θ2i respectively, and ~
x gives the mixed switching strategy for the defender. (5) solves the dual problem of maximizing rewards for each
attacker type (v θ2i ) given the defender’s strategy. This ensures that
attackers always select the best attack action. The constrains (6), (7)
and (8) represent the McCormick envelope that provides lower and
upper
bounds on each wij . Since we consider all possible switches,
P P
xi · xj = 1. This is enforced by constrain (9). Lastly, for
j∈C i∈C
P
P
xj ) = xi . This is represented by the
xi · xj = xi · (
each i,

(5)

j∈C i∈C

X

Automated Code
converter

𝑐1 = {Python, MySQL}

≤ (1 − naθ2i )M

c∈C

XX

𝑐4 = {php,
postgreSQL}

𝑐3 = {php, MySQL}

2i

x,n,v

𝑐2 = {Python,
postgreSQL}

c∈C θ2i ∈θ2 a∈Aθ
2i

Notice that this does not consider that switching costs between defender strategies. Essentially, this means the formulation assumes
that switching costs are uniform. Before we address this limitation
in the upcoming subsection, we take a little digression.
For our scenario, we have many attack actions. Thus, we observe that solving the MIQP version is more efficient (in computation time and memory usage) than solving the Mixed Integer Linear
Program (MILP) version of the DOBSS. This can be attributed to
the fact that the MILP formulation results in an increase in the dimensions
solution space. Theoretically, the MIQP solves for
P of theP
|C| + θ2i ∈θ2 aj ∈Aθ |aj | variables where as the MILP solves
P
P 2i
for |C| ∗ θ2i ∈θ2 aj ∈Aθ |aj | variables.

5.2

𝑐1 = {Python,
MySQL}

6.1

EMPIRICAL EVALUATION

Test Bed Description

PHP,
MySQL
Python,
MySQL
PHP, postgreSQL
Python,
postgreSQL

PHP,
MySQL

Python,
MySQL

PHP, postgreSQL

Python,
postgreSQL

Name

0

2

6

10

2

0

9

5

6

9

0

2

10

5

2

0

Script Kiddie
(SK)
Database
Hacker (DH)
Mainstream
Hacker (MH)

Table 1: Swithing costs for our system

• Switching between different languages while keeping the same
database dialect incurs minimal cost - workload is primarily
done is primarily on rerouting to the correct server with the
source language
• Switching between different database dialects while keeping
the same language incurs a slightly higher cost due to the
conversion required for the database structure and its contents. One also has to account for copying large amounts of
data to the database used in the current system configuration.
• Switching between different database dialects AND different
languages incur the most cost due to the combination of the
costs of conversion for the database as well as the penalty for
rerouting to the correct server with the source language.
The attacker types along with the attack action set size are defined in Table 2. We mined the NVD for obtaining CVE data from
January, 2013 to August, 2016 to generate these attack sets. If the
stakes of getting caught are too high for an attacker type given an
MTD system, he/she may choose not to attack. Hence, we have a
NO-OP action for each attacker type.
The optimization problems for the experiments were solved using Gurobi on an Intel Xeon E5 2643v3@3.40GHz machine with
6 cores and 64GB of RAM.

6.2

Strategy Evaluation

We evaluate our method using Bayesian Stackelberg Games on
our real life web application against the Uniform Random Strategy (URS), which is the state-of-the-art in such systems [18]. We
plot the values of the objective function in Equation 2 for both the

Prob.

|Aθ2i |

0.15

34

0.35

269

0.5

48

Table 2: Attacker types and attack action counts
BSG
U RS

−4
Obj

To answer the questions mentioned above, we develop a real
world MTD web application (shown in Figure 1) with 2 layers.
The key idea of applying MTD to web applications requires you to
have several versions of the same system, each written in either a
different language, using a different database, etc.
This diversity is not ubiquitous in legacy web applications, due
to cost, time, and resources required to build several versions of the
same web application. To aid this, we developed a framework to
automatically generate the diversity necessary for this web application. The current prototype is able to convert a web application
coded in Python to an equivalent one coded in PHP, and vice versa,
as well as a web application using a MySQL database to an identical version that uses PostgreSQL, and vice versa. In the future,
as more and more variations are developed, the set of defender’s
actions will increase.
The present set of valid configurations for our system is C =
{(PHP, MySQL), (Python, MySQL), (PHP, postgreSQL), (Python,
postgreSQL )}. The costs for switching between configurations is
shown in Table 1. These cost values generated by our system administrators are based on the following considerations:

(Technologies,
Expertise)
(PHP,4),
(MySQL,4)
(MySQL,10),
(postgreSQL,8)
(Python,4),
(PHP,6),
(MySQL,5)

−6
−8

0

0.2

0.4

0.6

0.8

1

α

Figure 2: Objective function values for Uniform Random Strategy Vs. Bayesian Stackelberg Game with switching costs as α
varies from 0 to 1.
strategies as α varies from 0 to 1. For URS, we use the exact values of wij = 0.25 ∗ 0.25 = 0.0625 ∀ i, j. The plot is shown in
Figure 2. Both are straight lines because although the value of α
changes, the strategy for URS is same (by definition) and the one
generated by BSG also remains the same. The latter case came as
a surprise to us initially. On further investigation, we noticed that
in the formulated game for our web-application, the Stackelberg
Equilibrium for our application (luckily) coincides with the least
switching cost strategy.
These attacker and defender strategies is shown in Table 3 alongwith the value of the defender’s reward (i.e. the first term in the objective function in Equation 2). Notice that, not only is the mixed
strategy generated by BSG more secure than URS, it leverages
fewer configurations than all valid configurations |C| = 4 the system has to offer. This result is in unison with previous work in
cyber-security which show that having many configurations does
not necessary imply that all of them have to be used for providing
the best security [3].

6.2.1

Studying the effect of α-values
To empirically show that our solver is actually considering costs
of switching, we change the value for switching from (PHP, postgreSQL ) to (Python, postgreSQL) and vice-versa from 2 (yellow boxes in Table 1) to 10. We plot this scenario in Figure 3. As
soon as α ≥ 0.4, the BSG generates (0.25, 0.25, 0.25, 0.25, 0.25)
(which is URS) as the most optimal strategy. After analysis, we
note that this happens because the most powerful attack actions in
the arsenal of the attacker types are for the systems (PHP, MySQL)
and (Python, MySQL). When, one does not prioritize switching
costs (α ∈ {0, 0.1, 0.2, 0.3}), the system keeps switching between
the more secure configurations nullifying the good attacks of the
attackers. As switching costs start to get more significant (α ∈
{0.4, 0.5, . . . 1.2}), the objective function value reduces if it sticks
to the stronger configurations since switching costs are now high
for these. It switches to the URS in this case. Beyond that, it switches

Method

Mixed Strategy

Defender’s
Reward

Attack sets (SK,
DH, MH)

k

CV sets

URS

(0.25, 0.25, 0.25,
0.25)

-5

1
2

BSG

(0, 0, 0.5, 0.5)

-3.25

CVE-2016-3477,
CVE-2015-3144,
CVE-2016-3477
CVE-2014-0185,
CVE-2014-0067,
CVE-2014-0185

{(CVE-2014-0185)}
{(CVE-2014-0185,
CVE-2015-5652)}

P (configuration= c)

Table 3: Comparison between the strategies generated by Uniform Random Strategy (URS) Vs. Bayesian Stackelberg Game
(BSG)
php_mysql
py_mysql
php_psql
py_psql

0.4

0.2

0
0

0.5

1

1.5

2

2.5

α→
BSG
U RS

Obj

−5
−10
−15

0

0.5

1

1.5

2

2.5

to the strategy (0.25, 0.5, 0, 0.25) as α keeps on increasing. When
α becomes close to 2, it completely ignores the security of the
system and tries to minimize the switching cost by proposing the
strategy (0.5, 0.5, 0, 0) as the cost for switching between (PHP,
MySQL) and (Python, MySQL) is the least (= 2).
In the bottom of Figure 3, we showcase the change in the values of objective function. At the start, the BSG generates a better
strategy when compared to URS. When the BSG strategy becomes
the same as the URS (for 0.4 ≤ α ≤ 1.2), we observe that the
objective function value for BSG is lower than URS. This is not
surprising since BSG is merely trying to estimate the value xi · xj
with the variables wij , whereas URS is using the exact value. As
we increase α further, we are essentially discouraging an MTD system, since now the cost of switching has become so high, whereas
naive URS pays no heed to this.

6.3

Identifying Critical Vulnerabilities

In real-world development teams, it is impossible to solve all the
vulnerabilities, especially in a system with so many technologies.
In current software systems, given a set of vulnerabilities, a challenging question often asked is which vulnerabilities should one fix

CPU Time
3m15s
421m27s

Table 4: Most critical vulnerability in the MTD system and the
time required to generate it.

to improve the security?
For an MTD system, this becomes a tough problem since the defender needs to reason about multiple attacker types– their probabilities and attack actions. For a given k, the set of k vulnerabilities,
which on being fixed, result in the highest gain in defender strategy,
is termed as the k critical vulnerability set (k−CV).
To address this problem, we remove each k-sized attack set from
the set of all attacks (A02 = A2 \ D ∀ D ⊂ A2 & |D| = k)
and evaluate the objective function (Equation 2). The sets A02 that
yield the highest objective values, provide the vulnerabilities D that
should be fixed to improve the defender’s system.
We tried to study this complicated behaviour for some toy examples before applying it to our application. An interesting phenomenon we noticed was that a k-set critical vulnerabilities (k−CV)
is not always a subset of the (k + 1)−CV. Suppose we want to find
3 vulnerabilities that we want to fix. Since it is not just a super-set
of the 2-CV, we need to solve this problem from the scratch with
k = 3. Hence, there is going to be combinatorial explosion here.
As

the value of k increases, we end up solving |A02 | = |Ak2 | MIQP
problems to identify the k−CVs.

6.3.1

α→

Figure 3: Top: Showcases the change in probabilities associated
with a particular configuration. Bottom: Objective function
values for Uniform Random Strategy Vs. Bayesian Stackelberg
Game with switching costs as α varies from 0 to 2.5 when the
cost of switching are as showcased in Table 1 with the values in
the yellow boxes being 10.

Objective
Value
-2.435
-1.973

Finding Critical Vulnerabilities in the Developed System

For our system, we start with k = 1, we increase number of critical vulnerabilities to be found by 1 at each step. The result remains
the same for α ∈ [0, 1] for our system. We do not play around
with α beyond this, mostly because this would be unrealistic for
any practical application. Unfortunately, the brute force approach
and the scalability of algorithms for solving normal extensive form
BSGs proves to be a key limitation.
This is not a surprise since the total number of unique CVEs
spread out among
the attackers is 287. When k = 3, we end up

solving 287
optimization
problems, which fails to scale in both
3
time and memory. Thus, we only show critical vulnerabilities identified up to k = 2 (in Table 4) using α = 0.2.
At present, we are trying to develop a single MIQP formulation
that tries to approximately generate the k-CV set. To reduce the
combinatorial explosion, we plan to use switch variables that can
turn attack actions on and off. This comes at the cost of increasing
the number of variables in the formulated optimization problem.

6.4

Model Robustness & Attacker
Type Sensitivity

It is often the case that a web application administrator (defender)
cannot accurately specify the probability for a particular attacker
type. In this section, we see how this uncertainty affects the optimal rewards generated by the system. We provide a notion for
determining sensitive attacker types and measuring the robustness
of a switching strategy.
For each attacker type i, we vary the probability Pθ2i by ±x%
x
)) where x is the sensitivity factor, which
(Pθnew
= Pθ2i (1 ± 100
2i
can be varied from a low value to a high value as needed. Note that
x
now p = Pθ2i × 100
needs to be adjusted or distributed amongst the

probabilities of the remaining attacker types. To make sure that this
distribution is done such that the sensitivity of attacker i actually
stands out, we propose to distribute p amongst the other attacker
types using a weighted model as per their existing probabilities as
shown below. For attacker j (6= i), its new probability would be:
= Pθ2j (1 ∓

P p
Pθ
k(6=i)

)
2k

NLR(BSG)

Pθnew
2j

M ainstreamHacker(M H)

2

Rn −Ro
Rn

−100

−50

CONCLUSIONS AND FUTURE WORK

In this paper, we propose a method to generate a switching strategy for real-world web application based on the Moving Target Defense (MTD) architecture. To find an effective switching strategy,
we model the system as a repeated Bayesian game. We develop
methods to assign attack actions to attacker types and generate realistic utilities based on expertise of security professionals. For obtaining real-world attack data, we mine vulnerabilities in the National Vulnerability Database (NVD) and obtain utilities based on
the Common Vulnerability Scoring System (CVSS). We formulate
an optimization problem which outputs a switching strategy that
maximizes system security while accounting for switching costs.
The generated strategy is shown to be more effective than the stateof-the-art for a real-world application. We also provide metrics that
can be used to validate the robustness of switching strategies, absent in literature for multi-agent cyber-security systems. Lastly, we
propose the problem of identifying critical vulnerabilities and provide a solution.
The techniques in this paper are not limited to only web applications. The attack actions mined from the security databases relate to

50

100

50

100

NLR(URS)

DatabaseHacker(DH)
ScriptKiddie(SK)

5

0
−100

Evaluation Based on the Developed System

0

M ainstreamHacker(M H)

(13)

We compute the attacker sensitivity for our system varying the
probability of each attacker type from −100% to +100% (of its
modeled probability) with 10% step sizes. We plot the results in
Figure 4 using Equation 13. The Mainstream and Database hacker
(MH & DH) are the least sensitive attacker types. The NLR values
for both these attackers are 0. This is the case since the real world
attack action used by these types remain the same even when their
probabilities change. On the other hand, if the probability associated with the Script Kiddie (SK) is underestimated in our model,
we see that the strategies deviate substantially from the optimal.
For our experiments in this section, we use α = 0.2. The max
NLR for our BSG strategy is 2.35 Vs. 9 for URS. The average of
the 60 NLR values is 0.061 for BSG and 0.88 for URS. These values indicate our model is more robust to variance in attacker type
uncertainty than the present state-of-the-art.

7.

1

0

Note that NLR values are ≥ 0. Higher values of NLR represent
more sensitive attacker types. Inaccurate probability estimates for
the sensitive attackers can be detrimental to the security of our
application. Note that lower NLR values indicate that a generated
strategy is more robust.

6.4.1

ScriptKiddie(SK)

(12)

~θ , then the sign in
When x% is subtracted from the probability P
2i
the above equation becomes positive, and vice-versa.
We now formally define the loss in reward to the defender as the
probability distribution over the attacker types change. Let Ro be
the overall reward for the defender when he uses the mixed strategy
for the assumed (and possibly incorrect) model of attacker type un~θnew ). Let Rn be the defender’s
~θ2 ) on the true model (P
certainty (P
2
optimal reward value for the true model. We compute the Normalized Loss in Rewards (NLR) for the defender’s strategy as follows:
NLR =

DatabaseHacker(DH)

−50

0

Varying sensitivity of attacker types (%)

Figure 4: NLR values for BSG and URS genereated strategies
when attacker types probabilities vary in [−100%, 100%].
all kinds of technologies, like operating systems, coding languages
etc. Hence, the modelling should be relevant to any software applications using the MTD architecture. It would be interesting to see
how effective they are in such scenarios.
Investigating the reward structure for a particular problem has
helped design provably fast solvers in the physical security domains. We believe this direction of research might help in developing faster solvers, alleviating the scalability problem of identifying
critical vulnerabilities, for the cyber-security domain as well.

8.

ACKNOWLEDGMENTS

This work was partially supported by the grants from National
Science Foundation (NSF-SFS-1129561) and the Center for Cybersecurity and Digital Forensics at Arizona State University.

REFERENCES
[1] K. Amin, S. Singh, and M. Wellman. Gradient methods for
stackelberg security games. AAMAS, 2016.
[2] D. Balzarotti, M. Cova, V. Felmetsger, N. Jovanovic,
E. Kirda, C. Kruegel, and G. Vigna. Saner: Composing static
and dynamic analysis to validate sanitization in web
applications. In Security & Privacy 2008. IEEE Symposium,
pages 387–401, 2008.
[3] K. M. Carter, J. F. Riordan, and H. Okhravi. A game
theoretic approach to strategy determination for dynamic
platform defenses. In ACM MTD Workshop, 2014, MTD ’14.
ACM, 2014.
[4] M. Carvalho and R. Ford. Moving-target defenses for
computer networks. Security Privacy, IEEE, 12(2):73–76,
Mar 2014.
[5] V. Conitzer and T. Sandholm. Computing the optimal
strategy to commit to. In Proceedings of the 7th ACM
Conference on Electronic Commerce, EC ’06, pages 82–90,
New York, NY, USA, 2006. ACM.
[6] A. Doupé, L. Cavedon, C. Kruegel, and G. Vigna. Enemy of
the state: A state-aware black-box web vulnerability scanner.
In USENIX Security Symposium, 2012.

[7] S. H. Houmb, V. N. Franqueira, and E. A. Engum.
Quantifying security risk level from cvss estimates of
frequency and impact. JSS, 83(9):1622–1634, 2010.
[8] S. Jones, A. Outkin, J. Gearhart, J. Hobbs, J. Siirola,
C. Phillips, S. Verzi, D. Tauritz, S. Mulder, and A. Naugle.
Evaluating moving target defense with pladd. Technical
report, Sandia National Labs-NM, Albuquerque, 2015.
[9] P. Manadhata. Game theoretic approaches to attack surface
shifting. In Moving Target Defense II, volume 100 of AIS,
pages 1–13. Springer New York, 2013.
[10] J. McCumber. Information systems security: A
comprehensive model. In Proceedings of the 14th National
Computer Security Conference, 1991.
[11] P. Mell, K. Scarfone, and S. Romanosky. Cvss v2 complete
documentation, 2007.
[12] H. Okhravi, T. Hobson, D. Bigelow, and W. Streilein.
Finding focus in the blur of moving-target techniques.
Security & Privacy, IEEE, 12(2):16–26, 2014.
[13] P. Paruchuri, J. P. Pearce, J. Marecki, M. Tambe, F. Ordonez,
and S. Kraus. Playing games for security: An efficient exact
algorithm for solving bayesian stackelberg games. In
AAMAS, 2008, pages 895–902, 2008.
[14] J. Pita, M. Jain, J. Marecki, F. Ordóñez, C. Portway,
M. Tambe, C. Western, P. Paruchuri, and S. Kraus. Deployed
ARMOR protection: the application of a game theoretic
model for security at the los angeles international airport. In
AAMAS 2008, Industry and Applications Track Proceedings,
pages 125–132, 2008.
[15] A. Prakash and M. P. Wellman. Empirical game-theoretic
analysis for moving target defense. In ACM MTD Workshop,
2015, 2015.
[16] J. Silver-Greenberg, M. Goldstein, and N. Perlroth.
JPMorgan Chase Hacking Affects 76 Million Households. In
The New York Times, 2014.
[17] A. Sinha, T. Nguyen, D. Kar, M. Brown, M. Tambe, and
A. X. Jiang. From physical security to cyber security.
Journal of Cybersecurity, 2016.
[18] M. Taguinod, A. Doupé, Z. Zhao, and G.-J. Ahn. Toward a
Moving Target Defense for Web Applications. In
Proceedings of 16th IEEE IC-IRI, 2015.
[19] M. Van Dijk, A. Juels, A. Oprea, and R. L. Rivest. Flipit: The
game of “stealthy takeover”. Journal of Cryptology,
26(4):655–713, 2013.
[20] H. Von Stackelberg. Market structure and equilibrium.
Springer SBM, 2010.
[21] D. S. Wicaksono and I. Karimi. Piecewise milp under-and
overestimators for global optimization of bilinear programs.
AIChE Journal, 54(4):991–1008, 2008.
[22] D. Wichers. Owasp top-10. OWASP, 2013.
[23] M. Winterrose, K. Carter, N. Wagner, and W. Streilein.
Adaptive attacker strategy development against moving
target cyber defenses. arXiv:1407.8540, 2014.
[24] R. Zhuang, S. A. DeLoach, and X. Ou. Towards a theory of
moving target defense. In ACM MTD Workshop, 2014, pages
31–40. ACM, 2014.

Discovering and Analyzing Deviant
Communities:
Methods and Experiments
Napoleon C. Paxton* , Dae-il Jang** , Ira S. Moskowitz* , Gail-Joon Ahn** , Stephen Russell* and Myong Kang*
*

**

Information Technology Division, Naval Research Laboratory, Washington, DC
School of Computing, Informatics, Decision Systems Engineering, Arizona State University, Tempe, AZ

Abstract—Botnets continue to threaten the security landscape of computer networks worldwide. This is due in part
to the time lag present between discovery of botnet traffic
and identification of actionable intelligence derived from the
traffic analysis. In this article we present a novel method to
fill such a gap by segmenting botnet traffic into communities
and identifying the category of each community member.
This information can be used to identify attack members
(bot nodes), command and control members (Command and
Control nodes), botnet controller members (botmaster nodes),
and victim members (victim nodes). All of which can be used
immediately in forensics or in defense of future attacks.
The true novelty of our approach is the segmentation of
the malicous network data into relational communities and
not just spacially based clusters. The relational nature of
the communities allows us to discover the community roles
without a deep analysis of the entire network. We discuss the
feasibility and practicality of our method through experiments
with real-world botnet traffic. Our experimental results show
a high detection rate with a low false positive rate, which gives
encouragement that our approach can be a valuable addition
to a defense in depth strategy.

I. I NTRODUCTION
There has been a significant amount of research devoted
to discovering botnet traffic within computer networks, but
an equally important area of research is the analysis of
the data once it has been discovered. Security analysts
in charge of decyphering information gathered after a
botnet attack always begin at a disadvantage due to the
everchanging landscape of botnet administration and the
custom and decentralized methods used to analyze the
data. Because of this, many botnets such as Mariposa (7
months), Kelihos (8 months), and Rustock (5 years), can
continue to operate for a significant amount of time after
an attack has been discovered, while waiting for actionable
information gathered from current analysis techniques [5].
This "wait" is significant because current analysis methods
have to decipher the commands used to administer the
botnets. Experts agree that this is time consuming and
non-trivial even for experienced and skilled analysts [13],
[4]. A preliminary analysis that will allow analysts to take
immediate steps, (such as identifying and blocking key
actors in the botnet), can lessen the effects of continued

operations until a more detailed analysis can be completed.
Malicious botnets, which are networks of compromised
machines, continue to be among the top threats found on
the Internet [16]. Attacks performed using botnets include:
Distributed Denial of Service (DDoS), Identity Theft, Click
Fraud, Phishing, Spam, and so on. Each type of attack
can cause significant harm to their victim and consume
considerable bandwidth of the networks they operate in.
For example, in the case of spam, a recent security report
from Trustwave found that 75.2% of all inbound emails
are considered spam sent by botnets [12]. Additionally, ten
percent of those spam emails contain malicious content,
which will infect vulnerable machines of users who click
on the email’s embedded link.
Defense In Depth is a strategy used by nearly every
network security professional to defend against threats on
the Internet. This strategy involves multiple layers of protective solutions such as anti-virus, anti-spyware, firewalls,
and intrusion detection/prevention systems. This strategy
also includes layers of analysis methods which generally
consist of custom tools that analyze malware and network
traffic. Each layer works in concert to defend systems.
Information discovered from the analysis layers are turned
into signatures that are fed into the protection layers.
Current botnet analysis techniques, which are based on
the custom tools, are effective in discovering fine-grained
details about botnets. However, due to the amount of time
that takes place between protection layers and analysis
layers, an additional analysis layer is still needed to reduce
the effects of the botnet while the more conclusive analysis
takes place.
Methods for finding communities have been studied extensively in a variety of networks including the Internet [6].
In each method, all networks are represented generically as
graphs composed of vertices (nodes) and edges (links). The
concept of communities does not have a widely accepted
definition. For the purpose of this article communities are
described as nodes in the network that communicate with
each other through links more than they do with any
other nodes in the same network. In previous research,
discovering the communities and the relationships between

Form Approved
OMB No. 0704-0188

Report Documentation Page

Public reporting burden for the collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, gathering and
maintaining the data needed, and completing and reviewing the collection of information Send comments regarding this burden estimate or any other aspect of this collection of information,
including suggestions for reducing this burden, to Washington Headquarters Services, Directorate for Information Operations and Reports, 1215 Jefferson Davis Highway, Suite 1204, Arlington
VA 22202-4302 Respondents should be aware that notwithstanding any other provision of law, no person shall be subject to a penalty for failing to comply with a collection of information if it
does not display a currently valid OMB control number

1. REPORT DATE

3. DATES COVERED
2. REPORT TYPE

OCT 2014

00-00-2014 to 00-00-2014

4. TITLE AND SUBTITLE

5a. CONTRACT NUMBER

Discovering and Analyzing Deviant Communities: Methods and
Experiments

5b. GRANT NUMBER
5c. PROGRAM ELEMENT NUMBER

6. AUTHOR(S)

5d. PROJECT NUMBER
5e. TASK NUMBER
5f. WORK UNIT NUMBER

7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES)

8. PERFORMING ORGANIZATION
REPORT NUMBER

Naval Research Laboratory ,Information Technology
Division,Washington,DC,20375
9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES)

10. SPONSOR/MONITOR’S ACRONYM(S)
11. SPONSOR/MONITOR’S REPORT
NUMBER(S)

12. DISTRIBUTION/AVAILABILITY STATEMENT

Approved for public release; distribution unlimited
13. SUPPLEMENTARY NOTES

10th IEEE International Conference on Collaborative Computing, 22-25 Oct 2014, Miami, FL.
14. ABSTRACT

Botnets continue to threaten the security landscape of computer networks worldwide. This is due in part to
the time lag present between discovery of botnet traffic and identification of actionable intelligence derived
from the traffic analysis. In this article we present a novel method to fill such a gap by segmenting botnet
traffic into communities and identifying the category of each community member. This information can be
used to identify attack members (bot nodes), command and control members (Command and Control
nodes), botnet controller members (botmaster nodes) and victim members (victim nodes). All of which can
be used immediately in forensics or in defense of future attacks. The true novelty of our approach is the
segmentation of the malicous network data into relational communities and not just spacially based
clusters. The relational nature of the communities allows us to discover the community roles without a
deep analysis of the entire network. We discuss the feasibility and practicality of our method through
experiments with real-world botnet traffic. Our experimental results show a high detection rate with a low
false positive rate, which gives encouragement that our approach can be a valuable addition to a defense in
depth strategy.
15. SUBJECT TERMS
16. SECURITY CLASSIFICATION OF:
a REPORT

b ABSTRACT

c THIS PAGE

unclassified

unclassified

unclassified

17. LIMITATION OF
ABSTRACT

18. NUMBER
OF PAGES

Same as
Report (SAR)

8

19a. NAME OF
RESPONSIBLE PERSON

Standard Form 298 (Rev. 8-98)
Prescribed by ANSI Std Z39-18

their nodes has revealed key facts about the purpose of the
community creation. In this article we investigate how this
method can be further extended to perform botnet analysis.
This article is organized as follows: the overview of
botnet analysis approaches is described in Section II. Section III discuss our botnet community analysis model which
is based on k-clique constructs. In Section IV, we discuss
our tool and evaluation results on both IRC and HTTP
botnets. To evaluate the effectiveness of our approach, we
compare information discovered in our analysis with the
results of a manual analysis of the same botnets. Our comparison shows community analysis methods can accurately
uncover preliminary information with a low false positive
rate. This information can be eventually used to reduce the
time between discovery of botnet activity and identification
of actionable intelligence. The future directions of our
approach are elaborated in Section V. Section VI concludes
the paper.

difficult and impractical. Since our approach is based on
physical structure and communication patterns, we do not
require this step for botnet analysis.
Sinkholing. Sinkholing is the current method of choice
for botnet analysis and defense [3]. In this approach, the
analyst deceives bots into taking orders from the analyst
instead of their normal command and control servers. Once
this is done the analyst receives all traffic packets passed
from the bots to the botnet. There are several drawbacks to
sinkholing and shutting down botnets. The biggest issue is
the complexity and time involved in conducting a sinkholing campaign. Normally, sinkholing involves a coordinated
effort from the analyst, ISPs, and law enforcement officials.
Another major concern is after a botnet is sinkholed, there
is only a small window to conduct an analysis of the
entire botnet. This is because the command and control
server and the master of the botnet are no longer controlled
by the deviant users whom the botnet used to belong to.
Shutting down the botnet also has its drawbacks. Although
the loss of the botnet is a setback for the administrators and
botmasters that controlled the botnet since the perpetrators
behind the botnet are normally not captured, they are free
to regroup and create new and more resilient botnets.
Each of these methods are useful in a defense in depth
approach over time, but new methods are needed to discover
information about botnets earlier so more immediate actions
can be taken to address the threats caused by the botnet
activity.

II. C URRENT B OTNET A NALYSIS M ETHODS
Botnets have the ability to conduct attacks or other
malicious activities within minutes or even seconds. Current
botnet analysis techniques designed to discover enough
information to slow down or stop botnets are effective once
the semantics of the data captured from the botnet can
be discovered [11]. Unfortunately, the deciphering of the
data normally takes days, and in some cases months, to
complete.
Signature Based Analysis. Most botnet analysis techniques today require a manual pre-processing step, which
involves reviewing the normal format of the command
and control protocol being used, and comparing it with
the format of the actual command structure found in the
botnet data. This is a mandatory step because many botnet
administrators modify their command and control protocols
to evade detection or monitoring. As mentioned before,
this step can be very time consuming depending on the
sophistication of the protocol modification and the skill
level of the analyst [4], [5]. The products of this type of
analysis are signatures which are used to power mechanisms such as anti-virus programs, firewalls, and blacklists.
Signatures block botnet traffic based on a defined ruleset.
Again, the problem with this approach is the length of time
involved in the signature discovery. In normal cases botnet
administrators slightly change their malware to avoid a
detection engine, this simple change places the requirement
on the analyst to repeat the tedious signature based process
each time a change occurs.
Anomaly Based Analysis. Anomaly based solutions
such as sandnets perform their analysis based on patterns
discovered during execution of the data [14]. Existing
approaches such as botsniffer [9] and bothunter [8] require
a malicious activity response module for each type of botnet
action that is to be monitored. Today botnets have become
sophisticated in disguising their activities so that it could
make defining malicious activity response modules both

III. B OTNET C OMMUNITY A NALYSIS
There exist several approaches in extracting and analyzing communities within the network data. Early algorithms,
such as the approach by Borgatti et. al. [2] and the kcore algorithm [15] showed how communities could be
extracted, but did not allow nodes to be part of more than
one community within a network. Networks such as botnets
do contain nodes that belong to multiple communities so
these methods could not be easily adapted for our approach.
CFinder is an algorithm that allows community members to
overlap and it is the most studied method in the literature. It
is based on k-clique percolation, which was introduced by
Palla et. al. [10]. This algorithm builds communities based
on k-cliques and has been proven effective in identifying
the semantics of many network communities such as social
networks and normal Internet traffic networks [6]. However,
this approach is not sufficient for our purposes in its native
form because it does not consider communication direction.
Attribute Selection. Analyzing botnet data using our
method is dependent on selecting attributes for two elements, (1) Discovering nodes and (2) Discovering links that
connect the nodes. Discovering these elements is dependent
on the format of the available data, but not the structure
of the command and control commands. For example, the
most common data format collected for all protocols is
packet capture data (PCAP) which is based on the packets
created by the transport layer of the TCP/IP protocol stack
2

when messages are sent back and forth over the Internet.
This means that if PCAP data is available for IRC, P2P,
HTTP, and any other botnet administration protocol it is
structured the same, the only preparation that needs to be
made before analysis is the selection for the attributes to
define the nodes and links.
Node attribute selection seeks to identify each member
of a community that sends or receives a message. We
selected IP address as our node attribute because each
node is required to have an IP address assigned to it. A
well known issue with IP addresses is that they tend to
change frequently, which makes identifying nodes uniquely
impossible when considering only the IP address. Our
current research is only concerned with discovering the
communities and the semantics of the communications between the nodes in each community. Hence, the uniqueness
of each node is not required. We leave identifying unique
nodes to future work.
Link attribute selection in our approach is concerned
with identifying identical links. Because of this, we selected Payload Length as our link. Payload length meets
our requirement since periodically bot nodes in a botnet
will either receive or send an identical message. Payload
length is also readily available and useful regardless of
the readability of the payload. For instance, if the payload
messages of a botnet are encrypted, we will not be able to
understand the communication across the network without
a time consuming decryption step, but since many payload
messages in a botnet tend to have the same content, these
identical messages which are encrypted using the same
algorithm will be the same size.
Node Category Discovery. To discover information
that can aid in botnet defense, we place each node in a
category based on their actions in the communities. These
categories are: Master Node-which initiates all commands
to the botnet, Command and Control Node-which acts as a
proxy between the Master Node and the rest of the botnet,
Bot Node-which carries out commands received from the
Command and Control and returns responses periodically
or when prompted, and finally the Victim Node-which is
the target of attacks and does not send a response recorded
in our data.

(a) k=2

(b) k=3

(c) k=4

Fig. 1. Example k-cliques: In order to be a k-clique each node needs
to have a connection to every other node in the clique. (a) Two fully
connected nodes (b) Three fully connected nodes (c) Four fully connected
nodes.

The k in k-clique represents the number of fully connected nodes in the clique. Fig. 1 displays three cliques
with different k values. All cliques are equal to or are a
subset of a maximal clique. In addition, there can be many
cliques in a maximal clique, but a maximal clique cannot
belong to another clique. Cliques percolate into each other
by being adjacent and communities are built from adjacent
cliques. We define several terms as follows:
Definition 3.2: The largest amount of fully connected
nodes k found in a particular community is known as the
maximal clique.
Definition 3.3: Two k-cliques are adjacent if they have
k 1 nodes in common.
Definition 3.4: A community is a set of two or more
adjacent cliques.
Note that others have relaxed the definition of adjacency
by varying k 1 to k i, and is dependent on the method
being used [10]. An important element captured using the
clique percolation method is community overlap.
Definition 3.5: Community overlap occurs when at
least one node is part of multiple communities.
In order to identify communities using this method we
first discover the maximal cliques in the botnet. This step
takes into account the botnet as a whole and finds the
maximal cliques built from fully connected nodes within the
botnet. Each maximal clique now represents a node which
will or will not be paired with other maximal cliques. To
identify the links between cliques we create an adjacency
matrix O with adjacent cliques i and j. In order to find all
cliques of size k that are percolating into each other and
forming communities, all values of O that are equal to or
greater than k-1 are given the value 1 in the matrix and
all other values of O are set to 0. After this process, each
value of 1 in the matrix represents a community and the
community overlap is discovered by identifying the number
of vertices shared by clique (i and j).
Once communities are discovered, we integrate directional data based on the Source and Destination IPs. This
step is straight forward and forms the basis of our analysis
by identifying how nodes communicate amongst each other.
Previous research has shown that bots make up at least
50% of the total nodes found in a botnet [9]. Using this
key metric as a threshold, we discover the category of
each node. Our node categorization algorithm performs
as follows:
1. Discovering Coordinated Activity–Identify all mes-

A. Botnet Community Model
We select k-clique constructs that are based on Palla et.
al. [10], to build our communities. Our intuition behind
this is two-fold: (1) our community identification is local,
which means if a node or link outside of the community
were to be removed, then the local community would not
be effected. (2) It allows overlaps, which means a node can
be part of more than one community at the same time. In
clique percolation, there is a graph with nodes and links,
(of weight 1 and non-directional), which represent a means
of communication or contact without self-edges.
Definition 3.1: A clique is a set of nodes that have a
link to every other node in the set.
3

sages sent to or received by at least 50% of the nodes
in a community graph and this step terminates if a
coordinated link is not discovered or no nodes in a
current community have been previously categorized;
2a. Identifying Command and Control Nodes–Identify all
nodes sending messages to or receiving and forwarding messages from coordinated nodes;
2b. Discovering Victim Node–Identify all nodes that receive messages from coordinated nodes and do not
respond;
3. Discovering Master Nodes–Identify all nodes that
sends/receives non coordinated messages to the command and control nodes without receiving a coordinated reply; and
4. Discovering Bot Nodes–Identify all nodes that are
part of the coordinated group that sent or received
coordinated messages.
A community graph is a set of all communities discovered in a temporal window. Each community graph
represents a timestep in our botnet analysis. We have
discovered that many botnets have session intervals of less
than 10 minutes, for this reason we chose 10 minute time
intervals for each community graph. This means that all
nodes and links that are discovered within a 10 minute
increment are part of the same community graph. We also
consider adjacent community graphs to account for sessions
that span across multiple community graphs. Assuming
that we are analyzing the initial community, step 1 of
our algorithm checks each community in the graph for
discovering identical links in one direction that reaches at
least 50%. If the community does not have a coordinated
group of at least 50% we do not consider it useful for
botnet analysis. In step 2, we check to see if the discovered
coordinated links have a one to many relationship. Step 2 is
split into (a) and (b) because at this point the single node
that has been identified will be classified as a Command
and Control Node if messages are being sent and received
which is identified as Step 2a. If messages are only being
received, the node will be classified as a Victim, which
is identified in Step 2b. At this point, the command and
control nodes have been identified. Nodes that send noncoordinated links to the command and control nodes are
identified in Step 3, and are considered bot masters because
no other node type recorded in the community will send
non- coordinated messages without receiving a coordinated
reply in the allocated time interval. Step 4, identifies the
nodes that are 50% or over of members that sent or received
a coordinated link. There has to be at least 2 nodes in this
category.

(a) GUI

(b) CUI
Fig. 2. Current Proof of Concept Tool: (a) Graphical Interface and (b)
Command-line

in Virtual Machines (VMs) designed to capture botnet
traffic. Our datasets consist of PCAPs from the HTTP based
BlackEnergy botnet and an unnamed IRC botnet.
Tools and Implementation. To conduct our analysis, we
created tools based on the Python and Perl programming
languages. We based our community extraction on the open
source tool, CFinder[1], to discover communities. Fig. 2
shows the proof-of-concept prototype of our graphical and
command line tools.
The front end of our tool is designed to provide options
in choosing the node.
A. Analysis of an IRC botnet
First we demonstrate our approach by analyzing network
traffic from a botnet controlled by the IRC protocol. As a
reminder, the verticies (nodes) are identified by IP address
and the edges (links) are identified by the message payload
size in bytes. Example (21B is a message of size 21 bytes).
Community Graph Analysis (IRC): Figure 3 shows
six randomly selected nodes from a community graph.
The applied directional links show that nodes (x.x.x.16,
x.x.x.17, x.x.x.18, x.x.x.19, x.x.x.10) all receive a (21B)
request (shown in dotted lines) from (node x.x.x.194). All
nodes except for node x.x.x.194 returned a (20B) response
(shown in solid lines). Following step 1 of our algorithm,
nodes x.x.x.10, x.x.x.16, x.x.x.17, x.x.x.18, and x.x.x.19 all
received and sent a message at the same time and since this
represents over 50% of the nodes found in the community
graph this qualifies as a coordinated communication event.
Based on step 2a of our algorithm, node x.x.x.194 is a

IV. B OTNET C OMMUNITY A NALYSIS E VALUATION
All of the components in our analysis are implemented
on commodity hardware using Inter Core i7 and 8GB
memory through Cygwin. This is important because no
modification of the hardware is required for our method to
operate. The data collection and analysis were conducted
4

COMMAND AND CONTROL node because it is the node
that sent and received the coordinated message. In this
community there were no nodes that received coordinated
messages without returning a message step 2b and there
were no nodes that sent non-coordinated messages to the
command and control node step 3. All the other nodes were
part of the group that made up the coordinated nodes which
only sent and received coordinated messages. According to
step 4 of our algorithm, these nodes all belong to the BOT
node category.

evaluation and Command and Control Nodes were fully
identified. Botmaster Nodes were identified with a (67%)
detection rate, but this result was a bit misled because 77
of those botmaster Nodes identified by manual analysis
connected to a Command and Control Node once and
did not commit any subsequent transactions. Victim Nodes
had a success rate of (87%), but attack detection had a
rate of (68%). The reason for the disparity here is many
attacks only involved one or two bots in the botnet. These
are reconnaissance attacks that are sent out before more
large-scale coordinated attacks are conducted. Currently
our approach does not capture these reconnaissance attacks in the communities. Overall our analysis result was
meaningful and promising and it shows our method was
conducted nearly three days faster than the manual analysis.
Community overlap was relatively high in our study. This
is interesting because normal Internet traffic is said to have
a relatively low overlap rate.

Fig. 3. Sample Community of IRC Botnet in a Community Graph:
Command and control node x.x.x.194 sends a link (21B) to all bots in the
community. Bots respond to the command and control node with identical
links of (20B).

Method
Bot Com
Manual

Time
30 min
3 days

Bots
4323
4310

C&C
34
34

botmasters
234
351

Victims
61
70

Attacks
219
321

TABLE I
IRC C OMMUNITY M ETHOD R ESULTS

In Figure 4 we first see the (20B) and (21B) messages
sent previously step 1. Node x.x.x.194 still qualifies as a
COMMAND AND CONTROL node based on Step 2a. Node
x.x.1.19 received coordinated messages but did not return
any data, so based on Step 2b it fits in the VICTIM node
category. Next we see node x.x.x.10, which was one of the
nodes found in the bot category in the previous community
graph and sent a non-coordinated message, (181B), to the
command and control node x.x.x.194. According to Step
3 this places the node in the BOTMASTER node category.
In this new graph all the other nodes in the graph sent
a message (9B) to the node x.x.1.19, which places it in
the VICTIM category. The nodes that sent the coordinated
message represent more than 50% of the nodes in the graph
and they only sent coordinated messages so according to
Step 4 these nodes belong to the BOT category.
Manual Analysis (IRC): The IRC botnet we analyzed
followed specifications from RFC 2812 and included all
message types. Link (21B) translated to a PING message
and link (20B) translated to a PONG message. PING/PONG
messages are sent periodically to determine what nodes
are considered available within the IRC network. In Figure 4(a), we can notice that the PING links (21B) were sent
throughout the network to see what nodes were available
and the PONG links (20B) gave the reply. In Figure 4(a),
a node x.x.x.10 sent an attack command to node x.x.x.194
with the destination node set to ALL. Figure 4(b) shows
the result of the command (ALL), where each of the bots
in the botnet sent a (9B) message to the node x.x.x.19.
Summary of Overall IRC Analysis. The overall results
discovered using our botnet community overlap method
were similar to those discovered using the manual analysis.
Bots were correctly classified (99%) of the time during the

(a) IRC Command Propagation Found in Community Graph 1

(b) IRC Command Execution Found in Community Graph 2
Fig. 4. Sample Result of Command Propagation and Attack Across
Adjacent Community Graphs: (a) Botmaster node x.x.x.10 sends a link
(181B) to command and control node x.x.x.194 to send a message to all
bots in the botnet. (b) All the bots in the botnet send a (9B) attack to
victim node x.x.x.19.

B. Analysis result of HTTP botnet
The HTTP botnet used in this article followed standard
protocol procedures in HTTP RFC 2616 [7]. Figure 5 shows
three partial communities across three community graphs
that were constructed from randomly selected nodes.
Community Graph Analysis (HTTP): Here we show
an example of our analysis across three community graphs
which are shown Figure 5. Figure 5(a) shows a segment
of a community graph where a node x.x.x.51 sent a coordinated link to all the other nodes in the community.
5

x.x.x.16, in the BOTMASTER node category because it
sent non-coordinated links without receiving a coordinated
response.
In the community graph shown in Figure 5(c), nodes that
were previously identified as belonging in the bot category
also sent a coordinated message to a new node x.x.x.89.
Since the node x.x.x.89 did not respond to the coordinated
link, it is placed in the VICTIM category. Also, if the nodes
that sent the coordinated message were not previously
identified as bots, they would have been identified as bots
in this graph because of the coordinated message that was
detected.

(a) HTTP Bots and Command and Control Server Interactions Found in
Community Graph 1

Manual Analysis (HTTP). Manual analysis of the community graph in Figure 5(a) shows that nodes x.x.x.27,
x.x.x.31, x.x.x.28, x.x.x.29, x.x.x.1, and x.x.x.30 are bots
sending requests to a command and control node x.x.x.51
for obtaining command instructions. Figure 5(b) shows a
series of communications between a botbotmaster x.x.x.16
and a command and control server x.x.x.51. In Figure 5(c),
bot nodes x.x.x.1., x.x.x.27, x.x.x.28, x.x.x.29, and x.x.x.30
all sent an attack message to the victim node x.x.x.89. These
results also are consistent with the analysis conducted using
our community graph analysis.

(b) HTTP Botmaster and Command and Control Server Interactions Found
in Community Graph 2

(c) HTTP Attack Discovered From Multiple Bots to a Victim Found in
Community Graph 3

Summary of Overall HTTP Analysis. The overall
results of our method compared to the manual analysis for
this botnet were nearly identical. Just like the analysis of
the IRC based botnet, bots were correctly classified (99%)
and Command and Control Nodes were fully identified. In
the case of the bots, the nodes that were not identified did
not participate in the coordinated group activity for some
reason. Since they did not perform anything malicious they
were not important from the attack analysis perspective.
Botmaster nodes were partially identified (31%) but this
result is again misled because all 9 of the botmasters that
were not discovered only connected to each other and did
not perform a malicious act. For victims we actually had 2
false positives. The manual analysis revealed that we incorrectly classified two botmasters as victims because multiple
bot nodes sent a link of the same size to the botmasters
within the same time interval. Finally we had a success
rate of (91%) for discovering attacks. All the attacks that we
missed were small-scale activities so they were not captured
in our community analysis. Our community overlap rate
was once again high across communities, which suggests
we may be able to leverage this attribute in future analysis
studies.

Fig. 5. Sample Result of Adjacent HTTP Botnet Community Graphs:
(a) Command and control node x.x.x.51 sends a coordinated link (279B)
to all the bot nodes in the botnet. (b) Botmaster node x.x.x.16 sends a
series of links (823B, 395B, 583B, 468B) to command and control node
x.x.x.51, which then sends a series of replies (78B, 1460B, 104B, 870B,
820B) back to the botmaster node.

Based on step 1, this qualifies as a coordinated event
since more than 50% of the nodes received a link of the
same size (279B). Based on step 2(a), node x.x.x.51 is
a COMMAND AND CONTROL node because it sent the
link. In this community graph there are no nodes that
received coordinated messages without returning a response
so step 2(b) does not apply and there were no nodes that
sent a non-coordinated link without receiving a coordinated
response, so no botmasters were discovered using step 3.
Since all nodes x.x.x.27, x.x.x.31, x.x.x.28, x.x.x.29, x.x.x.1,
and x.x.x.30 received a coordinated link (279B), these nodes
are classified as BOT nodes by step 4 of our algorithm.
Note that after all the bot nodes received a coordinated
link they returned similar, but non-identical replies. These
replies are updates and are currently used as metadata, but
not to identify the category of the nodes.
In the community graph illustrated in Figure 5(b), a new
node is discovered which sends a series of non-coordinated
links to a node x.x.x.51. The node x.x.x.51 was previously
identified as a command and control node in an adjacent
community graph. In this community graph steps 1,2 (a),
2(b), and 4 were not utilized, because no coordinated links
were observed, but since the node x.x.x.51 was already
identified in a previous graph, we were able to use its
previous state and apply step 3 which placed a new node,

Method
Bot Com
Manual

Time
12 min
2 days

Bots
2123
2102

C&C
5
5

botmasters
4
13

Victims
45
43

TABLE II
HTTP C OMMUNITY A NALYSIS R ESULTS

6

Attacks
59
65

V. D ISCUSSION

on their communication patterns. Discovering this information early in the overall analysis process gives analysts
enough information to make preliminary decisions, such as
blocking attacking IPs and identifying key nodes such as
the command and control servers.
Current methods to analyze botnets require the manual
step of reverse-engineering the command and control protocol used to administer the botnet. This is a nessecary step
for a detailed analysis, but presents an opportunity for the
botnet to continue its nefarious acts during the procurement
of the process. Our approach has shown through a botnet
analysis comparison of our method, and an expert based
manual method, that our approach identifies the correct
category for each node with a high percentage rate and a
low false positive rate. Since our approach is command and
control protocol independent it can perform this analysis
without reverse-engineering the botnet administration structure. This makes our analysis much faster than the detailed
analysis, and the information provided can prevent attacks
while waiting for the more detailed analysis to complete.
These results show that our approach shows great promise
as a potential add-on-layer to a defense-in-depth network
protection strategy.

Here we discuss future directions of our approach along
with potential approaches.
Attack Reconnaissance Discovery. An issue with discovering botnet communities using our method is the
possibility of not discovering all botnet transactions. For
our analysis we set the value of k to 3, which allows
us to identify all communities where at least three nodes
can communicate with each other. The communities are
not captured if it involves direct messages between two
nodes, such as botmaster to botmaster communications.
These transactions are usually used to discuss malicious
plans or send test attacks towards a target. One way to solve
this problem is to reduce the k value to 2, but this also
greatly enlarges the size of the communities discovered.
Instead of reducing the k value across the entire community, we will experiment with conducting an analysis that
reveals all adjacent links and nodes of identified botmaster
and command and control nodes. This should reveal the
"silent" botmasters that only connect to other botmasters
and command and control nodes.
Botnet Traffic Detection. Currently our method only
applies to botnet data after an attack has been discovered
by other methods. In the future we plan to investigate
expanding our approach to further discover botnet traffic
in a set of unfiltered network data. The current state
of our algorithm will not allow us to accomplish this
goal because of the significant amount of communities
that will be created, such as the case addressed in [6].
Furthermore, at k = 3, some of the communities created
by our approach would not be related to botnet traffic.
To address this issue we plan to modify our algorithm by
adding additional conditions which are more selective for
constructing communities. One possible option is to require
the detection of homogeneous interaction between nodes
before a community is extracted. Currently we consider the
homogeneous properties of the traffic after the communities
are discovered, which initiates our node classification. The
high success rate in correctly identifying these nodes show
that the homogenous property is of significant value and
has a reasonable chance to succeed in differentiating botnet
communities from other communities on the Internet.

R EFERENCES
[1] B. Adamcsek, G. Palla, I. J. Farkas, I. Derényi, and T. Vicsek.
Cfinder: locating cliques and overlapping modules in biological
networks. Bioinformatics, 22(8):1021–1023, 2006.
[2] S. Borgatti, M. Everett, and P. Shirey. Ls sets, lambda sets, and other
cohesive subsets. In In the Proceedings of Social Networks, 1990.
[3] D. Bradbury. Fighting botnets with sinkholes. Network Security,
2012(8):12–15, 2012.
[4] C. Y. Cho, D. Babic, E. C. R. Shin, and D. Song. Inference
and analysis of formal models of botnet command and control
protocols. In Proceedings of ACM Conference on Computer and
Communications Security. ACM, 2010.
[5] D. Dittrich. So you want to take over a botnet. In Proceedings of 5th
USENIX conference on Large-Scale Exploits and Emergent Threats.
USENIX, 2012.
[6] E. Gregori, L. Lezini, and C. Orsini. k-clique communities in the
internet as-level topology graph. In Proceedings of the 31st International Conference on Distributed Computing Systems Workshop,
pages 134–139. IEEE, 2011.
[7] N. W. Group. Hypertext transfer protocol request for comments.
http://www.ietf.org/rfc/rfc2616.txt, 1999.
[8] G. Gu, P. Porras, V. Yegneswaran, M. Fong, and W. Lee. Bothunter:
Detecting malware infection through ids driven dialog correlation.
2007.
[9] G. Guofei, J. Zhang, and W. Lee. Botsniffer: Detecting botnet command and control channels in network traffic. In Proceedings of the
15th Annual Network and Distributed System Security Symposium.
NDSS, 2008.
[10] G. Palla, I. Derényi, I. Farkas, and T. Vicsek. Uncovering the
overlapping community structure of complex networks in nature and
society. Nature, 435(7043):814–818, 2005.
[11] N. C. Paxton, G.-J. Ahn, and M. Shehab. Masterblaster: Identifying influential players in botnet transactions. In 35th Annual
IEEE International Computer Software and Applications Conference
(COMPSAC). IEEE, 2011.
[12] N. J. Percoco.
2013 trustwave global security report.
In www2.trustwave.com/rs/trustwave/images/2013-Global-SecurityReport.pdf. Trustwave, 2013.
[13] D. Plohmann and E. Gerhards-Padilla. Malware and botnet analysis
methodology. In Proceedings of 4th Annual Conference on Cyber
Conflict. CyCon, 2012.

VI. C ONCLUSION
In this article we introduced a new approach for analyzing botnet traffic. In particular, we made two notable
contributions:
Our first contribution was a novel algorithm for botnet
analysis based on an extension of k-clique community
finding constructs. By discovering communities in botnets,
events such as attacks are systematically identified without
having to conduct a time consuming, manual analysis of
the commands used to administer the botnets.
Our second contribution was a method to identify the
category that each node belongs to within the botnet based
7

[14] C. Rossow, C. J. Dietrich, H. Bos, L. Cavallaro, M. v. Steen,
F. Freiling, and N. Pohlmann. Sandnet: Network traffic analysis
of malicious software. ACM, 2011.
[15] S. Seidman. Network structure and minimum degree. In In the

proceedings of Social Networks, 1983.
[16] Z. Zhao, G.-J. Ahn, and H. Hu. Examining social dynamics for
countering botnet attacks. In 54th IEEE Global Communications
Conference (GLOBECOM). IEEE, 2011.

8

ECONOMICS OF CYBERSECURITY, PART 2

Mules, Seals, and Attacking Tools:
Analyzing 12 Online Marketplaces

Ziming Zhao, Mukund Sankaran, and Gail-Joon Ahn | Arizona State University
Thomas J. Holt | Michigan State University
Yiming Jing | Arizona State University
Hongxin Hu | Clemson University

A six-year analysis of 12 multilingual online marketplaces focuses on underground commerce, including
stolen user data, fake identities, and attacking tools and services. Migration trends, items for sale, and
seller and buyer characteristics reveal commonalities among these fraudulent markets.

R

esearchers have dissected and analyzed many technologies designed to facilitate cybercrime, such as
malware and botnets, and have proposed and deployed
countermeasures against such technologies. However,
studying the economy behind these technologies and
campaigns is imperative for obtaining a holistic view of
cybercrime. The majority of research examining online
underground markets considers small samples of mostly
English-language markets; few studies have systematically examined or compared multiple markets over long
periods of time (see the “Related Work in Online Market Analysis” sidebar).
To remedy this, we collected multilingual online
underground marketplace data from 12 market forums
between December 2005 and July 2011 and systematically examined and compared them to gain a deeper
understanding of cybercrime.

Forums and Data Overview

We first discovered three English-language forums
through Google using common terms in stolen data
markets, including “carding,” “dump,” “purchase,” “sale,”
32

May/June 2016

and “CVV” (card verification value).1 By exploring the
contents of the Russian Speaking Carder subforum of
these three English-language forums, we discovered
three Russian-language forums via user-shared links. We
found the other six forums in the same way—by analyzing the posts in the previously discovered forums. These
12 forums were geared toward commerce, whereas most
previously studied forums were designed for computer
hackers to communicate and share.
Most of the 12 marketplace forums were publicly
accessible without registration. A few were available
only for registered users. To access these, we created a
separate username for each forum but didn’t interact
with other registered users.
We don’t claim the data we have is complete; in fact,
we analyzed only certain subforums highly related to
cybercrime. For each forum, we gathered data that a
registered user would see, such as posts, replies, number
of posts from a specific user, and so on. We didn’t collect private data that was available only to specific users
or administrators, such as private messages and banned
user logs. The data was in HTML format and more than

Copublished by the IEEE Computer and Reliability Societies

1540-7993/16/$33.00 © 2016 IEEE

Related Work in Online Market Analysis

T

o peek into the understudied cybercrime economy, some
groups have studied specific underground economy cases,
such as keyloggers and spam campaigns; others have examined
online marketplaces that rent, sell, and distribute malware, botnet,
stolen user data, illegal services, and so forth. However, few published studies on cybercrime markets actually assess the pricing
structures for data and services. Even though “Exploring Stolen
Data Markets Online: Products and Market Forces” and “Examining the Risk Reduction Strategies of Actors in Online Criminal
Markets” touch on the subject, few papers have systematically
examined or compared multiple marketplaces communicating
in different languages over long periods of time.1,2 As a result,
it’s difficult to assess the scope of harm that cybercrime markets
cause, whether they operate on the open Web or Internet relay
chat (IRC). The 12 forums in our study were all geared toward
commerce, whereas most forums analyzed in previous literature
on underground society were designed for computer hackers to
communicate and share.1,3–7. For instance, “Examining the Social
Networks of Malware Writers and Hackers” explored the social
networks of a group of Russian hackers to understand the nature
of relationships and the ways that they affect information sharing
and action. “SocialImpact: Systematic Analysis of Underground
Social Dynamics” modeled online underground social dynamics by considering both social relationships and user-generated
contents and systematically quantified social impacts of individuals and groups.
Our study also differs from studies on Silk Road, a fraudulent market that focused on illegal and controlled substances.8 The forums

6 Gbytes in size. Some of the forum webpages contained direct evidence of financial and computer-aided
crime, whereas others contained conversations related
to such suspicious activities.

Data Preprocessing Methodology
Manual analysis of this large volume of data is tedious
and difficult; therefore, we chose a semiautomated
approach by developing programs and scripts that were
guided by our initial manual analysis. Then, we manually investigated and verified the extracted results.
After acquiring the forum webpages, we used
freshly designed parsers and our in-house social analysis tool to perform preprocessing.2 Our parsers automatically went through all the collected HTML pages
and identified and extracted basic information such
as each thread’s title, date information, usernames,
and post contents. Even though the input HTML
format differed among forums, our parsers output
­well-formatted information and stored it in a database.
www.computer.org/security

in our dataset were fraught with threads that were highly related to
financial crimes, identity fraud, and other suspicious activities.
References
1.	 T.J. Holt and E. Lampke, “Exploring Stolen Data Markets Online:
Products and Market Forces,” Criminal Justice Studies, vol. 23, no.
1, 2010, pp. 33–50.
2.	 T.J. Holt et al., “Examining the Risk Reduction Strategies of
Actors in Online Criminal Markets,” Global Crime, vol. 16, no. 2,
2015, pp. 81–103.
3.	 A. Abbasi et al., “Descriptive Analytics: Examining Expert Hackers in Web Forums,” Proc. IEEE Joint Intelligence and Security Informatics Conf. (JISIC 14), 2014, pp. 56–63.
4.	 S. Afroz et al., “Doppelgänger Finder: Taking Stylometry to the
Underground,” Proc. IEEE Symp. Security and Privacy (SP 14),
2014, pp. 212–226.
5.	 T.J. Holt et al., “Examining the Social Networks of Malware Writers and Hackers,” Int’l J. Cyber Criminology, vol. 6, no. 1, 2012, pp.
891–903.
6.	 M. Motoyama et al., “An Analysis of Underground Forums,” Proc.
ACM SIGCOMM Conf. Internet Measurement Conference (IMC
11), 2011, pp. 71–80.
7.	 Z. Zhao et al., “SocialImpact: Systematic Analysis of Underground Social Dynamics,” Proc. European Symp. Research in
Computer Security (ESORICS 12), 2012, pp. 877–894.
8.	 N. Christin, “Traveling the Silk Road: A Measurement Analysis of
a Large Anonymous Online Marketplace,” Proc. Int’l Conf. World
Wide Web (WWW 13), 2013, pp. 213–224.

Our in-house tool then took over and went through all
the webpages stored in the database, using a language
detection tool to determine the posts’ languages. Posts
that weren’t in English were translated using a language
translation tool. Our in-house tool computed the most
active and influential users in the dataset and visualized
their social dynamics.
To understand our marketplaces, we first automatically
identified selling and buying posts. For selling posts, we
used four criteria, classifying a post as a selling post when
the first and at least one other criterion were satisfied:
■■ At least one word related to selling appeared in the post.
Such words include “sell,” “offer,” “sale,” “give,” “trade,”
“vendor,” “dealer,” “merchant,” and their derivatives.
■■ The post’s length was sufficiently long (more than 150
characters). We used this feature because sellers usually provide product information, which invariably
made their posts quite long.
■■ The words “ICQ” or “PM” appeared in this post.
33

ECONOMICS OF CYBERSECURITY, PART 2

Table 1. Basic information about the 12 forums’ domain names.*
Registration and
expiration dates

Name

Registrant country

IP locations

Forum1

Russia

Germany (2), Lithuania (1), Ukraine (1), Portugal (1), Netherlands (1),
Moldova (1), Netherlands (1), and Germany (2)

Nov. 2010 to Nov. 2011

Forum2

N/A

Canada (1), Netherlands (1), and Germany (1)

N/A

Forum3

Russia

England

Feb. 2006 to Feb. 2015

Forum4

US, Netherlands

US (1), Canada (3), Netherlands (1), Germany (1), and Ukraine (1)

Sept. 2009 to Mar. 2011

Forum5

Russia

England

Apr. 2004 to Apr. 2015

Forum6

Russia

Sweden

Dec. 2004 to Dec. 2015

Forum7

N/A

N/A

N/A

Forum8

Russia

N/A

Apr. 2011 to ??

Forum9

Ukraine

Germany

Apr 2009 to Apr. 2015

Forum10

Brazil

N/A

N/A

Forum11

Russia

N/A

N/A

Forum12

N/A

N/A

N/A

* Numbers in parentheses indicate the number of consecutive IP locations in each country.

Sellers usually provided their ICQ (an IM program)
numbers or asked to use private message (PM) for
further communications.
■■ At least one word related to money was present.
Examples include a dollar sign, “webmoney,” “wm,”
“roubles,” “cash,” and “wallet.”
Buying posts had to meet the following two criteria:
■■ At least one word related to buying appeared in
the post. Such words include “buy,” “seek,” “look,”
“search,” “purchase,” and their derivatives.
■■ The post was short (less than 150 characters).
Our tool’s search engine component indexed all
original and translated text in webpages. Given one or
more keywords, our tool returned the webpages, posts,
and users related to such words. By building programs
and scripts on top of our in-house tool, we were able to
perform more sophisticated analysis on the original and
translated data.
During an initial manual analysis of our dataset, we
noticed that a substantial volume of valuable information resided in nontextual resources, so we also analyzed images and flashes in this dataset. To make this
analysis scalable, our tool first went through all folders
in our dataset and extracted unique images (based on
their hash values) larger than 20 Kbytes. This resulted in
fewer than 1,000 unique GIF and JPEG files. We manually went through these images to choose the ones that
pertained to commerce. After this process, we ended up
34	

IEEE Security & Privacy

with fewer than 100 images. A Russian translator helped
us understand the content on those images.

Domain Names, Whois Records,
and IP Addresses
In addition to the previous data, we acquired the Whois
records and IP address histories of the 12 domain names
while the forums were active. Our funding agencies
requested that we not publish the domain names publicly. Such information would provide unique insights
into where these underground forums were registered
and hosted and how they migrated from country to
country during their lifetime. Table 1 summarizes each
forum’s basic information, including registrant country,
IP locations, and registration and expiration dates, and
Table 2 shows the data we collected from each forum,
including its subforums; dates analyzed; and number of
threads, posts, and users.
Forum1 was an English-language forum dedicated
to trading credit cards and other financial information.
It was registered in November 2011 by a person who
lived in Russia for a year. During that year, the forum
had 10 different IP addresses that indicate that the
server migrated across six countries. Forum1 data contains 56 threads from the Market subforum, generated
by 86 users.
Forum2 was an English-language forum that had a
Russian-language carders subforum. Its domain name
was registered through privacyprotect.org, which
acts as a registrant proxy and obfuscates the real registrants’ identities. Therefore, we don’t know how
May/June 2016

Table 2. Summary of data from the 12 forums.
Name

Subforums

Dates covered

No. of threads

Forum1

Market

Dec. 2010 to Jan. 2011

56

112

81

Forum2

Russian speaking carders

Dec. 2010 to Jan. 2011

118

378

114

Forum3

Hacking & Security
> Money

Dec. 2005 to Feb. 2011

398

8,751

1,652

Forum4

Buy/Sell/Exchange/Jobs

Sept. 2009 to Feb. 2011

508

1,637

478

Forum5

Flea market

May 2008 to Jan. 2011

891

1,892

792

Forum6

Banks, Auction

July 2008 to Mar. 2011

775

7,983

1,585

Forum7

Russian speaking carders

Dec. 2010 to July 2011

300

1,710

344

Forum8

Verified services only
> accounts, enroll
> bank drops
> botnets, viruses, exploits
> call services, translation text
> cashing atm payment system
> cc with ccv
> design, scans documents, id
> drops for stuff
> dumps, sell, cashout
> hacking services
> money exchanges, wu
> other services
> plastic, holograms
> security, vpn, socks, proxy
> servers, hosting, rdp
> spam, flooding, job posting
> ssn, mmn, dob
> traffic, load

Apr. 2011 to July 2011

385

1,734

727

Forum9

Shop
> Buy/Sell
> Job

Aug. 2009 to Mar. 2011

600

1,960

614

Forum10

Hacking & Security
> Payment systems

Apr. 2007 to Mar. 2011

86

824

320

Forum11

Ack Software
> Trojans and keyloggers
> Scanners and rest
> SEO/Financial Objectives

July 2007 to Feb. 2011

824

2,534

808

June 2007 to Feb. 2011

749

1,842

871

Forum12

> Carding Forum
>> Fraud Sell/Buy/Exchange

long the domain name was actually registered to the
original registrants. From December 2010 to January 2011, Forum2 changed its IP address three times,
migrating from Canada to the Netherlands and then
to Germany.
Forum3 was a Russian-language website and forum
that was active at the time of this writing. It features
technology news and blogs, most of which focus on
hacking skills, such as vulnerability discovery and
exploit writing. Forum3 had a domain name registration record for 10 years, and was hosted in England. We
www.computer.org/security

No. of posts

No. of users

have an archive of 398 threads, most of which belong to
the subforum Money.
Forum4 was a Russian-language forum whose subforum Buy/Sell/Exchange/Jobs was fraught with the sale
of rogue programs and VPN (virtual private network)
services. The domain name was registered by registrants living in the US and the Netherlands from September 2009 to March 2011, during which the domain
migrated across five countries.
Forum5 was a Russian-language website and forum
that was active at the time of this writing. Its Whois
35

ECONOMICS OF CYBERSECURITY, PART 2

records indicate it had an 11-year registration from April
2004 to April 2015, and was hosted in England. Forum5
data belongs mainly to the subforum Flea market.
Forum6 was an active Russian-language website and
forum that reported crime-related news. It also had a
registration record of 11 years, from December 2004
to December 2015, and was hosted in Sweden. Its data
mainly belongs to the subforum Banks, Auction.
Forum7 was an active English-language forum with
a Russian-language carders subforum. Its domain name
was registered through several privacy-reserving proxies, including privacyprotect.org. Forum7 data covers
December 2010 to July 2011 in the Russian-language
carders subforum.
Forum8 was an English forum with a subforum
called Verified services only, which was further divided
into many subforums, each of which focused on one
area, such as bank drops and botnet, viruses, or exploits.
Forum8 acted like a “one-stop shop” where users could
find a variety of services. Our Forum8 data includes
user-generated content from 727 users.
Forum9 was an active Russian-language hacker
forum. The records indicate that it was registered by
someone living in Ukraine, and its server was located in
Germany. The domain name was registered from April
2009 to April 2015. We have data from its Buy/Sell and
Job subforums.
Forum10 was a Russian-language hacker forum with
a Payment systems subforum under Hacking & Security. We have data posted by 320 users from April 2007
to March 2011.
Forum11 was an active Russian-language hacker
forum. Its registration record is obfuscated. We have
the posts from subforums Trojans and keyloggers,
Scanners and rest, and SEO/Financial Objectives—all
­subforums of Ack Software.
Forum12 is a live Russian-language hacker forum
that has a popular carding subforum and Fraud Sell/
Buy/Exchange subforum with more than 700 posts and
800 users. The domain name was registered through
privacyprotect.org.
In summary, five out of the 12 forums were out of
service at the time of writing. According to our Whois
and IP address information, these five forums changed
their IP addresses many times during their life cycles. All
five forums provided few features apart from discussion
boards on selling and buying. Their Whois registration
records also show relatively short registration periods
that could indicate that the administrators planned to
run these forums and domain names for a short period
of time. These forums might have been reincarnated
through new domain names.
On the other hand, most of the active forums
were part of a larger website. Even though evidence of
36	

IEEE Security & Privacy

financial and computer-aided crime can be found in
these forums, their parent websites host legitimate news
articles and blogs. Their Whois records also show that
their domain names were registered for up to 11 years.
We assume such websites weren’t designed merely for
underground commerce; however, the communities
built around them participate in suspicious activities.

Marketplace Analysis

Here, we present analysis results on the marketplaces,
describing representative goods, seller and buyer characteristics, popular payment methods, and some persistent advertisements.

Goods
Common goods sold in underground markets include
dumps, skimmers, identities, attack tools, and mules.
Dumps. Dumps comprise stolen credit card or bank

account numbers and associated customer data;1,3 they
were the most popular goods for sale in our 12 marketplaces. Using our semiautomatic approach, we found
1,781 dumps sellers in this dataset. The prices for dumps
ranged from US$6 for a standard American credit card
to $200 for a corporate Canadian corporate card.
We found dumps all over the world including Europe,
Asia, the Middle East, Canada, and the US. Some had
service code 101 or 201, which means the cards could
be used internationally with a normal authorization
process and no restrictions on merchant type. Some
dumps had both International Air Transport Association track 1 data, which contains the cardholder’s name
as well as account number and other discretionary data,
and American Banking Association (ABA) track 2 data,
which contains the cardholder’s account, encrypted
PIN, plus other discretionary data. Some had only
track 2 data, for which sellers often offered free tools to
extract track 1 data.
There were some dumps with track 2 data and customer names. Dumps were sold either with or without
PINs and CVVs. Buyers sometimes left feedback on
sellers and helped other buyers to decide where to buy.
Examples include, “Bought 43 dumps with bonuses …
90% HIT OVER 2K AMAZING!” It’s hard to estimate
the amount of dumps in these markets of the sellers’ revenue, but most sellers claimed to update dumps every
day. Even though most sellers didn’t broadcast how they
acquired these dumps, one post, as shown in Figure 1a,
says the dumps were stolen with skimmers.

Skimmers. Users could buy skimmers for many types of
ATMs (such as Wincor, NCR, and Diebold Opteva);
prices ranged from $425 to $6,000 for a skimmer and its
accessories. Our tool identified 17 posts selling skimmers.
May/June 2016

(a)

(b)

Figure 1. Dumps and skimmers. (a) A post selling dumps. The title implies the dumps were obtained by skimming. (b) A
post selling skimmers. The presented skimmer cost US$5,000 and claimed to work on NCR ATMs. The original post was in
English and Russian.

Figure 1b shows such a selling post in which the
seller promoted Global System for Mobile Communications (GSM) skimmer for NCR ATMs. The seller
advertised that this skimmer could be installed in less
than six minutes, including the time for removing NCR
ATMs’ green antiskimming solution.
Identities. Identity-related goods were popular in our
marketplaces. Figure 2a shows the identity-related
items a user can buy from these markets. The left column shows a fake Russian passport, Israeli passport, and
Russian driver’s license. The middle column shows a
fake Russian ID with a hologram that the seller claimed
could “pass tests.” A Russian-speaking seller created
these fake IDs and charged 5,000 rubles apiece. This
seller claimed to provide customized fake IDs within
days. The right column shows several fake holograms,
which resembled the Russian Federation’s coat of arms.
English-speaking sellers also provided fake IDs.
For example, we found an English-speaking seller who
claimed to provide fully swipeable and scannable IDs
with correct hologram and ultraviolet display. This
person claimed to have holograms of Florida, Rhode
Island, New Jersey, Illinois, and Pennsylvania (with
UV) in stock and asked for $1 per hologram for orders
of less than 200 IDs. The price dropped to $0.50 per
hologram for orders over 500.
Attacking tools and services. The marketplaces were

fraught with attacking tools and services. For example,

www.computer.org/security

89 posts were selling distributed denial-of-service
(DDoS) tools and services. Figure 2b shows such a post
wherein the seller sold DDoS attacks for $50 per night.
The seller claimed the DDoS service had been verified by three markets, including Forum4, and sold the
Optima botnets as well.
An April 2011 post was selling the famous bankbot
Carberp, including links to a video of the tool. The seller
asked 2,500 WMZ (WebMoney transfer title unit that’s
equivalent to US dollars) for a version with loader and
grabber, 5,000 WMZ for a version with backconnect
and the ability to inject Internet Explorer and Firefox,
and 8,000 WMZ for a version with Virtual Network
Computing (VNC)-like remote control. Other attack
tools in the market were the PickPockeT botnet, Katrin
exploits pack for rent, webinjects for Zeus/Spyeye, and
a black hole exploits kit.
Mules. Four posts were either selling or buying mules.

The buyers posted the destinations for which they
needed muling services; however, it’s unclear which
goods they were trying to move.

Sellers and Buyers
We were interested in whether sellers were as well connected as buyers and other users. Because no explicit
social networks were defined in these forums, it was
impossible to retrieve users’ buddy lists or contacts,
as we can in Facebook or LinkedIn. Instead, we generated the connections between users based on the visible
37

ECONOMICS OF CYBERSECURITY, PART 2

(a)

(b)

Figure 2. Identity-related goods and attacking tools. (a) Identity-related goods found in the studied markets. The left column shows fake
Russian and Israeli passports and a fake Russian driver’s license. The middle column shows a fake ID with a hologram selling for 5,000 rubles. The
right column features fake holograms for US$1 each. (b) A post selling distributed denial-of-service attacks. The post was in Russian; the white
text in square bracket is the translation from an automated tool.

interactions among them in forum threads. If two users
posted in the same thread, our algorithm added them to
38	

IEEE Security & Privacy

each other’s contact list.
We use contacts per user (CPU) as a metric to
May/June 2016

Table 3. Number of sellers, buyers, and unclassified users in each forum.*
Name

Buyers

Sellers

Other

Forum1

31 (55)

21 (34)

39 (76)

Forum2

26 (180)

42 (201)

65 (318)

Forum3

203 (9,338)

279 (11,992)

1,329 (30,659)

Forum4

214 (607)

335 (807)

129 (624)

Forum5

363 (287)

623 (491)

134 (655)

Forum6

123 (2,964)

189 (4,469)

1,348 (18,406)

Forum7

95 (1,899)

108 (2,144)

216 (1,940)

Forum8

264 (1,143)

343 (1,183)

365 (3,222)

Forum9

242 (584)

408 (825)

181 (849)

Forum10

25 (633)

53 (1,036)

261 (3,237)

Forum11

217 (1,297)

348 (1,460)

434 (2,327)

Forum12

318 (1,078)

416 (1,495)

400 (3,570)

2,121 (20,065)

3,165 (26,137)

4,901 (65,833)

Total
Contacts per user

9.4

8.2

13.4

* The numbers in parentheses indicate the total number of contacts.

represent users’ social connectivity in each category.
As Table 3 shows, we identified the number of sellers,
buyers, other users, and their CPUs in each forum using
the aforementioned criteria. There were a total of 2,121
buyers and 3,165 sellers. On average, sellers had 8.2
contacts and buyers had 9.4, whereas users who weren’t
classified as a seller or a buyer had 13.4 contacts on average. We conducted two-sample t-tests (with the significance level set at 5 percent) to determine whether the
two user groups differed in terms of number and type
of contacts. We found that the buyers and sellers didn’t
significantly differ in number of contacts (p = 0.127, H0
accepted at a 5 percent significance level). However,
buyers and sellers did significantly differ from unclassified users in terms of number of contacts (p < 0.001, H0
rejected at a 5 percent significance level).
Manual verification reveals two reasons behind this
phenomenon. First, the selling and buying posts possibly triggered fewer replies than other types of threads.
We suspect that selling and buying transactions were
moved to private channels, such as PM or ICQ, soon
after an initial advertisement or solicitation, as research
has shown that private communications are frequently
used rather than overt purchases on the forums.1,4,5
However, other types of posts, such as discussion of
recent news, would receive more comments. Second,
sellers and buyers preferred to keep a low profile and
weren’t seen participating in other threads as much as
other users.
www.computer.org/security

We classified the 3,165 sellers into dumps sellers and
other types of sellers. There were 1,781 dump sellers
in the 12 forums, as Table 4 shows, which is more than
other sellers in total.
We were interested in whether dumps sellers’ posts
generated more discussions in public than other sellers’ posts. Although dumps sellers did dominate all
products sold, other resources were needed to facilitate
actual thefts. Thus, feedback is invaluable to assess their
quality. We used replies per user to represent the average
number of comments that users in a category receive.
We conducted a two-sample t-tests to determine
whether dump sellers’ posts received equal replies to
other sellers’ posts. No significant difference was found
between the groups in number of replies per user (p =
0.085, H0 accepted at a 5 percent significance level).
We analyzed the number of overlapping usernames
across all pairs of marketplaces. The results show these
forums didn’t share many users, with most pairs of forums
having less than 5 percent overlapping usernames. However, 57 percent of Forum2 users were also members of
Forum7, and 18.9 percent of Forum7 users were members of Forum2. Besides user overlap, we were also interested in seller overlap across all pairs of marketplaces. By
comparing the seller usernames, we found that most of
the overlapping usernames belonged to sellers. In the
66 market pairs, the shared usernames from five pairs all
belonged to sellers. In addition, 21 market pairs had more
than 50 percent of shared users acting as sellers.
39

ECONOMICS OF CYBERSECURITY, PART 2

Table 4. Number of dump sellers and other sellers.*
Name

Dump sellers

Other sellers

Forum1

14 (20)

7 (4)

Forum2

24 (129)

18 (88)

Forum3

165 (1,950)

114 (1,814)

Forum4

194 (526)

141 (309)

Forum5

318 (456)

305 (379)

Forum6

84 (896)

105 (1,866)

Forum7

60 (309)

48 (274)

Forum8

291 (847)

52 (63)

Forum9

210 (596)

198 (429)

Forum10

19 (169)

34 (240)

Forum11

178 (538)

170 (396)

Forum12

224 (449)

192 (313)

1,781 (6,885)

1,384 (6,175)

3.8

4.5

Total
Replies per user
*Numbers in parentheses indicate replies received by sellers.

Payment Methods
We identified several payment methods mentioned
in these forums and counted their occurrence in each
forum. Manual analysis revealed that most buyers
and sellers mentioned acceptable payment methods,
whereas in some cases, sellers were trying to sell credentials of those payment methods.
We differentiated the number of times a payment
method appeared in original posts and the number of
times it appeared in replies. This is because our manual
analysis revealed that a payment method’s appearance
in an original post was an indicator for buyers or sellers
to regard it as an acceptable financial channel to make
transactions. And, its appearances in the replies might
have been due to discussions and queries. However,
we don’t have transaction data to show the actual use
of any payment method. We use original post–to–all
posts ratio (OAR)—that is, the number of times a payment method appeared in an original post divided by
the number of times it showed in all posts—as a metric
to denote how often a method appeared in an original
post. The higher the OAR, the more likely the payment
method was acceptable for buyers and sellers.
Table 5 shows our database’s most popular payment
methods. WebMoney was mentioned the most and had
a 66.3 percent OAR. Yandex was the second most popular with 1,247 occurrences and a 55.3 percent OAR.
Liberty Reserve, a Costa Rica–based digital currency,
was mentioned the third most times. Liberty Reserve,
which was shut down by law enforcement agencies in
May 2013 for money laundering, was mentioned 702
40	

IEEE Security & Privacy

times and had a 26.3 percent OAR. Western Union
and PayPal were mentioned 669 times and 530 times,
respectively. E-gold—a digital gold currency operated
by Gold & Silver Reserve located in Florida—appeared
179 times and had a 64.2 percent OAR. E-gold was shut
down by the US government around 2008.
Most studies capture only a few months of data at a
time, which limits the assessment of preferred payment
types to what’s popular during that period. Even though
E-gold is no longer used, it’s still found in our sample
due to the fact that some posts were made when it was
in circulation. Nowadays, Bitcoin is the dominant anonymous online payment system.6 However, there were
only 6.5 million bitcoins in circulation among an estimated 10,000 users as of June 2011, compared to 12.5
million bitcoins and more than 6.5 million users today.7,8
In our dataset, Bitcoin was mentioned only 43 times in
total, and its OAR was significantly lower than average.

Persistent Advertisements
The marketplaces featured some persistent advertisements, which were placed as banner images using GIF
files or flashes. These ads weren’t posted by forum users
but by website administrators. The most common were
dump ads, shown in Figure 3a. These ads, both in English and Russian, usually had contact information—
either ICQ numbers or email addresses.
Black markets also advertised on other black markets
to attract more visitors. We found two ads for Forum2
and Forum1 in Forum4 and Forum11, respectively.
Recall that Forum11 was still running at the time of
May/June 2016

(a)

(b)

(c)

Figure 3. Persistent advertisements. (a) Dumps ads. The image on the bottom left says “The sale of fresh European CC [Credit Card].” (b) Spamming
and email account hacking ads. The Russian text on the left translates to “Spam mailings up to 1 billion a day!,” and the one on the right means
“Hacking mail without advance payments.” (c) Seal and hologram ads. The Russian text on the left translates to “Seal and stamp alterations with no
questions asked.” The text on the right means “Holograms and drawing text.”

writing, and our Forum11 data dates back to July 2007.
Based on the length of its lifetime, we suspect Forum11
has a reputation in this community and attracts new
markets to promote on it.

Discussion

Although this analysis provides an important overview
of the practices of cybercrime markets, it’s necessary
to recognize our data’s limitations. First, the forums in
this study were accessible during December 2005 to
July 2011 without using an anonymity network. Some
were even indexed by commercial search engines, such
as Google. Evidence suggests that more popular underground forums aren’t open to the public and require
vetting by known members to gain access.9 Second, the
forum data we collected comprises only posts made in
the forum threads, rather than PM exchanges between
users. Third, we don’t have users’ payment transaction data, which is important for understanding actual
money movement. This kind of data might be available
only from collaborations with financial sectors.
Despite these limitations, publicly accessible forums
provide an entry point in the underground cybercrime
marketplace, which many low-skilled hackers might use
to engage in illegal activity.1,4 The services available and
price points might differ from those of more hidden communities, although there is some evidence that a proportion of the vendors operating in this sample had solid
www.computer.org/security

reputations and engaged in transactions across multiple
forums to increase their prominence underground. As
such, this analysis demonstrates that sellers in these markets have some degree of complexity and sophistication,
even though the communities aren’t closed or vetted.

A

nalysis of our marketplace dataset led to several
key findings. First, the domain names and websites dedicated to black markets had shorter lifespans,
and their website servers migrated among multiple
countries in their lifetimes. Second, most goods sold
in these marketplaces included dumps, identity-related
documents and services, and attacking tools and services. Third, sellers and buyers had fewer contacts in
public threads than other users. Their posts triggered
fewer replies, and they were less likely to participate
in others’ threads. Fourth, there were more dump sellers than other kinds of sellers. Fifth, dump sellers did
not receive more feedback than other forms of sellers
in public threads. And finally, even though many pairs
of marketplaces didn’t share many users, most of the
shared users were sellers.

Acknowledgments
This research was supported in part by grants from Army
Research Office and Center for Cybersecurity and Digital Forensics at Arizona State University. The information
41

ECONOMICS OF CYBERSECURITY, PART 2

Table 5. Number of different payment methods in each forum.*
Name

WebMoney

Yandex

Liberty
Reserve

Western
Union

PayPal

E-gold

Bitcoin

Forum1

4 (4)

0 (0)

2 (2)

0

7 (7)

0

0

Forum2

45 (37)

5 (3)

26 (10)

30 (11)

4 (4)

0

0

Forum3

585 (174)

134 (36)

65 (11)

78 (15)

159 (39)

18 (3)

43 (6)

Forum4

456 (429)

92 (85)

47 (43)

27 (26)

24 (19)

2 (2)

0

Forum5

1,721 (965)

176 (148)

23 (20)

25 (21)

17 (16)

7 (6)

0

Forum6

218 (70)

177 (52)

6 (1)

71 (6)

3 (0)

2 (0)

0

Forum7

55 (34)

170 (3)

16 (13)

13 (9)

80 (59)

5 (3)

0

Forum8

645 (625)

42 (34)

440 (365)

353 (292)

124 (87)

5 (4)

0

Forum9

511 (436)

159 (142)

25 (22)

12 (10)

15 (13)

7 (0)

0

Forum10

312 (110)

50 (17)

11 (6)

16 (15)

40 (22)

132 (97)

0

Forum11

768 (605)

187 (132)

18 (14)

9 (7)

12 (11)

0

0

Forum12

385 (294)

55 (38)

23 (17)

35 (31)

45 (42)

1 (0)

0

5,705
(3783)

1,247 (690)

702 (524)

669 (443)

530 (319)

179 (115)

43 (6)

Total
Original
post–to–all
posts ratio
(percentage)

66.3

55.3

26.3

66.2

60.2

64.2

13.9

*Numbers in parentheses represent the number of times the original poster mentioned the payment method.

reported here does not reflect the position or the policy of the
funding agencies.

References
1.	 T.J. Holt and E. Lampke, “Exploring Stolen Data Markets
Online: Products and Market Forces,” Criminal Justice
Studies, vol. 23, no. 1, 2010, pp. 33–50.
2.	 Z. Zhao et al., “SocialImpact: Systematic Analysis of Underground Social Dynamics,” Proc. European Symp. Research in
Computer Security (ESORICS 12), 2012, pp. 877–894.
3.	 J. Franklin et al., “An Inquiry into the Nature and Causes of the
Wealth of Internet Miscreants,” Proc. ACM Conf. Computer
and Communications Security (CCS 07), 2007, pp. 375–388.
4.	 T.J. Holt, “Examining the Forces Shaping Cybercrime
Markets Online,” Social Science Computer Rev., vol. 31, no.
2, 2013, pp. 165–177.
5.	 M. Motoyama et al., “An Analysis of Underground
Forums,” Proc. ACM SIGCOMM Conf. Internet Measurement Conference (IMC 11), 2011, pp. 71–80.
6.	 V. Kostakis, and C. Giotitsas, “The (A)political Economy
of Bitcoin,” tripleC: Communication, Capitalism & Critique, vol. 12, no. 2, 2014, pp. 431–440.
7.	 S. Barber et al., “Bitter to Better—How to Make Bitcoin a
Better Currency,” Proc. Financial Cryptography and Data
Security, 2012, pp. 399–414.
8.	 F. Reid and M. Harrigan, “An Analysis of Anonymity in
42	

IEEE Security & Privacy

the Bitcoin System,” arXiv:1107.4524, 2013.
9.	 B. Stone-Gross et al., “The Underground Economy of
Spam: A Botmaster’s Perspective of Coordinating LargeScale Spam Campaigns,” Proc. USENIX Workshop on
Large-Scale Exploits and Emergent Threats (LEET 11),
2011, pp. 4–11.
Ziming Zhao is an assistant research professor in the

School of Computing, Informatics, and Decision Systems Engineering, Ira A. Fulton Schools of Engineering, Arizona State University. His research interests
include system and network security and cybercrime
analysis. Zhao received a PhD in computer science
from Arizona State University (ASU). Contact him at
zmzhao@asu.edu.

Mukund Sankaran is a junior Java developer at

ShareStream and was a student at ASU at the time
of this writing. His research interests include social
network analysis, text mining, and natural language
processing. Sankaran received an MS in computer science from ASU. Contact him at msankar2@asu.edu.

Gail-Joon Ahn is a professor in the School of Comput-

ing, Informatics, and Decision Systems Engineering, Ira A. Fulton Schools of Engineering and the
May/June 2016

Director of the Center for Cybersecurity and Digital
Forensics at ASU. His research has been supported
by the US National Science Foundation, US National
Security Agency, US Department of Defense, US
Department of Energy, Bank of America, Hewlett
Packard, Microsoft, and the Robert Wood Johnson
Foundation. Ahn received a PhD in information technology from George Mason University. He received
the US Department of Energy CAREER Award and
the Educator of the Year Award from the Federal Information Systems Security Educators Association. Contact him at gahn@asu.edu.
Thomas J. Holt is an associate professor in the School

of Criminal Justice at Michigan State University. His
research focuses on computer hacking, malware, and
the role of the Internet in facilitating all manner of
crime and deviance. His work has been published in
various journals including Crime and Delinquency,
Deviant Behavior, the Journal of Criminal Justice, and
Youth and Society. Contact him at holtt@msu.edu.

Yiming Jing is a senior software engineer at Samsung

Research America. His research interests include

access control models and mechanisms, security and
privacy in mobile computing, and secure software
engineering. Jing received a PhD from ASU and a BS
from Shanghai Jiao Tong University. Contact him at
ymjing@asu.edu.
Hongxin Hu is an assistant professor in the Division of

Computer Science, School of Computing, Clemson
University. His research interests include access control models and mechanisms, security and privacy in
social networks, security in cloud and mobile computing, network and system security, and secure software
engineering. He received a PhD in computer science
from ASU. Contact him at hongxinh@clemson.edu.

Selected CS articles and columns are also available for free
at http://ComputingNow.computer.org.

Keeping
YOU at the
Center
of Technology
myComputer, myCS,
Computing Now

What’s Trending?
The information you need
and only the information you need.
Industry intelligence delivered on your
terms, when and how you want it.
• myCS—delivers your publications
your way
• myComputer—customizable mobile
app delivering targeted information
specific to your specialty
• Computing Now—this award
winning website features industry
news and developments.
Learn something new.
Check out these resources today!

Stay relevant with the IEEE Computer Society

More at www.computer.org

www.computer.org/security

43

2015 48th Hawaii International Conference on System Sciences

Utilizing Network Science and Honeynets for Software Induced Cyber
Incident Analysis
Napoleon C. Paxton
U.S. Naval Research Laboratory
napoleon.paxton@nrl.navy.mil

Dae-il Jang
Arizona State University
daelsmail@gmail.com

Stephen Russell
U.S. Naval Research Laboratory
stephen.russell@nrl.navy.mil

Gail-Joon Ahn
Arizona State University
gahn@asu.edu

Ira S. Moskowitz
U.S. Naval Research Laboratory
ira.moskowitz@nrl.navy.mil

Paul Hyden
U.S. Naval Research Laboratory
paul.hyden@nrl.navy.mil

out at high speeds. In order to effectively understand
and defend against these attacks, it is necessary to
identify key situational attributes and actions quickly,
before the originators of the attack can cover their
tracks or attack other targets.
When dealing with attacks where malicious
software (malware) directly interacts with a victim
computer, current methods of cyber incident analysis
involve two major steps. Step one is to discover and
analyze the malware that was sent to the infected
system. This is also called the static step and is
typically a manual analysis. Step two is to run the
discovered malware in a closed simulated network
(sandbox) and evaluate its actions based on the
intelligence that was learned in step one. This is called
the dynamic step. In theory these two steps represent
the most effective method to conduct a detailed
analysis of the incident, if the analyst conducting the
static analysis step is a highly competent expert in
malware analysis. Unfortunately, modern malware
continues to evolve and become increasingly complex.
Because of this, a detailed static step analysis is likely
to take a significant amount of time for even the most
highly qualified analyst to complete [3]. Furthermore,
in the case of the dynamic step most sandbox analysis
systems have limited network simulation capabilities.
For instance, in order to completely simulate an
environment, the sandbox would need to be configured
to include every item and option in the network that
could be modified in any way [20]. This level of
customization is difficult to develop or operate and
thus unrealistic for any affordable simulation system.
Moreover, malware attacks are intrinsically driven by
situational performers (actors) and incorporating this
notion into the dynamic and static steps introduces
significant additional complexity into the assessment
process.
We believe an approach that can improve the
efficiency and effectiveness of analyzing cyber

Abstract
Increasing situational awareness and investigating the
cause of a software-induced cyber attack continues to
be one of the most difficult yet important endeavors
faced by network security professionals. Traditionally,
these forensic pursuits are carried out by manually
analyzing the malicious software agents at the heart of
the incident, and then observing their interactions in a
controlled environment. Both these steps are time
consuming and difficult to maintain due to the ever
changing nature of malicious software. In this paper
we introduce a network science based framework
which conducts incident analysis on a dataset by
constructing and analyzing relational communities.
Construction of these communities is based on the
connections of topological features formed when
actors communicate with each other. We evaluate our
framework using a network trace of the BlackEnergy
malware network, captured by our honeynet. We have
found that our approach is accurate, efficient, and
could prove as a viable alternative to the current status
quo.

1. Introduction
Today the importance of developing effective
methods to analyze and defend against cyber attacks is
no longer in doubt. Incidents such as recent data
breaches at Target retail stores and the PF Chang
restaurant chain as well as discovered and alleged
attacks against Nation states, bring worldwide attention
to the cyber attack problem [14, 9, 4]. This problem
has been growing exponentially despite constant
research geared towards reducing its impact. One of
the major issues causing this upward trend in attacks is
the dependence on outdated analysis systems [3].
Modern day attacks are often sophisticated and carried
1530-1605/15 $31.00 © 2015 IEEE
DOI 10.1109/HICSS.2015.619

5244

incidents should be able to identify the important
actors involved in the incident without requiring a
detailed internal description of the actor. Awareness of
actors’ roles and locations would reduce the time
necessary for manually analyzing complex malware
code. We also believe an approach that enhances the
effective static and dynamic steps needs to be able to
identify and track the transactions that take place
between actors. Beyond further characterizing attack
malware, transaction attribution would also reduce the
dependence on sandboxes for the discovery of
behavioral characteristics. Community-based analysis
from the multi-disciplinary field of network science
provides techniques that can satisfy these requirements.
Here actors and their interactions are modeled using
graph theory, where each actor is represented by a
graph vertex ܸ and each interaction between actors is
represented by a graph edge, ‫ܧ‬. Communities are then
extracted based on the context of the discovered
interactions [5]. One of the findings we present in this
paper shows that discovered community structures and
the relationships within those communities can
contribute to the understanding of the network as a
whole. This finding strengthens statements about the
benefits of community detection made in other fields,
such as biology and social networking [12, 16].
In this paper, we present and discuss our honeynetbased framework that captures network traces of cyber
incidents, identifies actors within the traced network,
and constructs communities based on the interactions
of the discovered actors. Our initial evaluation of the
framework is very encouraging. Distinct communities
were extracted from the data and the discovered
relationships within and outside of the communities
strongly suggest the role of the actor and the purpose
of the network.
The remainder of the paper is structured as follows.
In Section 2 we discuss related work in the area of
software-based cyber incident analysis, honeynet
technology, and network community detection using
network science methods. Section 3 discusses the
components of the honeynet-based framework. In
Section 4 we discuss the results of each module within
the framework, and Section 5 concludes the paper.

2.1. Related Work
In a recent survey on network-based botnet
detection methods by Garcia et al. [7], the authors took
an in-depth look at the most widely used and
researched botnet detection tools available. In this
review there was a discussion which highlighted the
fact that bot detection mechanisms have different
requirements than botnet detection mechanisms due to
the difference in detecting one machine as opposed to a
group of machines. Detecting a bot fits in the realm of
this paper since a bot is software that induces the cyber
incident.
Of these methods, "BotMiner" [9],
"BotSniffer" [10], "N-gram" [1], and "Tamed" [23],
were similar to our method based on their detection
approach. Our method is different from these and all
the other approaches found in this review because once
the malware is discovered using our system, it is
grouped into communities, which can then be analyzed
to determine relationships between actors located in the
same
community
and
throughout
multiple
communities. The methods presented in this survey
employ clustering techniques in their detection
algorithms. Clustering is conducted based on a metric
of distance and does not take into account relationships
[5].
In another recent review, which compared dynamic
malware analysis techniques, Egele et al. conducted a
study on methods that look to dynamically analyze
malware in an attempt to reduce the time gap between
discoveries of the malware to gaining intelligence from
it [4]. In this survey the authors acknowledge that
most forms of malware analysis still rely heavily on
manual static based analysis. They also discuss the
major forms of malware discovered on the Internet
today. The methods discussed in this work seek to
conduct an analysis of the malware without first
performing the manual static analysis step. They also
use clustering techniques and automated dynamic
analysis reports to describe observed actions. These
actions are then turned into behavioral profiles. Our
approach also focuses on behaviors, but instead of
using arbitrary or metric-based node clustering
techniques, we use node relationship based community
detection techniques which allows us to identify
relationships for a more fine grained and relational
analysis.
Two works which developed systems to detect and
analyze software induced malware networks are "In
Mining Botnet Behaviors on the Large-scale Web
Application Community" [6] and "Botnet Detection
Based on Traffic Behavior Analysis and Flow
Intervals" [24]. In this research the authors used
machine learning techniques to discover patterns
within the network that attempted to explain botnet

2. Background
In this section we discuss previous research that
focused on analyzing software induced incidents. We
also provide a background on important elements that
play a key role in our approach, such as honeynets,
network science based community detection, and the
dataset we collected and used for our evaluation of the
framework’s operation.

5245

behaviors. Our framework has the same goal of
identifying patterns, but machine learning techniques
suffer from their dependence on generating a training
set of data. Also, this type of analysis does not make
any connections between identified nodes of interest.
Our approach uses characteristics of the connections
between the nodes of interest to identify patterns.

biological, and social phenomena. It includes methods
and theories from a wide range of fields. The basis of
our approach, which is detecting the community
structure of graphs, is a graph theoretic approach that
fits into this area. A network is said to have community
structure if the nodes of the network can be grouped
into multiple sets of nodes, where the sets of nodes are
more connected internally than externally [13].
Community detection is different from node
clustering because community detection group nodes
based on context and not just distance [5]. This fact
becomes especially useful when considering node
overlap. Node overlap is when a node is a member of
two distinct communities at the same time [22]. By
investigating the context and the semantics of both
community memberships we can begin to understand
the purpose of the memberships. We can also begin to
understand the connections between the two
communities.

2.2. Honeynet Technology Overview
Honeynets are networks composed of machines that
are geared to attract and capture transactions of
malicious users [11]. If one machine is configured to
collect this data it is called a honeypot. This
technology has proven very useful in studying and
defending against malicious networks. In most cases a
general honeypot with a simple vulnerability will
receive many attack attempts within minutes. Virtually
any analysis tool or method can be plugged into the
honeynet in order to run analysis on the discovered
attacks. Honeynets can be configured in a variety of
ways, based on the desired level of interaction from the
malicious software. Simple implementations seek only
to capture traces of automated attacks which search for
vulnerabilities within systems on a subnet. These types
of honeynets are considered low interaction. Other
forms of honeynets allow the malware to connect to
locations outside of the network. These types of
honeynets are considered high interaction.
The
connections are normally limited so as not to allow the
malware to damage outside sources from the honeynet.
These types of implementations can become very
elaborate. It is possible to create a framework which is
an exact replica of a production network. Creating
such a honeynet would allow the system administrator
or researcher to investigate the effect a piece of
malware would have on the corresponding production
network. The goal of a successful honeynet is to
record data and discover patterns in malicious traffic,
without alerting the attacker, in order to discover a way
to render the attack useless. Researchers and security
professionals have used these methods to identify and
shutdown attacks from all over the world. For our
research we implement a high interaction honeynet in
order to discover enough information to track and
record all the interactions of the botnet. Recording this
information gives us details of the full botnet, which is
needed in order to verify the validity of our approach.

Figure 1: Three communities that overlap

There are several methods used to construct the
communities.
The most prevalent methods are
hierarchy based [21], modularity (null model) based
[18], information theory based [19], and clique based
[17]. Each model has its drawbacks and advantages.
In this paper we utilized the clique based method due
to its natural ability to discover overlaps within
communities.
The clique based method forms
communities by the percolation of fully connected
adjacent sub-graphs [17]. Sub-graphs are said to be
adjacent when they share k-1 nodes. The major
drawback to this approach is it is not considered the
most efficient community detection approach, but
recent tests show that it tested very well for networks
up to several million [17]. This is sufficient for our
initial tests, but we will explore optimizing our
algorithm in future work.

2.3. Network Science Based Community
Detection
Network Science is an inter-disciplinary field that
studies the network representations of physical,

5246

2.4. BlackEnergy Botnet Dataset
We chose the BlackEnergy 1.8 Botnet Tool Kit for
our malicious dataset analysis. The BlackEnergy Tool
Kit functions using HTTP as its means to communicate
with the command and control server. After a machine
is infected, it initiates a POST message to a PHP script.
This script is hosted on the command and control
server, logs all information from each infected
machine, and stores that content in a MySQL database.
Bots that are controlled using HTTP each have their
own separate connection channel to the command and
control. This is different from bots that are part of
IRC-administered botnets, which can view all other bot
commands and transactions if they are part the same
botnet channel. The dedicated communication channel
makes analysis of the entire botnet more difficult and
requires internal access of the command and control
server. To gain this level of access, we first installed
and executed the BlackEnergy toolkit on our honeynet,
using a Windows based machine on VMware as the
honeypot. Once an initial POST command was sent to
the command and control server, we were able to use
this information to masquerade as the command and
control server and capture communications sent to it
from other infected machines. Figure 2 shows the
initial POST after executing BlackEnergy and figure 3
shows a second infected machine sending its initial
POST to the command and control. In both figures the
bots send the initial message in red, which is the POST
request to stat.php. Stat.php is the php script that
collects messages from bots on the command and
control server. We also see the Host (anonymized
here), which is the command and control IP address.
The content length is also shown, which is the size of
the message and the build_ID is also displayed. The
build_ID is created when the bot is built and it consists
of the SMB hostname of the infected system as well as
the System Volume ID from the C:\ drive.

Figure 3: New Bot Connecting to Command and Control

3. Cyber Incident Analysis Framework
Our incident analysis framework is composed of
five modules which can each act as a standalone
method for malware analysis. In this particular
application we are conducting an analysis of a botnet
which is a network of computers that has been infected
by agents. This network is controlled by one or more
commanders, which are called botmasters or
bothearders. We chose a botnet as our first test dataset
because the important actors (Bots, Botnets, and
Command and Control Centers) are well defined and
network traffic concerning each actor can be detected
by our honeynet. These factors made it a good choice
for community detection.
Figure 4 shows the
framework.

3.1. Traffic and Log Collection Module
The traffic and log collection module is the entry
point to the framework. It aims to capture and monitor
network traffic at the edge of networks and at each
sensor of installed honeypots within the honeynet. This
module has two modes. It can capture live traffic from
a network in the form of packets by using the PCAP
library and it can load captured files stored on a file
system. Currently the types of stored traffic that can be
read with this module are PCAP, Netflow, Argus, and
Sebek. Other forms of log data can be formatted to be
included in the framework.
Collected data is
forwarded to the Traffic processing module.

Figure 2: Initial Connect to Command and Control

5247

Figure 4: Community Based Cyber Incident Analysis Framework

3.2. Traffic Processing Module
The Traffic processing module aims to pre-process
the traffic for flow correlation. The Traffic separator
module within the component separates the traffic into
10 minute time windows in order for us to observe
changes in behavior over time. The time window was
set at 10 minutes because it is the default time
programmed into the malware for connection intervals.
In the future we will modify the time window and
evaluate whether or not 10 minutes is the optimal value
for community detection. The packet parsing module
extracts header level information from the traffic such
as source IP (SrcIP), destination IP (DstIP), source
port, destination port, TCP/UDP payload size, source
to destination packet count and data size, destination to
source packet count and data size, and session interval.
And this module generates plain text and comma
separated value (CSV) files based on above
information. The Flow aggregation module generates
an input file for flow correlation.

3.3. Flow Correlation Module
The flow correlation module creates communities from
the normalized data inputted from the flow aggregation
module located in the traffic processing component.
We use a clique based method to generate
communities. In order to discover communities using
cliques, we first needed to identify the nodes and
edges. We modified the original k-clique percolation
algorithm [17] to perform our analysis. Instead of
identifying one entity to be a node, we added a
secondary node. Particularly, for our analysis each IP

address was equal to a "Primary" Node, and the
message size was equal to the "Secondary" Node. The
link
between
nodes
is
a
tuple
of
{Time,SrcIP,DstIP,MsgLen}. For the purpose of
constructing the communities, we do not consider
direction. Once the communities were formed we use
the tuple {SrcIP, DstIP} to add direction in order to
identify the role of each Primary Node. The purpose of
the Secondary Node is to identify all relevant
communications.
For instance, many botmaster
communications only include the botmaster and the
command and control node. By adding the message
size as a secondary node, we are able to separate each
meaningful communication into a community even if it
only contains two nodes. Figure 5 shows three
communities constructed using our method. The first
two communities are composed of a botmaster
connecting to the command and control with different
message lengths and the third community shows 2 bots
connected to a command and control using the same
message length. Since the message length is the same,
it becomes the node that connects the two bots into the
same community.

Figure 5: Three communities
5248

for each of the collection components. Because of this,
we will only discuss the results in terms of PCAP
traffic. After capturing and processing the data in the
Traffic and Log Collection Module and the Log
Processing Module respectively, our data was
analyzed by the Flow Correlation Module and full
PCAP data was sent to the Botmaster and C & C
Detection Module.
In the Flow Correlation Module, the component,
Botnet Community Graph Generator runs the
community detection algorithm to discover graphs of
communities within the data. Table 1 shows details of
the results.

The botnet community graph generator component
inside the flow correlation module produces a graph of
the communities within a 10 minute time period. This
time interval was set based on the default time interval
for bots to poll the command and control server. The
graph is then passed to the botnet behavior monitoring
module.

3.4. Botnet Behavior Monitoring Module
In the botnet behavior monitoring module we use a
custom python script to analyze the current community
graph and then compare it to previous graphs to
determine comparisons that have occurred over time.
Here we can discover the evolution of nodes and fluid
relationships within the same community and across
multiple communities.

Table 1: Community Graph Metric Values

Metric
Analysis Period (hrs)
Community Graphs
Communities

3.5. Bot Master and C&C Detection Module
The Bot master and C&C detection module is
where the results from the other modules are combined
and correlated to produce intelligence.
The botnet behavior modeling results component
gives a display of what has changed over time within
the community graphs.
The packet parsing results module captures and
displays parsing results from each data source that was
used in the analysis. This module was included to
provide the analyst with a lens into the lower level data
in case there is a question about the validity of the
monitoring results. For instance, the full packet from
PCAP data is available here. By including the payload
of the monitoring results, which is based on flows, we
add context to the analysis by being able to drill down
into the payload content. The analyst can also
manipulate the data before correlation is facilitated.
The correlation module adjusts the output of the
behavior monitoring results depending on what has
changed in the packet parsing results. If no change has
been made the correlation results will be identical to
the input for the behavior monitoring results. If a
change has been made, the results will change
accordingly.
An example change would be an
inaccuracy that the analyst notices. The significance of
this module is, if there are minor issues with the
analysis they can be corrected here instead of rendering
the entire analysis useless.

Value
168
1008
3120

As shown in table 1, the analysis period was
approximately 168 hours, which is also 7 days of
analysis. Since the Flow Correlation Module generates
community graphs in 10 minute increments, 1008
community graphs were generated. Within those
graphs we observed 3120 communities.
The Botnet Community Graph Module then
analyzes the details of the communities in each graph
using the Analyze Community Graph Component.
Table 2 shows the details of one of the community
graphs. Communities and each node within every
community are delineated using a period. Table 2
shows the details of community graph 128. There are
4 communities within the 10 minute community graph.
Communities 128.1, 128.2, and 128.4 each have 3
nodes within it. Community 128.3 has 24 nodes within
it.
Table 2: Community Graph 168

Community
128.1

Nodes
3

128.2

3

128.3

24

128.4

3

4. Framework Evaluation Results
Our honeynet captured live PCAP traffic to and
from the command and control servers. In our initial
experiment, connections between nodes were identical

5249

Overlap
{128.1.1:128.2.1;128.4.1},
{128.1.2:128.2.2;128.3.2;128
.4.2}
{128.2.1:128.1.1;128.4.1},
{128.2.2:128.1.2;128.3.2;128
.4.2}
{128.3.2:128.1.2;128.2.2;128
.4.2}
{128.4.1:128.1.1;128.4.1},
{128.4.2:128.1.2;128.3.2;128
.2.2}

the primary nodes (IPs) as shown in figure 5. The
results showed that the 15 most active actors only sent
4 message types of sizes (188, 228, 300, 48). The
varying activity of the actors highlight their roles. IP
length size 228 was only sent by actor (192.168.101.4)
and size 300 was only sent by actor (192.168.101.5).
This suggests a lack of coordination, which leads us to
believe these two actors are botmasters. IP length size
188 was used by the other 13 actors equally. This
suggests the activity was coordinated which leads us to
believe these actors are bots. Length size 48 was
correlated with each of the actors, but actors
(192.168.101.5 and 192.168.101.6) had uneven
distributions while the other 13 actors had an equal
amount of data sent. This is further evidence that the 2
uncoordinated actors are botmasters and the 13
coordinated actors are bots.
To evaluate the ability to discover the overall
purpose of the botnet using our framework we
investigate the content of the overlap node messages.
Message 48 was the basic “GET // HTTP” message
sent when a node refreshes its command and control
administration information. Message 228 and message
300 are Distributed Denial of Service commands being
sent to the command and control server. When the
bots check back with the server they will get the
command to attack a target. These four overlap nodes
represent ~85% of the data the dataset. By correlating
these nodes we can reasonably assume this botnet is
being used specifically for DDoS attacks.
Highly overlapping nodes, that were not command
and control nodes, were considered to be bots. This is
consistent with previous research which discovered
that flash crowds of a high percentage represented a
coordinated event caused by bots [9, 10]. Figure 7
shows a screen shot of our web-based community
detection analysis tool with the roles assigned to each
node.

The overlap of communities 128.1, 128.2, and 128.4
show that they are closely related. For instance, node
128.1.1 is the same node as 128.2.1 and node 128.4.1.
The second component within the Botnet Community
Graph Module is the Compare Botnet Community
Graph Component. In this component the current
incoming community graph is compared with all the
previous community graphs. The overall node overlap
is very significant within the botnet (84%). This was
an expected finding since most attacks and other
communications between bots and the command and
control server are coordinated. Previous research
found that most connections on the Internet have a very
low overlap rate amongst nodes [22]. Since we have
discovered that botnets have a high overlap rate, our
finding could prove to be significant if we can use the
presence of this high overlap as a detection tool. We
will explore this in future research.

Figure 6: G-test of top 15 actors based on aggregate
message sizes

Our Botmaster and C&C Detection Module
attempts to discover the role of each node within the
communities. In the Botnet Behavior Monitoring
Results Component, we find relationships in the flow
data that was collected. Each node is grouped based on
overlap. We then use the packet payloads within the
Packet Parsing Results Component to discover the
relationships between overlapping nodes.
To evaluate the significance of community overlap
we conduct a g-test on the 15 most active actors in the
botnet that sent messages to a command and control
server. A g-test is a measure of fitness to a distribution
of data. We use it to discover correlations between
actors and the overlap nodes. In our test active actors
refer to aggregated IP length sizes. Figure 6 displays
the g-test. Each IP length is an overlap node since the
IP length is used as the secondary node that connects

6. Conclusion
In this paper we introduced a cyber incident
analysis framework which is based on the detection of
communities within discovered attack data. This
framework does not need to perform a time consuming
manual analysis step or a closed system dynamic
analysis step to identify intelligence from the data.
Instead, all that is needed is high level identification
data and knowledge of communications between the
identified actors. Correlations between the overlap
nodes provided intelligence about the actors within the
malicious dataset as well as the overall intent of the
botnet. Coordinated activity suggested the presence of
bots within the network, and a high volume of

5250

Figure 7: Screen shot of web-based analysis tool

uncoordinated activity, but membership within the
community suggested the presence of botmasters.
These correlations also revealed a high overlap
percentage within the botnet, which is a significant
contrast with normal Internet traffic. Since all botnets
are defined by their coordinated activity, we hope to
use this trait as an identifiable metric for a general
community detection algorithm for botnets. Future
revisions of our methods aim to detect botnets without
initiating contact.
Cyber incident analysis in general includes the
gamut of cyber attacks conducted on a computer
network. One thing that all cyber incidents have in
common is unwanted activity on computer networks.
Community detection provides a way to identify
patterns in network traffic based on changes, so we
believe we can modify our techniques to analyze other
datasets besides botnets. For example, when malware
is installed on a system, processes are created, registry
entries are added or changed, and files are also added
or changed. Currently we are investigating using these
changes to files, processes, and registry entries as
nodes and the similarities between them as links. If
successful, we believe our approach will greatly
improve the current process of incident analysis.

[1] Abou-Assaleh, T., Cerone, N, Keselj, V, and Sweidan, R.,
"N-gram-based Detection of New Malicious Code.", In
Proceedings of the 24th Annual International Computer
Software and Applications Conference (COMPSAC 2004),
Hong Kong, 2004
[2]
Codenomicon,
"The
Heartbleed
http://www.heartbleed.com, April, 2014

Bug",

[3] Dittrich, D., "So you want to take over a botnet", In
Proceedings of 5th USENIX conference on Large-Scale
Exploits and Emergent Threats, USENIX, 2012
[4] Egele, Manuel, Scholte, Theodoor, Kirda, Engin, and
Kruegel, Christopher, "A Survey on Automated Dynamic
Malware Analysis Techniques and Tools, ACM Computing
Surveys, Vol. 44, No. 2, 2012
[5] Fortunato, S., "Community detection in graphs", Physics
Reports, 2010
[6] Garant, Daniel and Lu, Wei, "Mining Botnet Behaviors
on the Large-Scale Web Application Community", In
Proceedings of 27th International Conference on Advanced
Information Networking and Applications Workshops
(WAINA), IEEE, 2013

7. References

5251

[7] Garcia, S., Zunino, A., and Campo, M., "Survey on
network-based botnet detection methods", Security and
Communication Networks, May 2014

[17] Palla, Gergly, Derenyi, Imre, Farkas, Illes, and Vicsek,
Tamas, "Uncovering the overlapping community structure of
complex networks in nature and society", Nature, June 2005

[8] Geers, K., Kindlund, D., Moran, N., and Rachwald, R.,
"World War C: Understanding Nation-State Motives Behind
Today's
Advanced
Cyber
Attacks",
http://www.fireeye.com/resources/pdfs/fireeye-wwcreport.pdf, 2013

[18] Perry, Patrick and Wolfe, Patrick, "Null Models for
Network
Data",
Available
at
http://arxiv.org/abs/1201.5871v1, 2012
[19] Rosvall, Martin and Bergstrom, Carl, T., "An
information-theoretic framework for resolving community
structure in complex networks", Proceedings of the National
Academy of Sciences of the United States of America, 2007

[9] Guofei, G., Perdisci, R., Zhang, Junjie, and Lee, Wenke,
"BotMiner: Clustering Analysis of Network Traffic for
Protocol-and Structure-Independent Botnet Detection,
USENIX, 2008

[20] Rossow, C., Dietrich, C., J., Bos, H., Cavallaro, L.,
Steen, M., Freiling, Felix, C., and Pohlmann, N., "Sandnet:
Network Traffic Analysis of Malicious Software", ACM,
2011

[10] Guofei, Gu, Zhang, Junjie, and Lee, Wenke, "Botsniffer:
Detecting botnet command and control channles in network
traffic.", In Proceedings of the 15th Annual Network and
Distributed System Security Symposium, NDSS, 2008

[21] Wang, Jianxin, Li, Min, Chen, Jianer, and Pan, Yi, "A
Fast Hierarchical Clustering Algorithm for Functional
Modules Discovery in Protein Interaction Networks,
Computational Biology and Bioinformatics, IEEE/ACM
Transactions, 2011

[11] Honeynet Project, "Know Your Enemy:
GenII
Honeynets", http://old.honeynet.org/papers/gen2/, 2005
[12] Jia, Y., Garland, M., and Hart, J.C. "Social Network
Clustering and Visualization using Hierarchical Edge
Bundles", Computer Graphics Forum, December 2011

[22] Xie, J., Kelley, S., and Szymanski, B., "Overlapping
community detection in networks: the state of the art and
comparative study. In Social and Information Networks,
ACM, 2012

[13] Lancichinetti, Andrea and Fortunato, Santo,
"Community detection algorithms: A comparative analysis",
Phys. Rev. E 80, 056117, Novermber 2009

[23] Yen, Ting-Fang and Reiter, Michael, K., "Traffic
Aggregation for Malware Detection", Detection of Intrusions
and Malware, and Vulnerability Assessment Lecture Notes in
Computer Science, Volume 5137, 2008

[14] Krebs, B., "The Target Breach, By the Numbers",
http://krebsonsecurity.com/2014/05/the-target-breach-by-thenumbers/, May 14, 2014

[24] Zhao, David, Traore, Issa, Sayed, Bassam, Lu, Wei,
Saad, Sherif, Ghorbani, Ali, and Garant, Dan, "Botnet
detection based on traffic behavior analysis and flow
intervals", 27th IFIP International Information Security
Conference, Computers and Security, Volume 39, Part A,
November 2013

[15] Krebs, B., "P.F. Chang's Breach Likely Began in Sept.
2013",
http://krebsonsecurity.com/2014/06/p-f-changsbreach-likely-began-in-sept-2013/, June 14, 2014
[16] Leydesdorff, L. and Ahrweiler, P., "In Search of a
Network Theory of Innovations: Relations, Positions, and
Perspectives", Journal of the American Society for
Information Science and Technology (JASIST), 2013

5252

Federated Access Management for Collaborative
Network Environments: Framework and Case Study
Carlos E. Rubio-Medrano, Ziming Zhao, Adam Doupé and Gail-Joon Ahn
The Laboratory of Secure Engineering for Future Computing (SEFCOM)
Arizona State University
Tempe, AZ, USA

{crubiome, zmzhao, doupe, gahn}@asu.edu

ABSTRACT
With the advent of various collaborative sharing mechanisms
such as Grids, P2P and Clouds, organizations including private and public sectors have recognized the benefits of being
involved in inter-organizational, multi-disciplinary, and collaborative projects that may require diverse resources to be
shared among participants. In particular, an environment
that often makes use of a group of high-performance network facilities would involve large-scale collaborative projects and tremendously seek a robust and flexible access
control for allowing collaborators to leverage and consume
resources, e.g., computing power and bandwidth. In this
paper, we propose a federated access management scheme
that leverages the notion of attributes. Our approach allows
resource-sharing organizations to provide distributed provisioning (publication, location, communication, and evaluation) of both attributes and policies for federated access
management purposes. Also, we provide a proof-of-concept
implementation that leverages distributed hash tables (DHT)
to traverse chains of attributes and effectively handle the
federated access management requirements devised for interorganizational resource sharing and collaborations.

1.

INTRODUCTION

Traditionally, collaborative information sharing heavily
relies on client-server or email-based systems. By recognizing the inherent deficiencies such as a central point of
failure and scalability issues, several alternatives have been
proposed to support collaborative sharing of resources, including Grid computing, Peer-to-Peer (P2P) networking [11]
and Cloud computing [27]. Given all the diverse contexts of
collaboration, achieving effective access control is a critical requirement. The sharing of sensitive information and
resources is necessarily to be highly controlled by defining
what is shared, who and under which conditions is allowed to
share. In particular, users without pre-existing relationships
may try to collaborate and request the information. It is required for a resource provider to be able to cope with a large
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SACMAT’15, June1–3, 2015, Vienna, Austria.
c 2015 ACM ISBN 978-1-4503-3556-0/15/06 ...$15.00.
Copyright 
DOI: http://dx.doi.org/10.1145/2752952.2752977.

number of collaborators and guarantee the information and
resources be released only to trusted collaborators within
the community. In addition, resources are constructed with
various types and domain policies, and each collaborating
party may enforce security policies in their systems with
different degrees of assurance. Therefore, building systematic mechanisms for sharing resources across collaborative
network environments is indeed an important challenge.
Furthermore, organizations including private and public
sectors have recognized the benefits of being involved with
inter-organizational, multi-disciplinary collaborative projects
that may require diverse resources shared among participants, e.g., data, computation time, storage, etc. In particular, an environment that often makes use of a group of highperformance network facilities would involve large-scale collaborative projects and tremendously seek a robust and flexible access control for allowing collaborators to leverage and
consume resources. For example, under the US Department
of Energy (DoE), numerous research laboratories and scientists have collaborated and performed their experiments
demanding specific network bandwidth and designated computing resources from each other. They even exchanged
data and resources with other foreign researchers, which lead
them to utilize high-performance network environments such
as ESnet [29], GÉANT [7], and NORDUnet [21]. Despite the
necessary administrative tasks such as resource scheduling
and provisioning, there is a need to properly mediate the
way such resources are to be safely shared in the context of
collaborations. Because most of these providers depict their
own in-house authentication and authorization services, a
well-defined, inter-organizational and implementation-independent approach is needed. With this in mind, this paper presents our approach to address the aforementioned
challenges by leveraging the concept of attributes: observable properties that are exhibited by access control entities,
e.g., users and protected resources, that become relevant under a given security context [19], focused on DoE networks
and their collaborators’ networks. Using attributes as an
underlying framework, we propose an approach based on
the concept of a federation between participant organizations, allowing them to provision: specify, publish, locate,
and communicate attributes for federated access management purposes in a distributed way, thus allowing for the
specification and automated evaluation of both local (intradomain) and federated (inter-domain) policies. With this in
mind, this paper makes the following contributions:
• We formulate the main components involved in federated
access management. We show how attributes in the lo-

cal context can be leveraged in a federated context such
that access permissions for inter-organizational resource
sharing can be properly granted.
• We also provide a well-defined description of attributes,
which includes the use of data types, standardized names,
and run-time values, so that participants can unambiguously use those to define inter-organizational attributes
and policies for federated access management purposes.
• We propose an attribute generation approach by means of
a set of so-called attribute derivation rules (AD-Rules).
Moreover, we also introduce attribute derivation graphs
(AD-Graphs) that allow to compose AD-rules.
• We provide an initial step toward automated attribute
discovery based on distributed hash tables (DHT) [28],
which allows for efficient discovery and retrieval of attributes within a federated and distributed context. In
addition, we provide a proof-of-concept implementation
of our attribute provisioning scheme, including an evaluation approach that shows the feasibility of our approach
for real-life implementations.
This paper is organized as follows: we start by articulating
problem statements and technical challenges with respect to
federated access management in Section 2. Then, we describe our approach in Section 3 followed by the proof-ofconcept implementation and evaluation results in Section 4,
which shows the practicability of our approach for supporting real-world collaborations among the DoE-affiliated highperformance network facilities. We overview the related
work in Section 5 and discuss some relevant topics related to
our approach as well as matters for future work in Section 6.
Finally, Section 7 provides concluding remarks.

2.

BACKGROUND

As previously mentioned, DoE-affiliated high-performance
network facilities have identified the need to provide automated means for resource sharing between different administrative (and security) domains. As an example, the
Open Grid Forum [9] introduced a multi-organizational effort called the network services interface (NSI) [23] that is
composed of a set of well-defined protocols that allow participants to collaborate on research endeavors by implementing
inter-organizational services in an automated way. The protocol devised for a given NSI service is implemented by socalled network service agents (NSA) which are expected to
support all service-related tasks within the context of a given
administrative domain. Fig. 1 shows an example depicting a
data transfer between two hosts that are located within the
administrative boundaries of two different organizations and
whose networking path involves the participation of a third
network serving as a bridge. In this example, each participating network implements the protocol devised for the NSI
connection service by means of a dedicated NSA. Following
such a protocol, a connection request R is first serviced by
the local NSA where R originates (NSA1 in Fig. 1). On each
network, the local NSA is in charge of reserving local ports
and bandwidth to create a connection within its network
boundaries. NSA1 is also in charge of contacting the other
NSAs involved in serving R (NSA2 and NSA3 ) so that they
can make reservations within their inner networks. In addition, all involved NSAs must handle network connections

Figure 1: An NSI inter-domain data transfer: An end-user
presents credentials to the software agent labeled as NSA1 ,
requesting for data stored in a host under the ESnet domain
to be transferred to a host located under the NORDUnet
domain, which is in turn managed by the agent known as
NSA3 . The GÉANT domain (managed by NSA2 ) serves as
a bridge for the connection purpose.
between independent networks by physically interconnecting any relevant service termination points (STPs), which
are abstract (high-level) representations of actual network
ports and are labeled from A to F in Fig. 1. Once the connection path between the source and destination hosts is
completed, the requested data transfer takes place.
In this collaborative setting within DoE-affiliated highperformance network facilities, we articulate the following
the federated access management requirements that need to
be accommodated:
1. Participating organizations should be allowed to define
its own set of federated access management policies governing the way a given service, e.g., the aforementioned
connection service, is provided in response to both local
and external requests. As an example, ESnet may want
to give priority over local resources to requests originated
within its local domain.
2. Participating organizations may also agree on a set of
inter-domain federated access management policies governing a subset of service interactions between them. As
an example, ESnet and GÉANT may agree on a policy
allowing for a collaborative project between both organizations to be guaranteed with high quality of service by
reserving sufficient bandwidth for data transfers.
3. Participating organizations may implement their own inhouse federated access management systems, which may
in turn handle their own set of local credentials and possibly their own set of locally-relevant attributes. This may
potentially result in problems such as attribute incompatibility, or different attributes being assigned to the same
access control entity by different domains, e.g., users getting credentials issued by each service in response to their
access request, possibly result in a large set of credentials
to be handled. However, organizations may not favor a
complete replacement of their current authentication and
access control modules, as such an effort may involve considerable financial and organizational effort. As an example, ESnet may find it difficult to replace the current set
of locally-issued credentials for the more than 40 research
institutions currently being served by the network [29].
4. Every access control entity, e.g., end-users and protected
resources, involved in serving a given access request is
expected to provide a set of security-relevant properties,
e.g., user credentials or resource descriptors, which may

have in turn been assigned either by its local security
domain or by an external one, in such a way that proper
policy evaluation based on such properties can take place.
If a given entity fails to show those properties, even when
they may have been legitimately assigned beforehand, the
evaluation of a relevant access control policy may fail thus
causing legitimate access to be denied as a result. In
practice, such properties are commonly assumed to exist
at policy evaluation time, either locally or remotely, e.g.,
stored in a dedicated centralized database. In addition,
security-relevant properties may be in turn derived by
processing other related properties. As an example, user
credentials may be used to obtain the set of collaborative
projects the user is involved in, without requiring the user
to explicitly enumerate them, granting access only to the
resources those projects are entitled to. However, existing
infrastructures are not capable of seamlessly locating and
transforming security properties in a distributed setting
such as the one depicted in Fig. 1, which is composed of
several independently-managed security domains.
5. Finally, existing federated approaches for security, e.g.,
OpenID [26] or Shibboleth [18], are focused on authentication: support for authorization is limited and is mostly
left for third parties to implement from scratch, e.g., attribute and policy definition, discovery, and evaluation.
Consider the example of the three participant organizations on the data transfer requests depicted in Fig. 1. Each
organization agrees on an inter-organizational policy P 1 that
allows for data transfers between participants, e.g., from
STPs A to F, if all of the following conditions are met: first,
the requester is a member of a collaborative group labeled
as G. Second, the size of the data to be transferred is less
than or equal to 10 Tb. Third, the available bandwidth on
each network is higher than or equal to 1 Gbit/s.

3.

APPROACH

A well-defined approach for the specification and provisioning of both policies and security-relevant properties (attributes) is critical to enable inter-organizational resource
collaboration—specifically an approach that goes beyond
credential-sharing by including heterogeneous attributes obtained from different federated access management entities,
which may have been assigned by different security domains.
As depicted in a recent report by the National Institute for
Standards and Technology (NIST) [19], proper provisioning mechanisms may become a crucial component for the
successful development of new technologies and new infrastructures based on attributes. Inspired by recent successful approaches for federated authentication, we propose a
federated and distributed solution for the specification, location, generation, and communication of both attributes
and policies for federated access management purposes that
is intended to support automated resource sharing and the
establishment of collaborative projects among independent
organizations, each possibly implementing their own security domain as well as their own dedicated federated access management infrastructure. A graphical depiction of
our approach is shown in Fig. 2: a locally-defined attribute
a 1 belonging to a given user is transformed into a series of
federation-recognized attributes (a 2 , a 3 , a 4 ) that are in turn
provided by other organizations engaged in a federation and
may be used for access control decisions.

a4

a1
a2

a3

Figure 2: A federated access management framework: the
local attribute a 1 is transformed into the federated attributes labeled as a 2 , a 3 and a 4 by leveraging attribute
derivation rules (AD-Rules) implemented by remote peers.
In order to participate in our proposed federation, participating organizations under DoE-affiliated high-performance
network facilities must fulfill the following:
1. Attribute identification: Participating organizations are
to identify security-relevant properties within their local
domains that may serve as local attributes for federated
access management purposes. As an example, in Fig. 1,
ESnet should identify any relevant metadata belonging
to the data to be transferred that can be used to obtain
the properties that are relevant under policy P 1 , e.g., its
size in bytes.
2. Attribute mapping: Participants must map local attributes onto a set of publicly-known federated attributes to
be used in the context of an inter-domain collaboration.
Following our running example, a standard definition of
an attribute depicting the size of a given chunk of data,
e.g. a convention name, size unit, etc., would allow the
specification and enforcement of policies across organizational domains. Because participant organizations may
in turn have their own in-house definitions for local attributes, e.g., names, data ranges, etc., a consensual interorganizational definition of federated attributes is needed.
With this in mind, existing approaches based on ontological representations such as the one proposed by Paci,
et al. [24], may be utilized to mitigate the existence of
different attribute definition schemes, also known as attribute heterogeneity. Due to the nature of DoE-affiliated
network facilities, we assume such a common knowledge
base on attributes has been established beforehand.
3. Attribute discovery: Participants should allow organizational peers to leverage the federated attributes they provide by means of a discovery service. Following our running example, ESnet and GÉANT should be able to locate each other’s attributes when constructing an interdomain policy for shared connections.
4. Federated access management administration: Organizations should implement a proper administrative model
for creating, updating, and removing both local as well
as federated attributes and federated access management

ADR

policies that restrict access to protected resources within
collaborative projects.
5. Policy conflict resolution: Finally, participants should be
able to detect and resolve conflicts when constructing federated access management policies, e.g., contradictory or
redundant rules, etc. As an example, let’s assume the
ESnet domain also provides a local policy P 2 that allows
for intra-domain transfers to take place, e.g., from STPs
A to B in Fig. 1, if the requesting end-user is a member
of a certain local group and the data to be transferred
has not been obtained from a particular server storing
sensitive data located within the network scope. In such
a setting, the inter-organizational policy P 1 depicted in
Section 2 may be in conflict with P 2 if the data to be
transferred comes from such a data-sensitive server, as
P 1 may authorize the transfer but P 2 may deny it.
With respect to the evaluation of federated access management policies, participants are responsible for the following:
1. Policy retrieval : Upon receiving a given federated access
management request R, participants should retrieve the
set L containing local policies relevant to R. Following
our running example, ESnet should retrieve the P 2 policy
regarding data transfers originating in its local domain.
2. Attribute provision: Participants should provision any local and federated attributes as specified in the policies
contained in L. To enable this provisioning, participants
are to make their federated attributes available for other
peers to provision upon request. In addition, participants should make (allowable) attribute transformations
available to their peers. Following our running example, GÉANT transforms the credentials presented by an
end-user in the ESnet domain into an attribute depicting
membership to the federated collaborative project G that
is required in the inter-organizational policy P 1 .
3. Policy dispatch: Participants should dispatch policy evaluation requests for relevant federated policies I that are
relevant to R. Conversely, participants should evaluate
and provide results for any policy evaluation requests
they receive as part of a request evaluation process initiated by a federated peer. Back to our running example,
participant networks should retrieve all attributes relative to a connection request that happen to be under the
scope of their local security domain and should dispatch
both attribute and policy evaluation requests, e.g., P 1 ,
to the other networks involved in the construction of the
network path.
4. Results aggregation: Finally, the policy decisions for both
sets L and I should be derived and combined to produce
a final decision for the request R, which is to be communicated to the requesting entity, e.g., the end-user under
the ESnet domain in Fig. 1.

3.1 Model Description
We start the discussion of our model for federated access
management by defining the following components:
• actors are end-users (i.e. human agents) or subjects
(i.e. computer processes) acting on behalf of users;
• targets are the protected resources within a security
domain;

Permissions
Federated
Attributes

AC
Entities

AA

PA

Operators

Targets

ADR
Local
Attributes

Attributes

Figure 3: A model for federated access management: attributes are related to entities, e.g., end-users and protected
resources, by means of the attribute assignment (AA) relation. Attributes (both local and federated ) may be transformed into federated attributes by means of AD-Rules
(ADR). Permissions are related to attributes by means of
the permission assignment (PA) relation.

• context is the running (executing) environment, e.g.
operating system, supporting platform, etc., where a
given request is issued and/or served.
Fig. 3 shows a visual representation of our model: attributes are related to access control entities by means of
the attribute assignment (AA) relation, allowing each entity
to exhibit many different attributes and a single attribute to
be potentially exhibited by more than one entity. Federated
attributes are publicly-known attributes that may be relevant in the context of a given collaboration project. Local attributes are related to federated attributes through attribute
derivation rules (AD-Rules), which are shown as directed arrows in a dotted line in Fig. 3. The precise definition of such
AD-Rules, e.g., how local attributes are ultimately related
to federated ones, is defined by peers within the context of
a given collaboration. As we will discuss in Section 3.4, ADRules can be organized into a graph-like structure known as
an attribute derivation graph (AD-Graph), which provides a
representation of how attributes are related to permissions,
which are in turn related to federated attributes by means
of the permission assignment (PA) relation. Permissions are
depicted as a combination of a protected source (target) and
an operation that can be performed on it. A given attribute
may be related to one or more permissions, and a given permission may be related to one or more attributes.
A description of our proposed approach is shown in Fig.
4. The basic components are actors (ACT), targets (TAR),
and context (CON), which together construct the set E of
access control entities. Moreover, we also consider the sets
operations (OPER) and permissions (P). We define the sets
names (N) and values (V), which are used for defining the
sets of attributes (A) and federated attributes (F). The relationships between the elements of our model are described by
defining the attribute assignment (AA) and permission assignment (PA) relations, as well as our proposed AD-Rules.
The definition of AD-Graphs is based on the concepts of
graph theory and the definition of AD-Rules. The access
control decision process is modeled by functions provisionedAttributes, expectedAttributes, relatedPermissions, and checkAccess. Function provisionedAttributes calculates the set of
attributes that can be provisioned from a given AD-Graph

based on the local and federated attributes initially exhibited by a set of access control entities. Function expectedAttributes returns the set of attributes that are related to a
given permission, by inspecting the PA relation. The mirror
function relatedPermissions returns the set of all permissions that are associated in the PA relation with a given
attribute. Finally, function checkAccess implements the authorization checking functionality by first calculating the set
of attributes provisioned by the entities in a given access
control request and comparing it with the set of attributes
that are related to the requested permission, which is only
granted if the set of provisioned attributes (obtained from
the provisionedAttributes function) is a subset of the set of
attributes related to such permission, which is obtained from
the expectedAttributes function.

3.2 Attributes
We define attributes as an abstraction of security-relevant
properties that are exhibited by access control entities, namely, actors, targets, policies, and any applicable context. Their
physical nature, e.g., if the attribute represents a file’s metadata or an end-user credential, and the way those attributes
are collected from the access control entities remain dependent on each organizational domain.
As shown in Fig. 4, we define attributes to have the following three components: (1) a data type, which restricts
the nature and the possible range of values defined for the
attribute, (2) a name, which is later used for defining ADRules on them and is defined in the context of a given
inter-organizational setting, and (3) a value, which is used
when evaluating such AD-Rules. Examples of attributes
include: <Double, data.size, 100.0>, <String, data.source,
“server.esnet”>, and <Date, system.date, “10 -10 -2015 ”>.

3.3 Federated Attributes
Federated attributes are obtained by processing local attributes from access control entities under a given organizational domain. Such processing is to be modeled through the
AD-Rules, thus allowing federated attributes to be related
to access rights (permissions).
As an example, AD-Rules may provide functionality intended to validate a given local attribute by inspecting its
value component and producing a proper federated attribute
as a result. Thus, a validated federated attribute ensures
that a given collaboration state remains secure.
As described in Section 3.1, permissions can be assigned
to federated attributes, which then serve as a layer of association between local attributes and permissions defined in
another organizational domain for collaborative purposes.
Such a layer helps identify the local attributes that may be
involved in granting a given inter-domain permission, as well
as the set of constraints represented by AD-Rules that may
be involved in such a process. Moreover, our approach allows for AD-Rules to take federated attributes as an input or
may also take both local as well as federated ones as an input to produce federated attributes as a result, as depicted
in Fig. 3, thus allowing for expressing richer inter-domain
policies based on processing already existing federated attributes.

• ACT, the set of actors.
• TAR, the set of targets.
• CON, the set of context instances.
• OPER, the set of operations.
• P ⊆ TAR × OPER, the set of permissions.
• E = ACT ∪ TAR ∪ CON, the set of access control entities.
• N, the set of names.
• V, the set of values.
• T, the set of data types.
• A = { a | a = <type, name, value>where type ∈ T, name
∈ N, value ∈ V, the set of attributes.
• F ⊆ A, the set of federated attributes.
• AA ⊆ A × E, the attribute assignment relation mapping
attributes with a given access control entity.
• PA ⊆ P × A, the permission assignment relation mapping
permissions and attributes.
• ADR = { r | r: 2A → 2F }, the set of attribute derivation rules mapping sets of attributes to sets of federated
attributes.
• ADG, the set of directed, weakly connected, and possibly
cyclic attribute derivation graphs. A graph g = <NODES,
ARCS>∈ ADG if NODES ⊆ 2A and ARCS ⊆ ADR. We
say (n 1 , arc , n 2 ) ∈ g if n 1 , n 2 ∈ NODES and arc ∈ ARCS
and n 1 ⊆ domain(arc ) and n 2 ⊆ codomain(arc ).
• provisionedAttributes: 2E × ADG → 2A , a function mapping a set of entities E ′⊆ E with the set of attributes that
the entities in E ′can provision from a given ADG g. An
attribute f is said to be provisioned by an entity e ∈ E ′if
there exists a set of attributes A′= { a | a ∈ A, e ∈ E ′, (a ,
e) ∈ AA } ⊆ A and a set of paths P = {p | p = x 0 , x 1 ,
...x n , n ≥ 0} in g such that ∀ p ∈ P, x 0 ∈ A′and x n = f,
and ∀ x i , x j in p, 1 ≤ i < n, j = i + 1, ∃ r ∈ ADR such
that r (x i ) = x j .
• expectedAttributes: P → 2A , a function returning the set
of attributes that are related to a given permission p. Formally, returns all a ∈ A such that (p, a) ∈ PA.
• REQ = {req = <act, p = <tar, oper >, ctx >| act ∈ ACT,
p ∈ P, ctx ∈ CON}, the set of access control requests,
allowing an actor act to request for a permission p to be
granted.
• checkAccess: REQ × ADG → {true, false}, a boolean function that checks if a given request req = (act, p = (tar,
oper ), ctx ) ∈ REQ should be granted or denied based on
a given attribute derivation graph adg. Formally, the function returns true if provisionedAttributes({act, tar, ctx },
adg) ⊆ expectedAttributes(p), and returns false otherwise.

Figure 4: A model description of our approach.

3.4 Attribute Derivation Rules and Graphs

attributes and federated attributes. For this purpose, ADRules are said to be non-injective ∗ , as two or more elements
from an input set of attributes (domain) may be mapped to
the same element in the output set (co-domain).
In addition, AD-Rules can be chained together to produce
a graph-like structure showing how attributes can be provisioned. Such attribute derivation graphs (AD-Graphs) are
directed, because AD-Rules represent unidirectional edges
(due to their nature as functions). Moreover, AD-Graphs
are also weakly connected, as there is no requirement for
all nodes (attributes) to be connected to each other. Finally, AD-Graphs are also possibly cyclic, as a customized

As introduced in Section 3.1, attribute derivation rules
(AD-Rules) are expected to provide a mapping between local

∗
A function f : A → B is said to be injective or one-to-one,
∀ a, a ′∈ A, a 6= a′⇒ f (a) 6= f (a ′).

a set of starting nodes (local attributes) and a given ending node (federated attribute). Then, determining if such a
federated attribute grants the requested permission over the
desired resource. A general procedure for resolving an access
request, derived from the model shown in Fig. 3: given a federation F, a permission P, and a set of input attributes I the
procedure starts by obtaining the set of expected federated
attributes granting P, e.g., by parsing local and federated
access management policies. If the required set is found to
be a subset of I —that is, I contains the attributes required
for P, access is granted. Otherwise, the procedure extracts
a set of paths from an AD-Graph in F, each of these paths
starting with an attribute in the set I and ending with an
attribute in the required set. Then, each path is traversed
by executing each of the included AD-Rules. If new federated attributes are generated, and such attributes happen
to include the attributes in required, access is granted and
the procedure terminates. Otherwise, access is denied.

3.5 Attribute Provisioning

Figure 5: A distributed AD-Graph depicting policy P 1 : local attributes (shown in grey) are transformed into federated ones (shown in white). As an example, the AD-Rule
labeled as r 8 transforms attributes G (group membership),
Size (data size) and Bw-e , Bw-g , Bw-n (bandwidth) into
the federated attribute Ta that is related to the TP (data
transfer) permission.
chaining of AD-Rules may end up introducing a cycle in the
produced AD-Graph.
AD-Graphs may also support collaborative processing by
allowing a division into proper subgraphs, each subgraph
implemented in a different security domain: as mentioned in
Section 2, each participating domain is in charge of defining
its own permissions, local and federated attributes, as well
as the AD-Rules and AD-Graphs to generate those. ADGraphs can be modeled as a distributed graph: a given ADGraph G defined for a federation F may be divided into a
set of subgraphs G′1 , G′2 , ... G′n , such that each G′i is to
be processed by a different domain in F.
As an example, the AD-Graph in Fig. 5 implements the
inter-organizational policy P 1 described in Section 2 as follows: the ESnet local attribute Cred-e , which depicts a
locally-issued credential, is transformed by the AD-Rule labeled as r 3 into the federated attribute L that features membership to a local group within ESnet. L is subsequently processed by the AD-Rule r 6 in the GÉANT domain, producing
the federated attribute G , which in turn depicts membership to an inter-organizational collaborative group. Later,
G , along with attributes Size , Bw-e , Bw-g , and Bw-n are
taken as input for the AD-Rule labeled as r 8 , producing the
Ta attribute as a result. This attribute features an access
token related to the TP permission authorizing the data
transferring process shown in Fig. 1. Such a permission is
included in Fig. 5 for the illustrative purposes.
Leveraging the previous definitions, the problem of resolving an access request to a shared resource within a federation
can be first modeled as a path traversal problem within a distributed graph: determining if there exists a path between

In our approach, attribute provisioning is crucial to handle federated access management requests in the context
of inter-organizational resource sharing. Such a process includes allowing for participating organizations to know about
the AD-Rules that are implemented by other organizations
and are involved in a given AD-Graph G. Concretely, participants need up-to-date information about G so that they
can extract correct paths within G that can produce the
desired federated attributes. With this in mind, attribute
provisioning can therefore be divided into two process: path
discovery and path traversal.
The path discovery process allows for each organization to
distribute information about its locally-implemented ADRules to the federated access management federation, so
that they can potentially maintain a representation of G for
path calculation. However, there are several practical challenges: first, each organization needs to be notified when
changes to G occur, e.g. adding or removing a given ADRule, which may create a large set of communication messages between participants. Second, there is an added maintenance cost, e.g. processing time, that participating organizations must incur for handling and maintaining an up-todate G. Finally, storage efficiency may become an issue when
a large G must be locally maintained. An alternative approach would be creating a central database storing G, along
with a set of replicas for enhanced availability. However,
such a scheme may suffer from service bottlenecks and consistency issues when communicating updates to the replicas.
In addition, a centralized server may become the subject of
a denial of service (DoS) attack, which could certainly limit
the availability of the overall attribute provisioning scheme,
thus potentially preventing participating organizations from
serving federated access management requests. With this
in mind, there is a need for a distributed approach that allows for participating organizations to release information
about the AD-Rules they implement in such a way that the
administration burden, e.g., number of communication messages, is significantly reduced. In addition, such an approach
should also prevent organizations from having to store a
complete AD-Graph locally for path discovery purposes and
should provide support against attacks targeting a single
point of failure. We present an implementation tailored for
meeting such goals in Section 4.

Bw-e

r1

Net-e

Bw-n

r5

Net-n

NORDUnet

Bw-g

r7

G

GÉANT

ESnet

GÉANT

r3

Cred-e

G

r4

Cred-n

G

r6

L

ESnet

L

Bw-e

ESnet

Data

Size

NORDUnet

r2

GÉANT

Size

Ta

r8

G

GÉANT

NORDUnet

ESnet

Bw-g
Bw-n

Figure 6: An illustrative DHT ring depicting the AD-Graph
of Fig. 5: federated peers store entries containing information about the AD-Rules implemented by other peers in the
context of federated access management.
Following the model described in Fig. 3, the path traversal
process allows participating organizations to invoke the ADRules included in a given path p in G that may ultimately
produce a given federated attribute. Invocation of such ADRules should be done by following a sequence starting from
the first AD-Rule in p up to the last one. Each time an ADRule is executed, the produced set of attributes is added to a
set of input attributes for the next AD-Rule in the sequence.
In addition, the invocation of an AD-Rule r enables to locate
the federated domain implementing r, the set of input attributes, as well as the set of produced attributes. A request
for the invocation of r should include the set of attributes
that serve as its input. Finally, the attributes produced by r,
if any, should be then communicated back to the requesting
organization.

4.

IMPLEMENTATION AND EVALUATION

In this section, we describe our proof-of-concept implementation and evaluation results. We elaborate how we accommodate the concerns described in Section 3.5. Also, we
discuss how the path discovery process was implemented
with the concept of distributed hash tables (DHT) [28]. In
addition, we discuss our implementation on the path traversal process which is based on a client-server architecture for
the remote invocation of our proposed AD-Rules.

4.1 Path Discovery
Fig. 6 illustrates the path discovery process based on our
running example. We allow for participants in a federation F
to join a DHT ring to publish and retrieve information about
the AD-Rules that may produce federated attributes. This
process may be in turn decomposed into two inner components, namely, AD-Rule publishing and AD-Rule retrieval.
The procedure for publishing an AD-Rule is conducted
as follows: each domain is in charge of inserting an entry
into the DHT for each AD-Rule they implement for a given
AD-Graph under the context of F. Such an entry should
include information about the input attributes (either local

or federated ones), the name of the AD-Rule, and the set
of federated attributes to be produced as a result. Moreover, some information on how to execute such AD-Rule
should be also provided, e.g., a universal resource locator
(URL). As an example, the ESnet domain will publish an
entry into the DHT containing information about the ADRule r 1 , including the local input parameter Net , which
conceptually depicts information about the current state of
the local network, and the federated attribute Bw , which
provides a standard representation of the current bandwidth
capacity. In addition, such an entry should contain a valid
URL for other federated peers invoking the AD-Rule r 1 remotely. Following the insertion procedure for DHTs [28],
such an entry may end up being stored for future location
at a different federated peer, following a hashing scheme
based on the standardized naming convention for federated
attributes introduced in Section 3.2. In Fig. 6, the entry for
the AD-Rule labeled as r 1 (published by ESnet) ends up being stored by the DHT node under the scope of the GÉANT
domain. Conversely, AD-Rules may be retired from a given
AD-Graph by removing their corresponding entries from a
given DHT ring. Recall such procedure may not necessarily
remove the production of federated attributes in the context
of an AD-Graph, as such attributes may be produced by another AD-Rule in the DHT ring, e.g., removing the entry for
the AD-Rule r 6 does not prevent an attribute G from being
produced by the AD-Rule labeled as r 4 .
The retrieval procedure for entries containing information
about AD-Rules is to be conducted as follows: a participating domain D interested in producing a given attribute A
may retrieve the set S of entries corresponding to A in the
DHT ring, e.g., by hashing the A’s identifier. Then, by inspecting the information about AD-Rules contained in S, D
must determine if there exists a local or federated attribute
under its local domain that can be used as an input parameter to an AD-Rule to produce A. If so, information from the
corresponding entry in the set S is retrieved and the ADRule is invoked. However, if no suitable entry is found, e.g.
all input attributes to the entries in S are out of scope or cannot be locally produced, D may attempt to explore the DHT
ring once again for entries producing the attributes taken as
an input to the entries in S, thus potentially producing a set
P of graph paths in an AD-Graph stored in the DHT. Such
a process may be repeated up to the point when no more
entries can be obtained from the DHT or a cycle in the ADGraph stored in the DHT is detected, e.g., when an iteration
retrieves entries that were previously retrieved in the past,
or a path can be traversed. A path in P is traversed, e.g.,
by calling the sequence of AD-Rules contained in it, only if
it starts with an attribute under the scope of D and ends
with the desired attribute A. Considering our running example, an entity under the ESnet domain may provision an
attribute Ta depicted in Fig. 5 as follows: the DHT featured
in Fig. 6 retrieves the entry for the AD-Rule labeled as r 8
from the ring node implemented by NORDUnet. As the
input parameters of r 8 are all federated attributes, ESnet
inspects the DHT ring once again for determining proper
AD-Rules provisioning those attributes. Then, entries generating Bw-e (r 1 ), Bw-g (r 7 ), Bw-n (r 5 and r 9 ), Size (r 2 )
and G (r 4 , r 6 ), are returned. For the federated attribute Bwe , ESnet can provide the local attribute Net-e required for
r 1 , thus creating a traversable path within the distributed
AD-Graph. In addition, for the federated attribute Size ,

Table 1: Performance (ms) for policy P 1 .

Runtime Performance of our Attribute Provisioning Framework
3000
ALT

ALT
411
484
531
492
470
498

ATT
352
921
1,613
14,214
35,201
85,254

OPT
83
1,405
2,144
14,706
35,671
85,652

ESnet can also provide the required local attribute Data required for r 2 , thus creating a path as well. In the case of
G , the entry belonging to r 4 may be discarded as its input
attribute (Cred-n ) is local only to NORDUnet. However, in
the case of the entry for r 6 , ESnet may inspect the DHT
ring once again for an entry producing the input attribute
L. Next, the entry for r 3 is returned taking Cred-e as an
input. Since Cred-e is local to ESnet, another traversable
path is constructed. With respect to an attribute Bw-n , the
AD-Rules labeled as r 5 can be also discarded as its input
attribute (Net-n ) is local to NORDUnet. However, r 9 can
be used as it takes the federated attribute G as an input,
and a path producing G has been already obtained. Similarly, an attribute Bw-g can be obtained from r 7 as such
an AD-Rule takes G as an input. The setting depicted in
Fig. 5 and Fig. 6 allows for the AD-Rules labeled as r 7 and
r 9 to disclose network-related information, e.g., bandwidth,
only when membership to an inter-organizational project (as
depicted by the G attribute) can be shown.

4.2 Path Traversal
Our implementation supports the process of path traversal by allowing for each participant domain D to implement
a software agent that is capable of handling requests for the
invocation of the AD-Rules that are under the scope of D.
Information on locating such agent and invoking the implemented AD-Rules should be consistent with the entries
published in the DHT ring described in Section 4.1, e.g.,
ESnet may provide a TCP/IP agent that implements the
AD-Rule labeled as r 1 in Fig. 5 and Fig. 6. For a given
path P composed of n entries obtained from a DHT ring,
the traversal procedure would include requesting for the execution of each entry starting from the entry at the first
position and collecting the attributes produced by the ADRule being invoked (if any). The process continues as soon
as new attributes are produced on every AD-Rule invocation and finishes either when a given AD-Rule depicted by
an entry in the path is not able to produce any attributes
or the final entry (at position n - 1) has been executed and
the final attributes have been produced as a result.

4.3 Experimental Results
We have implemented the DHT functionality discussed
before by leveraging the Open Chord 1.0 API [15]: an open
source implementation of the Chord DHT [28] that allows
for remote peers to implement a DHT ring by communicating with each other over TCP/IP sockets. In addition,
our proposed AD-Rules, as discussed in Section 3.4, were
implemented by leveraging a client-server architecture over
TCP/IP sockets with the standard java.net package.
In the first experiment, we examined the inter-organizational policy P 1 shown in Fig. 5 and Fig. 6. Such an ADGraph is stored in a DHT ring composed of three nodes and
each of them simulates three participating organizations in

ATT

2500

2000

Time (ms)

Processing Time
10
50
100
100
2,500
5,000

1500

1000

500

0
10

50

100

Average Execution Time for AD-Rules (ms) (5-5, 10-10, 20-20)

Figure 7: Experimental results for our implementation.

our running example. In addition, each of these nodes has
been augmented with a server module implementing each
of the AD-Rules included in the aforementioned AD-Graph.
As an example, the ESnet domain was simulated by DHT
node as well as a server module implementing the r 1 , r 2 and
r 3 AD-Rules. In addition, the processing time of each ADRule included was simulated by introducing a code to halt
the execution for a certain period of time. In our experiments, we measured the average location time (ALT) for
constructing a given path P within the AD-Graph implementing P 1 policy. Also, we measured the average traversing time (ATT) for P to return a federated attribute as a
result. Finally, we calculated the overall provisioning time
(OPT) by consolidating both ALT and ATT. Table 1 shows
our experimental results when attempting to provision the
federated attribute Ta simulating an entity in the ESnet domain holding the local attributes Cred-e , Net-e and Data as
shown in our example. Since the length (number of DHT entries) of the paths under the experiments remains the same,
e.g. the same number of involved attributes and AD-Rules,
variation in the OPT for each experiment is mostly due to
the preconfigured execution time of the AD-Rules included
in such paths, whereas the ALT involved in constructing
those paths remains manageable.
In the second experiment, we measured the response time
in provisioning attributes over various AD-Graphs. On each
experiment, we produced an AD-Graph depicting a varying number of paths (branches) and each of them includes
the different number of composing nodes (links). In addition, we simulated the execution time of each AD-Rule
involved in the produced AD-Graph by using a configurable
parameter. We maintained the DHT and server configuration as described earlier. On each experiment instance, we
attempted to provision the attribute produced by the DHT
entry located at the last node of each path in the simulated
AD-Graph. As an example, for a path composed of l nodes,
we issue a request for the attribute produced by the DHT
entry located at position l -1, assuming that we can include
the attribute in the request as the input for the entry depicted in position 0 of the path. Fig. 7 shows our results
when constructing AD-Graphs of size (b-l ) where b stands
for the number of branches and l stands for the number
of links on each AD-Graph, e.g., the first three-column set
shows the evaluation results when setting up an execution

time of 10 ms for AD-Rules and constructing AD-Graphs of
size (5-5), (10-10) and (20-20) respectively.
As described before, we obtained both the ALT and the
ATT on each experiment, which are used to calculate the
OPT. In the first experiment, most of the overall provisioning time is spent on the path traversal, which is mostly influenced by both the execution time of each AD-Rule in a
given AD-Graph, as well as the length of the path. Similarly the ALT observed in the second experiment, while it
was also affected by the length of the path, remains just as
a small fraction of the OPT, mostly due to the nature of
distributed network settings based on DHTs.

5.

RELATED WORK

The problem of providing security guarantees in interorganizational settings has been largely addressed in literature. In particular, several federated identity [4] approaches
have been introduced to allow partnering organizations to
reuse locally-issued credentials when accessing resources located under the scope of an external security domain. As
an example, OpenID [26] and Shibboleth [18] have recently
gained acceptance in both industry and academia respectively for user-credential sharing. Our approach builds on
this idea by allowing participants to exchange federated attributes, thus potentially allowing for such attributes to serve
as tokens granting access to shared resources, in an approach
also inspired by Kerberos [20], OAuth [14] and more recently,
Facebook Login [8], which strives to allow third-party applications to leverage the user credentials defined for the popular social network to access application-dependent resources.
Moreover, our AD-Rules are inspired by the idea depicted
in the credential-discovery protocol proposed by the RT Framework [17], which allows for credentials issued by independent domains to be located and leveraged for federated access management purposes. Similar to the RAMARS Framework [12], our AD-Rules are depicted in a graph-like structure that allows for user-defined attributes to be transformed
into a set of widely-recognized credentials. However, the
RAMARS framework assumes each security domain implementing the transformation functions may be partially trusted
by modeling trust in the range [0,1]. In our approach, we
assume all federated peers fully trust each other for the implementation of the federation goals as discussed in Section 3
and the model presented in Fig. 4, due to the nature of DoEaffiliated high-performance network facilities.
In addition, recent approaches leveraging federated identity for sharing resources include the work of Broeder et
al. [2] and Ananthakrishnan et al. [1]. Moreover, Klingenstein [16] and Chadwick and Inman [5] incorporate the concept of end-user attributes with the federated identity. Our
approach includes attributes originated from different access
control entities rather than considering attributes and credentials from end-users.
In the context of attribute-based models, Zhang et al. [30]
introduced their attribute-based access control matrix, which
extends classical theory in the field of access control to accommodate attributes as well as the notion of security state.
Moreover, Priebe et al. [25] presented an approach leveraging the concepts of ontologies and the semantic web in order
to formalize the notion of attributes. An approach close to
ours was introduced by Covington and Sastry [6], who presented a contextual attribute access control (CABAC) model
which was realized in mobile applications. However, our

approach goes a step further by describing the way such attributes are mapped to access rights (permissions) by means
of AD-Rules and AD-Graphs. Recently, a notable approach
was proposed by Jin et al. [13], whose approach formalizes
a series of attribute-based model families. However, our approach introduces a notion of security token and AD-Rules
to capture the mapping between attributes and corresponding access rights.

6. DISCUSSION AND FUTURE WORK
Attribute Provisioning. As shown in Section 4, efficient provisioning of federated attributes is crucial for processing federated access management policies in order to resolve policies in a timely manner. The attribute provisioning
scheme presented in Section 3.5 supports this goal by reducing the number of communication messages between participating domains to determine if a given AD-Graph depicts a
path between a pair of attributes. Each participant organization should decide the number of times it will attempt to
retrieve new entries from a DHT ring when constructing a
given path. As an example, an organization may set a limit
of three explorations of the DHT ring while trying to find a
set of input attributes for AD-Rules that fall under the scope
of its local domain. Setting a low limit of explorations might
prevent participants from discovering a potential path in the
AD-Graph, however a large limit may increase attribute provisioning time, thus possibly affecting the overall processing
time of a given federated access management policy. In addition, due to the fact DHTs require participants to locally
store only a subset of all the entries included in a given
ring, our scheme allows participants to store only a subset of
AD-Rules entries, thus potentially relieving them from storing information related to the complete AD-Graph. In this
way, the process of adding and removing AD-Rules is significantly simplified, thus providing a means for modifying
a given AD-Graph to better meet the specific goals devised
for collaborations, e.g., adding new AD-Rules to handle user
credentials from a new participating domain.
Trust Model. Our current approach assumes all participants in our federation fully trust each other for the implementation of both the AD-Rules as well as the model defined
in Fig. 4. This strong assumption requires that participants
faithfully produce federated attributes by providing verified
and accurate AD-Rules and communicating those in a timely
manner. However, such an assumption may not always hold
in practice. As an example, the incorrect implementation
of a given AD-Rule may potentially compromise the overall
security of a federated environment. Future work may focus
on incorporating a trust model among participants and a
risk analysis framework such that incidents can be detected
and proper countermeasures can be deployed as a result.
Privacy. Following the fully-trusted assumption just described, a basic privacy model may be implemented on top of
our approach by allowing for sensitive information contained
in locally-defined attributes not to be revealed to other organizational peers when producing federated attributes. For
instance, in Fig. 5, sensitive information in attribute Cred ,
e.g., a user’s full name, may be replaced by a pseudonym
in the L attribute produced by the AD-Rule labeled as r 3 .
An alternative approach may allow for end-users to hide
sensitive attributes at request time by incorporating techniques such as the privacy-preserving attribute-based credentials (PABC) proposed by Camenisch et al. [3].

Policy Language and Conflict Resolution. Efficient
discovery and retrieval of policies (as shown in Section 3)
may benefit from the use of a standard policy language, in a
similar technique to the one used by the XACML role-based
access control (RBAC) Profile [22]. Moreover, a comprehensive policy specification framework is critical to detect and
resolve conflicts that may arise between federated and local
policies, or the intersection of the two, e.g., contradictory
rules, following an approach similar to the one proposed by
Hu et al. [10].
Integration with NSI. Finally, we plan to work on integrating our approach with the NSI effort presented in Section 2, in such a way that the collaborative efforts devised
by participant organizations can be better met by securily
leveraging DoE-affiliated high-performance facilities.

7.

CONCLUDING REMARKS

In this paper, we have explored the problem of implementing well-defined, consistent, and inter-organizational access
management for collaborative resource sharing. In our proposed approach and experiments, we also showed that participants could engage in a federation under a well-defined
set of responsibilities, including the use of standardized attribute definitions, attribute provisioning, and distributed
policy evaluation. We believe our approach may also be
applicable to any other collaborative settings beyond highperformance network environments, e.g. collaborative projects in the health-care domain would certainly benefit for
automated approaches that allow for information to be safely
shared between independently-run organizations, possibly
improving the patient experience and encouraging the development of groundbreaking advancements.

8.

ACKNOWLEDGEMENTS

We would like to thank the anonymous reviewers for their
valuable comments that helped improve the presentation
of this paper. This work was partially supported by the
grant from the United States Department of Energy (DESC0004308). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the
authors and do not necessarily reflect the views of the funding agency.

9.

REFERENCES

[1] R. Ananthakrishnan, J. Bryan, K. Chard, I. Foster, T. Howe,
M. Lidman, and S. Tuecke. Globus nexus: An identity, profile,
and group management platform for science gateways. In
Proceedings of 2013 IEEE International Conference on
Cluster Computing (CLUSTER), pages 1–3, Sept 2013.
[2] D. Broeder, R. Wartel, B. Jones, P. Kershaw, D. Kelsey,
S. Lüders, A. Lyall, T. Nyrönen, and H. J. Weyer. Federated
identity management for research collaborations. Technical
report, CERN, 2012.
[3] J. Camenisch, A. Lehmann, G. Neven, and A. Rial.
Privacy-preserving auditing for attribute-based credentials. In
Proceedings of European Symposium on Research in
Computer Security (ESORICS), pages 109–127, 2014.
[4] D. W. Chadwick. Federated identity management. In
Foundations of Security Analysis and Design V, pages
96–120. Springer, 2009.
[5] David W Chadwick and George Inman. Attribute aggregation
in federated identity management. IEEE Computer,
42(5):33–40, 2009.
[6] M. J. Covington and M. R. Sastry. A contextual
attribute-based access control model. In Proceedings of the
2006 International Conference on the Move to Meaningful
Internet Systems (OTM), pages 1996–2006. Springer, 2006.

[7] Europe’s National Research and Education Networks (NRENs).
Geánt Project Home, 2015. http://www.geant.net/.
[8] Facebook Inc. Facebook Login, 2015.
https://www.facebook.com/about/login/.
[9] Open Grid Forum. An Open Global Forum for Advanced
Distributed Computing, 2015. https://www.ogf.org/.
[10] H. Hu, Gail-J. Ahn, and K. Kulkarni. Detecting and resolving
firewall policy anomalies. IEEE Transactions on Dependable
and Secure Computing, 9(3):318–331, 2012.
[11] Jing J. and Gail-J. Ahn. Role-based access management for
ad-hoc collaborative sharing. In Proceedings of 11th
Symposium on Access Control Models and Technologies
(SACMAT), pages 200–209. ACM, 2006.
[12] Jing Jin and Gail-Joon Ahn. Authorization framework for
resource sharing in grid environments. Grid and Distributed
Computing, 63:148–155, 2009.
[13] X. Jin, R. Krishnan, and R. Sandhu. A unified attribute-based
access control model covering dac, mac and rbac. In
Proceedings of the 26th Annual IFIP WG 11.3 conference on
Data and Applications Security and Privacy (DBSec), pages
41–55. Springer, 2012.
[14] M. Jones and D. Hardt. The oauth 2.0 authorization
framework: Bearer token usage. Technical report, RFC 6750,
October, 2012.
[15] Kaffille, Sven and Loesing, Karsten. Open Chord, 2015.
http://sourceforge.net/projects/open-chord/.
[16] N. Klingenstein. Attribute aggregation and federated identity.
In Proceedings of the 2007 International Symposium on
Applications and the Internet Workshops (SAINT), pages
26–26, Jan 2007.
[17] Ninghui Li, J.C. Mitchell, and W.H. Winsborough. Design of a
role-based trust-management framework. In Proceedings of the
2002 IEEE Symposium on Security and Privacy, pages
114–130, 2002.
[18] R. L. Morgan, S. Cantor, S. Carmody, W. Hoehn, and
K. Klingenstein. Federated Security: The Shibboleth Approach.
EDUCAUSE Quarterly, 27(4):12–17, 2004.
[19] National Institute of Standards and Technology. Guide to
Attribute Based access Control (ABAC) Definition and
Considerations, 2013. NIST Special Publication 800-162 Draft.
[20] B.C. Neuman and T. Ts’o. Kerberos: an authentication service
for computer networks. Communications Magazine, IEEE,
32(9):33–38, Sept 1994.
[21] Nordic Council of Ministers. Nordic Infrastructure for Research
& Education (NORDUnet), 2015. https://www.nordu.net/.
[22] OASIS. XACML v3.0 Core and Hierarchical Role Based Access
Control (RBAC) Profile Version 1.0, 2014.
http://docs.oasis-open.org/xacml/3.0/xacml-3.
0-rbac-v1-spec-cd-03-en.html.
[23] Open Grid Forum. Network Services Interface (NSI), 2015.
https://redmine.ogf.org/projects/nsi-wg.
[24] F. Paci, R. Ferrini, A. Musci, K. Steuer, and E. Bertino. An
interoperable approach to multifactor identity verification.
IEEE Computer, 42(5):50–57, May 2009.
[25] T. Priebe, W. Dobmeier, and N. Kamprath. Supporting
attribute-based access control with ontologies. In Proceedings
of the First International Conference on Availability,
Reliability and Security (ARES), pages 465–472, Washington,
DC, USA, 2006. IEEE.
[26] D. Recordon and D. Reed. Openid 2.0: A platform for
user-centric identity management. In Proceedings of the Second
ACM Workshop on Digital Identity Management, DIM ’06,
pages 11–16, New York, NY, USA, 2006. ACM.
[27] M. S. Singhalm, S. Chandrasekhar, Ge Tingjian, R. Sandhu,
R. Krishnan, Gail-J. Ahn, and E. Bertino. Collaboration in
multi-cloud applications: Framework and security issues. IEEE
Computer, 2013.
[28] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and
H. Balakrishnan. Chord: A scalable peer-to-peer lookup service
for internet applications. In Proceedings of the 2001
Conference on Applications, Technologies, Architectures, and
Protocols for Computer Communications, pages 149–160, New
York, NY, USA, 2001. ACM.
[29] US Department of Energy. Energy Sciences Network (ESnet),
2015. http://www.es.net/.
[30] X. Zhang, Y. Li, and D. Nalla. An attribute-based access
matrix model. In Proceedings of the 2005 ACM symposium on
applied computing (SAC), pages 359–363, New York, NY,
USA, 2005. ACM.

RiskMon: Continuous and Automated
Risk Assessment of Mobile Applications
Yiming Jing† , Gail-Joon Ahn† , Ziming Zhao† , and Hongxin Hu‡
†

Arizona State University

‡

Delaware State University

{ymjing,gahn,zzhao30}@asu.edu, hhu@desu.edu

ABSTRACT

1.

Mobile operating systems, such as Apple’s iOS and Google’s
Android, have supported a ballooning market of feature-rich
mobile applications. However, helping users understand security risks of mobile applications is still an ongoing challenge. While recent work has developed various techniques
to reveal suspicious behaviors of mobile applications, there
exists little work to answer the following question: are those
behaviors necessarily inappropriate? In this paper, we seek
an approach to cope with such a challenge and present a
continuous and automated risk assessment framework called
RiskMon that uses machine-learned ranking to assess risks
incurred by users’ mobile applications, especially Android
applications. RiskMon combines users’ coarse expectations
and runtime behaviors of trusted applications to generate
a risk assessment baseline that captures appropriate behaviors of applications. With the baseline, RiskMon assigns
a risk score on every access attempt on sensitive information and ranks applications by their cumulative risk scores.
We also discuss a proof-of-concept implementation of RiskMon as an extension of the Android mobile platform and
provide both system evaluation and usability study of our
methodology.

Mobile operating systems, such as Android and iOS, have
tremendously supported an application market over the last
few years. Google Play announced 48 billion app downloads in May 2013 [27]. Almost at the same time, Apple’s
AppStore reached 50 billion downloads [31]. Such a new
paradigm drives developers to produce feature-rich applications that seamlessly cater towards users’ growing needs of
processing their personal information such as contacts, locations and other credentials on their mobile devices. Unfortunately, the large installed base has also attracted attention
of unscrupulous developers who are interested in users’ sensitive information for a variety of purposes. For example,
spyware tracks users’ locations and reports to remote controllers, and adware collects users’ identities for enforcing an
aggressive directed marketing.
To defend against such rogue applications, Android assists
users to review them at install time. Primarily, Android
relies on permissions to help users understand the security
and privacy risks of applications. In Android, an application
must request permissions to be allowed to access sensitive
resources. In other words, it is mandatory for Android applications to present its expected behaviors to users. Even
though permissions outline the resources that an application
attempts to access, they do not provide ﬁne-grained information about how and when such resources will be used.
Suppose a user installs an application and allows it to access her location information. It is hard for her to determine whether the application accesses her locations on her
demand or periodically without asking for her explicit consent. Therefore, it is imperative to continuously monitor the
installed applications so that a user could be informed when
rogue applications abuse her sensitive information. Previous
work has proposed real-time monitoring to reveal potential
misbehaviors of third-party applications [14, 22, 30, 38, 39].
Speciﬁcally, TaintDroid [14] and Aurasium [38] inspect an
application’s behaviors at variable and syscall level, respectively. While these techniques partially provide valuable insights into a user’s installed applications, it is still critical to
answer the following challenge: are the behaviors in mobile
applications necessarily inappropriate?
To answer this question, it is an end-user’s responsibility
to conduct risk assessment and make decisions based on her
disposition and perception. Risk assessment is not a trivial
task since it requires the user to digest diverse contextual
and technical information. In addition, the user needs to
apprehend expected behaviors of applications under diﬀerent
contexts prior to addressing her risk assessment baseline.

Categories and Subject Descriptors
C.4 [Performance of Systems]: Measurement techniques;
D.4.6 [Operating Systems]: Security and Protection—Access controls, Information flow controls

Keywords
Smartphones; Android; Risk Assessment

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CODASPY’14, March 3–5, 2014, San Antonio, Texas, USA.
Copyright 2014 ACM 978-1-4503-2278-2/14/03 ...$15.00.
http://dx.doi.org/10.1145/2557547.2557549.

INTRODUCTION

However, it is impractical for the normal users to distill
such a baseline. Instead, it is essential to develop an automated approach to continuously monitor applications and
eﬀectively alert users upon security and privacy violations.
In this paper, we propose an automated and continuous risk assessment framework for mobile platforms, called
RiskMon. RiskMon requires a user’s coarse expectations
for diﬀerent types of applications while user intervention is
not required for the subsequent risk assessment. The user
needs to provide her selection of trusted applications from
the installed applications on her device and her ranking of
permission groups in terms of their relevancy to the corresponding application. Then, RiskMon builds the user’s
risk assessment baseline for diﬀerent application categories
by leveraging API traces of her selected applications. RiskMon continuously monitors the installed applications’ behaviors, including their interactions with other applications
and system services. The risk of each interaction is measured
by how much it deviates from the risk assessment baseline.
For a better risk perception, RiskMon ranks installed applications based on the risk assessment results in a real-time
manner. Intuitively, the user can deem an application as
safe if it is less risky than any of her trusted applications.
As RiskMon interposes and assesses API calls before an
application gets the results, we foresee the possibility of integrating RiskMon into an automated permission granting
process as discussed in [18] and [32]. Furthermore, while
we implement RiskMon on the Android platform, RiskMon is equally applicable to other platforms (e.g. Apple
iOS and Microsoft Windows Phone) in assisting security experts to discover high-risk applications. Tools like RiskMon would practically help raise awareness of security and
privacy problems and lower the sophistication required for
concerned users to better understand the risks of third-party
mobile applications.
This paper makes the following contributions:
• We propose a methodology for establishing a risk assessment baseline from a user’s trusted applications
and her coarse expectations. Our approach lowers the
required sophistication to conduct eﬀective risk assessment for end-users;
• We propose a machine-learned ranking based framework that continuously monitors the runtime behaviors of mobile applications, automatically measures their
risks, and intuitively presents the risks;
• We implement a proof-of-concept prototype of RiskMon and demonstrate how it can be seamlessly deployed in Android; and
• We evaluate RiskMon with comprehensive experiments,
case studies, and crowd-sourced user surveys. Our
experimental results demonstrate the feasibility and
practicality of RiskMon.
The remainder of this paper proceeds as follows. Section 2
provides the motivation and problem description of this paper. Section 3 provides a high-level overview of the RiskMon framework and system design by illustrating each stage
of automated risk assessment. Section 4 presents prototype
implementation and evaluation of our framework. Section 5
discusses the limitations of our approach. Section 6 describes
related work. Section 7 concludes the paper.

2.

MOTIVATION AND BACKGROUND
TECHNOLOGIES

Users are concerned about security and privacy issues on
mobile devices. However, in most cases they are not aware
of the issues unless highlighted. Although Apple’s mandatory application review process [1] and Google Bouncer [25]
strive to mitigate misbehaving applications, users are still
responsible for defending themselves.

2.1

Use Cases and Threat Model

A continuous and automated risk assessment framework
enhances a number of use cases in the current mobile application ecosystems. In general, such a framework improves
user experience of security features and promotes understanding about risks of mobile applications. This enables
more users to discover misbehaving applications and possibly write negative reviews, thereby alerting and protecting
other users. In addition, it complements static and dynamic
analysis in ensuring appropriateness justiﬁcations by security analysts. This could be applied in both oﬃcial and alternative application markets as a pre-screening mechanism
to select suspicious applications for further analysis. Alternatively, a developer can evaluate her applications against
those of her competitors and improve security practices if
necessary. For the purposes of this paper we consider the
generic scenario where a user assesses her installed applications.
Applications, as long as they are not on users’ devices, do
not incur any substantial risk. Once an application is installed, it starts interacting with the operating system and
other applications. While the application accesses sensitive
resources, it gradually builds a big picture of the system
as well as the user. Each access, such as calling an API,
returns a tiny fraction of the picture and incurs a small
amount of risk. Once the picture is ﬁnished, it may contain
a user’s personal identities (e.g. contacts), device identities
(e.g. manufacturer) and context identities (e.g. locations,
WiFi SSIDs). Since risk assessment at the pre-installation
stage does not address such threats on users’ devices, we aim
to provide continuous risk assessment for normal users.

2.2

Risk Assessment of Mobile Applications

Recent work has proposed mechanisms to extract risk signals from meta information on application markets such as
permissions [16, 28, 33, 36], ratings [9, 10], and application
descriptions [26]. Their limitation is that such information
is fuzzy and fails to provide ﬁne-grained information about
how and when sensitive resources are used. For example, an
application may stay in the background and keep probing
a user’s locations and surroundings. Moreover, a malicious
application with split personalities [5] can evade screening
mechanisms of application markets. We argue that users
deserve the rights to understand what is happening on their
own devices. Thus, continuously revealing runtime behaviors plays a vital role as a necessary defense line against
rogue applications.
Previous research concerning applications’ runtime behaviors speciﬁes a set of risk assessment heuristics tailored to
their speciﬁc problems. For example, TaintDroid [14] considers a case in which sensitive data is transmitted over
the network. DroidRanger [40] and RiskRanker [20] assume
that dynamically loaded code is a potential sign of malware.
While these techniques provide valuable insights about run-

time behaviors of mobile applications, they do not justify
the appropriateness of the revealed behaviors. We argue
that runtime behaviors are not the only factor to determine
appropriateness. Another important factor is the contextual properties. For example, a location-based application
has good reason to upload a user’s locations for discovering
nearby restaurants. In contrast, it does not make sense for a
video player to use the locations. Also, a user’s expectations
are another critical factor. Even though an application is allowed to use a user’s sensitive information, the user should
have the capability to specify preferences for determining accesses to her own sensitive information. However, we cannot
assume that all users are able to digest contextual information and system-level expectations, which is necessary for
establishing a risk assessment baseline that captures appropriate behaviors. The absence of such a baseline renders
current risk assessment process ineﬀective. Therefore, it is
imperative to automate risk assessment for seamlessly helping users accommodate their preferences without requiring
additional intervention.

2.3 Android Platform
Android is a computing platform for mobile devices. It
implements a security architecture that adopts a sandbox
and a permission framework. While system services and installed applications are isolated and conﬁned in their respective sandboxes, they can interact and collaborate via APIs.
Each permission protects a set of APIs that access some
sensitive resources. A user can approve permission requests
of an application at install time so that the application is
allowed to use the corresponding APIs.
Permission groups: Permission group is a logical grouping of related permissions. For example, SOCIAL_INFO includes permissions that access a user’s contacts and call logs.
Given Android API level 18, Android provides 31 permission
groups to cover 134 permissions. Most permission groups are
self-descriptive, such as LOCATION and CAMERA. Android also
provides a short description for each permission group to
elaborate its corresponding resources.
API and direction of control flow: A typical Android application’s execution is orchestrated by API calls
and callbacks with opposite directions of control ﬂows. An
API call initiates a synchronous control ﬂow so that the
caller application gets results immediately after the API returns. API callbacks are designed for asynchronous control
ﬂows which enable a system service to notify an application when an event occurs or a result is ready. Both API
calls and callbacks are frequently used in accessing sensitive resources, such as getting a contact entry and receiving
location updates.
Binder IPC framework: While APIs enable applications to interact with each other and system services in
their respective process sandboxes, they are implemented
based on an underlying inter-process communication framework called Binder. Binder includes a kernel driver and a
userspace library. It serializes data objects as parcels for
sender process, and de-serialize parcels for recipient process.
Binder also manages IPC transactions in which parcels are
processed and delivered. Binder identiﬁes a transaction with
the UIDs and PIDs of sender and recipient processes as well
as a command code that speciﬁes the action to be performed
in the receipt process.

3.

RISKMON: OVERVIEW AND SYSTEM
DESIGN

In this section, we describe our risk assessment framework
that lowers the required intervention and sophistication in
risk assessment of mobile applications.
IT risk assessment guidelines, such as NIST SP 800-30 [35]
and CERT OCTAVE [2], illustrate general methodologies
that enable organizations to understand, assess and address
their information risks. For example, OCTAVE covers the
following critical tasks [3]:
1. Identify critical information assets and their security
requirements;
2. Consider the activities that can expose the identiﬁed
assets to threats due to organizational and/or technological vulnerabilities;
3. Deﬁne risk evaluation criteria that captures operational
context and organization’s tolerance; and
4. Create practice-based protection strategies and risk
mitigation plans.
While these guidelines deal with the infrastructure and
organizational risks by security experts, our framework attempts to adapt and automate the sophisticated risk assessment tasks for general users. Several existing state-of-theart frameworks attempt to automatically extract a universal
risk assessment baseline by mining the meta information of
a large number of mobile applications (e.g. Peng et al. [28]).
Compared with their approaches, RiskMon adheres to general risk assessment methodologies and considers user’s security requirements and operational contexts as indispensable
inputs. This design choice enables our framework to accurately capture user’s expected appropriate behaviors rather
than average practices of developers.
An underlying assumption of RiskMon is that a user’s
trusted applications could deﬁne her expected appropriate
behaviors. Recent empirical analysis showed that applications of similar categories normally request a similar set of
permissions [6], implying similar core functionalities. Hence,
each of the user’s trusted applications can be used as a reference point of appropriate behaviors for applications of similar categories. For example, Netﬂix application is under
“Entertainment” category, and Pandora’s Internet Radio application is under “Music & Audio” category. Even though
they are not in the same category, each application similarly
uses one of core functionalities such as the streaming service
of personalized media contents from remote servers. If a
user trusts Netﬂix application, it implicitly aﬃrms that Pandora application may also incur commensurate risks caused
by Netﬂix application. Thus, using Netﬂix application as a
reference point, the deviation or “distance” of runtime behaviors between Netﬂix and Pandora applications indicates
Pandora’s additional inherent risks.
We now summarize the design goals for a continuous and
automated risk assessment framework:
Continuous and fine-grained behavior monitoring: Applications access sensitive resources by calling APIs to communicate with each other and system services. To ensure
continuous monitoring on API calls, RiskMon interposes
Binder IPC on a user’s device. The risks incurred by API
calls are determined by the caller, the callee, and the data.
To capture such information, RiskMon opts for a ﬁne-grained

Android Applications
GooglePlay

Device

User

Meta
Information

API
Traces

Security
Requirements

Application Intelligence
Aggregator

Baseline
Learner

Risk
Meter

RiskMon

Figure 1: RiskMon Architecture for Android

scheme to capture various intelligences about applications.
This provides a well-founded base for measuring the “distance” between two API calls in the space of runtime behaviors.
Simplified security requirement communication: It is a
challenging task for users to specify security requirements
for security tools. To tackle this problem, RiskMon adopts
a simple heuristic that allows users to communicate security
requirements through their coarse expectations. Although
this reduces the burden on the user, we cannot entirely eliminate it. We note that acquiring a user’s expectations is necessary since each user has diverse preferences on the same
application. For instance, all users of Facebook application
may have disparate expectations for controlling their location and camera utilities.
Intuitive risk representation: The way in which risk is
presented signiﬁcantly inﬂuences a user’s perception and decision upon risky applications. A counterexample would be
standalone risk scores, such as a risk indicator saying “Facebook incurs 90 units of risk” without proper explanation.
As Peng et al. noted in [28], “it is more eﬀective to present
comparative risk information”. Inspired by their approach,
RiskMon presents a ranking of applications so that a user
can compare the potential loss of using an application with
other applications. In addition, the user can view the risk
composition of an application for supporting evidences.
Iterative risk management: Risk assessment is an ongoing iterative process. As applications get upgraded and
bring more functionalities, they introduce new risks that
should be measured. To this end, the risk assessment baseline should evolve to continuously monitor installed applications and update the risk assessment baseline periodically.
Moreover, users need to provide their feedbacks to RiskMon
by adding or revising their security requirements.
We now present our risk assessment framework. Figure 1
depicts the RiskMon architecture for Android. Our framework consists of three components: an application intelligence aggregator, a baseline learner, and a risk meter.
The application intelligence aggregator compiles a dataset
from API traces collected on a user’s device and meta infor-

mation crawled from application markets. API traces cover
an application’s interactions with other parts of the system
via API calls and callbacks. To complement API traces with
contextual information, RiskMon uses meta information on
application markets such as ratings, number of downloads
and category which provide a quantitative representation of
applications’ reputation and intended core functionalities.
The baseline learner combines a user’s coarse expectations
and aggregated intelligences of her trusted applications to
generate a training set. Afterwards, the baseline learner applies a machine-learned ranking algorithm to learn a risk assessment baseline. Then the risk meter measures how much
an application’s behaviors deviate from the baseline. Using
the deviation to provide risk information, risk meter ranks
a user’s installed applications by their cumulative risks and
presents the ranking to the user in an intuitive way. The remainder of this section describes each component in detail.

3.1

Application Intelligence Aggregator

This component aggregates intelligences about a user’s installed applications, including their runtime behaviors and
contextual information. As RiskMon monitors runtime behaviors by interposing Binder IPC, we propose a set of features for API traces tailored to the peculiarity of Binder.
Also, we seek contextual information from application markets and propose corresponding features to represent and
characterize them. The proposed features build a space
of application intelligences and enables subsequent baseline
generation and risk measurement. Unless explicitly speciﬁed, all features are normalized to [0,1] so that each of them
contributes proportionally.

3.1.1

Features for API Traces

Android applications frequently use APIs to interact with
system services. Considering that using most APIs does not
require any permission, we assume that resources protected
by at least one permission are a user’s assets.
We are interested in runtime behaviors, i.e. Binder transactions, that are used by APIs to reach the assets. However, APIs do not carry information about Binder transactions. To bridge this gap, we adopt existing work [4, 17]
to provide mappings from permissions to APIs. Meanwhile,
we analyzed the interface deﬁnitions of Android system services and core libraries to generate a mapping from APIs
to Binder transactions. As a result, we extracted 1,003
permission-protected APIs, of which each corresponds to a
type of Binder transactions. Each type of Binder transaction is identiﬁed by the corresponding system service, direction of control ﬂow, and a command code unique to the service. For example, an API named requestLocationUpdate
is identiﬁed as Binder IPC transaction (LocationManager,
callback, 1).
We attempt to represent a Binder transaction with its internal properties and contents. For a speciﬁc Binder transaction between an application and a system service, we are interested in its type so as to identify the corresponding asset.
Also we need to know the direction of control ﬂow for determining who initiates the transaction. As users trust the system services more than applications, RiskMon should differentiate Binder transactions initiated by applications and
system services. Thus, internal properties are represented
with the following features:

• Type of Binder transaction: 1,003 boolean features as a bit array, where one bit is set to 1 for the
corresponding transaction type and others are 0; and
• Direction of control flow: another boolean feature: 0 for transactions initiated from applications
(API calls), 1 for transactions initiated from system
services (API callbacks).
Note that we use 1,003 boolean features to represent the type
of Binder transactions instead of using one integer value.
This is because Binder transactions are independent from
each other, and the Binder command codes are simply nominal values. By using the array of 1,003 boolean values, the
distances between any two Binder transaction types are set
to the same value, which is important for our learning algorithm (Section 3.2.3).
In terms of contents, parcels in Binder transactions are
unstructured and highly optimized, and it is hard to restore
the original data objects without implementation details of
the sender and recipient. Therefore, we use length as one
representative feature of parcel. A motivating example is
accesses on contacts. From the length of a parcel we can infer
whether an application is reading a single entry or dumping
the entire contacts database. Thus, we propose the following
two features for parcels:
• Length of received parcel: length of the parcel received by an application in bytes; and
• Length of sent parcel: length of the parcel sent by
an application in bytes.

3.1.2

Features for Meta Information

Although meta information on application markets cannot
describe applications’ runtime behaviors, it is still viable to
use such information as contextual properties that capture
users’ and developers’ opinions and complement runtime behavior information.
In terms of representing the opinions of users, we use the
following features in correspondence with their counterparts
of meta information on application markets:
• Number of installs: a range of total number of installs since the ﬁrst release1 . We use logarithmic value
of the lower bound, i.e., log(1+lower bound of #installs) ;
• Number of reviews: a number of reviews written
by unique users. We use the logarithmic value, i.e.
log(1+#reviews); and
• Rating score: a number indicating the user-rated
quality of the application ranged from 1.0 to 5.0.
These three features capture an application’s popularity
and reputation. The ﬁrst two features are similar to number of views and comments in online social networks. Recent studies [37] demonstrated that online social networks
and crowd-sourcing systems expose a long-tailed distribution. Therefore, we assume they follow the same distribution
and use the logarithmic values.
We emphasize that we do not attempt to extract risk signals from these features. Instead, we adopt these features
1
Number of installs is speciﬁed with exponentially increasing
ranges: 1+, 5+, . . . , 1K+, 5K+, . . . , 1M+, 5M+.

Figure 2: SOM Representation of 13 Categories
to capture the underlying patterns of a user’s trusted applications as speciﬁed by the user and apply the patterns for
the subsequent risk assessment.
Next, we propose a feature to capture the developer’s
opinion:
• Category: a tuple of two numerical values normalized
to [-0.5, 0.5].
Google Play uses an application’s category to describe its
core functionalities (e.g. “Communication”). As of this writing, Google Play provides 27 category types. We choose SelfOrganizing Map (SOM) to give a 2-dimension representation
of categories. Barrera et al. [6] demonstrated that SOM
can produce a 2-dimensional, discretized representation of
permissions requested by diﬀerent categories of Android applications. Categories in which applications request similar
permissions are clustered together. Therefore we use the x
and y coordinates in the map to represent categories. Figure 2 depicts the coordinates of 13 categories as an example.
It is clear to see that some categories bear underlying similarities, such as “Entertainment”, “Media and Video” and
“Music and Audio” in the center of the ﬁgure2 .
Clearly an unscrupulous developer can claim an irrelevant
category to disguise an application’s intended core functionalities. However, a user can easily notice the inconsistencies
and remove such applications. In addition, falsifying an application’s meta information violates the terms of application market’s developer policies and may lead to immediate
takedown.
Finally, based on the scheme deﬁned by these features,
the application intelligence aggregator generates a dataset
consisted of feature vectors extracted from API traces and
meta information of each installed application.

3.2

Baseline Learner

The baseline learner is the core module of RiskMon. It
takes two types of inputs, which are a user’s expectations
and feature vectors extracted by the application intelligence
aggregator. Then the baseline learner generates a risk assessment baseline which is represented as a predictive model.

3.2.1

Acquiring Security Requirements

It is challenging for most users to express their security
requirements accurately. We aim to ﬁnd an approach that
2

For more details on SOM, please refer to [6].

Facebook

could be mostly acceptable by users. Krosnick and Alwin’s
dual path model [24] demonstrated that a satisficing user
would rely on salient cues to make a decision. Based on this
model we develop a simple heuristic:
For a specific application, accesses on resources
that are more irrelevant of a user’s expected core
functionalities incur more risks.
This heuristic captures a user’s expectations as security
requirements by risk aversion, which implies the reluctance
of a user to use a functionality with an unknown marginal
utility [29]. For example, a user may consider that, microphone is necessary to a VoIP application such as Skype.
But location seems not because she does not understand the
underlying correlation between disclosing her location and
making a phone call. Thus, microphone is more relevant and
less risky than location in her perception.
Base on this, the risk learner asks a user to specify a
relevancy level for each permission group requested by her
trusted applications. We choose permission groups to represent resources because it is much easier for general users to
learn 20+ permission groups than 140+ permissions. And
recent usability studies demonstrated the ineﬀectiveness of
permissions due to limited comprehension [12,19]. Although
users tend to overestimate the scope and risk of permission groups, they are more intuitive and reduce warning fatigue [19].
The process for users to communicate their security requirements with RiskMon is similar to a short questionnaire. Each permission group requested by a user’s trusted
applications corresponds to a ﬁve-point Likert item. The
user speciﬁes the level of relevancy on a symmetric bipolar scale, namely relevant, probably relevant, neutral, probably irrelevant or irrelevant. Figure 3 shows an example
of relevancy of permission groups for Facebook and Skype.
Permission groups are represented by self-descriptive icons,
which are identical to those shown in Android Settings. CAMERA preceding LOCATION for Facebook is possibly due to the
user’s preference to photo sharing compared to check-ins.
Note that the relevancy levels speciﬁed by users are subjective. With that said, users’ biased perception of applications and resources may aﬀect their speciﬁed relevancy levels. From our user study, a user told us that PHONE_CALLS is
relevant to Google Maps because he tapped a phone number shown in Google Map and then the dialer appeared. Although the dialer rather than Google Map has the capability
to make phone calls, the baseline learner considers it as the
security requirements for inter-application communication.
We next formalize the problem of acquiring security requirements. P G = {pg1 , pg2 , · · · , pgm } is a set of permission groups available in a mobile operating system. A =
{a1 , a2 , · · · , an } is a set of a user’s installed applications.
T A is a set of a user’s trusted and installed applications and
T A ⊆ A. RequestedP G : A → 2P G is a function that maps
an application to its requested permission groups. A user’s
security requirement Req is a mapping Req : T A×P G → R.
R = {1, 2, 3, 4, 5} is a set of relevancy levels, where a larger
value indicates higher relevancy and less risk and vice versa.

3.2.2

Compiling Training Set

Next we describe how the baseline learner compiles a training set from the aggregated application intelligences and
user-speciﬁed relevancy levels. For brevity, we apply the

Skype

Relevant
1
Low risk

2

3
Neutral

4

Irrelevant
5
High risk

Camera

Contacts

Phone Calls

Location

Microphone

Network

Figure 3: An Example of Specifying Relevancy for
Permission Groups
relevancy levels onto the feature vectors generated by the
application intelligence aggregator to generate a set of vectors annotated with relevancy levels.
To bridge the gap between permission groups and feature
vectors, we extract mappings of permission groups and permissions from the source code of Android. Meanwhile, existing work has provided mappings between permissions and
APIs [4, 17]. Therefore, we can assign the relevancy level on
feature vectors because each vector represents an API call
or callback.
We formalize the problem of compiling a training set as
follows. Algorithm 1 illustrates the process to compile the
training set T .
• X is a space of features as deﬁned by the scheme discussed in Section 3.1, X = {x1 , x2 , · · · , xl }, X ∈ Ri ,
where i denotes the number of features;
• DS = {Da1 , Da2 , · · · , Dam } is a collection of sets of
feature vectors, where Daj ⊆ X and Daj corresponds
to an application aj ;
• Apd : A × P G → DS is a function that maps an application and one of its requested permission groups to a
set of feature vectors; and
• T = {(x1 , r1 ), (x2 , r2 ), · · · , (xn , rn )} is a training set
consisted of annotated vectors, rk ∈ R, xk ∈ X.
Algorithm 1: Compiling Training Set
Data: DS, T A, Req
Result: T
T ← ∅;
for a ∈ T A do
pg ← RequestedP G(a);
r ← Req(a, pg);
D ← Apd(a, pg);
for x ∈ D do
add (x, r) to T;
end
end
return T

3.2.3

Generating Risk Assessment Baseline

Ranking Support Vector Machine (RSVM) [21, 23] is a
pair-wise ranking method. Generally it utilizes a regular

Support Vector Machine (SVM) solver to classify the order
of pairs of objects. Next we explain how we apply RSVM to
learn a risk assessment baseline.
We assume that a set of ranking functions f ∈ F exists
and satisﬁes the following:
xi ≺ xj ⇐⇒ f (xi ) < f (xj ),

(1)

where ≺ denotes a preferential relationship of risks.
In the simplest form of RSVM, we assume that f is a
linear function:
 x,
fw (x) = 
w,

(2)

where w
 is a weight vector, and 
·, · denotes inner product.
Combing (1) and (2), we have the following:
 xi − xj  < 0,
xi ≺ xj ⇐⇒ 
w,

(3)

Note that xi −xj is a new vector that expresses the relation
xi ≺ xj between xi and xj . Given the training set T , we
create a new training set T  by assigning either a positive
label z = +1 or a negative label z = −1 to each pair (xi , xj ).

(xi , xj ) : zi,j =

+1
−1

if ri > rj
if ri < rj

(4)

∀(xi , ri ), (xj , rj ) ∈ T
In order to select a ranking function f that ﬁts the training
set T  , we construct the SVM model to solve the following
quadratic optimization problem:
minimize
w


subject to


1
w
 ·w
 +C
ξi,j
2
∀(xi , xj ) ∈ T  : zi,j 
w,
 xi − xj  ≥ 1 − ξi,j (5)
∀i∀j : ξi,j > 0

Denoting w
 ∗ as the weight vector generated by solving (5),
we deﬁne the risk scoring function fw ∗ , for assigning risk
scores to the feature vectors in the application intelligence
dataset:
f

w
∗

∗

= 
w
 , x

(6)

For any x ∈ X, the risk scoring function measures its
projection onto w
 ∗ , or the distance to a hyperplane whose
normal vector is w
 ∗ . Thus, the hyperplane is indeed the risk
assessment baseline.

3.3 Risk Meter
Risk meter measures the risks incurred by each installed
application including those are trusted by the user. Note
that (6) gives a signed distance. We use the absolute value
to represent the deviation and risk. The risks incurred by
an application ai are the cumulative risks of its runtime
behaviors:

|fw ∗ (x)|
(7)

x∈Dai

Another goal of the risk meter is to provide supporting
evidences to end-users. To this end, it presents the measured
risks at three levels of granularities.
Application: In the simplest form, the risk meter presents
a ranking of installed applications by their risks as a bar
chart. The X axis indicates the applications and the Y axis
indicates the risks. A user can trust an application if it is

less risky than her trusted ones. In contrast, an application
that is signiﬁcantly risky can also draw a user’s attention.
Note that the risk meter does not provide any technical explanation at this level.
Permission group: The ranking of applications may
seem unconvincing sometimes for users. In such a case,
the risk meter can provide risk composition by permission
groups which is represented as a pie chart. The pie chart intuitively reveals the proportion of the risks incurred by the
core functionalities of an application. As users have basic
knowledge of permission groups when they specify security
requirements, they should be able to interpret the risk composition correctly.
API calls and callbacks:
The evidences presented
at this level are intended for experienced security analysts
who are familiar with the security mechanisms under the
hood of Android. This is the raw data generated by the risk
scoring function. An analyst can inspect values of features
to reconstruct the semantic view of runtime behaviors.
Moreover, RiskMon allows a user to establish and revise her security requirements iteratively. RiskMon may
generate biased or unconvincing evidences as a user may
not have clear and accurate security requirements at the
very beginning of using RiskMon. Thus, a user can provide
her feedback by adjusting her security requirements and/or
adding more trusted applications. RiskMon also periodically updates the security assessment baseline for observed
new runtime behaviors. All of these enable RiskMon to
approximate an optimum risk assessment baseline to help
users make better decisions.

4.

IMPLEMENTATION AND EVALUATION

In this section we ﬁrst discuss a proof-of-concept implementation of RiskMon. Then, we present the results of our
online user study followed by two case studies. We conclude
our evaluation with the usability and performance of our
system.

4.1

Implementation and Experimental Setup

We implemented a proof-of-concept prototype of RiskMon on the Android mobile platform. In terms of continuous monitoring, we implemented a reference monitor for
Binder IPC by placing hooks inside the Binder userspace
library. The hooks tap into Binder transactions and log
the parcels with zlog3 which is a high-performance logging
library. In addition, we implemented automated risk assessment based on SVMLight4 and its built-in Gaussian radial
basis function kernel.
We designed and conducted a user study to evaluate the
practicality and usability of RiskMon. We hand-picked 10
applications (Table 2) that were mostly downloaded from
Google Play in their respective categories. We assumed that
all the participants trust them. Then we used participants’
security requirements for the 10 applications and their application intelligences to generate the baselines. We also randomly selected 4 target applications from the Top Charts of
Google Play to calculate their risks based on the generated
baselines, including: a) CNN App for Android Phones (abbreviated as CNN); b) MXPlayer; c) Pandora Internet Radio
(abbreviated as Pandora); and d) Walmart. For both trusted
3
4

https://github.com/HardySimpson/zlog
http://svmlight.joachims.org/

Table 1: Demographics of the Participants
Gender
Age

Education

Category
Male
Female
18-24
25-34
35-54
Graduated high school or equivalent
Some college, no degree
Associate degree
Bachelor’s degree
Post-graduate degree

# of users
29 (87.9%)
4 (12.1%)
15 (45.5%)
16 (48.5%)
2 (6.1%)
3 (9.1%)
6 (18.2%)
1 (3.0%)
11 (33.3%)
12 (36.4%)

(a) Chase Mobile

Table 2: Applications Assumed to be Trusted by the
Participants in the User Study
Application
AmazonMobile
BejeweledBlitz
ChaseMobile
Dictionary.com
Dropbox
Google+
GooglePlayMovies&TV
Hangouts(replacesTalk)
MoviesbyFlixster
Yelp

Category
Shopping
Game
Finance
Books & Reference
Productivity
Social
Media & Video
Communication
Entertainment
Travel & Local

(10) and target (4) applications, we collected their one-day
runtime behaviors on a Samsung Galaxy Nexus phone. In
addition, we developed a web-based system that acquires
a participant’s security requirements, feeds them to RiskMon and presents the results calculated by RiskMon to
the participant. A participant was ﬁrst presented with a
tutorial page that explains how to specify relevancy levels
as her security requirements. Then she was required to set
relevance levels for each permission group requested by each
trusted application after reading the application’s descriptions on Google Play. Afterwards, RiskMon generated a
risk assessment baseline for the participant based on her inputs and runtime behaviors of the 10 trusted applications.
Then RiskMon applied the baseline on each of the 14 applications, and displayed a bar chart that illustrates a ranking of 14 applications by their measured cumulative risks.
Finally, an exit survey was presented to collect the participant’s perceived usability of RiskMon. Our study protocol
was reviewed by our institution’s IRB. And we recruited
participants through university mailing lists and Amazon
MTurk. 33 users participated in the study and Table 1 lists
the demographics of them.

4.2 Empirical Results
4.2.1

Security Requirements

From our user study shown in Table 2, we highlight the
results of Chase Mobile and Dropbox because they both request some ambiguous permission groups that are hard to
justify for users. Figure 4 demonstrates the average relevancy levels set by the participants for each permission
group requested by Chase Mobile and Dropbox. The error
bars indicate the standard deviation.

(b) Dropbox
Figure 4: Average Relevancy Levels Specified by the
Participants for Chase Mobile and Dropbox

Chase Mobile is a banking application with functionalities like depositing a check by taking a picture and locating nearest branches. Apparently NETWORK is more relevant
than others as participants agree that Chase Mobile needs
to access the Internet. Even though Chase Mobile uses LOCATION to ﬁnd nearby bank branches and CAMERA to deposit
checks, both LOCATION and CAMERA have lower relevancy levels than NETWORK. We believe it is because some participants
do not have the experiences of using such functionalities,
but the averages are still higher than neutral. We can also
observe that SOCIAL_INFO falls below “neutral”, showing participants’ concerns of why Chase Mobile uses such information.
Dropbox is an online ﬁle storage and synchronization service. From its results, we identiﬁed an interesting permission group, APP_INFO, whose description in Android’s oﬃcial document is: group of permissions that are related to
the other applications installed on the system. This authoritative description does not provide any cue of negative impacts, which leads to user confusion as we can see
that APP_INFO has the largest standard deviation. STORAGE,
SYNC_SETTINGS and ACCOUNTS are all above “probably relevant” possibly due to their self-descriptive names that are
semantically close to Dropbox’s core functionalities.
Moreover, we noticed that the participants tend to set
higher relevancy levels for self-descriptive permission groups,
while they tend to be conservative for other permission groups.
We note that this does not aﬀect RiskMon in acquiring a
user’s security requirements, because RiskMon captures the
precedence of one permission group over another. Thus, the
least relevant permission group (e.g. SOCIAL_INFO of Chase
Mobile) always gets the highest risk scores for both trusted
and distrusted applications.

4.2.2

Application Risk Ranking

Figure 5 illustrates the ranking of 14 applications by their
average cumulative risk scores as measured by 33 risk assessment baselines generated for the participants. We can
see that MXPlayer (2.55) and Walmart (12.72) fall within
the trusted applications, while CNN (54.15) and Pandora
(69.22) are ranked with highest risk scores.
Note that both Pandora and CNN are renowned applications developed by well-trained developers. Seemingly,
they should use sensitive information appropriately. Hence,
we veriﬁed them by manually dissecting their API traces.
We found that they both stayed in the background and attempted to keep connected to remote servers. To this end,
they kept polling ConnectivityManager for a ﬁne-grained
state of the current network connection. This is an unexpected practice for both privacy and performance perspectives and the oﬃcial Android documents suggest developers
register CONNECTIVITY_CHANGE broadcasts5 to get connectivity updates accordingly instead of polling. On the contrary,
Hangouts incurred almost imperceptible amount of risks, although it has similar requirements for connectivity. Therefore, RiskMon showed that even popular applications might
use sensitive information in a way that incurs potential risks
for users.

4.3 Case Studies
In this section we evaluate the eﬀectiveness of our approach. Note that there is no ground truth of user’s expected
appropriate behaviors. Thus, we opt for two case studies on
two applications, SogouInput and PPS.TV. We speciﬁed the
relevancy levels for 10 trusted applications and generated a
risk assessment baseline. Then, we veriﬁed their identiﬁed
risk composition with manual analysis.
SogouInput is an input method based on the pinyin method
of romanization, and PPS.TV is a video streaming application similar to its counterparts such as Hulu and Netﬂix. Both of them are feature-rich, free and have accumulated over 5,000,000 installs on Google Play. We note
that PPS.TV and SogouInput request 22 and 29 permissions, respectively. The numbers of requested permissions
make them suspicious over-privileged or privacy-infringing
applications.
The measured cumulative risk scores are 179.0 for SogouInput and 366.9 for PPS.TV. Table 3 demonstrates the
risk composition of SogouInput and PPS.TV by their requested permission groups. First, the unusually large portion of PHONE_CALLS indicates signiﬁcant use of capabilities
related to making phone calls and reading unique identiﬁers.
We veriﬁed the corresponding API traces and revealed that
it attempted to read a user’s subscriber ID and device ID.
Second and more notably, SOCIAL_INFO contributed 4.02% of
the total risks incurred by SogouInput. We veriﬁed the corresponding API traces and found that SogouInput accessed
content://com.android.contacts and received a parcel of
384 bytes. Usually an Android application queries the contact application and receives only the entries a user picks,
which is several bytes long. On the contrary, SogouInput attempted to dump the whole contacts data repository. Similar to SogouInput, PPS.TV utilized permissions related to
PHONE_CALL. In addition to reading a user’s device ID and
5

http://developer.android.com/training/
monitoring-device-state/connectivity-monitoring.
html

Table 3: Risk Composition by Permission Groups of
Applications in Case Studies
Application

SogouInput

PPS.TV

Permission Group
LOCATION
NETWORK
PHONE CALLS
SOCIAL INFO
Total:
LOCATION
NETWORK
PHONE CALLS
Total:

Risk Score
5.6 (3.13%)
104.4 (58.29%)
61.8 (34.56%)
7.2 (4.02%)
179.0 (100%)
26.0 (7.09%)
108.3 (29.52%)
232.6 (63.40%)
366.9 (100%)

Table 4: Usability Evaluation Results
Metric
Likeability
Simplicity
Risk perception

Average
0.811
0.674
0.758

Lower bound on 95%
confidence interval
0.797
0.645
0.751

subscriber ID, it also registered a callback to receive events
of call states. We note that this allows PPS.TV to read the
number of incoming calls.
The results leave much room for imagination: how come
an input method and a video streaming application need capabilities related to PHONE_CALLS, LOCATION and SOCIAL_INFO?
Possibly users get personalized services by disclosing these
information. However it comes with a price of privacy. RiskMon highlights the risks so that users can weigh the beneﬁt
and relevant cost by themselves.

4.4

System Usability

The criteria for usability were split into three areas: likeability, simplicity and risk perception. Likeability is a measure of a user’s basic opinion towards automated risk assessment. This identiﬁes whether users would like to accept
the proposed mechanism. Simplicity is a measure of how
intuitive the concepts and procedures are, which is useful in
evaluating the burden placed on users. Risk perception is a
measure of a user’s perceived awareness of risks through risk
assessment, which evaluates how users interpret the risks as
presented by RiskMon.
After using RiskMon, an exit survey was presented to collect users’ perceived usability of RiskMon. In the survey
we asked users questions on likeability (e.g. “indicate how
much you like using your trusted apps to set a baseline”),
simplicity (e.g. “do you agree that RiskMon requires less
mental eﬀorts in risk assessment”), and risk perception (e.g.
“do you feel the increased awareness of the risks of your
installed applications”). Questions were measured with a
ﬁve-point Likert scale. A higher score indicates a positive
opinion or agreement, while a lower score indicates a negative one or disagreement. Then scores were adjusted to [0,1]
for numerical analysis.
We analyzed a 95% conﬁdence interval for users’ answers.
Speciﬁcally we are interested in determining the average
user’s minimum positive opinions. Hence, we looked at the
lower bound of the conﬁdence interval. Table 4 shows that
an average user asserts 79.7% positively on likeability, 64.5%
on simplicity and 75.1% on risk perception. The results show
usability of RiskMon with the above-average feedback.

Figure 5: Average Cumulative Risk Scores Measured by the Participants’ Risk Assessment Baselines

Table 5: Microbenchmark Results
Benchmark
Feature extraction
Baseline generation (10 apps)
Risk measurement (per app)

Average (s)
8.27
289.56
0.55

Standard
Deviation (s)
0.07
235.88
0.17

4.5 System Overhead
To understand the performance overhead of RiskMon,
we performed several microbenchmarks. The experiments
were performed on a Samsung Galaxy Nexus phone with
a 1.2GHz dual-core ARM CPU. The phone runs Android
v4.2.2 and RiskMon built on the same version. Table 5
shows the average results.
Feature extraction: The application intelligence aggregator extracted feature vectors from the raw API traces of
33,368,458 IPC transactions generated by 14 applications in
one day. We measured the CPU-time used by parsing the
API traces and generating the feature vectors. The average time is 8.27 seconds, which is acceptable on a resourceconstrained mobile device.
Baseline generation: We ran baseline generation based
on the input acquired in the online user study. The processing time varies for diﬀerent participants, while the average
time is approximately 289.56 seconds due to the computation complexity of the radial basis function kernel of SVMLight.
Risk measurement: Applying the risk assessment baseline is much faster than baseline generation. We measured
the time taken to apply a risk assessment baseline on 14 applications. The average time per application is 0.55 seconds,
which is imperceptible and demonstrates the feasibility of
repeated risk assessment.
Finally, we anecdotally observed that it took 5-10 minutes for the participants to set relevancy levels for 10 applications. This usability overhead is acceptable compared to
the lifetime of a risk assessment baseline.

5. DISCUSSION
To capture actual risks incurred by applications used by a
user, RiskMon fundamentally requires running them on the
user’s device. We note that 48.5% of the respondents in our
user study claimed that they often test drive applications
on their devices. RiskMon itself does not detect or prevent sensitive data from leaving users’ devices. We would

recommend users use on-device isolation mechanisms (e.g.
Samsung KNOX6 ) or data shadowing (e.g. [22]). However,
it is far from perfect for running untrusted applications on
trusted operating systems.
RiskMon requires users to specify security requirements
through permission groups. While most of the frequently
requested permission groups are self-descriptive (e.g. LOCATION and CAMERA), some are ambiguous (e.g. APP_INFO) and
contain low-level APIs only known to developers. Although
we identify permission groups as an appropriate trade-oﬀ
between granularity and usability, we admit that permission
groups are still a partial artifact in representing sensitive resources for users. Note that we choose permission groups
only to demonstrate the feasibility of our approach of security requirement communication. As our future work, we
plan to develop a systematic and intuitive taxonomy of sensitive resources on mobile devices to facilitate more eﬀective
requirement communication. Moreover, generating a risk
assessment baseline is a compute-intensive task that does
not quite ﬁt resource-constrained mobile devices. Thus, we
plan to oﬄoad such a task to trusted third-parties or users’
public or private clouds in the future.
Regarding our current implementation of RiskMon, it
does not address: (1) interactions between third-party applications; and (2) interactions that do not utilize Binder.
This indeed illustrates potential attack vectors that can bypass RiskMon. Unauthorized accesses on resources of thirdparty applications [11] might be possible because such resources are not protected by system permissions. Also, two
or more malicious applications can collude via local sockets
or covert channels and evade the Binder-centric reference
monitor in RiskMon. For our future work, we will extend
our framework to maximize the coverage of attack vectors
in our approach.

6.

RELATED WORK

Analysis of meta information:
Meta information
available on application markets provides general descriptions of applications. Recent work has proposed techniques
to distill risk signals from them. Kirin [16] provides a conservative certiﬁcation technique that enforces policies to mitigate applications with risky permission combinations at install time. Sarma et al. [33] propose to analyze permissions
alongside with application categories in two large application
6
http://www.samsung.com/global/business/mobile/
solution/security/samsung-knox#con02

datasets. Peng et al. [28] use probabilistic generative models
to generate risk scoring schemes that assign comparative risk
scores on applications based on their requested permissions.
In addition to analysis on permissions, Chia et al. [10] and
Chen et al. [9] performed large-scale studies on application
popularity, user ratings and external community ratings. In
particular, Pandita et al. proposed WHYPER [26] which
automatically infers an application’s necessary permissions
from its description in natural languages. However, meta information does not accurately describe the actual behaviors
of applications. RiskMon uses meta information to provide
contextual information so as to complement the analysis on
the runtime behaviors for risk assessment.
Static and dynamic analysis: Analysis on execution
semantics of applications, such as static analysis of code and
dynamic analysis of runtime behaviors, can reveal how applications use sensitive information. Stowaway [17] extracts
API calls from a compiled Android application and reveals
its least privilege set of permissions. Enck et al. [15] developed a decompiler to uncover usage of phone identiﬁers and
locations. Pegasus [8] checks temporal properties of API
calls and detects API calls made without explicit user consent. TaintDroid [14] uses dynamic information ﬂow tracking to detect sensitive data leaking to the network. Regarding malware analysis, DroidRanger [40] and RiskRanker [20]
are systematic and comprehensive approaches that combine
both static and dynamic analysis to detect dangerous behaviors. DroidScope [39] reconstructs semantic views to collect
detailed execution traces of applications. These work focuses
on fundamental challenges for assessing actual risks incurred
by applications. However, they do not provide a baseline to
capture the appropriate behaviors under diverse contexts of
diﬀerent applications. Thus, their approaches are more intended for security analysts rather than end users.
Mandatory access control frameworks: RiskMon
includes a lightweight reference monitor for Binder IPC.
While it monitors IPC transactions for risk assessment, several frameworks mediate IPC channels as part of their approaches to support enhanced mandatory access control (MAC).
SEAndroid [34] brings SELinux kernel-level MAC to Android. It adds new hooks in the Binder device driver to
address Binder IPC. Quire [13] provides IPC provenance by
propagating veriﬁable signatures along IPC chains so as to
mitigate confused deputy attacks. Aurasium [38] uses libc
interposition to eﬃciently monitor IPC transactions without
modifying the Android platform. FlaskDroid [7] provides
ﬂexible MAC on multiple layers, which is tailored the peculiarity of the Android system. Along these lines, RiskMon
captures Binder transactions with a ﬁne-grained scheme to
facilitate risk assessment on applications’ runtime behaviors.

7. CONCLUSION
In this paper, we have presented RiskMon that continuously and automatically measures risks incurred by a user’s
installed applications. RiskMon has leveraged machinelearned ranking to generate a risk assessment baseline from
a user’s coarse expectations and runtime behaviors of her
trusted applications. Also we have described a proof-ofconcept implementation of RiskMon, along with the extensive evaluation results of our approach.

8.

ACKNOWLEDGEMENTS

This work was supported in part by the NSF grant (CNS0916688). Any opinions, ﬁndings, and conclusions or recommendations expressed in this material are those of the
authors and do not necessarily reﬂect the views of the funding agencies. We would also like to thank the anonymous
reviewers for their valuable comments that helped improve
the presentation of this paper.

9.

REFERENCES

[1] App review - apple developer. https://developer.
apple.com/support/appstore/app-review/, 2013.
[2] C. Alberts, A. Dorofee, J. Stevens, and C. Woody.
Introduction to the octave approach. Pittsburgh, PA,
Carnegie Mellon University, 2003.
[3] C. J. Alberts and A. Dorofee. Managing information
security risks: the OCTAVE approach.
Addison-Wesley Longman Publishing Co., Inc., 2002.
[4] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie.
Pscout: analyzing the android permission
speciﬁcation. In Proceedings of the 2012 ACM
conference on Computer and communications security,
pages 217–228. ACM, 2012.
[5] D. Balzarotti, M. Cova, C. Karlberger, E. Kirda,
C. Kruegel, and G. Vigna. Eﬃcient detection of split
personalities in malware. In Proceedings of the 19th
Annual Network and Distributed System Security
Symposium, 2010.
[6] D. Barrera, H. G. Kayacik, P. C. van Oorschot, and
A. Somayaji. A methodology for empirical analysis of
permission-based security models and its application
to android. In Proceedings of the 17th ACM conference
on Computer and communications security, pages
73–84. ACM, 2010.
[7] S. Bugiel, S. Heuser, and A.-R. Sadeghi. Flexible and
ﬁne-grained mandatory access control on android for
diverse security and privacy policies. In 22nd USENIX
Security Symposium (USENIX Security 2013).
USENIX, 2013.
[8] K. Z. Chen, N. Johnson, V. D’Silva, S. Dai,
K. MacNamara, T. Magrino, E. Wu, M. Rinard, and
D. Song. Contextual policy enforcement in android
applications with permission event graphs. 2013.
[9] Y. Chen, H. Xu, Y. Zhou, and S. Zhu. Is this app safe
for children?: a comparison study of maturity ratings
on android and ios applications. In Proceedings of the
22nd international conference on World Wide Web,
pages 201–212. International World Wide Web
Conferences Steering Committee, 2013.
[10] P. H. Chia, Y. Yamamoto, and N. Asokan. Is this app
safe?: a large scale study on application permissions
and risk signals. In Proceedings of the 21st
international conference on World Wide Web, pages
311–320. ACM, 2012.
[11] E. Chin, A. P. Felt, K. Greenwood, and D. Wagner.
Analyzing inter-application communication in android.
In Proceedings of the 9th international conference on
Mobile systems, applications, and services, pages
239–252. ACM, 2011.
[12] E. Chin, A. P. Felt, V. Sekar, and D. Wagner.
Measuring user conﬁdence in smartphone security and

[13]

[14]

[15]

[16]

[17]

[18]

[19]

[20]

[21]

[22]

[23]

[24]

[25]

privacy. In Proceedings of the Eighth Symposium on
Usable Privacy and Security, page 1. ACM, 2012.
M. Dietz, S. Shekhar, Y. Pisetsky, A. Shu, and D. S.
Wallach. Quire: Lightweight provenance for smart
phone operating systems. In USENIX Security
Symposium, 2011.
W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung,
P. McDaniel, and A. Sheth. Taintdroid: An
information-ﬂow tracking system for realtime privacy
monitoring on smartphones. In OSDI, volume 10,
pages 255–270, 2010.
W. Enck, D. Octeau, P. McDaniel, and S. Chaudhuri.
A study of android application security. In Proceedings
of the 20th USENIX conference on Security, SEC’11,
pages 21–21, Berkeley, CA, USA, 2011. USENIX
Association.
W. Enck, M. Ongtang, and P. McDaniel. On
lightweight mobile phone application certiﬁcation. In
Proceedings of the 16th ACM conference on Computer
and communications security, pages 235–245. ACM,
2009.
A. P. Felt, E. Chin, S. Hanna, D. Song, and
D. Wagner. Android permissions demystiﬁed. In
Proceedings of the 18th ACM conference on Computer
and communications security, pages 627–638. ACM,
2011.
A. P. Felt, S. Egelman, M. Finifter, D. Akhawe,
D. Wagner, et al. How to ask for permission. In Proc.
USENIX Workshop on Hot Topics in Security, 2012.
A. P. Felt, E. Ha, S. Egelman, A. Haney, E. Chin, and
D. Wagner. Android permissions: User attention,
comprehension, and behavior. In Proceedings of the
Eighth Symposium on Usable Privacy and Security,
page 3. ACM, 2012.
M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang.
Riskranker: scalable and accurate zero-day android
malware detection. In Proceedings of the 10th
international conference on Mobile systems,
applications, and services, pages 281–294. ACM, 2012.
R. Herbrich, T. Graepel, and K. Obermayer. Large
margin rank boundaries for ordinal regression.
Advances in Neural Information Processing Systems,
pages 115–132, 1999.
P. Hornyack, S. Han, J. Jung, S. Schechter, and
D. Wetherall. These aren’t the droids you’re looking
for: retroﬁtting android to protect data from
imperious applications. In Proceedings of the 18th
ACM conference on Computer and communications
security, pages 639–652. ACM, 2011.
T. Joachims. Optimizing search engines using
clickthrough data. In Proceedings of the eighth ACM
SIGKDD international conference on Knowledge
discovery and data mining, pages 133–142. ACM,
2002.
J. A. Krosnick and D. F. Alwin. An evaluation of a
cognitive theory of response-order eﬀects in survey
measurement. Public Opinion Quarterly,
51(2):201–219, 1987.
H. Lockheimer. Android and security - oﬃcial google
mobile blog. http://googlemobile.blogspot.com/
2012/02/android-and-security.html, 2012.

[26] R. Pandita, X. Xiao, W. Yang, W. Enck, and T. Xie.
Whyper: Towards automating risk assessment of
mobile applications. In Proceedings of the 22nd
USENIX conference on Security symposium. USENIX
Association, 2013.
[27] M. Panzarino. Google announces 900 million android
activations, 48 billion apps downloaded, 2013.
[28] H. Peng, C. Gates, B. Sarma, N. Li, Y. Qi,
R. Potharaju, C. Nita-Rotaru, and I. Molloy. Using
probabilistic generative models for ranking risks of
android apps. In Proceedings of the 2012 ACM
conference on Computer and communications security,
pages 241–252. ACM, 2012.
[29] M. Rabin. Risk aversion and expected-utility theory:
A calibration theorem. Econometrica,
68(5):1281–1292, 2000.
[30] V. Rastogi, Y. Chen, and W. Enck. Appsplayground:
automatic security analysis of smartphone
applications. In Proceedings of the third ACM
conference on Data and application security and
privacy, pages 209–220. ACM, 2013.
[31] A. Robertson. Apple passes 50 billion app store
downloads, 2013.
[32] F. Roesner, T. Kohno, A. Moshchuk, B. Parno, H. J.
Wang, and C. Cowan. User-driven access control:
Rethinking permission granting in modern operating
systems. In Security and Privacy (SP), 2012 IEEE
Symposium on, pages 224–238. IEEE, 2012.
[33] B. P. Sarma, N. Li, C. Gates, R. Potharaju,
C. Nita-Rotaru, and I. Molloy. Android permissions: a
perspective combining risks and beneﬁts. In
Proceedings of the 17th ACM symposium on Access
Control Models and Technologies, pages 13–22. ACM,
2012.
[34] S. Smalley and R. Craig. Security enhanced (se)
android: Bringing ﬂexible mac to android. In Proc. of
the 20th Network and Distributed System Security
Symposium (NDSS 2013), San Diego, CA, 2013.
[35] G. Stoneburner, A. Goguen, and A. Feringa. Risk
management guide for information technology
systems. Nist special publication, 800(30):800–30, 2002.
[36] Y. Wang, J. Zheng, C. Sun, and S. Mukkamala.
Quantitative security risk assessment of android
permissions and applications. In Data and
Applications Security and Privacy XXVII, pages
226–241. Springer, 2013.
[37] D. M. Wilkinson. Strong regularities in online peer
production. In Proceedings of the 9th ACM conference
on Electronic commerce, pages 302–309. ACM, 2008.
[38] R. Xu, H. Saı̈di, and R. Anderson. Aurasium:
Practical policy enforcement for android applications.
In Proceedings of the 21st USENIX Security
Symposium, 2012.
[39] L. K. Yan and H. Yin. Droidscope: seamlessly
reconstructing the os and dalvik semantic views for
dynamic android malware analysis. In Proceedings of
the 21st USENIX Security Symposium, 2012.
[40] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang. Hey, you,
get oﬀ of my market: Detecting malicious apps in
oﬃcial and alternative android markets. In
Proceedings of the 19th Annual Network and
Distributed System Security Symposium, 2012.

Publications

2015

ACTRA - A Case Study for Threat Information
Sharing
Jon C. Haass
Embry-Riddle Aeronautical University - Prescott, haassj@erau.edu

Gail-Joon Ahn
Arizona State University at the Tempe Campus

Frank Grimmelmann
ACTRA, Inc.

Follow this and additional works at: http://commons.erau.edu/publication
Part of the Defense and Security Studies Commons, Other Political Science Commons, and the
Policy Design, Analysis, and Evaluation Commons
Scholarly Commons Citation
Haass, J. C., Ahn, G., & Grimmelmann, F. (2015). ACTRA - A Case Study for Threat Information Sharing. CCS'15 The 22nd ACM
Conference on Computer and Communications Security, (). http://dx.doi.org/http://doi.org/10.1145/2808128.2808135

This Article is brought to you for free and open access by ERAU Scholarly Commons. It has been accepted for inclusion in Publications by an
authorized administrator of ERAU Scholarly Commons. For more information, please contact commons@erau.edu.

ACTRA – A case study for threat information sharing
Jon C. Haass

Gail-Joon Ahn

Frank Grimmelmann

Embry-Riddle University
3700 Willow Creek Road
Prescott, AZ, 86301
+1-928-777-6975

Arizona State University
699 S. Mill Avenue
Tempe, AZ 85281
+1-480-965-9007

ACTRA, Inc.
2102 Encanto Blvd, MD 3900
Phoenix, AZ 85009
+1-623-551-1526

jon.haass@erau.edu

gahn@asu.edu

fgrimmelman@actraaz.org

ABSTRACT
This paper provides a case study for information sharing within a
public/private not-for-profit partnership organization called
ACTRA – Arizona Cyber Threat Response Alliance, Inc.. This
initiative is comprised of public and private entities with
government agencies as invited guests aligned around the goal of
improved response to cyber security events. Technical, political,
legal and organizational issues arise when multiple parties attempt
to exchange information in a formal setting. Benefits and specific
solutions developed are discussed. The study concludes with
several areas for future improvement and investigation as well as
recommendations for newly forming sharing groups.

Categories and Subject Descriptors
D.4.6 [Security and Protection]: Information and Data Sharing –
access controls, information flow controls, authentication See
also K.6.5. Intellectual Property, Government Privacy and Ethics.

General Terms
Security and Privacy

Keywords
TAXII, STIX, Cyber Threat Intelligence Sharing, ISAO, ISAC

1. INTRODUCTION
The conceptual benefit of sharing cyber threat information is at
the heart of the current anti-malware industry led by companies
such as McAfee and Symantec. Information sharing among
different organizations without that same central provider has
been evolving in pockets with the FS-ISAC, formed in 1999, one
of the earliest examples. The move from theoretical benefits to
practical implementation of multi organization cyber threat
information sharing remains a challenge. New Information
Sharing and Analysis Organizations (ISAO) constructs are being
encouraged and partially funded by government initiatives under
the Department of Homeland Security (DHS).
Many organizations and participants today agree on why
information sharing is important. In a recent report to Congress
advantages described included greater agility and situational
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that
copies bear this notice and the full citation on the first page. To copy
otherwise, or republish, to post on servers or to redistribute to lists,
requires prior specific permission and/or a fee.
ACM CCS Conference’15, October 12-16, 2015, Denver, CO, USA.
Copyright 2015 ACM 1-58113-000-0/00/0010 …$15.00.

awareness as well as a “deeper understanding of threat actors’
tactics, techniques and procedures (TTPs)” [1]. If properly
developed, shared information should lower the cost of defense
and increase the ability to discover compromised systems. A
survey of IT professionals (not all of whom were in formal shared
information networks) reported, however, that most of the threat
information they received was not timely or specific enough
(actionable) to meet their perceived need [2].
Cyber security professionals are today primarily embedded in the
IT organization though it is now clear that the impact to a
company or organization goes beyond the classic bounds of the
technical computer domain. Product information, business
strategies, sales and marketing contact information, and legal
documents stored electronically are supported by IT but are
fundamentally controlled and used by other organizations. Access
to these, their linkage with email accounts, web applications and
documents stored on a variety of platforms including mobile
devices and cloud systems stretches the ability of an IT
department to protect the data [3].
Furthermore, in the first version of the National Institute for
Standards and technology (NIST) cyber security framework, it is
highlighted that access to threat information including TTP is
critical to the development and maintenance of a robust cyber
security plan and implementation within an organization [4].
One of the goals of ACTRA and similar ISAO’s is to break down
the resistance to information sharing and engage not only the
technical workers but also the business leadership. The high level
management teams are best equipped to see the overall scale of
risk and reward beyond just the direct cost of spending on cyber
security. The success of information sharing requires the
development of metrics that can be gathered, monitored, analyzed,
and then effectively communicated to achieve improvement as
well as to continue justifying the expense of the practice [5].
A number of potential models for effective information sharing
have been proposed. It is the community of interest that must
implement and investigate the results of corporate and
government information exchange where the vast bulk of critical
assets sought by adversaries reside [6]. Cyber crime, increasingly
the work of large networks of individuals, is best countered with a
similarly organized structure [7].

2. ACTRA FORMATION
ACTRA grew out of relationships developed with FBI’s
InfraGard and the Arizona Counter Terrorism Intelligence Center
(ACTIC). When the Presidential directive 16363 was signed, it
lent credibility to the concept of bringing private sector
representatives to the table. The organization is incorporated as a
not for profit company with a board, a technical group of subject

matter experts as well as an advisory board from private and
public sector entities. This structure divides along lines of
business, policy and technology with interchange as needed to
create a functioning solution for the different requirements of the
constituents.

What is the role of academic members beyond the obvious special
case of alignment as either a public institution or private entity?
For researchers and students in the field of cyber intelligence and
security, public policy and law, it is an excellent opportunity for
study and experience.

The ACTIC, formed in 2005, is a government sharing structure
that was to address the challenges for timely exchange of
intelligence and critical information among state, local and federal
public safety agencies and ultimately provide a real-time
information link with law enforcement and first responders [8].

3.2 Legal and Financial Matters

ACTRA built on experience gained through the efforts to bridge
tribal, state, local and federal agencies, adding the dimensions of
the private sector and support of academic interests. The
foundation of the effort rests upon the desire to improve security
without adding another layer of expense or process that would be
a burden to members, resulting in a flat responsive structure that
today operates in near real-time.
This regional, cross industry information sharing group (ISAO)
provides the opportunity to have in person meetings creating trust
helping bridge organizational reluctance. ACTRA today has
grown to include 14 of the 16 critical infrastructure sectors and is
offering a multi-sector, regional and nationally scalable solution.

3. CHALLENGES
In late 2012 there were few examples of cross sector cyber threat
information sharing models, most were ad hoc and primarily point
to point informal sharing among colleagues. Much of the success
was hidden and below the approval radar of the organizations in
which workers operated. However this type of activity does not
scale nor can it be funded to become institutional. It may rely on
single points of contact that could move to a different job position
losing that valuable connection. ACTRA on the other hand was
designed to be visible at the C level organization to foster the
needed support for the technology wizards that would ultimately
have the challenge of implementation.

3.1 Organizational Issues and Concerns
Marketing and awareness was an initial hurdle and required
communication via phone, email and at events in what seemed
like a 24/7 campaign. CSO and CEO alike were at first reluctant
to enter into a new type of unproven relationship with potentially
competitive organizations. Worse perhaps, what does it mean to
share information with the government? In the past most people
and companies seek to remain out of the range of government
interaction.
Corporate members could benefit from classified or sensitive data
available from government agencies. Sharing with other
corporations can likewise provide coverage that no single
company no matter the size can hope to access. Many companies
are not practiced in the handling and dissemination of external
data. What is the profit motive and accountability structure?
Government entities enjoy certain protection from liability,
however, they are at risk if classified data is shared in an
irresponsible manner.
This can compromise on going
enforcement or surveillance activities and be costly in terms of
lost efforts and use of government funds. Individuals can also be
harmed in their careers should problems arise within their
jurisdiction.

It was recognized from the outset that a template non-disclosure
agreement (NDA) followed by a membership agreement was the
best approach to meeting the legal requirements of the different
organizations. As reviews occurred the template rapidly matured
and was able to be operational within 3 months. This put the
Alliance, formed as a nonprofit corporation at the hub of the
communications since the agreement is with the Alliance not with
the peers. This solved the potential nightmare of N2 agreements
as the network grew.
Key to the relationship was the agreement to protect the names of
members in the organization unless they were willing to be
associated in a public manner.
Some companies and
organizations were concerned that they would become a greater
target should they be identified as an active participant in
information sharing. The actual threat versus perceived threat is
still something to be measured.
It was also discovered that different types of members would be
required in order to gain the advantage of disparate players. As
will be further discussed in future work, this is an issue
particularly for smaller organizations that may benefit from
sharing yet can not participate fully for either technical or
financial reasons.
Would there be increased liability for a company if it received
threat information that was not promptly utilized? This scenario is
playing out in a recently settled court case with retail giant Target
and its potential inaction in 2013 to vulnerabilities. The cost to a
company in legal and financial fallout could be large. Faced with
undefined risk, corporate members seek to limit their exposure
with legal and policy choices that are being discussed in new
legislative proposals.

3.3 Technical Hurdles
As security organizations scramble to keep up with the everevolving threats, each organization develops its own methods and
practices. Best practices differ by industry sector as well as by the
size of the organization. Sophisticated and larger organizations
with strong technical cyber security teams utilize network
monitoring, intrusion detection and other management tools.
These can integrate external threat data in manual or even
automatic modes. The mechanism for translating threats into a
standard format and framework has improved but is still in an
early stage. The decision to utilize STIX and TAXII as the
interface puts a burden on less able or resourced organizations
[9]. There is additional potential risk in connecting networks even
if the reason is for the sharing of sanitized indicators. This is
mitigated by implementation of appropriate internal processes.

4. SOLUTIONS AND BENEFITS
ACTRA was able to build on developments and experiments from
other sharing organizations such as the ISACs and government
inter agency experiences thanks to the broad skill set of the
different invested participants. Even so, solutions necessarily
have evolved and will continue to shift. As more organizations
join, the tools and techniques will mature.

It was recognized that information was valuable on different time
scales. The ideal state is for a threat or vulnerability to be
discovered rapidly, characterized and communicated in a timely
and actionable manner. As taken from Verizon’s 2013 study on
data breaches shown in Table 1, this desire does not match well
with the reality of cyber threats [10].
Table 1. Time scale disparity: compromise vs discovery; the
fraction of breaches and the time to damage and discovery.
Timescale

Minutes

Hours

Days

Weeks

Damage

23%

60%

13%

3%

Discovery

1%

9%

11%

78%

Damage is done in seconds, minutes, and hours while discovery
and containment are more often measured in days, weeks or even
months. Of course it is possible that the early stages of
reconnaissance and planning are also on a longer time scale.
These activities are today not visible. This issue points to the
leading edge of cyber security research – what tools and
techniques can close this gap? Is information sharing in the form
of a larger but more loosely coupled information gathering honey
net coupled with intelligent mining and pattern analysis able to
shift the advantage?

4.1 Situational Awareness – White Papers
At the policy and educational level, ACTRA has been successful
in raising awareness in the highest levels of organizations. These
products provide insights, best practices, and tips for improving
awareness among the users within an organization. One example
is a debrief on some of the valuable learning from the recent
incident where a corporation such as SONY was targeted by a
nation state level threat actor with intent to damage not just gain
financially or exfiltrate intellectual property. The papers are
appropriate to the slower time scale and meant to be consumed via
email. Their impact is on policies and procedures, offering a
reminder to practice and keep frameworks alive and changing.
Based upon comparisons within ACTRA, teams that have a clear
response plan and procedures, and most importantly practice
disaster scenarios, are better able to handle actual situations.
Sharing of these best practices, backup and recovery techniques
and example plans has been rated very useful.
Companies are also re-packaging threat information and white
papers, providing a version as educational outreach to include the
“end user” in the cyber security defense plan. Data inputs for
enriching threats intelligence is also available through outreach
via “crowd sourcing”. This changes it from some abstract item to
a current and actual example.

4.2 News and Blog Site
ACTRA has developed an invitation only site to allow members
to access information on their schedule rather than push via email.
A user can then request notification when a new entry of interest
is posted. Information is categorized based on the survey
responses for types relevant to the member. The site has an
editorial board and a process for creating articles, alerts, and
intelligence briefs. Members can also contribute posts or
comments. This is successfully utilizing university students to
seek relevant material via open source (OSINT) methods, which

provides an excellent experience for the students and a cost
effective resource to the Alliance.

4.3 Alerts
More actionable and timely are the official use only alerts
including FOUO information with specific data from on-going
investigations, analysis or active events. Though these may still
be old compared to the actual initial breach, it is early in the
analysis lifecycle so not all attribution or analysis is available.
Examples include potential IP addresses, web addresses, code
samples, and hash signatures associated with a specific known
event. This can be utilized by an IT organization to update
firewall or intrusion detection systems (IDS) rules, compare with
logs from their own organization network feeds and potentially
create additional data from their early alert. ACTRA disseminates
these in both classified and un-classified settings through its
vetted and pre-trusted relations.
This is one of the more sensitive types of communication as it
represents information that, if leaked, could alert the attacker of
the ability to identify possibly causing them to go underground,
change their TTP or accelerate plans with any existing campaign.
ACTRA has created limited distribution lists and the efforts are
rated as beneficial by recipients. They would like to see more
timely and actionable alerts and this is an area of future growth.
Separate classified briefings were held with invitation only and
pre-registered list used to validate attendees. This met the
security needs of the public agencies as well as provided greater
access to intelligence to the private sector participants.

4.4 Automated Data
The most exciting development is the acquisition and
dissemination of threat data that is closer to real time based on
information gathered from IDS, security information and event
management (SIEM) solutions and investigations. The goal of
this work is to achieve a machine to machine connection that can
be used along with other threat intelligence data in the security
operations center of member organizations. The groups have
agreed to utilize the NIST/MITRE standard STIX/TAXII.
Vendors are supporting the import of data and discussions are
beginning to consider creating an international standard. The
Alliance members’ implementation is still in the early stages.
Those participating indicate a strong interest in continuing and
rate the value of the effort as high.
The most successful operational efforts occur from member
contributions which can include zero day events. In the past
month automated feeds have come on-line with 30,000+ events all
available to members

4.5 Survey on Benefits
In the early stage of ACTRA formation, a survey was developed
to understand what kinds of information would be valuable, who
the expected audience was and how the data should be delivered.
This helped to develop the products and organize the Alliance.
The results were consistent with larger surveys [11] and the
survey included some questions to allow correlation. One of the
results found was that top leadership, including the board, is
generally uninvolved. This was important in the decision to target
the C-level and board level of member organizations with
appropriate materials.
The area of greatest interest by the survey respondents was
support or intelligence on advanced persistent threats (APT). This

has been a focus for the think tank group within the Alliance and
remains an area of future growth. New tools and incident
management systems appear promising and more are supporting
the chosen exchange formats.
A new follow up survey to assess how the Alliance has performed
in meeting the expectations of its members has begun. The full
results of that new survey, though not available yet, will help
guide new investments over the next year. Early indications point
to continued technical and monetary investment in ACTRA, a
desire to connect with other organizations and enhancement of the
real time components.

5. FUTURE EFFORTS
Continued operations and enhancement of the present set of
offerings point to a change in the all-volunteer model. The ability
to deliver products in a timely and predictable manner with loose
accountability is problematic. An aspect of this was apparent in
the predominance of larger corporations among the members.
Smaller organizations cannot spare their already limited resources
on a regular basis. The organization is looking at a variety of
different models as well as seeking other sources for funding to
create a core team.
As seen in recent security breaches and reported in surveys,
smaller companies in the supply chain have been targeted as
means to access ultimate higher value assets. It is critical to
include smaller members of the supply chain in future initiatives
and this has begun with educational efforts in cooperation with
the Arizona Tech Council. This will build the critical trust factor
without compromising the security of present members.

involvement for proactively coping with security threats and
exploits in a timely manner.
Recommendations: Other ISAO’s could benefit from the
experiences gained over the course of ACTRA early stages: 1)
Establish expectations and set realistic goals with at least semiannual review of progress; 2) Allow for changes in the plan,
admitting when adjustments are required; 3) Create an atmosphere
of transparency and inclusion. 4) Develop a core team and
leadership that is willing and able to meet regularly and often; 5)
Establish alternate representatives to maintain continuity; and 6)
Create a communication method for decisions, issues and
suggested solutions.

7. ACKNOWLEDGMENTS
Thanks to the core team board and the subject matter experts of
ACTRA that participated in interviews and dialogue. SWSIS
scholarship winner Evelyn Brown, a student in the Cyber program
at Embry-Riddle University, provided valuable assistance in
research and survey development.

8. REFERENCES
[1] Lewis, J.A., and Zheng, D.E., March, 2015, Cyber threat
information sharing recommendations to Congress and the
Administration. A report of the Center for Strategic and
International Studies.
[2] Ponemon, April 2014. Exchanging cyber threat intelligence:
there has to be a better way. Ponemon Institute Research
Report, Ponemon Institute LLC.

The success of using students to provide OSINT capabilities,
create reports, develop material for and manage blog sites and
newsletters will be continued. An initiative to provide internship
and co-op opportunities will allow a more reliable access to this
resource particularly in the summer months. Funding from grant
programs and the awareness of the workforce growth opportunity
for companies will assist this development.

[3] Peretti, K., 2014. Cyber threat intelligence: to share or not
to share Privacy and Security Law Report, Bureau of
National Affairs.

An area of research includes adding multiple authentication levels
in automated data to help reduce false positives. Another topic to
be explored is the identification of “critical” indicators.

[5] Fleming, M. H., Goldstein, E., and Roman, J. January, 2014.
Evaluating the impact of cybersecurity information sharing
on cyber incidents and their consequences. Homeland
Security Studies and Analysis Institute.

Experience with member companies and academic researchers has
earned trust and it is planned to make more data available for
testing newly developed algorithms and concepts. An area of
interest is creating weight methods to validate threat indicators
derived from different sources. This is relevant when the sources
have different methods, practices and standards for inclusion in
the set.

[4] NIST 2014. Framework for Improving Critical
Infrastructure Cybersecurity . Version 1.0. National Institute
of Standards and Technology. Accessed at:
http://www.nist.gov/cyberframework/.

[6] White, G. and Zhao, W., 2014, Designing a Formal Model
Facilitating Collaborative Information Sharing for
Community Cyber Security, System Sciences (HICSS), 47th
Hawaii International Conference on, pp.1987-1996.
doi: 10.1109/HICSS.2014.252 IEEE

This points to a variety of desired improvements in the data
sharing platform as companies and vendors learn better the
methods and automation to transform internal threat data into a
sanitized exchange format.

[7] Zhao, Z., Ahn, G.-J., Hu, H. and Mahi D. 2012,
SocialImpact: Systematic Analysis of Underground Social
Dynamics, 17th European Symposium on Research in
Computer Security (ESORICS), Pisa, Italy, September 1014, 2012

6. CONCLUSIONS

[8] ACTIC, 2005. Accessed at: azdohs.gov/Councils/acticoc.

With over two years as an organization, ACTRA continues to
grow in membership and scope of its offerings. Even though
some participants expressed their disappointment that progress
was not more rapid given the time investment, this case study
clearly indicated the importance and necessity of the systematic
procedures and framework that can facilitate threat information
sharing. Information sharing, like the popular social networking
activity, is a group activity and requires active and frequent

[9] Barnum, S. 2013. Standardizing cyber threat intelligence
information with the Structured Threat Information
eXpression (STIX). The MITRE Corporation.
[10] Verizon, 2013. Data Breach Investigations Report. Accessed
at: www.verizonenterprise.com/DBIR/
[11] PwC, 2015. Global State of Information Security 2015.
Accessed at: http://www.pwc.com/gsiss2015

Behind Closed Doors: Measurement and Analysis
of CryptoLocker Ransoms in Bitcoin
Kevin Liao, Ziming Zhao, Adam Doupé, and Gail-Joon Ahn
Arizona State University
{kevinliao, zmzhao, doupe, gahn}@asu.edu
called bitcoins1 , to other addresses by issuing transactions,
which are then broadcast to the public blockchain.
Since all confirmed transactions are visible to the public, the
blockchain’s inherent transparency has proven to be ineffective
in preserving the anonymity of its users (legitimate users
and cybercriminals alike). While Bitcoin addresses alone are
not explicitly tied to any real-world entities, a number of
recent research efforts have shown that monetary movements
and address links can be traced throughout the blockchain
data structure [3]–[8]. Even though there have been many
attempts to enhance user privacy with varying degrees of
success (i.e. generating multiple addresses, using bitcoin mixers
such as Bitcoin Fog [8], or using privacy-enhancing overlays
such as Coinjoin [9]), user privacy is further undermined
when real-world information and quasi-identifiers found on
the Internet can be imputed to users’ Bitcoin addresses. Given
Bitcoin’s meteoric rise in popularity and scale, such a condition
was inevitable and the overlap between publicly available
data and blockchain data has improved identification and
attribution throughout a vast, connected network of users—
there are addresses tied to forum usernames, anonymous online
marketplaces, Bitcoin exchanges, and popular Bitcoin services.
Privacy-preserving online services, such as the Tor hidden
network [10] and the Bitcoin system, while undoubtedly
useful in many aspects, play nontrivial roles in the burgeoning
I. I NTRODUCTION
cybercrime landscape. The fact remains that an elegant solution
for distinguishing legitimate and illicit use of these services
Increasingly, Bitcoin [1] is becoming a staple utility among is far from reach since the goals of Tor, Bitcoin, and the like
cybercriminals [2]—two of the digital currency’s main attrac- are to protect privacy en masse. While Bitcoin does enable
tions are its provisions for pseudoanonymity and its irreversible criminal enterprises to better obfuscate money laundering
transaction protocol. Unfortunately, these provisions engender schemes compared to traditional financial systems, we have
the dichotomous incentives between legitimate users, who wish seen that digital footprints embedded in the Bitcoin blockchain
to transfer money efficiently and securely, and cybercriminals, can reveal salient information about its users. Given the recent
who leverage these properties to commit irrevocable and prevalence of CryptoLocker [11] — a family of ransomware
supposedly untraceable financial fraud.
that encrypts files on a victim’s system and demands a ransom
Although the notion of digital currencies has existed long to be paid (through MoneyPak or Bitcoin) for the decryption
before Bitcoin’s debut, Bitcoin was proposed by an individual key — from September 2013 through early 2014, we use this as
under the pseudonym Satoshi Nakamoto in 2008. Nakamoto an opportunity to better understand the mechanics of a digital
introduced a distributed public ledger that serializes a record money laundering economy and to generate threat intelligence
of all confirmed transactions known as the blockchain. A fun- on brazen cybercrimes. More generally, we aim to answer the
damental breakthrough in technology, the blockchain enables who, why, and how behind CryptoLocker in hopes that our
the Bitcoin system to operate under a decentralized peer-to- findings may be extendable to future cybercrime forensics and
peer network where users are identifiable by public keys, or
more commonly referred to as Bitcoin addresses, intended
1 The Bitcoin system and peer-to-peer network are referred to as “Bitcoin”
to provide pseudonymity. Users can transfer digital currency, while the unit of currency is referred to as “bitcoin” or abbreviated as “BTC”.

Abstract—Bitcoin, a decentralized cryptographic currency that
has experienced proliferating popularity over the past few years,
is the common denominator in a wide variety of cybercrime.
We perform a measurement analysis of CryptoLocker, a family
of ransomware that encrypts a victim’s files until a ransom
is paid, within the Bitcoin ecosystem from September 5, 2013
through January 31, 2014. Using information collected from
online fora, such as reddit and BitcoinTalk, as an initial starting
point, we generate a cluster of 968 Bitcoin addresses belonging
to CryptoLocker. We provide a lower bound for CryptoLocker’s
economy in Bitcoin and identify 795 ransom payments totalling
1,128.40 BTC ($310,472.38), but show that the proceeds could
have been worth upwards of $1.1 million at peak valuation. By
analyzing ransom payment timestamps both longitudinally across
CryptoLocker’s operating period and transversely across times
of day, we detect changes in distributions and form conjectures
on CryptoLocker that corroborate information from previous
efforts. Additionally, we construct a network topology to detail
CryptoLocker’s financial infrastructure and obtain auxiliary information on the CryptoLocker operation. Most notably, we find
evidence that suggests connections to popular Bitcoin services,
such as Bitcoin Fog and BTC-e, and subtle links to other
cybercrimes surrounding Bitcoin, such as the Sheep Marketplace
scam of 2013. We use our study to underscore the value of
measurement analyses and threat intelligence in understanding
the erratic cybercrime landscape.
Index Terms—Bitcoin, CryptoLocker, cybercrime, ransomware, security.

analytics. Our contributions are the following:
• We design and implement a framework that collects data
from the blockchain and automatically identifies ransom
payments to Bitcoin addresses belonging to CryptoLocker.
From this, we measure CryptoLocker’s economy in Bitcoin
and provide a lower-bound estimate of financial damages
from September 5, 2013 through January 31, 2014.
• We present a novel approach to analyzing Bitcoin transactions by examining ransom payment timestamps both
longitudinally across CryptoLocker’s operating period, as
well as tranversely across times of day, to distinguish
trends and changes in timestamp distributions.
• We construct a non-trivial, topological network of CryptoLocker addresses and systematically examine CryptoLocker’s financial infrastructure and money laundering
strategies. By leveraging external, real-world data, we
find connections to popular services such as Bitcoin Fog
and BTC-e, and speculate connections to other Bitcoin
cybercrime, such as the Sheep Marketplace heist.
II. BACKGROUND
To understand our analysis of the CryptoLocker economy,
we first discuss the Bitcoin protocol in Section II-A, and we
next discuss the CryptoLocker ransomware in Section II-B.
A. Anatomy of a Bitcoin Transaction
Bitcoin is a decentralized cryptographic currency that was
proposed by Satoshi Nakamoto in 2008 [1]. A bitcoin can
be abstracted as a chain of transactions among owners who
are identifiable by public keys generated from an asymmetric
encryption scheme2 . We will refer to these public keys as
Bitcoin addresses, or simply addresses, throughout the rest of
this paper.
To transfer bitcoins, a user issues a transaction, which
consists of a set of inputs, a set of outputs, and a change
address. The inputs are Bitcoin addresses that belong to the
payer. The outputs are Bitcoin addresses that identify the payee
accounts, and the change address (which is optional) is where
the leftover bitcoins from the transactions are sent (the change
address belongs to the payer). Bitcoin’s transaction protocol
stipulates that inputs to a new transaction must reference the
exact value of outputs from previous transactions. In other
words, users must specify from whom they received the bitcoins,
thus forming a chain of transactions, and inputs to a new
transaction may reference as many previous transactions needed
to sufficiently fund the new output. These are known as multiinput transactions. Finally, the payer digitally signs a hash3 of
the transaction from which he or she received the bitcoins and
the public key address of the payee.
We illustrate Bitcoin’s transaction protocol in Figure 1. We
see that there are three transactions, A, B, and C, and we will
refer to their respective owners as Alice, Bob, and Charlie. In
transaction A, a transaction of 2.0 BTC sent to Alice is used as
2 Elliptic

Curve Digital Signature Algorithm (ECDSA)

3 SHA-256

Fig. 1. The diagram illustrates the anatomy of bitcoin transactions. We have
transactions A, B, and C owned by Alice, Bob, and Charlie, respectively. We
can see that previous transactions to Alice and Bob are referenced in their
respective transactions to Charlie, forming a chain of transactions.

an input to a transaction of 1.5 BTC to Charlie. Since the input
value exceeds the output value, the remaining 0.5 BTC is sent to
a change address belonging to Alice. In transaction B, we see a
similar scenario in which Bob transfers 1.0 BTC to Charlie, but
a change address is not necessary because the input and output
values were equivalent. In transaction C, we see that Charlie
transfers 2.0 BTC to an unnamed user. To issue this transaction,
transaction C references the two previous transactions, from
Alice and Bob, that Charlie received as inputs. Again, the total
input value exceeds the required output value, so 0.5 BTC are
sent to a change address belonging to Charlie.
We can see that the validity of a bitcoin is dependent on
the correctness of each signature in the transaction chain, it is
simple to verify a transaction’s history but difficult to tamper
with confirmed transactions that are deeply embedded in the
blockchain (usually six blocks of confirmation is considered
secure against double-spending attacks [12]). Therefore, Bitcoin
transactions are essentially irreversible. This feature, coupled
with Bitcoin’s pseudonymity, enables cybercriminals to commit
financial fraud that is virtually impossible to reverse and
difficult to trace.
B. CryptoLocker Ransomware
On September 5, 2013, CryptoLocker emerged as a new
family of ransomware that encrypted files on a victim’s system
until a ransom is paid [11]. The decryption keys were withheld
by the threat actors who demanded ransoms to be paid either
through MoneyPak or Bitcoin within 72 hours, otherwise the
decryption keys would (allegedly) be destroyed and recovery
of the encrypted files would be virtually impossible.
CryptoLocker’s infection vector took two forms. In its initial
release, CryptoLocker threat actors primarily targeted business
professionals via spam emails taking the form of “customer
complaints” against recipients’ organizations. Malicious executable files were attached in ZIP archives, which would
aggressively encrypt all the files on a system if opened. Later
versions of CryptoLocker, beginning on October 7, 2013, were
distributed through Gameover ZeuS [13], a peer-to-peer botnet
that used Cutwail spam botnet to send massive amounts of
spam email impersonating well-established online retailers and

III. M EASUREMENT M ETHODOLOGY
We next explain our approach to collecting information
from the blockchain and various online fora in an effort
to measure CryptoLocker’s economy and generate threat
intelligence on the CryptoLocker operation. We begin by
highlighting how we generated an address cluster belonging to
CryptoLocker, which we call SCL , from two seed addresses in
Section III-A. Based on information from previous efforts and a
preliminary examination of SCL , we designed and implemented
a framework for identifying ransom payments from the set of
all transactions sent to our cluster in Section III-B.

900

USD per BTC

financial institutions. These emails typically spoofed invoices,
order confirmations, or urgent unpaid balances to lure victims
into following malicious links which redirected to CryptoLocker
exploit kits.
From September 2013 through early 2014, CryptoLocker
infections were most prevalent in the United States. A study
from the Dell SecureWorks Counter Threat Unit (CTU) research
team [11] shows that from October 22, 2013 to November
1, 2013, 22,360 systems were infected in the United States,
constituting 70.2% of global CryptoLocker infections. During
this period, CryptoLocker was also prevalent in Canada, Great
Britain, India, and several countries in the Middle East and
South Central Asia. In a later sample, gathered from December
9, 2013 to December 16, 2013, during a sinkhole when CryptoLocker activity was limited, CryptoLocker infections became
more dispersed. The concentration of infected systems in the
United States dramatically declined to 23.8% (1,540 infected
systems) and CryptoLocker activity became more prevalent in
Great Britain (1,228 infected systems constituting 19.0% of
global infections), Australia (836 infections constituting 12.9%
of global infections), several other European countries, China,
India, and Brazil.
Although the United States is disproportionately represented
in total global CryptoLocker infections, most ransom payments
from the United States were issued through MoneyPak, an
invariably more economical option than Bitcoin. This was due
to bitcoin’s price volatility at the time. Conversion rates soared
from $120/BTC in September 2013 to well over $1,300/BTC in
late November 2013. We show the exchange rate of US dollars
and bitcoin throughout CryptoLocker’s operational period in
Figure 2. As a result, the CryptoLocker threat actors adjusted
the ransom demand on several occasions to ensure that ransom
demands were not exorbitant. Since, in almost all cases in the
United States, there were no advantages to paying through
the Bitcoin system, individuals who elected to pay via Bitcoin
presumably resided in countries outside of the United States
where MoneyPak was unavailable [11]. For this reason, bitcoin
ransom payments represent only a small portion of the total
financial damages caused by CryptoLocker.

600

300

Sep 2013

Oct 2013

Nov 2013

Dec 2013

Date

Jan 2014

Feb 2014

Fig. 2. The plot shows exchange rates between US dollars and bitcoins during
CryptoLocker’s operational period from September 2013 through January
2014.

for forensic analysis of the blockchain. Initially, we found two
known CryptoLocker addresses by manually investigating a
reddit thread4 in which victims and researchers posted Bitcoin
addresses belonging to the ransomware. We will refer to one
of these seed addresses, which collected 27 ransom payments,
as Aseed1 , and the other seed address, which collected 23
ransom payments, as Aseed2 , throughout the remainder of this
paper. An interested reader can find the hashes of all Bitcoin
addresses mentioned in the Appendix. To expand our dataset of
addresses, we use the following two clustering heuristics (based
on the Bitcoin transaction protocol detailed in Section II-A)
to generate a set of Bitcoin addresses controlled by the same
user(s), known as clusters [4]:
1) Multi-input Transactions: A multi-input transaction occurs when a user u makes a transaction in which
the payment amount p exceeds the available bitcoins
(references of prior payments to u) in u’s wallet5 . In
such a case, the Bitcoin protocol inputs a set of bitcoins
B from u’s wallet to sufficiently fund p. Therefore, we
can conclude that if the bitcoins in B are owned by a
set of distinct input addresses Si , the input addresses in
Si are controlled by the same user u.
2) Change Addresses: The Bitcoin protocol generates a new
change address in u’s wallet to collect change when the
sum of inputs in B exceeds p. When the set of output
addresses So contains two addresses such that one is a
newly generated address an and the other corresponds
to a payment’s destination address ad , we can conclude
that an is a change address and is controlled by u.
From Aseed1 , we generate a set of 968 Bitcoin addresses
belonging to the CryptoLocker cluster, SCL , which happens
to include Aseed2 . Although our study does not claim to be
representative of the entire CryptoLocker population within the
Bitcoin ecosystem, which is difficult to quantify due to a lack

A. Collecting and Generating Addresses
To collect Bitcoin addresses belonging to CryptoLocker,
we used an approach similar to M. Spagnuolo’s study on
CryptoLocker using BitIodine [7], an open source framework

4 https://www.reddit.com/r/Bitcoin/comments/1o53hl/disturbing bitcoin
virus encrypts instead of/
5 A “wallet” is a collection of private keys. It is the Bitcoin equivalent of a
bank account.

of confirmed Bitcoin addresses belonging to CryptoLocker,
we can systematically measure a subset of CryptoLocker’s
economy, SCL , and make inferences about CryptoLocker and
its constituents.
B. Ransom Identification Framework

IV. DATA OVERVIEW
We begin by validating the accuracy of our data and showing
how conservative our estimates are in Section IV-A. We then
perform valuations of the CryptoLocker economy and measure
ransom payments at different stages in its operational period
in Section IV-B.

The goal of our ransom identification framework is to distinguish ransom payments from the set of all transactions to SCL . A. Data Validation
Foremost, we designed and implemented our identification
We realize that it is difficult to both comprehensively
framework to be precise — we wanted to identify ransom measure SCL ’s economy and precisely identify all ransom
payments with a high degree of confidence and minimize the payments to SCL beyond a reasonable doubt. In turn, the
number of extraneous transactions included in our dataset. stringent transaction value and timestamp parameters used in
Second, we built our framework to be lightweight — rather our ransom identification framework provide a lower bound
than querying the entire Bitcoin blockchain, we chose a semi- estimate of ransom payments and SCL ’s economy. To gauge
automatic approach to crawl and parse transactions to SCL how conservative our previous estimates are using the aforemenusing the Blockchain API [14]. For each address in SCL , points tioned framework, we take three different measurements with
of interest included the total number of transactions, total sent varying transaction value and timestamp parameters. The three
and received bitcoins, and the number of ransom payments measurement methods are as follows: Method 1) transactions to
received. For each transaction, we were interested in input SCL without any transaction value or timestamp filters, Method
and output addresses, bitcoins transferred, and timestamps (in 2) transactions to SCL filtered only by transaction values, and
UNIX epoch time).
Method 3) transactions to SCL filtered by both transaction
The time and ransom parameters in our identification frame- values and timestamps (ransom identification framework).
work reflected findings from previous studies on CryptoLocker
ransomware [7], [11] and our own cursory analysis of SCL .
TABLE I
M EASUREMENTS BY M ETHOD
The heuristics we use are as follows:
• Payments of approximately 2 BTC (±0.1 BTC) between
Method
Transactions
BTC
USD
September 5, 20136 (CryptoLocker release date) and
Method 1
1,071
1,541.39
539,080.69
November 11, 2013 to allow for a three-day ransom period
Method 2
933
1,257.27
373,934.76
after CryptoLocker authors decreased the ransom amount
Method
3
795
1,128.40
310,472.38
to 1 BTC around November 8
• Payments of approximately 1 BTC (±0.1 BTC) between
November 8, 2013 and November 13, 2013 to allow for
Table I and Figure 3 show the daily volumes of bitcoins
a three-day ransom period after CryptoLocker authors de- paid to SCL , and their values in US dollars commensurate with
creased the ransom amount to 0.5 BTC around November daily exchange rates7 , using the three different measurements.
10
We see that there are clear disparities between our estimates
• Payments of approximately 0.5 BTC (±0.05 BTC) be- from Method 1, which accounted for all transactions to S
CL ,
tween November 10, 2013 and November 27, 2013 to compared to our estimates from Method 2 or 3, particularly in
allow for a three-day ransom period after CryptoLocker the month of November. The causes of the discrepancies on
authors decreased the ransom amount to 0.3 BTC around November 13 and 14 are four 7 BTC transactions, which are
November 24
filtered by Methods 2 and 3, that we cannot find any conclusive
• Payments of approximately 0.3 BTC (±0.05 BTC) be- evidence on. The causes of the discrepancies from November
tween November 24, 2013 and December 31, 2013
25 through November 27 are eight 4 BTC transactions and a
• Late payments of approximately 10 BTC (±0.1 BTC)
single transaction8 of 15.6 BTC (November 25). We discover
between November 1, 2013 and November 11, 2013 when that these transactions eventually end up in the secondary
CryptoLocker introduced their “CryptoLocker Decryption money laundering address used in the Sheep Marketplace scam
Service” for victims who failed to pay ransoms within of 2013 (see Section VI-B). Comparing estimates between
the given time frame
Method 2, which filtered transactions based on known ransom
• Late payments of approximately 2 BTC (±0.1 BTC)
amounts demanded by CryptoLocker (i.e. 2 BTC, 0.5 BTC, 0.3
between November 11, 2013 and January 31, 2014 when BTC), and Method 3, which filtered transactions by ransom
CryptoLocker decreased the cost of their “CryptoLocker amounts and their respective periods of activity, we see smaller
Decryption Service”
differences between our estimates, which is a good indication
• Payments of approximately 0.6 BTC (±0.1 BTC) between
that the time intervals chosen in our ransom identification
December 20, 2013 and January 31, 2014
6 Time

intervals are in Universal Time Coordinates (UTC) from the start of
the initial day to the end of the final day.

7 There are many BTC/USD exchange rates available. We use the “24h
average” BTC/USD exchange rate from http://www.quandl.com.
8 https://blockchain.info/tx/43355544/

80

BTC

60

40

20

0
Sep 2013

Oct 2013

Nov 2013

Dec 2013

Jan 2014

Feb 2014

Dec 2013

Jan 2014

Feb 2014

Date
USD (in thousands)

30

20

10

0
Sep 2013

Oct 2013

Nov 2013

Date
Method 1

Method 2

Method 3

Fig. 3. The plots show longitudinal trends in the value of ransom payments to SCL from September 2013 through January 2014. We compare data yielded by
our identification framework to two other measurements detailed in Section III-B. Method 1 measures all transactions to SCL , Method 2 measures ransom
payments filtered by known bitcoin ransom demands, and Method 3 measures ransom payments filtered by both ransom demands and timestamps (ransom
identification framework).

framework (including the 72-hour buffer periods) produce in price should they have been exchanged at the height of
reliable estimates. This is important because filtering by ransom bitcoin’s exchange rate. In Figure 4, we show a valuation
amounts is a relatively strong and straightforward heuristic, in US dollars of the CryptoLocker economy throughout its
whereas filtering by time intervals is an invariably weaker operational period. We can see our estimate of $310,472.38 with
heuristic. This is because the date that a ransom is paid is the assumption that the CryptoLocker threat actors cashed out
dependent on the date that an individual’s system is infected ransom proceeds at the end of each day (“daily cash in”). In the
and the 72-hour payment window, so it is entirely possible “cumulative cash in” curve, we assume that the CryptoLocker
that a system could have been infected by an older version threat actors aggregated the bitcoins collected from ransom
of CryptoLocker demanding an outdated ransom. We consider payments, and we perform a valuation commensurate with
these anomalous ransom payments and omit these transactions the USD/BTC exchange rate on each day. Based on the
by choosing Method 3 for the purpose of maintaining reliable latter assumption, we estimate that the peak valuation of
and precise data for analyzing trends in ransom payments in the CryptoLocker economy occurred on November 29, 2013
Section V.
when they had collected a total of 1,044.13 BTC worth
upwards of $1.18 million. The USD/BTC exchange rate also
reached its peak on that day at $1,332.26/BTC. This estimate
B. CryptoLocker Economy in Bitcoin
is corroborated by the valuation of CryptoLocker provided
Using Method 3, we identify 795 ransom payments to
by Spagnuolo et al. at $1.1 million taken on December 15,
SCL , which contribute a total of 1,128.40 extorted bitcoins.
2013 [7].
Using daily bitcoin to USD exchange rates, we estimate
It is difficult to accurately measure or visualize the rate of
that these ransom payments valued $310,472.38. However,
CryptoLocker infections from Figure 3 due to the changing
as we mentioned before these figures are conservative and the
ransom demands and exchange rates for bitcoins, so we
payouts to SCL may have been as much as 1,541.39 BTC and
construct a time series plot showing the frequency of ransom
$539,080.69 based on Method 1, though we cannot be certain
payments to SCL throughout CryptoLocker’s operational period.
that the unaccounted transactions are ransom payments.
From Figure 5, we begin to see low levels of activity starting
Since the exchange rates for bitcoins were quite volatile on September 9, 2013 when the first ransom9 of 1.99 BTC is
throughout the months of CryptoLocker’s operation, the value
9 https://blockchain.info/tx/33208314/
of these extorted bitcoins would have seen a meteoric increase

TABLE II
S UMMARY OF C RYPTO L OCKER R ANSOM T YPES
Type

Time period

No. ransoms

BTC

USD

2 BTC

Sep. 5 - Nov. 11

422

843.77

146,623.33

10 BTC (Late)

Nov. 1 - Nov. 11

9

89.80

23,780.19

1 BTC

Nov. 8 - Nov. 13

43

43.04

15,904.49

0.5 BTC

Nov. 10 - Nov. 27

116

58.01

46,415.23

2 BTC (Late)

Nov. 11 - Jan. 31

10

20.00

14,492.46

0.3 BTC

Nov. 24 - Dec. 31

144

43.19

37,759.44

0.6 BTC

Dec. 20 - Jan. 31

51

30.59

25,497.24

Sep. 5 - Jan. 23

795

1,128.40

310,472.38

Total

Valuation (USD in millions)

1.2

30

Number of ransoms

0.9

0.6

20

0.3

10

0.0
Sep 2013

Oct 2013

Nov 2013

Dec 2013

Date

Cumulative cash in

Jan 2014

Feb 2014

Daily cash in

Fig. 4. The plot shows valuations of SCL (using Method 3) in USD. The
“cumulative cash in” curve performs a valuation commensurate with the total
bitcoins extorted in USD while the “daily cash in” curve performs a valuation
commensurate with daily bitcoins extorted to USD.

paid to SCL . On October 8, 2013 through October 11, 2013,
we see a sharp increase in ransom payments (27, 21, 37, and
29, respectively), which is consistent with our knowledge on
CryptoLocker’s use of the spam botnet Gameover ZeuS starting
on October 7, 2013 [13]. As a result, we see that the original
ransom of 2 BTC constituted 422 of the 795 identified ransoms
and nearly half of the total transaction volume in US dollars.
This was undoubtedly CryptoLocker’s most prolific period in
terms of successful infections. Over the next two months, we
see undulating periods of activity which leads us to believe
that CryptoLocker may have been distributed in several batches
throughout its operation. SCL experiences a significant decline
in ransom payments starting in mid-December of 2013 and
eventually comes to a close by the end of January 2014; we
are not aware of any further CryptoLocker addresses after this
period.
V. DATA A NALYSIS
Our goal is to gain insight on CryptoLocker’s targets and
changes in targets throughout its operation by statistically
determining distinct distributions in the times of day that
different ransom types (i.e. 2 BTC, 1 BTC) were paid to
SCL . We achieve this by performing Kolmogorov-Smirnov
(goodness of fit) tests on ransom payment timestamps to

0
Sep 2013

Oct 2013

Nov 2013

Dec 2013

Date

Jan 2014

Feb 2014

Fig. 5. The plot shows number of ransoms paid to SCL on each day from
September 2013 to January 2014.

determine whether different ransom types come from different
populations in Section V-A. We analyze these trends and
explain our findings in Section V-B.
A. Kolmogorov-Smirnov Tests
The Kolmogorov-Smirnov test for goodness of fit is based
on the maximum difference between either an empirical and
a hypothetical cumulative distribution (one-sample) or two
empirical cumulative distributions (two-sample) [15], [16].
For our study, we use two-sample Kolmogorov-Smirnov tests
to determine, using ransom payment timestamps, whether or
not samples from different ransom types come from different
parent populations at the 99.5% confidence level. Our sample
populations include 2 BTC, 1 BTC, 0.5 BTC, 0.3 BTC, and 0.6
BTC ransoms, but exclude 10 BTC (Late) and 2 BTC (Late)
ransoms, because we do not have sufficient sample sizes. We
provide metadata on each type of ransom in Table II.
We begin by stating the null hypotheses of our KolmogorovSmirnov tests: fn1 (x) and fn2 (x) are samples of two empirical
cumulative distribution functions f1 (x) and f2 (x), and that
H0 : f1 (x) = f2 (x)

− ∞ ≤ x ≤ +∞

(1)

The alternative hypotheses are that
H1 : f1 (x) 6= f2 (x)

− ∞ ≤ x ≤ +∞

(2)

00:00

00:00

22:00

22:00

18:00

2BTC

16:00

16:00

10BTC(L)
1BTC
0.5BTC
2BTC(L)

Time (UTC)

20:00

18:00

Time (UTC)

20:00

Ransom type

14:00
12:00
10:00

14:00
12:00
10:00

0.3BTC

08:00

08:00

0.6BTC

06:00

06:00

04:00

04:00

02:00

02:00

00:00

00:00
Oct 2013

Nov 2013

Dec 2013

Jan 2014

0.0e+00

5.0e−06

Date

1.0e−05

1.5e−05

2.0e−05

Density

Fig. 6. The plot shows trends in the times of day that ransoms were paid to SCL .
TABLE III
F IVE - NUMBER SUMMARY AND MEAN (H:M:S UTC)

2 BTC

Sample

Min.

Q1

Median

Q3

Max.

Mean

2 BTC

00:01:20

08:55:36

13:55:06

18:01:00

23:58:33

13:12:42

1 BTC

00:34:31

14:11:09

17:07:49

21:11:29

23:54:33

16:28:47

0.5 BTC

00:07:27

05:51:07

15:16:48

19:23:24

23:55:19

13:14:47

0.3 BTC

00:06:59

04:15:56

11:33:30

17:29:14

23:54:45

11:16:19

0.6 BTC

00:00:01

08:27:37

13:53:14

16:54:00

23:11:33

12:36:46

1 BTC

0.5 BTC

0.3 BTC

0.6 BTC

2 BTC

0.3028 | 0.2770 0.1449 | 0.1815 0.1802 | 0.1671 0.1068 | 0.2566

1 BTC

0.2476 | 0.3089 0.3532 | 0.3006 0.3461 | 0.3582

0.5 BTC

0.1865 | 0.2158 0.2067 | 0.2907

0.3 BTC

0.1908 | 0.2819

0.6 BTC
Fail to reject H0

D | D crit

Reject H0

D | D crit

Fig. 7. The table compares the test statistic D and the critical value Dcrit
for all permutations of ransom types. If D > Dcrit , we may reject the
null hypothesis and assume that the samples come from two different parent
populations at the 99.5% confidence level. These are shown in red.

In Figure 7, we compare D and Dcrit for each permutation.
For permutations where D < Dcrit , we fail to reject the
null hypothesis, which tells us that the two samples did not
come from different populations at the 99.5% confidence level.
For permutations where D > Dcrit , we may reject the null
hypothesis, which tells us that the two samples come from two
different populations at the 99.5% confidence level.
B. Analysis of Timestamp Data

Before we go into detail on the time series and density plots
in Figure 6 and a statistical summary of time distributions
in Table III, we put into perspective a hypothetical time
distribution that CryptoLocker victims from the United States
We then compute empirical cumulative distribution functions,
paid primarily in bitcoin (which we know to be false from
f1 (x) and f2 (x), from the two samples. To compute the test
the CryptoLocker study by CTU researchers [11]). What we
statistic D from f1 (x) and f2 (x), we find the maximum
do know is that CryptoLocker targeted business professionals,
absolute difference over all values of x given by
so we would expect ransom payments to be transacted during
D = max|Fn1 (x) − Fn2 (x)|
(3) typical working hours, or at the very least, during the daytime.
x
Let us assume a typical 9:00 a.m. to 5:00 p.m. working day
After computing D for all permutations of our sample pop- for business professionals in the United States. In Pacific Time
ulations, we compute critical values, Dcrit , at the 99.5% (PT, UTC-08:00), 9:00 a.m. to 5:00 p.m. would correspond to
confidence level for each permutation given by
17:00 UTC to 1:00 UTC on the following day. In Eastern Time
(ET, UTC-05:00), 9:00 a.m. to 5:00 p.m. would correspond to
p
Dcrit = 1.73 (n1 + n2 )/n1 n2
(4) 14:00 UTC to 22:00 UTC. Based on Figure 6 and Table III,

the only sample that could follow such a distribution is the 1
BTC sample, however, we cannot conclude that 1 BTC ransom
payments were primarily paid by victims from the United
States without further evidence. Because we have no reason
to believe that the marginal number of CryptoLocker victims
in the United States who opted to pay using bitcoin would
choose to pay in the nighttime, we assume that ransoms paid
to SCL came from outside of the United States.
From our Kolmogorov-Smirnov tests, we find that the
timestamp sample of 2 BTC ransoms differs from samples
of 1 BTC and 0.3 BTC ransoms. Additionally, we find that
the sample of 1 BTC ransoms differs from the sample of 0.3
BTC ransoms. Thus, we know that all three samples come
from different populations at the 99.5% confidence level. In
the 2 BTC sample, the median time of payment is 13:55:06
UTC with an interquartile range (Q3 − Q1 ) of 09:05:24 hours.
From the density curve in Figure 6, we see that it has a
unimodal distribution, which suggests that a large portion of
ransom payments during this time came from the same region.
Referring back to the CTU researchers’ study, we see that from
October 22, 2013 to November 1, 2013, they measure 1,767
infections from Great Britain, which has the second highest
percentage of total global infections (5.5%) after the United
States (70.2%). If we use our rough 9:00 a.m.–5 p.m. “working
day conjecture”, we would expect ransom payments from Great
Britain (GMT, UTC±00:00) to be concentrated between 9:00
UTC and 17:00 UTC. This is consistent with the first and third
quartiles from the 2 BTC sample (08:55:20 UTC and 18:01:00
UTC), but again, we make no solid claims without further
evidence.
Turning to the 1 BTC sample, the median time of payment
is 17:07:49 UTC with an interquartile range of 07:00:20 hours.
We see that it also has a unimodal distribution and restate that
the distribution of timestamps from this sample roughly models
what we would expect if a majority of these ransoms were paid
from the United States. Next, we take a look at the 0.3 BTC
sample, which has a median time of payment of 11:33:30 and
an interquartile range of 13:13:18. We see that the large spread
can be attributed to the 0.3 BTC sample’s bimodal probability
distribution, which suggests that the ransom sample came from
two distinct sources. One of these sources closely resembles the
time distribution from our 2 BTC sample, which we imputed
to ransom payments from Great Britain. The second source
of ransoms in early December falls between a 6-hour time
interval from 23:00 UTC to 5:00 UTC on the following day.
Referring back to the CTU researchers’ study, from December
9, 2013 to December 13, 2013, their measurements show that
CryptoLocker infections become more dispersed with 23.8%
from the United States, 19.0% from Great Britain, and 12.9%
from Australia. We continue to see CryptoLocker infections in
Great Britain, which is consistent with one of the peaks in the
bimodal 0.3 BTC sample. If we convert the time interval from
23:00 UTC to 5:00 UTC using our “working day conjecture”
and set 23:00 UTC as 9:00 a.m., we would expect these ransoms
to come from time zones with an offset of UTC+10:00. This
corresponds to the Australian Eastern Time Zone, which is,

Fig. 8. A visualization of outgoing bitcoin transactions from the CryptoLocker
cluster, SCL , network. Based on Louvain Modularity for community detection,
we distinguish 17 distinct sub-communities in the SCL network. We see that
the ransom balances from all addresses within a community are transferred to
a single aggregate address at the center. We group several sub-communities
together based on shared addresses and the times they were active (i.e.
Community 1, or c1 ) and identify eight communities of interest (c1 through
c8 ).

again, consistent with measurements by the CTU researchers’
CryptoLocker study, however we make no solid claims that a
large portion of the 0.3 BTC ransoms undoubtedly came from
Australia.
VI. F INANCIAL I NFRASTRUCTURE
We next turn to understanding CryptoLocker’s financial
infrastructure by analyzing communities in the CryptoLocker
cluster, SCL . We begin by overviewing SCL ’s topology in
Section VI-A. Examining SCL at a lower level, we impute realworld data found on various online fora and Bitcoin services
to distinct communities in Sections VI-B to VI-C. We find
connections to BTC-e and Bitcoin Fog and speculations to the
Sheep Marketplace scam and other bitcoin cybercrime.
A. Transaction Graph
To better understand CryptoLocker’s financial infrastructure,
we use Gephi10 , an open source software for network visualization and exploration, to visualize outgoing transactions
from SCL (Figure 8). In total, the network contains 993
nodes (addresses) and 1,020 weighted (by BTC), directed
edges, which delineate one or more transactions between two
addresses. The 993 addresses in the network are comprised
of 968 addresses from SCL and 25 additional addresses that
are recipients of outgoing transactions from SCL , which we
10 http://gephi.github.io/

11/16/2013
Sheep 50,000
BTC balance

11/19/2013
Anomalous tx
from a1 to Sheep

11/21/2013
Sheep goes offline

11/26/2013
Community 4's
tx to Sheep

11/29/2013
Sheep reaches
96,000 BTC balance

12/6/2013
Community 7's
tx to Sheep

10/15/2013
a1 s last activity
11/29/2013

11/16/2013

10/15/2013

11/1/2013

12/1/2013

12/6/2013

Fig. 9. Timeline of activity related to the Sheep Marketplace.

will call aggregate addresses. Using the Louvain Method for to the Sheep Marketplace is provided in Figure 9 (with the
community detection, we distinguish 17 distinct communities assumption that these speculations are true).
in the CryptoLocker network [17]. An interested reader can
1) Case study on Aseed1 : We first manually analyze Aseed1
see that the typical community is comprised of addresses to understand CryptoLocker’s early operation. We discover
in SCL (child nodes) that report to a central aggregate an anomalous transaction sharing the aforementioned Sheep
address to which all collected ransom payments are sent to Marketplace pattern, which prompts us to look for this same
(parent node). We characterize eight communities of interest pattern in other communities.
(arbitrarily and not chronologically named c1 through c8 ) that
Incoming transactions: On September 7, 2013, Aseed1
yield external information on addresses in SCL from our receives a payment of one BTC from a temporary address
analysis. Communities 2 through 8 are canonical communities a1 active for only that day. An outgoing payment for the same
in that they each correspond to only one aggregate address. amount is processed four days later. We believe this was a test
Community 1, on the other hand, is not centralized around one trial for CryptoLocker’s payment system. On September 13,
single aggregate address, but rather is comprised of multiple 2013, Aseed1 receives its first ransom payment of two BTC.
small communities and aggregate addresses. We will expand Throughout the rest of the month, Aseed1 receives 26 additional
on c1 ’s topology in Section VI-B, which we learn to be ransom payments of approximately two BTC each, which totals
CryptoLocker’s earliest community.
to 53.9081 BTC (worth about $6,600 at the time of payment).
On September 29, 2013, Aseed1 receives an anomalous payment
B. BTC-e and the Sheep Marketplace
of 0.0002 BTC from an inconclusive single-use address a2 .
Outgoing Transactions: From September 27, 2013 to October
Before we begin our analysis of CryptoLocker’s communities,
15,
2013, Aseed1 makes nine outgoing payments amounting
it helps to provide background on one pattern we found in
to
53.9081
BTC (the exact number of bitcoins collected from
several communities, namely an indirect connection to the
ransom
payments)
to aggregate addresses in c1 . Aseed1 ’s
Sheep Marketplace scam of 2013. The Sheep Marketplace
remaining
balance
after
its distribution of ransom payments
was the successor of the Silk Road [18], [19], an anonymous
is
the
unaccounted
0.0002
BTC. Considering that the exact
online marketplace specializing in the trade of narcotics, after
amount
of
bitcoins
from
ransom
payments is transferred to
its infamous takedown in February 2011. Launched in March
aggregate
addresses,
as
opposed
to the entire balance, we
2013, the Sheep Marketplace quickly gained traction as the
hypothesize
that
transfers
from
child
addresses to aggregate
leading anonymous online drug marketplace until, on November
addresses
were
automated,
rather
than
performed manually.
21, 2013, the owners shut down the site and absconded with
An
Anomalous
Transaction:
On
November
19, 2013, over a
96,000 bitcoins (over $100 million) belonging to its users [20].
month
after
A
’s
last
activity
and
right
before
the Sheep
We find that several aggregate addresses and child addresses
seed1
11
Marketplace
shutdown,
we
find
that
the
unaccounted
0.0002
make transactions to BTC-e , one of the largest bitcoin
BTC
is
transferred
as
part
of
a
multi-input
transaction
of 15
exchanges available where users can convert bitcoins into other
BTC
to
an
address
A
belonging
to
BTC-e.
From
cryptocurrencies, Dollars, Euros, and Rubles. From BTC-e,
exchange1
the
BTC-e
address,
the
15
BTC
are
included
in
a
multi-input
the bitcoins are then transferred to two money laundering
addresses used in the Sheep Marketplace scam. While it is transaction of 1,000 BTC to an address that we later learn to
unclear what sort of connection the CryptoLocker operation and be Sheep’s primary money laundering address Asheep1 , which
the Sheep Marketplace may share, if there is any connection has processed over 466,000 BTC as of February 2015.
Our efforts to find external data on Asheep1 leads us to a
at all, we continue by pointing out instances in which the two
are somehow linked. A timeline of SCL ’s activity in relation reddit thread that details how user sheeproadreloaded2 [21]
traced the $100 million of stolen bitcoins from the Sheep
11 https://btc-e.com/
Marketplace, through Bitcoin Fog, to the money laundering

address Asheep1 . Examining the transaction history of Asheep1 ,
3) Community 4: We next take a look at c4 , which is
we find that it has a balance of 50,000 BTC on November 16, comprised of 110 addresses. Throughout mid-November (when
2013. Throughout the rest of the month, we notice a massive CryptoLocker decreased the ransom amount due to the rising
increase in activity as it receives a total of 96,500 BTC while value of bitcoins), addresses in c4 receive numerous ransom
sending a total of 50,000 BTC to auxiliary addresses, most payments of 0.5 BTC. On November 26, 2013, the balances
notably a secondary money laundering address, Asheep2 .
from addresses in c4 are transferred to a single-use aggregate
Considering the time of Aseed1 ’s final transaction just two address Ac4 belonging to BTC-e, which collects a total of
days prior to the Sheep Marketplace’s alleged theft, and its 96.6 BTC. On the same day, the aggregate address transfers
discontinued use after transferring its balance to aggregate its balance into a multi-input transaction of 1,000 BTC to
addresses, we speculate that Aseed1 ’s anomalous 0.0002 BTC the Sheep Marketplace’s secondary money laundering address,
may have been part of the Sheep scam. Posted within a week of Asheep2 .
4) Community 7: Community c7 is a medium-sized comAseed1 ’s anomalous transaction on November 22, 2013, we find
12
munity
containing 83 addresses. Its aggregate address Ac4 also
a reddit thread detailing a similar occurrence in which a user
belongs
to BTC-e and collects 82.2 BTC from December 5
reports having 3.9 BTC stolen from his or her Mt. Gox [22]
to
December
9, 2013. On December 6, 9, and 10, we see
account and transferred to an intermediate address before
that
the
aggregate
address transfers its bitcoins in multi-input
ending up in Asheep2 . This indicates that Aseed1 ’s anomalous
transactions
of
400
BTC, 500 BTC, and 300 BTC, which are
transaction is not an isolated incident and we use this finding
also
sent
to
Sheep’s
secondary address, Asheep2 .
as a point interest for other CryptoLocker addresses.
2) Community 1: While canonical communities c2 through C. Botnets, Speculations, and Misc.
c8 each correspond to only one aggregate address, we group five
From communities c2 , c3 , c5 , c6 , and c8 , we characterize
small communities, which we will call sub-communities, and
how CryptoLocker’s operation evolved over time and we find
six aggregate addresses into c1 . The largest sub-community
subtle connections to other bitcoin cybercrime.
in c1 , containing 42 addresses (including addresses Aseed1
1) Community 2: By far the largest community in the Crypand Aseed2 ), is the connecting component between the four
toLocker network, c2 accounts for one-third of the addresses
surrounding sub-communities. We combine these five subin SCL . We find that c2 quickly follows c1 and is active
communities into a single community, c1 , based on connectivity
from October through mid-November, CryptoLocker’s most
and the times they were active.
prolific period of operation. Consistent with CryptoLocker’s
We find that addresses in c1 were active during the onset use of Gameover ZeuS and the Cutwail botnet starting on
of CryptoLocker’s attacks between September 9, 2013 and October 7, 2013, the increased distribution of ransomware
October 15, 2013. According to c1 ’s decentralized topography called for more addresses to collect ransom payments. Out of
and the reuse of addresses for ransom collection (i.e. Aseed1 the 328 addresses in c , 318 are single-use addresses. Thus, we
2
and Aseed2 ), we can assume with a high degree of confidence infer that the CryptoLocker threat actors opted to dynamically
that CryptoLocker’s threat actors did not dynamically generate generate addresses, instead of reusing addresses, to obfuscate
new addresses for its nascent attacks. The value in doing so their activity.
would be to obfuscate relationships between CryptoLocker
At the center of c2 is an aggregate address Ac2 belonging
addresses and money laundering addresses.
to BTC-e, which has received a total of 5,332.8 BTC. There
Examining c1 at a low level, we find that the addresses in is a notable disparity between how the extorted bitcoins were
c1 ’s largest sub-community report to two single-use aggregate handled between c1 and c2 . In c1 , we see a clear indication
addresses which collect 40 BTC and 20 BTC. From here, that the CryptoLocker threat actors decide to use Bitcoin
we see that these balances are processed through long chains mixers, particularly Bitcoin Fog, to launder their proceeds.
of single-input transactions with fractional bitcoins chipped In c2 , however, we see that the threat actors decide to generate
away in each transaction, which is characteristic of the Bitcoin new addresses for each ransom payment and directly transfer
Fog mixer [8]. Bitcoin Fog is a mixing service accessible via their proceeds to BTC-e without any means of obfuscation. The
Tor and allows users to deposit their bitcoins to up to five downfalls of the former method, which include a prolonged
newly generated addresses. To deter obvious indications of return on proceeds, transaction fees, diminished anonymity
using Bitcoin Fog, the service takes a randomized fee between for large transactions, and trust in a third party, may have
1–3% of the transaction value and processes bitcoins over deterred CryptoLocker’s growing enterprise from continued
a randomized timespan between 6 and 96 hours. The four use of Bitcoin Fog. In the latter method, the CryptoLocker
remaining sub-communities in c1 are all similar in size and authors might have assumed that newly generated addresses
structure. Each sub-community consists of between 14 and 18 would be sufficient in preserving privacy.
addresses which lead to aggregate addresses holding 20 to 40
2) Community 3: Community c3 is a medium-sized commuBTC in preparation for tumbling.
nity consisting of 52 addresses. On February 12, 2014, 14.63
BTC are transferred to c3 ’s single-use aggregate address Ac3
predominantly in 0.3 BTC ransom payments. Considering the
12 https://www.reddit.com/r/Bitcoin/comments/1r9rtp/i just had 39 btc
stolen from my mtgox account/
time frame of 0.3 BTC ransom payments, we presume that

c3 is one of CryptoLocker’s later communities. The balance a simulation of Bitcoin in a university setting, and proved
from c3 ’s aggregate address is transferred on March 3, 2014 that behavior-based and transaction-based clustering techniques
as part of a 100 BTC multi-input transaction to an address could effectively deanonymize up to 40% of Bitcoin users
a3 which has processed 374 BTC as of April 2014. Further in the simulation [4]. Ron and Shamir perform an analysis
analysis of c3 and its aggregate address does not yield any of the entire transaction graph and examine how users spend
useful information, however, we note that this transaction is bitcoins, how bitcoins are distributed among users, and means
one of SCL ’s last movements.
by which users protect their privacy in the Bitcoin system [5].
3) Community 5: c5 is a medium-sized community contain- Meiklejohn et al. explored Bitcoin wallets by using clustering
ing 57 addresses. On January 14, 2014, c5 ’s aggregate address heuristics (similar to Androulaki et al.) in order to classify
Ac5 collects a sum of 50 BTC from its component addresses. the owners of Bitcoin wallets and discussed the growing
After just one hour, the balance is transferred as part of a discrepancy between potential anonymity and actual anonymity
multi-input transaction of 1,134.99 BTC to an address, a4 , that in the Bitcoin protocol [6].
has processed over 277,000 bitcoins as of early 2014. In our
In the growing literature on measuring cybercrime, our
search for external information, we find another reddit thread13 study on CryptoLocker is related to a number of works aimed
posted on February 3, 2014 explaining how the reddit user’s at analyzing cybercrime in the Bitcoin ecosystem. Christin
coins were subject to an unauthorized withdrawal attempt to performed a comprehensive measurement analysis of the Silk
a4 (though the transaction was unsuccessful due to insufficient Road, detailing the anonymous marketplace’s constituents
funds). We also find a BitcoinTalk thread14 alleging that the and discussing socioeconomic and policy implications of the
address is related to the BitPay hack while another comment results [18]. In a later study, Soska and Christin perform a
in a separate blogpost15 suggests that the address belongs to longitudinal study of online anonymous marketplaces, which
Mt. Gox.
includes the Sheep Marketplace, and examines how these
4) Community 6: Community c6 , the second largest commu- virtual marketplaces have grown and evolved [19]. Spagnuolo
nity in the CryptoLocker cluster, is comprised of 141 addresses. et al. created an expandable framework, called BitIodine [7],
The community’s aggregate address Ac6 collects a total of 100 used for forensic analysis of the Bitcoin blockchain; they
BTC in ransoms payments on February 12, 2014 (another investigate addresses corresponding to the Silk Road owner,
one of CryptoLocker’s later communities). One day later, the known as Dread Pirate Roberts, and CryptoLocker ransomware.
balance is transferred as part of a 528.74 BTC multi-input Möser evaluated the effectiveness of several mixing services,
transaction to an address, a5 , which has processed over 11,000 commonly used to launder bitcoins, on preserving privacy [8].
bitcoins as of February 2014. One reddit post 16 mentions that Vasek et al. investigated the impact of distributed denial-ofa5 is related to the potential Mt. Gox address, a4 . Thus, we service attacks on popular Bitcoin services [23]. Ron and
assume that a5 is, at the very least, tied to some kind of Bitcoin Shamir used the blockchain to timeline events leading to Silk
cybercrime.
Road owner Dread Pirate Robert’s accumulation of wealth
5) Community 8: c8 is comprised of just 22 addresses. The before his arrest [24]. In a similar fashion to many of the
aggregate address Ac8 receives just 6.67 BTC on February 12, aforementioned works, we have performed the first in-depth,
2014. One day later, we see that the balance is transferred to systematic analysis of the CryptoLocker network in the Bitcoin
a5 . Again, we assume that this community may be linked to ecosystem.
some kind of Bitcoin cybercrime.
VIII. D ISCUSSION AND F UTURE W ORK
VII. R ELATED W ORK
Our study corroborates findings from previous studies on
The public’s interest in Bitcoin has continually grown CryptoLocker ransomware, but we want to emphasize that
throughout the years, undeterred by countless hacks and scams. the measurements and analysis in our own study were solely
Therefore, it is important for users to fully understand the drawn from blockchain analysis and crawling publicly available
implications and limitations of the Bitcoin system. Numerous data. In some cases of cybercrime analysis, this can be
studies have thoroughly examined the flawed provisions for a substantial limitation, but in others, this can be quite a
privacy inherent in the Bitcoin system. Reid and Harrigan valuable resource. We concede that our findings are, at best,
performed one of the first analyses of anonymity in the Bitcoin controvertible assumptions unless further concrete evidence
system and were able to attribute external identifying informa- on the CryptoLocker operation proves otherwise; although
tion to addresses using a nascent representation of the Bitcoin we show that our findings are consistent with other studies
transaction network [3]. Androulaki et al. tested Bitcoin’s on CryptoLocker, our study cannot standalone prove any of
privacy provisions, in both the actual Bitcoin environment and the conjectures made beyond a reasonable doubt. However,
13 https://www.reddit.com/r/Bitcoin/comments/1wvz66/who is taking my
bitcoins/
14 https://bitcointalk.org/index.php?topic=399024.0
15 http://btcanalytics.blogspot.com/2014/02/
bitcoins-most-mysterious-wallet.html
16 https://www.reddit.com/r/DarkNetMarkets/comments/1xw39e/ok so
everyones trying to find out the giant/

considering how rapidly the cybercrime landscape is changing,
there will be circumstances in which we, as researchers, do
not possess substantial evidence on nascent cybercrimes. In
this regard, we may use some of the techniques discussed in
our study to form a rudimentary understanding on these new
schemes.

We have performed an in-depth, measurement analysis on
CryptoLocker’s economy and financial infrastructure. Initially,
from two seed CryptoLocker addresses gathered from online
fora, we generate a cluster of 968 addresses belonging to
the CryptoLocker enterprise. From there, we identify and
quantify ransoms paid (in bitcoin) by victims and produce an
estimate upwards of $310,472.38 in financial damages. Based
on our analysis of ransom timestamps, we form conjectures on
regions where CryptoLocker infections were prevalent from
trends in the times that ransom payments were made and
compare our findings with other studies on CryptoLocker.
Finally, we visualize the CryptoLocker operation’s underlying
financial infrastructure and analyze the topology in a modular
fashion. We find subtle links between CryptoLocker, the Sheep
Marketplace heist, and other Bitcoin cybercrime schemes.
Our findings suggest that Bitcoin cybercrime may be much
more interconnected than originally considered and that further
analysis could uncover and confirm any existing relationships
in the underground cybercrime landscape.
Given the increased prevalance of ransomware in the cybercrime landscape as of late, we believe that our study may enable
further research in longitudinally measuring the evolution,
economies, and strategies of ransomware criminal enterprises.
We plan to further develop our heuristics for identifying
ransom transactions from the Bitcoin blockchain in order to
comprehensively measure the economies of CryptoLocker, as
well as newer families of ransomware, and better understand
their underlying financial infrastructures and money laundering
strategies.
ACKNOWLEDGEMENTS
This research was supported in part by grants from Army
Research Office and Center for Cybersecurity and Digital
Forensics at Arizona State University. The information reported
here does not reflect the position or the policy of the funding
agencies.
R EFERENCES
[1] S. Nakamoto. (2012) Bitcoin: A peer-to-peer electronic cash system.
[Online]. Available: http://www.bitcoin.org/bitcoin.pdf
[2] S. T. Ali, D. Clarke, and P. McCorry, “Bitcoin: Perils of an unregulated
global p2p currency,” in Security Protocols XXIII. Springer, 2015, pp.
283–293.
[3] F. Reid and M. Harrigan, An analysis of anonymity in the bitcoin system.
Springer, 2013.
[4] E. Androulaki, G. O. Karame, M. Roeschlin, T. Scherer, and S. Capkun,
“Evaluating user privacy in bitcoin,” in Financial Cryptography and Data
Security. Springer, 2013, pp. 34–51.
[5] D. Ron and A. Shamir, “Quantitative analysis of the full bitcoin
transaction graph,” in Financial Cryptography and Data Security.
Springer, 2013, pp. 6–24.
[6] S. Meiklejohn, M. Pomarole, G. Jordan, K. Levchenko, D. McCoy, G. M.
Voelker, and S. Savage, “A fistful of bitcoins: characterizing payments
among men with no names,” in Proceedings of the 2013 conference on
Internet measurement conference. ACM, 2013, pp. 127–140.
[7] M. Spagnuolo, F. Maggi, and S. Zanero, “Bitiodine: Extracting intelligence from the bitcoin network,” in Financial Cryptography and Data
Security. Springer, 2014, pp. 457–468.
[8] M. Moser, R. Bohme, and D. Breuker, “An inquiry into money laundering
tools in the bitcoin ecosystem,” in eCrime Researchers Summit (eCRS),
2013. IEEE, 2013, pp. 1–14.

[9] S. Meiklejohn and C. Orlandi, “Privacy-enhancing overlays in bitcoin,”
in Financial Cryptography and Data Security. Springer, 2015, pp.
127–141.
[10] P. Syverson, R. Dingledine, and N. Mathewson, “Tor: the secondgeneration onion router,” in Proceedings of the USENIX Conference
on Security Symposium. USENIX Association, 2004.
[11] K. Jarvis. (2014) Cryptolocker ransomware, 2013. [Online].
Available: http://www.secureworks.com/cyber-threat-intelligence/threats/
cryptolocker-ransomware/
[12] G. O. Karame, E. Androulaki, and S. Capkun, “Double-spending fast
payments in bitcoin,” in Proceedings of the 2012 ACM conference on
Computer and communications security. ACM, 2012, pp. 906–917.
[13] B. Stone-Gross. (2012) The lifecycle of peer-to-peer (gameover)
zeus. [Online]. Available: https://www.secureworks.com/research/the
lifecycle of peer to peer gameover zeus
[14] Blockchain api. [Online]. Available: https://blockchain.info/api/
blockchain api/
[15] F. J. Massey Jr, “The kolmogorov-smirnov test for goodness of fit,”
Journal of the American statistical Association, vol. 46, no. 253, pp.
68–78, 1951.
[16] I. T. Young, “Proof without prejudice: use of the kolmogorov-smirnov
test for the analysis of histograms from flow systems and other sources.”
Journal of Histochemistry & Cytochemistry, vol. 25, no. 7, pp. 935–941,
1977.
[17] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast
unfolding of communities in large networks,” Journal of Statistical
Mechanics: Theory and Experiment, vol. 2008, no. 10, 2008.
[18] N. Christin, “Traveling the silk road: A measurement analysis of a large
anonymous online marketplace,” in Proceedings of the 22nd international
conference on World Wide Web, 2013, pp. 213–224.
[19] K. Soska and N. Christin, “Measuring the longitudinal evolution of the
online anonymous marketplace ecosystem,” in Proceedings of the 24th
USENIX Conference on Security Symposium. USENIX Association,
2015, pp. 33–48.
[20] S.
Kerner.
Sheep,
bitcoin
and
the
$100
million heist. [Online]. Available: http://www.eweek.com/security/
sheep-bitcoin-and-the-100-million-heist.html
[21] sheepreloaded2. I just chased him through a bitcoin tumbler, and
when he came out with 96,000 btc, i was waiting for him... [Online].
Available: https://www.reddit.com/r/SheepMarketplace/comments/1rvlft/
i just chased him through a bitcoin tumbler and
[22] R. McMillan. The inside story of mt. gox bitcoin’s $460 million disaster.
[Online]. Available: http://www.wired.com/2014/03/bitcoin-exchange/
[23] M. Vasek, M. Thornton, and T. Moore, “Empirical analysis of denialof-service attacks in the bitcoin ecosystem,” in Financial Cryptography
and Data Security. Springer, 2014, pp. 57–71.
[24] D. Ron and A. Shamir, “How did dread pirate roberts acquire and
protect his bitcoin wealth?” in Financial Cryptography and Data Security.
Springer, 2014, pp. 3–15.

A PPENDIX

Aseed1
Aseed2
Aexchange1
Asheep1
Asheep2
Ac2
Ac3
Ac4
Ac5
Ac6
Ac7
Ac8
a1
a2
a3
a4
a5

Table of Bitcoin Addresses
1KP72fBmh3XBRfuJDMn53APaqM6iMRspCh
18iEz617DoDp8CNQUyyrjCcC7XCGDf5SVb
161yYpWYCx8cWGYW95QaZ9NUuR3fd5n4xt
1CbR8da9YPZqXJJKm9ze1GYf67eKAUfXwP
174psvzt77NgEC373xSZWm9gYXqz4sTJjn
1AEoiHY23fbBn8QiJ5y6oAjrhRY1Fb85uc
1D5DoY5KxGtcatoxR5M3fSEeRpxfkgbsA3
15F4g9sou83dNojKBikHx9vAkgnr1AhAEH
1C1ypgQSiFdkwkRN7F9VrYFJG4wjyGPsfB
1KpYNzAjTXZHwY782S4JMQbAXD8Ymyyw8s
1AzMZUvHuakMgEaukDuzdAMujkXxgrHCGZ
1LXbUwPDaBGAwxAQzutsLoTQJhTeyGskQb
1wffa72YQFTYJGMwuxbvWHFNAFGNKX3Bm
1Jfb6hbqfzwdLdR6Bspfh4HkND2mFj8LL
14CR4HYnJpvNFmtpoq34JUdHcA2rXeehkd
1Facb8QnikfPUoo8WVFnyai3e1Hcov9y8T
15WtLXz24WitRWtfdEzWPWZJYYDEBjjhUf

Achieving Security Assurance with
Assertion-based Application Construction
Carlos E. Rubio-Medrano and Gail-Joon Ahn

Karsten Sohr

Ira A. Fulton Schools of Engineering
Arizona State University
Tempe, Arizona, USA, 85282
{crubiome, gahn}@asu.edu

Center for Computing Technologies (TZI)
Universität Bremen
28359 Bremen, Germany
sohr@tzi.de

Abstract—Modern software applications are commonly built
by leveraging pre-fabricated modules, e.g. application programming interfaces (APIs), which are essential to implement the
desired functionalities of software applications, helping reduce
the overall development costs and time. When APIs deal with
security-related functionality, it is critical to ensure they comply
with their design requirements since otherwise unexpected flaws
and vulnerabilities may be consequently occurred. Often, such
APIs may lack sufficient specification details, or may implement
a semantically-different version of a desired security model to
enforce, thus possibly complicating the runtime enforcement of security properties and making it harder to minimize the existence
of serious vulnerabilities. This paper proposes a novel approach
to address such a critical challenge by leveraging the notion of
software assertions. We focus on security requirements in rolebased access control models and show how proper verification
at the source-code level can be performed with our proposed
approach as well as with automated state-of-the-art assertionbased techniques.

I.

I NTRODUCTION

In recent years, there has been an increasing interest
in leveraging heterogeneous pre-fabricated software modules,
e.g. application programming interfaces (APIs) and software
development kits (SDKs), in order to not only reduce the
overall development costs and time in producing high-quality
applications, but also minimize the number of incorrect behaviors (bugs) observed in the final product. However, recent
literature has shown that such modules often lack the proper
specification details (in the form of formal or informal specification) that are essential to guide how a given module can be
used correctly for implementing security-related functionality
[1] [2]. Such a problem may potentially become the source
of serious security vulnerabilities, as developers may not be
fully aware of the omissions and flaws they may introduce
into their applications by failing to implement a security model
in a proper way. In order to solve this problem, we propose
an assertion-based approach to capture security requirements
of security models and create well-defined representations of
those requirements. This way, the security features could be
effectively understood by all participants in the software development process so that they can leverage these features when
implementing security-related functionalities for multi-module
applications while being engaged in a highly-collaborative
environment at the same time. These assertion-based security
specifications would be used in conjunction with existing stateof-the-art methodologies and tools to verify security properties
COLLABORATECOM 2014, October 22-25, Miami, United States
Copyright © 2014 ICST
DOI 10.4108/icst.collaboratecom.2014.257691

at the source-code level. In this paper, we choose the wellknown role-based access control (RBAC) [3] as security model
to enforce access control requirements over an application that
is in turn composed of several heterogeneous modules. Also,
we utilize existing tools to verify a set of security properties,
thus providing a way to locate and possibly correct potential
security vulnerabilities in software applications.
This paper is organized as follows: we start by providing
some background in Section II. Next, we examine the general
problem, as well as the problem instance discussed in this
paper in Section III. We then present our approach in Section
IV, and a case study depicting three Java-based software
applications and an experimental process in Section V. In
Section VI, we provide some discussion on the benefits and
observed shortcomings of our approach as well as some related
work. Finally, Section VII presents directives for our future
work and concludes the paper.
II.

BACKGROUND

Software assertions are commonly described as formal
constraints intended to describe what a software system is
expected to do at runtime, and are commonly written as
annotations in the system’s source code [4]. Using assertions,
developers can specify what conditions are expected to be valid
before and after a certain portion of code gets executed, e.g.
the expected range of values intended for the parameter of
a given function. Design by contract (DBC) [5] is a software
development methodology based on assertions and the assumption that the developers and the prospective users (clients) of
a given software module establish a contract between each
other in order for the module to be used correctly. Commonly,
such a contract is defined in terms of assertions in the form
of pre and post conditions, among other related constructs.
Before using a DBC-based software module M, clients must
make sure that M’s preconditions hold. In a similar fashion,
developers must guarantee that M’s postconditions hold once
it has finished execution, assuming its corresponding preconditions were satisfied beforehand. The Java Modeling Language
(JML) [6], is a behavioral interface specification language
(BISL) for Java, with a rich support for DBC contracts. Using
JML, the behavior of Java modules can be specified using
pre and post conditions, as well as class invariants, which are
commonly expressed in the form of assertions, and are added
to Java source code as the form of comment such as //@
or /*@...@*/. Fig. 1 shows an excerpt of a Java interface

1 public interface Account{
2
3 //@ public instance model double balance;
4
5 //@ public invariant balance > 0.0;
6
7 /*@ public normal_behavior
8
@ requires amt > 0.0;
9
@ assignable balance;
10
@ ensures balance == (\old(balance) - amt);
11
@*/
12 public void withdraw(double amt)
13
throws SecurityException;
14
15 }

Fig. 1: An Excerpt of a JML-annotated Banking Application.
named Account, which belongs to a banking application and
has been annotated with JML specifications. A summary of the
JML features exercised in this paper can be found in [6] and
[7].
In recent years, the American National Institute of Standards (ANSI) released a standard document that provides welldefined descriptions of the main components and functions that
define RBAC [8], and it is mostly based on the well-known Z
specification language [9]. In addition, a dedicated profile has
been introduced to provide support for expressing RBAC policies by taking both the aforementioned ANSI RBAC standard
as a reference foundation as well as the well-known eXtensible
Access Control Markup Language (XACML), which is a
standard language for supporting the distributed definition and
storage & enforcement of rich access control policies [10],
[11].
III.

P ROBLEM D ESCRIPTION

As mentioned earlier, recent literature includes examples
showing that mission-critical applications, e.g. banking mobile
applications, have suffered from serious security vulnerabilities
derived from an incorrect use of their supporting security APIs
at the source-code level [1], [2]. Among the possible causes
of this problem, insufficient software specifications, including
the definition of prerequisites and hidden assumptions, as well
as the existence of multiple semantic variations of a given
security model, e.g., the lack of foundation on a standardized,
well-defined model serving as a reference, are cited as common
sources of incorrect implementations. Moreover, the problem
gets aggravated by the lack of effective software verification
procedures at the source-code level, which could affect the
chances of identifying and potentially correcting security vulnerabilities exhibited by applications before deploying in a
production system. In this paper, we address an instance of this
problem by choosing RBAC as the security model to enforce
access control requirements in a software application that is
in turn composed of several modules. Each of them possibly
implements a different version of RBAC whose semantics may
or may not strictly adhere to an existing RBAC reference
model such as the one described in [8]. We therefore aim
to verify that such heterogeneous modules, when used to
build a target application, correctly enforce a well-defined
and consistent high-level RBAC policy, despite the differences
they may exhibit with respect to their inner workings related
to RBAC features, which could eventually result in security
vulnerabilities.

Fig. 2 (a) and Fig. 2 (b) show a Java-based example where
a high-level RBAC policy is enforced at runtime by placing
authorization checks before performing security-sensitive operations. In both instances, a policy depicts a role manager
as a senior role to teller, and allows for users, who are
assigned to roles that happen to be senior to manager, to
execute both the transfer and withdraw operations, whereas
users holding teller role are allowed to execute the withdraw
operation only. Fig. 2 (a) shows a Java class BankAccount,
which leverages the Spring Framework API [12] for implementing an authorization check (lines 7-16). Similarly, Fig.
2 (b) shows another class DebitBankAccount depicting
an authorization check using the Apache Shiro API [13]
(lines 7-11). In such a setting, it is desirable to evaluate
the correct enforcement of the aforementioned RBAC policy
as follows: first, the authorization checks depicted in both
examples must correctly specify the roles that are allowed to
execute each of the security-sensitive operations. For instance,
the authorization check depicted in Fig. 2 (a) incorrectly allows
for another role agent to also execute the withdraw method,
which in turn represents a potential security vulnerability.
Second, the role hierarchy depicted in the high-level policy
must be correctly implemented at the source-code level by
leveraging both APIs. As roles that happen to be senior to role
manager should be allowed to execute both the transfer
and withdraw methods, the role hierarchy must be correctly
implemented by placing accurate authorization checks within
the source code. In addition, the role hierarchy must be also
defined correctly in the supporting API configuration files. as
an incorrect implementation, e.g. missing role names within
the XML files defined for the Spring API, may prevent users
with the role manager from executing the transfer method.
A more serious problem may be originated if users with the
role teller are allowed to execute the transfer method.
Finally, if users with the role manager are allowed to execute
the transfer method, but are disallowed from executing
the withdraw method (Fig. 2 (b)) by incorrectly configuring
the Spring API depicted in Fig. 2 (a), a given object of class
DebitBankAccount may be left in an inconsistent state,
thus also creating a serious security problem.
IV.

O UR A PPROACH : A SSERTION - BASED A PPLICATION
C ONSTRUCTION

In order to provide a solution to the problem described
in Section III, we propose an approach that combines the
concepts of specification modeling and software assertions for
describing security features at the source-code level. These socalled assertion-based security models are intended to provide
compact, well-defined and consistent descriptions that may
serve as a common reference for implementing security-related
functionality. Our approach strives to fill in the gap between
high-level descriptions of security features, which are mostly
abstract and implementation-agnostic, and supporting descriptions focused at the source-code level, which are intended to
cope with both security-related and behavioral-based specifications. As it will be described in Section VI, previous work
has also explored the use of software assertions and DBClike contracts for specifying access control policies. However,
our approach is intended to leverage the modeling capabilities
offered by software specification languages using a welldefined reference description of a security model as a source,

1 import org.springframework.security.core.*;
2 public class BankAccount implements Account{
3
4 public void withdraw(double amt)
5
throws SecurityException{
6
7
Iterator iter = SecurityContextHolder
8
.getAuthorities().iterator();
9
10
while(iter.hasNext()){
11
GrantedAuthority auth = iter.next();
if (!auth.getAuthority().equals("teller") ||
12
13
!auth.getAuthority().equals("agent")){
throw new SecurityException("Access Denied");
14
15
}
16
}
17
this.balance -= amt;
18 }
19 }

(a) Spring Framework API.

1 import org.apache.shiro.*;
2 public class DebitBankAccount{
3
4 public void transfer(double amt, BankAccount acc)
5
throws SecurityException{
6
if(!SecurityUtils.getSubject().hasRole("manager")){
7
8
9
throw new SecurityException("Access Denied");
10
11
}
12
13
acc.withdraw(amt);
this.balance += amt;
14
15
16 }
17
18
19 }

(b) Apache Shiro API.

Fig. 2: Enforcing an RBAC Policy by Leveraging Heterogeneous Security Modules.
in such a way it not only allows for the correct communication,
enforcement and verification of security-related functionality,
but it also becomes independent of any supporting APIs used
at the source-code level, thus potentially allowing for its deployment over applications composed of several heterogeneous
modules as shown in Fig. 3: an assertion-based security model
is intended to be enforced over a target application that is
in turn composed of two modules leveraging security APIs
and two modules whose security-related functionality has been
implemented from scratch. This way, the semantic differences
exhibited by such modules, as shown in Section III, can be
effectively mitigated. Moreover, by leveraging state-of-theart methodologies based on assertions, effective automated
verification of security properties at the source-code level
becomes feasible, thus providing a means for discovering and
possibly correcting potential security vulnerabilities.
To address the problem instance discussed in this paper,
we leverage the JML modeling capabilities, e.g. model classes
[7], to describe the ANSI RBAC standard described in Section
II. Later on, these model classes are used to create assertionbased constraints, which are in turn incorporated into the DBC
contracts devised for each module in an application. This way,
a high-level RBAC policy can be specified at the source-code
level by translating it into assertion-based constraints included
in DBC contracts. Following our running example, Fig. 4
shows an excerpt of a model class JMLRBACRole, which depicts the role component and some of its related functionalities
as devised in the ANSI RBAC standard, e.g. role hierarchies.
Such a model class is leveraged in Fig. 5 to augment the
JML-based contract depicted in Fig. 1 with security-related
assertions restricting the execution of the withdraw method
to users who activate a role senior to teller. We start by defining
a model variable role, of type JMLRBACRole (line 5),
which is later used for defining access control constraints in the
two specification cases depicted in Fig. 5: the first specification
case, depicted in lines 9-14, allows one to properly execute
the withdraw method, e.g. deducting from the balance of a
given account, only if the object stored in the role variable
represents a role senior to teller1 . The second specification
1 Following

the ANSI RBAC standard, a given role is always senior to itself.

Assertion-based Security Model

Module1
(API1)

Module2
(API2)

Module3

Own
Code

Software Application

Fig. 3: Deploying Assertion-based Security Models over a
Multi-module Application.
1 package edu.asu.sefcom.ac.rbac;
2 public class JMLRBACRole
3
extends JMLRBACAbstractRole{
4
5 public boolean isSeniorRoleOf(
6
JMLRBACAbstractRole role){
7
8
if(this.equals(role)){ return true; }
9
10
return getAllJuniorRoles().contains(role);
11 }
12 }

Fig. 4: An Excerpt of a JML Model Class Depicting an
ANSI RBAC Role Component.
case, shown in lines 16-20, allows for the withdraw method
to throw a runtime exception if the aforementioned constraint
is found to be false. In addition, such a specification case also
prevents any modification to the state (e.g. private fields) of a
given object of type BankAccount from taking place.
Fig. 7 depicts our approach: a high-level RBAC policy,
which is encoded by means of the dedicated RBAC profile
provided by XACML [11], is translated into a series of DBC
contracts. Later on, such contracts, along with the source code

1 //@ model import edu.asu.sefcom.ac.rbac.*;
2 public interface Account{
3
4 //@ public instance model double balance;
5 //@ public instance model JMLRBACRole role;
6
7 //@ public invariant balance > 0.0;
8
9 /*@ public normal_behavior
10
@ requires amt > 0.0;
11
@ assignable balance;
12
@ ensures role.isSeniorRoleOf(
13
@ new JMLRBACRole("teller")) ==>
14
@ (balance == \old(balance) - amt);
15
@ also
16
@ public exceptional_behavior
17
@ requires !role.isSeniorRoleOf(
18
@ new JMLRBACRole("teller"));
19
@ assignable \nothing;
20
@ signals_only SecurityException;
21
@*/
22 public void withdraw(double amt)
23
throws SecurityException;
24
25 }

Fig. 5: Enhancing a DBC contract with Access Control
Assertions.

1 import org.springframework.security.core.*;
2 public class BankAccount implements Account{
3
4 //@ public represents role <- mapRole();
5
6 /*@ public pure model JMLRBACRole mapRole(){
7
@
8
@ JMLRBACRole newRole = new JMLRBACRole("");
9
@ RBACMonitor monitor = new RBACMonitor();
10
@
11
@ Iterator iter = SecurityContextHolder
12
@
.getAuthorities().iterator();
13
@
14
@ while(iter.hasNext()){
15
@
GrantedAuthority auth = iter.next();
if (auth.getAuthority().equals("teller")){
16
@
17
@
newRole = new JMLRBACRole("teller");
18
@
}
19
@ }
20
@
21
@ return newRole;
22
@ }
23
@*/
24 ...
25 }

Fig. 6: An Excerpt Showing a JML Abstraction Function.

for a given software application, are fed into JML-based automated tools for verification purposes. Since such an application
may be in turn composed of heterogeneous modules and each
of them possibly represents a different API for implementing
security-related functionality, e.g. enforcing an RBAC policy,
the configuration files for such APIs must be also taken into
account when leveraging automated tools for verification, as
described in Section III. In order to automate the creation of
DBC contracts such as the ones depicted in Fig. 5, we designed
an automated tool that translates RBAC policies encoded in
the RBAC XACML profile into JML-based specifications, thus
relieving policy designers and software architects from crafting
such contracts manually and eliminating a potential source for
errors.

<xml ...>
<....>
<..../>

DBC/JML
Contracts

+
RBAC XACML
Policy Files

Java
Source
Code

JML-based
Verification
Tools

+
API
Config.
Files

Fig. 7: A Framework for Assertion-based Security Assurance.

As described in Section I, we aim to provide the verification
of security properties by leveraging an approach based on
automated unit testing [14] as well as the JML specifications
depicting the assertion-based models described above. For
such a purpose, we adopt JET [14], which is a dedicated
tool tailored for providing automated runtime testing of Java
modules with JML-based assertions, e.g. classes. Using JET,
testers can verify the correctness of a Java module by checking
the implementation of each method against their corresponding
JML specifications. In addition, we also aim to provide support
for finding possible security vulnerabilities by means of static
techniques. For such a purpose, we leverage the ESC/Java2 tool
[6], which is based on a theorem prover and internally builds
verification conditions (VCs) from the source code being analyzed, and its corresponding JML-based specifications, which
the theorem prover then attempts to prove, thus allowing for the
automated analysis of whole code modules without running the
applications. In particular, ESC/Java2 uses modular reasoning
[15], which is regarded as an effective technique when used
in combination with static checking since code sections can
be analyzed and their JML-based specifications can be proved
by inspecting the specification contracts of the methods they
call within their method bodies. Later, in Section V, we
present our findings on leveraging both techniques in a set
of case studies depicting mission-critical Java applications.
In order to support the verification process just described,
proper constructs are needed to map the modeling features
included in DBC contracts (as depicted in Fig. 5) and the
implementation source code of each heterogeneous module.
For such a purpose, we leverage the features offered by the
JML abstraction functions [7], which allow for JML model
features to be properly mapped to source-code level constructs,
thus providing a way to verify that each heterogeneous module
implements a given high-level policy correctly. As an example,
Fig. 6 shows an excerpt where a JML model method is
used to map the source code implementing security features
as provided by the Spring Framework API with the model
features depicted in Fig. 5.
In general, the correct enforcement of a security model may
involve the following cases: first, a high-level security policy,
which is based on a well-defined security model definition,
should be correctly defined and all policy conflicts must have
been resolved, e.g. evaluating a given RBAC policy by using
techniques such as the ones discussed in [16]. Second, access
to all protected resources within a given application, e.g. the
withdraw operation depicted in Fig. 5, is guarded by an

TABLE I: Distribution of Responsibilities for Enforcing an
Assertion-based Security Model In a Collaborative Setting.
Actor

Description of Tasks

Security Domain Experts

Develop an assertion-based security model by
using a precise definition as a reference, e.g. using
the ANSI RBAC standard. (See Fig. 4).

Security Policy Administrators

Instantiate the security model to be enforced, e.g.
specification of an RBAC policy based on the
ANSI RBAC standard.

Software Architects

Incorporate the security policy into DBC constructs by specifying assertion-based constraints
(See Fig. 5).

Code Developers

Correctly implement the DBC specifications defined by software architects (including security
checks). Provide a mapping between the security
model and the security APIs used for implementation purposes (See Fig. 6).

Code Testers

Verify both the functional and the security related
aspects of a given software application based on
their DBC specifications (See Section V).

authorization check (adhering to the well-known principle of
complete mediation). Following our example, authorization
checks should depict the RBAC constructs defined in the overall policy, e.g. checking for the correct roles and/or permissions
before executing any sensitive operation. Third, supporting
components for the security model features is implemented
correctly, e.g. RBAC role hierarchies. Finally, we also require
that the detection of runtime policy violations is implemented
properly, e.g. exception handling and data consistency. With
this in mind, for the problem instance addressed in this paper,
we make the following assumptions: first, the ANSI RBAC
model is well-understood by all participants in the software
development process, e.g. policy designers, software architects
and developers. Second, the assertion-based specification of the
security model is correct: in other words, it has been verified
beforehand. Third, any supporting RBAC modules, including
security APIs and SDKs, have been implemented correctly,
even though their semantics with respect to RBAC may differ,
as addressed in Section III.
Finally, our approach is intended to be carried out by
the different participants in the software development process,
in such a way that the process of constructing vulnerabilityfree software becomes a collaborative responsibility shared by
all involved actors, obviously including the source-code level
developers. Table I shows a summary of the tasks devised for
each participant.
V.

C ASE S TUDY

In order to provide a proof-of-concept implementation of
our approach, we developed a reference description of the
security model under study by using a set of JML model
classes based on the case illustrated in Fig. 4. Such a reference
model contains 960 lines of code grouped in 17 Java classes,
including 1,383 lines of JML specifications depicting the
functionality desired for RBAC as described in the ANSI
RBAC standard. For our case study, we leveraged a pair
of open-source Java applications: OSCAR EMR [17], which
is a rich web-based software platform tailored for handling
electronic health records (EMR). It consists of approximately
35,000 lines of code organized into 110 classes and 35
packages. In addition, we also leveraged JMoney [18], a

TABLE II: A Sample RBAC Policy for Evaluation Purposes.
Role
Employee
Teller
Agent
Manager

Junior Roles

Sample Allowed Operations

-

deposit

Employee

withdraw, deposit

Employee

close, deposit

Teller, Agent

transfer, withdraw, deposit, close

financial application consisting of 7,500 lines of code grouped
into 45 classes. Finally, we developed a banking application
depicting the running examples shown in this paper. Such an
application leverages the Apache Shiro and Spring Framework
Security APIs, as well as our own RBAC monitor developed
for implementing security-related functionality. It consists of
36 classes and contains 1,550 lines of code as well as 1,450
lines of JML specifications, which utilize our JML model
classes in DBC contracts, as shown in Fig. 5.

In order to verify the effectiveness of our approach for
detecting faulty implementations of the RBAC security model,
we followed an approach inspired in mutation testing [19]: we
inserted variations (also known as mutants) in both the source
code and the API configuration files of the applications considered in our study, in an effort to introduce inconsistencies
in the implementation of their corresponding RBAC Policies.
As an example, Fig. 8 shows different mutants introduced to
the RBAC policy shown in Table II: first, the original policy
is modified to add an unintended permission (transfer, (t))
to a role employee (Fig. 8 (a)). Such a modification creates
a potential security vulnerability as it allows employee, and
all other roles senior to it, e.g. agent and teller, to execute
an operation that was originally intended only for a role
manager. Similarly, Fig. 8 (b) shows a permission (deposit, (d))
being removed from the employee role. Such a modification
produces an inconvenience to such a role and all other roles
that happen to be senior to it, as execution of the deposit
operation will be denied at runtime. Fig. 8 (c) shows another
example where the original role hierarchy of the RBAC policy
is modified to introduce an unintended role (supervisor, (S)).
This way, the newly-introduced role creates a pair of security
vulnerabilities: first, it inherits the permissions from all junior
roles in the hierarchy, thus allowing for the execution of
unintended operations. Second, it also allows for a senior role
in the hierarchy to obtain an extra permission (audit, (a)), thus
possibly allowing them to perform unintended operations as
well. Fig. 9 shows an excerpt of an XML configuration file
depicting the role hierarchy modification shown in Fig. 8 (c)
(lines 6-8). Finally, Fig. 8 (d) shows a case when a role is
removed from a role hierarchy: teller is left aside by removing
the relationships with both the manager (senior) and the
employee (junior) roles. It expose an inappropriate permission
revocation to not only users holding the role teller, as such a
role is prevented from getting the permissions of its junior roles
(e.g. deposit, (d)), but also senior roles since it prevented from
getting the permissions assigned to teller (e.g., withdraw, (w))
including all other permissions that could be obtained from
junior roles to teller.

Following the automated testing approach described in
Section IV, we conducted a set of experiments to measure
the effectiveness of our assertion-based models, along with our
enhanced DBC contracts, in detecting the mutations introduced
into the applications tested in our case study. Such experiments
were carried out on a PC equipped with an Intel Core Duo
CPU running at 3.00 GHZ, with 4 GB of RAM, running
Microsoft Windows 7 64-Bit Enterprise Edition. First, we
measured the impact of our approach in the average execution
time of the applications. As described in [14], the JML-based
specifications depicting our model classes are translated into
runtime assertion checking (RAC) code, which is then executed along with the original application code for verification
purposes. In order to provide a mapping between the modeling
features included in JML contracts (as depicted in Fig. 5)
and the implementation code of each heterogeneous module,
we leveraged the features offered by the JML abstraction
functions [7]: we enhanced our supporting tool described
in Section IV to also produce abstraction functions for the
referred Spring Framework and Apache Shiro APIs. We then
executed a sample trace of the Java methods exposed by our
three applications and calculated the average execution time
over 1,000 repetitions. Such a trace was created to contain
representative operations for each application, e.g. the trace
created for the OSCAR EMR application that contains Java
methods used to update patient’s personal data as well as
information about medical appointments and prescriptions.
As shown in Table III, the introduction of RAC code has a
moderate impact on the performance, which is mostly due to
the overhead introduced by the RAC code generated to process
both the JML contracts as well as the abstraction functions. We
then recorded the results obtained by our tool while attempting
to detect (kill) the mutants introduced in both the configuration
of the Security APIs as well as the authorization checks
guarding each of the Java methods contained in our sample
traces, following the approach depicted in Fig. 8. Table III
shows a report on the number of generated test cases, including
the number of meaningful ones produced by the tool. 2 Our
meaningful test cases were able to kill all the mutants inserted
into our case study applications.
In an additional experiment, we compared the time taken by
our JML model classes to detect each of the mutant generation
techniques depicted in Fig. 8. Once again, we used a trace
of Java methods depicting the main functionality for each
application, and used the automated mutant-generation tool
described before to generate different variations to an original
RBAC policy. The results, as shown in Fig. 12, show that
adding/removing a role to a given hierarchy is the most costly
mutation to be detected by the RAC code through processing
our assertion-based JML classes. This is mostly due to the way
how role hierarchies are implemented in our JML classes, by
using a series of java.util.ArrayList objects to store
references to each senior/junior role in a given hierarchy, and
allowing for such references to be inspected recursively when
determining if there is a seniority relationship between two
given roles.
2 In JET, a test case T for a given method M is said to be meaningful if
the tool is able to randomly create values for M’s formal parameters in such
a way M’s preconditions involving such parameters are satisfied. Otherwise T
is said to be meaningless.

t

M

A. Assertion-based Verification
c

A

w

T

t

c

M

t

S

a

A

T

E

T

w

d

E

(a) Adding a Permission.

c

A

d

E

t

M

(b) Removing a Permission.

w

c

d

(c) Adding a Role.

M

t

A

T

E

d

w

(d) Removing a Role.

Fig. 8: Introducing Mutants in an RBAC Policy.
1 <?xml ...>
2 ...
3 <beans:bean id="roleHierarchy" ...>
4
<beans:property name="hierarchy">
5
<beans:value>
6
manager
> supervisor
7
supervisor > teller
8
supervisor > agent
9
teller
> employee
10
agent
> employee
11
</beans:value>
12
</beans:property>
13 </beans:bean>
14 ...

Fig. 9: Introducing Mutants in Spring Framework.
TABLE III: Experimental Data on Using JET and ESC/Java2.
Banking

JMoney

OSCAR

46

136

125

4.56

17.32

15.4

209.76

2355

1925

Total methods
JET
Analysis time per method /s
Total analysis time /s
Runtime overhead /s
Generated test cases
Meaningful test cases

0.97

2.34

1.78

1000

1000

1000

150

250

225

ESC/Java2
Analysis time per method /s
Total analysis time /s

0.43

2.07

0.5

19.66

281.41

63.00

As mentioned in previous sections, we also leverage the
ESC/Java2 tool for providing verification guarantees based on
static analysis techniques and our proposed approach. However, despite the support provided for JML-based constructs by
such a tool, some challenges must be addressed: first, in order
to prove the correctness of a certain source code C against
its corresponding JML contracts, the tool additionally requires
that the JML specifications of each library called within C are
available, including the specifications of additional libraries the
original ones may eventually call later on. In some cases, such
a requirement may notoriously increase the amount of VCs

1 public class Subject{
2
3 /*@ public normal_behavior
4
@ requires true;
5
@ ensures \result == true || \result == false;
6
@ also
7
@ public exceptional_behavior
8
@ requires false;
9
@ assignable \nothing;
10
@*/
public /*@ pure @*/ boolean hasRole(String r){
11
12
return true;
13
}
14 }

Fig. 10: Specifications Stubs for the Apache Shiro API.
1 public interface Account{
2
3 /*@ public normal_behavior
4
@ requires amt > 0.0;
5
@ assignable balance;
6
@ ensures
7
@
(SecurityUtils.getSubject()
8
@
.hasRole("teller") ||
9
@
SecurityUtils.getSubject()
10
@
.hasRole("manager"))
11
@
==>
12
@
...
13
@*/
14 public void withdraw(double amt)
15
throws SecurityException;
16 }

Fig. 11: Translating Model JML Classes.
6

Performance of JML Model CLasses against Mutation Techniques

10

ADD PERM

REM PERM

ADD ROLE

REM ROLE

5

Processing Time (ms)

10

creep problem. In particular, as described in Section IV,
we assumed the Security APIs leveraged within our case
study have been implemented correctly and previously verified
elsewhere. Therefore, there is no need to include their corresponding source code in our verification process. Based on
this observation, we provided specification stubs for the leveraged Security APIs whose JML-based annotations are trivially
satisfied. Fig. 10 shows the translated JML specifications for
the method hasRole of class Subject, which implements
an authorization check in the Apache Shiro API, as shown in
Fig. 2 (b). This process can be carried out by security domain
experts for the Security APIs and must only be revised when
new API versions are released. Second, as mentioned before,
the JML model classes, which are a core part of the approach
shown in Section IV, are beyond the current capabilities of
ESC/Java2. To overcome this limitation, we provided JML
specifications that do not employ the JML model classes and
use low-level JML concepts instead. For example, the role
hierarchy depicted in Table II and Fig. 5, which checks that the
current user is granted a role senior to teller (e.g. manager),
can be translated into the JML contracts shown in Fig. 11 (lines
7-10): the references to the model class JMLRBACRole have
been substituted for the hasRole method of class Subject
provided by the Apache Shiro API, and are integrated together
by using the operator || in JML, applied to all relevant senior
roles (e.g., the manager role in line 10).
After the preparation steps, we applied our analysis technique to the applications under our case study, by following
the mutation-based approach described before. We used a
conventional Lenovo Thinkpad T510 laptop (Intel Core i7620M Processor, 2.66GHz, 8 GB RAM). All mutants were
automatically detected by ESC/Java2 even if they were hidden
within the many methods of our case studies. The runtime of
the three applications under our case study is given in Table III.
VI.

4

10

3

10

2

10

Number of mutants introduced in RBAC Policy

Fig. 12: Runtime performance of a Dynamic Verification
Approach.
that need to be proved by the tool, so the verification process
becomes prohibitively expensive, resulting in the specification
creep problem [15]. Second, an additional problem arises from
the lack of support offered by the current tool for advanced
JML concepts, such as the JML model classes introduced in
Section IV and the JML abstraction functions also described
before, as the internally-produced VCs are too complex for the
tool to handle, which limits the applicability of our assertionbased models.
Subsequently, we present an approach that addresses these
challenges while still providing verification guarantees for our
assertion-based approach. First, we addressed the specification-

D ISCUSSION

AND

R ELATED W ORK

The experimental results depicted in Section V-A support
our claim that our approach can effectively expose the set of security vulnerabilities caused by the incorrect source-code level
implementations of security models. In our approach, we have
selected Java for our proof-of-concept implementation due to
its extensive use in practice. Moreover, we have also chosen
JML as the specification language for defining our assertionbased security models due to its enhanced tool support as
well as its language design paradigm, which supports rich
behavioral specifications. At the same time it strives to handle
the complexity of using complex specification constructs, in
such a way it becomes suitable for average developers to use
[6]. (see Table I). We believe our approach can be extended
to other programming languages/development platforms. For
instance, Spec# [20] provides rich DBC-based specifications
for the C# language, depicting an approach similar to JML.
Moreover, our approach can be also applied to other Javabased frameworks such as JEE [21] or Android [22], which
may help implement authorization checks for guarding access
to its core system services. Despite our success, some issues
still remain in the verification process. In particular, ESC/Java2
may produce false positives (in case the built-in theorem prover
cannot prove a VC) and false negatives (e.g., restrictions on
loop unrolling). To deal with this situation, a possible solution
may consider a runtime testing approach, like the one we have

described using the JET tool, for all methods raising warnings
by ESC/Java2, thus showing a way in which both techniques
can be to provide stronger guarantees for the verification.
Second, as shown in Table III, the number of meaningful
test cases produced by the JET tool is considerably less than
the number of test cases created, which may affect the test
coverage provided by the tool and could allow for potential
security vulnerabilities to remain hidden during the verification
process. This is mostly due to the limitations on the automated
testing technique [14]. A possible solution would adopt a static
approach for those methods whose test coverage is found to
be below a given threshold.
Our work is related to other efforts in software security:
Architectural risk analysis [23] attempts to identify security
flaws on the level of the software architecture and hence is
unrelated to the source-code level addressed in this approach.
Language-based security approaches in the sense of Jif [24]
allow software to be verified against information flow policies
rather than supporting specific security requirements for different Security APIs. Formal verification of RBAC properties has
been already discussed in the literature [16]. These approaches
are mostly focused on verifying the correctness of RBAC
models without addressing their corresponding verification
against an implementation at the source-code level. The work
closely related to ours involves the use of DBC, which was
explored by Dragoni, et al. [25]. In addition, Belhaouari et al.
introduced an approach for the verification of RBAC properties
based on DBC [26]. Both approaches, while using DBC for
checking RBAC properties, do not include the use of reference
models to better aid the specification of DBC constraints in
the security context. Moreover, no support is provided as APIindependent constructs, such as the JML model capabilities
discussed in our approach.
VII.

C ONCLUSIONS

AND

F UTURE W ORK

In this paper, we have addressed the problem originated
by the existence of security vulnerabilities in software applications. We have shown how such vulnerabilities, which may
exist due to the lack of proper specification and verification
of security checks at the source-code level, can be tackled
by using well-defined reference models with the help of
software assertions, thus providing a reference for the correct
enforcement of security properties over applications composed
of heterogeneous modules such as APIs and SDKs. Future
work would include the introduction of assertion-based models
to better accommodate other relevant security paradigms, e.g.,
the correct usage of cryptography APIs. Also, we plan to
refine our proposed RBAC model introduced in Section IV by
introducing an automated translation from the specifications
depicted in the ANSI RBAC standard, which are written in
the Z specification language, to our supporting language JML.
ACKNOWLEDGMENT
This work was partially supported by a grant from the US
Department of Energy (DE-SC0004308) .
R EFERENCES
[1]

M. Georgiev, S. Iyengar, S. Jana, R. Anubhai, D. Boneh, and
V. Shmatikov, “The most dangerous code in the world: validating SSL
certificates in non-browser software,” in Proc. of the ACM Conf. on
Computer and comm. security, 2012, pp. 38–49.

[2] S. Fahl, M. Harbach, T. Muders, L. Baumgärtner, B. Freisleben,
and M. Smith, “Why eve and mallory love Android: an analysis of
Android SSL (in)security,” in Proc. of the ACM Conf. on Computer
and communications security, 2012, pp. 50–61.
[3] R. S. Sandhu, E. J. Coyne, H. L. Feinstein, and C. E. Youman, “RoleBased Access Control Models,” IEEE Computer, vol. 29, no. 2, pp.
38–47, 1996.
[4] D. S. Rosenblum, “A practical approach to programming with assertions,” IEEE Trans. Softw. Eng., vol. 21, no. 1, pp. 19–31, Jan. 1995.
[5] C. A. R. Hoare, “An axiomatic basis for computer programming,”
Communications of the ACM, vol. 12, no. 10, pp. 576–580, Oct 1969.
[6] L. Burdy, Y. Cheon, D. Cok, M. Ernst, J. Kiniry, G.-T. Leavens,
K. Leino, and E. Poll, “An overview of JML tools and applications,”
in Proc. 8th Int’l Workshop on Formal Methods for Industrial Critical
Systems (FMICS 03), 2003, pp. 73–89.
[7] Y. Cheon, G. Leavens, M. Sitaraman, and S. Edwards, “Model variables:
cleanly supporting abstraction in design by contract: Research articles,”
Softw. Pract. Exper., vol. 35, no. 6, pp. 583–599, May 2005.
[8] American National Standards Institute Inc., “Role Based Access Control,” 2004, ANSI-INCITS 359-2004.
[9] J. M. Spivey, The Z notation: a reference manual. Upper Saddle River,
USA: Prentice-Hall, Inc., 1989.
[10] OASIS, “eXtensible Access Control Markup Language (XACML) TC,”
2014, https://www.oasis-open.org/committees/xacml/.
[11] OASIS, “XACML v3.0 Core and Hierarchical Role Based Access
Control (RBAC) Profile Version 1.0,” 2014, http://docs.oasis-open.org/
xacml/3.0/xacml-3.0-rbac-v1-spec-cd-03-en.html.
[12] Pivotal, Inc., “Spring security 3.1.2,” 2013, http://static.springsource.
org/spring-security/site/index.html.
[13] The Apache Software Foundation, “Apache shiro 1.2.1,” 2013, http:
//shiro.apache.org/.
[14] Y. Cheon, “Automated random testing to detect specification-code inconsistencies,” in Proc. of the 2007 Int’l Conf. on Software Engineering
Theory and Practice, Orlando, Florida, U.S.A., 2007.
[15] C. Flanagan, K. R. M. Leino, M. Lillibridge, G. Nelson, J. B. Saxe,
and R. Stata, “Extended static checking for Java,” in Proc. of the ACM
SIGPLAN Conf. on Prog. language design and implementation, 2002,
pp. 234–245.
[16] H. Hu and G.-J. Ahn, “Enabling verification and conformance testing
for access control model,” in Proc. of the 13th ACM Symp. on Access
Control Models and Technologies, 2008, pp. 195–204.
[17] OSCAR EMR, “OSCAR Electronic Medical Records System,” 2014,
http://oscar-emr.com/.
[18] J. Gyger and N.l Westbury, “JMoney Financial System,” 2014, http:
//jmoney.sourceforge.net/.
[19] Y. Jia and M. Harman, “An analysis and survey of the development of
mutation testing,” IEEE Transactions on Software Engineering, vol. 37,
no. 5, pp. 649 –678, 2011.
[20] M. Barnett, R. Leino, and W. Schulte, “The spec# programming system:
An overview,” in Proc. of the 2004 Int’l Conf. on Construction and
Analysis of Safe, Secure, and Interoperable Smart Devices. Berlin:
Springer-Verlag, 2005, pp. 49–69.
[21] Oracle
Inc., “Java Platform
Enterprise
Edition,”
2014,
urlhttp://www.oracle.com/technetwork/java/javaee/overview/index.html.
[22] Google Inc., “Android,” 2014, http://www.android.com.
[23] G. McGraw, Software Security: Building Security In. Addison-Wesley,
2006.
[24] A. Sabelfeld and A. C. Myers, “Language-based information-flow
security,” IEEE J. Selected Areas in Communications, vol. 21, no. 1,
pp. 5–19, Jan. 2003.
[25] N. Dragoni, F. Massacci, K. Naliuka, and I. Siahaan, “Security-bycontract: Toward a semantics for digital signatures on mobile code,”
in Public Key Infrastructure, ser. LNCS. Springer Berlin, 2007, vol.
4582, pp. 297–312.
[26] H. Belhaouari, P. Konopacki, R. Laleau, and M. Frappier, “A design by
contract approach to verify access control policies,” in 17th Int’l Conf.
on Engineering of Complex Computer Systems (ICECCS), july 2012,
pp. 263 –272.

2015 IEEE Conference on Network Function Virtualization and Software Defined Network (NFV-SDN)

VNGuard: An NFV/SDN Combination Framework
for Provisioning and Managing Virtual Firewalls
Juan Deng† , Hongxin Hu† , Hongda Li† , Zhizhong Pan† ,
Kuang-Ching Wang† , Gail-Joon Ahn‡ , Jun Bi , Younghee Park
† Clemson University ‡ Arizona State University  Tsinghua University  San Jose State University
Abstract—Network Function Virtualization (NFV) together
with cloud technology enables users to request creating ﬂexible virtual networks (VNs). Users also have speciﬁc security
requirements to protect their VNs. Especially, due to changeable network perimeters, constant VM migrations, and usercentric security needs, VNs require new security features that
traditional ﬁrewalls fail to provide, because traditional ﬁrewalls
rely greatly on restricted network topology and entry points to
provide effective security protection. To address this challenge,
we propose VNGuard, a framework for effective provision and
management of virtual ﬁrewalls to safeguard VNs, leveraging
features provided by NFV and Software Deﬁned Networking
(SDN). VNGuard deﬁnes a high-level ﬁrewall policy language,
ﬁnds optimal virtual ﬁrewall placement, and adapts virtual
ﬁrewalls to VN changes. To demonstrate the feasibility of our
approach, we have implemented core components of VNGuard
on top of ClickOS. Our experimental results demonstrate the
effectiveness and efﬁciency of virtual ﬁrewalls built on VNGuard.

I. I NTRODUCTION
Network function virtualization (NFV) was recently proposed to decouple network functions (NFs), such as ﬁrewall,
load balancer, NAT, and web proxy, from dedicated hardware
and implement them as pure software instances on industrial
standard high-volume servers, networking and storage. NFV
calls for a carrier-grade cloud platform, leveraging de-facto
industry cloud management and standards [1]. NFV together
with cloud platforms allows a user to build ﬂexible virtual
networks (VNs).
Users also have security requirements to protect their VNs,
more speciﬁcally, the applications or services running on the
VNs. Cloud providers, such as Google Cloud Platform [2],
have already allowed users to request protecting their services. Unfortunately, traditional ﬁrewall technique lacks the
ﬂexibility and adaptivity to meet the new security needs
arising with VNs.1 First of all, a traditional ﬁrewall depends
on restricted network topology and entry points to provide
effective security protection. However, due to the dispersion
of virtual machines (VMs) in VNs across racks and data
centers, and VM migrations for the purpose of resource
management and optimisation, the perimeter of VNs become
blurred and ﬂuid [1]. Second, a user may have speciﬁc security
requirements for VNs, which require dedicated small ﬁrewalls
tailored to accommodate their requirements, while traditional
1 In traditional networks, ﬁrewall functions are generally implemented on
vendor proprietary appliances or middleboxes. However, middleboxes usually
lack a general programming interface, and their ﬂexibility and versatility are
also very limited [3].

978-1-4673-6884-1/15/$31.00 ©2015 IEEE

ﬁrewalls are usually large proprietary appliances, and provisioning customized appliances for each user is costly and impractical. Third, VNs change frequently and the changes take
effect fast. Changes may come from either users or the service
provider. For example, a user may issue VN changes because
s/he has needs to change or update the services running within
the VN, or the NFV provider decides to migrate VMs for the
purpose of resource management and optimization. This calls
for dynamic and fast ﬁrewall reconﬁguration and replacement
to adapt to VN changes, which cannot be easily achieved by
traditional ﬁrewalls.
In NFV, a ﬁrewall, serving as a vital security network
function, is implemented as a software instance (a.k.a virtualized ﬁrewall or virtual ﬁrewall). A virtual ﬁrewall offers the
necessary ﬂexibility and mobility to effectively protect VNs.
With virtual ﬁrewalls, users are enabled to ﬂexibly deﬁne
and manage customized ﬁrewalls to protect their own VNs.
Also, virtual ﬁrewalls break the dependency on ﬁxed network
topology and entry points, since they can be placed on any
VM with great ﬂexibility, as long as the VM can provide
the required resources. In addition, virtual ﬁrewalls, being
software instances, can be reconﬁgured and moved easily and
fast to adapt to VN changes.
The ﬂexibility and mobility of virtual ﬁrewalls must rely on
the support of dynamic, fast and reliable trafﬁc steering. As
virtual ﬁrewalls are no longer required to be placed at ﬁxed
network entry points, underlying ﬂexible trafﬁc steering must
be in place to pass network trafﬁc to virtual ﬁrewalls. The
migration of virtual ﬁrewalls also need a robust trafﬁc steering
support to ensure no security holes during and after virtual
ﬁrewall migration. Software Deﬁned Networking (SDN), recognized as complementary technology to NFV [4]–[8], is able
to provide the trafﬁc engineering needed by virtual ﬁrewalls.
To this end, we propose VNGuard, a comprehensive framework for effectively provisioning and managing virtual ﬁrewalls, leveraging both NFV and SDN techniques. VNGuard
enables users to readily deﬁne their security policies for the
VNs without concerning low-level VN deployment. VNGuard
can also automatically translate high-level security policies
into low-level ﬁrewall rules, and ﬁnd an optimal virtual
ﬁrewall deployment solution while still respecting resource
and performance constraints. In addition, VNGuard enables
virtual ﬁrewall reconﬁguration and replacement to adapt to VN
changes and ensures that the replacement remains optimal. To
the best of our knowledge, VNGuard is the ﬁrst solution for

107

2015 IEEE Conference on Network Function Virtualization and Software Defined Network (NFV-SDN)

systematic design and management of virtual ﬁrewalls based
on NFV and SDN. We summarize our contributions as follows:
• We introduce a high-level service-oriented policy language in VNGuard that allows users to specify high-level
security policies without considering low-level concrete
VN deployment.
• We propose an approach based on Integer Programming
to ﬁnd an optimal virtual ﬁrewall placement, which fulﬁls
resource constraints.
• We provide a mechanism for dynamic virtual ﬁrewall
adaption to protect the VNs, which can be frequently
changed and migrated.
• We implement core components of VNGuard on top
of ClickOS [23]. Our experiment results show that our
approach can efﬁciently and effectively provision and
manage virtual ﬁrewalls.
The rest of the paper is organized as follows. Section II
presents an overview of VNGuard framework. Section III
describes our high-level service-oriented policy language.
Section IV presents our solution for ﬁnding optimal virtual
ﬁrewall placement. Section V introduces our approach for
dynamic virtual ﬁrewall adaption. Section VI presents our
VNGuard implementation and the evaluation of VNGuard efﬁciency. We overview related work in Section VII. Section VIII
discusses several important issues. Conclusion and future work
are addressed in Section IX.
II. VNGuard F RAMEWORK
In designing VNGuard, we achieve the following design
goals:
• High-Level Service-Oriented Policy Language. A user
has speciﬁc security requirements to protect the services
running on the VNs, but s/he may lack the expertise and
experience to be able to write low-level ﬁrewall rules
that are associated with VN deployment. Besides, VN
deployment information may not be readily available to
users, because the service provider who provisions VNs
may intentionally hide the deployment information to
protect the infrastructure. Therefore, a new ﬁrewall policy
language is desirable and should be high-level, serviceoriented, and user-centric for a user to easily specify
his/her security requirements.
• Optimal Virtual Firewall Placement. A user’s security
requirements need to be translated to ﬁrewall rules that
are associated with VN deployment. There may exist
thousands of ﬁrewall rules for a user. Placing all rules
in one virtual ﬁrewall instance may not be applicable,
considering that rule overload causes ﬁrewall performance degradation, as suggested in Figure 5. Obviously,
more resources can help achieve higher performance.
However, resources in cloud are valuable, and must be
utilized optimally. Given a set of ﬁrewall rules, ﬁnding a
placement solution that meets the optimization goal while
respecting to both performance and resource constraints
is a bin packing problem, which is typically combinatorial
NP-hard.

VNGuard
Policy Specification

FW Instances

Policy
Language
Firewall
Placement

SDN
Switches

Policy
Transformation
Firewall
Adaption

Firewall
Provision

SDN Controller
OpenFlow

Fig. 1. VNGuard framework.

Dynamical Virtual Firewall Adaption. VNs are more
ﬂexible than traditional networks and face changes more
frequently. VN changes require virtual ﬁrewalls to be
properly reconﬁgured and replaced, so that VNs receive
the same protection during and after changes. A mechanism should be design to dynamically adapt virtual
ﬁrewalls to VN changes.
We design VNGuard as shown in Figure 1, which is an
SDN application [6]. VNGuard has four major components:
Policy Speciﬁcation, Firewall Placement, Firewall Adaption,
and Firewall Provision. Policy Speciﬁcation deﬁnes a highlevel service-oriented Policy Language for a user to specify
security policies. Policy Transformation transfers high-level
security policies to low-level ﬁrewall rules. These rules are
then processed by Firewall Placement to ﬁnd an optimal
virtual ﬁrewall placement. Firewall Adaption is responsible
for virtual ﬁrewall adaption with respect to VN changes and
migrations. Firewall Provision is responsible for provisioning
virtual ﬁrewalls and also maintains a database on the deployment information of virtual ﬁrewalls.
•

III. H IGH -L EVEL S ERVICE -O RIENTED P OLICY L ANGUAGE
Our purpose to design a high-level, service-oriented, and
user-centric policy speciﬁcation language is to enable users to
easily specify their security policies without the knowledge of
low-level VN deployment information.
Our policy language deﬁnes several basic components as
shown in Table I. V = {v1 , v2 , ...} is a set of VNs that a user
has. Each VN hosts multiple services. A service is deﬁned as
a combination of VNs that host the service, and the protocol
and the port number that the service uses. For example, an
http service running in VN v1 is described as
v1 , 80, tcp
Using such a deﬁnition, a user can deﬁne different security
policies for the same service in different VNs. For example,
a user may allow incoming SSH connections to one VN, but
ban them to another.
An object is a communication end point. It is deﬁned as a
combination of hosts and ports. Hosts are uniquely represented

108

2015 IEEE Conference on Network Function Virtualization and Software Defined Network (NFV-SDN)

TABLE I
BASIC C OMPONENTS OF O UR H IGH -L EVEL P OLICY L ANGUAGE

P = {p1 , p2 , ...}

P is a ﬁnite set of ports that services use.

T = {tcp, udp, icmp, ...}

T is a ﬁnite set of protocols that services use.

V = {v1 , v2 , ...}

V is a ﬁnite set of VNs that a user has.

s ::= V̄ , p, t

A service s has three members with V̄ being a subset of a user’s VNs that
run s (that is, V̄ ⊆ V ), p ∈ P being the port number used by s, and t ∈ T
being the protocol used by s. s can call its members by s.1 = V̄ , s.2 = p
and, s.3 = t.

Z = {s1 , s2 , ..}, and for all s(i) .1 = v

A security zone Z is a ﬁnite set of services {s1 , s2 , ...} in the same virtual
network.
An action a is one of accept, deny and delete. delete is used in the virtual
ﬁrewall adaption.

a ::= accept | deny | delete
o ::= IP | domain name | V N name, p

An object o has two members with the ﬁrst being either an IP address, a
domain name, or the name of a VN, and the second element p ∈ P being a
port number.

policy ::= s, a, o

A policy deﬁnes the access right of object o on service s. A policy can call
its members by using policy.1 = service, policy.2 = r, and policy.3 =
o. We also allow consecutive member calling. For example policy.1.1 =
V̄ , andpolicy.3.2 = p.

by either IP addresses, a domain name, or the name of a
VN. Hosts may exist inside or outside of a user’s VNs. Hosts
outside of a user’s VNs are identiﬁed by either IP addresses
or a domain name. Hosts inside a user’s VNs are usually
identiﬁed by either IP addresses or the name of a VN.
Our language can supports a wide card representation of
policies. For example,
∗, 80, tcp
describes an http service exiting in all virtual networks of a
user.
A policy is formalized as
s, a, o
that deﬁnes access right of object o on service s. For example,
v1 , 80, tcp, deny, v2 , ∗
states that trafﬁc from a virtual network v2 is denied to access
the http service in a virtual network v1 .
Our policy language can easily support the deﬁnitions of
global policies, group policies, and local policies by simply
manipulating member V̄ in the service deﬁnition V̄ , p, t. A
global policy is deﬁned as
∗, p, t, a, o
that states that the service deﬁned by port p and protocol t
in ALL of a user’s VNs deny/accept trafﬁc from object o. A
group policy is deﬁned as
V̄ , p, t, a, o where (V̄ ⊂ V )
that states that the service deﬁned by port p and protocol t in
the subset of a user’s VNs, V̄ , deny/accept trafﬁc from object
o. Naturally, a local policy is deﬁned as

v, p, t, a, o
that states that the service deﬁned by port p and protocol t
in a user’s VN, v, deny/accept trafﬁc from object o.
With our policy language, users are able to write high-level
policies easily without knowing low-level VN deployment.
Policy Transformation (Figure 1) translates the high-level
polices to low-level ﬁrewall rules that are associated with the
low-level VN deployment. To do so, Policy Translation needs
to retrieve VN deployment information, which is maintained
by Firewall Provision. For example, for a policy
v1 , 80, tcp, deny, v2 , ∗
Policy Transformation retrieves the deployment information of
v1 and v1 , and ﬁnds the IP address (10.10.1.2) of the VM in
v1 that hosts the http service and IP addresses (130.127.24.*)
of v2 , and generates a ﬁrewall rule as 2
130.127.24.∗, 10.10.1.2, 80, tcp, deny
Note that Policy Transformation in VNGuard can also detect
and resolve rule conﬂicts by using the conﬂict detection and
resolution mechanism introduced in our previous work [18].
IV. O PTIMAL V IRTUAL F IREWALL P LACEMENT
Figure 2 shows the process of virtual ﬁrewall placement
in VNGuard. User-speciﬁed security policies are processed by
Policy Transformation and transformed to low-level ﬁrewall
rules. Rule Database keeps a copy of the rules for each user,
which will be used later for virtual ﬁrewall adaption. The
rules are then sent to Firewall Placement. Firewall placement
subjects to resource constraints, which are stored in Resource
2 A ﬁrewall rule is normally speciﬁed as a 6-tuple of source address, source
port, destination address, destination port, protocol, action.

109

2015 IEEE Conference on Network Function Virtualization and Software Defined Network (NFV-SDN)

1. Policies
2. Rules
Policy
Transformation

Rule
Database

Firewall
Provision

Firewall
Placement

Policy
Transformation

4. Resource
updates

2. Rules
4. Firewall
placement

1. Service
delete policy

Resource
Constraints
Database

3. Resource
constraints

Firewall
Provision

Resource
Constraints
Database

2. Rules

3. Rules

Firewall
Adaption

3. Rule
updates

Rule
Database

Fig. 3. Firewall Adaption to Service Deletion.

5. Resource updates

1. policies

Fig. 2. Firewall Placement Digram.

Policy
Transformation

Constraints Database. Firewall Placement retrieves the constraints and works out an optimal placement solution. The
solution is sent to the Firewall Provision for creating and
running virtual ﬁrewall instances. We consider two resource
constraints on virtual ﬁrewall rule placement:
• NFV service provider limits the number of virtual ﬁrewall
instances that a user can have.
• NFV service provider limits the resource that each virtual
ﬁrewall instance can have. Hence, there is a cap on the
number of rules that a virtual ﬁrewall instance can hold.
To achieve the optimization goal of virtual ﬁrewall placement,
Firewall Placement in VNGuard uses an Integer Programming
based solution to ﬁnd the optimal placement.
Integer Programming Based Solution Integer Programming is a method for the optimization of a linear objective
function, subjecting to linear constraints. We model the resource constraints as
• Let F = {f1 , ..., fN } be a set of virtual ﬁrewall instances
that a user can have.
• Let C = {c1 , ..., cN } with ci be the number of ﬁrewall
rules that an instance fi can hold.
These constraints are stored in Resource Constraints Database.
Let R = {r1 , r2 , ..., rM } be the set of rules to be placed.
Each rule is to be placed on only one instance, because virtual
ﬁrewall performance degrades as the number of rules loaded
on it increases (Figure 5). Let vij ∈ {0, 1} be an indicator of
placing rule ri on instance fj . If vij = 1, it indicates that rule
ri is placed on instance fj . Otherwise, the rule is placed on
another instance.
Deﬁnition: A placement V = {v11 , ..., vM N } is feasible if it
satisﬁes the following conditions:

condition(1): i vij ≤ cj for each j
condition(2): j vij = 1 for each i
condition(3): vi,j ∈ {0, 1} for each i, j
Condition (1) states that the number of ﬁrewall rules placed on
each instance fj must not exceed its capacity. Condition (2)
guarantees that a ﬁrewall rule is placed on only one instance.
We denote the objective function that a service provider
wants to optimize as G(V ), a function of placement V .
Our Integer Programming formulization for virtual ﬁrewall
placement problem is:
min: G(V )

Rule
Database

3. old
rules
9. rule
updates

2.rules
Firewall
Adaption
4. rules to
bedeleted

Firewall
Provision

4. rules to
be added

Firewall
Placement

7. placement

5. resource updates
due to rule deletion
8. resource updates
due to rule
placement

6. resource
constraints

Resource
Constraints
Database

Fig. 4. Firewall Adaption to Policy Update.

s.t. condition(1), condition(2), condition(3)
Solving the above problem gives a feasible placement V .
Integer Programming deals with linear objective functions
and constraints. For the ﬁrewall placement formulization,
the constraints are always linear, but the objective functions
may be nonlinear. For example, if we consider the objective function
the number of ﬁrewall instances, then
 to be 
G(V ) = j min(1, i vij ). In this case, non-linear Integer
Programming [19] should be used.
Resource Updates Firewall Provision creates the ﬁrewall
instances according to the optimal solution provided by
Firewall Placement. Then it updates Resource Constraints
Database. For the instances in F that have rules placed,
decrease their corresponding c values by the number of rules
placed on them. The updated c values reﬂect the number of
new rules that can be placed on these instances in the future.
The update of Resource Constraints Database is crucial for
the virtual ﬁrewall adaption.
V. DYNAMIC V IRTUAL F IREWALL A DAPTION
VNs are relatively easy to be changed. VN changes may be
initiated by either a user or an NFV service provider. In this
paper, we consider three types of VN changes.
• Type I: A user adds or deletes services in a VN.
• Type II: A user updates security policies for a VN.
• Type III: VM migration and scaling out/in.
The changes of a VN require reconﬁguring and replacing
virtual ﬁrewalls to ensure that the VN receives the same
protection during and after changes. We describe below how
VNGuard adapts virtual ﬁrewalls to VN changes.
Type I. When a service is deleted, the corresponding ﬁrewall rules protecting that service should be located and safely

110

2015 IEEE Conference on Network Function Virtualization and Software Defined Network (NFV-SDN)

deleted, to save resource. We are aware that one ﬁrewall
rule may be applied to multiple services. Analysis should be
conducted so that the rule deletion will not affect services other
than the deleted one. Figure 3 shows the process of ﬁrewall
adaption to service deletion. A user speciﬁes the services to
be deleted using our policy language, with action setting to
delete:
s, delete, o
Policy Transformation translates the service deletion policies
to ﬁrewall rules with action setting to delete, and sends
them to Firewall Adaption. Firewall Adaption sends the rules
to Firewall Provision, and deletes them in Rule Database.
Firewall Provision locates the ﬁrewall instances that have
these rules and then deletes them. After rule deletion, Firewall
Provision updates Resource Constraints Database. For the
instances in F who have rules deleted, their c values will
be added by the number of deleted rules, because after the
rule deletion, the instances release room for new rules in the
future.
When a user adds a new service, s/he also speciﬁes the
security policies for that service. The policies will be transformed to ﬁrewall rules and placed as we have discussed in
Section IV.
Type II. A user may update security policies for a VN.
Policy update may result in some old ﬁrewall rules to be
deleted, and/or some new rules to be added. Figure 4 shows
the process of ﬁrewall adaption to security policy updates.
Policy Transformation generates the new rules for the updated
security policies, and sends them to Firewall Adaption. Firewall Adaption retrieves from Rule Database the old rules,
compares new rules with old ones, and ﬁnds (1) old rules to
be deleted and (2) new rules to be added. Rules to be deleted
are sent to Firewall Provision. Rules to be added are sent to
Firewall Placement, which works out a placement solution
and then sends the solution to Firewall Provision. Firewall
Provision will perform rule deletion and placement operations.
At last, Firewall Provision will update Resource Constraints
Database.
Type III. Changes occur to VMs in a VN often. Common
changes include VM migration and scaling out/in [22]. Virtual
ﬁrewalls protecting the VN must adapt to these VM changes. A
VM may be migrated from one rack to another, due to resource
maintenance. In this case, the old ﬁrewall placement may no
longer be optimal and the placement must be conducted again.
In scaling out, new copies of existing VMs are created. New
ﬁrewall rules must be added so as to protect these new copies.
In scaling in, a VM is deleted. Then, the ﬁrewall rules that
are associated with the VM must be located and deleted. We
further discuss some safety issues caused by Type III changes
in Section VIII and would explore solutions in our future work.
VI. I MPLEMENTATION AND E VALUATION
We implemented the core components of VNGuard on
top of ClickOS [23] for provisioning and managing virtual
ﬁrewalls. ClickOS is a Xen-based software platform optimized

Fig. 5. The average processing time per packet of the virtual ﬁrewalls with
different numbers of rules. The incoming trafﬁc rate is set to 90Mbps and
packet size varies from 64-byte to 1024-byte.

Fig. 6. The average processing time per packet of the virtual ﬁrewall with
different number of rules. Packet size is set to1024-byte and throughput varies
from 10Mbps to 90Mbps.

for fast provision of virtual network functions at large scale.
A virtual network function instance created in ClickOS can be
as small as 5MB, and can be booted within 30 milliseconds.
It only takes around 220 milliseconds to create and boot
400 instances. ClickOS adopts Click [24] for the virtual
network function development. Click provides large numbers
of simple, well-known networking processing elements for
building virtual network functions. However, ClickOS does not
offer the necessary features to support virtual ﬁrewall adaption.
In particular, ClickOS does not allow ﬁrewall rules on a
virtual ﬁrewall to be updated without rebooting the ﬁrewall. To
solve this problem, we developed three new Click elements:
1) FirewallTable; 2) FirewallMatch; and 3) FirewallManager.
The FirewallTable element acts as the basic storage of ﬁrewall rules. The FirewallMatch element receives and forwards
packets according to the ﬁrewall rules in FirewallTable. The
FirewallManager element is designed to send messages to
update ﬁrewall rules in FirewallTable. Firewall administrators
can specify a network interface in a virtual machine and
send messages encapsulated by IP packets via that network
interface. For the virtual ﬁrewall placement, VNGuard makes
use of a Matlab Integer Programming solver.
We designed experiments to evaluate three key aspects

111

2015 IEEE Conference on Network Function Virtualization and Software Defined Network (NFV-SDN)

in varied sizes and rates to a server, and the trafﬁc was passed
to and processed by a virtual ﬁrewall provisioned by our
VNGuard. We measured the processing time per packet of
the virtual ﬁrewall. The client and server are two VMs on
CloudLab, and each with two Intel E5-2660 V2 10-core CPUs
at 2.20GHz,16x 16GB DDR4 RAM and Dual-port Intel 10be
NIC. The virtual ﬁrewall created by VNGuard had 1 CPU and
40 MB memory. Figure 5 shows the average processing time
per packet with 90Mbps incoming packet rate. The observation
indicates an approximately line-rate increase of the average
processing time per packet as we added up to 2100 ﬁrewall
rules. With the same number of rules, the processing time
appears to increase as the packet size grows. Figure 6 shows
the average processing time of each packet, with the packets
size setting to 1024 bytes, and the throughput varing from
10Mbps to 90Mbps. As the number of rules increases, we
can see a steady, line-rate increase of the average processing
time per packet. However, with the same number of ﬁrewall
rules, the throughput appears to have little effect on the average
processing time per packet.
Experiment 2. We adopted an Integer Programming based
approach for virtual ﬁrewall placement in VNGuard. The
performance of the approach is inﬂuenced by (1) the number
of rules (M ) to be placed, and (2) the number of instances (N )
to place the rules in. In our experiment, we measured the time
to ﬁnd an optimal placement solution for different M and N
values. Figure 7 shows our experiment results. Larger M and
N are longer it takes to ﬁnd an optimal placement. According
to the study conducted by [26], the average number of ﬁrewall
rules in real networks is around 793. We have tested our
approach with the maximum of 2100 rules in our experiments.
Even though there are 7 instances, our system takes less
than 0.2 second to ﬁnd an optimal placement solution, which
indicates that our approach is pretty efﬁcient.
Experiment 3. To adapt to VN changes, two operations are
essential: ﬁrewall rule addition and deletion. We tested the
average time of these two operations on a virtual ﬁrewall
created by our VNGuard. Figure 8 shows the average time
used to add ﬁrewall rules to a virtual ﬁrewall. As the number
of ﬁrewall rules increases, the time consumed to add the rules
increases. The addition is pretty efﬁcient, as it took less than
300ms to add as many as 450 ﬁrewall rules. Figure 9 shows
the average time used to delete ﬁrewall rules from a virtual
ﬁrewall, which demonstrates the efﬁciency of rule deletion.

Fig. 7. Firewall Placement Performance.

Fig. 8. The average time of ﬁrewall rule addition.

Fig. 9. The average time of ﬁrewall rule deletion.

of VNGuard: (1) the packet processing performance of the
virtual ﬁrewalls provisioned by VNGuard; (2) the performance
of virtual ﬁrewall placement; and (3) the performance of
virtual ﬁrewall adaption. Our experiments are conducted using
CloudLab [25], a platform providing computing infrastructure
that enables experimenters to run cloud software stacks such
as OpenStack and CloudStack.
Experiment 1. The packet processing performance of a
virtual ﬁrewall is inﬂuenced by (1) the number of ﬁrewall
rules, (2) the packet size, and (3) the rate of incoming packets.
To test the performance, we set up a client generating trafﬁc

VII. R ELATED W ORK
ClickOS [23] has been developed as a high-performance
platform to support the development of virtual network functions. Virtual machines built on ClickOS are small (5MB)
and boot quickly (around 30 milliseconds). Also, ClickOS can
run tens of them concurrently. Our VNGuard implementation
leverages some features provided by ClickOS for building virtual ﬁrewalls. However, the virtual network functions created
by ClickOS lack adaptivity, since they cannot be dynamically
updated without rebooting the system. We have addressed this

112

2015 IEEE Conference on Network Function Virtualization and Software Defined Network (NFV-SDN)

critical problem by developing several new Click elements in
VNGuard for more effective provision of virtual ﬁrewalls.
Hu et al. [28] proposed a comprehensive framework, called
FlowGuard, for building robust SDN ﬁrewalls, which are
actually SDN applications running on top of SDN controllers.
Challenges in designing SDN ﬁrewalls were identiﬁed and
solved in FlowGuard. However, the work in this paper attempts to investigate solutions for effectively provisioning and
managing virtual ﬁrewalls in context of NFV.
Zhang et al. [20] demonstrated that careless policy updates
may result in security volitions. They presented safe and
efﬁcient policy update algorithms for ﬁrewall policy updates.
However, the proposed algorithms are only able to deal with
policy updates on a single ﬁrewall. The policy adaption mechanism in VNGuard coordinates policy updates across multiple
virtual ﬁrewalls.
Different network function control frameworks have
been recently proposed [3], [7], [9]–[13]. In particular,
Split/Merge [13] is a control framework to achieve virtual
middlebox elasticity, providing the ability to create or delete
virtual middlebox replicas on demand. Split/Merge identiﬁes
the internal and external states of a virtual middlebox, and
provides APIs for copying the internal states from the virtual
middlebox to its replica. OpenNF [7] is another framework for
controlling the internal states of virtual middleboxes. OpenNF
provides APIs for richer controls, including copy, move, and
some other operations. OpenNF also solves the race condition
problem when some internal state is being moved, packets
might arrive at the source instance after the move starts, or
at the destination instance before the state transfer completes.
Both Split/Merge and OpenNF can be applied to help solve the
race condition problem in virtual ﬁrewall adaption, since it also
needs to move internal states (ﬁrewall rules) from one virtual
ﬁrewall to another. Some other network function control
frameworks, including Slick [9], FlowTags [10], Stratos [11],
and SIMPLE [12], mainly provide controls over trafﬁc steering
among network functions.
VIII. D ISCUSSION

rules in data centers. It would be interesting to compare the
Integer Programming based approach with other approaches
for virtual ﬁrewall placement.
Virtual ﬁrewall scaling in/out are other important problems
that should be addressed in VNGuard. In virtual ﬁrewall
scaling out, a new instance is created, and some rules in
the old ﬁrewall instance will be moved to the new instance
with the network trafﬁc being moved alongside. This situation could cause two safety implications. One is the race
condition that has been discussed in [7]. The “lost-free”
and “order-preserving” move algorithms have been proposed
in [7] to solve the race condition problem. However, there
are limitations with those algorithms, because they rely on
buffering network trafﬁc at the SDN controller side during
moving network states, which signiﬁcantly consumes valuable
bandwidth between SDN controller and switches. Thus, a new
solution should be investigated to address the virtual ﬁrewall
scaling in/out problems in VNGuard.
IX. C ONCLUSION AND F UTURE W ORK
In this paper, we have proposed VNGuard, an NFV/SDN
combination framework for effectively provisioning and managing virtual ﬁrewalls to safeguard VNs. VNGuard deﬁnes
a high-level ﬁrewall policy language, ﬁnds optimal virtual
ﬁrewall placement, and adapts virtual ﬁrewalls to VN changes.
Our experimental results have demonstrated the efﬁciency and
effectiveness of virtual ﬁrewalls built on VNGuard. In the
future, we will expand our VNGuard framework for building
robust stateful virtual ﬁrewalls, especially considering the
safety state migration management for virtual ﬁrewalls. We
also plan to implement VNGuard in other popular open-source
NFV platforms, such as OPNFV [27].
ACKNOWLEDGMENTS
This work was partially supported by the grants from
National Science Foundation (NSF-IIS-1527421, NSF-CNS1537924 and NSF-CNS-1531127).

In this work, we employed an Integer Programming based
approach to ﬁnd optimal virtual ﬁrewall placement. In building
the Integer Programming model, we have considered resource
constraints. However, service level agreements (SLAs) on
performance should be also satisﬁed in reality. Hence, performance constraints may need to be considered when determining virtual ﬁrewall placement. The performance depends on
the number of rules held in a virtual ﬁrewall instance and the
resources (e.g. CPU, memory, etc.) assigned to the instance.
We would explore a new model with respect to various
network performance factors for virtual ﬁrewall placement in
the future.
We have demonstrated the efﬁciency of the Integer Programming based approach for virtual ﬁrewall placement in
Section VI. Some other optimization algorithms could be also
explored for the policy placement. For example, Moshref et
al [15] proposed a heuristic algorithm to place network ﬂow

113

R EFERENCES
[1] P. Busschbach, “Network functions virtualisation - challenges
and
solutions,”
Alcatel-Lucent
Corp.,
France,
Strategic White Paper, 2013. [Online]. Available: http:
//www.tmcnet.com/tmc/whitepapers/documents/whitepapers/2013/
9377-network-functions-virtualization-challenges-solutions.pdf
[2] Google Cloud Platform. [Online]. Available: https://cloud.google.com/
compute/docs/networking#ﬁrewalls
[3] S. Rajagopalan, D. Williams, and H. Jamjoon, “Pico replication: A high
availability framework for middleboxes,” in SoCC’13, Santa Clara, CA,
2013.
[4] J. Machi. (2013, December 17). NFV said to SDN: I’ll be
there for you. [Online]. Available: https://www.sdncentral.com/market/
nfv-said-sdn-ill/2013/12/
[5] S. K. N. Rao, “SDN and its use-cases-NV and NFV,” NEC Technologies
India Limited, White Paper, 2014. [Online]. Available: http://www.
nectechnologies.in/en TI/pdf/NTI whitepaper SDN NFV.pdf
[6] Open Networking Foundation (ONF), “OpenFlow-enabled SDN and
network function virtualisation,” Tech. Rep., Feb., 2014. [Online].
Available: https://www.opennetworking.org/images/stories/downloads/
sdn-resources/solution-briefs/sb-sdn-nvf-solution.pdf

2015 IEEE Conference on Network Function Virtualization and Software Defined Network (NFV-SDN)

[7] A. Gember-Jacobson, R. Viswanathan, C. Prakash, R. Grandl, J. Khalid,
S. Das, and A. Akella, “OpenNF: enabling innovation in networking
function control,” in SIGCOMM’14, Chicago, IL: ACM, 2014, pp. 163174.
[8] F. Paganelli, M. Ulema, and B. Martini, “Context-aware service composition and delivery in NGSONs over SDN,” in IEEE Communications
Magazine, vol. 52, issue 8, 2014, pp. 97-105.
[9] B. Anwer, T. Benson, N. Feamster, D. Levin, and J. Rexford, “A slick
control plane for network middleboxes,” in HotSDN’13, HongKong,
China: ACM, 2013, pp. 147-148.
[10] S. K. Fayazbakhsh, V. Sekar, M. Yu, and J. C. Mogul, “FlowTags:
Enforcing network-wide policies in the presence of dynamic middlebox
actions using ﬂow tags,” in HotSDN’13, HongKong, China: ACM, 2013,
pp. 19-24.
[11] A. Gember, R. Viswanathan, C. Prakash, R. Grandl, J. Khalid, S. Das,
and A. Akella, “Stratos: A network-aware orchestration layer for virtual
middleboxes in clouds,” in arXiv preprint arXiv:1305.0209, 2013.
[12] Z. A. Qazi, C. Tu, L. Chiang, R. Miao, V. Sekar, and M. Yu ,
“SIMPLE fying middlebox enforcement using SDN,” in SIGCOMM’13,
HongKong, China: ACM 2013, pp. 27-38.
[13] S. Rajagopalan, D. Williams, H. Jamjoon, and A. Warﬁeld, “Split/merg:
system support for elastic execution in virtual middleboxes,” in NSDI’13,
Lombard, IL: ACM, 2013, pp. 227-240.
[14] S. Mehraghdam, M. Keller, and H. Karl, “Specifying and placing chains
of virtual network functions,” in arXiv preprint arXiv:1406.1058, 2014.
[15] M. Moshref, M. Yu, A. Sharma, and R. Govindan, “Scalable rule
management for data centres,” in NSDI’13, Lombard, IL: ACM, 2013,
pp. 157-170.
[16] S. Zhang, F. Ivancic, C. Lumezanu, Y. Yuan, A. Gupta, and S. Malik,
“An adaptable rule placement for software deﬁned networks,” in 2014
44th IEEE/IFIP International Conference on Dependable Systems and
Networks (DSN), Atlanta, GA, 2014, pp. 88-99.
[17] European Telecommunications Standards Institute (ETSI) GS, “Network
functions virtualisation (NFV); Infrastructure Overview,” Group Speciﬁcation, 2015. [Online]. Available: http://www.etsi.org/deliver/etsi gs/
NFV-INF/001 099/001/01.01.01 60/gs NFV-INF001v010101p.pdf

[18] H. Hu, G. Ahn, and K. Kulkarni, “Detecting and Resolving Firewall
Policy Anomalies,” in IEEE Transactions on dependable and secure
computing, vol. 9, no. 3, 2012, pp. 318-331.
[19] M. Jünger, Th.M. Libelling, D. Naddef, G.L. Nemhauser, W. R. Pulleyblank, G. Reinelt, G. Rinaldi, and A. Wolsey, “Nonlinear integer
programming,” in “50 Years of Integer Programming 1958-2008: The
Early Years and State-of-the-Art Surveys”, New York, Spring-Verlag,
2009.
[20] C. C. Zhang, M. Winslett, and C. A. Gunter, “On the safety and efﬁciency of ﬁrewall policy deployment,” in IEEE Symposium on Security
and Privacy, Berkeley, CA, 2007, pp. 33-50.
[21] Y. Gao, X. Chen, N. Pan, and Z. Morley Mao, “On the safety of
enterprise policy deployment,” in NDSS 2010, San Diego, CA, USA,
2010.
[22] European Telecommunications Standards Institute (ETSI) GS, “Network
functions virtualisation (NFV); Terminology for main concepts in NFV,”
Group Speciﬁcation, 2013. [Online]. Available: http://www.etsi.org/
deliver/etsi gs/NFV/001 099/003/01.01.01 60/gs nfv003v010101p.pdf
[23] J. Martins, M. Ahmed, C. Raiciu, V. Olteanu, M. Honda, R. Bifulco,
and F. Huici, “ClickOS and the art of network function virtualisation,”
in 11th USENIX Symposium on Networked System Design and Implementation, 2011, pp. 459-473.
[24] E. Kohler, R. Morris, B. Chen, J. Jannotti, and M. Frans Kaashoek, “The
click modular router,” in ACM Transactions on Computer Systems, vol.
18, issue 3, 2000, pp. 263-297.
[25] University of Utah, Cloudlab Technology. Available: http://www.
cloudlab.us/technology.php
[26] M. Chapple, “Firewall rules are meant to be managed, not broken,” 2012. Available: http://www.biztechmagazine.com/article/2012/08/
ﬁrewall-rule-management-key-network-security.
[27] OPNFV. Available: https://www.opnfv.org/
[28] H. Hu, W. Han, G. Ahn, and Z. Zhao, “FlowGuard: building robust
ﬁrewalls for software-deﬁned network,” in HotSDN’14, Chicago, IL,
USA, 2014.

114

SoK: Everyone Hates Robocalls: A Survey of Techniques against Telephone Spam
Huahong Tu, Adam Doupé, Ziming Zhao, and Gail-Joon Ahn
Arizona State University
{tu, doupe, zzhao30, gahn}@asu.edu

Abstract—Telephone spam costs United States consumers
$8.6 billion annually. In 2014, the Federal Trade Commission
has received over 22 million complaints of illegal and wanted
calls. Telephone spammers today are leveraging recent technical advances in the telephony ecosystem to distribute massive
automated spam calls known as robocalls. Given that anti-spam
techniques and approaches are effective in the email domain,
the question we address is: what are the effective defenses
against spam calls?
In this paper, we first describe the telephone spam ecosystem, specifically focusing on the differences between email
and telephone spam. Then, we survey the existing telephone
spam solutions and, by analyzing the failings of the current
techniques, derive evaluation criteria that are critical to an
acceptable solution. We believe that this work will help guide
the development of effective telephone spam defenses, as well
as provide a framework to evaluate future defenses.

I. I NTRODUCTION
The national and global telephony system is a critical
component of our modern infrastructure and economy. In
the United States (US), the mobile telephone subscribership
penetration rate has already surpassed 100% [1]. According
to the U.S. Bureau of Labor Statistics, each day more than
240 million hours are spent on telephone calls in the United
States, equating to more than 88 trillion hours each year [2].
However, with the pervasiveness of telephone service
subscribership, telephone spam has also become an increasingly prevalent issue in the US. Recent technical advances
in the telephony ecosystem are leveraged by spammers to
distribute massive automated spam calls, known as robocalls. The Federal Trade Commission’s (FTC) National Do
Not Call Registry’s cumulative number of complaints of
illegal calls in the US totaled more than 22 million in
2014 [3], with about 200,000 complaints each month about
robocalls alone [4]. Despite US laws prohibiting robocalling
and telephone spamming (with some exceptions), complaints
on illegal calls have reached record numbers year after
year, which indicates that the laws have not deterred the
spammers.
Spam calls are significant annoyances for telephone users.
Unlike email spam, which can be ignored, spam calls
demand immediate attention. When a phone rings, a call
recipient generally must decide whether to accept the call
and listen to the call. After realizing that the call contains
unwanted information and disconnects from the call, the
recipient has already lost time, money (phone bill), and

productivity. A study in 2014 by Kimball et al. [5] found
that 75% of people listened to over 19 seconds of a robocall
message and the vast majority of people, 97%, listen to
at least 6 seconds. Even when the recipient ignores or
declines the call, today spammers can send a prerecorded
audio message directly into the recipient’s voicemail inbox.
Deleting a junk voicemail wastes even more time, taking at
least 6 steps to complete in a typical voicemail system.
Telephone spam are not only significant annoyances,
they also result in significant financial loss in the economy, mostly due to scams and identity theft. According
to complaint data collected by the FTC, Americans lose
more than $8.6 billion due to fraud annually, and the vast
majority of them (and still increasing) are due to phone
communication [4]. This situation is surprising, given the
significant gains made in reducing the amount of email
spam. This raises the question: are there any simple and
effective solutions that could stop telephone spam? The unfortunate answer is no. We found that this issue is not easily
solved, and, in fact, the simple and effective techniques
against email spam cannot be applied to telephone systems.
There are significant differences and unique challenges in the
telephone ecosystem that require novel approaches. Many
existing solutions have failed to overcome these challenges
and, as a result, have yet to be widely implemented.
The objective of this paper is to survey the existing
solutions in combating telephone spam and, by analyzing the
failings of the current techniques, derive the requirements
that are critical to an acceptable solution. This work will
help guide the development of effective telephone spam
defenses, as well as provide a framework to help evaluate
the techniques against telephone spam.
The main contributions of this paper are the following:
• We describe the telephone spam ecosystem, focusing
on the players involved and the technical challenges
that make telephone spam distinct from email spam.
• We develop a taxonomy that classifies the existing antispam techniques into three categories, providing a highlevel view of the benefits and drawbacks of each type
of technique.
• We provide a systematization of assessment criteria
for evaluating telephone spam countermeasures, and
we evaluate existing techniques using these assessment
criteria.

•

Termination Network

Termination Carrier

Possibly further anonymized behind VPNs and
Tor networks

Long Distance Network

Trunk Line

Spammer

VoIP Carrier

While email spam is arguably the most well-known form
of spam, telephone spam is now more popular than ever.
The Public Switched Telephone Network (PSTN) is an
aggregate of various interconnected telephone networks that
adheres to the core standards created by the International
Telecommunication Union, allowing most telephones to
intercommunicate. We define telephone spam as the mass
distribution of unwanted content to modern telephones in the
PSTN, which includes voice spam that distributes unwanted
voice content to answered phones, and voicemail spam
that distributes unwanted voice content into the recipient’s
voicemail inbox.
Due to the much greater capacity of IP infrastructure
and the wide availability of IP-based equipment, telephony
service providers have shifted their network infrastructure to
IP-based solutions, and the operation cost of the telephone
network has dramatically decreased. While the core PSTN
infrastructure has evolved to be almost entirely IP-based,
the core signaling protocols have not changed. The entire
ecosystem still relies on the three-decade-old Signaling System No. 7 (SS7) [6] suite of protocols, allowing any phone to
reach any other phone through a worldwide interconnection
of switching centers.
A very common way of disseminating telephone spam
is robocalling, which uses an autodialer that automatically
dials and delivers a prerecorded message to a list of phone
numbers. An autodialer is a generic term for any computer program or device that can automatically initiate calls
to telephone recipients. Today, an autodialer is usually a
computer program with Voice over Internet Protocol (VoIP)
connectivity to a high volume VoIP-to-PSTN carrier, that
may include features such as voicemail and SMS delivery,
customizable caller ID, Call Progress Analysis, scheduled
broadcast, text-to-speech, Interactive Voice Response, etc.
The high reachability of telephone numbers has led to
telephony being an attractive spam distribution channel. Almost every adult in the US can be reached with a telephone
number, and the vast majority of telephone numbers are
mobile telephone subscribers. Although VoIP usage has been
growing rapidly, we found that it is more of an add-on
protocol (instead of a wholesale replacement) of existing
mobile wireless and landline services. Using 2013 statistics,
there are about 335 million mobile telephone subscribers [1],
136 million fixed-telephone subscribers [7], and 34 million
VoIP subscribers [8] in the US (population 318 million).
We believe the improved cost efficiency of telephone
spamming, advancement of spam distribution technology,
and high reachability of telephone numbers contributed to
the recent surge in telephone spam. Furthermore, we believe
that telephone spam has the potential to be more persuasive

Open Internet

II. BACKGROUND

Interexchange Carrier

We provide a discussion on what we believe to be the
future direction of solving the telephone spam problem.

Victims

Possibly routing through more layers than
depicted

Figure 1: Routing of a spam call.

Victim

Spammer

VoIP
Carrier

Interexchange
Carrier

Termination
Carrier

Leads Seller

Figure 2: The flow of money in the telephone spam ecosystem.

than email spam, particularly when spammers use techniques
such as caller ID spoofing.
A. Key Players of Telephone Spam
To understand the telephone spam ecosystem, we will first
identify and explain the roles of all players who take part in
the routing of a telephone spam. Figure 1 show a graphical depiction of the routing process: The spammer connects through the Internet to an Internet Telephony Service
Provider, then the call is routed through an Interexchange
Carrier, before finally being accepted by the Termination
Carrier, who then routes the call to the victim.
Another way to understand the ecosystem is to show
how money flows through the system, which we display in
Figure 2: the money flows from the victim to the spammer,
and the spammer uses this money to obtain leads (new phone
numbers to spam) and to pay for the spam calls, the Internet
Telephony Service Provider receives the money from the
spammer and pays the Interexchange Carrier, who then pays
the Termination Carrier. Next we examine each of these
roles in turn.
Spammer is the agent that carries out the spamming
operation. The spammer could be part of an organization,
or an independent contractor that offers spamming-as-aservice. The goal of the spammer is usually to extract
money from victims through sales and scams, or to launch
a campaign of harassment. For cost efficiency, spam calls
are typically initiated using an autodialer connected to an
Internet Telephony Service Provider to reach the PSTN
victims. Currently, spamming to VoIP victims are not as
common, mainly due to the limited pool of potential victims,
and some VoIP users, such as Skype, may not be reachable
most of the time. We will describe the spammer’s operation
in more detail in Section II-B.

Internet Telephony Service Provider (ITSP), also
known as a VoIP carrier, is a type of termination carrier that
offers telecommunications service over the TCP/IP network,
i.e. the Internet. The ITSP typically offers high volume
calling at a lower cost compared to traditional carriers, and
generates revenue based on the minutes of calls hosted.
Whenever the spammer makes an outbound call to a PSTN
number, the ITSP will convert the signaling protocol from
VoIP to SS7, and route the converted signal through an
interexchange carrier.
Interexchange Carrier (IXC), also known as a long
distance carrier, is a cross-regional carrier that carries call
traffic between telephone exchanges over long distances.
The IXC charges its subscribers (mainly termination carrier
such as the ITSPs and local mobile/landline carriers) for
handling long distance phone calls and compensates the
next-hop carrier (such as the recipient’s termination carrier) for access. Unlike the peering model between Internet
service providers [9], the IXC negotiates access rates with
other carriers, known as intercarrier compensation. In the
US, intercarrier compensation [10] is a complex system in
which the rates vary according to traffic origination, location,
carrier, and traffic type, and the rates are governed by
federal and state regulators. In general, when two carriers are
directly connected, the originating carrier compensates the
next-hop carrier for routing the call in the next-hop carrier’s
network.
Termination Carrier, also known as local exchange
carrier, is a carrier that provides call routing services within
a local network that terminates at its end users. The termination carrier may be operating a landline, mobile, or IPbased telephone network. Most consumers and businesses
rely on termination carriers for their telecommunications
services. The termination carrier typically bills the IXC for
the amount of incoming traffic, known as the access charge.
In the US and some other countries, the recipient subscriber
may also be partially billed for incoming calls.
B. Spammer Operation
Spamming (regardless of the medium) requires three basic
elements: a recipient list, content, and a mass distribution
channel. In addition, a more sophisticated spammer may
employ circumvention measures to defeat spam countermeasures, and to avoid being stopped by law enforcement
agencies.
1) Gathering Numbers: Spamming first requires a list of
potential victims to contact, and in the case of telephone
spam: a list of phone numbers. While there are many ways
a spammer could gather phone numbers, the simplest method
is to purchase the numbers from a leads seller. We did
a simple Google search (keyword “leads for sale”) and
found hundreds of websites that offers access to millions
of curated phone numbers for less than $100. There are
also other ways to harvest phone numbers, such as crawling

the web, collecting form submissions, downloading leak
databases, covertly gathering through smartphone apps, or
simply generating the numbers based on phone numbering
plans. However, we do not know for sure the most popular
means of obtaining a list of phone numbers for spamming,
due to the lack of existing studies. Once the spammer gathers
a list of phone numbers, the spammer can load it in an
autodialer for mass distribution of the content.
2) Voice Spam Content: The content of telephone spam is
typically a prerecorded audio stream made by either recording human voice or by using a text-to-speech synthesizer
program. Telephone spam can also deliver interactive voice
content, with the use of an Interactive Voice Response (IVR)
system. When the recipient answers a call from an autodialer
with interactive content, the recipient can interact with the
system through voice and keypad inputs, and an automated
voice message is played back based on the interaction.
There are a wide variety of spam types, such as telemarketing, impersonation scam, debt collection, political
campaigns, one-ring scam, and so on. In order to provide
insight into the telephone spam content, we collected 100
audio samples from various publicly available sources where
audio recordings of voice or voicemail spam are uploaded.
We perform this analysis to gain a general understanding of
voice and voicemail spam, and we emphasize that, due to
the biased method of data collection, these results do not
constitute measurements that reflect trends on the whole of
voice and voicemail spam. However, these results provide
needed background and insight into the actual voice and
voicemail spam. We will describe the following prevalent
types of spam: credit card verification scam, fake tax agent
scam, and political robocalls.
In the credit card verification scam samples, the called
recipients are informed that their credit card account was
deactivated, and they are asked to enter their credit card and
social security number over the phone to verify their identity
and get the account reactivated. While we only were able
to listen to the audio of the call, based on comments from
some of the uploaders, the scammers would spoof the caller
ID to make it look as if the call originated from the credit
card issuer. All of these scam calls used an Interactive Voice
Response system to interact with the recipients and collect
their credit card information. We found that the audio from
the scammer’s IVR system came from either a synthesized
voice or audio duplicated from the IVR system of the real
credit card issuer. From what we observed, the use of caller
ID spoofing and sound duplicated from the real credit card
issuer’s IVR system made it almost indistinguishable from
a real credit card verification call.
In the fake tax agent scam samples, the recipient receives
a call from the scammer identifying himself as a tax agent
of the Internal Revenue Service (IRS) and provides a fake
badge number. The scammer proceeds to tell the recipient
that he or she owes a specific amount of money to the

IRS. Often, the scammers demand immediate payment and
threaten jail, deportation, or loss of driver’s license if the
victim does not pay. Based on the comments from the
uploaders, the scammers would spoof their caller ID to make
it look as if the call originated from a government agency
by showing an area code from 202 (Washington, DC). These
scammers seem to target immigrants [11]. We found that the
majority used a live person to interact with the victim, and
the rest used a prerecorded synthesized voice without an IVR
system. One thing we noted was that all of the live person
scammers had a South Asian accent, and in our opinion, the
accent had made the call sound highly suspicious and easy
to recognize as a scam (which might explain why it was
posted online as a scam).
In the political robocall samples, the typical content is a
prerecorded message making a political advertisement, or a
poll asking the recipient about their political opinion. In the
United States, political robocalls are exempt from regulation
by the national Do-Not-Call Registry and the Telephone
Consumer Protection Act of 1991. Before a national or state
level election, they are distributed in high frequency using
voice and voicemail broadcasting autodialers. All of the
audio samples contained a prerecorded message, and most
polls used an IVR system to interact with the recipient.
3) Mass Distribution: Mass distribution is the next critical step to a successful spam operation. The goal is to
massively and cost-effectively deliver the spam content to
a list of telephone numbers.
Using VoIP service to distribute calls to PSTN numbers,
the content can be disseminated at a much higher volume,
and at a fraction of the cost compared to traditional telephony. To understand the distribution cost of spamming, we
researched the prices and found hundreds of VoIP service
providers offering pay-by-the-minute calling service to US
telephone numbers priced around $0.01 per minute. We also
found some fixed monthly-fee pricing model with unlimited
calling for about $150, however, these service providers tend
to target small businesses, and these plans usually come with
throttling, so high volume calling services are almost always
offered with a pay-by-the-minute model.
Some VoIP service providers (such as CallFire1 and CallEm-All2 ) even cater specifically to telemarketers, providing
features such as integrated autodialer and customizable caller
ID in their service.
4) Circumvention: Spamming is an adversarial game, as
spam defenses are widely introduced, the spammer has an
incentive to defeat them. According to a poll conducted by
Harris Poll on behalf of WhitePages in 2013, 22% of US
smartphone users used a call-blocking app or a feature to
block calls on their device [12]. Most mobile phones today
1 https://www.callfire.com/
2 https://www.call-em-all.com/

contain basic capability to automatically block calls from a
list of unwanted callers.
For the spammers today, two common ways to defeat them
is to use voicemail injection and caller ID spoofing.
Voicemail injection is a recent extension of the autodialer
which delivers prerecorded voice messages into the recipients’ voice mailbox (voicemail). Typically, when a phone
call is unanswered or declined, it gets forwarded to an
answering machine that lets the caller leave a voice message. A voicemail broadcasting autodialer uses Answering
Machine Detection (AMD) [13] technology to automatically complete the process of inserting a prerecorded voice
message into the recipient’s voicemail. A more recent type
of voicemail broadcaster can even deliberately trigger the
recipient’s voicemail, a technique known as Forced Busy
Channel [14], to directly inject a voice message into the
recipient’s voicemail without waiting for the call to be
unanswered or declined.
Caller ID spoofing is the practice of deliberately falsifying
the caller ID information sent to the recipient that identifies
the caller of a phone call. It is particularly effective for
defeating the call blockers and helps to further a variety of
scams. The caller ID service provides the caller’s telephone
number (and in some cases the caller’s name) to the recipient
before or during the ring of an incoming call. It allows the
recipient to decide whether to answer a call based on the
caller ID information, or to call back if the call could not be
answered. The caller ID number is also widely used in other
non-voice communication services, such as SMS, MMS, and
many smartphone apps. The caller ID number is typically
provided by the caller’s switch, which can control what
caller ID number is sent on a call-by-call basis. For general
consumers, a legally mandated privacy feature allows them
to hide the calling number [15]. However, malicious callers
can also take advantage of the declarative nature of the
caller ID mechanism to spoof or block the caller ID number,
in order to defeat spam filters and further a variety of
scams. The caller ID number can be easily spoofed because
there is no built-in authentication mechanism, and it is not
immediately verifiable by the recipient. The caller’s service
provider does not have any legal obligation to ensure that
the caller ID number in the call request header is indeed
owned by the caller before it is transmitted. In fact, some
ITSPs today advertise customizable caller ID as a service
feature.

III. K EY C HALLENGES
We identify several challenges in combating telephone
spam—that are significantly different from email spam—
some of which are technical and some of which are regulatory.

A. Immediacy Constraint
Unlike email, which can be queued for later analysis, a
voice call has an immediacy constraint. A telephone call
request is immediate and therefore must be analyzed as
soon as it appears, and the telephone anti-spam system must
complete analysis and take action within a short window of
time to reduce the delay. If a solution adds too much delay
to a call request, the legitimate caller may assume that the
recipient could not answer the phone and hang up.

With the rise of VoIP services that provide features such
as caller ID customization over the Internet, it is trivial for
any caller to cheaply and effectively spoof the caller ID.
Thus, any telephone spam defense technique that relies on
the caller ID is now vulnerable to caller ID spoofing.
F. Difficulty of Tracing Spam Calls

The bar for user acceptance of a telephone anti-spam
system is much higher compared to email. Consumers,
rightly, have a very low tolerance for false positives of
blocked calls. Phone calls tends to be more urgent and
important compared the email, and once a phone call is
wrongfully blocked it could have severe consequences.

One way to combat spam is to make it illegal and enforce
those laws. In the history of email spam, a small number of
players were responsible for the majority of the spam, hence
taking action against these big targets resulted in significant
drops of spam volume. For instance, shutting down the Rustock botnet reduced global spam levels by around 40% [17].
It is reasonable to assume a similar distribution of telephone
spammers. Unfortunately, identifying the actual distribution
of telephone spammers is difficult due to the technical and
regulatory challenges of monitoring PSTN traffic and the
prevalence of caller ID spoofing.
It is difficult to locate the true origin of a call after it
has been initiated. PSTN calls are designed to work on
the principle of forwarding tables and circuit switching.
Each time a call is placed, only the destination number is
used for routing. It works by establishing individual circuits
down a sequence of neighboring switches until it ends up
at the recipient’s terminal. The outbound switch(es) do not
necessarily need to know whether the optional caller ID
number in the call request header would route back to
the caller’s terminal. If the outbound switch also serves as
the caller’s inbound switch, then the TSP could perhaps
verify the true owner of the caller ID number from its own
records. However, the TSPs do not have a legal obligation to
perform any verification, or to share that information with
the recipient, thus, without the cooperation of the caller’s
TSP, tracing a spam call is almost impossible.
To make matters worse, as spam calls can now be initiated
over the Internet, a spammer can further hide behind proxies,
VPNs, or Tor networks, or even distribute outbound calls
using a botnet, adding even more difficulty in tracing the
exact whereabouts of a spammer.

E. Caller ID Spoofing

G. Entrenched Legacy Systems

The Caller ID service is an information service that
provides the recipient with information of the caller before
answering the phone, which could be useful for blocking
spam calls. However, caller ID fundamentally has no authentication mechanism and is easily spoofed. The only security
mechanism comes from having the TSP send the caller ID
on behalf of the caller. This security mechanism is eroded
when the spammer subscribes to a TSP service that allows
customization of caller IDs. It used to be prohibitively expensive for individuals and small businesses to purchase the
equipment necessary to enable the customization of caller
IDs (an ISDN-PRI trunk line costs $500 to more than $1,000
per month and a PBX system that costs thousands [16]).

The PSTN ecosystem has been around for several decades,
allowing any phone to reach any other phone through a
vast interconnection of switching centers. While the core
networks have evolved to be almost entirely carried by
an IP-based infrastructure, the signaling protocols have not
changed (to ensure legacy compatibility). Even though VoIP
is touted as a major revolution of voice communication,
the legacy of PSTN protocols will remain for many years
to come. Change is difficult when the entire ecosystem
must ensure that the majority of legacy systems will work,
and therefore wholesale replacement of the core telephony
system is a nonstarter. As a result, telephone spammers can
exploit the weaknesses in the legacy technology (such as the

B. Difficulty of Working with Audio Streams
The content of a voice call is difficult to parse and analyze:
the content is an audio stream as opposed to the text of an
email. To make matters worse, the content of a voice call is
only revealed when the call is answered, and both the caller
and the recipient will be affected if an anti-spam system
answers the call. Whereas an email anti-spam system can
easily analyze the content of an email, and neither the sender
nor the receiver is affected.
C. Lack of Useful Header Data
Voice calls lack the rich header data of email. When a
call arrives at the recipient, it contains little useful header
information. An example of a call header used in traditional
phone terminals is shown in Table III in the Appendix. An
email header, however, has well-defined and informationrich SMTP headers—before the content of the email. It is
also difficult to omit the sender’s IP address and domain
name of the email. This is in stark contrast to a call request
header, where the header data is easily omittable by a
spammer.
D. Hard to Gain User Acceptance

lack of caller ID verification) to run a successful spamming
operation.
H. Lack of Effective Regulations
Unfortunately, there is also a lack of incentive for the
industry to participate in the anti-spam effort. Unlike email
and Internet traffic where the peering model [9] incentivizes
the Internet service providers to reduce the load of spam
traffic on their systems, telephony service providers profit
from the spam-generated traffic and intercarrier compensation fees. Most players (phone number collectors, lead
sellers, telephony service providers, and backbone carriers)
in the PSTN ecosystem profit from telephone spam, except
the consumer. Although TSPs may benefit in other ways
by reducing telephone spam (for instance, in better public
relations or charging spam-filtering service as a fee), there
exists, at least, a minor monetary disincentive.
Further complicating matters, the current United States
law ensure that TSPs are immune from liability for servicing
spam calls [18] under the Telephone Consumer Protection
Act of 1991, which means that they cannot be held liable
for servicing spam calls. Classified as common carriers,
TSPs have an obligation to move all phone traffic with no
exceptions [19]. Therefore, it is difficult to implement antispam solutions at the most natural place: the TSP who has
a direct view of the telephony network.
I. Lack of Globalized Enforcement
In the United States, a number of laws and regulation
exist at both the federal and state levels, such as making
robocalling illegal (with some exemptions) [20], making
caller ID spoofing illegal (with some exemptions) [21], and
the establishment of a national Do-Not-Call Registry [22].
The FTC is also interested in stopping telephone spam, and
they have held numerous competitions to combat robocalling [23]. Despite resolute efforts by the US government,
robocalling and caller ID spoofing is still an unsolved
problem. Technology and globalization have resulted in
telephony networks shifting from a national ecosystem to a
global ecosystem. With the use of VoIP service, a telephone
spammer can cheaply distribute outbound calls from an
overseas location. Because the spammers lie beyond the
jurisdiction of US law enforcement authorities, it is hard for
law enforcement to prosecute those spammers for breaking
the law. Effective control of telephone spam would therefore
require cross-border enforcement. However, cross-border
jurisdiction of telephone spam has yet to catch up with
the present technology, and many countries would have no
incentive to cooperate with US regulatory and enforcement
agencies.
IV. BASIC T ECHNIQUES
To identify the state-of-the-art in preventing voice and
voicemail spam, we gathered existing techniques from academic, industry, SPam over Internet Telephony (SPIT), and

Internet domain, and systematically categorize them into the
following classes: (1) Call Request Header Analysis, (2)
Voice Interactive Screening, and (3) Caller Compliance.
A. Call Request Header Analysis
Call Request Header Analysis is a category of techniques
that filters calls based on the header information associated
with the call request. For instance, the caller ID is a popular
type of request header information that can be used to
analyze a call. The effectiveness of Call Request Header
Analysis depends on the accuracy of the information
collected, which could be severely impacted when spoofing
or omission is possible.
Caller ID Blacklisting rejects a call if the caller’s phone
number (captured from caller ID or Automatic Number
Identification service) appears on a blacklist, otherwise,
calls from all other phone numbers are accepted. This
can be used to block spam calls by blacklisting phone
numbers that are known to be spamming, and the recipient’s
terminal would silently block all phone calls from those
phone numbers without disturbing the recipient. Caller ID
Blacklisting only blocks phone numbers that are explicitly
added to a blacklist, hence it tends to be permissive to all
other callers. As caller ID service has become ubiquitous
in all telephone services, Caller ID Blacklisting does not
face compatibility issues. Caller ID Blacklisting is easy to
implement and requires very little computational resources,
and it is a common feature in modern smartphones [24],
[25]. However, a blacklist must be well populated to be
effective against spam, therefore compiling a comprehensive
list would not be scalable for the recipient. A spammer
could defeat Caller ID Blacklisting by spoofing any number
not known to be blacklisted, hence it is not effective against
most forms of call request header manipulation.
Caller ID Whitelisting only accepts calls from phone
numbers that appear on a whitelist, otherwise, calls from
all other phone numbers are rejected. This can be used to
block spam calls by whitelisting phone numbers that are
known to be trusted, and the recipient’s terminal would
silently block phone calls from all other phone numbers
without disturbing the recipient. Caller ID Whitelisting is
easy to implement and requires very little resources, and
it is easy to find implementations on modern smartphones
[26], [27]. Caller ID Whitelisting blocks all calls that are
not added to a whitelist, and does not need to be well
populated to be effective against spam, hence it is quite
scalable for the recipient when defending against spam. It
is usually quite easy to populate a whitelist, as the numbers
could be derived from the recipient’s contacts list. However,
unknown legitimate callers would always get blocked in
Caller ID Whitelisting. A spammer could defeat Caller ID
Whitelisting by spoofing the caller ID of a number known

to be trusted by the recipient, however this is more difficult
without prior knowledge about the recipient’s whitelist.
Caller Reputation System uses reputation or trust
associated with a caller’s phone number to determine if the
caller is a spammer. A Caller Reputation System maintains
and publishes reputation scores associated with individual
callers, in which the reputation scores are computed based
on various caller-related information such as recipient
black/white-lists [28]–[31], caller behavior [29], [32],
[33], recipient behavior [28], [34], [35], caller’s domain
reputation [30], [36], social connections [34], [37]–[40], and
recipient feedbacks [28], [29], [31], [36], [41], [42]. There
are also many opportunities to improve a Caller Reputation
System by developing better scoring algorithms. The Caller
Reputation System can be used to filter spam calls by
configuring the recipient’s terminal to block calls from
callers associated with poor reputation. A Caller Reputation
System generally requires a large amount of data, which are
usually crowdsourced from many recipients, and the data
would need to be curated by an administrative third party. It
would also require frequent maintenance to ensure quality
and freshness of data in order to be effective. However,
large scale collection of personal information could be at
risk of violating privacy. Caller Reputation System could be
vulnerable to Sybil attacks, where a malicious caller obtains
multiple identities to gain a large influence over its own (or
other caller’s) reputation. Because the reputation of a caller
is associated with the caller’s phone number, a spammer
could defeat the Caller Reputation System by spoofing the
caller ID to a number with a good reputation. A malicious
caller could also sabotage someone by deliberately making
junk calls while spoofing the caller ID number, such that
the victim gets a poor reputation.
Caller Behavior Analysis uses the call behavioral features
associated with a caller’s phone number to determine if
the caller is a spammer, using behavioral features such as
call count/velocity [29], [33], [39], [43]–[49], call duration
sum/mean/variance [29], [39], [44]–[46], [48]–[50], call
rejection count/ratio [35], [39], [44], [46], [47], [49],
[51], [52], recipient diversity count/ratio [44], [45], [49],
[52], invalid recipient count/ratio [39], [47]–[49], [51],
repeated call count/ratio [45], [52], outbound-to-inbound
ratio [33], [48], [51], [53], [54], simultaneous calls [46],
and caller’s domain behavior [32], [51]. There are also
many opportunities to improve the technique by developing
better classification algorithms. Acquiring the caller’s
behavioral information usually requires participation from
the caller’s telephony service provider or a honeypot of
telephones [33], [35]. If not required by regulation, it is
usually not in the TSP’s business interest to report on or
impose a call behavior restriction on their callers. The
callers’ behavioral information would need to be updated

frequently to ensure accuracy and freshness in order to be
effective. Large scale collection of callers’ call behavior
could also face privacy issues and numerous obstacles from
legal regulations. Because the call behavior of a caller is
associated with the caller’s phone number, a spammer could
defeat the Caller Reputation System by spoofing the caller
ID to a number with good calling behavior. Furthermore, a
spammer could hide its illegitimate call behaviors by using
multiple caller identities.
Device Fingerprinting collects a variety of metadata from
the call request header for the purpose of creating a device
fingerprint of a caller’s terminal. Device fingerprinting
improves the accuracy of determining the caller’s identity
by using only a set of information that meets the properties
of diversity and stability. Device Fingerprinting has been
proposed for SPIT prevention by blacklisting or whitelisting
the device fingerprints of SIP-based terminals [55].
However, in PSTN, device fingerprint information is a
scarce resource. This is due to the little amount of header
information in PSTN call requests (an example of which is
shown in Table III in the Appendix) compared to SIP or
email, resulting in having too little workable information
for device fingerprinting to work effectively.
Caller ID Anomaly Detection searches for anomalous
patterns in the caller ID, such as invalid format, invalid
number, unavailable number, toll-free number, area codes,
regular expression, to determine if the caller is a spammer.
Caller ID Anomaly Detection is quite easy to implement and
requires very little computational resources and, therefore,
is easy to find in several call blocking apps [56], [57].
Caller ID Anomaly Detection does not track information
associated with any individual caller, instead, it looks
for general patterns in the caller ID that can be used to
differentiate spammers and legitimate callers. As Caller
ID Anomaly Detection tend to find matches more broadly,
it tends to be easier to manage and maintain. However,
some patterns may be potentially prone to false negatives,
and therefore may restrict some legitimate callers, such as
VoIP users or privacy enabled callers. A spammer could
defeat Caller ID Anomaly Detection by carefully crafting
the caller ID to not trigger any known anomalous patterns.
ANI-CPN Matching checks whether the Calling Party
Number (CPN) captured by the caller ID service matches
with the Automatic Number Identification (ANI) number
captured by the ANI service [58]. Automatic Number
Identification service [59] is a separate type of calling line
identification service that can capture the calling number
information even when the caller ID is not presented. It
was originally designed to obtain the calling party’s billing
number from a local exchange carrier to any interconnecting
carrier for billing of long distance calls. In most cases,

the billing number is the same as the CPN, and usually
when a mismatch happens it is likely due to caller ID
spoofing, or the caller is calling from a private branch
exchange (PBX). ANI-CPN Matching assumes that a
legitimate caller’s CPN matches the ANI number whereas
a malicious caller would spoof the CPN which results in
a mismatch. However, ANI service are usually not made
available to regular consumers (usually only offered to
800 toll-free, 900 premium-rate, or 911 emergency service
lines), therefore, only some businesses would benefit from
this technique. ANI service is also not always reliable at
capturing the caller’s ANI number. Placing a legitimate call
using an outbound VoIP service or a calling card service
would result in a non-working or a generic ANI number
being captured. As a result, false positives may frequently
occur which hinders user acceptance.
ANI-II Filtering can be used to filter spam calls by
blocking certain types of origin service captured by the
ANI-II service. ANI-II [60] is an extension of the ANI
service that identifies the type of service associated with the
originating switch. Each type of service is represented by
a two-digit code. ANI-II Filtering assumes that legitimate
callers would have a valid (00 or 61) ANI-II code, whereas,
malicious callers would be making VoIP calls that would
have an invalid ANI Failure (02) code, and therefore
should be blocked. However, with the growing use of
VoIP service by regular consumers, this technique could
potentially result in too many false positives if all calls
with ANI Failure codes are blocked. Only some businesses
would benefit from an implementation of this technique, as
ANI-II service is usually offered only to premium-rate, tollfree, or emergency lines. Therefore, this technique would
not be accessible or cost effective for the regular consumers.
B. Voice Interactive Screening
Voice Interactive Screening is a category of techniques
that forces the caller to interact with a voice input-based
interactive system and decide if the call is spam after
analyzing the caller’s interaction. The system either requires
active or passive interaction from the caller. An active
interaction system relies on the caller providing a response
to a specific task which requires some effort from the
caller, whereas a passive interaction system silently gathers
the caller’s response without explicitly informing the caller.
Voice Interactive Screening techniques do not need to
rely on the caller ID or any other call request header
information, hence they are generally not vulnerable to
caller ID spoofing. However, Voice Interactive Screening
techniques generally require processing of audio signals,
which tends to be more complex to implement. Because
these techniques can only work after recording a length of
the caller’s voice, all Voice Interactive Screening techniques

have a screening period, therefore, would introduce
additional delay to the caller. Due to the recording of the
caller’s voice during the screening, in the US, some states
require explicit consent of recording the conversation,
which could hinder the screening process or invoke privacy
fears from some legitimate callers. As telephone audio
can be manipulated, and tends to contain artifacts such as
background noise, network dropouts, or compression losses,
Voice Interactive Screening techniques are generally more
prone to errors.
Audio Fingerprinting uses the voice recording of the
caller, or audio features extracted from the voice recording
of the caller, to analyze for similarity to a set of known
spam call profiles. If the voice recording is similar to an
audio stream of a known spam profile, then the call is
classified as spam. Audio Fingerprinting has been proposed
to combat replayed voice spam in several works [61]–[67].
However, the performance of Audio Fingerprinting depends
on the completeness of spam profiles, which is usually not
feasible for a recipient to collect. Audio Fingerprinting
would usually require a thirty-party to continuously collect
and maintain the known-spam audio profiles to ensure
effectiveness. However, a spammer could potentially defeat
the mechanism by dynamically creating variations of the
spam audio message (such as adding audio artifacts or
using personalized messages) to avoid identification.
Speech Content Analysis first records the caller’s voice,
then makes use of speech recognition technology to
transcribe the voice into text. The text is then analyzed with
text profiles of known spam calls to classify if the call is
spam. As opposed to managing audio recordings, a corpus
of text data is usually much easier to manage. As many spam
calls are simply variations of a call script, a keywords-based
classification model could be used against variations of a
same type of spam [68]. However, the effectiveness of this
technique depends on the accuracy of speech recognition,
and of course the effectiveness of the classification model.
In practice, automatic speech recognition of telephone voice
is an ongoing research problem [69], which tends to be
prone to errors, and still has several years to go to reach
human-level performance [70].
Acoustic Pattern Analysis extracts distinguishing acoustic
patterns from the caller’s audio stream, such as signal
losses [71], peak uniformity [71], noise uniformity [71],
voice activity [72], [73], and double talks [72]–[74], to
determine if the call is spam. Audio Fingerprinting looks
for general patterns in the audio signal that can broadly
distinguish spam calls from legitimate calls. Unlike Audio
Fingerprinting and Speech Content Analysis, Acoustic
Pattern Analysis does not require a large collection of
known-spam profiles, which could be difficult to gather and

maintain. However, some patterns may be prone to false
positives and could be easily defeated with manipulation of
the audio stream.
CAPTCHA/Turing Test is an interactive challengeresponse technique that requires the caller to complete a
reverse Turing test to determine whether the caller is a
human or robocaller. The tests are designed to be difficult
for a computer but easy for a human to complete. For
instance, the test could ask the caller to key in what they
hear from a distorted audio stream of random numbers [75]–
[77]. However, CAPTCHA/Turing Test would need to be
careful not to discriminate against certain groups of people,
such as people with poor English or disabilities, while
not giving too much leeway for abuse by “decaptcha"
systems [78]. On the other hand, CAPTCHA/Turing Test
would also need to be careful not to be illegible even
for users with no handicaps, as the legitimate caller may
become irritated by the obstacles of initiating a call with
the recipient. Because CAPTCHA/Turing Test is highly
interactive, it tends to require a high degree of effort, and
cause significant delays to the caller.
C. Caller Compliance
Caller Compliance is a category of techniques that require
the caller to first satisfy a compliance requirement prior
to or during a call request. If the caller is able to satisfy
the compliance requirement, then the caller is allowed to
communicate with the recipient. Satisfying the requirements
should be easy for a legitimate caller but difficult (or
costly) for a spammer. Some compliance measures require
special changes made to the call setup process or to the
communicating terminals. Some techniques require prior
instructions given to the caller.
Do Not Call Registry simply provides a registry of
phone numbers that spammers are legally prohibited from
calling in most circumstances. The spammer may be
subject to substantial fines if they fail to comply. The
registry is usually maintained by the national government,
in the US [22], the list is maintained by the Federal
Trade Commission. However, the recipients would need to
actively provide feedbacks for the government to legally act
on spammers violating the law. The Do Not Call Registry
can act as a good deterrence for domestic law-abiding
telemarketers, however it would have little effectiveness on
spoofed numbers and overseas spammers.
Graylisting [79] first rejects the initial call request from a
caller and then accepts the next call request from the same
caller made within a short period of time. This technique
defends against autodialers that simply call a list of phone
numbers and do not make repeated call attempts. The

technique also assumes that if an uninformed (about the
defense) caller is calling about legitimate business, the
caller will try again. The implementation is simple and
does not require changes to the infrastructure. However,
the legitimate caller must make two calls for every call
request, which introduces additional delay and calling cost.
A spammer could easily defeat the Graylisting mechanism
by configuring the autodialer to automatically call again
if a call goes unanswered, but at the cost of higher phone
bills and reduced efficiency.
Consent-based Communication first requires the caller to
send a consent request to the recipient before initiating a
call. For instance, the request could be a forwarded greeting
message where an answering machine first records the
name spoken with the caller’s voice and then plays it to
the recipient [80]–[82]. The recipient then decides whether
to accept the caller’s request to communicate. If the call
is spam, the recipient is only limited to being exposed
to an abridged recording (or the request message) of the
spam call. However, the recipient is still disturbed for every
unconsented caller, therefore it is not scalable, and the
recipient is not spared from the disturbance of a spam call.
It also adds delay to each call, as legitimate callers are
forced to wait for consent before each call.
Call Back Verification first rejects an initial call from
a caller, then forces the caller to wait for the recipient
to call back the caller. Call Back Verification is a good
defense against caller ID spoofing, as it forces the caller
to provide a genuine caller ID. The basic mechanism is
simple, and some implementations try to automate this
process [83], [84]. However, it requires the caller to first
own a reachable inbound number, which could restrict
communication from legitimate VoIP users and telephone
extension terminals. Call Back Verification also add delays
to each communication, as the legitimate caller must wait
for the recipient to call back. Calling back could also add
calling cost on both the caller and recipient in PSTN, which
can be especially significant for premium or international
numbers.
Weakly Secret Information requires the caller to
demonstrate knowledge of a weakly secret information
before allowing communication with the recipient. Weakly
secret information could be in various forms such as a
passcode, an extension code, a limited-use phone number,
or a message identifier [85]. However, the recipient would
first need to share the weakly secret information to all
trusted callers, hence it may not be scalable for a recipient
with a large contact list. Legitimate calls from unknown
callers would also be restricted from communicating with
the recipient.

Payment at Risk is a micropayment, cost-based, technique
where the caller is required to deposit a small amount
of money before making a call. If the recipient reports
that the call is spam, then the deposit is confiscated or
kept by the recipient, otherwise the money is refunded
to the caller. This was proposed as a method for SIP
spam prevention [38]. This technique prevents spamming
by making it prohibitively expensive to send out a
large amount of spam calls, while costing very little
for legitimate callers. However, the solution requires a
universal micropayment system that collects payment on
every call, which may require significant resources to create
and administer. There also are many questions regarding
the legality of this approach, for instance on the lawful
confiscation of payments and abuse of spam reporting. The
value amount of the deposit would also affect the number of
recipients needed to report on the spam caller to effectively
make spamming unprofitable.
Proof of Work is a computational, cost-based, technique
where the caller’s terminal is required to produce a proofof-work, such as hashcash [86], that is moderately hard to
compute (being computational or memory-bound) but easy
for the recipient to verify, before allowing communication
with the recipient. As the amount of work increases,
it would be prohibitively inefficient to distribute large
amounts of spam calls. A legitimate caller would not be
significantly affected for making a few number of calls. On
one hand, Proof of Work has an advantage over Payment
at Risk by not requiring a micropayment system, therefore
avoiding the administrative and legality issues. On the other
hand, Proof of Work faces a trade-off problem between
permissiveness and anti-spam effectiveness. In PSTN, due
to the significant share of low-end telephone terminals, the
difficulty of the work would need to be low enough to
ensure permissiveness. However, this may allow a spammer
using moderately powerful computerized terminals to easily
generate as much work as needed for spamming. Legitimate
callers with high outbound calls, such as a bank, may
also be obstructed from doing legitimate business if it
is prohibitively costly to generate the proof-of-works to
contact a large number of customers.
Proof of Identity requires the caller to send a verifiable
identity token that would authenticate the credentials of
the caller whenever making a call. This technique has
been proposed for SIP domain users [83], [87]–[89], due
to the availability of SSL/TLS certificates and maturity of
the underlying public key infrastructure. This technique
prevents spamming by ensuring that the caller could be held
responsible for making illegal calls, and prevents scams by
ensuring that the caller cannot impersonate as someone else.
Proof of Identity could also prevent a spammer from using
multiple identities when identity verification is required.

Proof of Identity has an advantage over Proof of Work by
not having the issue of deciding the right difficulty level
of proof-of-work which could either obstruct calls from
low-end telephone terminals or give too much leeway for
spamming. However, the scheme could be hard to deploy
in PSTN, as it would require establishment of a certificate
authority for issuing and verifying caller identities, and may
require significant changes to the call request protocols in
PSTN.

V. A SSESSMENT C RITERIA
It is clear that there is no shortage of techniques to combat
telephone spam, but what would an ideal telephone spam
defense entail? Therefore, we propose a set of assessment
criteria.
We separate the assessment criteria into three categories:
(1) Usability, which evaluates the ease-of-use from either
the caller or recipient’s perspective, (2) Deployability, which
evaluates the ease of installation, deployment, and operation, and (3) Robustness, which evaluates the technique’s
resilience against errors and effectiveness against a spammer
actively evading the defense. We define each of the identified
criteria and give a mnemonic name.
A. Usability Criteria
No-Disturbance-to-Recipient When a known-spam call
arrives, the technique does not disturb the recipient, such
as prompting for additional action from the recipient.
Scalable-for-Recipient The technique does not increase the
burden of work on the recipient with an increasing number
of spam calls. The technique can handle a large variety of
spam calls with minimal input from the recipient.
Effortless-for-Caller When initiating a call, the technique
requires minimal or zero effort from the caller.
Negligible-Changes-to-Call-Setups The technique requires
negligible changes to the existing call setups or
configurations in the callers’ terminals.
Negligible-Delays When initiating a call, the technique
adds negligible or unperceivable delay to the caller, other
than the typical time to connect and time waiting for the
recipient to answer the phone.
Permissive-for-VoIP-Callers The technique would not
restrict any legitimate calls that use VoIP service. For
instance, some outbound-only VoIP users (such as Skype)
tend to have a generic (or unavailable) caller ID number
and cannot receive incoming PSTN calls.

Permissive-for-Unknown-Callers The technique would not
restrict calls from a legitimate caller not known by the
recipient.
B. Deployability Criteria
Negligible-Changes-to-Infrastructure The technique requires
zero or negligible changes to existing PSTN protocols,
terminals, or infrastructure.
No-Third-Party-Involvement The technique does not require
a third-party. A compromise of the third-party would not
result in mishandled calls or in a breach of privacy.
Low-Resource-Requirement The technique is lightweight
and does not require a significant amount of resources (e.g.,
people, equipment, engineering, or funding) to initiate and
deploy.
Low-Maintenance The technique requires low maintenance,
in terms of administrative cost, time, or resources, to
maintain good working order.
Negligible-Cost-per-Call The technique adds negligible
cost to each call, taxed on the legitimate caller, recipient,
third-party, or carriers. The cost could also be indirect, such
as reduced efficiency or capacity.
C. Robustness Criteria
Effective-Against-Dynamic-Caller-ID-Spoofing
The
technique is robust even when the spammer spoofs
different caller IDs nondeterministically.
Effective-Against-Targeted-Caller-ID-Spoofing
The
technique is robust even when the spammer spoofs a
specific caller ID known to be trusted by the recipient.
Effective-Against-Unavailable-Caller-ID The technique
is robust even when the spammer makes the caller ID
unavailable or sends a faulty caller ID to cause errors.
Effective-Against-Multiple-Identities The technique is robust
even when the spammer initiate calls from multiple sources,
such as using multiple subscriber accounts or a telephone
botnet, to disseminate spam calls. This is different from
caller ID spoofing where the caller IDs are not necessarily
spoofed but are instead initiated from different sources.
Effective-Against-Answering-Machine-Detection
The
technique is robust even when the spammer uses Answering
Machine Detection technology, which is a feature in
autodialers that can distinguish human pick-ups from
answering machines. With AMD, an autodialer can be

configured to call again later if the call was not answered
by a human, or to deliver the audio message into the
recipient’s voicemail.
Effective-Against-Dynamic-Audio-Content The technique is
robust even when the spammer uses an autodialer capable
of personalizing or altering the audio messages for different
recipients. This is usually featured in autodialers that are
able to synthesize text to speech.
We evaluate each technique using the criteria proposed in
Section V, and Table I visually summarizes this evaluation.
Each technique is evaluated as either satisfying the criteria
(denoted as ), may satisfy the criteria (denoted as #
G), or
not satisfying the criteria (denoted as #). “May satisfy the
criteria” means that the technique can be made to satisfy the
criteria depending on the implementation or configuration,
while some implementations do not fully satisfy the criteria.
Of course, this analysis requires some opinion, and in each
case we evaluated each technique and criteria to the best
of our abilities. While others may disagree with the exact
assessment of each technique, we believe that the criteria
outlined in Section V will help to guide future telephone
spam defenses and to provide a framework to evaluate these
defenses.
VI. C OMBINING T ECHNIQUES
From analyzing all the standalone techniques, it is clear
that there is no single technique that can satisfy all the
criteria. Therefore, an improved anti-spam system would
look to combine different techniques, to leverage the
positives and compensate the negatives. We outline the
different ways in which a solution could use a combination
of standalone techniques.
Phased Decisions combine several techniques into a linear
sequence (i.e., a pipeline process) of decision stages. If
an earlier technique determines the call is spam, then it
may not be necessary to run the evaluation techniques
at later stages. This is suitable for combining techniques
that uses information that are obtained chronologically,
such as first using Call Request Header Analysis, followed
by Voice Interactive Screening. We found use of Phased
Decisions approach in related works by Niccolini and
Quitek et al. [96], [97], Schlegel et al. [98], Gritzalis and
Mallios [99], [100], and Azad and Morla [39].
Weighted Scoring combines several techniques by running
each technique individually and then combining the outputs
to produce a final score by applying a weighted scoring
method. The classification of whether the call is spam
is based on the final score. As Weighted Scoring need
to collect outputs from all standalone techniques, it is
suitable for combining techniques that can be performed

G
#
G
#
# G
#
# G
#
# G
#
#
G
#
#
G
#
G
G
#
G
#

#
#
#
G
G
#
G
#

# #
#
#
G #
#
G #
#
G #
#
G #
G
# #
G #
G
# #
G #
#
G
#
G
#
G
#
G
# #
#
#
G
#
G
#

#
#
#
#
#
G
#
G
#
G
#
G

Effective-Against-Dynamic-Audio-Content

Effective-Against-Multiple-Identities

Effective-Against-Answering-Machine-Detection

Effective-Against-Unavailable-Caller-ID

Effective-Against-Targeted-Caller-ID-Spoofing

Effective-Against-Dynamic-Caller-ID-Spoofing

Robustness

Negligible-Cost-per-Call

No-Third-Party-Involvement

References
Caller ID Blacklisting
[24], [25]
#
G
Caller ID Whitelisting
[26], [27]
#
Caller Reputation System
[28]–[42], [90]
#
G
G
#
#
G
Caller Behavior Analysis [29], [32], [33], [35], [39], [41], [43]–[54], [91], [92]
#
G
#
G
Call Request Header Analysis
Device Fingerprinting
[55]
#
G
#
G
Caller ID Anomaly Detection
[56], [57]
#
G
ANI-CPN Matching
[58]
G
#
ANI-II Filtering
[58]
G
#
Audio Fingerprinting
[61]–[67]
#
G #
#
G
Speech Content Analysis
[62], [68]
#
G #
#
G
Voice Interactive Screening
Acoustic Pattern Analysis
[71]–[74]
#
G #
#
G
CAPTCHA/Turing Test
[75]–[77]
# #
Do Not Call Registry
[22] #
G #
G #
G
#
Graylisting
[74], [79]
#
G #
G
#
#
G
Consent-based Communication
[80]–[82] #
# #
G #
G
#
#
G
Call Back Verification
[83], [84] #
G #
G #
G # #
G #
G
Caller Compliance
Weakly Secret Information
[85]
#
G #
G #
G
# #
G #
G
Payment at Risk
[38]
# #
G
# # # #
Proof of Work
[86], [93]–[95]
# #
G #
Proof of Identity
[83], [87]–[89]
# #
G # #
G
= satisfy the criteria #
G= may satisfy the criteria #= does not satisfy the criteria

Low-Maintenance
Low-Resource-Requirement

Negligible-Changes-to-Call-Setups

Negligible-Changes-to-Infrastructure

Permissive-for-VoIP-Callers

Deployability

Permissive-for-Unknown-Callers

Negligible-Delays

Effortless-for-Caller

No-Disturbance-to-Recipient

Scalable-for-Recipient

Usability

#
G

#
G
#
G
#
G
#
#
#

# #
G

G
# G
#
G
# G
#
G
# G
#

#
G
# # #
G
#
#
G

Table I: Evaluation of various standalone techniques against the criteria described in Section V.

simultaneously, such as the various standalone Call
Request Header Analysis techniques. We found use of
Weighted Scoring approach in related works by Dantu and
Kolan [101], Niccolini and Quitek et al. [96], [97], Schlegel
et al. [98], Hansen et al. [102], and Mathieu et al. [103].
Conditional Procedures combine several techniques based
on a predefined set of rules (i.e., a policy or an algorithm).
This allows for higher flexibility of combining the techniques, such as using a different sequence of standalone
techniques based on the preference of each recipient or
the reputation of each caller. We found use of Conditional
Procedures approach in related works by d’Heureuse et
al. [104], Dritsas et al. [105], Scata and La Corte [106],
and Soupionis and Gritzalis [47].
We evaluate existing solutions using a combined approach, and summarized which standalone techniques those
solutions incorporated in Table II. All of these works are
mainly focused on defense against SPIT, and some of these
may include SPIT-specific techniques that does not appear

in our table. Again, this analysis requires some opinion, and
we evaluated each solution to the best of our abilities. We
believe that the various strategies of combining techniques
outlined in Section VI will help to improve future telephone
spam defenses.
VII. R ELATED W ORK
While in this paper we have compared and analyzed the
state-of-the-art research in telephone spam defense, we will
now discuss related survey papers. Most of the papers focus
on spam in the Voice over IP (VoIP) domain, so-called SPam
over Internet Telephony (SPIT), rather than the larger PSTN
telephony network.
Keromytis [107], [108] presented two comprehensive surveys of VoIP security, which summarized previous works
related to VoIP security and organized them according to an
extended version of the VoIP Security Alliance (VoIPSA)
Threat Taxonomy. The papers reviewed many previous
works addressing every type VoIP threat in the VoIPSA
taxonomy, with the social threats of spamming as one of
the categories.

Phased Decisions
Weighted Scoring
Conditional Procedures
Caller ID Blacklisting
Caller ID Whitelisting
Caller Reputation System
Caller Behavior Analysis
Device Fingerprinting
Caller ID Anomaly Detection
ANI-CPN Matching
ANI-II Filtering
Audio Fingerprinting
Speech Content Analysis
Acoustic Pattern Analysis
CAPTCHA/Turing Test
Do Not Call Registry
Graylisting
Consent-based Communication
Call Back Verification
Weakly Secret Information
Payment at Risk
Proof of Work
Proof of Identity

[96], [97]



[98]



[99]


[100]


[101]

[102]

[103]

[104]




















































[105]





































[106]








Table II: Summary of various anti-spam solutions using a combination of standalone techniques.

Baumann et al. [109] presented a survey of potential
solutions to SPIT. The paper provided an overview and
classification of SPIT prevention methods based on detection using Signaling versus Voice and order-based Before
Call versus After/While Call. The paper also proposed a
Biometric Framework for SPIT Prevention as a way to bind
identities to each caller.
Phithakkitnukoon et al. [110] presented a survey focused
on five primary types of VoIP attacks, SPIT being one of
them. The authorized provided an introduction to the basic
knowledge of VoIP systems and its available security tools,
and summarized a list of proposed solutions for SPIT from
previous literature.
Quinten et al. [111] presented a survey evaluating the
techniques to prevent and reduce SPIT. The authors evaluated the effectiveness of techniques by dividing them into
four categories: unsuitable techniques, techniques with potential, suitable techniques, and combinations of techniques.
Dantu et al. [112] presented a survey discussing the
attacks and solutions in VoIP, with VoIP Spam and Phishing
being one of the attacks. The authors reviewed previous
work addressing all types of VoIP attacks and proposed a
high-level security architecture to make the VoIP infrastructure more secure and robust.
Dritsas et al. [113] presented a survey reviewing a list
of SPIT identification criteria that can be used by anti-SPIT
mechanisms and identified the different detection stages. The
authors propose two generic categories of SPIT identification

criteria: SIP Message criteria and SIP User Agent criteria.
They also proposed a two-fold evaluation framework for
discovering possible SPIT messages.
Marias et al. [114] presented a survey assessing the
threats and vulnerabilities that the SIP protocol introduces.
The authors also reviewed existing anti-SPIT mechanisms
and classified them into three classes: Prevent, Detect, and
Handle. The paper also proposes a list of qualitative and
quantitative criteria to assess the effectiveness of the antiSPIT countermeasures.
Khan et al. [115] presented a survey reviewing various
existing methods for preventing spam in IP telephony. The
paper also presented a discussion on the implementation
costs of different types of techniques, and commented that
no single technique is sufficient and therefore a framework
of multiple techniques is recommended.
Rosenberg et al. [116] presented an open memo reviewing
various solutions that might be possible to deal with SIP
spam. The author also presented some borrowed techniques
that have been employed to deal with email spam. In
conclusion, the author recommends using identity related
techniques, while also commented that identity techniques
may be vulnerable when a SIP request without an authenticated identity cannot know whether the request lacked such
an identity because the originating domain didn’t support it,
or because a man-in-the-middle removed it.
In general, most existing survey papers focus on techniques against SPIT or more specifically spam in the SIP

protocol. This paper is focused on techniques to address
spamming in the PSTN telephony network. Some techniques
for SPIT are not applicable to PSTN due to protocol differences. As far as we are aware, this is the first survey
paper specifically addressing spam calls directed to the
PSTN telephony network. In terms of evaluation differences,
we are the first to propose a taxonomy to classify the
existing standalone techniques into three categories, the first
to evaluate the standalone techniques based on three sets of
assessment criteria, and the first to outline the three strategies
of combining standalone techniques.
VIII. C ONCLUSION
From analyzing and evaluating the existing solutions that
attempt to address telephone spam, we reach the conclusion
that there is no universally acceptable solution to telephone
spam. Every approach thus far has different tradeoffs, specifically between usability, deployability, and robustness.
From our analysis of the telephone spam ecosystem and
defensive techniques, we believe that usability is the most
important criteria for evaluating a defense. Unlike email,
which can be delayed or possibly lost due to a false positive,
telephony solutions have a high bar for user acceptance,
and we believe that users will not adopt techniques that
impose excessive burden on both the caller and recipient.
Therefore, future research into this area must consider the
usability of the defense from both the caller and the recipient
perspective.
We believe that one promising avenue of research is
using a combination of techniques, which should improve
on the robustness of standalone techniques, and potentially
each technique could address the weaknesses of the others.
However, as the telephony system has real-time immediacy
constraints, care must be taken so that the combination of
techniques will not degrade the user experience due to higher
complexity. Our intuition leads us to recommend combining
no more than two standalone techniques, as we observed that
a good balance of usability, deployability, and robustness
could be achieved by using two standalone techniques.
One glaring issue that continually reoccurs when analyzing the telephone spam ecosystem is caller ID spoofing. We
believe that the key to combating telephone spam is to make
the caller ID trusted and verifiable, while making minimal
changes to existing infrastructure. For instance, from our
evaluation of Call Request Header Analysis techniques,
they provide the best overall usability and deployability,
however they suffer from robustness due to the spammer’s
ability to spoof the caller ID. If caller ID spoofing can
be effectively prevented, then we believe that Call Request
Header Analysis would satisfy all of our evaluation criteria.
Telephone spam is poised to increase significantly,
defrauding consumers of billions of dollars. Therefore, an
effective telephone spam defense is critical. However, the
techniques and approaches that were effective in combating

email spam are inappropriate when applied to telephone
spam. We attribute this to differences not only in the
technology used, but more fundamentally to the type of
communication. This is why a survey of the telephone
spam area is necessary: to highlight these differences and
to define the ideal criteria for telephone spam defenses. We
hope that this paper provides a framework to help guide
and shape future telephone spam defenses.
ACKNOWLEDGMENT
This work was partially supported by the grants from
Cisco Inc. and Center for Cybersecurity and Digital Forensics at ASU.
R EFERENCES
[1] CTIA,
“Annual
Wireless
Industry
Survey,”
http://www.ctia.org/your-wireless-life/how-wirelessworks/annual-wireless-industry-survey.
[2] U.S. Bureau of Labor Statistics, “American time use survey
fact sheet,” http://www.bls.gov/tus/atussummary.pdf, June
2015.
[3] Federal Trade Commission, “National do not call registry
data book fy 2014,” https://www.ftc.gov/system/files/
documents/reports/national-do-not-call-registry-data-bookfiscal-year-2014/dncdatabookfy2014.pdf, Federal Trade
Commission, Tech. Rep., 2015.
[4] Federal Trade Commission, “Consumer sentinel data book
for january - december cy 2014,” https://www.ftc.gov/
system/files/documents/reports/consumer-sentinel-networkdata-book-january-december-2014/sentinel-cy2014-1.pdf,
Federal Trade Commission, Tech. Rep., 2015.
[5] S. H. Kimball, T. Levy, H. Venturelli, and S. Miller, “Interactive Voice Recognition Communication in Electoral Politics: Exploratory Metadata Analysis,” American Behavioral
Scientist, 2014.
[6] A. R. Modarressi and R. Skoog, “Signaling System No. 7:
A Tutorial,” IEEE Communications Magazine, 1990.
[7] International Telecommunication Union, “Fixed-telephone
subscriptions,”
http://www.itu.int/en/ITU-D/Statistics/
Documents/statistics/2014/Fixed_tel_2000-2013.xls.
[8] Statista, “Countries by number of Voice over
Internet Protocol (VoIP) subscribers in 1Q 2013,”
http://www.statista.com/statistics/236824/number-of-voipsubscribers-by-leading-countries/.
[9] B. Woodcock and V. Adhikari, “Survey of Characteristics of
Internet Carrier Interconnection Agreements,” Packet Clearing House, Tech. Rep., 2011.
[10] Federal Communications Commission, “Intercarrier
compensation,”
https://www.fcc.gov/encyclopedia/
intercarrier-compensation, 2015.

[11] P. Casanova, R. Bandyopadhyay, and V. Balasubramaniyan,
“Largest IRS Phone Scam Likely Exceeded 450,000 Potential Victims in March,” http://www.pindropsecurity.com/irsphone-scam-live-call_analysis/, 2015.
[12] Marketwired, “From Stalkers to Spam, WhitePages
Study Breaks Down Reasons Americans Block
Calls,”
http://www.marketwired.com/press-release/fromstalkers-to-spam-whitepages-study-breaks-down-reasonsamericans-block-calls-1900134.htm.
[13] C. A. Hamilton, “Machine answer detection,” Dec. 6 1994,
uS Patent 5,371,787.
[14] T. Mobarak and A. Han, “Method and apparatus for forcing
a call to a carrier provided voice mail facility,” 2013, uS
Patent 8,605,869.
[15] Federal Communications Commission, “Calling Number
Identification Service–Caller ID,” 2015.
[16] C. Business, “PRI Trunk Plans,” http://business.comcast.
com/phone/pri-trunks/plans-pricing.
[17] E. Park, “Rustock Takedown’s Effect on Global Spam
Volume,” http://www.symantec.com/connect/blogs/rustocktakedown-s-effect-global-spam-volume, 2011.
[18] M. Carney, “Courts deem CallFire a common carrier,
setting a major precedent at intersection of telecom
and tech law,” http://pando.com/2015/02/27/courts-deemcallfire-a-common-carrier-setting-a-major-precedent-atintersection-of-telecom-and-tech-law/, Feb. 27, 2015.
[19] K. Cox, “FTC: Totally Fine By Us If Phone
Companies
Block
Robocalling
Numbers,”
http:
//consumerist.com/2015/01/27/ftc-totally-fine-by-us-ifphone-companies-block-robocalling-numbers/, Jan. 27,
2015.
[20] Federal Communications Commission, “Telephone consumer protection act 47 u.s.c. Âğ 227,” https://transition.fcc.
gov/cgb/policy/TCPA-Rules.pdf.
[21] Public Law 111âĂŞ331 111th Congress, “Truth in caller id
act of 2009,” https://www.congress.gov/111/plaws/publ331/
PLAW-111publ331.pdf.
[22] Federal Trade Commission, “National Do Not Call Registry,” https://www.donotcall.gov/.
[23] Federal Trade Commission, “Robocalls | consumer information,” https://www.consumer.ftc.gov/features/feature-0025robocalls, 2015.
[24] E. Montejo, “How to block phone calls on your
Android phone,” http://www.androidauthority.com/how-toblock-phone-calls-numbers-android-phone-246484/.
[25] Apple Inc., “Block calls and block or filter messages on your
iPhone, iPad, or iPod touch,” https://support.apple.com/enus/HT201229.
[26] T. Nimmerjahn, “Whitelist Call Blocker,” https:
//play.google.com/store/apps/details?id=de.tn_software.
callblocker.

[27] NQ Mobile Security, “NQ Mobile Call Blocker,” http://en.
nq.com/callblocker.
[28] P. Kolan and R. Dantu, “Socio-technical defense against
voice spamming,” ACM Transactions on Autonomous and
Adaptive Systems (TAAS), vol. 2, no. 1, p. 2, 2007.
[29] F. Wang, Y. Mo, and B. Huang, “P2p-avs: P2p based cooperative voip spam filtering,” in Wireless Communications and
Networking Conference, 2007. WCNC 2007. IEEE. IEEE,
2007, pp. 3547–3552.
[30] P. Patankar, G. Nam, G. Kesidis, and C. R. Das, “Exploring
anti-spam models in large scale voip systems,” in Distributed
Computing Systems, 2008. ICDCS’08. The 28th International Conference on. IEEE, 2008, pp. 85–92.
[31] R. Zhang and A. Gurtov, “Collaborative reputation-based
voice spam filtering,” in Database and Expert Systems
Application, 2009. DEXA’09. 20th International Workshop
on. IEEE, 2009, pp. 33–37.
[32] C. Sorge and J. Seedorf, “A provider-level reputation system
for assessing the quality of spit mitigation algorithms,” in
Communications, 2009. ICC’09. IEEE International Conference on. IEEE, 2009, pp. 1–6.
[33] V. B. Payas Gupta, Bharat Srinivasan and M. Ahamad,
“Phoneypot: Data-driven Understanding of Telephony
Threats,” in Proceedings of the Symposium on Network and
Distributed System Security (NDSS).
[34] P. Kolan, R. Dantu, and J. W. Cangussu, “Nuisance level of
a voice call,” ACM Transactions on Multimedia Computing,
Communications, and Applications (TOMM), vol. 5, no. 1,
p. 6, 2008.
[35] T. S. Corporation, “Nomorobo,” https://www.nomorobo.
com.
[36] K. Srivastava and H. G. Schulzrinne, “Preventing spam for
sip-based instant messages and sessions,” 2004.
[37] Y. Rebahi and D. Sisalem, “Sip service providers and the
spam problem,” in Proceedings of the 2nd VoIP Security
Workshop, 2005.
[38] Y. Rebahi, D. Sisalem, and T. Magedanz, “Sip spam detection,” in Digital Telecommunications„ 2006. ICDT’06.
International Conference on. IEEE, 2006, pp. 68–68.
[39] M. A. Azad and R. Morla, “Multistage spit detection in transit voip,” in Software, Telecommunications and Computer
Networks (SoftCOM), 2011 19th International Conference
on. IEEE, 2011, pp. 1–9.
[40] M. A. Azad, R. Morla, “Caller-rep: Detecting unwanted calls
with caller social strength,” Computers & Security, vol. 39,
pp. 219–236, 2013.
[41] Y.-S. Wu, S. Bagchi, N. Singh, and R. Wita, “Spam detection
in voice-over-ip calls through semi-supervised clustering,” in
Dependable Systems & Networks, 2009. DSN’09. IEEE/IFIP
International Conference on. IEEE, 2009, pp. 307–316.

[42] F. Wang, F. R. Wang, B. Huang, and L. T. Yang, “Advs:
a reputation-based model on filtering spit over p2p-voip
networks,” The Journal of Supercomputing, vol. 64, no. 3,
pp. 744–761, 2013.

[55] H. Yan, K. Sripanidkulchai, H. Zhang, Z.-Y. Shae, and
D. Saha, “Incorporating active fingerprinting into spit
prevention systems,” in Third annual security workshop
(VSWâĂŹ06). Citeseer, 2006.

[43] D. Shin, J. Ahn, and C. Shim, “Progressive Multi GrayLeveling: A Voice Spam Protection Algorithm,” IEEE Network, 2006.

[56] EveryCaller, “Call Control,” http://www.everycaller.com.

[44] H.-J. Kim, M. J. Kim, Y. Kim, and H. C. Jeong, “Devs-based
modeling of voip spam callersâĂŹ behavior for spit level
calculation,” Simulation Modelling Practice and Theory,
vol. 17, no. 4, pp. 569–584, 2009.
[45] M.-Y. Su and C.-H. Tsai, “A prevention system for spam
over internet telephony,” Appl. Math, vol. 6, no. 2S, pp.
579S–585S, 2012.
[46] M. Amanian, M. Moghaddam, and H. Roshkhari, “New
method for evaluating anti-SPIT in VoIP networks,” in
Computer and Knowledge Engineering (ICCKE), 2013 3th
International eConference on. IEEE, 2013, pp. 374–379.
[47] Y. Soupionis and D. Gritzalis, “Aspf: Adaptive anti-spit
policy-based framework,” in Availability, Reliability and
Security (ARES), 2011 Sixth International Conference on.
IEEE, 2011, pp. 153–160, http://dx.doi.org/10.1109/ARES.
2011.29.
[48] N. Chaisamran, T. Okuda, and S. Yamaguchi, “Trust-based
voip spam detection based on calling behaviors and human
relationships,” Information and Media Technologies, vol. 8,
no. 2, pp. 528–537, 2013.
[49] R. J. B. Chikha, T. Abbes, W. B. Chikha, and A. Bouhoula,
“Behavior-based approach to detect spam over IP telephony attacks,” International Journal of Information Security, 2015.

[57] Budaloop, “Regex Call Blocker,” https://play.google.com/
store/apps/details?id=com.budaloop.regexblocker.
[58] Pindrop Security, “Fraud Detection System,” http://www.
pindropsecurity.com/fraud-detection-system.
[59] S. J. Brolin and S. Colodner, “Automatic number identification in subscriber loop carrier systems,” Nov. 1 1977, uS
Patent 4,056,690.
[60] I. Neustar, “Nanpa : Ani ii digits - view assignments,” https://www.nationalnanpa.com/number_resource_
info/ani_ii_assignments.html, 2015.
[61] S. Horvath and T. Kasvand, “Voice identification prescreening and redirection system,” Sep. 6 2002, uS Patent
App. 10/236,810.
[62] D. Reich and R. Szabo, “Method and system of determining unsolicited callers,” Apr. 28 2004, uS Patent App.
10/833,515.
[63] C. Pörschmann and H. Knospe, “Analysis of Spectral Parameters of Audio Signals for the Identification of Spam
Over IP Telephony.” in CEAS, 2008.
[64] C. Pörschmann and H. Knospe, “Spectral Analysis of Audio
Signals for the Identification of Spam Over IP Telephony,”
in Proceedings of the NAG/DAGA International Conference
on Acoustics, 2009.

[50] H. Sengar, X. Wang, and A. Nichols, “Call Behavioral analysis to Thwart SPIT attacks on VoIP networks,” in Security
and Privacy in Communication Networks. Springer, 2012,
pp. 501–510.

[65] D. Lentzen, G. Grutzek, H. Knospe, and C. Porschmann,
“Content-based Detection and Prevention of Spam over
IP Telephony-System Design, Prototype and First Results,”
in Proceedings of the IEEE International Conference on
Communications (ICC), 2011.

[51] H. J. Kang, Z.-L. Zhang, S. Ranjan, and A. Nucci, “Sipbased voip traffic behavior profiling and its applications,” in
Proceedings of the 3rd annual ACM workshop on Mining
network data. ACM, 2007, pp. 39–44.

[66] J. Strobl, B. Mainka, G. Grutzek, and H. Knospe, “An Efficient Search Method for the Content-Based Identification of
Telephone-SPAM,” in Proceedings of the IEEE International
Conference on Communications (ICC), 2012.

[52] Y. Bai, X. Su, and B. Bhargava, “Adaptive Voice Spam
Control with User Behavior Analysis,” in Proceedings of
the IEEE International Conference on High Performance
Computing and Communications (HPCC), 2009.

[67] S. A. Iranmanesh, H. Sengar, and H. Wang, “A Voice Spam
Filter to Clean Subscribers’ Mailbox,” Security and Privacy
in Communication Networks, 2013.

[53] R. MacIntosh and D. Vinokurov, “Detection and mitigation
of spam in IP telephony networks using signaling protocol
analysis,” in Advances in Wired and Wireless Communication, 2005 IEEE/Sarnoff Symposium on. IEEE, 2005, pp.
49–52.
[54] S. Phithakkitnukoon, R. Dantu, R. Claxton, and N. Eagle,
“Behavior-based adaptive call predictor,” ACM Transactions
on Autonomous and Adaptive Systems (TAAS), vol. 6, no. 3,
p. 21, 2011.

[68] F. Maggi, “Are the Con Artists Back? A Preliminary Analysis of Modern Phone Frauds,” in Proceedings of the IEEE
International Conference on Computer and Information
Technology (CIT), 2010.
[69] L. R. Rabiner, “Applications of speech recognition in the
area of telecommunications,” in Automatic Speech Recognition and Understanding, 1997. Proceedings., 1997 IEEE
Workshop on. IEEE, 1997, pp. 501–510.
[70] David R. Wheeler, “Voice recognition will always be
stupid,” http://www.cnn.com/2013/08/20/opinion/wheelervoice-recognition/.

[71] V. A. Balasubramaniyan, A. Poonawalla, M. Ahamad,
M. T. Hunter, and P. Traynor, “Pindr0p: Using singleended audio features to determine call provenance,” in
Proceedings of the 17th ACM Conference on Computer
and Communications Security, ser. CCS ’10. New York,
NY, USA: ACM, 2010, pp. 109–120. [Online]. Available:
http://doi.acm.org/10.1145/1866307.1866320

[85] K. Ono and H. Schulzrinne, “Have i met you before?: using
cross-media relations to reduce spit,” in Proceedings of the
3rd International Conference on Principles, Systems and
Applications of IP Telecommunications. ACM, 2009, p. 3.

[72] H. Hai, Y. Hong-Tao, and F. Xiao-Lei, “A SPIT Detection
Method Using Voice Activity Analysis,” in Proceedings of
the International Conference on Multimedia Information
Networking and Security (MINES), 2009.

[87] H. Tschofenig, R. Falk, J. Peterson, J. Hodges, D. Sicker,
J. Polk, and A. Siemens, “Using saml to protect the session
initiation protocol (sip),” IEEE Network, vol. 20, no. 5, pp.
14–17, 2006.

[73] J. Quittek, S. Niccolini, S. Tartarelli, M. Stiemerling,
M. Brunner, and T. Ewald, “Detecting SPIT calls by checking human communication patterns,” in Proceedings of the
IEEE International Conference on Communications (ICC),
2007.

[88] S. Saklikar and S. Saha, “Identity federation for voip-based
services,” in Proceedings of the 2007 ACM workshop on
Digital identity management. ACM, 2007, pp. 62–71.

[74] J. Quittek, S. Niccolini, S. Tartarelli, and R. Schlegel,
“Prevention of Spam over IP Telephony (SPIT),” NEC, Tech.
Rep., 2006.
[75] J. Lindqvist and M. Komu, “Cure for spam over internet telephony,” in 4TH IEEE CONSUMER COMMUNICATIONS
AND NETWORKING CONFERENCE (CCNC 2007). ProceedingsâĂ˛e vol., n, 2007, pp. 896–900.
[76] A. Markkola and J. Lindqvist, “Accessible Voice
CAPTCHAs for Internet Telephony,” in Proceedings
of the Symposium on Accessible Privacy and Security
(SOAPS), 2008.
[77] Y. Soupionis, G. Tountas, and D. Gritzalis, “Audio
CAPTCHA for SIP-based VoIP,” in Proceedings of International Information Security Conference, 2009.
[78] E. Bursztein and S. Bethard, “Decaptcha: Breaking 75% of
eBay Audio CAPTCHAs,” in Proceedings of the USENIX
Workshop on Offensive Technologies (WOOT), 2009.

[86] A. Back, “Hashcash - A Denial of Service CounterMeasure,” http://www.hashcash.org/hashcash.pdf, 2002.

[89] L. Kong, V. A. Balasubramaniyan, and M. Ahamad, “A
lightweight scheme for securely and reliably locating sip
users,” in VoIP Management and Security, 2006. 1st IEEE
Workshop on. IEEE, 2006, pp. 9–17.
[90] V. Balasubramaniyan, M. Ahamad, and H. Park, “Callrank:
Combating spit using call duration, social networks and
global reputation.” in CEAS, 2007.
[91] R. Dantu and P. Kolan, “Preventing voice spamming,” in
Proceedings of the IEEE Global Telecommunications Conference (GLOBECOM), Workshop on VoIP Security Challenges and Solutions, 2004.
[92] B. Mathieu, Y. Gourhant, and Q. Loudier, “Spit mitigation
by a network level anti-spit entity,” in Proc. of the 3rd
Annual VoIP Security Workshop, 2006.
[93] C. Dwork and M. Naor, “Pricing via Processing or Combatting Junk Mail,” in Advances in Cryptology (CRYPTO),
1992.

[79] E. Harris, “The Next Step in the Spam Control
War: Greylisting,” http://projects.puremagic.com/greylisting/
whitepaper.html, 2003.

[94] N. Banerjee, S. Saklikar, and S. Saha, “Anti-vamming trust
enforcement in peer-to-peer voip networks,” in Proceedings
of the 2006 international conference on Wireless communications and mobile computing. ACM, 2006, pp. 201–206.

[80] Google Voice, “Screen calls,” https://support.google.com/
voice/answer/115083.

[95] C. Jennings, “Computational puzzles for spam reduction in
sip,” 2007.

[81] Verizon, “Call Intercept,” https://www.verizon.com/
support/residential/phone/homephone/calling+features/call+
intercept/130058.htm.

[96] S. Niccolini, “Spit prevention: state of the art and research
challenges,” in Proceedings of the 3rd Workshop on Securing
Voice over IP, 2006.

[82] Phone.com, “Phone.com university âĂŞ screening
calls
for
your
business
line
|
phone.com,”
https://www.phone.com/blog/tips-tricks/2014/02/24/phonecom-university-screening-calls-business-line/,
February
2014.

[97] J. Quittek, S. Niccolini, S. Tartarelli, and R. Schlegel, “On
Spam over Internet Telephony (SPIT) Prevention,” IEEE
Communications Magazine, 2008.

[83] N. Croft and M. Olivier, “A Model for Spam Prevention
in IP Telephony Networks using Anonymous Verifying Authorities,” in Proceedings of the Annual Information Security
South Africa Conference, 2005.
[84] H. Mustafa, W. Xu, A. R. Sadeghi, and S. Schulz, “You
Can Call but You Can’t Hide: Detecting Caller ID Spoofing
Attacks,” in Proceedings of the Conference on Dependable
Systems and Networks (DSN), 2014.

[98] R. Schlegel, S. Niccolini, S. Tartarelli, and M. Brunner,
“Ise03-2: Spam over internet telephony (spit) prevention
framework,” in Global Telecommunications Conference,
2006. GLOBECOM’06. IEEE. IEEE, 2006, pp. 1–6.
[99] D. Gritzalis and Y. Mallios, “A sip-oriented spit management
framework,” Computers & Security, vol. 27, no. 5, pp. 136–
153, 2008.

[100] D. Gritzalis, G. Marias, Y. Rebahi, Y. Soupionis, and
S. Ehlert, “Spider: A platform for managing sip-based spam
over internet telephony spit,” Journal of Computer Security,
vol. 19, no. 5, pp. 835–867, 2011.
[101] R. Dantu and P. Kolan, “Detecting spam in voip networks,”
in Proceedings of the steps to reducing unwanted traffic on
the internet on steps to reducing unwanted traffic on the
internet workshop. USENIX Association, 2005, pp. 5–5.
[102] M. Hansen, M. Hansen, J. Möller, T. Rohwer, C. Tolkmit,
and H. Waack, “Developing a legally compliant reachability management system as a countermeasure against spit,”
in Proceedings of Third Annual VoIP Security Workshop,
Berlin, Germany, 2006.
[103] B. Mathieu, S. Niccolini, and D. Sisalem, “SDRS: a voiceover-IP spam detection and reaction system,” Security &
Privacy, IEEE, vol. 6, no. 6, pp. 52–59, 2008.
[104] N. d’Heureuse, J. Seedorf, and S. Niccolini, “A policy
framework for personalized and role-based spit prevention,”
in Proceedings of the 3rd International Conference on Principles, Systems and Applications of IP Telecommunications.
ACM, 2009, p. 12.
[105] S. Dritsas, V. Dritsou, B. Tsoumas, P. Constantopoulos, and
D. Gritzalis, “Ontospit: Spit management through ontologies,” Computer Communications, vol. 32, no. 1, pp. 203–
212, 2009.
[106] M. Scatá and A. L. Corte, “Security analysis and countermeasures assessment against spit attacks on voip systems,”
in Internet Security (WorldCIS), 2011 World Congress on.
IEEE, 2011, pp. 177–183.
[107] A. D. Keromytis, “A survey of voice over ip security
research,” in Information Systems Security. Springer, 2009,
pp. 1–17.
[108] Keromytis, Angelos D, “A comprehensive survey of voice
over ip security research,” Communications Surveys & Tutorials, IEEE, vol. 14, no. 2, pp. 514–537, 2012.

[109] R. Baumann, S. Cavin, and S. Schmid, “Voice over ipsecurity and spit,” Swiss Army, FU Br, vol. 41, pp. 1–34,
2006.
[110] S. Phithakkitnukoon, R. Dantu, and E.-A. Baatarjav, “Voip
securityâĂŤattacks and solutions,” Information Security
Journal: A Global Perspective, vol. 17, no. 3, pp. 114–123,
2008.
[111] V. M. Quinten, R. Van De Meent, and A. Pras, “Analysis
of techniques for protection against spam over internet
telephony,” in Dependable and Adaptable Networks and
Services. Springer, 2007, pp. 70–77.
[112] R. Dantu, S. Fahmy, H. Schulzrinne, and J. Cangussu, “Issues and challenges in securing voip,” computers & security,
vol. 28, no. 8, pp. 743–753, 2009.
[113] S. Dritsas, Y. Soupionis, M. Theoharidou, Y. Mallios, and
D. Gritzalis, “Spit identification criteria implementation: Effectiveness and lessons learned,” in Proceedings of The Ifip
Tc 11 23rd International Information Security Conference.
Springer, 2008, pp. 381–395.
[114] G. F. Marias, S. Dritsas, M. Theoharidou, J. Mallios, and
D. Gritzalis, “SIP vulnerabilities and anti-SPIT mechanisms
assessment,” in Computer Communications and Networks,
2007. ICCCN 2007. Proceedings of 16th International Conference on. IEEE, 2007, pp. 597–604, http://dx.doi.org/10.
1109/ICCCN.2007.4317883.
[115] S. F. Khan, M. Portmann, and N. W. Bergmann, “A Review
of Methods for Preventing Spam in IP Telephony,” Modern
Applied Science, vol. 7, no. 7, p. p48, 2013.
[116] J. Rosenberg, C. Jennings, and J. Peterson, “The session
initiation protocol (SIP) and spam,” RFC 5039, January,
Tech. Rep., 2008.
[117] M. W. Slawson and C. I. O. C. Waiting, “Caller ID Basics,”
Intertek Testing Services/Testmark Laboratories, Lexington,
KY, 2001.

A PPENDIX
Description
Message Type (MDMF)
Message Length
Parameter Code (Date & Time)
Parameter Length
Month (November)
Day (28)
Hour (3pm)
Minutes (43)
Parameter Code (CPN)
Parameter Length (10)
From (6062241359)

Parameter Code (Name)
Parameter Length (9)
Name (Joe Smith)

Checksum

Decimal
128
33
1
8
49
49
50
56
49
53
52
51
2
10
54
48
54
50
50
52
49
51
53
57
7
9
74
111
101
32
83
109
105
116
104
88

ASCII

1
1
2
8
1
5
4
3

6
0
6
2
2
4
1
3
5
9

J
o
e
S
m
i
t
h

Hex
80
21
01
08
31
31
32
38
31
35
34
33
02
0A
36
30
36
32
32
34
31
33
35
39
07
09
4A
6F
65
20
53
6D
69
74
68
58

Table III: MDMF message sample in the existing POTS
protocol [117].

Evaluation of Seasonal Impacts on
Nitrifiers and Nitrification
Performance of a Full-Scale Activated
Sludge System
This work is submitted in complete fulfilment for the degree of
Doctor of Philosophy (Biotechnology) in the Department of
Biotechnology and Food Technology, Faculty of Applied Sciences at
the Durban University of Technology, Durban, South Africa

Oluyemi Olatunji Awolusi
(BSc. (Hons): Microbiology; MSc: Environmental Control and Management)

July 2016
SUPERVISOR: Professor Faizal Bux
CO-SUPERVISOR: Dr S.K. Sheena Kumari

DECLARATION

“I declare that the thesis herewith submitted for the degree Doctor of Philosophy:
Biotechnology at the Durban University of Technology is my original work and has
not been previously submitted for a degree at any other institution of higher education,
and that its only prior publication was in the form of conference papers, book chapter
and/or journal articles. I further declare that all the sources cited or quoted are
acknowledged and indicated by means of a comprehensive list of references.”

-------------------------------------------Oluyemi Olatunji Awolusi

I hereby approve the final submission of the following thesis.

---------------------------------Prof. F. Bux D. Tech. (DUT)

---------------------------------Dr Sheena Kumari PhD (Mangalore University)

ii

ABSTRACT

Seasonal nitrification breakdown is a major problem in wastewater treatment plants
which makes it difficult for the plant operators to meet discharge limits. The present
study focused on understanding the seasonal impact of environmental and operational
parameters on nitrifiers and nitrification, in a biological nutrient removal wastewater
treatment works situated in the midlands of KwaZulu Natal.
Composite sludge samples (from the aeration tank), influent and effluent water
samples were collected twice a month for 237 days. A combination of fluorescent insitu hybridization, polymerase chain reaction (PCR)-clone library, quantitative
polymerase chain reaction (qPCR) were employed for characterizing and quantifying
the dominant nitrifiers in the plant. In order to have more insight into the activated
sludge community structure, pyrosequencing was used in profiling the amoA locus of
ammonia oxidizing bacteria (AOB) community whilst Illumina sequencing was used
in characterising the plant’s total bacterial community. The nonlinear effect of
operating parameters and environmental conditions on nitrification was also
investigated using an adaptive neuro-fuzzy inference system (ANFIS), Pearson’s
correlation coefficient and quadratic models.
The plant operated with higher MLSS of 6157±783 mg/L during the first phase
(winter) whilst it was 4728±1282 mg/L in summer. The temperature recorded in the
aeration tanks ranged from 14.2oC to 25.1oC during the period. The average ammonia
removal during winter was 60.0±18% whereas it was 83±13% during summer and this
was found to correlate with temperature (r = 0.7671; P = 0.0008). A significant
correlation was also found between the AOB (amoA gene) copy numbers and
temperature in the reactors (α= 0.05; P=0.05), with the lowest AOB abundance
recorded during winter. Sanger sequencing analysis indicated that the dominant
nitrifiers

were

Nitrosomonas

spp.

Nitrobacter

spp.

and

Nitrospira

spp.

Pyrosequencing revealed significant differences in the AOB population which was 6
times higher during summer compared to winter. The AOB sequences related to

iii

uncultured bacterium and uncultured AOB also showed an increase of 133% and 360%
respectively when the season changed from winter to summer. This study suggests that
vast population of novel, ecologically significant AOB species, which remain
unexploited, still inhabit the complex activated sludge communities. Based on ANFIS
model, AOB increased during summer season, when temperature was 1.4-fold higher
than winter (r 0.517, p 0.048), and HRT decreased by 31% as a result of rainfall (r 0.741, p 0.002). Food: microorganism ratio (F/M) and HRT formed the optimal
combination of two inputs affecting the plant’s specific nitrification (qN), and their
quadratic equation showed r2-value of 0.50.
This study has significantly contributed towards understanding the complex
relationship between the microbial population dynamics, wastewater composition and
nitrification performance in a full-scale treatment plant situated in the subtropical
region. This is the first study applying ANFIS technique to describe the nitrification
performance at a full-scale WWTP, subjected to dynamic operational parameters. The
study also demonstrated the successful application of ANFIS for determining and
ranking the impact of various operating parameters on plant’s nitrification
performance, which could not be achieved by the conventional spearman correlation
due to the non-linearity of the interactions during wastewater treatment. Moreover, this
study also represents the first-time amoA gene targeted pyrosequencing of AOB in a
full-scale activated sludge is being done.
Keywords: amoA; Nitrifiers; NGS; Illumina; Pyrosequencing; Adaptive neuro-fuzzy
inference system; SAOR; SNFR; qPCR; activated sludge

iv

DEDICATION

This thesis is dedicated to all who have contributed positively to my building in life
and most importantly, to those who constituted themselves as stumbling blocks on my
path in one way or the other. You are all important and necessary part of my motivation
in my journey to success.

v

ACKNOWLEDGEMENTS

Words may not be enough to deeply appreciate those whom God has used to make this
vision a reality. May the Lord indeed, bless them all.


God Almighty, ever faithful; constant and loving father.



My supervisor, Prof F. Bux; for giving me the opportunity to conduct the research
under his mentorship. I am grateful for his time and guidance all through this project.
I equally appreciate him for the financial support given when the DUT bursary was
not there again. All these have contributed immensely to the successful completion of
this work.



My co-supervisor, Dr. Sheena Kumari; for constantly believing in me and her
motivation especially when the protocols were all failing and there was no result in
view. Thank you for your constructive criticism and input throughout the work. I
cannot thank you enough for your dedication to my work.



My wife and my closest friend; your unfeigned love, understanding, sacrifice and
unwavering support throughout this programme will forever be appreciated. I will
always love you.



To my parents: (1) Mr. and Mrs. F.O. Awolusi; I appreciate immensely your love,
prayers, financial and moral support; you have endured and stayed by me all through
this long journey; (2) Mr. and Mrs. R. O. Adeosun; I am equally grateful to you for
your love, prayers, support and for trusting me. Grandma Iloko, Mrs E. B. Awolusi,
your constant prayers, that seed of love (finance) when I was leaving home for this
programme will forever be precious to me. You shall all live long enough to reap the
harvest (Amen).



I appreciate my siblings for their unalloyed support and confidence in me: ‘Funke
(Gold) and Tosin, Oluwole and Tolu, Oluwatimileyin, Oyindamola and my wonderful
cousin, Temitope Akintade. I equally appreciate Omolola and Mojolaoluwa, and
Omobolanle. I love you all. I will equally like to appreciate my precious aunty; Mrs

vi

Omolara Olabisi, your goodwill and financial support when you heard about my
admission can never be forgotten.


Special thanks to Dr. Nasr Mahmoud for his superlative assistance to surmount the
ANFIS part of this study; the short period of research interaction we had was most
fruitful. I am grateful to Dr. Nishani for the encouragement and friendliness. Special
thanks to Dr. Enitan Abimbola, Kriveshin Pillay, Jashan Gokal, Christine Odinga,
Karen Reddy, and Thobela Conco for your friendship and assistance during sampling
and analysis, it would have been more-tasking. Dr. Abhishek and every other colleague
at the IWWT, for your support and friendliness, thank you all.



My age-long colleagues and friends, Dr. Yinka Aiyegoro, Dr. Ayo Adegoke, Dr.
Mobolaji Adegboye and Mayowa Agunbiade, for being there all the way with constant
encouragement and support.



I will like to appreciate Emmanuel Adewumi, Michael Adebowale, Dr Samuel Ilupeju
and family, Adetoyese Adeyemo, Ife Adegunloye and family, Pst. Kayode Akindeji
and family, Pst. Kester, Pst. Stanley and his wife for their kind support and
encouragement. This list can never be complete without thank Surveyor S. A.
Adeniran my HOD at work when I was leaving for this programme. You were solidly
there for me and it’s only God that can truly reward you for your goodwill towards
me.

vii

TABLE OF CONTENTS

DECLARATION ......................................................................................................... ii
ABSTRACT ................................................................................................................ iii
DEDICATION ............................................................................................................. v
ACKNOWLEDGEMENTS ........................................................................................ vi
TABLE OF CONTENTS .......................................................................................... viii
LIST OF FIGURES .................................................................................................. xiii
LIST OF TABLES .................................................................................................. xviii
ABBREVIATIONS .................................................................................................. xix
PREFACE ............................................................................................................... xxiii
CHAPTER ONE: INTRODUCTION ....................................................................... 1
1.1

AIMS AND OBJECTIVES OF THE STUDY .............................................. 5

1.1.1

Broad aim ............................................................................................... 5

1.1.2

Specific objectives ................................................................................. 5

CHAPTER TWO: LITERATURE REVIEW ........................................................... 6
2.1

NITRIFICATION .......................................................................................... 6

2.2

NITRIFYING COMMUNITY STRUCTURE .............................................. 8

2.2.1

Ammonia oxidizing bacteria and Nitrite oxidizing bacteria .................. 8

2.2.2

Ammonia oxidizing archaea ................................................................ 10

2.3

FACTORS AFFECTING NITRIFIERS AND NITRIFICATION ............. 12

2.3.1

Environmental factors .......................................................................... 12

2.3.2

Plant Operational conditions ................................................................ 14

2.4

ASSESSING NITRIFIERS DIVERSITY AND ABUNDANCE ............... 18

2.4.1

Most probable number (MPN) ............................................................. 18

viii

2.4.2

Quinone profiling ................................................................................. 19

2.4.3

Fluorescent in situ hybridization (FISH) ............................................. 19

2.4.4

Microarray ............................................................................................ 25

2.4.5

Polymerase chain reaction (PCR) – based techniques ......................... 25

2.4.5.2 Terminal restriction fragment length polymorphism (T-RFLP) .......... 27
2.4.6

Quantitative real-time PCR (qPCR) ..................................................... 27

2.4.7

Next generation sequencing approaches .............................................. 28

2.5

STATISTICAL ANALYSIS AND MODELLING IN WASTEWATER

TREATMENT ....................................................................................................... 33
2.6

RESEARCH OUTPUT ............................................................................... 34

CHAPTER THREE:

CHARACTERIZATION

OF

THE

DOMINANT

NITRIFERS IN ACTIVATED SLUDGE SYSTEM USING CONVENTIONAL
MOLECULAR METHODS ...................................................................................... 35
3.1

INTRODUCTION ....................................................................................... 35

3.2

MATERIALS AND METHODS ................................................................ 36

3.2.1

Plant description ................................................................................... 36

3.2.2

Sample collection ................................................................................. 37

3.2.3

Florescent in-situ Hybridization (FISH) .............................................. 39

3.2.4

Genomic DNA extraction .................................................................... 41

3.2.5

Spectrophotometric analysis ................................................................ 43

3.2.6

Polymerase chain reaction.................................................................... 44

3.2.7

Cloning, sequencing and phylogenetic analysis .................................. 44

3.2.8

Nucleotide sequence accession numbers ............................................. 48

3.3

RESULTS .................................................................................................... 48

3.3.1

Comparison of DNA extraction methods ............................................. 48

3.3.2

Detection of nitrifiers using FISH ........................................................ 50

ix

3.3.3

Detection of the dominant nitrifiers using PCR ................................... 51

3.3.4

Cloning and analysis ............................................................................ 53

3.3.5

Phylogenetic analysis ........................................................................... 55

3.4

DISCUSSION ............................................................................................. 59

3.5

CONCLUSIONS ......................................................................................... 64

3.6

RESEARCH OUTPUTS ............................................................................. 64

CHAPTER FOUR:

SEASONAL VARIATION IN COMMUNITY STRUCTURE

OF AEROBIC NITRIFYING ACTIVATED SLUDGE: THE NEXT-GENERATION
SEQUENCING APPROACH .................................................................................... 65
4.1

INTRODUCTION ....................................................................................... 65

4.2

MATERIALS AND METHODS ................................................................ 66

4.2.1

Wastewater treatment plant operation .................................................. 66

4.2.2

DNA extraction .................................................................................... 66

4.2.3

Seasonal analysis of community structure in the activated sludge ...... 66

4.2.4

Short-read archive accession numbers ................................................. 68

4.3

RESULTS .................................................................................................... 68

4.3.1

The total microbial community diversity as revealed by Illumina

sequencing analysis ............................................................................................ 68
4.4

DISCUSSION ............................................................................................. 78

4.5

CONCLUSIONS ......................................................................................... 82

4.6

RESEARCH OUTPUT ............................................................................... 82

CHAPTER FIVE: IMPACT OF ENVIRONMENTAL AND OPERATIONAL
PARAMETERS ON NITRIFYING COMMUNITY AND PLANT PERFORMANCE
83
5.1

INTRODUCTION ....................................................................................... 83

5.2

MATERIALS AND METHODS ................................................................ 84

5.2.1

Wastewater treatment plant operation and samples ............................. 84

x

5.2.2

Process monitoring and chemical analysis ........................................... 84

5.2.3

Calculating nitrification rate of the wastewater treatment plant .......... 85

5.2.4

Batch experiment for specific nitrification rate determination ............ 85

5.2.5

DNA extraction .................................................................................... 86

5.2.6

Standard curve preparation for quantitative real-time PCR analysis ... 86

5.2.7

Quantitative real-time PCR (qPCR) analysis ....................................... 87

5.2.8

Statistical Analysis ............................................................................... 89

5.3

RESULTS .................................................................................................... 89

5.3.1

Process performance and operational conditions ................................. 89

5.3.2

Nitrification rate ................................................................................... 93

5.3.3

Specific nitrification rate determination by batch experiment ............. 94

5.3.4

Quantification of AOB and NOB ......................................................... 95

5.4

DISCUSSION ............................................................................................. 97

5.5

CONCLUSIONS ....................................................................................... 100

5.6

RESEARCH OUTPUT ............................................................................. 101

CHAPTER SIX:
EVALUATING
NITRIFICATION

APPLICATION

OF

ARTIFICIAL

OPERATIONAL
AND

INTELLIGENCE

PARAMETERS

NITRIFIERS

IN

AN

FOR

INFLUENCING

ACTIVATED

SLUDGE

PROCESS………………………………………………………………………….103
6.1

INTRODUCTION ..................................................................................... 103

6.2

MATERIALS AND METHODS .............................................................. 105

6.2.1

Plant description ................................................................................. 105

6.2.2

Sampling protocol .............................................................................. 105

6.2.3

DNA

extraction

and

real-time

quantitative

PCR

(qPCR)

amplification .................................................................................................... 105
6.2.4

Analytical analysis ............................................................................. 106

xi

6.2.5
6.3

Adaptive neuro fuzzy inference system (ANFIS) .............................. 107

RESULTS AND DISCUSSION ............................................................... 110

6.3.1

Environmental conditions and system performance .......................... 110

6.3.2

Temporal changes in dominant nitrifiers’ abundance ratios .............. 113

6.3.3

Effect of operational conditions on specific nitrification rate ............ 114

6.3.4

Effect of operational conditions on AOB........................................... 118

6.3.5

Effect

of

operational

conditions

on

NOB

(Nitrobacter

and

Nitrospira) ........................................................................................................ 121
6.4

CONCLUSIONS ....................................................................................... 125

6.5

RESEARCH OUTPUTS ........................................................................... 126

CHAPTER SEVEN: GENERAL

CONCLUSIONS

AND

RECOMMENDATIONS ......................................................................................... 127
CONCLUSIONS .................................................................................................. 127
SIGNIFICANCE AND NOVELTY OF THE RESEARCH FINDINGS ............ 128
RECOMMENDATIONS ..................................................................................... 129
REFERENCE ........................................................................................................... 131
APPENDICES ......................................................................................................... 161

This thesis is a compilation of different manuscripts, where each chapter is an
individual entity; therefore, certain repetitions are unavoidable across chapters.
Moreover, Chapter Six has been published as it is and retains the Microbial Ecology
Journal format with results and discussion written together.

xii

LIST OF FIGURES

Fig. 2.1: The nitrification pathway incorporating the AOA (Awolusi et al., 2015):
ammonia oxidizing archaea; AMO: ammonia monooxygenase; HAO: hydroxylamine
oxidoreductase; NOR: nitrite oxide ............................................................................. 7
Fig. 2.2: Schematic representation of the nitrifying community in wastewater [adapted
from (Awolusi et al., 2015)] ...................................................................................... 10
Fig. 2.3: Diagrammatic description of Fluorescent in situ hybridization (ITRC, 2013)
.................................................................................................................................... 24
Fig. 2.4: Schematic diagram of pyrosequencing System (Gharizadeh et al., 2001) .. 30
Fig. 2.5: Schematic diagram of Illumina sample preparation and sequencing (Kircher
et al., 2011) ................................................................................................................ 32
Fig. 3.1: Schematic diagram of the full-scale biological treatment process under
study…………………………………………………………………………………37
Fig. 3.2: Agarose gel depicting genomic DNA isolated from sludge samples. Plates
[A], [B], and [C] depict extracted DNA using enzymatic, sonication and freeze-thaw
treatments respectively. Lanes M = 1 kb DNA ladder; lanes A2 – A4 shows genomic
DNA extracted from samples A, B and C respectively using enzymatic method; lanes
B1– B3 shows genomic DNA from samples A, B and C respectively using sonication;
and lanes C1 – C3 shows extracted DNA from samples A, B and C respectively using
freeze-thaw method. ................................................................................................... 50
Fig. 3.3: Micrograph of hybridized samples. Nitrifiers on each plate are shown as
follows: A(I) Micrograph of AOB hybridised by Cal Fluor Red 590 labelled AOB
oligonucleotide probe (NSO 1225); A(II) corresponding image showing AOB stained
with DAPI (blue); B(I) Micrograph of Nitrobacter hybridised with Cal Fluor Red 590
labelled NIT3 oligonucleotide probe; B(II) corresponding image showing Nitrobacter
stained with DAPI (blue); C(I) Micrograph of Nitrospira hybridised with Cal Fluor

xiii

Red 590 labelled Ntspa 662 oligonucleotide probe C(II) corresponding image showing
Nitrospira stained with DAPI (blue). ......................................................................... 51
Fig. 3.4: Primer specificity: Agarose gel showing PCR products for AOB at 490-bp.
Lane 1 denotes the 100-bp DNA ladder, whilst lanes 2 – 14 indicates resulting bands
from using amoA1F/amoA2R .................................................................................... 52
Fig. 3.5: Primer specificity: Agarose gel showing PCR products for Nitrospira spp. at
151 bp and Nitrobacter spp. at 397-bp. Lane 1 denotes the 100-bp DNA ladder, whilst
lanes 2–7 indicates resulting bands from using NSR 1113F/NSR 1264R and lanes 8–
13 depicting resultant bands from using FGPS872/FGPS1269 ................................. 52
Fig. 3.6: Cloned nitrifiers PCR product on IPTG/X-Gal-LB agar plates. Overnight E.
coli DH5α colonies incubated at 37oC after transformation with pTZ57R/T plasmid
vector. White and blue colonies were observed on LB agar containing IPTG and XGal .............................................................................................................................. 53
Fig. 3.7: Agarose gel image of PCR product from colony PCR products of amoA
amplicons (~490 bp) obtained after transformation (Lanes 2 – 8). Lane 1 = 100 bp
ladder. Colony PCR for amoA. .................................................................................. 54
Fig. 3.8: Agarose gel image of PCR product from colony-PCR products of Nitrospira
and Nitrobacter amplicons (~151 bp [Lanes 2 – 4, 6 – 8, 10 – 12, 14] and 397 bp
[Lanes 15; 17 – 19] respectively) obtained after transformation. Lane 1 = 100 bp
ladder. ......................................................................................................................... 54
Fig. 3.9: Phylogenetic tree of the bacterial amoA gene sequences recovered from
municipal activated sludge. A neighbour-joining tree was constructed from the
resulting alignment with MEGA 6, and the bootstrap values were based on 1000
replicates. The scale bar represents 0.02 change per site. The sequence of Bacillus
cereus was used as an out group. ............................................................................... 56
Fig. 3.10: Phylogenetic neighbour-joining tree based on partial 16S rRNA genes of
Nitrobacter species. A neighbour-joining tree was constructed from the resulting
alignment with MEGA 6, and the bootstrap values were based on 1000 replicates. The

xiv

scale bar represents 0.01 change per site. The sequence of Bacillus cereus was used as
an out group. .............................................................................................................. 57
Fig. 3.11: Phylogenetic tree of Nitrospira species in municipal activated sludge. The
scale bar represents 1% estimated sequence divergence. A neighbour-joining tree was
constructed from the resulting alignment with MEGA 6, and the bootstrap values were
based on 1000 replicates. The scale bar represents 0.01 change per site. The sequence
of Bacillus cereus was used as an out group. ............................................................. 58
Fig. 4.1: Taxonomic distribution of different bacterial phylogenetic groups during
summer and winter in the reactor at Phylum level. The percentages of the
phylogenetically classified sequences are plotted on the y-axis…………………….70
Fig. 4.2: Taxonomic distribution of different bacterial phylogenetic groups during
summer and winter in the reactor at the Class level. The percentages of the
phylogenetically classified sequences are plotted on the y-axis. ............................... 71
Fig. 4.3: Taxonomic distribution of different bacterial phylogenetic groups during
summer and winter in the reactor at Order level. The percentages of the
phylogenetically classified sequences are plotted on the y-axis. ............................... 72
Fig. 4.4: Taxonomic distribution of different bacterial phylogenetic groups during
summer and winter in the reactor at the Family level. The percentages of the
phylogenetically classified sequences are plotted on the y-axis. ............................... 73
Fig. 4.5: Rank abundance plot: (a) Phase 1 (winter); and (b) Phase 2 (summer). The
plots show the taxonomic abundances ordered with the most abundant ranked first and
plotted at the leftmost side and the least abundant ranked last and plotted toward the
right. The y-axis plots the abundances of annotations in each taxonomic group in log
scale ............................................................................................................................ 74
Fig. 4.6: Phylogenetic tree of some selected ammonia oxidizing bacteria OTUs based
on amoA gene locus pyrosequencing reads using BLASTN and MEGAN for samples
collected during summer ............................................................................................ 76

xv

Fig. 4.7: Phylogenetic tree of some selected ammonia oxidizing bacteria OTUs based
on amoA gene locus pyrosequencing reads using BLASTN and MEGAN for samples
collected during winter............................................................................................... 77
Fig. 4.8: (a) AOB diversity as revealed by pyrosequencing during summer, (b) AOB
diversity as revealed by pyrosequencing during winter ............................................. 78
Fig. 5.1: (a) Temperature variation in the reactor during the study and dissolved
oxygen concentration within the reactor during the study (b) Wastewater quality
indicating COD concentrations in the influent and effluent…………………………91
Fig. 5.2: (a) Variation in mixed liquor suspended solid concentration during the study.
(b) Measured nitrogen species concentrations of the plant during the study and
ammonia removal efficiency ...................................................................................... 92
Fig. 5.3: The nitrification rates measured in the aeration tanks during the period
investigated ................................................................................................................ 93
Fig. 5.4: Time-course profiles of the specific ammonium oxidizing rate (SAOR) and
specific nitrate forming rate (SNFR) of the plant ...................................................... 94
Fig. 5.5: Real-time PCR data for the purified DNA (Nitrospira) used in generating
standard curve indicating linearity over six order of magnitude (R2>0.99) (a) The
qPCR amplification curve (b) Standard curve. .......................................................... 96
Fig. 5.6: qPCR temporal changes in AOB, Nitrospira spp. and Nitrobacter spp. during
this study and ammonia removal rate of the plant ..................................................... 97
Fig. 6.1: Typical first-order Sugeno ANFIS architecture…………………………..107
Fig. 6.2: Temporal changes in dominant nitrifiers’ ratios in the full-scale wastewater
treatment plant under study. ..................................................................................... 114
Fig. 6.3: Effect of operating conditions on qN (The left-most input variable is the most
relevance with respect to qN). a) Every input variable's influence on qN; b) All two
input variable combinations and their influence on qN. ........................................... 117

xvi

Fig. 6.4: Effect of operating conditions on AOB (The left-most input variable is the
most relevance with respect to AOB). a) Every input variable's influence on AOB; b)
All two input variable combinations and their influence on AOB........................... 120
Fig. 6.5: Effect of operating conditions on Nitrobacter (The left-most input variable is
the most relevance with respect to Nitrobacter). a) Every input variable's influence on
Nitrobacter; b) All two input variable combinations and their influence on Nitrobacter.
.................................................................................................................................. 122
Fig. 6.6: Effect of operating conditions on Nitrospira (The left-most input variable is
the most relevance with respect to Nitrospira). a) Every input variable's influence on
Nitrospira; b) All two input variable combinations and their influence on Nitrospira.
.................................................................................................................................. 124

xvii

LIST OF TABLES

Table 2.1: Summary of techniques that have been employed for biodiversity studies
on nitrifiers ................................................................................................................. 21
Table 2.2: Summary of techniques that have been employed for quantitative studies
on nitrifiers ................................................................................................................. 22
Table 3.1: Average (winter and summer) wastewater characteristics and operational
parameters of the selected plant as observed during the study period……………….38
Table 3.2: rRNA – targeted oligonucleotide probes used and their specificity ......... 41
Table 3.3: Primers and the optimized amplification conditions ................................ 45
Table 3.4: Comparison of DNA extraction methods based on concentration and
purity .......................................................................................................................... 49
Table 5.1: Primers used and their specificity………………………………………..87
Table 5.2: Optimized real-time PCR protocols for quantifying nitrifiers .................. 88
Table 5.3: Description of qPCR standard curves parameters optimized for the
analysis during this study ........................................................................................... 95
Table 6.1: Operational conditions and ANFIS model parameters of the full-scale
wastewater treatment plant under study…………………………………………….112

xviii

ABBREVIATIONS

ALR

: Ammonia loading rate (kg COD/m3.d)

amoA

: Ammonia monooxygenase

Anammox

: Anaerobic ammonium oxidation

ANFIS

: Adaptive neuro-fuzzy inference system

AOA

: Ammonia oxidizing archaea

AOB

: Ammonia oxidizing bacteria

BLAST

: Basic Local Alignment Search Tool

BOD

: Biological oxygen demand

C: N

: Carbon: Nitrogen

CARD-FISH : Catalysed Reporter Deposition Fluorescence In Situ Hybridization
CAS

: Conventional activated sewage sludge system

CO2

: Carbon dioxide

COD

: Chemical oxygen demand

Cq

: Threshold cycle

Cr(VI)

: Hexavalent Chromium

DAPI

: 4′-6-diamino-2-phenylindole

DGGE

: Denaturing gradient gel electrophoresis

DNA

: Deoxyribonucleic acid

DNTPs

: Deoxy-nucleotide triphosphates

xix

DO

: Dissolved oxygen

EDTA

: Ethylenediaminetetra-acetate

F/M

: Food to microorganism ratio

FISH

: Fluorescent in-situ hybridization

FISH-MAR

: Fluorescent in situ hybridization- Microautoradiography

HAO

: Hydroxylamine oxidoreductase

HRT

: Hydraulic retention time

IPTG

: Isopropyl-β-d-thiogalactopyranoside

LB

: Luria-Bertani

MBR

: Membrane bioreactor

MCRT

: Mean cell residence time

MLSS

: Mixed liquor suspended solids

MPN

: Most probable number

NCBI

: Centre for the Biotechnology Information

ng

: Nanogram

NGS

: Next generation sequencing

NH2OH

: Hydroxylamine

NH3

: Ammonia

NO2–

: Nitrite

NO3–

: Nitrate

NOB

: Nitrite oxidizing bacteria

xx

NOR

: Nitrite oxide

OD

: Optical density

ORL

: Organic loading rate (kg COD/m3.d)

OUT

: Operational taxonomic unit

PacBio

: Pacific Biosciences

PBS

: Phosphate saline buffer

PCR

: Polymerase chain reaction

PCR-DGGE

: Polymerase chain reaction–denaturing gradient gel electrophoresis

PGM

: Personal Genome Machine

PVP

: Polyvinyl pyrrolidone

qN

: Specific nitrification rate

q-PCR

: Quantitative real-time

rDNA

: Ribosomal Deoxyribonucleic acid

RFLP

: Restriction fragment length polymorphism

𝑅𝑛𝑖𝑡𝑟𝑖𝑓𝑖𝑐𝑎𝑡𝑖𝑜𝑛 : Rate of plant’s nitrification
rRNA

: Ribosomal ribonucleic acid

SAOR

: Specific ammonium oxidizing rate

SBS

: Sequencing-by-synthesis

SDS

: Sodium dodecyl sulfate

SNFR

: Specific nitrate forming rate

SNOR

: Specific nitrite oxidizing rate

xxi

SRT

: Sludge retention time

TBE

: Tris-boric acid-ethylene

TE

: Tris-EDTA

TGGE

: Temperature gradient gel electrophoresis

TN

: Total nitrogen

T-RFLP

: Terminal restriction fragment length polymorphism

Tris-HCl

: Tris hydrochloride

UQ

: Ubiquinone

WWTP

: Wastewater treatment plant

X-gal

: β-galactosidase substrate

𝑄𝑖𝑛

: Influent flowrate (L3/ T)

xxii

PREFACE

The following publications has emanated from this study:
(a) Journal Articles
1) Awolusi, O. O., Kumari, S. K. S., Bux, F. 2015. Ecophysiology of nitrifying
communities in membrane bioreactors. International Journal of Environmental
Science and Technology 12: 747-762
2) Awolusi, O. O., M. Nasr, Kumari, S. K. S., Bux, F. (2016) Artificial intelligence
for the evaluation of operational parameters influencing nitrification and nitrifiers in
an activated sludge process. Microbial Ecology DOI: 10.1007/s00248-016-0739-3
3) Awolusi, O. O., M. Nasr, Kumari, S. K. S., Bux, F. Principal component analysis
for interaction of wastewater characteristics and nitrifiers at a full-scale activated
sludge plant. Environmental Science and Pollution Research (submitted)

(b) Book Chapter
1) Gokal, J., Awolusi, O. O., Enitan, A. M., Kumari, S. K. S., and Bux, F. 2015.
Molecular characterization and quantification of microbial communities in wastewater
treatment systems. In: Shukla, P. eds. Microbial biotechnology: an interdisciplinary
approach. Taylor & Francis (ISBN: 978-1-4987-5677-8) (In press)
Conference Papers
1) Awolusi O. O., Kumari S.K., Bux F. Investigation of nitrogen converters in
municipal wastewater treatment plant. Water Institute of Southern Africa (Water - The
ultimate constraint) biennial conference, the International Convention Centre, Durban,
15th - 19th May 2016.

xxiii

2) Awolusi O. O., Kumari S. K., Bux F. 2015. Seasonal impact on nitrification
potential of activated sludge treating municipal wastewater. Paper presented at 4th
Young Water Professional (South Africa) Biennial Conference and 1st Africa-wide
YWP Conference, CSIR International Convention Centre, Pretoria, South Africa, 16th
– 18th November 2015 (Oral presentation).
3) Awolusi, O. O., Enitan, A. M., Kumari, S. K. S., and Bux, F. 2015. Nitrification
efficiency and community structure of municipal activated sewage sludge. Paper
presented at 17th International Conference on Biotechnology, Bioengineering and
Bioprocess Engineering, Rome, Italy, September 17 - 18, 2015 (Oral presentation).
4) Awolusi O. O., Kumari S.K., Bux F. 2014. Characterization and quantification of
nitrifying community in activated sludge system treating municipal wastewater. Paper
presented at Water Institute of Southern Africa (WISA) 2014 (Water Innovations)
biennial conference, Mbombela Stadium, Nelspruit, South Africa (Oral presentation).

xxiv

CHAPTER ONE: INTRODUCTION

Historically, the epidemics in London between 1831 and 1866, which resulted from
water pollution, necessitated the requirement of specific regulations on wastewater
treatment and discharge. This in turn prompted the construction and operation of
wastewater treatment plants (WWTPs) and the eventual development of advanced
wastewater treatment technologies (Glicksman and Batzel, 2010; Sciampacone,
2013).The untreated wastewater is usually laden with high content of pollutants
(organic and inorganic) and pathogens. Discharging this untreated wastewater into
water bodies usually results in disruption of the normal ecological functioning of
aquatic ecosystems and widespread waterborne diseases (Holeton et al., 2011; Uan et
al., 2013). In aquatic environments, the inorganic nitrogen (NH3 and NO2-) and
phosphates at elevated levels (>0.05 mg/L) have been implicated to stimulate
eutrophication (WEF, 2009; Chuai et al., 2012). Even at low concentrations (<0.2
mg/L), the unionized ammonia has been reported to be acutely toxic to fish (Yang et
al., 2010; Chen et al., 2012). As a result, national governments around the globe have
environmental agencies saddled with the responsibility of enforcing compliance with
effluent discharge limits which includes dissolved organic carbon (biological or
chemical oxygen demand) as well as nitrogen compounds and phosphates (Holeton et
al., 2011).

Although there are biological and chemical ways of treating wastewater, the former is
usually the preferred choice as it is more environmentally friendly (Akpor and Muchie,
2010). Activated sludge, membrane bioreactors (MBRs), trickling filters, up-flow
anaerobic sludge blanket reactors, lagoons and artificial wetlands are the most
commonly used biological treatment processes for both industrial and domestic
wastewaters (Akpor and Muchie, 2010; Heffernan et al., 2011). Biological wastewater
treatment harnesses the ability of the microorganisms to metabolize the pollutants in

1

wastewater for synthesizing their cells’ building blocks. These bioreactors are
configured and operated in a way to select and enrich the specialized microbial
consortium that are required for nutrient removal (Lopez-Vazques, 2009). The
bioprocesses through which nutrients are transformed and removed within these
engineered systems depend on structure and concentration of the mixed microbial
community with nitrifiers occupying an important ecological niche within it (Graham
et al., 2007; Ozdemir et al., 2011).

Nitrification as a process is essential for nitrogen removal in biological nutrient
removing (BNR) systems (You and Lin, 2008; Ward, 2013). Nitrifying bacteria form
an important part of this ecological system and are responsible for ammonia
biotransformation and removal through nitrification. Nitrification process involves the
bioconversion of ammonia into nitrite by either ammonia-oxidizing bacteria (AOB) or
ammonia-oxidizing archaea (AOA) and subsequent conversion of nitrite to nitrate by
nitrite-oxidizing bacteria (NOB) (Bae et al., 2013; Ward, 2013). Nitrifiers are
‘vulnerably delicate’, with characteristic slow growth rate (Wei et al., 2013).
Nitrification, like any other process that hinges on microbial physiology, is subject to
failure whenever there is a shift in operational conditions or in the presence of toxic
compounds (Ducey et al., 2010). This shift may result in the loss of key microbial
populations which need to be replenished in order for the system to recover its
functional ability (Kim et al., 2011).

Nitrification process in BNR systems is usually limited by the nitrifiers’ physiological
activities (Zhang et al., 2011a; Dogan et al., 2014; Lotti et al., 2014). Monitoring the
nitrifiers, especially ammonia oxidizing bacteria (AOB) in wastewater treatment
systems, is therefore important in order to prevent nitrification failure (Siripong and
Rittmann, 2007). According to Gentile et al. (2007), it is important to understand how
the microbial communities correlates to system stability in a bid to design functionally
reliable wastewater treatment systems. The nitrifiers could serve as indicator
parameter for preventing washout of important functional groups in wastewater

2

treatment facility. Various studies have reported nitrification depletion or loss due to
seasonal temperature variations especially during winter (Caballero, 2011; FloresAlsina et al., 2011; Yao et al., 2013). It is therefore important to understand the role
of nitrifiers’ diversity and abundance in such functional fluctuations. Majority of the
studies however, have been carried out in regions with extremely low winter average
temperatures (temperate regions) contrary to the sub-tropical temperature regime
experienced in some parts of the Southern hemisphere.

Seasonal fluctuations and failures in nutrients removal due to the operational and
environmental changes have been widely reported in engineered wastewater treatment
systems (Wang et al., 2012). Among these, seasonal temperature variation has been
implicated as a major cause of breakdown in ammonia removal efficiency and
nitrification (Vieno et al., 2005; Wan et al., 2011) and with climate change
experienced globally these impact could be further magnified. Majority of the studies
have been conducted over short period of time. What we knew about the organisms
involved in nitrification is changing with some novel detection tools (Sorokin et al.,
2012; Stahl and de la Torre, 2012). There have been reports by different authors
(Limpiyakorn et al., 2011; Mussmann et al., 2011; Zhang et al., 2011b) on the probable
involvement of AOA in wastewater nitrification which indicate our inconclusive
knowledge of wastewater microbiology. However, there is still need to establish if
AOA are ubiquitous in all engineered systems in order to establish a holistic
knowledge of nitrogen biotransformation and AOA contribution in wastewater
treatment.

Understanding the microbial community structure of activated sludge has never been
an easy task. Culture-dependent methods have been relied upon solely in the past to
study microorganisms present in the natural environment including wastewater
ecosystems. Only a few bacterial species were thought to be involved in the process
based on these laboratory culture techniques, whereas in reality, a great diversity of
organisms have been involved and are nonculturable. The advent of molecular

3

techniques has brought about a better understanding of the structure and functions of
microbial communities including nitrifiers in wastewater treatment systems. In recent
past, the nitrifying community structure of activated sludge systems have been
investigated

using

different

techniques

including;

quinone

profiling,

(a

chemotaxonomic method) (Li et al., 2006), restriction fragment length polymorphism
(RFLP) (Gao and Tao, 2012), fluorescent in situ hybridization (FISH), denaturing
gradient gel electrophoresis (DGGE) (Yu et al., 2011), clone library (Yao et al., 2013),
terminal restriction fragment length polymorphism (T-RFLP) (Whang et al., 2012),
quantitative real-time PCR (qPCR) (Cho et al., 2014). However, these techniques have
well documented limitations that often reduce their ability to unravel the complete
microbial community structure of the activated sludge (Awolusi et al., 2015). Nextgeneration sequencing which has the capacity of performing about several hundreds
of thousands of reactions simultaneously is gaining ground in studies involving
understanding the microbial community structure of wastewater treatment systems
(Liu et al., 2012; Ye and Zhang, 2013). It has the advantage of revealing the microbial
diversity with more accuracy and details.

South Africa is a sub-tropic region with warm temperate weather conditions.
Wastewater treatment plants in the KwaZulu-Natal have a history of nitrification
failure especially during the winter. This study therefore, investigated the nitrification
efficiency and nitrifying community in one of the full-scale municipal wastewater
treatment plants situated midlands of KwaZulu-Natal province, over two seasons
(summer and winter). The plant’s nitrification efficiency was investigated in
correlation to diversity and abundance of the different nitrifying populations. A
combination of FISH, PCR-clone library, quantitative polymerase chain reaction
(qPCR) and next generation sequencing (pyrosequencing and Illumina) was employed
in understanding the microbial community structure of the plant. The effect of
operating parameters and environmental conditions on nitrification and nitrifiers was
also investigated using an adaptive neuro-fuzzy inference system (ANFIS), Pearson’s
correlation coefficient and quadratic models. To the best of our knowledge this is the
first time ANFIS, rather than the typical simple correlation approach would be used

4

for investigating nitrification. The amoA-locus-targeted pyrosequencing was also
employed to study AOB diversity for the first time.

1.1

AIMS AND OBJECTIVES OF THE STUDY

1.1.1

Aim

The aim of this study was to monitor the seasonal changes in population profiles of
chemolithoautotrophic nitrifying bacteria in a full-scale municipal activated sludge,
using advanced molecular techniques and correlate this to the plant's performance.

1.1.2

Specific objectives

The specific objectives are to:
 characterize the dominant nitrifers in activated sludge system using
conventional molecular methods
 evaluate the seasonal variation in the microbial community structure of the
activated sludge using the next-generation sequencing approach
 quantify the dominant nitrifying bacterial populations using qPCR and
determine their nitrification performance
 evaluate the influence of operational and environmental parameters on
nitrification and nitrifiers in the activated sludge using artificial intelligence
(AI)

5

CHAPTER TWO: LITERATURE REVIEW

2.1

NITRIFICATION

Nitrification involves the biological conversion of ammonia/ammonium to nitrite by
ammonia-oxidizing bacteria (AOB) and ammonia-oxidizing archaea followed by the
conversion of nitrite to nitrate by nitrite-oxidizing bacteria (NOB) (Bae et al., 2013;
Mukherjee, 2013). In a wastewater treatment process, most of the organic nitrogen
contained in raw sewage in the form of urea and faecal material will be converted to
ammonia by hydrolysis through anaerobic processes while travelling through the
sewer pipes (Daims and Wagner, 2010). Various authors have noted that nitrification
can be carried out by organisms other than bacteria such as protozoa, algae and fungi,
however, at a very low level rate (1,000–10,000 times less than the rates associated
with bacteria) (Gerardi, 2002; Nicol and Schleper, 2006).

Nitrifying bacteria are aerobes and chemolithoautotrophs, obtaining their energy by
oxidation of either NH3 or NO2– (Daims and Wagner, 2010; Jin et al., 2010). Certain
bacteria called anammox (anaerobic ammonium oxidation) are capable of oxidizing
NH3 under anaerobic conditions. These organisms use NH4+as their energy source and
NO2–as electron acceptor with the production of hydrazine in an intermediate process
(Xiao et al., 2013). The AOB uses the enzyme ammonia monooxygenase (amoA) to
catalyse the oxidation of ammonia to hydroxylamine (NH2OH) (Bahadoorsingh,
2010), and the enzyme hydroxylamine oxidoreductase converts it to NO2– (Canfield et
al., 2010). The NOB further oxidizes NO2– to NO3– using nitrite oxidoreductase
enzyme (Bahadoorsingh, 2010) (Fig. 2.1). Although all nitrifiers are known to be slow
growers, NOB has a lower specific growth rate than the AOB (Daims and Wagner,
2010). Thus, a successful nitrification process requires a balance in the linked activity
of these two nitrifying bacterial groups involved. It has been reported that factors such
as high ammonia concentration and low dissolved oxygen (DO) level can result in the
disruption of the equilibrium between these two nitrification steps, resulting in

6

significant reduction in the activities of nitrite oxidizers which can lead to toxic nitrite
build-up and a subsequent failure of nitrification process (Mbakwe et al., 2013).
According to Graham et al. (2007), there is a delicate and vulnerable AOB–NOB
mutualism present, which makes the process prone to chaotic behaviour and
incomprehensible failure at times.

Fig. 2.1: The nitrification pathway incorporating the AOA (Awolusi et al., 2015):
ammonia oxidizing archaea; AMO: ammonia monooxygenase; HAO: hydroxylamine
oxidoreductase; NOR: nitrite oxide

7

The nitrification process in wastewater is therefore limited by the AOB and NOB
population densities and their physiological activities in different types of wastewater
treatment plants (WWTP), including conventional activated sludge treatment systems
and membrane bioreactor (MBR) (Graham et al., 2007; Huang et al., 2010a; Zhang et
al., 2011b). In both cases, the nitrification efficiency seems to be controlled by the
prevalent operational and environmental conditions (Manser et al., 2005;
Bahadoorsingh, 2010). Various authors have reported 96–99 and 92–98 % ammonia–
nitrogen and chemical oxygen demand (COD) removals in treatment systems
investigated (Liang et al., 2010; Yu et al., 2010; Ozdemir et al., 2011). Specific
ammonia oxidization rate and nitrite oxidization rates were also reported to vary with
no particular pattern during wastewater treatment (Liang et al., 2010; Yu et al., 2010;
Ozdemir et al., 2011).

2.2

NITRIFYING COMMUNITY STRUCTURE

2.2.1 Ammonia oxidizing bacteria and Nitrite oxidizing bacteria
The majority of nitrifiers in wastewater remains uncultivable, and thus, only very few
strains of AOB (25 species) and NOB (8 species) have so far been identified and
classified based on conventional cultivation techniques (Egli et al., 2003; WojnowskaBaryla et al., 2010). The growth rate of autotrophic bacteria (nitrifiers) is five times
slower than that of heterotrophic bacteria in WWTPs (Ozdemir et al., 2011). Thus, the
nitrifiers form only 3 – 20 % of the total bacteria in activated sludge (Gerardi, 2002;
Xia et al., 2010b; Yu et al., 2011; Cydzik-Kwiatkowska et al., 2012), which makes the
isolation of nitrifiers difficult. However, the successful application of molecular
techniques to the complex environmental samples has helped to unravel the
complexity and diversity of these groups in nature (Gao and Tao, 2012).

The 16S rDNA sequences revealed that these two groups of nitrifying bacteria (AOB
and NOB) are phylogenetically distinct (Daims and Wagner, 2010). All ammonia
oxidizers can be classified in the β-subclass of Proteobacteria with the exception of

8

Nitrosococcus, which belongs to a distinct branch of the γ-subclass. The NOB can be
found within the α- and γ-subclasses of Proteobacteria, with the exceptions of
Nitrospira, which has its own distinct phylum (Duan et al., 2013), and Nitrospina,
which belongs to the δ-subclass of Proteobacteria (Zeng et al., 2012) (Fig. 2.2). Due
to their low specific growth rate and sensitivity to stress from environmental and
operational factors, their population and physiological activities can limit the rate of
biotransformation of nitrogen in many WWTPs. Although the dominance of
Nitrospira (K-strategist) over Nitrobacter (r–Strategist) in activated sludge has been
widely reported (Yapsakli et al., 2011; Ye et al., 2011); however, earlier observations
by Nogueira and Melo (2006), and Wagner et al. (2002) were contrary. These authors
noted that there is usually an irreversible prevalence of Nitrobacter spp. over
Nitrospira spp. in plants after spike in nitrite concentration even after subsequent
reduction in nitrite concentration. Nitrobacter spp. usually exhibit inhibitory effect on
the growth of Nitrospira once it dominates (Nogueira and Melo, 2006). Fukushima et
al. (2013) also reported that Nitrobacter spp. though a weak competitor compared to
Nitrospira under low nitrite concentration, however it can be selected over Nitrospira
spp. in plants with low inorganic carbon in addition to low nitrite concentration.

The recognized diversity of NOB has been curiously low and they have been known
to belong to two bacterial phyla. Sorokin et al. (2012) expanded our knowledge of
NOB with the discovery of Nitrolancetus hollandicus isolated from a nitrifying
reactor. This organism belongs to the popular phylum Chloroflexi not previously
known to contain any nitrifying organism. This organism is distinguished from all
other NOB being Gram positive with an unusual membrane lipids consisting 1, 2-diols.
It is thermo-tolerant over a broad range of 25-63oC. It has low affinity for nitrite (Ks
≈ 1 mM). It grows on nitrite and CO2 with ability to use formate as a source of energy
and carbon. It has the genes for CO2 fixation via Calvin cycle and nitrite
oxidoreductase similar to proteobacterial NOB.

9

Fig. 2.2: Schematic representation of the nitrifying community in wastewater [adapted
from (Awolusi et al., 2015)]

2.2.2 Ammonia oxidizing archaea
The developments in molecular biology techniques have helped us to understand the
diversity, distribution and abundance of possible functional archaea in engineered
systems such as WWTPs (Hatzenpichler, 2012). In recent times, the contribution of
archaea to nitrification in WWTPs is being acknowledged by various researchers;

10

however, very little information is available on the physiology and activity of
ammonia-oxidizing archaea in the environment. Among the different AOA,
Candidatus Nitrosopumilus maritimus was the first member of the group to be isolated
(Stahl and de la Torre, 2012). This species is reported to have the same growth and
cell production rates as those of AOB and is capable of using ammonia as the sole
energy source for growth (You et al., 2009).

AOA can tolerate environment with oxygen concentration over the range of <3.1 µM–
0.2 mM; however, the environment with low oxygen may select them in contrast to
AOB (Limpiyakorn et al., 2011). The AOB uses the Calvin cycle to fix their carbon,
whereas the AOA rely on the 4-hydroxybutyrate pathway or citric acid cycle
(Hatzenpichler, 2012). The AOA was previously grouped under phylum
Crenarchaeota (Jin et al., 2010; Zhang et al., 2011a) but have recently been
reclassified under phylum Thaumarchaeota (Stahl and de la Torre, 2012). Ozdemir et
al. (2011) in a study on nitrification, reported the presence of a small fraction of AOA
among other nitrifiers.

An observation of interest about AOA is that they are less sensitive to plant operational
conditions (e.g. DO and ammonia loading) compared to AOB (Jin et al., 2010;
Sonthiphand and Limpiyakorn, 2010). The fact that in natural environments AOA are
associated with significant role in nitrification contrary to what is currently known
about engineered systems leaves the question of whether the optimum conditions for
their ecological functioning have been adequately understood or replicated in such
systems. If the assertion by some authors that AOA are tolerant to fluctuations in
operational conditions (Jin et al., 2010; Sonthiphand and Limpiyakorn, 2010) is valid,
then it may be desirable to harness its potential for a stable and efficient wastewater
treatment. There would be need for the development of engineered systems that can
adequately replicate the conditions which support AOA’s optimal growth as obtained
in the natural environment. The role and efficiency of AOA in nitrification remains
unclear, since their isolation and cultivation is still largely unsuccessful. The archaeal

11

membrane lipids (isoprenoid glycerol dialkyl glycerol tetraethers) have been suggested
as a bio-indicator for investigating the ecophysiology of AOA in wastewater treatment
bioreactors. These lipids have been observed to correlate with archaeal amoA gene
copies (You et al., 2009). Recently, AOA that were deficient in both carbon fixation
and NH3 oxidation abilities despite possessing amoA gene were reported (Mussmann
et al., 2011; Stahl and de la Torre, 2012). This indicates that AOA importance in
nitrification cannot be determined based on mere presence or abundance of arch-amoA
gene. Various authors observed that the AOA are able to utilize amino acids as a
carbon source akin to heterotrophs (You et al., 2009; Bouskill et al., 2011). Recently,
studies based on radiocarbon and genomic analyses suggest that the AOA either
include both heterotrophs and autotrophs, or they are single population of mixotrophs
(Bouskill et al., 2011).

2.3

FACTORS AFFECTING NITRIFIERS AND NITRIFICATION

Nitrification, like any other process that hinges on microbial physiology, is subject to
failure whenever there is a shift in operational conditions or in the presence of
inhibitory substances (Ducey et al., 2010). Thus, efficient nitrification in wastewater
treatment plants depends on a combination of environmental and operational
parameters which include pH, temperature (Gerardi, 2002; Kim et al., 2011), DO,
sludge retention time (SRT), hydraulic retention time (HRT), substrate concentration
(Bae et al., 2002; Liu et al., 2010a) and presence of inhibitory or toxic substances
(Cecen et al., 2010).

2.3.1

Environmental factors

2.3.1.1 pH and alkalinity
Traditionally, efficient nitrification has been reported at a pH ranging from 7.5 to 8.5
(Sajuni et al., 2010; Fulweiler et al., 2011). A higher pH value of 8–9 was reported to
favour elevated nitrite accumulation, thereby affecting the optimal nitrification process

12

(Bae et al., 2002). A study conducted by Bae et al. (2002) on activated sludge plants
reported an increase in the specific ammonium oxidizing rate (SAOR) when the pH
increased from 7 to 8; however, the rate dropped as the pH reached 9 and yielded the
lowest activity at pH 10 (Bae et al., 2002). In the same experiment, the specific nitrite
oxidizing rate (SNOR), on the other hand, correlated with an increase in pH from 7 to
9, but was decreased at pH 10. Similarly, He et al. (2009) in their study on nitrification,
noted that pH plays a major role in NH3 and total nitrogen (TN) removal in reactor.
When the influent pH was acidic (approximately 4.8), the NH3 removal rate was 56
%, whereas that of TN was 45 %. An increased removal of NH3 up to 99 % was
observed, while that of TN rose to 91 % when the pH was neutral (7.2), and a decrease
to 75 % (NH3) and 60 % (TN) was noted when the pH increased to about 9.7. These
findings by He et al. (2009) also indicate that efficient nitrification falls within pH
range of 7.5–8.5.

2.3.1.2 Temperature
Temperature typically has a significant effect on nitrifiers and their nitrification
efficiency (Ducey et al., 2010). According to earlier studies, the optimal temperature
range for nitrifiers was observed to be between 15 and 30 oC (Chandra and Sathasivan,
2011). Colliver and Stephenson (2000) reported that most nitrifiers will grow
optimally in a temperature range of 25–30oC. A study conducted by Huang et al.
(2010b) showed that the optimal temperature regime that supported Nitrobacter
growth was between 24 and 25 oC, whereas higher range of 29–30 oC favoured
Nitrospira. The activity of the AOB is generally faster than that of NOB because of
their different activation energy, which is between 72 and 60 kJ mol-1 for AOB,
whereas it is from 43 to 47 kJ mol-1 for NOB (Hulle, 2005). In a reactor treating
synthetic wastewater, Kim et al. (2008) found that when the temperature increased
from 20 to 30 oC, oxidation of ammonia proceeded from 0.253 to 1.33 g N/g VSS d
(5.3-fold increase) whereas nitrite oxidation was just by a multiple of 2.6 times (0.45–
1.18 g N/g VSS d), thereby indicating a high correlation of temperature with ammonia

13

oxidation. These findings therefore indicate that the influence of environmental
conditions on different nitrifying populations (AOB and NOB) varies.

Recent reports on activity of nitrifiers at very low temperature and DO level indicate
that nitrifiers are capable of adapting to extreme conditions such as low temperature.
Zhang et al. (2011a) observed that Nitrosospira spp. thrives at lower temperatures (4–
10 oC) compared to other nitrosifyer bacteria. Ducey et al. (2010) reported a high
nitrification rate of 11.2 mg N/g MLVSS/h at low temperatures (5 oC) by an
acclimatized nitrifying community, which is far above the optimum 1.71–2.0 mg NO3N/gVSS-h reported by Fan et al. (2000) and Kornboonraksa et al. (2009). These
observations show that nitrifiers are capable of adaptation in response to
environmental and operational conditions; however, a sudden shift in environmental
factors would certainly affect the nitrifiers’ activity. Earlier research efforts also
documented the effect of temperature on the nitrifying populations’ diversity.
Caballero (2011) observed in an activated sludge a higher diversity of AOB during
winter compared to summer. Wang (2013) reported significant seasonal changes in
AOB community structures and abundances in a wetland. He noted AOB community
structures were significantly different between winter and summer with winter having
a higher diversity (Wang, 2013). Similarly Miller (2011), observed a higher diversity
of AOB in a pond during winter whereas the AOB amoA gene copy number was higher
during summer.

2.3.2

Plant Operational conditions

2.3.2.1 Dissolved oxygen
A DO concentration of between 3 and 4 mg O2 L-1 has been described as optimum for
AOB and NOB growth (Hulle, 2005). However, Sarioglua et al. (2009) observed a
higher nitrogen removal of about 85–95 % in WWTP treating domestic wastewater
when the DO level was maintained at low level (1.5 mg O2 L-1). Niche-specific
adaptation to DO concentration has been observed within the NOB, with Nitrospira

14

demonstrating a negative correlation to DO concentrations (r = -0.46, P<0.01),
whereas Nitrobacter exhibited a positive correlation (r = 0.38, P<0.01)

(Huang et

al., 2010a). Nitrobacter population was also found to increase in winter (low
temperatures) and high DO levels (Huang et al., 2010b). This shows that nitrifiers can
be highly specialized; exhibiting niche-specific adaptation in response to
environmental and operational conditions. The microbial ecology of nitrifiers reveals
that Nitrospira thrives optimally in an environment with a combination of low nitrite
and oxygen levels, whereas Nitrobacter requires an environment with elevated levels
of nitrite and oxygen. This makes them k- and r-strategists, respectively, based on r–k
selection theory (Bahadoorsingh, 2010). Studies on the relationship between NOB
(Nitrospira

and

Nitrobacter)

populations

and

their

sensitivity

to

environmental/operating factors that favours good nitrification (under high DO and
limited NH3 conditions) are necessary to understand their effect on plant performance
(Huang et al., 2010b). Liu (2012) noted that NOB exhibited a significant O2 affinity
under prolonged low DO concentrations (0.16–0.37 mg/l) which in turn made them a
better competitor for O2 as their abundance increased comparably to AOB. According
to Liu and Wang (2013), under extended period of low dissolved oxygen
concentrations (≤ 0.5 mg/L) the endogenous decay of both ammonia/nitrite oxidizing
bacteria was retarded. This resulted in increased biomass density which nullified some
low DO impact on nitrification. He also reported near complete nitrification with 0.16–
0.37 mg/l DO range. Under extended low DO period NOB demonstrated significant
increase in O2 affinity which in turn made them a better O2 competitor.

2.3.2.2 Sludge retention time (SRT) and Hydraulic retention time (HRT)
It has been reported that longer SRT could impact the biological activities negatively,
including nitrification rate (Yu et al., 2010). A study conducted by Yu et al. (2010),
observed a negative correlation between SRT and the nitrifier activities, i.e. for both
specific ammonia oxidizing rate (SAOR) and specific nitrate formation rate (SNFR).
The reactor operated at a shorter SRT of 30 days showed a higher SAOR and SNFR
(0.22 kg NH4+-N/kg MLSS/day and 0.13 kg NO3-N/kg MLSS/day, respectively),

15

compared to the system operated for a longer SRT of 90 days (0.12–0.14 kg NH4+N/kg MLSS/day and 0.068–0.042 kg NO3-N/kg MLSS/day, SAOR and SNFR,
respectively). This reflects earlier reports which also indicated a negative correlation
of SRT to SAOR/SNFR in wastewater treatment (Li et al., 2006). Similarly, Huang et
al. (2001) reported that SRT has no significant influence on the biological activity
when the reactor was operated at SRT of less than 40 days. Cicek et al. (2001) reported
that when a pilot-scale bioreactor was operated at an increased SRT up till 30 days,
there was no significant effect on nitrification. The impact of hydraulic retention time
(HRT) on nitrification efficiency of wastewater treatment systems has also been
reported. Li et al. (2013) observed that a decrease in HRT from 30 to 5 h resulted in
an increase in specific ammonium-oxidizing and nitrate-forming rates. Additionally,
the study indicated that the decrease in HRT led to a reduction of AOB population
density, whereas the NOB, especially the fast growing Nitrobacter spp., increased
significantly.

2.3.2.3 Substrate concentration and Food to microorganism (F/M) ratio
Research findings have shown that nitrifiers get inhibited by free ammonia and
unionized nitrous acid (Gil and Choi, 2001; WEF, 2011; Mousavi et al., 2014).
Increased accumulation of NH3 in bio-treatment systems occurs whenever toxicant or
any inhibitory factor disrupts the nitrifiers’ functional ability. This increased NH3-N
level often gets to inhibitive level, which can result in loss of nitrification that can last
for several days to months. Concentration of NH3-N above a threshold of 200 mg/L
has been reported to inhibit nitrification efficiency (Mordorski, 1987; Kim and Kim,
2003). Optimizing the carbon: nitrogen (C: N) ratio is also essential for efficient
nitrogen removal in waste treatment systems. A low C: N ratio favours nitrification,
whereas a higher ratio supports the heterotrophs (Fu et al., 2010). In a study of
membrane-aerated biofilm reactor, nitrification efficiency of 93 % was achieved at C:
N ratio 5; however, at C: N ratio of 6, increased heterotrophic bacteria growth was
observed with resultant inhibition of nitrifiers (Liu et al., 2010b). According to Fu et

16

al. (2010) also, it was observed that AOB and NOB showed negative correlation with
C: N ratio.

The available carbon substrate for the unit mass of microorganism (known as F/M
ratio) can impact nitrification. According to Wu et al. (2014), F/M ratio between 0.2
and 0.4 proved to be optimum for nitrification, whilst the inhibitory effect of higher
F/M ratio on the nitrifiers noted.

2.3.2.4 Inhibitory substances
When toxic substances inhibit the nitrifier population, their cell growth and the
ammonia oxidation are affected. Strong toxicity will cause nitrification to be impaired
due to the disappearance of the nitrifiers (Kim and Kim, 2003). According to Caballero
(2011) there are many compounds that can exert inhibitory effect on nitrification which
include; metals, amines, proteins, tannins, phenols, alcohols, carbamates, benzene and
un-ionized ammonia at certain concentrations. Various authors have reported that
metal toxicants inhibits AOB populations and ammonium oxidation whereas it has
little or no effect on NOB and nitrite oxidation (Hu et al., 2002; Kelly et al., 2004 ;
Hawkins et al., 2008; Zhang et al., 2014). In activated sludge treating wastewater
containing Cr(VI), the AOB were found to be more sensitive than NOB to Cr(VI).
However, AOB recovery was rapid both in activity and quantity compared to NOB. In
another study involving cyanide toxicity, Kim and Kim (2003) observed that the free
cyanide has high toxicity on nitrifiers whereas complex cyanide has comparably low
toxicity effect.

2.3.2.4 Predators
Predators grazing can strongly impaired nitrification in wastewater treatment
processes since the plant’s nitrification efficiency is determined by the nitrifying
bacteria abundance in the system and their specific activity. Lee and Welander (1994)

17

noted significant correlation between predators (protozoa and metazoan) abundance
and nitrification efficiency of a nitrifying plant in their study. They also report that
vigorous grazing of these predators on the bacterial population can hamper biotransformations that are critical for process performance. According to different
studies (Carvalho et al., 2006; Shi et al., 2010; Filali et al., 2012), due to nutrient
availability, AOB are usually found at surface of the flocs and granules in activated
sludge whereas the NOB are located deeper. This can give rise to a lowering of AOB
population abundance which is important for the first rate limiting process of
nitrification.

2.4

ASSESSING NITRIFIERS DIVERSITY AND ABUNDANCE

Only a few bacterial species, were thought to be involved in the process, based on the
laboratory culture techniques, whereas in reality, a great diversity of the organisms
involved are nonculturable. The advent of molecular techniques has brought about a
better understanding of the structure and functions of microbial communities including
nitrifiers in wastewater treatment systems. These, however, still have limitations when
applied in full-scale WWTPs. Summary of these techniques used for detecting
nitrifiers from wastewater ecosystem is presented in Tables 2.1 and 2.2. As shown in
the Tables (2.1 and 2.2), FISH and PCR-DGGE has been extensively used for
nitrifiers’ biodiversity, whilst qPCR and FISH among the most widely used techniques
for their quantification. Some advantages and disadvantages of these commonly used
techniques are highlighted below.

2.4.1

Most probable number (MPN)

The MPN involves samples being incubated in a mineral medium selective for
nitrifiers. This method usually involves bias because the synthetic medium and
laboratory conditions cannot truly reproduce the complex ecological interactions
which apply in the activated sludge environment (Hirooka et al., 2009; Xia et al.,
2010a; Ayanda and Akinsoji, 2011). The cells are sometimes bound within the

18

complex matrix called floc, and some microbes interdepend on others for their
metabolic activities, which can only be achieved in a complex ecosystem such as the
activated sludge system (Ducey et al., 2010). In effect negligible diversity and amount
of the nitrifiers are enumerated using the MPN (Xia et al., 2010a; Ayanda and
Akinsoji, 2011). Li et al. (2006) investigated nitrifiers’ population dynamics using
MPN and FISH, and they observed that FISH correlated more with the specific
nitrification rate analysis than the MPN.

2.4.2

Quinone profiling

Quinone profiling, a chemotaxonomic method, is used for microbial community
structure analysis from environmental samples (Kurisu et al., 2002). This technique is
based on the presence of specific respiratory quinone as an indicator of a particular
bacterial population. However, since some bacterial groups that are phyletically
different share similar quinone groups, this technique is inadequate for analysis beyond
the phylum level (Kurisu et al., 2002). In a study by Li et al. (2006), ubiquinones
belonging to UQ-8 (β-Proteobacteria), UQ-9 (α-Proteobacteria) and UQ-10 (γProteobacteria) were recovered. However, the authors noted the difficulty in
reconciling the NOB with the quinone profiles. The entire analysis based on the
quinone profiling is characterized by assumptions and would require more specific
techniques to complement it. Thus, the species specificity was a limiting factor for this
technique when applying to complex environmental samples.

2.4.3

Fluorescent in situ hybridization (FISH)

Fluorescent in situ hybridization, a widely used molecular method, involves the
binding of fluorescent oligonucleotide probes to ribosomal ribonucleic acid (rRNA)
(Fig. 2.3) (Nielsen, 2009; Junier et al., 2010; Xia et al., 2010b; Yu et al., 2011). This
method can be employed for both identification and quantification of specific bacterial
groups directly from the environment even up to the species level (Li et al., 2006).
However, the major limitations of this technique include the lack of availability of

19

probes, inefficient cell permeability, inadequate or difference in ribosome content
which can lead to low signal intensity, loop and hairpin formation of rRNA structure,
as well as rRNA-protein interactions which hinders hybridization, auto-fluorescence
and non-specific bindings (Nielsen, 2009; Ge et al., 2015).

20

Table 2.1: Summary of techniques that have been employed for biodiversity studies on nitrifiers
Type of reactor

Sample type

Method of analysis*

Lab Scale

Synthetic Wastewater

FISH

Lab Scale

Synthetic Wastewater

Quinone profiling

α, β, and γ Proteobacteria

(Li et al., 2006)

Full-scale

Municipal sewage

FISH

AOB and Nitrobacter sp.

(Yu et al., 2011)

Full-scale

Municipal sewage

PCR-DGGE

Nitrosomonas sp.,

(Yu et al., 2011)

Full-scale

Municipal sewage

RFLP

Nitrosomonas sp.,

(Yu et al., 2011)

Lab Scale

Synthetic Wastewater

FISH

β-Proteobacteria (Nitrobacter)

(Yu et al., 2010)

Lab Scale

Synthetic Wastewater

PCR-DGGE

Lab Scale

Synthetic Wastewater

RFLP

Nitrosomonas sp.; Nitrosospira sp.

(Yu et al., 2010)

Lab Scale

Synthetic Wastewater

FISH

β-Proteobacteria; Nitrobacter sp.

(Zhang et al., 2009b)

Synthetic Wastewater

T-RFLP

Nitrosomonas sp.; Nitrospira sp.;

(Liang et al., 2010)

Lab Scale

Population detected
Nitrospira sp., Nitrosomonas sp.,
Nitrobacter sp.

Nitrosomonas sp.; Nitrosospira
sp.; Nitrospira sp.

Reference
(Li et al., 2006)

(Yu et al., 2010)

Nitrobacter sp.

Full Scale

Industrial wastewater

Microarrays

Nitrosomonas sp.

(Kelly et al., 2005)

Full Scale

Municipal wastewater

Microarrays

Nitrospira sp.

(Siripong et al., 2006)

*FISH: Fluorescent in-situ hybridization, PCR-DGGE: Polymerase chain reaction–denaturing gradient gel electrophoresis; RFLP: Restriction
fragment length polymorphism, T-RFLP: Terminal restriction fragment length polymorphism, MBR: Membrane bioreactor
21

Table 2.2: Summary of techniques that have been employed for quantitative studies on nitrifiers
Type of Reactor

Influent

Method of analysis

Estimated population

Reference

Lab Scale

Synthetic Wastewater

FISH

AOB (% among total bacteria) ≈ 23 – 57%;
Nitrosomonas sp. (% among AOB) ≈ 50 90%

(Li et al., 2006)

Lab Scale

Synthetic Wastewater

MPN

AOB ≈ 107 - 109 l-1;
NOB ≈ 105 - 108 l-1

(Li et al., 2006)

Full-scale

Municipal sewage

FISH

AOB≈ 1.9 - 4.5%;
NOB≈ 0.9 – 2.8%

(Yu et al., 2011)

Pilot Scale

Domestic Wastewater

q-PCR

amoA AOB≈ 1.15 – 4.05%;
Nitrobacter≈0.04-1.17%; Nitrospira≈8.2313.01%; amoA AOA≈0.05-0.09%

(Ozdemir et al., 2011)

Lab Scale

Synthetic Wastewater

MPN

AOB ≈1.5 x 107 - 3.4 x 107 cells g-1 MLSS;
NOB ≈ 2.7 x 104- 1.4 x 107cells g-1 MLSS

(Yu et al., 2010)

Lab Scale

Synthetic Wastewater

q-PCR

AOB ≈108 cells/l

(Liang et al., 2010)

FISH: Fluorescent in-situ hybridization, MPN: Most probable number, q-PCR: Quantitative real-time PCR, MBR: Membrane bioreactor, AOB:
Ammonia oxidizing bacteria, NOB: Nitrite oxidizing bacteria, MLSS: Mixed liquor suspended solids, amoA: Ammonia monooxygenase

22

Unlike the fast-growing microorganisms, the cellular rRNA content of anammox and
β-Proteobacterial ammonia oxidizers do not really reflect the physiological activity of
these organisms, especially during starvation and inhibition periods (Schmid et al.,
2005). Thus, correlation of the nitrifier population to its physiological activity can be
biased (Schmid et al., 2005). Witzig et al. (2002) observed that due to the low foodto-microorganisms conditions in membrane bioreactor with resultant low rRNA
molecules for the organisms, less than half of the population were detectable by FISH
whereas 80 % in activated sludge. However, few researchers have reported a direct
correlation between nitrifier population and specific ammonium and nitrite oxidation
rate using FISH probes (Yu et al., 2011). Yu et al. (2011) in a study using FISH
observed a direct correlation between the nitrifier population and the specific
ammonium and nitrite utilization rate. In spite of all the above-mentioned limitations,
FISH is still considered important as it provides information about the presence,
relative abundance, morphology and spatial distribution of microorganisms in its
natural habitat. Due to these disadvantages, researchers have come up with new ideas
for its improvement, viz catalysed reporter deposition–FISH, microautoradiography
combined with FISH, FISH–confocal scanning laser microscope, and combinatorial
labelling and spectral imaging–FISH (Egli et al., 2003; Daims et al., 2006; Valm et
al., 2012).

23

Fig. 2.3: Diagrammatic description of Fluorescent in situ hybridization (ITRC, 2013)

24

2.4.4

Microarray

Some other less frequently applied techniques for wastewater samples include
microarray and most probable number (MPN). Microarray is a multiplex technique
that harnesses the characteristics of DNA or RNA to bind to their complementary
sequences (Gilbride et al., 2006). Siripong et al. (2006) in a study on WWTPs noted
that the microarray technique was able to confirm the presence of nitrifiers; however,
due to insufficient fluorescence intensity, it failed to differentiate adequately between
matched and mismatched sequence. This indicates a significant shortcoming of this
technique. Kelly et al. (2005) investigated nitrifiers in samples from a wastewater
treatment facility and observed that the microarray technique could detect nitrifiers
directly without any need for complementary PCR amplification. However, they
observed that other methods, especially T-RFLP, were sensitive enough to confirm the
presence of more diversity of nitrifiers (Nitrospira sp. and Nitrobacter sp.) apart from
only Nitrosomonas sp. that microarray could detect (Kelly et al., 2005).

2.4.5

Polymerase chain reaction (PCR) – based techniques

Polymerase chain reaction (PCR) is a fundamental, routinely used non-culture based
technique of analysing activated sludge community structure and function. The 16S
rRNA gene is usually targeted when determining the overall microbial diversity in
activated sludge (Fukushima, 2010), whilst genes such as polyphosphate kinase (ppk);
nitrite reductase (nirK and nirS); ammonia monooxygenase (amoA) and nitrate
reductase (narG) among others target functional level (Fukushima, 2010; Kim et al.,
2011). The bacterial 16S rRNA molecule is about 1.5 kb size. When partially or wholly
sequenced, it has sufficient conserved and variable nucleotide regions with reliable
phylogenetic information (Amann et al., 1995; Clarridge, 2004; Ramdhani, 2012).
Hence, the 16S rRNA targeted primers are usually employed to obtain amplicons from
genomic DNA extracted from activated sludge. Some of the widely used PCR-based
techniques are discussed below.

25

2.4.5.1 Denaturing gradient gel electrophoresis (DGGE)
Denaturing gradient gel electrophoresis, a PCR-based method, is a common method
of choice by researchers and is based on generating a genetic profile or ‘‘fingerprint’’
of the microbial community of complex environmental samples (Li et al., 2006; You
et al., 2009). The species richness of the microbial community being examined is
revealed by the different base pair sequences in the amplicons (Gao and Tao, 2012).
This method has been employed extensively by researchers to evaluate the microbial
community composition of different wastewater treatment samples (Boon et al., 2002;
Xia et al., 2010b; Zhang et al., 2010) or ‘‘shifts’’ in microbial community composition
over time (Zhang et al., 2009a; Wan et al., 2011; Yu et al., 2011). Yu et al. (2011)
using a combination of PCR-DGGE and clone library analysis established
Nitrosomonas spp. as the dominant AOB. This technique has also been used
successfully by researchers to study the shift in the dominance of different species of
nitrifiers (Yu et al., 2011).

The sensitivity of this method is high, and its main advantage is that the individual
DNA bands, or fragments from the gel can be excised and phylogenetically analysed.
However, since the DGGE analysis can only be performed for shorter PCR amplicons
(≤500 bp), the sequences of the bands obtained from a gel correspond to only short
fragments of DNA (200–500 bp), and thus, the phylogenetic relations are less
constantly established using DGGE bands (Sanz and Kochling, 2007; Gao and Tao,
2012). Analysis from DGGE technique can also be influenced adversely by the
following limitations: the difficulty of DNA extraction and PCR amplification,
depending on the nature of the samples, the variations in DNA copy number after PCR,
depending on the abundance of the specific microorganisms and the intensity of the
band obtained on a DGGE gel (Sanz and Kochling, 2007; Gao and Tao, 2012). The
nonspecific amplification of the PCR primers and the presence of duplex molecules of
DNA can also introduce error into the results obtained by this method (Guler, 2006;
Li et al., 2006).

26

2.4.5.2 Terminal restriction fragment length polymorphism (T-RFLP)
Terminal restriction fragment length polymorphism (T-RFLP) is one of the techniques
which are being used by the researchers to monitor the microbial shift based on the
restriction banding pattern. The technique involves cleavage of terminally labelled
PCR-amplified gene by the restriction enzymes (Sanz and Kochling, 2007; Gao and
Tao, 2012). The technique can be employed to investigate the shift in both the spatial
and temporal microbial community composition from a given natural or engineered
ecosystem (Yang et al., 2011). It is a highly sensitive technique and can be used for
semi-quantitative analysis of microbial populations in a particular microbial ecological
system as an alternative to PCR-DGGE (Liu et al., 2010b). The fingerprints from TRFLP are usually inadequate for identification of individual taxonomic units (Yang et
al., 2011). Nonetheless, it is possible to sequence and identify the dominant organisms
via comparison of the fragments generated with a sequence from a public database or
a related clone library (Yang et al., 2011). However, like any other PCR-based
techniques, the biases related to DNA isolation steps and amplification also can affect
the accuracy of this method (Sanz and Kochling, 2007). Liang et al. (2010) used the
T-RFLP technique successfully to investigate the difference in nitrifier population
from two different reactors.

2.4.6

Quantitative real-time PCR (qPCR)

The quantitative real-time PCR (qPCR) is the most commonly used and accepted
technique in the recent years to quantify microbes from natural and engineered
environments. This technique can be used to quantify the particular gene copies of
target organisms from a complex environment using species-specific primers. It is an
efficient and rapid technique regarded as more sensitive than FISH (Haarman and
Knol, 2005; Fukushima, 2010). However, according to Zhang et al. (2009a), the
application of either AOB 16S rDNA or the functional gene amoA for the analysis
usually has their different shortcomings of false positives and false negatives,
respectively. A combination of the two assays is therefore usually a way of overcoming
and compensating for the disadvantages when applied to AOB detection and

27

quantification. Using qPCR, Ozdemir et al. (2011) investigated nitrifiers and found
that the NOB (Nitrospira sp.) population was 5–10 times higher than that of AOB in
the WWTP. Kim et al. (2011) and Cho et al. (2014) in different studies investigated
nitrifying communities of activated sludge and noted that Nitrobacter spp. had higher
population densities compared to Nitrospira spp.

2.4.7

Next generation sequencing approaches

The traditional Sanger/dideoxy sequencing approach to process complex
environmental samples has shown to be grossly inadequate, due to the hundreds or
thousands of important sequences that go unnoticed when employing this method
(Shokralla et al., 2012). Due to thousands of potential DNA templates usually present
in wastewater samples, there is a strong need for a technique that is capable of
simultaneous detection of diverse microbial communities in different DNA templates
(Morozova and Marra, 2008; Shokralla et al., 2012). The Sanger or dideoxy
sequencing method, though useful in its own right, is limited in the quantity of targets
that can be sampled because of the read length limitations, purity requirements and
expense involved (Mardis, 2008). Contrarily, the Next generation sequencing (NGS)
approach offers a speedy, relatively inexpensive alternative with a vastly improved
amount of data production. This allows for the investigation of microbial ecology on
a larger scale and with more detail than was possible with previously used sequencing
technology (Ju and Zhang, 2015a).

Next generation sequencing offers the advantage of direct sequencing from
environmental samples without a prior cloning step in a bacterial host as in the
traditional Sanger approach. Undoubtedly, NGS has revolutionized environmental
metagenomic research, with stiff competition between manufacturers for ever
improving platforms and technologies allowing for a variety of NGS options at an ever
decreasing cost. The 454/Roche FLX system and Illumina/Solexa Genome Analyzer
NGS platforms have been widely used in deciphering the community structure of

28

activated sludge (Ju et al., 2014; Wang et al., 2014; Yang et al., 2014; Ju and Zhang,
2015a; Keshri et al., 2015).

2.4.7.1 The 454/Roche FLX system
This employs an approach termed as pyrosequencing and it is one of the most widely
used NGS for wastewater study. Pyrosequencing is a real-time DNA sequencing
technique that monitors DNA synthesis through a series of linked enzymatic processes
(Fig. 2.4) (Ronaghi, 2001; Shokralla et al., 2012). Unlike other alternatives, it does not
require cloning, gel electrophoresis, size separation, labelled oligonucleotides or
labelled primers (Ju and Zhang, 2015a). The technique can be employed for detection,
identifying and typing bacteria (Choi and Liu, 2014; Sekar et al., 2014).

The maiden application of pyrosequencing wastewater was to investigate the plasmid
metagenome and the antimicrobial resistance pattern of the activated sludge (Hu et al.,
2012). Ye et al. (2011) noted that the traditional molecular techniques do not give a
complete profile of the community structure present in the wastewater; however,
pyrosequencing has the potential of a truer estimation and more detail reflection of
such communities. In a study of nitrifying communities in WWTPs, Ye et al. (2011)
identified Nitrosomonas spp., Nitrospira spp., Nitrosospira spp., Nitrosococcus spp.
and Nitrobacter spp. by using pyrosequencing technology. They noted that apart from
Nitrosomonas spp. and Nitrospira spp., other nitrifiers did not have significant
contribution in the nitrification process (Ye et al., 2011). Zhang et al. (2011a) in a
study, observed an incongruity in the results when nitrifying communities in different
wastewater bioreactors were analysed using quantitative PCR and pyrosequencing.
Majority of the nitrifiers identified with high-thoroughput pyrosequencing were
related to Nitrosomonas spp. (Zhang et al., 2011a). The abundance and diversity of
AOB and NOB were equally investigated in tannery sludge samples by Wang et al.
(2014). This technique has also been successfully applied in studying the microbial

29

community shift in different wastewater treatment systems different authors (Zhu et
al., 2013; Choi and Liu, 2014; Hai et al., 2014).

Fig. 2.4: Schematic diagram of pyrosequencing System (Gharizadeh et al., 2001)

2.4.7.2 Illumina/Solexa Genome Analyzer
It is based on "DNA clusters" or "DNA colonies", which involves the amplification of
DNA and primer that have been attached on a flow cell. Each cluster contains
approximately one million copies of the original fragment which is enough to indicate
bases incorporated at signal intensity adequate for detection during sequencing
(Mardis, 2008). The Illumina system adopts the sequencing-by-synthesis (SBS)
technology in which DNA polymerase and the four nucleotides are added at the same
time to the flow-cell channels for incorporation into the oligo-primed cluster fragments

30

(Fig. 2.5) (Mardis, 2008; Liu et al., 2012). This SBS technology uses an exclusive
reversible terminator-based method to detect single base as they are incorporated into
DNA template strands and non-incorporated nucleotides are washed away. The
fluorescently labelled nucleotides images are captured by the camera. The fluorescent
dye cum terminal 3' blocker is chemically removed for the next cycle of incorporation
to begin (Quail et al., 2012). Unlike pyrosequencing, the DNA chains are elongated
one nucleotide at a time and image capturing can be done at a delayed time, giving
room for very large arrays of DNA colonies to be captured by successive images taken
from a single camera (Parmar et al., 2014). Illumina platform is more effective at
sequencing homopolymeric regions than pyrosequencing, however, it yields shorter
sequence reads and the accuracy is still comparable to or superior to that of
pyrosequencing (Varshney et al., 2009; Ju and Zhang, 2015a). Ju et al. (2014)
employed Illumina in investigating the seasonal dynamics of activated sludge over a
period of 4 years. A combination of Illumina and pyrosequencing have been used by
Sorokin et al. (2012) for genomic study of NOB and an entirely novel nitrifier named
Nitrolancetus hollandicus.

31

Fig. 2.5: Schematic diagram of Illumina sample preparation and sequencing (Kircher
et al., 2011)

According to Xia et al. (2010a), knowledge of microbial community structure of
wastewater treatment bioreactors is still insufficient, the emergence of molecular
techniques notwithstanding. Hai et al. (2014) noted that there is still a lack of
knowledge of temporal dynamics of microbial community of activated sludge. In this
study, a combination of Pyrosequencing and Illumina sequencing techniques were
employed to investigate the total bacterial and AOB communities involved in the full
scale municipal nitrifying plant over two different seasons. The wastewater
characteristics and operational parameters were also monitored.

32

2.5

STATISTICAL ANALYSIS AND MODELLING IN WASTEWATER

TREATMENT

Statistical measures such as correlation, covariance and simple regression have been
used in capturing how two data series move together or relate over time (Damodaran,
2011). Many studies have applied simple correlation or cross-correlational approaches
in capturing the relationships or interdependence between the various operational
parameters and plant efficiencies in WWTPs (Kornboonraksa and Lee, 2009; Huang
et al., 2010a; Dong and Reddy, 2012; Wang et al., 2014). However, due to
simultaneous dependence on several factors, relationship between microbial groups in
WWTPs is usually nonlinear (Klemetti, 2010). Hence, modelling the existing complex
relationships in the full-scale WWTPs needs advanced nonlinear modelling tool (Kim
et al., 2011). A robust, nonlinear system known as artificial intelligence (AI) can depict
the existing interactions between WWTP operational parameters as well as their
correlation with the simulation output (Lu et al., 2012; Alambeigi et al., 2015). AI
integrates artificial neural network (ANN), fuzzy inference system (FIS), and adaptive
neuro fuzzy interference system (ANFIS). ANN is capable of modelling nonlinear
systems effectively and have been used widely in engineering (Lu et al., 2012;
Alambeigi et al., 2015; Nasr et al., 2015a). FIS allows a logical data-driven modelling
approach and has the ability to establish qualitative interdependency among variables
(Pramanik and Panda, 2009; Nguyen and Sugeno, 2012). ANFIS is a neuro-fuzzy
system that has the potential to capture the benefits of both ANN and FIS in a single
framework which is capable of handling complex and nonlinear relationships among
several parameters (Azar, 2010; Azar, 2011; Nasr et al., 2015a).

33

2.6

RESEARCH OUTPUT

(a) Journal Articles
1) Awolusi, O. O., Kumari, S. K. S., Bux, F. 2015. Ecophysiology of nitrifying
communities in membrane bioreactors. International Journal of Environmental
Science and Technology 12: 747-762
(b) Book Chapter
1) Gokal, J., Awolusi, O. O., Enitan, A. M., Kumari, S. K. S., and Bux, F. 2015.
Molecular characterization and quantification of microbial communities in wastewater
treatment systems. In: Shukla, P. eds. Microbial biotechnology: an interdisciplinary
approach. Taylor & Francis (In press)

34

CHAPTER THREE: CHARACTERIZATION OF THE
DOMINANT NITRIFERS IN ACTIVATED SLUDGE SYSTEM
USING CONVENTIONAL MOLECULAR METHODS

3.1

INTRODUCTION

Optimum and efficient nitrification hinges on a better understanding of the structure
and dynamics of the nitrifying community structure within the wastewater treatment
systems (Xia et al., 2008; Hu et al., 2012). Nitrification involves two sequential steps
where ammonia (NH3) is oxidized in turn into nitrite (NO2-) and nitrate (NO3-). A
consortium of AOB and AOA are usually involved in the first rate limiting ammoniaoxidizing step in nitrification i.e. oxidation of ammonia to nitrite which is subsequently
oxidized to nitrate by the NOB (Ramond et al., 2015). Activated sludge system is
unique in terms of its microbial community structure which plays an important role in
the stability and efficiency of the plants (Eschenhagen et al., 2003; Zhang et al.,
2012b). The advent of molecular techniques have revealed that only less than 15% of
the microbial community in the activated sludge can be cultured (Wagner et al., 1993).
However, most often than not, the success of the molecular method employed depends
largely on the integrity of the genomic DNA extracted. A representative and accurate
bacterial diversity profiling requires nucleic acid extraction method without bias
(Rajendhran and Gunasekaran, 2008).

Nucleic acids extraction method involves direct or indirect lysis procedures (Bourrain
et al., 1999). The direct lysis procedure involves the disruption of cells within the
environmental sample matrix and subsequent purification of the DNA, whereas
indirect method entails separating the cell from the sample matrix prior to lysis and
nucleic acid extraction (Rajendhran and Gunasekaran, 2008). However, the indirect
approach is usually not efficient as compared to the direct approach (Roh et al., 2006).
It involves an initial cation-exchange resin separation of the cell from the sample
matrix and subsequent centrifugation (Bourrain et al., 1999). Various non-culture

35

based techniques have also been employed in studying the microbial community
structure of the activated sludge. Fluorescent in situ hybridization (FISH), is a quick
and widely used molecular method, which involves the binding of fluorescent
oligonucleotide probes to ribosomal ribonucleic acid (Awolusi et al., 2015). It provides
information about the presence, abundance, morphology and spatial distribution of
microorganisms in its natural habitat. Different researchers have used FISH technique
in understanding the nitrifiers present in wastewater treatment plants (Yu et al., 2010;
Yu et al., 2011; Valm et al., 2012). In this chapter, the aim was to ascertain the most
suitable DNA extraction method for the activated sludge; and characterize the
dominant nitrifers (AOA, AOB and NOB) in the activated sludge system, using
conventional molecular methods including FISH, PCR and phylogenetic analysis.

3.2

MATERIALS AND METHODS

3.2.1

Plant description

The full-scale WWTP selected for this study is situated in the midlands of KwaZuluNatal province, South Africa. The plant receives a discharge of 82880 ± 20832 m3/d
(average dry weather flow), including 90% domestic and 10% industrial wastewaters.
The plant was designed based on the criteria of a modified Johannesburg (JHB)
configuration, which offered anaerobic, anoxic, and aerobic biological processes
(Daims and Wagner, 2010). As shown in Fig. 3.1, the effluent from primary settling
tank is distributed to the pre-anoxic and anaerobic tanks. The pre-anoxic basin is
enriched with return activated sludge from the bottom of a final settler, whilst effluent
from anaerobic tank is discharged into the anoxic unit. An internal recycle is pumped
from the last part of aerobic units to the anoxic zone. The mixed liquor, containing
activated sludge, flows from the aerobic zone to a secondary settler, where it is
separated under a quiescent condition into treated wastewater and return activated
sludge. Wastewater characteristics and operational parameters for the plant are shown
in Table 3.1.

36

3.2.2

Sample collection

Composite sludge samples (from the aeration tank), influent and effluent water
samples were collected fortnightly for a period of 237 days (May - July 2012 and
November 2012 - March 2013). Sterile sampling bottles were used in collecting the
samples and all samples were maintained at 4oC while in transit to the lab.
Temperature, dissolved oxygen (DO) concentrations and pH measurements were done
using a portable YSI meter (YSI 556 Multiprobe System). The plant operational
parameters were obtained from the plant operators.

Fig. 3.1: Schematic diagram of the full-scale biological treatment process under study

37

Table 3.1: Average (winter and summer) wastewater characteristics and operational
parameters of the selected plant as observed during the study period
Phase-1

Phase-2

Parameter
Winter

Summer

Rainfall (mm)

26.0 ± 18.6

116.8 ± 32.0

Temperature

16.5 ± 2.1

22.8 ± 2.7

pH

7.3 ± 0.2

7.2 ± 0.1

DO (mg/l)

0.6 ± 0.3

0.6 ± 0.1

MLSS (mg/l)

6157 ± 783.3

4728 ± 1282.0

Chemical oxygen demand (mg/l)

1156 ± 976.1

684.7 ± 258.9

Ammonia (mg/l)

31.6 ± 6.0

24.4 ± 4.5

Flow Rate (ML/Day)

62.0 ± 2.2

96.8 ± 14.5

HRT (h)

6.3 ± 0.2

4.3 ± 1.0

OLR (kg-COD/m3.d)

4.0 ± 1.1

4.5 ± 1.8

ALR (g-NH4/m3.d)

121 ± 22.0

144 ± 29.0

F/M (g-COD/g-MLSS.d)

0.6 ± 0.1

0.9 ± 0.3

COD removal (%)

97.5 ± 1.3

94.1 ± 2.6

Ammonia Removal (%)

60.0 ± 18.0

83.0 ± 13.0

COD: chemical oxygen demand; HRT: hydraulic retention time; OLR: organic loading
rate; ALR: ammonia loading rate; F/M: food to micro-organisms ratio

38

3.2.3

Florescent in-situ Hybridization (FISH)

FISH analysis was performed for initial, rapid screening and characterization of the
nitrifying community according to the modified protocols (Amann et al., 1995; Fuchs
et al., 2007).

3.2.3.1 Cell fixation and pre-treatment
Sludge sample (1 ml) was centrifuged, then washed with 1X PBS and the resulting
pellet was fixed in a 3:1 (v/v) mixture of paraformaldehyde solution and 1X PBS (PBS:
130 mM sodium chloride, 10mM sodium phosphate buffer [pH 7.2]). This above
mixture was incubated overnight at 4oC and afterwards span down by centrifugation
and the pellet washed with 1X PBS. The fixed pellet was resuspended in equal volumes
of fresh 1X PBS–absolute ethanol mixture; this was stored at -20oC until used for
hybridization. Before the hybridization step, the fixed samples were washed and
resuspended in 1 ml of fresh 1X PBS. The resulting mixture was pre-treated according
to the optimized wattage (8 watts) earlier reported (Ramdhani, 2012), using an
Ultrasonic Liquid Processor (Misonix XL-2000). The floc dispersion was optimized
at the optimum wattage (8 Watts) for 6, 8 and 10 min to ensure the best result. The
mixture was further diluted with 0.5 ml sterile deionized water (Amann et al., 1995;
Fuchs et al., 2007).

3.2.3.2 Oligonucleotide probe selection
The oligonucleotide probes (Table 3.2) targeting the commonly found nitrifying
groups in the activated sludge (Betaproteobacterial AOB, Genus Nitrospira and
Nitrobacter spp.) were used (Bassin et al., 2012; Li et al., 2013; Lienen et al., 2014).
The 5' end of the oligonucleotide probes used were labelled with CAL Fluor Red 590
fluorescence dye (Inqaba Biotechnical Industries (Pty), South Africa).

39

3.2.3.3 Whole cell hybridization
The Teflon-coated slides were washed in alcohol (1% HCl in 70% ethanol). Coplin jar
was filled with 100 ml of diluted poly-L-lysin (0.01%, Sigma-Aldrich, Germany) at
room temperature and the slides were allowed to stand for 5 min in coplin jar
containing poly-L-lysin. Slides were then drained and dried at 60oC for 1 hour. About
ten microliter volume of the pre-treated fix sample was spotted on the Teflon-coated
slide and dried at 46oC for about 10 min. The specimen on the slide was dehydrated
sequentially in 50, 80, and 100% ethanol for 3 min each (Amann, 1995). Fresh
hybridization buffer was prepared by mixing 5 M NaCl, 1 M Tris-HCl (pH 8),
Formamide (Table 3.2) and 10% SDS. One microliter of FISH probe and 9 µl of
hybridization buffer were added onto the spotted well. The slides were then placed into
a hybridization tube (50 ml falcon tube, protected from light) containing filter paper
soaked with hybridization buffer. This was incubated overnight at 46oC. After
hybridization, the slide was placed in hybridization tube containing pre-warmed (at
48oC) wash buffer (1 M Tris/HCl, 10 % SDS, 0.5 M EDTA and 5 M NaCl [Table 3.2]),
and was incubated in hybridization oven for 1 hour at 48oC. The slides were then
washed with sterile deionized water and air-dried. Furthermore, 8 µl volume of 4′-6diamino-2-phenylindole (DAPI) was added to the slide and left for 10 min. The slide
was washed with 1X PBS and allowed to air-dry in the dark. The slides were thereafter
mounted using anti-fading Vectashield solution (Vector Laboratories, Burlingame,
CA).

40

Table 3.2: rRNA – targeted oligonucleotide probes used and their specificity

Probe
name

Target

Sequence (5′ – 3′)

Nso1225

Betaproteobacterial
AOB

CGCCATTGTATTACGT
GTGA

35/700

(Bassin et
al., 2012)

NIT3

Genus Nitrobacter

CCTGTGCTCCATGCTCC
G

40/460

(Lienen et
al., 2014)

Ntspa662

Genus Nitrospira

GGAATTCCGCGCTCCT
CT

35/700

(Li et al.,
2013)

FA1 (%)/NaCl (µl)

Reference

(1) FA = Formamide concentration

3.2.3.4 Image analysis
The hybridized slides were examined using a Zeiss Axio-Lab HB050/AC microscope
(Carl Zeiss, Germany) equipped with a HBO 50 W Hg vapour lamp, with appropriate
filter sets, specific for TAMRA and FAM using ×100 Plan Apochromat Objective.
Images were captured using the Zeiss AxioCam MRC camera and analysis was carried
out using Zeiss Axio vision Release 4.8 imaging software.

3.2.4

Genomic DNA extraction

Genomic DNA extraction forms a critical and important step for almost all molecular
based analysis, as the extracted DNA becomes the precursor upon which the success
of the analysis hinges. Genomic DNA was extracted from sludge samples (aerobic
samples) collected during the winter and summer seasons. To ensure the integrity of
the genomic DNA used in this study, three extraction methods (enzymatic, freeze-thaw
and sonication) based on different lysis treatment, including enzymatic and physical
techniques were optimized in this study.

41

The enzymatic method was carried out using the protocol described by Purkhold et al.
(2000). Activated sludge sample (2 ml) was centrifuged at 5000x g for 5 min and the
pellet was resuspended in 725 µl DNA extraction buffer (Tris-HCl [pH 8; 100 mM],
EDTA [pH 8; 100 mM]. Fifty microliter volume of enzyme mix A (lysozyme [0.0142
mg/ µl]; lipase [0.0223 mg/ µl]; pectinase [0.017 mg/ µl]; β-Glucuronidase [0.011 mg/
µl]) was added to the resuspended pellet above, mixed gently by inversion and then
incubated at 37°C for 30 min. Furthermore, 50 µl of enzyme mix B [Proteinase K (0.01
mg/µl); Protease (0.01 mg/µl); Pronase (0.04 mg/µl)] was added to the same tube in
step above, gently mixed by inversion and then incubated at 37°C for 30 min.
Afterwards, 75 µl volume of 20% SDS was added to the incubated mixture above and
further incubated at 65°C for 2 hrs. The resultant mixture above was incubated again
at 65°C for 20 min after 600 µl of phenol: chloroform: isoamyl alcohol (25:24:1)
mixture was added and then mixed by inversion. The tube above was then vortexed
and centrifuged at 10,000 x g for 10 min at room temperature and the aqueous phase
was transferred into a fresh Eppendorf tube.

With regards to the aqueous phase obtained, 100 μg/ ml of RNase A was added to a
final concentration of 10 μg/ml and incubated at 37°C for 30 min. The sample was
then extracted with 1 volume chlorofom: isoamyl alcohol (24:1), mixed by inversion,
and centrifuged at 10,000x g for 10 min at room temperature. The aqueous phase was
then transferred into a fresh Eppendorf tube. DNA was precipitated by adding 0.6
volume of isopropanol to the tube and incubated at room temperature for 1 hr. The
DNA was collected by centrifugation (10,000 x g at 4°C for 20 min) and the
supernatant discarded. The DNA pellet was washed with 2.5 volume cold 70% ethanol.
The tube was inverted to air-dry pellets for about 10 min and pellet was resuspended
in TE buffer. The quality and quantity of the extracted DNA was ascertained with
NanoDrop ND-1000 spectrophotometer (NanoDrop Technologies, USA). The
extracted genomic DNA was stored at –20oC until further analysis.

42

The freeze–thaw method was done according to modified Briese (2002) protocol. For
this, two millilitre volume of the sludge sample was centrifuged at 7000 rpm for 5
minutes at 4oC. The pellet was washed with 1X PBS twice. The pellet was resuspended
in 750 µl volume of the lysis buffer (plus 0.2% each of PVP and β-Mercaptoethanol)
and incubated at 65oC for two hours. The mixture was then frozen-thawed (5 minutes
in ice-ethanol slurry and 3 minutes in water-bath at 65oC) for 5 times. To this, equal
volume of Tris-saturated Phenol-Chloroform-Isoamyl alcohol (25:24:1) was added,
vortexed and centrifuged for 2 minutes at 12000 rpm (4°C). The supernatant was
transferred to a fresh tube and equal volume of Chloroform was added, vortexed and
centrifuged 2 minutes at 12000 rpm 4°C. The supernatant was transferred into a fresh
tube and 0.6 volume of Isopropyl alcohol was added. Precipitation was carried out at
–20oC for 1 hour. The DNA was pelletized at 12000 rpm (4°C) for 20 minutes. The
pellet was washed (12000 rpm 4°C) with 1 ml cold 70% ethanol and air dried for 15
minutes at room temperature. The air dried DNA was thereafter dissolved in TE buffer
and stored at -20oC until further analysis. The procedure for the second mechanical
lysis method which involved sonication was similar to the freeze-thaw method except
that the freeze thaw step in ice-ethanol slurry/hot water bath was replaced with
sonication using an Ultrasonic Liquid Processor (Misonix XL-2000). The pellet was
sonicated for 15 minutes at maximal intensity according to the optimized method by
Lemarchand et al. (2005), thereafter the DNA purification was carried out as described
above.

3.2.5

Spectrophotometric analysis

A total of six replicates were used in evaluating the quality and quantity of the different
extraction protocols with the aid of NanoDrop ND-1000 Spectrophotometer (Thermo
Scientific, USA) at 260/230 and 260/280 nm spectrophotometric absorbance ratios.
Three genomic DNA extraction protocols that were based on three different lysis
methods viz: enzymatic, freeze-thaw and sonication were optimized in this study. One
microliter volume of genomic DNA sample was used for the analysis and the resulting

43

DNA was diluted to lower concentration (1-10 ng/µl) using molecular grade water for
further analysis.

3.2.6

Polymerase chain reaction

The DNA was amplified using Veriti TM 96-well Thermal Cycler (Applied
Biosystems, USA) and the thermocycling conditions are as shown in Table 3.3. The
PCR was performed in a total reaction volume of 50 μl containing 10 ng of DNA
template. The final concentrations of the different components in the reaction mix were
200 µM of DNTPs, 1.5 mM of MgCl (Taq buffer with initial MgCl concentration of
20 mM), 2.5 U of Taq DNA polymerase (Thermo Scientific, Lithuania) and 0.5 µM of
each primer (Table 3.3). The extracted genomic DNA and PCR amplicons were
subjected to agarose gel electrophoresis with 1% (wt/vol) agarose gel. The
electrophoresis was carried out and optimized at 80 volts for 60 minutes and the gel
was visualized under UV light using Vacutec gel documentation system (Vacutec,
South Africa).

3.2.7

Cloning, sequencing and phylogenetic analysis

The PCR amplicons with the expected size were purified using QIAquick PCR
purification kit (Qiagen, USA) following the manufacturer’s instruction. The cloning
was carried out using the InsTAclone PCR Cloning Kit (Thermo Scientific).
Competent cells were prepared from Escherichia coli (DH5α). During PCR
amplification, the Taq DNA polymerase enzyme adds one 3'-adenine overhang to the
two terminals of the PCR product. This unique structure of the amplicon makes it
suitable for cloning of amplicons with 3'-adenine overhang into the vector cloning
directly. These overhangs at the insertion site also prevent the restoration of circularity
to a vector.

44

Table 3.3: Primers and the optimized amplification conditions
Target

Primer

Initial
Denaturation
o

C

Min

PCR conditions
Cycles

Denaturation
o
C
S

Annealing
o
C
S

Elongation
o
C
S

Final
elongation
o

C

Min

Reference

AOB amoA

amoA-1F/
amoA-2R

95

2

35

94

45

55

45

72

45

72

7

(Jin et al., 2011)

Nitrospira
16S rDNA

NSR1113F/NSR
1264R

94

5

40

94

30

65

30

72

30

72

15

(Dionisi et al., 2002)

Nitrobacter
16S rDNA

FGPS872/FGPS126
9

95

10

35

95

60

50

60

72

60

72

7

(Cebron and Garnier, 2005)

Archaea
16S rDNA

Arc622f/Arc915r

94

5

40

94

60

53

60

72

60

72

5

(Chang et al., 2001)

ArchamoAF/ArchamoAR

95

5

30

94

45

53

60

72

60

72

15

(Francis et al., 2005)

AOA amoA

45

3.2.7.1 Ligation
The purified PCR product was ligated to pTZ57R/T vector according to the
manufacturer’s instruction (Thermo Scientific, InsTAclone PCR Cloning Kit). The
ligation mixture was prepared by adding 3 μl volume of vector pTZ57R/T, 6 μl 5X
ligation buffer, 5 μl purified amplicon or supercoiled pTZ57R DNA as control DNA ,
1 μl T4 DNA ligase and DNase/RNase free water to make up to 30 μl. The mixture
was vortexed briefly and incubated overnight at 4oC for maximum number of
transformants.

3.2.7.1 Competent cell preparation and transformation
LB broth (2 ml) was seeded with a single colony of freshly streaked E. coli DH 5α and
incubated at 37o C and 200 rpm overnight in a shaking incubator. On the day of
transformation, 1.5 ml of pre-warmed (37o C) LB broth was inoculated with 150 μl
volume of E. coli DH 5α overnight culture and incubated at 37o C for 30 minutes in a
shaker. The resulting bacterial cells were centrifuged at 10000 x g for 1 minute and
the cells were resuspended in 300 μl of T-solution and incubated on ice for 5 min. The
cells were then centrifuged for 1 minute at 10000 x g, resuspended in 120 μl of Tsolution and kept on ice for 5 minutes. In a 2 ml Eppendorf tube, 2.5 μl volume of the
prepared ligation mixture (containing the vector DNA) was incubated on ice for 2
minutes, fifty microliter volume of the prepared cells were mixed with the DNA in the
Eppendorf tube and incubated on ice for 5 minutes. This mixture was plated quickly
plated on pre-warmed LB agar containing 5-Bromo-4-chloro-3-indolyl β-Dgalactopyranoside

(X-Gal)/

isopropyl-β-d-thiogalactopyranoside

(IPTG)

and

incubated overnight at 37oC (Sambrook and Russell, 2001).

3.2.7.2 Recombinant clones selection
Identification of the recombinant clones was carried out using the method previously
described by Padmanabhan et al. (2011). This is based on the alpha complementation,

46

where cells containing vector with an insert may be identified using blue/white
selection. In order to carry out the blue/white screening, a vector (pTZ57R/T) having
both ampicillin resistance (ApR) gene and β-galactosidase (lacZ) enzyme which
cleaves lactose into glucose and galactose was used. Recombinant plasmid was
transformed into E. coli and white colonies that grew on LB plates containing
antibiotics (ampicillin), X-Gal, and IPTG were picked for colony PCR amplification.
The E. coli cells without the vector could not grow on the LB-ampicillin agar due to
antibiotic toxicity. The plasmid pTZ57R/T and the DNA having the gene of interest
(amplicon) were both split with the restriction enzyme. White clones were randomly
selected on LB antibiotic agar plates containing X-gal and IPTG stock solutions and
positive clones were confirmed by colony PCR using appropriate primer-sets and
resolved on agarose gel for further confirmation of plasmids containing the targeted
inserts.

3.2.7.3 Recombinant clone analysis using colony PCR
Colony PCR was carried out in order to confirm the positive transformants. The
concentration of each component of the PCR mix was according to Degrange and
Bardin (1995) protocol earlier described except for the template DNA prepared
differently. Single white colony to be verified was picked from the agar plate randomly
using sterile pipette tip and suspended into the PCR mix. Colony PCR was conducted
using the appropriate primer sets as listed in Table 3 and amplification conditions.

3.2.7.4 Sequencing and phylogenetic analysis
The purified colony PCR amplicons were submitted to commercial lab (Inqaba
Biotechnical Industries (Pty), South Africa) for sequencing and analysis. The obtained
sequences were edited using Finch TV software. Clones that were 97% similar were
assembled into single operational taxonomic unit (OUT), with their representative
nucleotide sequences used for further analysis. The sequences obtained were checked
against the National Centre for the Biotechnology Information (NCBI) GenBank

47

database using the Basic Local Alignment Search Tool (BLAST) for their
phylogenetic affiliations. A combination of nucleotide sequences from this study and
those obtained from NCBI database were aligned with CLUSTALX implemented in
BioEdit (Hall, 1999). The aligned sequences were exported into MEGA6 (Tamura et
al., 2013) where matrices of evolutionary distances were computed. Phylogenetic trees
were then constructed and checked by bootstrap analysis (based on 1,000 replicates)
(Tamura et al., 2011).

3.2.8

Nucleotide sequence accession numbers

The GenBank accession numbers for the nucleotide sequences of the clones isolated
in this study are KP337415-KP337452.

3.3

RESULTS

3.3.1

Comparison of DNA extraction methods

Three different extraction methods namely; enzymatic, sonication and freeze-thaw
were compared. The result obtained from samples A, B and C comparing these three
methods are shown below (Table 3.4 and Fig. 3.2). Samples A, B and C were sludge
samples taken on different days. Using the three extraction methods, DNA was
extracted from replicates of each sample A, B and C. The integrity and shearing of
each extracted DNA was examined visibly via electrophoresis on an agarose gel (1%
[w/v]). Genomic DNA with purity within the acceptable range was successfully
extracted with the 3 methods, but with different DNA concentration yields. The
extraction method involving sonication yielded DNA with significant shearing in all
the 3 samples A, B and C (Fig. 3.2). Furthermore, variability was observed in terms of
DNA concentration obtained from the different extraction techniques, with the
enzymatic method yielding highest concentrations (Table 3.4). Variability in terms of
DNA concentration was also observed among replicates of the same sample (Table
3.4).

48

Table 3.4: Comparison of DNA extraction methods based on concentration and purity
Enzymatic method

A260/280

A260/230

A

2.06±0.20

1.69±0.10

B

2.21±0.10

C

2.18±0.10

Samples

Sonication method

Concentration

A260/280

A260/230

799.60±14.70

1.81±0.10

2.20±0.40

1.74±0.10

775.20±15.50

1.83±0.11

1.59±0.02

802.90±37.31

1.81±0.10

(ng/μl)

Freeze-thaw method

Concentration

Concentration

A260/280

A260/230

482.80±19.40

1.87±0.10

2.20±0.50

352.79±19.40

2.52±0.20

403.90±11.30

1.85±0.10

2.31±0.21

433.93±13.10

2.11±0.11

521.00±15.30

1.83±0.11

1.95±0.10

370.00±17.30

(ng/μl)

(ng/μl)

49

Fig. 3.2: Agarose gel depicting genomic DNA isolated from sludge samples. Plates
[A], [B], and [C] depict extracted DNA using enzymatic, sonication and freeze-thaw
treatments respectively. Lanes M = 1 kb DNA ladder; lanes A2 – A4 shows genomic
DNA extracted from samples A, B and C respectively using enzymatic method; lanes
B1– B3 shows genomic DNA from samples A, B and C respectively using sonication;
and lanes C1 – C3 shows extracted DNA from samples A, B and C respectively using
freeze-thaw method.

3.3.2

Detection of nitrifiers using FISH

Preliminary detection and identification of the nitrifiers was carried out using FISH
probes targeting AOB and NOB (Table 3.2).

The Betaproteobacterial AOB,

Nitrospira spp. and Nitrobacter spp. were detected all through the sampling period.
The FISH micrographs of the samples hybridized with CAL Fluor Red 590 positive
with AOB, Nitrospira spp. and Nitrobacter spp. are shown in Fig.3.3.

50

Fig. 3.3: Micrograph of hybridized samples. Nitrifiers on each plate are shown as
follows: A(I) Micrograph of AOB hybridised by Cal Fluor Red 590 labelled AOB
oligonucleotide probe (NSO 1225); A(II) corresponding image showing AOB stained
with DAPI (blue); B(I) Micrograph of Nitrobacter hybridised with Cal Fluor Red 590
labelled NIT3 oligonucleotide probe; B(II) corresponding image showing Nitrobacter
stained with DAPI (blue); C(I) Micrograph of Nitrospira hybridised with Cal Fluor
Red 590 labelled Ntspa 662 oligonucleotide probe C(II) corresponding image showing
Nitrospira stained with DAPI (blue).

3.3.3

Detection of the dominant nitrifiers using PCR

Using primers set amoA1F/amoA2R with the optimized PCR conditions (Table 3.3)
resulted in specific amplicons at the expected base pair length (490 bp) (Fig 3.4). The
primer sets NSR 1113F/NSR 1264R and FGPS872/FGPS1269 targeting the Nitrospira
spp. and Nitrobacter spp. respectively were used to detect the NOB in the plant.

51

Successful amplification of Nitrospira spp. and Nitrobacter spp. were confirmed with
amplicons yielding band size of 151 bp and 497 bp respectively (Fig 3.5). For the
archaea, primer sets targeting the archaea amoA and 16S rDNA primer sets were used
according to the conditions stated in Table 3.3. There was no successful archaea
amplification during this study even after the annealing temperatures was optimized
over a range (50 – 58oC).

Fig. 3.4: Primer specificity: Agarose gel showing PCR products for AOB at 490-bp.
Lane 1 denotes the 100-bp DNA ladder, whilst lanes 2 – 14 indicates resulting bands
from using amoA1F/amoA2R

Fig. 3.5: Primer specificity: Agarose gel showing PCR products for Nitrospira spp. at
151 bp and Nitrobacter spp. at 397-bp. Lane 1 denotes the 100-bp DNA ladder, whilst
lanes 2–7 indicates resulting bands from using NSR 1113F/NSR 1264R and lanes 8–
13 depicting resultant bands from using FGPS872/FGPS1269

52

3.3.4

Cloning and analysis

Successful transformation was confirmed with the growth of white and blue colonies
on IPTG/X-Gal-LB agar plates after overnight incubation (Fig. 3.6). The blue colonies
represent the cells transformed with non-recombinant plasmids, whereas the colonies
formed by recombinant cells appeared white. The PCR amplification from the
recombinant clones (white colonies on IPTG/X-Gal-LB agar plate) yielded amplicons
with expected base pair size on agarose gel after electrophoresis (Fig. 3.7 and 3.8).
These were later sent for sequencing at Inqaba Biotechnical Industries (Pty), South
Africa.

Fig. 3.6: Cloned nitrifiers PCR product on IPTG/X-Gal-LB agar plates. Overnight E.
coli DH5α colonies incubated at 37oC after transformation with pTZ57R/T plasmid
vector. White and blue colonies were observed on LB agar containing IPTG and XGal

53

Fig. 3.7: Agarose gel image of PCR product from colony PCR products of amoA
amplicons (~490 bp) obtained after transformation (Lanes 2 – 8). Lane 1 = 100 bp
ladder. Colony PCR for amoA.

Fig. 3.8: Agarose gel image of PCR product from colony-PCR products of Nitrospira
and Nitrobacter amplicons (~151 bp [Lanes 2 – 4, 6 – 8, 10 – 12, 14] and 397 bp
[Lanes 15; 17 – 19] respectively) obtained after transformation. Lane 1 = 100 bp
ladder.

54

3.3.5

Phylogenetic analysis

The sequences obtained were analysed using the NCBI BLAST programme. The
clones were grouped into the same operational taxonomic unit (OTU) based on 97%
sequence similarity and their representative sequences were employed for further
analysis. The dominant AOB sequences during the study were related to uncultured
ammonia

oxidizing

bacterium,

uncultured

Nitrosomonadaceae

bacterium,

Nitrosomonas sp. and uncultured bacterium (Fig. 3.9). The comparative sequences
analysis for Nitrobacter clones revealed 95 – 97% relatedness to uncultured alpha
proteobacteria, uncultured bacterium, uncultured Nitrobacter sp., and uncultured
Bradyrhizobium sp. (Fig. 3.10). The partial sequences obtained from Nitrospira clones
revealed 98 – 100% similarity to uncultured bacterium, Candidatus Nitrospira
defluvii, uncultured Nitrospira sp. and uncultured Nitrospirae bacterium (Fig. 3.11).
The partial sequences obtained were used in constructing the phylogenetic tree and
also deposited with GenBank to obtain accession numbers (KP337415-KP337452).

55

Fig. 3.9: Phylogenetic tree of the bacterial amoA gene sequences recovered from
municipal activated sludge. A neighbour-joining tree was constructed from the
resulting alignment with MEGA 6, and the bootstrap values were based on 1000
replicates. The scale bar represents 0.02 change per site. The sequence of Bacillus
cereus was used as an out group.

56

Fig. 3.10: Phylogenetic neighbour-joining tree based on partial 16S rRNA genes of
Nitrobacter species. A neighbour-joining tree was constructed from the resulting
alignment with MEGA 6, and the bootstrap values were based on 1000 replicates. The
scale bar represents 0.01 change per site. The sequence of Bacillus cereus was used as
an out group.

57

Fig. 3.11: Phylogenetic tree of Nitrospira species in municipal activated sludge. The
scale bar represents 1% estimated sequence divergence. A neighbour-joining tree was
constructed from the resulting alignment with MEGA 6, and the bootstrap values were
based on 1000 replicates. The scale bar represents 0.01 change per site. The sequence
of Bacillus cereus was used as an out group.

58

3.4

DISCUSSION

The success of molecular analyses of environmental samples is largely dependent on
the purity, yield, and molecular weight of the extracted genomic DNA (Shan et al.,
2008). Isolation of high molecular weight DNA allows the characterization of large
regions of the genomes (Rajendhran and Gunasekaran, 2008). In this study, the
efficiency of the different DNA extraction methods was evaluated since cell lysis is
extremely critical. Although there are different studies that have reported optimal DNA
extraction methods from sludge, however, lysis method with the highest DNA yield
for different sludge samples varies with specific sludge sample (Bourrain et al., 1999).
Due to variation in microbial compositions and floc morphology different activated
sludge samples required specific cell lysis method adapted to them (Rajendhran and
Gunasekaran, 2008). Optimization of the DNA extraction method is necessary in order
to have efficient and representative release of nucleic acids from complex community
such as activated sludge (Bourrain et al., 1999). In this study, the enzymatic method
yielded highest nucleic acid concentration (775.20 – 802.90 ng/µl) followed by
sonication (403.90 – 521.00 ng/µl) and freeze-thaw (352.79 – 433.93 ng/µl). However,
the mechanical cell lysis involving sonication proved to be harsh, with resultant
genomic DNA having severe shearing. Sonication has been reported an effective
technique for dispersing sludge sample aggregates during DNA extraction (Picard et
al., 1992; Lemarchand et al., 2005). However, according to earlier studies, high
genomic DNA shearing could result when employing this treatment, since it is capable
of disrupting the DNA molecules (Lemarchand et al., 2005; McIlroy et al., 2009).
According to Rajendhran and Gunasekaran (2008), when comparing mechanical lysis
procedure, sonication is more vigorous than freeze-thaw method (thermal-shock)
resulting in more DNA degradation as evident in this present study (Fig. 3.2).

The physical integrity of the genomic DNA extracted is very important as excessive
shearing can inhibit the amplification of large gene regions or result in PCR artefacts
(chimeras) (McIlroy et al., 2009). There was little shearing effect observed in genomic
DNA isolated with both freeze-thaw and enzymatic methods (Fig. 3.2), which makes

59

the obtained nucleic acid useful for the downstream analysis. McIlroy et al. (2009)
noted that it was impossible to have a total cell lysis for DNA extraction from activated
sludge without unacceptable shearing of the DNA, hence, a compromise must be made
between total cell lysis and shearing. Both freeze-thaw and enzymatic methods yielded
genomic DNA with good purity that was close to 1.8 at 260/280 nm absorbance ratio
(Table 3.4). As indicated in Table 3.4, the sonication and freeze-thaw extraction
methods yielded DNA with 260/230 absorbance ratio within the range for pure DNA
(sonication: 2.11 - 2.52; Freeze-thaw: 1.95-2.20), however, it was relatively lower for
enzymatic method (1.59 - 1.74). According to the Beer-Lambert law, there is a direct
correlation between absorbance and concentration. Although the nucleic acids absorbs
at many wavelengths, however their peak absorbance of UV light occurs at 260 nm.
The 280 nm absorbance is measured because this is typically where proteins and
phenolic compounds have a strong absorbance. Many organic compounds have strong
absorbance at around 225 nm. In addition to phenol, TRIzol, and chaotropic salts, the
peptide bonds in proteins absorb light between 200 and 230 nm (UCR, 2016;
Thermoscientific, n.d.).

The A260/280 ratio is generally used to determine protein contamination of a nucleic
acid sample. The aromatic proteins have a strong UV absorbance at 280 nm. For pure
DNA, A260/280 ratio should be approximately 1.8±0.1 (Lemarchand et al., 2005;
Singka et al., 2012). A lower ratio indicates the sample is protein contaminated which
affect downstream applications involving the nucleic acid (UCR, 2016;
Thermoscientific, n.d.). The A260/230 ratio indicates the presence of organic
contaminants including phenol, TRIzol, chaotropic salts and other aromatic
compounds. The 260/230 ratio for pure DNA samples is between 2.0 and 2.2 (UCR,
2016; Thermoscientific, n.d.). However, according to earlier study by Lemarchand et
al. (2005), DNA extracted from environmental samples with OD 260/280 range
between 1.46 and 1.79 are pure enough for PCR without any inhibition. The freezethaw method gave genomic DNA of higher purity but lower DNA yield when
compared to the enzymatic method. Ferrera et al. (2010) earlier observed that phenol–
chloroform extraction after enzymatic lysis resulted in better DNA yields and

60

detectable diversity when compared to freeze-thaw method. The reduced
concentration associated with the freeze-thaw procedure when compared to enzymatic
lysis could be due to lower cell wall lysis efficiency achieved with the freeze-thaw
treatment (Lemarchand et al., 2005). Bourrain et al. (1999) also noted a lower DNA
yield resulting from freeze-thaw (thermal shock) procedure when compared to
enzymatic treatment of the sludge sample. Rajendhran and Gunasekaran (2008) noted
freeze-thaw method is usually more efficient for lysing gram-positive bacterial cells.
The quality of the extracted DNA with freeze-thaw method was sufficient for PCR
amplification of 16S rRNA and amoA gene of bacterial nitrifiers without inhibition.
Hence, freeze-thaw method was adopted throughout this study.

FISH was used as a quick screening method for identifying the nitrifiers in the samples.
Nielsen (2009) earlier reported inefficient cell permeability as one of the many limits
of the FISH technique. Ramdhani et al. (2013) reported optimum condition for
dispersal of flocs obtained from nitrifying municipal activated sludge as 8 watts for 8
min. However, in this study when sonication was carried out at 8 watts for 8 min, the
floc dispersion was not effective. Efficient floc dispersion was only recorded when
sonication time was increased from 8 min (at 8 watts) to 10 min. The result indicated
that sonication at 8 watts for 10 min was optimum for this particular sludge sample,
and it further demonstrated the need for FISH pre-treatment optimization for sludge
samples (Ramdhani et al., 2010). The presence of the Betaproteobacterial AOB,
Nitrospira spp. and Nitrobacter spp. (Fig. 3.3) were detected in abundance throughout
the sampling period in the sludge samples using the optimized protocol (Table 3.2).
This result is similar to various studies that have reported successful identification of
nitrifiers in activated sludge using Nso1225 (AOB), NIT3 (Nitrobacter spp.) and
Ntspa662 (Nitrospira spp.) FISH oligonucleotide probes (Egli et al., 2003; Li et al.,
2006; Shi et al., 2010).

The importance of molecular techniques in understanding the microbial community
structure of activated sludge has been documented by different authors (Gao and Tao,

61

2011). However, the need for complementary use of these molecular techniques in
order to obtain a better assessment of microbial diversity has been noted, since they all
have both advantages and pitfalls (Rastogi and Sani, 2011). In this study, the FISH
analysis was complemented by PCR, sequencing and phylogenetic analysis for
identification purpose. All the nitrifier primers used in this study (Table 3.3) produced
positive amplicons from the sludge samples, except the AOA that could not be
successfully amplified using primer set amoAF/Arch-amoAR. Although, some earlier
studies have reported AOA (using the same primer set) to be involved in ammonia
biotransformation in engineered systems (Ozdemir et al., 2011; Hatzenpichler, 2012),
however, this organism was not identified to be involved in nitrification all through
this study. This could suggest that AOA was not important in the nitrification process
of this plant and may not be ubiquitous in all engineered wastewater treatment systems.

The phylogenetic analysis showed that the AOB sequences in this study were related
to uncultured ammonia oxidizing bacterium, uncultured Nitrosomonadaceae
bacterium, Nitrosomonas sp. and amoA gene of the uncultured bacterium (Fig. 3.9).
This finding indicated similarity to previous report in which the dominant AOB in
eight different activated sludge systems were closely related to Nitrosomonas spp.
(Wang et al., 2010). Siripong and Rittmann (2007) likewise reported the dominance
of Nitrosomonas spp. in seven different WWTPs studied. The AOB in this study could
not be identified beyond the genus level and there was no evidence of high species
richness among them based on the results obtained (Fig. 3.9). Wang et al. (2012) also
reported, the phylogenetic analysis of cloned amoA genes that indicated all the
dominant AOB in the WWTP studied to be closely related to Nitrosomonas spp. It has
been reported that Nitrosomonas spp. has a relatively high Ks for ammonia and this
makes them frequently found in environments with moderately high ammonia
concentrations (Wang et al., 2012). An average ALR of 121 ± 22.0 - 144 ± 29.0 gNH4/m3.d recorded in this plant could be one of the reasons for Nitrosomonas spp.
dominance. Another possible reason for the low AOB diversity observed in this
present study could be as a result of the industrial component of the municipal influent
being received in this plant. Wang et al. (2010) earlier reported that WWTPs receiving

62

mixed domestic and industrial influent usually have low AOB diversity. Studies have
also shown that activated sludge systems can possibly select for preponderance of
single bacterial population or highly diverse bacterial populations can exist together
(Rowan et al., 2003; Ding et al., 2011). Ramdhani (2012) reported variations in the
abundance and nitrifying community structures of different South African’s WWTPs.
Identifying the microbes responsible for pollutants biotransformation and removal can
reveal some information about the properties of the activated sludge (CydzikKwiatkowska et al., 2012). The prevailing factors in different wastewater treatment
plants are complex and this usually results in high variability in microbial structure,
which differs from plants to plants (Ahmed et al., 2007; Calderon et al., 2012;
Fukushima et al., 2013).

The Nitrobacter clones isolated in this study showed more affiliation to uncultured
alpha proteobacterium, uncultured bacterium, uncultured Nitrobacter sp. and
uncultured Bradyrhizobium sp. (Fig 3.10) whereas the Nitrospira clones were closely
related to uncultured bacterium, Candidatus Nitrospira defluvii, uncultured Nitrospira
sp. and uncultured Nitrospirae bacterium (Fig 3.11). Nitrospira defluvii was first
isolated in pure culture from activated sludge treating municipal wastewater by Spieck
et al. (2006). Nitrobacter spp. and Nitrospira spp. have been commonly reported in
different WWTP receiving municipal influent by many authors (Ramdhani, 2012;
Ramdhani et al., 2013; Fujitani et al., 2014). Nitrobacter and Nitrospira have been
reported as the key NOB that coexist in different activated sludge systems (Kim and
Kim, 2006; Ramdhani, 2012; Hoang et al., 2014). Other AOB species (Nitrosolobus,
Nitrosovibrio, Nitrosospira and Nitrosococcus) were not identified in this plant. This
indicates that the nitrifiers’ community of the plant was not highly diverse. Various
studies have reported the existence of Nitrosomonas, Nitrosospira and Nitrosococcus
as the AOB in nitrifying wastewater treatment plants (Guler, 2006; Nielsen et al.,
2010; Duan et al., 2013).

63

3.5

CONCLUSIONS

 The study revealed that DNA extraction method involving freeze-thaw yielded DNA
with the best purity and minimal shearing. Sonication method resulted in significant
degradation of the DNA, hence it was not suitable for this sample.
 The phylogenetic analysis of the dominant nitrifying populations in the plant revealed
similarity in species richness over the seasons. Perhaps this is because the PCR-clone
libraries of environmental samples could be limited in resolution; hence there is need
for next generation sequencing which can give a better detail in terms of microbial
diversity in environmental samples over time and space.
 This municipal reactor has its nitrifying community made up of Nitrosomonas spp.
Nitrobacter spp. and Nitrospira spp. This indicates that the species richness among
AOB in the plant was not high. Hence, the community did not exhibit substantial
congeneric homotaxis, which can impart high functional redundancy on them.
 This study revealed that AOA was not part of the dominant nitrifiers in this plant.
Hence, it was not an important player in ammonia biotransformation in this WWTP
and may not be ubiquitous in all nitrifying WWTPs.

3.6

RESEARCH OUTPUTS

a) Conference papers
1. Awolusi O. O., Kumari S.K., Bux F. Investigation of nitrogen converters in municipal
wastewater treatment plant. Water Institute of Southern Africa (Water - The ultimate
constraint) biennial conference, the International Convention Centre, Durban, 15th 19th May 2016.

2. Awolusi O. O., Kumari S.K., Bux F. Characterization and quantification of nitrifying
community in activated sludge system treating municipal wastewater. Paper presented
at Water Institute of Southern Africa (WISA) 2014 (Water Innovations) biennial
conference, Mbombela Stadium, Nelspruit, South Africa (Oral presentation).

64

CHAPTER FOUR: SEASONAL VARIATION IN COMMUNITY
STRUCTURE OF AEROBIC NITRIFYING ACTIVATED
SLUDGE: THE NEXT-GENERATION SEQUENCING
APPROACH

4.1

INTRODUCTION

Understanding the complex microbial community in WWTPs is important in
designing functionally stable and effective treatment systems. The advent of molecular
techniques has revealed the inadequacies of traditional microbiological methods of
identifying and quantifying microbes in wastewater (Xia et al., 2010a). The different
Sanger-sequencing based molecular approaches including; polymerase chain reaction
– denaturing gradient gel electrophoresis (PCR-DGGE), terminal restriction fragment
length polymorphism (T-RFLP), temperature-gradient gel electrophoresis (TGGE)
and cloning have been successfully used in profiling the high microbial diversity
harboured in WWTPs (McMahon et al., 2009; Gomez-Silvan et al., 2010). Fluorescent
in situ hybridization among others have also been used in microbial diversity profiling
of engineered wastewater treatment environments with some degrees of success
(Awolusi et al., 2015). More recently, it has been shown that the traditional Sanger
sequencing is yet, grossly underestimating the communities of the complex
environmental samples due to the hundreds or thousands of important sequences that
go unnoticed when employing this method (Shokralla et al., 2012). A major
shortcoming of this technique is that it requires in vivo amplification of DNA
fragments in bacterial hosts (cloning) prior to sequencing. Cloning is labour-intensive,
tediously long and subject to bacterial host bias (Morozova and Marra, 2008).

Due to the thousands of template DNA usually present in wastewater samples there is
need for technique that is capable of simultaneous reading from different DNA
templates (Shokralla et al., 2012). The dideoxy or Sanger sequencing, due to the
expenses involved, can limit the depth of diversity that could be sampled (Mardis,
2008). Moreover, the diversity of clones being selected for subsequent dideoxy

65

sequencing is highly subjective and limited by human bias. Contrarily, the Next
generation sequencing (NGS) approach offers a speedy, and extensive data production
with the opportunity of investigating the microbial ecology on a larger scale and with
more details (Ju and Zhang, 2015a). Next generation sequencing offers the advantage
of direct sequencing from environmental samples without prior cloning into a bacterial
host before sequencing, as obtained in the traditional Sanger approach. The NGS has
revolutionized the genomic and metagenomic research with different platforms being
commercially available. In this chapter, variation in community structure of the
aerobic nitrifying activated sludge over the winter and summer was evaluated using
the combination of pyrosequencing and Illumina sequencing techniques.

4.2

MATERIALS AND METHODS

4.2.1

Wastewater treatment plant operation

Wastewater characteristics and operational parameters for the selected plant in this
study are shown in Table 3.1.

4.2.2

DNA extraction

Genomic DNA was extracted from sludge samples (aeration basin) taken over the
winter and summer seasons using the freeze-thaw method as described in section 3.2.4.

4.2.3

Seasonal analysis of community structure in the activated sludge

4.2.3.1 Sample preparation and DNA extraction
The total bacterial community diversity was investigated using Illumina Genome
Analyser whilst the diversity of AOB group was assessed using high-throughput
pyrosequencing approach. Samples taken between the 1st and 78th day represented the
winter period (May - July 2012) whilst the samples from 79th through 237th day

66

(November 2012 - March 2013) represented summer. The extracted DNA samples for
the winter months were pooled together in equimolar quantities to make up the winter
template DNA sample, whilst the same was done for the summer months. These
resulted in two separate template DNA samples that used for the Illumina and
pyrosequencing analysis. The detail freeze-thaw DNA extraction protocol is shown in
Section 3.2.4.

4.2.3.2 Sequencing and Analysis
The pooled DNA (winter and summer samples) were subjected to high-throughput
sequencing using the Illumina MiSeq platform at Inqaba Biotechnical Industries (Pty),
South Africa, using the universal bacterial fusion primer sets targeting the
hypervariable V3-V4 region of the 16S rRNA with adapter primers attached to its 3′
end (Wang et al., 2014). The obtained reads were trimmed and filtered where only q30
(i.e. high quality) reads and a minimum length of 50 bp (after trimming) were selected
(Dogan et al., 2014). Using the genomic CLC software, the selected reads were aligned
and this was compared to known 16-18S rRNA gene tag database (E-value cut-off at
0.005) using BLASTn programme (Sekar et al., 2014). Dissimilarity cut-off of 0.03
and 0.20 was used to cluster the cleaned (selected) reads into operational taxonomic
units. Taxonomic classification into domain, phylum, order, class, families and genus
was performed using a set of confidence threshold based on OTU diversity and reads
(OTU abundance) (Keshri et al., 2015). The percentage or relative taxonomic
abundance of individual taxon within the community was computed by comparing the
number of sequences assigned to a specific taxon with the total number of sequences
obtained from the sample. The raw Illumina file (fastq) has been deposited into NCBI
sequence Read Archive.

The amoA locus of the AOB in the activated sludge was amplified using the primer
set: amoA-1F/amoA-2R. The PCR was performed in a total reaction volume of 50 μl
containing 10 ng of DNA template. The final concentrations of the different

67

components in the reaction mix (200 µM of DNTPs, 1.5 mM of MgCl [Taq buffer with
initial MgCl concentration of 20 mM], 2.5 U of Taq DNA polymerase [Thermo
Scientific, Lithuania] and 0.5 µM of each primer) were according to modified
protocols from Degrange and Bardin (1995). The PCR products were purified and endrepaired.

The amoA amplicons generated from the PCR were sent to Inqaba

Biotechnical Industries (Pty), South Africa, where the composition of the amplicon of
amoA targeted locus was then determined by pyrosequencing. The barcodes for
multiplexing were incorporated between the forward primers (amoA-1F) and the 454adpter sequence for pyrosequencing using Roche 454 FLX Titanium sequencing
platform (Roche, USA) (Schloss et al., 2009). After sequencing, the unique tags
obtained were aligned with the 16S rRNA database with the aid of the BLASTN
programme (Sekar et al., 2014). The tag redundancy was eliminated and sequences
were assigned into OTU based on similarities of greater than 90%. With the aid of
MEGA6 software, representative sequences were aligned using the ClustalW
programme. The neighbour-joining method was employed for the phylogenetic
analysis (Tamura et al., 2013). The raw pyrosequencing .sff file has been deposited
into the NCBI sequence Read Archive.

4.2.4

Short-read archive accession numbers

The raw reads for the pyrosequencing and Illumina have been deposited into NCBI
Sequence Read Archive under the accession numbers SRP053412 and SRP058452
respectively.

4.3

RESULTS

4.3.1

The total microbial community diversity as revealed by Illumina

sequencing analysis
The total bacterial community diversity in summer and winter was investigated using
Illumina (Miseq) sequencing platform. Seasonal variation was observed in the species

68

richness of the plant’s microbial community. The summer sample was higher in
diversity compared to the winter samples (Figs. 4.1 – 4.4). In total, 9 and 12, bacterial
phyla apart from the unclassified sequences were identified for the winter and summer
seasons respectively. Verrucomicrobia, Firmicutes, Bacteroidetes, Chloroflexi,
Planctomycetes, Actinobacteria, Proteobacteria and Acidobacteria sequences were
common in both samples. Representatives of Spirochaetes, Fusobacteria and
Fibrobacteres were present in abundance in summer sample (Fig. 4.1). Actinobacteria
(29.4%) was the most abundant during winter, whilst majority of the sequences from
the summer sample were related to Proteobacteria (13.2%). The majority of sequences
from both seasons could not be classified even at the phylum level [50.6% (winter)
and 66.5% (summer)]. Substantial variations in proportions of the phyla (i.e.
composition) were observed over the seasons (Fig. 4.1). During winter, Proteobacteria
(9.5%) was the second predominant category followed by Planctomycetes (2.7%),
Firmicutes (2.5 %), Bacteroidetes (1.8 %), Verrucomicrobia (1.5 %), Chloroflexi (1.3
%), Acidobacteria (0.5 %) and Euryarchaeota (0.3 %). Spirochaetes, Fibrobacteres
and Fusobacteria were not identified during this season. However, in contrast, during
summer Verrucomicrobia (5.6 %) were found to be the second most dominant phyla
followed by Planctomycetes (4.4 %), Actinobacteria (3.4 %), Firmicutes and
Bacteroidetes were both fourth most dominant (2.0 %), followed by Acidobacteria
(1.0 %), Spirochaetes (0.7 %), Fibrobacteres (0.5 %) and Fusobacteria (0.2 %).

The class Actinobacteria accounted for 29.9 % during winter, whilst it was 3.4 % in
summer (Fig. 4.2). Flavobacteria, Deltaproteobacteria, Betaproteobacteria,
Alphaproteobacteria, Acidobacteria, Chloroflexi, Clostridia, Gammaproteobacteria,
Bacteroidetes, and Planctomycetacia were found during both seasons (Fig. 4.2).
Methanobacteria and Bacilli were exclusively found during winter whilst
Sphingobacteria,

Gemmatimonadetes,

Spirochaetes,

Fusobacteria,

Verrucomicrobiae, Fibrobacteres and Chlamydiae where found only during summer
(Fig. 4.12). The sequence reads were classified taxonomically which showed high
diversity at lower taxonomic levels with 20 orders and 26 families identified during
winter whilst it was 27 orders and 35 families during summer (Figs. 4.3 and 4.4). The

69

Mycobacteriaceae, Planctomycetaceae and Verrucomicrobiaceae were the most
dominant families among the sequences classified during the two seasons sampled
(winter and summer).

Fig. 4.1: Taxonomic distribution of different bacterial phylogenetic groups during
summer and winter in the reactor at Phylum level. The percentages of the
phylogenetically classified sequences are plotted on the y-axis.

70

Fig. 4.2: Taxonomic distribution of different bacterial phylogenetic groups during
summer and winter in the reactor at the Class level. The percentages of the
phylogenetically classified sequences are plotted on the y-axis.

71

Fig. 4.3: Taxonomic distribution of different bacterial phylogenetic groups during
summer and winter in the reactor at Order level. The percentages of the
phylogenetically classified sequences are plotted on the y-axis.

72

Fig. 4.4: Taxonomic distribution of different bacterial phylogenetic groups during
summer and winter in the reactor at the Family level. The percentages of the
phylogenetically classified sequences are plotted on the y-axis.

The rank abundance plot which is used in NGS analysis to represents the species
richness (number of species) and evenness (relative abundance of species) (Kim et al.,
2013; Keshri et al., 2015) was constructed with the abundance of the uncultured
sequences during the study (Fig 4.5a and b). During winter, the uncultured bacterium
was the most abundant followed by Methylocella silvestris, uncultured Chloroflexales,
Tetrasphaera australiensis, Mesorhizobium sp., and Hyphomicrobium sp. These
groups accounted for 92 % of the total sequences. The six most abundant groups during
summer were uncultured bacterium, uncultured Betaproteobacteria, Knoellia
subterranean, uncultured planctomycete, Afipia genosp, uncultured verrucomicrobia,
which covered 82 % of total sequences. In total, about 0.04 % of the sequences could
not be classified up to genus level during the winter whilst it was only 0.03 % during
summer. The analysis based on diversity and relative abundance of different species
indicated a strong difference among the bacterial communities at different seasons in
the plant (Fig 4.5a and b). It was observed that the plant harboured diverse microbial

73

communities over the different seasons and only a small microbial community overlap
was observed during the winter and summer. About 30 sequences were found in
common to both seasons whilst there were 33 other sequences that were found in the
winter samples which did not exist in summer and 49 others that were found only
during summer.

Fig. 4.5: Rank abundance plot: (a) Phase 1 (winter); and (b) Phase 2 (summer). The
plots show the taxonomic abundances ordered with the most abundant ranked first and
plotted at the leftmost side and the least abundant ranked last and plotted toward the
right. The y-axis plots the abundances of annotations in each taxonomic group in log
scale

74

4.3.2

Ammonia oxidizing bacteria profiling based on amoA gene using high

throughput pyrosequencing
Ammonia oxidation has been identified as the rate limiting step in nitrification hence,
the diversity of the AOB in this system was examined to understand their role in
nitrification efficiency. The AOB diversity for the different seasons was revealed by
454-pyrosequencing using the amoA-1F and amoA-2R primer sets (with multiplex
barcodes inserted between the forward primers and the 454 adapter sequence). With
the aid of MEGA6 software, representative sequences were aligned using the ClustalW
programme and the neighbour-joining method was employed for the phylogenetic
analysis (Figs. 4.6 – 4.7). A total record of 212 and 1192 effective sequences were
obtained from the winter and summer samples respectively. After comparing them
with the NCBI database, substantial percentages of the read from either sample (72 %
in winter and 78 % in summer samples) returned no hits and could not be assigned to
any phylum. (Fig. 4.8).

The identified AOB populations during study include the uncultured ammonia
oxidizing bacteria, uncultured bacterium and Nitrosomonas oligotropha. Among these
identified AOB populations, the uncultured ammonia oxidizing bacteria was the most
dominant throughout the study with 97% and 95% during summer and winter seasons
respectively, whilst the uncultured bacterium was 2% and 5% during the summer and
winter respectively. The Nitrosomonas oligotropha was about 1% of the AOB
population during the summer season, however, it was not detected during the winter
(Fig. 4.8). The AOB diversity was 6 times higher during summer than winter (Fig. 4.8)
when a higher NH3 removal rate and temperature were recorded (Table 3.1). The AOB
sequences related to uncultured bacterium and uncultured AOB showed increase of
133% and 360% respectively when the season changed from winter to summer (Fig.
4.8).

75

Fig. 4.6: Phylogenetic tree of some selected ammonia oxidizing bacteria OTUs based
on amoA gene locus pyrosequencing reads using BLASTN and MEGAN for samples
collected during summer

76

Fig. 4.7: Phylogenetic tree of some selected ammonia oxidizing bacteria OTUs based
on amoA gene locus pyrosequencing reads using BLASTN and MEGAN for samples
collected during winter

77

Fig. 4.8: (a) AOB diversity as revealed by pyrosequencing during summer, (b) AOB
diversity as revealed by pyrosequencing during winter

4.4

DISCUSSION

The seasonal population dynamics of nitrifying and total bacterial communities of the
full-scale municipal bioreactor was investigated. The physicochemical analysis during
winter and summer revealed significant difference in operating conditions for the
investigated seasons (Table 3.1). Higher organic and ammonia loading rates, solid

78

retention time, MLSS, COD, were noticed during winter (Phase 1), whereas
temperature and influent flow rates during the phase 2 (summer) were higher for the
plant (Table 3.1). According to Cydzik-Kwiatkowska et al. (2012), identifying the
microbes responsible for pollutants biotransformation and removal reveals a lot of
information regarding the properties of the activated sludge. Previous studies by
Keshri et al. (2015) and Imarla et al. ( 2006) showed a high correlation between the
microbial community structure and physicochemical parameters as noted by previous
studies. The importance of the molecular techniques in understanding the microbial
community structure of activated sludge has been documented by different authors
(Gilbride et al., 2006; Gao and Tao, 2011; Rastogi and Sani, 2011). Generally, the
traditional molecular techniques such as ribosomal intergenic spacer analysis (RISA),
terminal restriction fragment length polymorphism (t-RFLP), denaturing gradient gel
electrophoresis (DGGE), 16S rRNA clone libraries and FISH are known to be effective
for microbial community characterization, however, they are inefficient for full
spectrum or in-depth taxa detection in highly complex communities (Xia et al., 2010a;
Rastogi and Sani, 2011; Shokralla et al., 2012). On the other hand, next-generation
sequencing approach (including Illumina and pyrosequencing) provides sufficient
sequencing depth to cover the complex microbial communities (Zhang et al., 2012b;
Keshri et al., 2015).

In this study, the Illumina sequencing technique was employed in profiling the
microbial communities of the activated sludge system treating municipal wastewater
at different seasons. The community structure as revealed by Illumina indicated that
during summer, a season characterized with warmer temperature had more species
richness when compared to the winter. Researchers have shown that temperature has
an influence on microbial community compositions (Cydzik-Kwiatkowska et al.,
2012). On the contrary, earlier findings by Ju et al. (2014) indicated that there was
higher bacterial species richness in the activated sludge studied during winter as
compared to summer. However, geographical comparisons is difficult since
environmental conditions and operating parameters differ substantially across regions.
Activated sludge systems can either select for preponderance of single bacterial

79

population or highly diverse bacterial populations can exist together simultaneously
(Ramdhani, 2012). It was also observed that despite overall higher microbial diversity
obtained during summer; certain microbial populations (Tetrasphaera spp. and
Ruminococcus spp.) had higher abundance during winter when compared to summer.
This was similar to earlier finding by Ju et al. (2014) that reported higher abundance
of Tetrasphaera spp. and Ruminococcus spp. during winter compared to summer.
However in this present study, genus Bifidobacterium had a lower abundance in winter
contrary to earlier observations by Ju et al. (2014). This result indicates that knowledge
of activated sludge metagenomics is still incomplete and that individual plant may
select for their unique microbial community compositions based on the prevailing
operational conditions of the plant (Miura et al., 2007; Ramdhani, 2012; Ramdhani et
al., 2013; Ju and Zhang, 2015b). The plant had significant variation in the influent
wastewater compositions, prevailing operational and environmental parameter (Table
3.1) which correlated with variations in the microbial community structure of the
reactor. This variation in microbial diversity affects the plant’s seasonal nitrification
performance as earlier reported (Rowan et al., 2003; Miura et al., 2007). The highest
percentage ammonia removal efficiency was recorded during summer when the
greatest AOB diversity was found in the reactor (Table 3.1). It indicates that AOB
diversity could be a contributory factor to efficient ammonia removal in activated
sludge. However, the significant variation in the total bacterial community diversity of
the plant had no significant effect on the carbon removal of the plant. The average
COD removal of the plant across the two seasons investigated did not indicate
significant variation (Table 3.1).

Based on the pyrosequencing analysis, the higher AOB diversity was observed in
summer when there was a comparatively higher ammonia removal efficiency (Table
3.1). The Nitrosomonas oligotropha was only detected in the summer sample which
indicate a possible higher diversity during summer compared to the winter period (Fig
4.8). Furthermore, the AOB diversity was 6 times higher during summer than winter
when a higher NH3 removal rate and temperature were recorded. Using
pyrosequencing, Zhang et al. (2015) also observed higher AOB diversity in summer

80

compared to winter when monitoring three different WWTP. Niu et al. (2016) also
reported a significant decrease in bacterial amoA genes copy numbers during winter,
in a water purification plant. In this study, the AOB sequences related to uncultured
bacterium and uncultured AOB showed increase of 133% and 360% respectively when
the season changed from winter to summer. Nitrosomonas oligotropha-like sequence
that were detected from summer samples (1%) were absent in winter samples (Fig 4.8).
Earlier research efforts have documented similar trend in different environment.
Temperature has a major influence on AOB diversity and population structure with
lower species richness correlating to lower temperatures (Urakawa et al., 2008).
Similarly, Ju et al. (2014) observed a higher abundance of Nitrosomonas in activated
sludge during summer. Faulwetter et al. (2013) also reported seasonal impact on AOB
community structure in constructed wetland with higher diversity during summer
compared to winter. A higher diversity of amoA gene was also recorded during
summer in the tidal wetland investigated by Zheng et al. (2013).

Overall, the summer period harboured larger AOB diversity compared to winter as
revealed in this study. A significant proportion of the effective sequences (72 % in
winter and 78 % in summer sample) termed "no hits" could not be successfully
classified into any known bacterial 16S rRNA sequences since they showed no
similarity to the available sequences in NCBI database. This suggests yet unidentified
populations and vast unexploited AOB diversity. Yang et al. (2011) reported that
unassigned or unclassified bacteria usually consists higher proportion in activated
sludge compared to other environments such as soil, because activated sludge have a
more complex microbial communities. Shi et al. (2013) also reported the occurrence
of unclassified bacteria sequences in chlorination and clear water tanks. They noted
that these unclassified OTUs from the different samples were closely clustered in the
phylogenetic tree. There is need for more study in order to identify these ecologically
significant diversity of novel AOB species which makes up the complex activated
sludge communities.

81

4.5

CONCLUSIONS

 Pyrosequencing reveals higher diversity of AOB in the reactor during summer that was
characterized by higher temperature. Furthermore, N. oligotropha was only identified
during summer. This indicates that higher temperature elicited increased AOB
diversity.
 The AOB diversity was 6 times higher during summer than winter when a higher NH3
removal rate and temperature were recorded. The AOB sequences related to uncultured
bacterium and uncultured AOB showed increase of 133% and 360% respectively when
the season changed from winter to summer. This suggests that higher AOB diversity
resulted in increased nitrification in activated sludge.
 Despite the high variability in seasonal diversity of total bacteria in the plant, the
carbon removal efficiency of the plant was not affected as it remains stable across the
two seasons.
 Our finding suggests that vast diversity of novel, ecologically significant AOB species,
which remain unexploited still inhabit the complex activated sludge communities
 Future research should target characterization of the nitrifying populations in
wastewater as pyrosequencing revealed a large percentage of the microbial community
that did not match any of the know sequences on the existing database.

4.6

RESEARCH OUTPUT

1) Awolusi O. O., Kumari S.K., Bux F. Investigation of nitrogen converters in municipal
wastewater treatment plant. Water Institute of Southern Africa (Water - The ultimate
constraint) biennial conference, the International Convention Centre, Durban, 15th 19th May 2016 (Oral presentation).

2) Awolusi O. O., Kumari S.K., Bux F. 2014. Characterization and quantification of
nitrifying community in activated sludge system treating municipal wastewater. Paper
presented at Water Institute of Southern Africa (WISA) 2014 (Water Innovations)
biennial conference, Mbombela Stadium, Nelspruit, South Africa (Oral presentation).

82

CHAPTER FIVE: IMPACT OF ENVIRONMENTAL AND
OPERATIONAL PARAMETERS ON NITRIFYING
COMMUNITY AND PLANT PERFORMANCE

5.1

INTRODUCTION

The activated sludge has been largely successful in treating municipal wastewater;
however, it is sensitive to operational or environmental variations, as well as toxic
loading (Kim et al., 2011). There are a number of physiochemical and operational
factors that affect the success of nitrification in WWTPs. It has been reported that
factors such as high ammonia concentration and low dissolved oxygen (DO) level can
result in the disruption of the equilibrium between the two nitrification steps, resulting
in significant reduction in the activities of nitrite oxidizers which can lead to toxic
nitrite build-up and a subsequent failure of nitrification process (Mbakwe et al., 2013).
The nitrifying populations are also sensitive to variability in pH, temperature,
alkalinity, NH3–N and NO2–concentrations, the presence of inhibitory or toxic
substances which often lead to failure of the system (Kim et al., 2011). Nitrification
could also be impacted by influent variability, organic loading, Sludge retention time
(SRT) and Food/microorganism ratio (F/M ratio). A balance between the two linked
ammonia and nitrite oxidation steps is required for nitrification to proceed efficiently.

Nitrification efficiency of a WWTP can be determined by directly monitoring the
nitrogen species biotransformation (plant’s) in the wastewater treatment plants. Also
the biomass from the WWTP can be used in laboratory batch experiments to estimate
the nitrification capacity of activated sludge in the full-scale plant (Yu et al., 2011).
Generally, this laboratory batch estimation is done in terms of the specific ammonia
oxidizing rate (SAOR) and specific nitrite formation rate (SNFR) (Yu et al., 2011; Li
et al., 2013). SAOR and SNFR are usually estimated from the rates of decrease in
NH4+–N concentration and increase in NO3−–N concentration over time. These have

83

been used in determining the activities of activated sludge biomass in oxidizing
ammonia and nitrite respectively (Yu et al., 2010; Yu et al., 2011; Li et al., 2013).
In a quest for rational design of functionally stable biological wastewater treatment
systems there is need to understand the basic relationships between microbial
community structure, its dynamics and functional stability (Gentile et al., 2007). Also
there is need to study and understand the effects of various environmental factors on
the two bacterial groups and on the overall nitrification in order to know how best to
operate the reactor for maximum nitrification and stability. The aim of this chapter was
to quantify the dominant nitrifying bacterial populations using qPCR and determine
their nitrification performance. The cross-correlational relationship existing between
the nitrifier populations (copy numbers) and the plant’s nitrification performance was
also determined.

5.2

MATERIALS AND METHODS

5.2.1

Wastewater treatment plant operation and samples

The configuration, wastewater characteristics and operational parameters for the plant
under investigation are shown in Table 3.1. The detailed sampling procedure for this
study is also shown in section 3.2.2.

5.2.2

Process monitoring and chemical analysis

The collected samples were filtered with MN 85/90 filter papers (Macherey – Nagel,
Germany) and the supernatant were analysed for the nitrogen species (NH4+ −N, NO2−N, NO3- −N) using Thermo Scientific™ Gallery™ Automated Photometric Analyser
(Vantaa, Finland) (Appendix 1). Samples for chemical oxygen demand (COD)
measurement were first digested according to standard method 5220D (APHA, 1998)
– closed reflux colorimetric method – in the microwave digester (Milestone Start D,
Sorisole, Italy) at 150oC for 1 h in COD vials containing the digestion solution
(Appendix 2). The COD concentration in the resulting digest was measured using

84

Gallery™ Automated Photometric Analyser. Temperature, dissolved oxygen (DO)
concentrations and pH measurements were done on-site using a portable YSI meter
(YSI 556 Multiprobe System). The mixed liquor suspended solids (MLSS) was also
measured using standard methods (APHA, 1998).

5.2.3

Calculating nitrification rate of the wastewater treatment plant

Nitrification rates in the plant were calculated based on the parameters monitored in
the plant and the information supplied by the plant operators (Surmacz-Górska, 2000;
Ramdhani et al., 2013) in this study. The nitrification rate was calculated according to
the equation below:
𝑅𝑛𝑖𝑡𝑟𝑖𝑓𝑖𝑐𝑎𝑡𝑖𝑜𝑛 =

𝑄𝑖𝑛[𝑁𝐻4+ – 𝑁]𝑖𝑛 – [𝑁𝐻4+ – 𝑁]𝑜𝑢𝑡 )
𝑉𝑟𝑒𝑎𝑐𝑡𝑜𝑟𝑠 [𝑀𝐿𝑆𝑆]𝑟𝑒𝑎𝑐𝑡𝑜𝑟𝑠

Where:
𝑅𝑛𝑖𝑡𝑟𝑖𝑓𝑖𝑐𝑎𝑡𝑖𝑜𝑛 = rate of plant’s nitrification
𝑄𝑖𝑛 = influent flowrate (L3/ T)
[𝑀𝐿𝑆𝑆]𝑟𝑒𝑎𝑐𝑡𝑜𝑟𝑠 = Mixed liquor suspended solid of the reactor (M/L3) and
𝑉𝑟𝑒𝑎𝑐𝑡𝑜𝑟𝑠 = reactor working volume (L3).

5.2.4

Batch experiment for specific nitrification rate determination

Specific nitrification rate which includes specific ammonium oxidization rate (SAOR)
and specific nitrate formation rate (SNFR) were measured on sampling days in the
laboratory according to the method previously described (Zhang et al., 2009b). Batch
experiments were performed to evaluate the variations of nitrification activities of
activated sludge (AOB, and NOB) in the bioreactor. Sludge sample (100 ml) from the
aerobic tank was centrifuged at 8,000 rpm for 10 min and then washed with buffer
medium to remove the background concentrations of nitrogen. The biomass (pellet)

85

was then transferred to a 250-ml Erlenmeyer flask and suspended with 100 ml of
mineral medium. This was performed in a shaking incubator at 30oC. Samples were
taken at an interval of 30 min to analyse the concentrations of NH4+-N and NO2--N.
The SAOR and SNFR was determined by monitoring the decreased rate of NH4+-N
concentration and NO2--N concentration versus time, respectively.

5.2.5

DNA extraction

Genomic DNA was extracted from sludge samples (aerobic samples) as described in
section 3.2.4. The quality and quantity of the extracted DNA was ascertained with
NanoDrop ND-1000 spectrophotometer (NanoDrop Technologies, USA). The
extracted genomic DNA was stored at –20oC until further use.

5.2.6

Standard curve preparation for quantitative real-time PCR analysis

Individual standard curves were prepared for different species of nitrifiers using
purified 16S rRNA gene fragments (target DNA) obtained from PCR-amplified
Nitrobacter spp. (FGPS872f and FGPS1269r), Nitrospira spp. (NSR1113F and
NSR1264R) and AOB (amoA-1F and amoA-2R) respectively (Lienen et al., 2014).
The concentrations (µg/µl) of the purified DNA (purified 16S rRNA gene fragments)
used as templates for the standard were determined using NanoDrop ND-1000
spectrophotometer (NanoDrop Technologies, USA). This was used in calculating their
copy numbers, which was based on their molecular weight and Avogadro’s number
(Trivedi et al., 2009). The formula used in estimating the copy number is as shown
below:
(Amount in ng x Avogadro′ s number)
𝑁𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑐𝑜𝑝𝑖𝑒𝑠 =
Lenght in bp x 1 x 109 x 650

86

The average weight of a base pair (bp) is 650 Daltons and Avogadro’s number is
6.022×1023. The Ten-fold serial dilutions of the target DNA were prepared from 108
to 102 copy numbers.
5.2.7

Quantitative real-time PCR (qPCR) analysis

The real time PCR quantification was carried out with the primer sets targeting
different species of nitrifiers (Table 5.1) according to the modified method described
by Steinberg and Regan (2009). A Bio-Rad C1000 Touch Thermal Cycler-CFX96
Real-Time System (BIO-RAD, USA) was employed for the qPCR. The qPCR reaction
mixture was made up of 8 μl of SsoFast EvaGreen Supermix (Bio-Rad Laboratories
Pty Ltd, USA), 1 μl of each primer (final concentration of 0.4 μM), 4 μl of template
DNA (final concentration of 1 ng), and molecular grade water to a final volume of 20
μl. A modified Steinberg and Regan (2009) amplification protocol was employed
(Table 5.2). For each experimental set up, appropriate negative controls containing no
genomic DNA were subjected to the same amplification condition. The specificity of
each qPCR assay was confirmed by using both melting curve analysis and agarose gel
electrophoresis.

Table 5.1: Primers used and their specificity
Sequence (5′ → 3′)
Primers

Target

amoA-1F

GGGGTTTCTACTGGTGGT

amoA-2R

CCCCTCKGSAAAGCCTTCTTC

FGPS872

CTAAAACTCAAAGGAATTGA

Reference

Ammonia
(Yu et al., 2010)
Monooxygenase

Nitrobacter
FGPS1269

TTTTTTGAGATTTGCTAG

NSR1113F

CCTGCTTTCAGTTGCTACCG
Nitrospira

NSR1264R

(Ozdemir et al.,
2011)

(Wang et al., 2011)

GTTTGCAGCGCTTTGTACCG

87

Table 5.2: Optimized real-time PCR protocols for quantifying nitrifiers
Quantitative real-time PCR conditions using the primers
Real-time PCR step

AOB

Nitrospira spp.

Nitrobacter spp.

amoA-1F/amoA-2R

NSR1113F/NSR1264R

FGPS872/FGPS1269

1. Initial activation

3:30 min at 95°C

3:30 min at 95°C

3:30 min at 95°C

2. Denaturation

0:30 min at 95°C

0:30 min at 95°C

0:30 min at 95°C

3. Annealing

0:30 min at 54°C

0:30 min at 65°C

0:30 min at 52°C

4. Extension

0:30 min at 72°C

0:30 min at 72°C

0:30 min at 72°C

5. Read fluorescence

Read

Read

Read

6. Go to step 2 for

40 times

40 times

40 times

7. Melt curve

55 to 65oC, increment

55 to 65oC, increment

55 to 65oC, increment

of 0.5oC every 50 s

of 0.5oC every 50 s

of 0.5oC every 50 s

Read

Read

Read

8. Read fluorescence

In each assay, a plot of the threshold cycle (Cq) against the logarithmic starting quantity
value of every 16S rRNA gene fragment (target DNA) was made and the standard
curve with linear range having regression analysis correlation co-efficient (R2) value
that is greater than 0.98 was considered suitable (Kumari et al., 2009; Yapsakli et al.,
2011). In addition, each qPCR assay with standard curve having suitable efficiency
(90 to 110 %), and slope ranging from –3.58 to –3.1 only were considered. In order to
quantify the 16S rRNA gene concentration of each nitrifier in the unknown DNA
sample, the Cq values of each sample was interpolated into the respective standard
curve.

88

5.2.8

Statistical Analysis

GraphPad Prism version 5.00 for Windows (GraphPad Software, San Diego California
USA) was used in carrying out Pearson correlation, one-way analysis of variance and
unpaired t-test. Microsoft Excel 2010 was used in calculating standard deviation.

5.3

RESULTS

5.3.1

Process performance and operational conditions

A full-scale system treating municipal wastewater was monitored for 237 days. The
sampling regime was divided into two: phase 1 (winter) which lasted from the 1st day
up till the 78th day; and phase 2 (summer) which was from 79th to 237th day. The
average precipitation of the study site, influent wastewater characteristics and
operational parameters measured in the plant during the study period is shown in Table
3.1. The temperature recorded in the aeration tanks ranged from 14.2oC to 25.1oC (Fig.
5.1a). The average temperature during summer and winter seasons were 22.8±1.5 and
16.5±2.0 oC respectively. The aeration tanks had fifteen surface aerators for sludge
mixing. Simultaneous breakdown of two to three aerators was frequently observed
during the sampling at the plant. The average DO concentration in the aeration tank
during the summer and winter were 0.60±0.10 and 0.66±0.40 mg/l respectively (Fig.
5.1a).

The influent COD load varied during the sampling period with an overall average of
999.3±694 mg/L. The lowest influent COD (377 mg/l) load was recorded during
summer, whereas the highest COD load of 1340 mg/l was observed during winter (Fig.
5.1b). The plant showed an efficient COD removal rate during the two seasons
(95.44±2.754%). The average mixed liquor suspended solids (MLSS) of 6157±783
mg/l was recorded during winter whereas it was 5070±1172 in summer (Fig. 5.2a).
The SRT of the plant was lower during summer (average of 22 days) as compared to
the winter period (average of 25 days). The pH in the reactor over the entire sampling

89

period (winter and summer seasons) was relatively stable with a mean of 7.3±0.2 pH
units (Table 3.1).

The average influent ammonia concentrations during the first 78th days (winter) was
31.69±6.04 mg/L whilst it was 24.47±4.58 mg/l during the summer. The effluent
NH4+–N concentrations were 3.40 and 13.24 mg/l summer and winter respectively (Fig
5.2b). The influent and effluent nitrite concentrations were always lower than 1 mg/l
during winter and summer periods. The nitrogen removal performance of the plant in
terms of ammonia is shown in Fig 5.2. There was a significant variation in ammonia
removal efficiency across the two seasons. The average ammonia removal during
winter was 60.0±18.0% whereas it was 83.0±13.5% during summer and this was found
to correlate with temperature (r = 0.7671; P = 0.0008). The ammonia removal also
demonstrated significant correlation with the AOB population (copies/l) (r = 0.55; P
=0.03).

90

Temperature

DO

A

30

1.5
Winter

Summer

1.0

DO (mg/l)

Temperature (oC)

25

20

0.5
15

7
23

1
21

3
19

9
17

9
16

6

1

13

12

10

5

90

78

64

43

29

15

0.0

1

10
Days

B

Influent

4000

Effluent

1500

Summer

Winter

1000

2000

500

Effluent COD (mg/l)

Influent COD (mg/l)

3000

1000

7
23

1
21

3
19

9
17

9
16

6
13

1
12

5
10

90

78

64

43

29

15

0

1

0
Days

Fig. 5.1: (a) Temperature variation in the reactor during the study and dissolved
oxygen concentration within the reactor during the study (b) Wastewater quality
indicating COD concentrations in the influent and effluent

91

A

10000

Winter

MLSS (mg/l)

8000

Summer

6000

4000

2000

7
23

1

3

21

9

19

17

9
16

6

1

13

5

12

10

90

78

64

43

29

15

1

0
Days

Nitrite (Influent)

Ammonia (Influent)

Nitrite (Effluent)

Ammonia (Effluent)

Ammonia Removal (%)

50

100
Summer

23
7

21
1

19
3

17
9

16
9

13
6

0

12
1

0

10
5

20

90

10

78

40

64

20

43

60

29

30

15

80

1

Nitrogen Species (mg/l)

Winter
40

Ammonia removal (%)

B

Nitrate (Influent)
Nitrate (Effluent)

Days

Fig. 5.2: (a) Variation in mixed liquor suspended solid concentration during the study.
(b) Measured nitrogen species concentrations of the plant during the study and
ammonia removal efficiency

92

5.3.2

Nitrification rate

In this study, the plant’s highest nitrification rate was observed during the summer
with an average of 0.085±0.020 g N-NH4+ g MLSS-1 d-1; whereas the lowest average
rate of 0.063±0.054 g N-NH4+ g MLSS-1 d-1 was recorded during winter (Fig. 5.3).
Nitrification rate of the plant ranged from 0.022 to 0.071 g N-NH4+ g MLSS-1 d-1 during
winter whilst it was between 0.035 and 0.138 g N-NH4+ g MLSS-1 d-1 during summer.
The percentage ammonia removal (Fig. 5.2) and the calculated nitrification rate of the
plant (Fig. 5.3) showed a significant correlation (r = 0.74; P = 0.003). The nitrification
rates of the plant during the period investigated is shown in Fig 5.3. At the peak of
winter, when the lowest temperature (Fig. 5.1) of 14oC was recorded on day 64,
nitrification rate was 0.022 N-NH4+ g MLSS-1 d-1 (Fig. 3) which was the lowest
recorded during the study.

Nitrifiaction Rate (g N-NH4+ g MLSS-1 d-1)

Summer

Winter

0.15

0.10

0.05

7
23

1
21

3
19

9
17

9
16

6
13

1
12

5
10

90

78

64

43

29

15

1

0.00
Days

Fig. 5.3: The nitrification rates measured in the aeration tanks during the period
investigated

93

5.3.3

Specific nitrification rate determination by batch experiment

The specific nitrification rate of the biomass in terms of specific ammonium
oxidization rate (SAOR) and specific nitrate formation rate (SNFR) were determined
in a laboratory batch experiment (Fig. 5.4). The SAOR obtained ranged between 0.010
and 0.148 g N g-1 MLSS d-1 whilst SNFR was from 0.1700 to 0.6310 g N g-1 MLSS d1

. The highest values of both SAOR and SNFR recorded during the batch experiment

were 0.1488 and 0.6310 g N g-1 MLSS d-1 respectively. These values were obtained
from the biomass taken during summer period (day 88). The estimated SNFR from the
batch experiment was higher than the SAOR all through the experiment. A significant
correlation was observed between the plant’s nitrification rate and SAOR (r = 0.65; P
= 0.04). The SNFR (r = 0.70; P = 0.02) also had a significant correlation with the
plant’s nitrification rate.

SNFR/g/day

SAOR/g/day
0.8

Specific nitrification rate
(g g-1 SS d-1)

Winter

Summer

0.6

0.4

0.2

14
6

13
2

12
2

88

78

71

60

47

30

14

1

0.0
Days

Fig. 5.4: Time-course profiles of the specific ammonium oxidizing rate (SAOR) and
specific nitrate forming rate (SNFR) of the plant

94

5.3.4

Quantification of AOB and NOB

Parameters for the qPCR standard curve, obtained after optimization is shown in Table
5.3 below. The qPCR efficiencies were between 90 and 110 % and the standard curves
were linear over six order of magnitude (R2>0.99) (Fig. 5.5). The AOB population
abundance was quantified using the primer set targeting the amoA (ammonia
monooxygenase) gene locus whereas Nitrospira and Nitrobacter 16S rDNA were
targeted for the NOB (Table 5.1). The AOB abundance was within the range of 1.6 x
107 – 1.7 x 109 copies/l. The Nitrospira and Nitrobacter spp. were found to be 2.4 x
108 – 3.8 x 109 copies/l and 9.3 x 109 – 1.4 x 1011 copies/l respectively. The Nitrobacter
spp. abundance was highest during the study, having about 2 orders of magnitude
above the AOB throughout the study. The Nitrobacter spp. was the dominant NOB
throughout this study. The changes in AOB, Nitrospira spp. and Nitrobacter spp.
abundance across the study period is shown in Fig. 5.6 below. A significant correlation
was found between the AOB (amoA gene) copy numbers and temperature in the
reactors (α= 0.05; P=0.0498). The lowest AOB abundance was recorded during the
winter, whereas there was no correlation observed between the NOB and temperature.
The NOB population remained almost stable with slight shifts throughout the sampling
period (Fig. 5.6).

Table 5.3: Description of qPCR standard curves parameters optimized for the analysis
during this study
Target
Parameter
AOB

Nitrobacter spp.

Nitrospira spp.

Efficiency

102.5±2.1

92.75±1.63

107.3±1.9

Slope

-3.3±0.05

-3.5±0.05

-3.2±0.04

R2 of Slope

0.998±0.001

0.99±0.01

0.998 ± 0.04

Intercept

39.8±2.2

35.0±0.59

37.2±0.14

95

Fig. 5.5: Real-time PCR data for the purified DNA (Nitrospira) used in generating
standard curve indicating linearity over six order of magnitude (R2>0.99) (a) The
qPCR amplification curve (b) Standard curve.

96

AOB

Nitrobacter spp.

100

Ammonia Removal (%)

Nitrospira spp.

1.010 12

80

Summer

Winter

Copies/l

1.010 11
60
1.010 10
40
1.0

10 09
20

1.010 08

1.010 07
7
23

1
21

3
19

9
17

9
16

6
13

1
12

5
10

90

78

64

43

29

15

1

0
Days

Fig. 5.6: qPCR temporal changes in AOB, Nitrospira spp. and Nitrobacter spp. during
this study and ammonia removal rate of the plant

5.4

DISCUSSION

Seasonal temperature variation has been implicated as one of the environmental factors
affecting nitrification rates in wastewater treatment facilities (Kim, 2013; Arévalo et
al., 2014). In this study, a significant seasonal variations in temperature (α= 0.05; P=<
0.0001) was observed in the reactor. The experimental site had its highest rainfall
during its summer season as observed during the study (Table 3.1). The dilution effect
of the rainfall contributed to lowering the plant’s loading rates during summer (Table
3.1). There was a significant variation in the influent ammonia concentration of the
plant. The average influent ammonia concentration was 24.5±4.6 mg/l during summer
whilst it was 31.7±6.1 mg/l in winter. The highest NH3 concentration in the effluent
(17.4 mg/l) was observed during the winter period when the temperature was 16.0oC
(Fig 5.2). The lowest ammonia removal of 12.1% and AOB abundance (1.6 x 108 ±

97

Ammonia removal (%)

1.010 13

1.3 x 107 copies/l) were observed when the lowest temperature (14.2oC) was recorded
(Figs. 5.2 and 5.6). Similarly, Kim et al. (2008) earlier noted a significant correlation
between temperature and ammonia oxidation. In this study, a reduction in the average
NH3 removal efficiency of the plant from 83.0±13.0% during summer (day 1 – 78) to
60.0±18% during winter (day 79 – 237) was observed. This was also found to correlate
significantly with seasonal temperature fluctuation (α= 0.05; P=0.0008). However,
neither temperature nor NOB population density had correlation with nitrite oxidation
rate of the plant. The non-correlational relationship observed between NOB and the
plant’s operational parameters could be because of the cross-correlation approach that
was employed. It has been noted that several parameters interact simultaneously to
influence the biological process under the uncontrolled environment which prevails in
the full-scale WWTP (Kim et al., 2011). Hence, there is need for an advanced
nonlinear modelling tool in order to be able to determine some of the relationships that
exists in the WWTP.

The highest percentage ammonia-nitrogen removal (83 ± 13%) and nitrification rate
(0.138 N-NH4+ g MLSS-1 d-1) were recorded at the plant during summer. The SAOR
was found to be lower than the SNFR throughout the study period with the average
values of 0.07036 and 0.4368 g N g-1 MLSS d-1 respectively. This is in accordance
with earlier findings in an aerobic batch experiment, where a lower SAOR was
obtained in comparison to SNFR (Fujita et al., 2010). Furthermore, it was observed
that the SAOR and SNFR obtained had no proportional relationship with ammonia and
nitrite-oxidation measured in their experiment (Fujita et al., 2010). However, in the
current study, both SAOR and SNFR obtained showed significant correlation with the
plant’s nitrification rate. Moreover, the specific nitrification (SNFR and SAOR) results
obtained in this study reflects the population densities (higher NOB copy numbers
compared to AOB) of the nitrifiers obtained using qPCR. This demonstrates that
specific nitrification rate determined in the laboratory batch experiment, can serve as
an indicator of the plant’s nitrifying community and performance. Yu et al. (2011)
reported similar finding in which the SAOR and SNFR obtained were related to the
AOB: NOB ratio in a batch experiment.

98

The quantitative PCR results revealed the constant dominance of Nitrobacter spp.
among the nitrifier’s community and the NOB was clearly more abundant than AOB
throughout the study. Due to the limiting oxygen levels observed (Table 5.3), there
was a possibility of nitrite-loop and hence an increased NOB population. The average
copy number of AOB to NOB ratio varied from 0.11 (summer) to 0.02 (winter) during
the period investigated (Fig. 5.6), which was lower than the theoretical ratio of 2.0
reported for good nitrification (Winkler et al., 2012). However, low AOB/NOB ratios
of 0.2 and 0.3 was recorded by Winkler et al. (2015) in an investigation of a lab-scale
and pilot-scale aerobic granular sludge. It was observed that an increase in temperature
and/or a decrease in DO level led to an elevated NOB/AOB ratio (Winkler et al., 2015).
Seasonal temperature was observed to have positive correlation with the AOB gene
copy number (r = 0.5; P = 0.05) whereas NOB was not affected by the temperature
shifts (Fig. 5.6). This result is consistent with earlier findings, which revealed that
AOB abundance had correlation with the wastewater effluent quality; with AOB
population decrease resulting in nitrification rate reduction (LaPara and Ghosh, 2006;
Zhang et al., 2009a).

Under low DO level, denitrifiers can carry out incomplete nitrate reduction which can
serve as additional nitrite source for NOB and partially uncouple their growth from
AOB, thereby resulting in their elevated population density (Winkler et al., 2012). Liu
(2012) noted that NOB exhibited a significant O2 affinity under prolonged low DO
concentrations (0.16 - 0.37 mg/l) which in turn made them a better competitor for O2
as their abundance increased comparably to AOB. Another possible reason for the
higher population load of NOB observed in this study could be due to the fact that
under extended period of low dissolved oxygen concentrations (<= 0.5 mg/l) the
endogenous decay of both ammonia/nitrite oxidizing bacteria would be retarded (Liu
and Wang, 2013). According to Liu and Wang (2013), this reduced endogenous decay
would result in increased biomass density which would nullify some low DO impact
on nitrification. They also reported near complete nitrification with 0.16 - 0.37 mg/l
DO range. Furthermore, they noted that under extended low DO period, NOB
demonstrated significant increase in O2 affinity which in turn made them a better O2

99

competitor than AOB. However, it is important to note that these results were based
on laboratory experiments, unlike the different scenario in this study, involving a fullscale plant where more than one factor influence each other.

The dominance of Nitrospira (K-strategist) over Nitrobacter (r – Strategist) in
activated sludge has been previously reported (Yapsakli et al., 2011; Ye et al., 2011),
however in this study a contrary observation was noted. The Nitrobacter/Nitrospira
ratio was 5.4 and 10.2 during summer and winter respectively. This could possibly be
explained based on the earlier observations of Nogueira and Melo (2006); and Wagner
et al. (2002) in which irreversible prevalence of Nitrobacter spp. over Nitrospira spp.
in WWTP after a spike in nitrite concentration and even after subsequent reduction in
nitrite concentration was recorded. Nitrobacter usually exhibit inhibitory effect on the
growth of Nitrospira once it dominates. Fukushima et al. (2013) also reported that
Nitrobacter spp., though a weak competitor compared to Nitrospira under low nitrite
concentration, can be selected over Nitrospira spp. in plants with low inorganic carbon
in addition to low nitrite concentration. The plant studied had low AOB population
density which could result in lowered rate of ammonia conversion to nitrite. This could
probably give a selective advantage to Nitrobacter spp. as observed in this study.
Furthermore,

Winkler

et

al.

(2015)

observed

an

unprecedentedly

high

Nitrobacter/Nitrospira ratios in different aerobic reactor. They observed an increase
in the ratio from 1.5 to 3.5 when the temperature increased from 10oC to 30oC.

5.5

CONCLUSIONS

 The seasonal dynamics of nitrifying community in full-scale municipal bioreactor was
investigated and there was a significant difference in the nitrification efficiency of the
plant during the two seasons monitored with a two-fold increase in nitrification
observed during summer compared to winter.
 The ammonia removal efficiency of the plant had a significant linear correlation with
the AOB population density of the plant. However, no significant correlation could be

100

established between NOB and operational parameters, which may be due to the crosscorrelational approach used. Hence, there is need for the application of a nonlinear
modelling approach such as ANFIS, in order to determine the relationship.
 There was a significant correlation between the nitrification rates of the plant and the
batch specific nitrification rate (in terms of SAOR) determined in the laboratory
experiment. Hence, the specific ammonia oxidation rate (SAOR) can be used as
indication of nitrifying population densities and nitrification performance of
wastewater treatment plants.

5.6

RESEARCH OUTPUT

a) Journal Articles
1) Awolusi, O. O., M. Nasr, Kumari, S. K. S., Bux, F. Principal component analysis
for interaction of wastewater characteristics and nitrifiers at a full-scale activated
sludge plant. Environmental Science and Pollution Research (Submitted)

b) Conference Papers
1) Awolusi O. O., Kumari S. K., Bux F. 2015. Seasonal impact on nitrification
potential of activated sludge treating municipal wastewater. Paper presented at 4th
Young Water Professional (South Africa) Biennial Conference and 1st Africa-wide
YWP Conference, CSIR International Convention Centre, Pretoria, South Africa, 16th
– 18th November 2015 (Oral presentation).

2) Awolusi, O. O., Enitan, A. M., Kumari, S. K. S., and Bux, F. 2015. Nitrification
efficiency and community structure of municipal activated sewage sludge. Paper
presented at 17th International Conference on Biotechnology, Bioengineering and
Bioprocess Engineering, Rome, Italy, September 17 - 18, 2015 (Oral presentation).

101

3) Awolusi O. O., Kumari S.K., Bux F. 2014. Characterization and quantification of
nitrifying community in activated sludge system treating municipal wastewater. Paper
presented at Water Institute of Southern Africa (WISA) 2014 (Water Innovations)
biennial conference, Mbombela Stadium, Nelspruit, South Africa (Oral presentation).

102

CHAPTER SIX: APPLICATION OF ARTIFICIAL
INTELLIGENCE FOR EVALUATING OPERATIONAL
PARAMETERS INFLUENCING NITRIFICATION AND
NITRIFIERS IN AN ACTIVATED SLUDGE PROCESS

6.1

INTRODUCTION

Harnessing chemolithotrophic nitrifiers’ ability to remove ammonia from wastewater,
is one of the primary tasks in protecting water resources from pollution discharges
(Wang et al., 2012). However, these nitrifying bacteria are highly sensitive to changes
in environmental parameters and plant operational conditions, such as pH,
temperature, dissolved oxygen (DO) level, organic loading rate (OLR), ammonia
loading rate (ALR) and hydraulic retention time (HRT) (Hu et al., 2009). Neutral to
slightly basic pH range (7.5 to 8.5) has been reported as optimum for efficient
nitrification (Fulweiler et al., 2011). According to an earlier finding, at neutral pH,
99% of ammonia was removed, however, this dropped to about 75% at a basic pH of
9.7 whilst acidic pH (4.8) resulted in an impaired removal efficiency of 56% (Hu et
al., 2009). Although it was reported that nitrification would proceed at a temperature
range of 20°C to 37°C (Stark, 1996), nonetheless niche differentiation exists among
the members of NOB group, with Nitrobacter having preference for relatively low
temperatures (24 – 25°C) whist Nitrospira thrives at higher temperatures (29 – 30°C)
(Huang et al., 2010a). Kim et al. (2011) demonstrated that, raising temperature from
20 to 30oC resulted in a 5.3-fold increase in ammonia oxidation, and a 2.6-fold increase
in nitrite oxidation.

Lower nitrification performance has been observed at higher organic loading due to
the competition for DO between total bacteria and nitrifying organisms (autotrophic
bacteria) in wastewater treatment system (Wu et al., 2013). Huang et al. (2010a)
demonstrated that higher DO concentrations were more suitable for Nitrobacter
growth, whilst Nitrospira was selectively enriched when DO concentrations were less
than 1.0 mg/L. The available carbon substrate for the unit mass of microorganism

103

(known as F/M ratio) can also impact nitrification. A study by Wu et al. (2013)
suggested that high F/M ratio should be avoided to minimize its negative impact on
nitrification, and it indicated that F/M between 0.2 and 0.4 was the optimum range for
nitrification. The influence of HRT on nitrification efficiency was also observed when
HRT decreased from 30 to 5 h with a resultant increase in specific ammoniumoxidizing and nitrate-forming rates (Li et al., 2013). Additionally, the decrease in HRT
led to a reduction of AOB population density, whereas the NOB, especially the fast
growing Nitrobacter spp., increased significantly (Li et al., 2013).

Modelling of a full-scale wastewater treatment plant (WWTP), operated under an
uncontrolled environment, requires advanced nonlinear modelling tools to simulate the
complex relationships between inputs and outputs (Kim et al., 2011). According to
Klemetti (2010), due to simultaneous dependence on different factors, competition
between microbial groups are usually nonlinear. Artificial intelligence (AI) is an
example of a nonlinear system that is capable of depicting the interactive influence
between variables as well as their correlation with the simulation output (Nasr et al.,
2015b). AI incorporates artificial neural network (ANN), fuzzy inference system (FIS)
and adaptive-neuro fuzzy inference system (ANFIS). ANN has the ability to model
nonlinear systems efficiently, owing to their high accuracy, adequacy and quite
promising applications in engineering (Nasr et al., 2012). FIS allows a logical datadriven modelling approach, which uses "if–then" rules and logical operators to
establish qualitative relationships among the variables (Nasr et al., 2014).

ANFIS is a neuro-fuzzy system that has the potential to capture the benefits of both
ANN and FIS in a single framework (Nasr et al., 2015b). Moreover, ANFIS can handle
complex and highly nonlinear relationships between several parameters, without the
difficult task of dealing with deterministic non-linear mathematics (Nasr et al., 2015a).
Modelling based on ANFIS needs a little knowledge about the process to track given
input/output data. In this context, it is expected that the effect of system operation on
nitrification process could be studied using ANFIS. To the best of our knowledge, this

104

is the first study applying ANFIS technique to describe the nitrification performance
at a full-scale wastewater treatment plant subjected to dynamic operational parameters.
In this chapter, the focus was to evaluate the influence of operational and
environmental parameters, on nitrification and the different nitrifiers’ population
abundance in the plant, using an advanced nonlinear modelling tool (ANFIS). ANFIS
results were further validated with cross-correlation coefficients and quadratic models.

6.2

MATERIALS AND METHODS

6.2.1

Plant description

The full-scale WWTP under study is situated midlands of KwaZulu-Natal province,
South Africa. The plant description has been given previously (Section 3.2.1 and Fig.
3.1).

6.2.2

Sampling protocol

The WWTP was monitored for a period of 237 days; i.e. from May to July 2012 and
from November 2012 to March 2013. The sampling protocol is as described in Section
3.2.2.

6.2.3

DNA extraction and real-time quantitative PCR (qPCR) amplification

The freeze-thaw DNA extraction procedure employed in this study has been
previously described in Section 3.2.4. The qPCR was carried out as described in
chapter 4. For the quantitative real-time PCR, the primers already described in Table
4.1 were used. The optimized protocols used for quantifying the nitrifiers are shown
in Table 4.2. To confirm amplification of the correct product, the amplicons from
qPCR were electrophoresed in 1.2% (wt/vol) agarose gel for the presence of the
expected gene product sizes. The qPCR standard curve parameters used for the
analysis are listed in Table 4.3.

105

6.2.4

Analytical analysis

Concentrations of inorganic nitrogen species and COD were estimated using standard
methods (APHA, 1998). Temperature, DO and pH measurements were carried out
using the YSI 556 MPS (Multiprobe System). The full physicochemical analysis is as
previously described in Section 5.2.2.

6.2.4.1 Calculations
Operational conditions such as HRT, OLR, ALR and F/M ratio were calculated
according to Tchobanoglous et al. (2003) as follows (Eqs. 1 – 4):
HRT 

V
Q

Eq. 1

OLR 

Q  COD
V

Eq. 2

ALR 

Q  N  NH 4
V

F M

Q  COD
MLSS  V



Eq. 3

Eq. 4

Where, HRT: hydraulic retention time; V: reactor volume; Q: flow rate; OLR: organic
loading rate; COD: chemical oxygen demand; ALR: ammonia loading rate; N-NH4+:
ammonia nitrogen; F/M: food-to-microorganisms ratio; MLSS: mixed liquor
suspended solids.

106

6.2.5

Adaptive neuro fuzzy inference system (ANFIS)

6.2.5.1 Architecture of ANFIS
To present the ANFIS architecture, two fuzzy "if–then" rules based on a first-order
Takagi–Sugeno fuzzy model were considered:
Rule-1: If ( x is A1 ) and ( y is B1 ) then ( f1 = p1 x + q1 y + r1 )
Rule-2: If ( x is A2 ) and ( y is B2 ) then ( f 2 = p2 x + q2 y + r2 )
Where x and y are the inputs,

Ai and Bi are the fuzzy sets, f i are the outputs within

the fuzzy region specified by the fuzzy rule;

pi , qi and ri are the design parameters

determined during the training process.

As shown in Fig. 6.1, the ANFIS architecture to implement these two rules has a total
of five layers, in which a circle indicates a fixed node, whereas a square indicates an
adaptive node. The functioning of each layer can be described as follows (Jang, 1993):

Layer-1

Layer-2

Layer-3

Layer-4

x
A1

M

x

w1

N

Layer-5

y

w1
w1 f1

A2


B1

M

y

B2

w2 f 2

N

w2

f

w2

x

y

Fig. 6.1: Typical first-order Sugeno ANFIS architecture

107

Layer-1 (Input node): Parameters in this layer referred to "premise parameters". Every
single node generates a fuzzy membership grade of linguistic label. The membership
functions (MFs) of

Ai and Bi  2 are given by Eq. 5 and Eq. 6, respectively.

Oi1   Ai x 

i = 1, 2

(Eq. 5)

Oi1   Bi2  y 

i = 3, 4

(Eq. 6)

Where x (or y ) is the input to node i , and Ai (or Bi  2 ) is the linguistic label (small,
large, etc.) related to this node. If the bell-shaped MF is generalized,

 A x  is given
i

by Eq. 7.
 A x  
i

1

(Eq. 7)

bi

2

 x  ci  

 
1  
a

 i  


Where ai ,

bi and ci are the MF parameters, governing the bell-shaped functions

accordingly.

Layer-2 (Rule nodes): In the second layer, the nodes are labelled with M , indicating
that they perform as a simple multiplier. The AND/OR operator is used to get one
output that represents the antecedent of the fuzzy "if–then" rule. The outputs of this
layer are defined as firing strengths of the rules. Each node analyses the firing strength
by cross multiplying all the incoming signals (Eq. 8).

Oi2  wi   Ai x  Bi  y 

i = 1, 2

(Eq. 8)

108

Layer-3 (Average nodes): In the third layer, the nodes are labelled with N ,
demonstrating that they play a normalization role to the firing strengths from the
previous layer. Thus, outputs of this layer are called "normalized firing strengths". As
shown in Eq. 9, the ith node calculates the ratio of the ith rules firing strength to the
sum of all rules’ firing strengths.

Oi3  wi 

wi
w1  w2

i = 1, 2

(Eq. 9)

Layer-4 (Consequent nodes): In this layer, every node i is an adaptive node with a node
function. The output of each node is the product of the normalized firing strength and
a first order polynomial (for a first-order Sugeno model). Hence, the outputs of this
layer are expressed by Eq. 10.

Oi4  wi fi  wi  pi x  qi y  ri 

i = 1, 2

(Eq. 10)

Where wi is the output of layer-3, and { pi , qi , ri } are consequent parameters,
pertaining to the first order polynomial.

Layer-5 (Output node): In the fifth layer, there is only one single fixed node labeled
with  . The single node computes the overall output as the summation of all incoming
signals. Thus, the overall output of the model is given by Eq. 11 as follows:
 2

  wi fi 
2

Oi5   wi fi   i 1
w

w
i 1
1
2

(Eq. 11)

109

6.2.5.2 Application of ANFIS
The function exhsrch in MATLAB was used to select the set of inputs that
considerably impact the nitrification activity. Theoretically, exhsrch builds an ANFIS
model for each combination and trains it for one epoch, sequentially reports the
performance achieved. ANFIS uses a hybrid learning algorithm to tune the parameters
of a Sugeno-type fuzzy inference system (Azar, 2011). The algorithm uses a
combination of the least-squares and back-propagation gradient descent methods to
model a training data set (Jang, 1993). The dataset is randomly classified into training
(70%) and checking (30%) arguments. The training process stops if the designated
epoch number is reached or the error goal is achieved, whichever comes first. The
checking data are used for testing the generalization capability of the ANFIS, and
monitor how well the model predicts the corresponding dataset output values.
Moreover, ANFIS validates models using a checking data set to test for overfitting of
the training data. Recently, this technique has been successfully implemented in the
field of wastewater treatment technology (Fawzy et al., 2015; Nasr et al., 2015a).

The results and discussion in this chapter was combine into a single section as it
appears in the already published article (Appendix Four: Microbial Ecology, DOI
10.1007/s00248-016-0739-3). Hence, it does not follow the separate “results” and
“discussion” format used in other chapters.

6.3

RESULTS AND DISCUSSION

6.3.1

Environmental conditions and system performance

The winter season (1st – 78th d) experienced little or no rainfall resulting in an average
influent flow rate of 61,990 ± 2,172 m3 d-1, whilst it increased to 93,062 ± 18,106 m3
d-1 during the summer (79th – 237th day). The influent COD during the summer was
1.3-fold lower than in the winter due to the dilution effect of increased rainfall (Table
6.1). The OLR increased during summer with increasing flow rate, despite the lower

110

COD, and reached 4.5 ± 1.8 kg COD m-3 d-1. The deviations in OLRs could be
attributed to the variation in the type of influent as a result of commercial and industrial
activities occurring around the treatment plant. The F/M ratio was 0.6 ± 0.1 d-1 in the
winter and increased by 48% during the summer (Table. 6.1). There is no ideal F/M
ratio that can work for all activated sludge treatment systems. Previous studies indicate
that the recommended range for F/M ratio in conventional, completely mixed and high
rate activated sludge processes ranged between 0.2 – 0.4, 0.2 – 0.6 and 0.4 – 1.5 d-1,
respectively (Tchobanoglous and Burton, 1991).

Although the influent ammonia during summer was 1.2-fold lower than in winter, the
respective ALR increased by 18.8% resulting from the summer rainfall (Table. 6.1).
The ammonia removal efficiency improved from 60 ± 18 to 83 ± 13% although the
ALR rose from 121 ± 22 to 144 ± 29 g N-NH4+ m-3 d-1 through winter to summer,
respectively. The increase in ammonia removal efficiency and nitrification rate with
ALR indicated that ammonia concentration was not the nitrification limiting factor in
this plant. This suggested that other operational conditions had a greater influence on
the nitrification process rather than ALR. Results from this study (60.0 ± 18.0 - 83.0±
13.0%) were lower than the 97 - 99.9% ammonia removal that was obtained by
Campos et al. (1999) when the nitrifying activated sludge unit was subjected to high
nitrogen loading rates (up to 7,500 g N-NH4+ m-3 d-1).

The higher nitrification performance of the plant could be due to operation of the unit
under a controlled environment, where the nitrifying activated sludge was fed with
synthetic wastewater containing ammonia and other nutrient sources with regulated
pH. The influent nitrate concentration during the study period varied between 0.25 and
3.68 mg/l with an average value of 1.51 ± 0.77 mg/l (Fig. 5.3; Chapter 5). Nitrate
removal efficiencies exhibited 64.6 ± 27.6% and 88.0 ± 26.3% during winter and
summer seasons, respectively. The concentration of effluent nitrate during the winter
was 3.6-fold higher than summer. This might be an indication of the increased

111

NOB/AOB ratio during the winter that promotes nitrate accumulation and thus a higher
effluent nitrate concentration in winter (Zhang et al., 2012a; Mozumder et al., 2013).

Table 6.1: Operational conditions and ANFIS model parameters of the full-scale
wastewater treatment plant under study
Parameters

Phase 1 (Winter)

Phase 2 (Summer)

Rainfall (mm)

26.0 ± 18.6

116.8 ± 32.0

Temperature (°C)

16.5 ± 2.1

22.4 ± 2.7

HRT (h)

6.3 ± 0.2

4.3 ± 1.0

4.0 ± 1.1

4.5 ± 1.8

ALR (g N-NH4 m d )

121 ± 22

144 ± 29

F/M (g COD g-1 MLSS d-1)

0.6 ± 0.1

0.9 ± 0.3

qN (mg N-NH4+ g-1 MLSS d-1)

12.3 ± 6.1

26.6 ± 10.7

AOB (copies ×109 l-1)

OLR (kg COD m-3 d-1)
+

-3

-1

1.00 ± 0.86

7.35 ± 5.75

9 -1

Nitrobacter spp. (copies ×10 l )

34.8 ± 19.0

50.8 ± 46.1

Nitrospira spp. (copies ×109 l-1)

3.32 ± 0.60

11.9 ± 11.2

The DO levels throughout the aeration tank varied between 0.24 and 1.27 mg/l, with
an average value of 0.63 ± 0.22 mg/l. The DO concentration in our study was lower
than the optimum value of 1.7 mg/l for a complete nitrification process (Ruiz et al.,
2003). The pH in the feed over the entire sampling period was relatively stable with
an average value of 7.2 ± 0.1, which is close to the optimum for nitrifiers (7.5 – 8.0)
(Ruiz et al., 2003). Ruiz et al. (2003) reported that at the range of pH 6.45 – 8.95, as
observed here, a complete nitrification to nitrate occurs, while at pH lower than 6.45
and higher than 8.95 would result in complete inhibition of nitrification.

112

6.3.2

Temporal changes in dominant nitrifiers’ abundance ratios

The AOB abundance was within the range of 1.55 × 108 – 1.65 × 1010 copies/l MLSS,
whereas the Nitrobacter spp. and Nitrospira spp. were found to be in the range of 9.32
× 109 – 1.40 × 1011 copies/l MLSS and 2.39 × 109 – 3.76 × 1010 copies/l MLSS,
respectively (Fig. 5.6). The Nitrobacter spp. abundance was 29-fold higher than AOB
throughout the study period showing a clear dominance of NOB in the selected WWTP
(Fig. 6.2). The average AOB to NOB ratio varied from 0.03:1 (winter) to 0.15:1
(summer), which was lower than the theoretical ratio of 2:1 reported for good
nitrification (Winkler et al., 2012). Due to the prevailing limiting oxygen levels (0.63
± 0.22 mg O2 l-1) in the reactor, there was a possibility of nitrite-loop. This
phenomenon usually occurs when denitrifiers reduce nitrate to nitrite supplying
additional nitrite for NOB, leading to a higher NOB/AOB ratio than theoretically
expected (Winkler et al., 2012). Additionally, Liu (2012) noted that under long-term
low DO, the oxygen affinity of NOB increases significantly, which makes NOB a
better competitor for oxygen compared to AOB. This high NOB/AOB ratio resulted
in sub-optimal ammonia transformation in this study. Whereas earlier studies have
recorded about 99% ammonia removal (Hu et al., 2009), in this study the highest NH3
removal that was recorded was 83 ± 13%.

A higher Nitrobacter: Nitrospira ratio of 7.4: 1.0 was also recorded. This could
possibly be explained based on the earlier observations of Wagner et al. (2002) and
Nogueira and Melo (2006). They noted an irreversible prevalence of Nitrobacter spp.
over Nitrospira spp. in WWTP after a history of spike in nitrite concentration, even
after subsequent reduction in nitrite concentration. Nitrobacter usually exhibit
inhibitory effect on the growth of Nitrospira once it dominates. Furthermore,
Fukushima et al. (2013) reported that Nitrobacter spp. can be selected over Nitrospira
spp. in plants with low inorganic carbon in addition to low nitrite concentration.
However, there have been no studies on the distribution of Nitrospira and Nitrobacter
in DO-limiting condition over an extended period of time at a full-scale WWTP.
Despite several other reports that Nitrospira spp. often are the dominant NOB in

113

AOB, Nitrobacter and Nitrospera
(copies.L-1)

1.6E+11
1.4E+11
1.2E+11
1E+11

activated
sludge systems (Whang et al., 2009), the result from this study indicates
that
AOB
8E+10
the knowledge about nitrifying bacteria populations at full-scale level Nitrobacter
still needs
6E+10

Nitrospira

further investigations.
4E+10
2E+10
0
NOB/AOB and Nitrobacter/Nitrospera

160 0

20

40

60

80

100 120 140 160 180 200 220 240
Time (d)

140
120
100
80

NOB/AOB

60

Nitrobacter/Nitrospira

40
20
0
0

20

40

60

80

100 120 140 160 180 200 220 240
Time (d)

Fig. 6.2: Temporal changes in dominant nitrifiers’ ratios in the full-scale wastewater
treatment plant under study.

6.3.3

Effect of operational conditions on specific nitrification rate

In this investigation, it was observed that the efficiency and effectiveness of a
nitrifying activated sludge system depended on several factors. The specific
nitrification rate (qN) showed a strong positive correlation to temperature (r 0.726, p
0.002). The qN noticeably increased by 2.2-fold and exhibited 26.6 ± 10.7 mg N-NH4+
g-1 MLSS d-1 during the summer season when the temperature was elevated to 22.4 ±
2.7°C. The ANFIS model indicated that temperature exhibited the least error,
demonstrating its relevance with respect to the qN (Fig. 6.3a). The considerable impact
of temperature on qN could be attributed to the high seasonal variation observed during
the monitored period. This observation was in agreement with previous studies, which
stated that increasing temperature could enhance the rate of nitrification and nitrifier

114

growth (Tarre and Green, 2004). Xu et al. (2012) reported that growth rate of nitrifiers
increased exponentially at a temperature range of 10 – 25°C, reaching a constant and
optimal growth rate between 25 and 35°C, however, at 40°C the growth rate
diminished drastically.

According to the ANFIS results in Fig. 6.3a, HRT has the second rank after
temperature regarding the operational conditions affecting qN. The current study
witnessed a significant increase in qN with a decrease in HRT (r -0.651, p 0.009). This
result was in agreement with a study by Li et al. (2013), where qN increased from 320
to 450 mg N-NH4+ g-1 MLSS d-1 (elevated by 41%) when the HRT decreased from 10
to 5 h, showing that the decline in HRT led to an enhancement in ammonia oxidation
activity. On the contrary, other studies have reported that lower HRT results in
increasing loading rates, which negatively affect the nitrifiers due to their competition
with heterotrophic bacteria for substrates (oxygen and ammonia) (Nogueira et al.,
2002). In our study, the negative trend between qN and HRT can be linked to the
seasonal change, which was the key factor in the development of nitrification, since
qN increased to 26.6 ± 10.7 mg N-NH4+ g-1 MLSS d-1 in summer season when
temperature increased to 22.4 ± 2.7ºC, while HRT declined to 4.3 ± 1.0 h.

In the current study, the qN showed a significant positive correlation with ALR (r
0.571, p 0.026). However, it was found that high concentration of ammonia in the
influent can negatively affect nitrification due to substrate inhibition by free ammonia
(Kim et al., 2006). This discrepancy could be attributed to the fact that the ALR of 120
- 140 g N-NH4+ m-3 d-1 observed in our study was still lower than the inhibitory limits
reported in previous studies (Campos et al., 1999; Kim et al., 2006). For example,
Campos et al. (1999) investigated the possibilities of obtaining a full ammonia
oxidation at increasing ALR from 500 to 7,500 g N-NH4+ m-3 d-1. Additionally, Kim
et al. (2006) found that nitrification efficiency increased to 100% with N-NH4+ loading
of 700 g m-3 d-1 at 18°C, and leachate was completely nitrified up to a load of 1,500 g
N-NH4+ m-3 d-1 at 28°C.

115

Other operational conditions such as DO showed no significant effect on qN (r -0.141,
p 0.617). This observation was in agreement with a study by Kim et al. (2006), where
the DO was not a limiting factor for nitrification. Additionally, the role of pH in our
study was not significant when compared to other environmental conditions (p 0.332)
due to its narrow range of variation. The pH range observed in this study (6.97 – 7.47)
was within the optimal range for the metabolism and growth of autotrophic nitrifiers
(Zhang et al., 2012a).

Referring to the ANFIS model (Fig. 6.3a), the training and checking errors were
comparable, which implies that no overfitting occurred. This means that selection of
more than one input can be explored to re-build the ANFIS model. The plot in Fig.
6.3b showed all two input variable combinations and their influence on qN.

116

Fig. 6.3: Effect of operating conditions on qN (The left-most input variable is the most
relevance with respect to qN). a) Every input variable's influence on qN; b) All two
input variable combinations and their influence on qN.

It was found that HRT and F/M (the left-most input variable) formed the optimal
combination of two input attributes. Additionally, it was observed that the minimal
training and checking errors reduced significantly from that of the best 1-input model,
indicating that the combination of HRT and F/M improved the prediction performance.
A quadratic model was developed to confirm the ANFIS results by estimating the qN
over independent variables (HRT and F/M). The polynomial equation (Eq. 12),

117

including constant, linear, interaction, and squared terms, provided a determination of
coefficient (r2-value) with the experimental data of 0.50.

qN  A  BHRT  CF/M  DHRT  F/M  EHRT  FF/M
2

2

(Eq. 12)

A = -76.2257; B= 24.3626; C = 149.0787; D = -17.1593; E = -1.8146; F = -41.3636
Where, qN in mg N-NH4+ g-1 MLSS d-1; HRT in h; F/M in d-1

6.3.4

Effect of operational conditions on AOB

The AOB was found to be HRT dependent with r-value of -0.741 (p 0.002). The high
correlation between HRT and AOB was in accordance with the ANFIS results, where
HRT exhibited the least training error among other operational conditions (Fig. 6.4a).
It was found that AOB exhibited a negative correlation with the current range of HRT
(4.3 – 6.3 h). Similar results were reported by Li et al. (2013) where an enhancement
in AOB community was observed when HRT declined from 7 to 5 h. They also noted
that AOB had a positive correlation when HRT became higher than 10 h (Li et al.,
2013). Our results showed a good correlation between AOB and temperature (r 0.517
and p 0.048), indicating that temperature had a positive impact on the AOB
community. The positive correlation between temperature and AOB was previously
illustrated by Park et al. (2008), who found that low temperature could not only
decrease the attached biomass and activity of AOB, but also produced a change in the
composition of the AOB species. According to ANFIS results, the two variables, HRT
and temperature were the most relevant parameters with respect to AOB (Fig. 6.4a).
Our results suggested that an increase in AOB during the summer season resulted from
an increase in temperature in line with a decrease in HRT.

As noticed from the ANFIS model (Fig. 6.4b), interaction of HRT with other
environmental factors provided a reliable assessment of the plant performance. This

118

might be due to the fact that the current study was based on full scale observations
where several environmental parameters were interacting together in a dynamic
manner. The influence of two environmental parameters indicated that the
combination of HRT and temperature exhibited lower training error than either HRT
or temperature by 64% and 70%, respectively. These results further confirm our
hypothesis that the AOB dominated in summer season due to the impact of both HRT
and temperature.

119

Fig. 6.4: Effect of operating conditions on AOB (The left-most input variable is the
most relevance with respect to AOB). a) Every input variable's influence on AOB; b)
All two input variable combinations and their influence on AOB.

120

Comparable to the qN results, the ANFIS model indicated that the combination of HRT
and F/M could be the most relevant input to the AOB (output) (Fig. 6.4b).
Subsequently, HRT and F/M were employed in a polynomial function of degree 2 to
determine their quadratic regression (Eq. 13). The estimated coefficient of
determination showed r2-value of 0.614.





AOB  A  BHRT  CF/M  DHRT  F/M  EHRT  FF/M 1011
2

2

(Eq. 13)

A = 1.0114; B= -0.2456; C = -0.6173; D = 0.0567; E = 0.0161; F = 0.1696
Where, AOB in copies l-1; HRT in h; F/M in d-1

6.3.5

Effect of operational conditions on NOB (Nitrobacter and Nitrospira)

The presence of NOB is necessary for wastewater treatment plants to achieve complete
nitrification. In this investigation, Nitrobacter spp. indicated no significant correlation
with the operational conditions (p > 0.1). This suggests that the abundance of
Nitrobacter could tolerate seasonal and environmental variations. The ANFIS model
indicated that F/M had the highest impact on Nitrobacter abundance (Fig. 6.5a). The
strength of the relationship between the F/M and Nitrobacter spp. was further
estimated by Pearson correlation coefficient which showed an r-value of 0.359 (p >
0.1). The importance of F/M was previously reported, where some organic compounds
in the wastewater positively affected the activity of NOB (Kim et al., 2006). The
ANFIS model was also used to identify relationships between Nitrobacter spp.
abundance and the combination of two operational parameters (Fig. 6.5b). The model
indicated that F/M and temperature form the optimal combination of two input
attributes. The polynomial equation of their quadratic interaction is presented in Eq.
14 (r2-value 0.49).



Nitrobacte r  A  BF/M  CT   DF/M  T   EF/M  FT 
2

2

10

11

(Eq. 14)

A = -0.7143; B= -3.4550; C = 0.2579; D = -0.0050; E = 1.9650; F = -0.0062

121

Where, Nitrobacter in copies L-1; F/M in d-1; T in °C

Fig. 6.5: Effect of operating conditions on Nitrobacter (The left-most input variable is
the most relevance with respect to Nitrobacter). a) Every input variable's influence on
Nitrobacter; b) All two input variable combinations and their influence on Nitrobacter.

122

Cross-correlation coefficients indicated that increase in Nitrospira spp. was
significantly affected by a decline in HRT (r -0.627 and p 0.012). Similarly, the ANFIS
model showed that the input HRT exhibited the least training error (Fig. 6.6a), which
was in accordance with the p values. Additionally, HRT showed inverse correlation
with Nitrobacter spp. (r -0.364 and p > 0.1). Similarly, Li et al. (2013) reported that a
short HRT favoured the relative growth of NOBs, particularly the fast-growing
Nitrobacter spp., in the conventional activated sludge system. As observed from the
ANFIS results (Fig 6.6b), the combination of HRT and F/M exhibited a 4-fold
lowering of the training error when compared to HRT individually. Therefore, the
quadratic polynomial formula indicating the combinatory effect of HRT and F/M on
Nitrospira can be presented by Eq. 15 (r2-value 0.716).





Nitrospira  A  BHRT  CF/M  DHRT  F/M  EHRT  FF/M 1011
2

2

Eq.

15
A = 1.9980; B= -0.7133; C = 0.1599; D = -0.0062; E = 0.0636; F = -0.1640

Where, Nitrospira in copies l-1; HRT in h; F/M in d-1

123

Fig. 6.6: Effect of operating conditions on Nitrospira (The left-most input variable is
the most relevance with respect to Nitrospira). a) Every input variable's influence on
Nitrospira; b) All two input variable combinations and their influence on Nitrospira.

124

In a similar study, Huang et al. (2010a) investigated the impact of environmental
variables on Nitrobacter and Nitrospira. They observed that, Nitrobacter populations
were negatively correlated to temperature (r -0.49 and p < 0.001), while the Nitrospira
abundance showed a strong positive correlation to temperature (r 0.59 and p < 0.0001).
Additionally, Nitrobacter populations were significantly and positively correlated to
DO (r 0.38 and p < 0.01). However, Nitrospira abundance showed a significantly
negative correlation to DO (r -0.46 and p < 0.01). Moreover, HRT showed a significant
impact on Nitrobacter spp. (r 0.334 and p < 0.05). When comparing our findings with
that of Huang et al. (2010a) both studies used the cross-correlation coefficients to
determine the significant impact of operational parameters on Nitrobacter and
Nitrospira. However, our study further applied artificial modelling technique in
confirming the r results, as well as to determine the optimum combination of two input
variables.

6.4

CONCLUSIONS

The AI approach succeeded in describing the effect of operating condition on
nitrification process. Results from the ANFIS model were in accordance with
Spearman's correlation coefficients, and it was concluded that:
 The qN was noticeably increased by 2.2-fold and exhibited 26.6 ± 10.7 mg NNH4+ g-1 MLSS d-1 when the temperature elevated from 16.5 ± 2.1 to 22.4 ±
2.7°C (r 0.726, p 0.002).
 The qN was also significantly affected by these individual parameters: HRT (r
-0.651, p 0.009) and ALR (r 0.571, p 0.026).
 HRT and F/M formed the optimal combination of two inputs affecting the q N,
and their quadratic equation showed r2-value of 0.50.
 AOB increased in the summer season, when temperature was 1.4-fold higher
than during winter (r 0.517, p 0.048), and HRT decreased by 31% as a result
of rainfall (r -0.741, p 0.002).

125

 No single input had a significant effect on Nitrobacter spp., indicating that the
abundance of Nitrobacter could tolerate seasonal and environmental variations
once the population is established in the system.
 Nitrospira spp. increased by 3.6 times when HRT declined during the summer
season (r -0.627, p 0.012).
 A polynomial function of 2nd degree for (HRT, F/M and AOB), (F/M,
temperature and Nitrobacter) and (HRT, F/M and Nitrospira) showed r2values of 0.61, 0.49 and 0.72, respectively.

6.5

RESEARCH OUTPUTS

a) Journal article
1) Awolusi, O. O., M. Nasr, Kumari, S. K. S., Bux, F. Artificial intelligence for the
evaluation of operational parameters influencing nitrification and nitrifiers in an
activated sludge process. Microbial Ecology DOI: 10.1007/s00248-016-0739-3 (In
press)

126

CHAPTER SEVEN: GENERAL CONCLUSIONS AND
RECOMMENDATIONS

CONCLUSIONS
This study examined the nitrifying community structure in a full-scale municipal
wastewater treatment plant. The diversity and abundance of the different nitrifying
populations in the plant was investigated, and their impact on nitrification efficiency
was determined. A combination of FISH, PCR-clone library, quantitative polymerase
chain reaction (qPCR) and next generation sequencing was applied. The effect of
operating parameters and environmental conditions on nitrification was investigated.
ANFIS, Pearson’s correlation coefficient and quadratic models were used to determine
and rank the plant’s operational conditions that influenced the nitrification
performance.

The research succeeded in establishing the following key findings:
 PCR-clone libraries of environmental samples was limited in taxonomic
resolution, whereas pyrosequencing yielded a better detail in terms of
microbial diversity in activated sludge.
 The species richness among AOB in the plant was not high. Hence, the
community did not exhibit substantial congeneric homotaxis, which can impart
high functional redundancy on them.
 Pyrosequencing reveals higher diversity of AOB in the reactor during summer
that was characterized by higher temperature. Furthermore, N. oligotropha was
only identified during summer. This indicates that higher temperature elicited
increased AOB diversity.
 The AOB diversity was 6 times higher during summer than winter when a
higher NH3 removal rate and temperature were recorded. The AOB sequences
related to uncultured bacterium and uncultured AOB showed increase of 133%

127

and 360% respectively when the season changed from winter to summer. This
suggests that higher AOB diversity resulted in increased nitrification rate of
the activated sludge.
 There was a significant difference in the nitrification efficiency of the plant
during the two seasons monitored with a two-fold increase in nitrification
observed during summer compared to winter.
 The cross-correlational approach could not establish any significant correlation
between NOB population abundance and operational parameters except when
ANFIS was used.
 There was a significant correlation between the nitrification rates of the plant
and the batch specific nitrification rate (in terms of SAOR) determined in the
laboratory experiment. Hence, the specific ammonia oxidation rate (SAOR)
can be used as indication of nitrifying population densities and nitrification
performance of wastewater treatment plants.
 The qN was noticeably increased by 2.2-fold and exhibited 26.6 ± 10.7 mg NNH4+ g-1 MLSS d-1 when the temperature elevated from 16.5 ± 2.1 to 22.4 ±
2.7°C (r 0.726, p 0.002).
 Based on ANFIS, HRT and F/M formed the optimal combination of two inputs
affecting the qN, and their quadratic equation showed r2-value of 0.50.
 AOB increased in the summer season, when temperature was 1.4-fold higher
than during winter (r 0.517, p 0.048), and HRT decreased by 31% as a result
of rainfall (r -0.741, p 0.002).
 Using ANFIS, no single input had a significant effect on Nitrobacter spp.,
indicating that the abundance of Nitrobacter could tolerate seasonal and
environmental variations once the population is established in the system.

SIGNIFICANCE AND NOVELTY OF THE RESEARCH FINDINGS
 This study can be considered as novel since it was the first time pyrosequencing
was used for amoA locus profiling of AOB community composition in full scale
wastewater plants.

128

 The findings from the current study have set the foundation for future application
of these advanced molecular techniques in understanding the diversity and role of
uncultured AOB in wastewater treatment
 This study suggests that vast population of novel, ecologically significant AOB
species, which remain unexploited, still inhabit the complex activated sludge
communities.
 The PCR yielded no positive amplification for AOA, which could suggests that
archaea did not play an important role in the nitrification process of this WWTP
and may not be ubiquitous in all nitrifying WWTPs.
 Furthermore, novelty was demonstrated in this study since earlier studies on
nitrification used the cross-correlation coefficients to determine the significant
impact of operational parameters on nitrifiers. This study in addition to crosscorrelation, further applied artificial modelling technique in confirming the
results, as well as to determine the optimum combination of two input variables.
 This study indicated that artificial intelligence could be used as a tool to elucidate
the factors influencing nitrification process in full-scale wastewater treatment
plants. It further indicates that ANFIS, is better than conventional Spearman
correlation, since the latter could not (in some cases) detect correlation between
microbial populations (NOB) and plant’s operating parameters due to the nonlinearity of the interactions in wastewater treatment.

RECOMMENDATIONS
 There is need for more research effort towards isolating and characterization of the
nitrifying populations (AOB, AOA and NOB) in wastewater, as pyrosequencing
revealed a large diversity of uncultured AOB and previously unidentified
organisms.
 The operational conditions of the WWTP including HRT and loading rates should
be manipulated in order to overcome the diminishing nitrification arising from low
temperature during winter.

129

 The findings of the research would be workshopped with staff from Umgeni Water
Board whom commissioned the research.

130

REFERENCE

Ahmed, Z., Cho, J., Lim, B. R., Song, K. G. and Ahn, K. H. 2007. Effect of sludge
retention time on membrane fouling and microbial community structure in a
membrane bioreactor. J Membr Sci, 28: 211-218.
Akpor, O. B. and Muchie, M. 2010. Bioremediation of polluted wastewater influent:
phousphorus and nitrogen removal. Sci Res Essays, 5: 3222-3230.
Alambeigi, F., Khadem, S. M., Khorsand, H. and Hasan, E. M. S. 2015. A comparison
of performance of artificial intelligence methods in prediction of dry sliding
wear behavior. Int J Adv Manuf Technol, DOI 10.1007/s00170-015-7812-9.
Amann, R. I., Ludwig, W. and Schleifer, K. H. 1995. Phylogenetic identification and
in situ detection of individual microbial cells without cultivation. Microbiol
Rev, 59: 143–169.
APHA 1998. Standard Methods for the Examination of Water and Wastewater
American Public Health Association.
Arévalo, J., Ruiz, L. M., Pérez, J. and Gómez, M. A. 2014. Effect of temperature on
membrane bioreactor performance working with high hydraulic and sludge
retention time. Biochemical Engineering Journal, 88: 42-49.
Awolusi, O. O., Kumari, S. K. S. and Bux, F. 2015. Ecophysiology of nitrifying
communities in membrane bioreactors. Int J Environ Sci Technol, 12: 747-762.
Ayanda, O. S. and Akinsoji, O. S. 2011. Biological wastewater treatment
Microbiology chemistry and diversity measurement of ammonia oxidizing
bacteria. African J Microbiol Res, 5: 5831-5840.
Azar, A. 2011. Adaptive neuro-fuzzy system as a novel approach for predicting postdialysis urea rebound. Int J Intelligent Sys Technol Applications, 10: 302-330.
Azar, A. T. 2010. Adaptive neuro-fuzzy systems. Fuzzy syst.: 85-110.

131

Bae, H., Park, J. H., Jun, K. S. and Jung, J. Y. 2013. The community analysis of
ammonia-oxidizing bacteria in wastewater treatment plants revealed by the
combination of double labeled T-RFLP and sequencing. J Environ Sci Health
Part A 46: 345–354.
Bae, W., Baek, S., Chung, J. and Lee, Y. 2002. Optimal operational factors for nitrite
accumulation in batch reactors. Biodegradation, 12: 359-366.
Bahadoorsingh, P. 2010. Comparison of nitrification activity in membrane and
conventional enhanced biological phosphorus removal processes. PhD, The
University of British Columbia.
Bassin, J. P., Kleerebezem, R., Muyzer, G., Rosado, A. S., van Loosdrecht, M. C. and
Dezotti, M. 2012. Effect of different salt adaptation strategies on the microbial
diversity, activity, and settling of nitrifying sludge in sequencing batch
reactors. Appl Microbiol Biotechnol, 93: 1281-94.
Boon, N., De Windt, W., Verstraete, W. and Top, E. M. 2002. Evaluation of nested
PCR-DGGE (denaturing gradient gel electriphoresis) with group-specific 16S
rRNA primers for the analysis of bacterial communities from different
wastewater treatment plants. FEMS Microbiol Ecol, 39: 101-112.
Bourrain, M., Achouak, W., Urbain, V. and Heulin, T. 1999. DNA extraction from
activated sludges. Curr Microbiol, 38: 315-319.
Bouskill, N. J., Eveillard, D., O’Mullan, G., Jackson, G. A. and Ward, B. B. 2011.
Seasonal and annual reoccurrence in betaproteobacterial ammo-nia-oxidizing
bacterial population structure. Environ Microbiol, 13: 872–886.
Briese, V. 2002. DNA precipitation [Online]. Available: http://www.protocolonline.org/cgi-bin/prot/view_cache.cgi?ID=2744 [Accessed 9/15/ 2012].
Caballero, A. R. 2011. Study of bacterial communities – a wastewater treatment
perspective. PhD, Mälardalen University.

132

Calderon, K., Gonzalez-Martinez, A., Montero-Puente, C., Reboleiro-Rivas, P.,
Poyatos, J. M., Juarez-Jimenez, B., Martinez-Toledo, M. V. and Rodelas, B.
2012. Bacterial community structure and enzyme activities in a membrane
bioreactor (MBR) using pure oxygen as an aeration source. Bioresour Technol,
103: 87-94.
Campos, J., Garrido-Fermindez, J., Mendez, R. and Lema, J. 1999. Nitrification at high
ammonia loading rates in an activated sludge unit. Bioresour Technol, 68: 141148.
Canfield, D. E., Glazer, A. N. and Falkowski, P. G. 2010. The evolution and future of
earth’s nitrogen cycle. Sci, 330: 192–196.
Carvalho, G., Meyer, R. L., Yuan, Z. and Keller, J. 2006. Differential distribution of
ammonia- and nitrite-oxidising bacteria in flocs and granules from a
nitrifying/denitrifying sequencing batch reactor. Enzym Microb Technol, 39:
1392-1398.
Cebron, A. and Garnier, J. 2005. Nitrobacter and Nitrospira genera as representatives
of nitrite-oxidizing bacteria : detection , quantification and growth along the
lower Seine River ( France ). Water Res, 39: 4979-4992.
Cecen, F., Semerci, N. and Geyik, A. G. 2010. Inhibition of respiration and distribution
of Cd, Pb, Hg, Ag and Cr species in a nitrifying sludge. J Hazard Mater, 178:
619–627.
Chandra, D. S. and Sathasivan, A. 2011. Effect of temperature on onset of nitrification
in chloraminated distribution system. Desalin Water Treat, 32: 95-99.
Chang, O.-C., Liu, W.-T. and Fang, H. H. P. 2001. Study of microbial community of
brewery-treating granular sludge by denaturing gradient gel electrophoresis of
16S rRNA gene. Water Sci Technol, 43: 77-82.
Chen, Y., Sun, H., Yang, W. and Yang, Z. 2012. Incubation and oxidative stress of
grass carp (Ctenopharyngodon idella) embryos exposed to different un-ionized
ammonia levels. J Freshw Ecol, 27: 143–150.

133

Cho, K. H., Kim, J.-O., Kang, S., Park, H., Kim, S. and Kim, Y. M. 2014. Achieving
enhanced nitrification in communities of nitrifying bacteria in full-scale
wastewater treatment plants via optimal temperature and pH. Sep Purif
Technol, 132: 697-703.
Choi, J. and Liu, Y. 2014. Biodegradation of oil sands process affected water in
sequencing batch reactors and microbial community analysis by highthroughput pyrosequencing. Int Biodeterior Biodegrad, 92: 79-85.
Chuai, X., Chen, X., Yang, L., Zeng, J., Miao, A. and Zhao, H. 2012. Effects of
climatic changes and anthropogenic activities on lake eutrophication in
different ecoregions. . Int J Environ Sci Technol, 9: 503–514.
Cicek, N., Macomber, J., Davel, J., Suidan, M. T., Audic, J. and Genestet, P. 2001.
Effect of solids retention time on the performance and biological
characteristics of a membrane bioreactor. Water Sci Technol, 43: 43-50.
Clarridge, J. E. 2004. Impact of 16S rRNA gene sequence analysis for identification
of bacteria on clinical microbiology and infectious diseases. Clin Microbiol
Rev, 17: 840–862.
Colliver, B. B. and Stephenson, T. 2000. Production of nitrogen oxide and dinitrogen
oxide by autotrophic nitrifiers. Biotechnol Adv, 18: 219-232.
Cydzik-Kwiatkowska, A., Zielińska, M. and Wojnowska-Baryła, I. 2012. Impact of
operational parameters on bacterial community in a full-scale municipal
wastewater treatment plant. Polish J Microbiol, 61: 41-49.
Daims, H., Taylor, M. W. and Wagner, M. 2006. Wastewater treatment: A model
system for microbial ecology. Trends Biotechnol, 24: 483-489.
Daims, H. and Wagner, M. 2010. The Microbiology of Nitrogen Removal. In: Seviour,
R. J. and Nielsen, P. H. (eds.) Microbial ecology of activated sludge. London:
IWA.

134

Damodaran, A. 2011. The little book of valuation: how to value a company, pick a
stock and profit, Hoboken, John Wiley & Sons.
Degrange, V. and Bardin, R. 1995. Detection and counting of Nitrobacter populations
in soil by PCR. Appl Environ Microbiol, 61: 2093-2098.
Ding, L., Zhou, Q., Wang, L. and Zhang, Q. 2011. Dynamics of bacterial community
structure in a full-scale wastewater treatment plant with anoxic-oxic
configuration using 16S rDNA PCR-DGGE fingerprints. African J Biotechnol,
10: 589-600.
Dionisi, H. M., Layton, A. C., Harms, G., Gregory, I. R., Robinson, K. G. and Sayler,
G. S. 2002. Quantification of Nitrosomonas oligotropha-like ammoniaoxidizing bacteria and Nitrospira spp. from full-scale wastewater treatment
plants by competitive PCR. Appl Environ Microbiol, 68: 245-253.
Dogan, H., Can, H. and Otu, H. H. 2014. Whole genome sequence of a Turkish
individual. PLoS One, 9: e85233.
Dong, X. and Reddy, G. B. 2012. Ammonia-oxidizing bacterial community and
nitrification rates in constructed wetlands treating swine wastewater. Ecol Eng,
40: 189-197.
Duan, L., Song, Y., Xia, S. and Hermanowicz, S. W. 2013. Characterization of
nitrifying microbial community in a submerged membrane bioreactor at short
solids retention times. Bioresour Technol, 149: 200-7.
Ducey, T. F., Vanotti, M. B., Shriner, A. D., Szogi, A. A. and Ellison, A. Q. 2010.
Characterization of a microbial community capable of nitrification at cold
temperature. Bioresour Technol, 101: 491-500.
Egli, K., Langer, C., Siegrist, H. R., Zehnder, A. J. B., Wagner, M. and Van Der Meer,
J. R. 2003. Community analysis of ammonia and nitrite oxidizers during startup of nitritation reactors. Appl Environ Microbiol, 69: 3213-3222.

135

Eschenhagen, M., Schuppler, M. and Röske, I. 2003. Molecular characterization of the
microbial community structure in two activated sludge systems for the
advanced treatment of domestic effluents. Water Res, 37: 3224-3232.
Fan, X. J., Urbain, V., Qian, Y., Manem, J., Ng, W. J. and Ong, S. L. 2000. Nitriﬁcation
in a membrane bioreactor (MBR) for wastewater treatment. Water Sci Technol,
42: 289 - 294.
Faulwetter, J. L., Burr, M. D., Parker, A. E., Stein, O. R. and Camper, A. K. 2013.
Influence of season and plant species on the abundance and diversity of sulfate
reducing bacteria and ammonia oxidizing bacteria in constructed wetland
microcosms. Microb Ecol, 65: 111-127.
Fawzy, M., Nasr, M., Abdel-Gaber, A. and Fadly, S. 2015. Biosorption of Cr(VI) from
aqueous solution using agricultural wastes, with artificial intelligence approach
Separ Sci Technol, doi:10.1080/01496395.2015.1115068

Ferrera, I., Massana, R., Balague, V., Pedros-Alio, C., Sanchez, O. and Mas, J. 2010.
Evaluation of DNA extraction methods from complex phototrophic biofilms.
Biofouling, 26: 349-57.
Filali, A., Bessiere, Y. and Sperandio, M. 2012. Effects of oxygen concentration on
the nitrifying activity of an aerobic hybrid granular sludge reactor. Water Sci
Technol, 65: 289-95.
Flores-Alsina, X., Corominas, L., Snip, L. and Vanrolleghem, P. A. 2011. Including
greenhouse gas emissions during benchmarking of wastewater treatment plant
control strategies. Water Res, 45: 4700-10.
Francis, C. A., Roberts, K. J., Beman, J. M., Santoro, A. E. and Oakley, B. B. 2005.
Ubiquity and diversity of ammonia-oxidizing archaea in water columns and
sediments of the ocean. Proc Natl Acad Sci USA, 102: 14683-14688.

136

Fu, B., Liao, X., Ding, L. and Ren, H. 2010. Characterization of microbial community
in an aerobic moving bed biofilm reactor applied for simultaneous nitrification
and denitrification. World J Microbiol Biotechnol, 26 1981–1990.
Fuchs, B. M., Pernthaler, J. and Amann, R. 2007. Single cell identification by
fluorescence in situ hybridization. In: Reddy, C. A., Beveridge, T. J., Breznak,
J. A., Marzluf, G., Schmidt, T. M. and Snyder, L. R. (eds.) Methods for General
and Molecular Microbiology. 3rd ed. Washington D.C.: ASM Press.
Fujita, M., Tsuji, K. and Akashi, A. 2010. Temporal variation in maximum cellspecific nitrification rate. Water Sci Technol, 61: 2069-73.
Fujitani, H., Ushiki, N., Tsuneda, S. and Aoi, Y. 2014. Isolation of sublineage I
Nitrospira by a novel cultivation strategy. Environ Microbiol, 16: 3030-40.
Fukushima, T., Whang, L. M., Chiang, T. Y., Lin, Y. H., Chevalier, L. R., Chen, M.
C. and Wu, Y. J. 2013. Nitrifying bacterial community structures and their
nitrification performance under sufficient and limited inorganic carbon
conditions. Appl Microbiol Biotechnol, 97: 6513-23.
Fukushima, T. B., P. L. 2010. Polymerase chain reaction (PCR) technology. In:
Seviour, R. J. and Nielsen, P. H. (eds.) Microbial ecology of activated sludge.
London: IWA
Fulweiler, R. W., Emery, H. E., M., H. E. and Berounsky, V. M. 2011. Assessing the
role of pH in determining water column nitrification rates in a coastal system.
Estuar Coasts 34: 1095–1102.
Gao, D. and Tao, Y. 2012. Current molecular biologic techniques for characterizing
environmental microbial community. Front Environ Sci Engin, 6 82–97.
Gao, D. W. and Tao, Y. 2011. Versatility and application of anaerobic ammoniumoxidizing bacteria. Appl Microbiol Biotechnol, 91: 887-94.

137

Ge, S., Wang, S., Yang, X., Qiu, S., Li, B. and Peng, Y. 2015. Detection of nitrifiers
and evaluation of partial nitrification for wastewater treatment: A review.
Chemosphere, doi: 10.1016/j.chemosphere.2015.02.004.
Gentile, M. E., Nyman, J. L. and Criddle, C. S. 2007. Correlation of patterns of
denitrification instability in replicated bioreactor communities with shifts in
the relative abundance and the denitrification patterns of specific populations.
ISME J, 1: 714-28.
Gerardi, M. 2002. Nitrification and denitrification in the activated sludge process. New
York: John Wiley and Sons, Inc.
Gharizadeh, B., Kalanetra, K., Garcia, C. A., Johansson, B. and Nyren, P. 2001.
Typing of human papillomavirus by pyrosequencing. Lab Invest, 81: 637-679.
Gil, K. I. K. and Choi, E. S. 2001. Modelling of inhibition of nitrite oxidation in
biological nitritation processes by free ammonia. Biotechnol Lett, 23: 20212026.
Gilbride, K. A., Lee, D. Y. and Beaudette, L. A. 2006. Molecular techniques in
wastewater: Understanding microbial communities, detecting pathogens, and
real-time process control. J Microbiol Methods, 66: 1-20.
Glicksman, R. L. and Batzel, M. R. 2010. Science, politics, law and the arc of the clean
water act: the role of assumptions in the adoption of a pollution control
landmark. Wash Univ J Law Policy 32 99–138.
Gomez-Silvan, C., Molina-Munoz, M., Poyatos, J. M., Ramos, A., Hontoria, E.,
Rodelas, B. and Gonzalez-Lopez, J. 2010. Structure of archaeal communities
in membrane-bioreactor and submerged-biofilter wastewater treatment plants.
Bioresour Technol, 101: 2096-105.
Graham, D. W., Knapp, C. W., Van Vleck, E. S., Bloor, K., Lane, T. B. and Graham,
C. E. 2007. Experimental demonstration of chaotic instability in biological
nitrification. ISME J, 1: 385-93.

138

Guler, N. 2006. Identification of nitrifier diversity and activity in biological
wastewater treatment systems. MSc, Marmara University.
Haarman, M. and Knol, J. 2005. Quantitative real-time PCR assays to identify and
quantify fecal Bifidobacterium species in infants receiving a prebiotic infant
formula. Appl Environ Microbiol 71 2318–2324.
Hai, R., Wang, Y., Wang, X., Li, Y. and Du, Z. 2014. Bacterial community dynamics
and taxa-time relationships within two activated sludge bioreactors. PLoS One,
9: 1-8.
Hall, T. A. 1999. BioEdit: a user-friendly biological sequence alignment editor and
analysis program for Windows 95/98/NT. Nucleic acids symp ser, 41: 95-98.
Hatzenpichler, R. 2012. Diversity, physiology, and niche differentiation of ammoniaoxidizing archaea. Appl Environ Microbiol, 78: 7501–7510.
Hawkins, S. A., Robinson, K. G., Layton, A. L. and Sayler, G. S. 2008. Response of
Nitrobacter spp. ribosomal gene and transcript abundance following nitrite
starvation and exposure to mechanistically distinct inhibitors. Environ Sci
Technol 42 901–907.
He, S. B., Xue, G. and Wang, B. Z. 2009. Factors affecting simultaneous nitrification
and denitrification (SND) and its kinetics model in membrane bioreactor. J
Hazard Mater, 168: 704-10.
Heffernan, B., van Lier, J. B. and van der Lubbe, J. 2011. Performance review of large
scale up-flow anaerobic sludge blanket sewage treatment plants. Water Science
and Technology, 63: 100-107.
Hirooka, K., Asano, R. and Nakai, Y. 2009. Change in the community structure of
ammonia-oxidizing bacteria in activated sludge during selective incubation for
MPN determination. J Ind Microbiol Biotechnol, 36: 679-685.

139

Hoang, V., Delatolla, R., Abujamel, T., Mottawea, W., Gadbois, A., Laflamme, E. and
Stintzi, A. 2014. Nitrifying moving bed biofilm reactor (MBBR) biofilm and
biomass response to long term exposure to 1oC. Water Res, 49: 215-24.
Holeton, C., Chambers, P. A. and Grace, L. 2011. Wastewater release and its impacts
on Canadian waters. Can J Fisher Aquat Sci, 68: 1836–1859.
Hu, J., Li, D., Liu, Q., Tao, Y., He, X., Wang, X., Li, X. and Gao, P. 2009. Effect of
organic carbon on nitrification efficiency and community composition of
nitrifying biofilm. J Environ Sci, 21: 387-394.
Hu, M., Wang, X., Wen, X. and Xia, Y. 2012. Microbial community structures in
different wastewater treatment plants as revealed by 454-pyrosequencing
analysis. Bioresour Technol, 117: 72-9.
Hu, Z., Chandran, K., Grasso, D. and Smets, B. F. 2002. Effect of nickel and cadmium
speciation on nitrification inhibition. Environ Sci Technol, 36: 3074-3078.
Huang, H., Gedalanga, P. and Olson, B. H. Distribution of Nitrobacter and Nitrospira
Communities in an Aerobic Activated Sludge Bioreactor and their
Contributions to Nitrite Oxidation. WEFTEC, 2010a.
Huang, X., Gui, P. and Qian, Y. 2001. Effect of sludge retention time on microbial
behaviour in a submerged membrane bioreactor. Process Biochemistry, 36:
1001-1006.
Huang, Z., Gedalanga, P. B., Asvapathanagul, P. and Olson, B. H. 2010b. Influence of
physicochemical and operational parameters on Nitrobacter and Nitrospira
communities in an aerobic activated sludge bioreactor. Water res, 44: 4351 4358.
Hulle, S. V. 2005. Modelling, simulation and optimization of autotrophic nitrogen
removal processes. PhD, Ghent University.
Imarla, T., Hector, S. B., Deane, S. M. and Rawlings, D. E. 2006. Resistance
determinants of a highly arsenic-resistant strain of Leptospirillum ferriphilum

140

isolated from a commercial biooxidation tank. Appl Environ Microbiol 72:
2247–2253.
ITRC. 2013. Environmental molecular diagnostics: New site characterization and
remediation enhancement tools. [Online]. Washington, D.C.: Interstate
Technology & Regulatory Council, Environmental Molecular Diagnostics
Team.

Available:

http://itrcweb.org/EMD_TechRegDraft/Content/9%20Fluorescence%20in%2
0situ%20hybridization.htm [Accessed 10/26/ 2015].
Jang, J. S. 1993. ANFIS: Adaptive-Network-based Fuzzy Inference Systems. IEEE
Trans Syst Man Cybern, 23 665-685.
Jin, T., Zhang, T. and Yan, Q. 2010. Characterization and quantification of ammoniaoxidizing archaea ( AOA ) and bacteria ( AOB ) in a nitrogen-removing reactor
using T-RFLP and qPCR. Appl Microbiol Biotechnol, 87: 1167–1176.
Jin, T., Zhang, T., Ye, L., Lee, O. O., Wong, Y. H. and Qian, P. Y. 2011. Diversity
and quantity of ammonia-oxidizing archaea and bacteria in sediment of the
Pearl River Estuary, China. Appl Microbiol Biotechnol, 90: 1137-45.
Ju, F., Guo, F., Ye, L., Xia, Y. and Zhang, T. 2014. Metagenomic analysis on seasonal
microbial variations of activated sludge from a full-scale wastewater treatment
plant over 4 years. Environ Microbiol, 6: 80-89.
Ju, F. and Zhang, T. 2015a. 16S rRNA gene high-throughput sequencing data mining
of microbial diversity and interactions. Appl Microbiol Biotechnol, 99: 41194129.
Ju, F. and Zhang, T. 2015b. Bacterial assembly and temporal dynamics in activated
sludge of a full-scale municipal wastewater treatment plant. ISME J, 9: 683695.
Junier, P., Molina, V., Dorador, C., Hadas, O., Kim, O. S., Junier, T., Witzel, J. P. and
Imhoff, J. F. 2010. Phylogenetic and functional marker genes to study

141

ammonia-oxidizing microorganisms (AOM) in the environment. Appl
Microbiol Biotechnol, 85: 425-40.
Kelly, J. J., Siripong, S., McCormack, J., Janus, L. R., Urakawa, H., El Fantroussi, S.,
Noble, P. A., Sappelsa, L., Rittmann, B. E. and Stahl, D. A. 2005. DNA
microarray detection of nitrifying bacterial 16S rRNA in wastewater treatment
plant samples. Water Research, 39: 3229-3238.
Kelly, R. T., Henriques, I. D. S. and Love, N. G. 2004 Chemical inhibition of
nitrification in activated sludge. Biotechnol Bioeng, 85: 683–694.
Keshri, J., Mankazana, B. B. J. and Momba, M. N. B. 2015. Profile of bacterial
communities in South African mine-water samples using Illumina nextgeneration sequencing platform. Appl Microbiol Biotechnol, 99: 3233-3242.
Kim, D., Lee, D. and Keller, J. 2006. Effect of temperature and free ammonia on
nitrification and nitrite accumulation in landfill leachate and analysis of its
nitrifying bacterial community by FISH. Bioresour Technol, 97: 459-468.
Kim, D. J. and Kim, S. H. 2006. Effect of nitrite concentration on the distribution and
competition of nitrite-oxidizing bacteria in nitratation reactor systems and their
kinetic characteristics. Water Res, 40: 887-94.
Kim, J., Guo, X. and Park, H. 2008. Comparison study of the effects of temperature
and free ammonia concentration on nitrifiers and nitrite accumulation. Proc
Biochem, 43: 154-160.
Kim, S.-S. and Kim, H.-J. 2003. Impact and threshold concentration of toxic materials
in the stripped gas liquor on nitrification. Korean J Chem Eng, 20: 1103-1110.
Kim, T. S., Jeong, J. Y., Wells, G. F. and Park, H. D. 2013. General and rare bacterial
taxa demonstrating different temporal dynamic patterns in an activated sludge
bioreactor. Appl Microbiol Biotechnol, 97: 1755-65.

142

Kim, Y. M. 2013. Acclimatization of communities of ammonia oxidizing bacteria to
seasonal changes in optimal conditions in a coke wastewater treatment plant.
Bioresour Technol, 147: 627-31.
Kim, Y. M., Cho, H. U., Lee, D. S., Park, D. and Park, J. M. 2011. Influence of
operational parameters on nitrogen removal efficiency and microbial
communities in a full-scale activated sludge process. Water Res, 45: 5785-95.
Kircher, M., Heyn, P. and Kelso, J. 2011. Addressing challenges in the production and
analysis of Illumina sequencing data. BMC Genom, 12: 382.
Klemetti, R. 2010. Modelling the start-up of biological phosphorus removal at low
temperature. P.hD., Aato University.
Kornboonraksa, T., Lee, H. S., Lee, S. H. and Chiemchaisri, C. 2009. Application of
chemical precipitation and membrane bioreactor hybrid process for piggery
wastewater treatment. Bioresour Technol, 100: 1963-1968.
Kornboonraksa, T. and Lee, S. H. 2009. Factors affecting the performance of
membrane bioreactor for piggery wastewater treatment. Bioresour Technol,
100: 2926-32.
Kumari, S. K., Marrengane, Z. and Bux, F. 2009. Application of quantitative RT-PCR
to determine the distribution of Microthrix parvicella in full-scale activated
sludge treatment systems. Appl Microbiol Biotechnol, 83: 1135-41.
Kurisu, F., Satoh, H., Mino, T. and Matsuo, T. 2002. Microbial community analysis
of thermophilic contact oxidation process by using ribosomal RNA approaches
and the quinone profile method. Water Res, 36: 429-438.
LaPara, T. M. and Ghosh, S. 2006. Population dynamics of the ammonia-oxidizing
bacteria in a full-scale municipal wastewater treatment facility. Environ Eng
Sci, 23: 309-319.
Lee, N. M. and Welander, T. 1994. Influence of predeators on nitrification in aerobic
biofilm processes. Wat Sci Tech, 29: 355-364.

143

Lemarchand, K., Berthiaume, F., Maynard, C., Harel, J., Payment, P., Bayardelle, P.,
Masson, L. and Brousseau, R. 2005. Optimization of microbial DNA extraction
and purification from raw wastewater samples for downstream pathogen
detection by microarrays. J Microbiol Methods, 63: 115-26.
Li, H., Yang, M., Zhang, Y., Yu, T. and Kamagata, Y. 2006. Nitrification performance
and microbial community dynamics in a submerged membrane bioreactor with
complete sludge retention. J Biotechnol, 123: 60-70.
Li, H., Zhang, Y., Yang, M. and Kamagata, Y. 2013. Effects of hydraulic retention
time on nitrification activities and population dynamics of a conventional
activated sludge system. Front Environ Sci Eng China, 7: 43-48.
Liang, Z., Das, A., Beerman, D. and Hu, Z. 2010. Biomass characteristics of two types
of submerged membrane bioreactors for nitrogen removal from wastewater.
Water Res, 44: 3313-3320.
Lienen, T., Kleybocker, A., Verstraete, W. and Wurdemann, H. 2014. Moderate
temperature increase leads to disintegration of floating sludge and lower
abundance of the filamentous bacterium Microthrix parvicella in anaerobic
digesters. Water Res, 65: 203-212.
Limpiyakorn, T., Sonthiphand, P., Rongsayamanont, C. and Polprasert, C. 2011.
Abundance of amoA genes of ammonia-oxidizing archaea and bacteria in
activated sludge of full-scale wastewater treatment plants. Bioresource
Technology, 102: 3694–3701.
Liu, G. 2012. Nitrification performance of activated sludge under low dissolved
oxygen conditions. PhD, Missouri University of Science and Technology
Liu, G. and Wang, J. 2013. Long-term low DO enriches and shifts nitrifier community
in activated sludge. Environ Sci Technol, 47: 5109-17.
Liu, H., Yang, F., Shi, S. and Liu, X. 2010a. Effect of substrate COD/N ratio on
performance and microbial community structure of a membrane aerated
biofilm reactor. J Environ Sci, 22: 540-546.

144

Liu, L., Li, Y., Li, S., Hu, N., He, Y., Pong, R., Lin, D., Lu, L. and Law, M. 2012.
Comparison of next-generation sequencing systems. J Biomed Biotechnol,
2012: 1-11.
Liu, Y., Shi, H., Xia, L., Shen, T., Wang, Z., Wang, G. and Wang, Y. 2010b. Study of
operational conditions of simultaneous nitrification and denitrification in a
Carrousel oxidation ditch for domestic wastewater treatment. Bioresour
Technol, 101: 901-6.
Lopez-Vazques, C. M. 2009. The competition between polyphosphate-accumulating
organisms and glycogen-accumulating organisms: temperature effects and
modelling. PhD, Delft University of Technology.
Lotti, T., Kleerebezem, R., Hu, Z., Kartal, B., Jetten, M. S. and van Loosdrecht, M. C.
2014. Simultaneous partial nitritation and anammox at low temperature with
granular sludge. Water Res, 66: 111-21.
Lu, P., Chen, S. and Zheng, Y. 2012. Artificial Intelligence in Civil Engineering. Math
Probl Eng, 2012: 1-22.
Manser, R., Gujer, W. and Siegrist, H. R. 2005. Membrane bioreactor versus
conventional activated sludge system: population dynamics of nitrifiers. Water
Sci Technol, 52: 417–425.
Mardis, E. R. 2008. Next-generation DNA sequencing methods. Annu Rev Genomics
Hum Genet, 9: 387-402.
Mbakwe, I., De Jager, P. C., Annandale, J. G. and Matema, T. 2013. Nitrogen
miniralization from sludge in an alkaline saline coal gasification ash
environment. J Environ Qual 42: 835–845.
McIlroy, S. J., Porter, K., Seviour, R. J. and Tillett, D. 2009. Extracting nucleic acids
from activated sludge which reflect community population diversity. Antonie
Van Leeuwenhoek, 96: 593-605.

145

McMahon, K. D., Gu, A. Z., Nerenberg, R. and Sturm, B. M. 2009. Molecular methods
in biological systems. Water Environ Res, 81: 986-1002.
Miller, K. M. 2011. Characterization of microbial nitrification and denitrification in
an urban Wisconsin marsh. MSc, University of Wisconsin-La Crosse.
Miura, Y., Hiraiwa, M. N., Ito, T., Itonaga, T., Watanabe, Y. and Okabe, S. 2007.
Bacterial community structures in MBRs treating municipal wastewater:
relationship between community stability and reactor performance. Water Res,
41: 627-37.
Mordorski, C. J. 1987. Process for protection of biological nitrification systems.
United States patent application 841,636.
Morozova, O. and Marra, M. A. 2008. Applications of next-generation sequencing
technologies in functional genomics. Genomics, 92: 255-264.
Mousavi, S. A., Ibrahim, S. and Aroua, M. K. 2014. Effect of carbon source on
acclimatization of nitrifying bacteria to achieve high-rate partial nitrification
of wastewater with high ammonium concentration. Appl Water Sci: doi:
10.1007/s13201-014-0229-z.
Mozumder, M. S., Picioreanu, C., van Loosdrecht, M. C. and Volcke, E. I. 2013. Effect
of heterotrophic growth on autotrophic nitrogen removal in a granular sludge
reactor. Environ Technol, 35: 1027-1037.
Mukherjee, M. 2013. Identification, enumeration and diversity of ammonia-oxidizing
archaea in the Laurentian great lakes. PhD, Bowling Green State University.
Mussmann, M., Brito, I., Pitcher, A., Sinninghe Damste, J. S., Hatzenpichler, R.,
Richter, A., Nielsen, J. L., Nielsen, P. H., Muller, A., Daims, H., Wagner, M.
and Head, I. M. 2011. Thaumarchaeotes abundant in refinery nitrifying sludges
express amoA but are not obligate autotrophic ammonia oxidizers. Proc Natl
Acad Sci U S A, 108: 16771-6.

146

Nasr, M., Ateia, M. and Hassan, K. 2015a. Artificial intelligence for greywater
treatment using electrocoagulation process. Separ Sci Technol: doi:
10.1080/01496395.2015.1062399.
Nasr, M., Mahmoud, A. E. D., Fawzy, M. and Radwan, A. 2015b. Artificial
intelligence modeling of cadmium(II) biosorption using rice straw Appl Water
Sci, doi: 10.1007/s13201-015-0295x.
Nasr, M., Moustafa, M., Seif, H. and El-Kobrosy, G. 2014. Application of fuzzy logic
control for Benchmark simulation model.1. Sustainable Environment
Research, 24: 235-243.
Nasr, M., Moustafa, M., Seif, H. and El Kobrosy, G. 2012. Application of artificial
neural network (ANN) for the prediction of EL-AGAMY wastewater treatment
plant performance-EGYPT. Alexandria Eng J, 51: 37-43.
Nguyen, H. T. and Sugeno, M. 2012. Fuzzy systems: modeling and control, Springer
Science & Business Media.
Nicol, G. W. and Schleper, C. 2006. Ammonia-oxidising Crenarchaeota: important
players in the nitrogen cycle? Trends Microbiol, 14: 207-212.
Nielsen, J. L. 2009. Protocol for fluorescence in situ hybridization (FISH) with rRNAtargeted oligonucleotides. In: Nielsen, P. H., Daims, H. and Lemmer, H. (eds.)
FISH handbook for biological wastewater treatment. London: IWA
Publishing.
Nielsen, P. H., Mielczarek, A. T., Kragelund, C., Nielsen, J. L., Saunders, A. M., Kong,
Y., Hansen, A. A. and Vollertsen, J. 2010. A conceptual ecosystem model of
microbial communities in enhanced biological phosphorus removal plants.
Water Res, 44: 5070-88.
Niu, J., Kasuga, I., Kurisu, F., Furumai, H., Shigeeda, T. and Takahashi, K. 2016.
Abundance and diversity of ammonia-oxidizing archaea and bacteria on
granular activated carbon and their fates during drinking water purification
process. Appl Microbiol Biotechnol, 100: 729-42.

147

Nogueira, R., Melo, L., Purkhold, U., Wuertz, S. and Wagner, M. 2002. Nitrifying and
heterotrophic population dynamics in biofilm reactors: effects of hydraulic
retention time and the presence of organic carbon. Water Res, 36: 469-481.
Nogueira, R. and Melo, L. F. 2006. Competition between Nitrospira spp. and
Nitrobacter spp. in nitrite-oxidizing bioreactors. Biotechnol Bioeng, 95: 16975.
Ozdemir, B., Mertoglu, B., Yapsakli, K., Aliyazicioglu, C., Saatci, A. and Yenigun,
O. 2011. Investigation of nitrogen converters in membrane bioreactor. J
Environ Sci Health, Part A, 46: 37-41.
Padmanabhan, S., Banerjee, S. and Mandi, N. 2011. Screening of Bacterial
recombinants: strategies and preventing false positives. In: Brown, G. (ed.)
Molecular Cloning - selected applications in medicine and biology Rijeka:
InTech.
Park, J., Byun, I., Park, S. and Park, D. 2008. Nitrifying bacterial communities and its
activities in aerobic biofilm reactors under different temperature conditions.
Korean J Chem Eng, 25 1448-1455.
Parmar, A. M., Patel, K. D., Doshi, N. S., Kapadiya, G. M., Patel, B. S. and Sen, D. J.
2014. Correlation approach between shotgun sequencing with DNA
sequencing in molecular genomics. World J pharm pharm sci, 3: 963-995.
Picard, C., Ponsonnet, C., Paget, E., Nesme, X. and Simonet, P. 1992. Detection and
enumeration of bacteria in soil by direct DNA extraction and polymerase chain
reaction. Appl Environ Microbiol, 58: 2717–2722.
Pramanik, N. and Panda, R. K. 2009. Application of neural network and adaptive
neuro-fuzzy inference systems for river flow prediction. Hydrol Sci J, 54: 247260.
Purkhold, U., Pommerening-Röser, A., Juretschko, S., Schmid, M. C., Koops, H. P.
and Wagner, M. 2000. Phylogeny of all recognized species of ammonia
oxidizers based on comparative 16S rRNA and amoA sequence analysis:

148

implications for molecular diversity surveys. Appl Environ Microbiol, 66:
5368-5382.
Quail, M. A., Smith, M., Coupland, P., Otto, T. D., Harris, S. R., Connor, T. R.,
Bertoni, A., Swerdlow, H. P. and Gu, Y. 2012. A tale of three next generation
sequencing platforms: comparison of Ion Torrent, Pacific Biosciences and
Illumina MiSeq sequencers. BMC Genomics, 13: 341.
Rajendhran, J. and Gunasekaran, P. 2008. Strategies for accessing soil metagenome
for desired applications. Biotechnol Adv, 26: 576-90.
Ramdhani, N. 2012. Detection and quantification of nitrifying bacteria from South
African biological nutrient removal plants. PhD, Durban University of
Technology.
Ramdhani, N., Kumar, S. and Bux, F. 2010. Impact of pre-treatments on nitrifying
bacterial community analysis from wastewater using fluorescent in situ
hybridization and confocal scanning laser microscopy. J Gen Appl Microbiol,
56: 101-106.
Ramdhani, N., Kumari, S. and Bux, F. 2013. Distribution of Nitrosomonas-related
ammonia-oxidizing bacteria and Nitrobacter-related nitrite-oxidizing bacteria
in two full-scale biological nutrient removal plants. Water Environ Res, 85:
374-381.
Ramond, J. B., Lako, J. D. W., Stafford, W. H. L., Tuffin, M. I. and Cowan, D. A.
2015. Evidence of novel plant-species specific ammonia oxidizing bacterial
clades in acidic South African fynbos soils. J Basic Microbiol: doi:
10.1002/jobm.201400933.
Rastogi, G. and Sani, R. K. 2011. Molecular techniques to assess microbial community
structure, function, and dynamics in the environment. In: Ahmad, I., Ahmad,
F. and Pichtel, J. (eds.) Microbes and Microbial Technology. New York:
Springer.

149

Roh, C., Villatte, F., Kim, B. G. and Schmid, R. D. 2006. Comparative study of
methods for extraction and purification of environmental DNA from soil and
sludge samples. Appl Biochem Biotech, 134: 97-112.
Ronaghi, M. 2001. Pyrosequencing sheds light on DNA sequencing. Genome Res, 11:
3-11.
Rowan, A. K., Snape, J. R., Fearnside, D., Barer, M. R., Curtis, T. P. and Head, I. M.
2003. Composition and diversity of ammonia-oxidising bacterial communities
in wastewater treatment reactors of different design treating identical
wastewater. FEMS Microbiol Ecol, 43: 195-206.
Ruiz, G., Jeison, D. and Chamy, R. 2003. Nitrification with high nitrite accumulation
for the treatment of wastewater with high ammonia concentration. Water Res,
37: 1371-1377.
Sajuni, N. R., Ahmad, A. L. and Vadivelu, V. M. 2010. Effect of filter media
characteristics, pH and temperature on the ammonia removal in the
wastewater. J Appl Sci, 10: 1146–1150.
Sambrook, J. and Russell, D. W. 2001. Gel electrophoresis of DNA and pulsed field
agarose gel electrophoresis. In: Sambrook, J. and Russell, D. W. (eds.)
Molecular cloning, a laboratory manual. New York, USA: Cold Spring
Harbour Laboratory Press.
Sanz, J. L. and Kochling, T. 2007. Molecular biology techniques used in wastewater
treatment: an overview Process Biochem 42 119–133.
Sarioglua, M., Insel, G., Artan, N. and Orhon, D. S. 2009. Model evaluation of
simultaneous nitrification and denitrification in a membrane bioreactor
operated without an anoxic reactor. J Membr Sci, 337: 17-27.
Schloss, P. D., Westcott, S. L., Ryabin, T., Hall, J. R., Hartmann, M., Hollister, E. B.,
Lesniewski, R. A., Oakley, B. B., Parks, D. H., Robinson, C. J. and Sahl, J. W.
2009. Introducing mothur: open-source, platform-independent, community-

150

supported software for describing and comparing microbial communities. Appl
Environ Microb, 75: 7537-7541.
Schmid, M. C., Maas, B., Dapena, A., van de Pas-Schoonen, K., van de Vossenberg,
J., Kartal, B., van Niftrik, L., Schmidt, I., Cirpus, I., Kuenen, J. G., Wagner,
M., Sinninghe Damste, J. S., Kuypers, M., Revsbech, N. P., Mendez, R., Jetten,
M. S. and Strous, M. 2005. Biomarkers for in situ detection of anaerobic
ammonium-oxidizing (anammox) bacteria. Appl Environ Microbiol, 71: 16771684.
Sciampacone, A. 2013. Matter pictured in its place: cholera and the slums of London.
Dandelion Postgrad Arts J Res Netw 4 1–19.
Sekar, S., Zintchem, A. A. E. A., Keshri, J., Kamika, I. and Momba, M. N. B. 2014.
Bacterial profiling in brine samples of the Emalahleni Water Reclamation
Plant, South Africa, using 454-pyrosequencing method. FEMS Microbiol Lett:
1-9.
Shan, G., JIN, W., Lam, E. K. H. and Xing, X. 2008. Purification of total DNA
extracted from activated sludge. J Environ Sci, 20: 80-87.
Shi, P., Jia, S., Zhang, X. X., Zhang, T., Cheng, S. and Li, A. 2013. Metagenomic
insights into chlorination effects on microbial antibiotic resistance in drinking
water. Water Res, 47: 111-20.
Shi, X. Y., Sheng, G. P., Li, X. Y. and Yu, H. Q. 2010. Operation of a sequencing
batch reactor for cultivating autotrophic nitrifying granules. Bioresour
Technol, 101: 2960-4.
Shokralla, S., Spall, J. L., Gibson, J. F. and Hajibabaei, M. 2012. Next-generation
sequencing technologies for environmental DNA research. Mol Ecol, 21:
1794-805.
Singka, D., Kumdhitiahutsawakul, L., Rekkriangkrai, P. and Pathom-aree, W. 2012.
A Simple method for DNA extraction from activated. Chaing Mai J Sci, 39:
111-118.

151

Siripong, S., Kelly, J. J., Stahl, D. A. and Rittmann, B. E. 2006. Impact of
prehybridization PCR amplification on microarray detection of nitrifying
bacteria in wastewater treatment plant samples. Environ Microbiol, 8: 156474.
Siripong, S. and Rittmann, B. E. 2007. Diversity study of nitrifying bacteria in fullscale municipal wastewater treatment plants. Water Res, 41: 1110-20.
Sonthiphand, P. and Limpiyakorn, T. 2010. Communities of ammonia-oxidizing
archaea and bacteria in enriched nitrifying activated sludge. World Acad Sci
Eng Technol, 64: 425-428.
Sorokin, D. Y., Lucker, S., Vejmelkova, D., Kostrikina, N. A., Kleerebezem, R.,
Rijpstra, W. I., Damste, J. S., Le Paslier, D., Muyzer, G., Wagner, M., van
Loosdrecht, M. C. and Daims, H. 2012. Nitrification expanded: discovery,
physiology and genomics of a nitrite-oxidizing bacterium from the phylum
Chloroflexi. ISME J, 6: 2245-56.
Spieck, E., Hartwig, C., McCormack, I., Maixner, F., Wagner, M., Lipski, A. and
Daims, H. 2006. Selective enrichment and molecular characterization of a
previously uncultured Nitrospira-like bacterium from activated sludge.
Environ Microbiol, 8: 405–415.
Stahl, D. A. and de la Torre, J. R. 2012. Physiology and diversity of ammoniaoxidizing archaea. Annu Rev Microbiol, 66: 83-101.
Stark, J. 1996. Modeling the temperature response of nitrification Biogeochem, 35:
433-445.
Steinberg, L. M. and Regan, J. M. 2009. mcrA-targeted real-time quantitative PCR
method to examine methanogen communities. Appl Environ Microbiol, 75:
4435-42.
Surmacz-Górska, J. 2000. Usuwanie zanieczyszczeń organicznych oraz azotu z
odcieków powstających w wysypiskach odpadów komunalnych (Removal of

152

organics and nitrogen from landfill leachate). Zeszyty Naukowe. Inżynieria
Środowiska/Politechnika Śląska: 1-149.
Tamura, K., Peterson, D., Peterson, N., Stecher, G., Nei, M. and Kumar, S. 2011.
MEGA5: molecular evolutionary genetics analysis using maximum likelihood,
evolutionary distance, and maximum parsimony methods. Mol Biol Evol, 28:
2731-2739.
Tamura, K., Stecher, G., Peterson, D., Filipski, A. and Kumar, S. 2013. MEGA6:
molecular evolutionary genetics analysis version 6.0. Mol Biol Evol, 30: 27252729.
Tarre, S. and Green, M. 2004. High-rate nitrification at low pH in suspended and
attached biomass reactors. Appl Environ Microb, 70: 6481-6487.
Tchobanoglous, G. and Burton, F. 1991. Wastewater engineering treatment, disposal
and reuse, New York, McGraw-Hill, .
Tchobanoglous, G., Burton, F. L. and Stensel, H. D. 2003. Wastewater engineering:
treatment and reuse, New York, Metcalf and Eddy Inc. McGraw- Hill, .
Thermoscientific

n.d.

Assessment

of

nucleic

acids

purity.

Nano

Drop

spectrophotometers. T042 - Technical Bulletin T042 Rev 1/11.
Trivedi, P., Sagaram, U. S., Kim, J. S., Brlansky, R. H., Rogers, M. E., Stelinski, L.
L., Oswalt, C. and Wang, N. 2009. Quantification of viable Candidatus
Liberibacter asiaticus in hosts using quantitative PCR with the aid of ethidium
monoazide (EMA). Eur J Plant Pathol, 124: 553-563.
Uan, D. K., Yeom, I. T., Arulazhagan, P. and Banu, J. R. 2013. Effects of sludge
pretreatment on sludge reduction in a lab-scale anaerobic/anoxic/oxic system
treating domestic wastewater. Int J Environ Sci Technol 10: 495–502.
UCR. 2016. Nucleic acid quality/concentration. University of Califonia Reagents
[Online].

Available:

153

http://cancer.ucsf.edu/research/cores/genome/services/genomeanalysisservice
analyze [Accessed 7/1/ 2016].
Urakawa, H., Tajima, Y., Numata, Y. and Tsuneda, S. 2008. Low temperature
decreases the phylogenetic diversity of ammonia-oxidizing archaea and
bacteria in aquarium biofiltration systems. Appl Environ Microbiol, 74 894–
900.
Valm, A. M., Mark Welch, J. L. and Borisy, G. G. 2012. CLASI-FISH: Principles of
combinatorial labeling and spectral imaging. Syst Appl Microbiol: doi:
10.1016/j.syapm.2012.03.004.
Varshney, R. K., Nayak, S. N., May, G. D. and Jackson, S. A. 2009. Next-generation
sequencing technologies and their implications for crop genetics and breeding.
Trends Biotechnol, 27: 522-30.
Vieno, N., Tuhkanen, T. and Kronberg, L. 2005. Seasonal Variation in the Occurrence
of Pharmaceuticals in Effluents from a Sewage Treatment Plant and in the
Recipient Water. Environ Sci Technol, 39: 8220-8226.
Wagner, M., Amann, R., Lemmer, H. and Schleifer, K. H. 1993. Probing activated
sludge with oligonucleotides specific for proteobacteria: inadequacy of
culture-dependent methods for describing microbial community structure.
Appl Environ Microbiol, 59: 1520-1525.
Wagner, M., Loy, A., Nogueira, R., Purkhold, U., Lee, N. and Daims, H. 2002.
Microbial Community composition and function in wastewater treatment
plants. Antonie Van Leeuwenhoek, 81: 665-680.
Wan, C. Y., De Wever, H., Diels, L., Thoeye, C., Liang, J. B. and Huang, L. N. 2011.
Biodiversity and population dynamics of microorganisms in a full-scale
membrane bioreactor for municipal wastewater treatment. Water Res, 45:
1129-38.

154

Wang, L., Zheng, Z., Luo, X. and Zhang, J. 2011. Performance and mechanisms of a
microbial-earthworm ecofilter for removing organic matter and nitrogen from
synthetic domestic wastewater. J Hazard Mater, 195: 245-53.
Wang, X., Wen, X., Criddle, C., Wells, G., Zhang, J. and Zhao, Y. 2010. Community
analysis of ammonia-oxidizing bacteria in activated sludge of eight wastewater
treatment systems. J Environ Sci, 22: 627–634.
Wang, X., Wen, X., Xia, Y., Hu, M., Zhao, F. and Ding, K. 2012. Ammonia oxidizing
bacteria community dynamics in a pilot-scale wastewater treatment plant.
PLoS One, 7: 1-7.
Wang, Y. F. 2013. Molecular analysis of ammonia oxidizing prokaryotes in mangrove
wetlands and factors affecting their dynamics. PhD Thesis, The University of
Hong Kong.
Wang, Z., Zhang, X.-X., Lu, X., Liu, B., Yan, L., Long, C. and Li, A. 2014. Abundance
and diversity of bacterial nitrifiers and denitrifiers and their functional genes
in tannery wastewater treatment plants revealed by high throughput
sequencing. PLoS One: 1-9.
Ward, B. B. 2013. Nitrification [Online]. Princeton, NJ, USA: Elsevier. Available:
https://www.princeton.edu/nitrogen/publications/pdfs/Ward_2015_Nitrificati
on.pdf [Accessed 10/23/ 2015 2015].
WEF 2009. Biological Nutrient Removal Processes In: Federation, W. E. (ed.)
Operation of Municipal Wastewater Treatment Plants: MoP No. 11. New
York: WEF Press.
WEF 2011. Nutrient Removal: WEF manual of practice No 34. ISBN:
9780071737098: McGraw-Hill Professional.
Wei, D., Xue, X., Chen, S., Zhang, Y., Yan, L., Wei, Q. and Du, B. 2013. Enhanced
aerobic granulation and nitrogen removal by the addition of zeolite powder in
a sequencing batch reactor Appl Microbiol Biotechnol 97: 9235–9243.

155

Whang, L. M., Chien, I. C., Yuan, S. L. and Wu, Y. J. 2009. Nitrifying community
structures and nitrification performance of full-scale municipal and swine
wastewater treatment plants. Chemosphere, 75: 234–242.
Whang, L. M., Wu, Y. J., Lee, Y. C., Chen, H. W., Fukushima, T., Chang, M. Y.,
Cheng, S. S., Hsu, S. F., Chang, C. Y. and Shen, W. 2012. Nitrification
performance and microbial ecology of nitrifying bacteria in a full-scale
membrane bioreactor treating TFT-LCD wastewater. Bioresour Technol, 122:
70-77.
Winkler, M. K., Bassin, J. P., Kleerebezem, R., Sorokin, D. Y. and van Loosdrecht,
M. C. 2012. Unravelling the reasons for disproportion in the ratio of AOB and
NOB in aerobic granular sludge. Appl Microbiol Biotechnol, 94: 1657-66.
Winkler, M. K., Le, Q. H. and Volcke, E. I. 2015. Influence of partial denitrification
and mixotrophic growth of NOB on microbial distribution in aerobic granular
sludge. Environ Sci Technol, 49: 11003-10.
Witzig, R., Manz, W., Rosenberger, S., Kruger, U., Kraume, M. and Szewzyk, U.
2002. Microbiological aspects of a bioreactor with submerged membranes for
aerobic treatment of municipal wastewater. Water Res, 36: 394-402.
Wojnowska-Baryla, I., Cydzik-Kwiatkowska, A. and Zielinska, M. 2010. The
application of molecular techniques to the study of wastewater treatment
systems. Methods Mol Biol, 599: 157–183.
Wu, P., JI, X., Song, X. and Shen, Y. 2014. Mechanism of efficient nutrient removal
and microbial analysis of a combined anaerobic baffled reactor–membrane
bioreactor process. Int J Environ Sci Technol, 11: 1611-1618.
Wu, Y. J., Whang, L. M., Chang, M. Y., Fukushima, T., Lee, Y. C., Cheng, S. S., Hsu,
S. F., Chang, C. H., Shen, W., Yang, C. Y., Fu, R. and Tsai, T. Y. 2013. Impact
of food to microorganism (F/M) ratio and colloidal chemical oxygen demand
on nitrification performance of a full-scale membrane bioreactor treating thin

156

film transistor liquid crystal display wastewater. Bioresour Technol, 141: 3540.
Xia, S., Duan, L., Song, Y., Li, J., Piceno, Y. M., Andersen, G. L., Alvarez-Cohen, L.,
Moreno-Andrade, I., Huang, C. L. and Hermanowicz, S. W. 2010a. Bacterial
community structure in geographically distributed biological wastewater
treatment reactors. Environ Sci Technol, 44: 7391-7396.
Xia, S., Li, J. and Wang, R. 2008. Nitrogen removal performance and microbial
community structure dynamics response to carbon nitrogen ratio in a compact
suspended carrier biofilm reactor. Ecol Eng, 32: 256-262.
Xia, S., Li, J., Wang, R., Li, J. and Zhang, Z. 2010b. Tracking composition and
dynamics of nitrification and denitrification microbial community in a biofilm
reactor by PCR-DGGE and combining FISH with flow cytometry. Biochem
Eng J, 49: 370-378.
Xiao, P., Cai, Q., Zhang, D., Yao, Z. and Lu, P. 2013. Characteristics of nitrogen
removal and nitrous oxide production in CANON process. J Chem Technol
Biotechnol, 89: 552-558.
Xu, M., Schnorr, J., Keibler, B. and Simon, H. M. 2012. Comparative analysis of 16S
rRNA and amoA genes from archaea selected with organic and inorganic
amendments in enrichment culture. Appl Environ Microbiol, 78: 2137-2146.
Yang, C., Zhang, W., Liu, R., Li, Q., Li, B., Wang, S., Song, C., Qiao, C. and
Mulchandani, A. 2011. Phylogenetic diversity and metabolic potential of
activated sludge microbial communities in full-scale wastewater treatment
plants. Environ Sci Technol, 45: 7408-15.
Yang, Q., Wang, J., Han, X., Xu, Y., Liu, D., Hao, H., Li, X., Guo, Y., Niu, T. and Qi,
S. 2014. Analysis of the bacterial community in a full-scale printing and dyeing
wastewater treatment system based on T-RFLP and 454 pyrosequencing.
Biotechnol Bioprocess Eng, 19: 191-200.

157

Yang, W., Xiang, F., Liang, L. and Yang, Z. 2010. Toxicity of ammonia and its effects
on oxidative stress mechanisms of juvenile crucian carp (Carassius auratus).
J Freshw Ecol, 25: 297–302.
Yao, S., Ni, J., Chen, Q. and Borthwick, A. G. 2013. Enrichment and characterization
of a bacteria consortium capable of heterotrophic nitrification and aerobic
denitrification at low temperature. Bioresour Technol, 127: 151-7.
Yapsakli, K., Aliyazicioglu, C. and Mertoglu, B. 2011. Identification and quantitative
evaluation of nitrogen-converting organisms in a full-scale leachate treatment
plant. J Environ Manage, 92: 714-23.
Ye, L., Shao, M. F., Zhang, T., Tong, A. H. and Lok, S. 2011. Analysis of the bacterial
community in a laboratory-scale nitrification reactor and a wastewater
treatment plant by 454-pyrosequencing. Water Res, 45: 4390-8.
Ye, L. and Zhang, T. 2013. Bacterial communities in different sections of a municipal
wastewater treatment plant revealed by 16S rDNA 454 pyrosequencing. Appl
Microbiol Biotechnol, 97: 2681-90.
You, J., Das, A., Dolan, E. M. and Hu, Z. 2009. Ammonia-oxidizing archaea involved
in nitrogen removal. Water Res, 43: 1801–1809.
You, S. J. and Lin, M. Y. 2008. Estimation of the Diversity of Denitrifying Bacteria in
a Membrane Bioreactor by PCR Amplification with nir Gene Probes. Environ
Eng Sci, 25: 1301-1310.
Yu, T., Li, D., Qi, R., Li, S. T., Xu, S. W. and Yang, M. 2011. Structure and dynamics
of nitrifier populations in a full-scale submerged membrane bioreactor during
start-up. Appl Microbiol Biotechnol, 90: 369-76.
Yu, T., Qi, R., Li, D., Zhang, Y. and Yang, M. 2010. Nitrifier characteristics in
submerged membrane bioreactors under different sludge retention times.
Water Res, 44: 2823–2830.

158

Zeng, Y., De Guardia, A., Ziebal, C., De Macedo, F. J. and Dabert, P. 2012.
Nitrification and microbiological evolution during aerobic treatment of
municipal solid wastes. Bioresour Technol, 110: 144-52.
Zhang, B., Sun, B., Ji, M. and Liu, H. 2009a. Population dynamic succession and
quantification of ammonia-oxidizing bacteria in a membrane bioreactor
treating municipal wastewater. J Hazard Mater, 165: 796-803.
Zhang, B., Sun, B., Ji, M., Liu, H. and Liu, X. 2010. Quantification and comparison
of ammonia-oxidizing bacterial communities in MBRs treating various types
of wastewater. Bioresour Technol, 101: 3054-3059.
Zhang, H., Zhai, H., Ji, M., Su, X., Du, Z. and Liu, J. 2014. Long-term effect of Cr(VI)
on ammonia-oxidizing and nitrite-oxidizing bacteria in an activated sludge
system. Desalin Water Treat: doi : 10.1080/19443994.2014.893208.
Zhang, L., Jiang, J., Yang, J., Hira, D. and Furukawa, K. 2012a. High rate nitrogen
removal by the CANON process at ambient temperature. Water Sci Technol 65
1826-1833.
Zhang, T., Shao, M. F. and Ye, L. 2012b. 454 pyrosequencing reveals bacterial
diversity of activated sludge from 14 sewage treatment plants. ISME J, 6: 113747.
Zhang, T., Ye, L., Tong, A. H., Shao, M. F. and Lok, S. 2011a. Ammonia-oxidizing
archaea and ammonia-oxidizing bacteria in six full-scale wastewater treatment
bioreactors. Appl Microbiol Biotechnol, 91: 1215-25.
Zhang, Y., Chen, L., Sun, R., Dai, T., Tian, J. and Wen, D. 2015. Ammonia-oxidizing
bacteria and archaea in wastewater treatment plant sludge and nearby coastal
sediment in an industrial area in China. Appl Microbiol Biotechnol, 99: 4495507.
Zhang, Y., Zhou, J., Guo, J., Zhang, X., Zhao, L. and Yuan, S. 2011b. Study on nitrite
accumulation characteristics and nitrifying population dynamics at different
growth environments. Int J Biol Life Sci, 7: 65-69.

159

Zhang, Y., Zhou, J., Zhang, J. and Yuan, S. 2009b. An innovative membrane
bioreactor and packed-bed biofilm reactor combined system for shortcut
nitrification-denitrification. J Environ Sci, 21: 568-574.
Zheng, Y., Hou, L., Liu, M., Lu, M., Zhao, H., Yin, G. and Zhou, J. 2013. Diversity,
abundance, and activity of ammonia-oxidizing bacteria and archaea in
Chongming eastern intertidal sediments. Appl Microbiol Biotechnol 97: 8351–
8363.
Zhu, X., Tian, J., Liu, C. and Chen, L. 2013. Composition and dynamics of microbial
community in a zeolite biofilter-membrane bioreactor treating coking
wastewater. Appl Microbiol Biotechnol, 97: 8767-75.

160

APPENDICES

APPENDIX ONE: Reagents preparation for thermo scientific™ gallery™
automated photometric analyzer (vantaa, finland)
A.

TOTAL OXIDISED NITROGEN (TON)

Principle: Nitrate was reduced to nitrite by hydrazine under alkaline conditions. The
total

nitrite

ions

are

then

reacted

with

sulphanilamide

and

N-1-

naphthylethylenediamine dihydrochloride under acidic conditions to form a pink azodye. The absorbance was measured at 540nm and was related to the TON
concentration by means of a calibration curve.
Stock Solutions Reagent Preparation
Sodium Hydroxide (Reagent 1): 0.8g Sodium Hydroxide (NaOH) was dissolved in
100ml of distilled water. This solution was stable for 1 day.
Reductant (Reagent 2): 0.325g of hydrazine sulphate N2H4.H2SO4 was dissolved in
400ml distilled water. 0.75ml of stock copper sulphate solution and 5ml of zinc
sulphate was adde and maked up to 500ml with distilled water. This solution was stable
for 1 month.
Stock Solutions required for Reductant:
Copper Sulphate Solution: 0.78g CuSO4.5H2O dissolved in 200ml of distilled water.
This solution was stable for 1 month.
Zinc Sulphate Solution: 9.0g Zinc Sulphate was dissolved in 200ml distilled water.
This solution was stable for 1 month.
Colour Reagent (Reagent 3): 50ml of concentrated Phosphoric acid (HP3O4) was
carefully added to 500ml of distilled water. 5g of sulphanilamide was added and
dissolved

completely

before

adding

0.25g

N-(1-naphthyl)-ethylenediamine

161

dihydrochloride. Then diluted to 1000ml with distilled water, stored in an amber bottle
between 2 - 8C. This solution was stable for 1 month.
TON Standard Solution: Dissolve 1.6306g of dried Potassium Nitrate (KNO3) in
1000ml volumetric flask of distilled water. Stored between 2 - 8C this solution was
stable for 1 month.
Measurement: Concentration was measured using Thermo Gallery photometric
analyser (Thermo Scientific, UK)

B) NITRITE (NO2)
Principle: Diazotization of sulphanilamide by nitrite in the presence of Phosphoric
acid, at 1.9 pH and the subsequent formation of an azo dye with N-1naphthylethylenediamine (NEDD). The absorbance of this compound was measured
spectrophotometrically at 520nm and was related to the nitrite by means of a
calibration curve.
Stock Solutions Reagent Preparation
Colour Reagent: 50ml of concentrated Phosphoric acid (HP3O4) was carefully added
to 500ml of distilled water. 5g of sulphanilamide was added and dissolve completely
before adding 0.25g N-(1-naphthyl)-ethylenediamine dihydrochloride. Then, diluted
to 1000ml with distilled water, stored in an amber bottle between 2-8C. This solution
was stable for 1 month.
Nitrite Standard Solution 100mg/l: 0.493g of dried sodium nitrite (NaNO2) was
dissolved in 1000ml distilled water.
Measurement: Concentration was measured using Thermo Gallery photometric
analyser (Thermo Scientific, UK)

162

C) AMMONIA NITROGEN (NH3–N).
Principle: Ammonia reacts with hypochlorite ions generated by the alkaline hydrolysis
of sodium dichloroisocyanurate to form monochloramine. This reacts with salicylate
ions in the presence of sodium nitroprusside at around pH 12.6 to form a blue
compound. The absorbance of this compound was measured spectrophotometrically
at wavelength 660nm and was related to the ammonia concentration by means of a
calibration curve.

Stock Solutions Reagent Preparation
Sodium Salicylate Solution (Reagent 1): 65g of Sodium Salicylate [C7H5O3Na] and
65g of tri-Sodium Citrate [C6H5Na3O7.2H2O] was dissolved in 400ml ammonia free
deionised water, the pH was adjusted to less 8.0 of necessary with 0.4% Nitric acid.
0.49g of Sodium Nitroprusside [Na2[Fe(CN)5NO].2H2O] was added, dissolved and
maked up to 500ml with ammonia free deionised water. This solution was stable for 1
month.
D.I.C Solution (Reagent 2): 16g Sodium Hydroxide [NaOH] was dissolved in 250ml
ammonia free deionised water. Cooled and 1.0g of Sodium Dichloroisocyanurate
[Cl2Na(NCO)3.2H2O] as added, allowed to dissolve and make up to 500ml with
ammonia free deionised water. This solution was stable for 1 month.
Ammonia Standard Solution – 1000mg/l as N: 3.819g of dried Ammonium Chloride
(NH4 Cl) was dissolved in 1000ml of ammonia free water. Stored between 2 - 8C, the
solution was stable for 1 month.
Measurement: Concentration was measured using Thermo Gallery photometric
analyser (Thermo Scientific, UK)

163

APPENDIX TWO: Determination of total chemical oxygen demand (cod) in
wastewater sample
Procedure
Water samples for analysis were collected in bottles from the sampling points of both
full and pilot-scale UASB reactors. The closed reflux colorimetric method (APHA,
1998) with was used. The COD concentration in the wastewater was determined
according to the standard method 5220D, microwave digestion (Milestone Start D,
Sorisole, Italy) was first used to digest the samples at 150 °C for 1 h in COD vials
containing the Digestion Solution (0–15,000 mg COD/L). Then, the concentration was
measured using Aquakem Gallery discrete autoanalyser (Thermo Scientific, UK).
Five millilitre sample was measured and transferred into a microwave Teflon tube.
The Teflon tube was inserted into the microwave safety vessel. Three millilitre (3ml)
of digestion solution (0.01667M, K2Cr2O7) and 7 ml of sulphuric acid reagent were
carefully added to the sample. The sample was carefully mixed, tightly capped and
digested at 150oC for 55 minutes using the microwave digester (Milestone Start D,
Sorisole, Italy). Standard were prepared and blank reagent was also digested with the
sample as control. After cooling, the solution was transferred into Gallery cuvettes for
colorimetric analysis using the Thermo Gallery photometric analyser. Results were
recorded in mg/L.

164

APPENDIX THREE:

Fluorescent in- situ hybridisation

1 x Phosphate-Buffered saline (PBS)
8g NaCl
0.2g KCl
1.44g Na2HPO4
0.24g KH2PO4
All components were dissolved in distilled water, made up to 1000ml and pH was
adjusted to 7.4 and autoclaved.
Paraformaldehyde (4%)
65 ml Distilled water
4g Paraformaldehyde
2M NaOH
Distilled water was heated to 60˚C. Paraformaldehyde was added. One drop 2M NaOH
was added and stirred rapidly until solution clarified. This was removed from heat and
33 ml of 3 x PBS was added. The pH was adjusted to 7.2 with HCl, filtered and cooled
cool down to 4˚C. This solution was made up fresh for each use.
Cell Fixation
1 x PBS
Paraformaldehyde
Ethanol

165

Procedure: The samples were washed twice with 1 x PBS. Three volumes 4%
paraformaldehde was used with 1 volume of sample for Gram negative bacteria, whilst
one volume of ethanol was used with one volume of sample for Gram positive bacteria.
This was stored at 4˚C for 1-3 hrs. This was centrifuged and supernatants were discarded.
Pellets were washed twice with 1 x PBS. Supernatant were discarded. To store, the
pellets was resuspended in 1 x PBS. (50% of original sample volume) and absolute
ethanol (50% of original sample volume). This was stored at -20˚C for further analysis.

Pre-treatment of Microscope Slides
Teflon-coated slides were cleaned by soaking in diluted Poly-L-Lysine solution (1:10Sigma Diagnostics, USA) for 15 minutes at room temperature
Solutions:
(1:10) Poly – L – Lysine (Sigma diagnostics, U.S.A. Procedure no. P8920)
Allow solution to reach room temperature (18 - 26˚C) before use.
Dilute 1:10 with dH2O.

Procedure:


Clean slide surface by soaking in a warm soap solution for 1 h, rinse thoroughly
with dH2O and air dry.



Immerse clean slides in diluted (1:10) Poly-L-Lysine solution for 10 min.



Drain Poly-L-Lysine solution from slide and dry in an oven for one hour at 60˚C
or at room temperature overnight.



Store treated slide in a sealed container.

166

Cell dispersion using sonication
Introduction:
The sludge was compact and thick. In order to get to all cells in the sludge, it is often
necessary to disperse the cells by sonication using a sonicator at low frequency, after
paraformaldehyde fixation.
Procedure:


Fill a 2 mL Eppendoff tube with 1 mL fixed sample.



In order to prevent spillage of the sample, slightly cover the opening of the
Eppendoff tube with the cover.



Insert the probe so that the tip of the probe is approximately 1 cm above the base
of the Eppendoff tube and sonicate 8 watts for 5 to 10 min for an ML =2500 3000

Immobilization of fixed microbial cells on treated microscope slides
Procedure:


Dilute sonicated sample in ddH2O



Spot 10 µL of sonicated sample onto each well of a pre-treated microscope slide.



Allow the spots to air dry



Dehydrate the spots through successive passages through 50%, 80% and 100% v/v
ethanol washes (lasting 3 min each).



Subsequently slides can be stored dry at room temperature in a desiccators
indefinitely.

Calculation of working probe dilution
Since 50 ng of probe is required per hybridization and 10 µL of hybridization solution
is required per spot, a working concentration of 5 ng/µL is used.

167

M1V1

=

M2 V2

(840 ng/µL)(1 µL)

=

(5ng/µL)(V2)

=

(840 ng/µL X 1 µL) / 5ng/µL

V2

164 µL hyb buffer + 1 µL probe
Therefore 16 hybridizations can be performed using 10 µL of probe/hybridization
solution (containing 50 ng of probe) per hybridization.

Hybridization Solution (pH 7.2; 20%)
5.26g NaCl
0.24g Tris
0.01 SDS
0.16g EDTA
20 ml fortunately*
All components were dissolved in 80 ml distilled water. Formamide was added and
solutions were made up to a final volume of 100 ml.
*All chemical and quantities remained constant for all percentages of hybridization
solutions. Only the formamide concentration changes as per the percentage required.
E.g. 30% hybridisation solutions will require 30 ml formanide.

Wash Buffer
2.42g Tris
1.86g EDTA
0.1g SDS

168

12.56g 5M NaCl (20% wash buffer)
8.76g (25%)
6.55g (30%)
4.68g (35%)
3.27g (40%)
2.33g (45%)
NaCl was added to 1ml 1M Tris-HCl, 50µl 10% SDS, sterile distilled water and made
up to 50 ml. Add 5M NaCl according to the breakdown above, 1 Ml of 1M Tris/HCl, 50
µl 10% SDS, sterile distilled water to make up to 50 ml.
5M NaCl stock solution
2150µl

(20%)

1020

(30%)

700

(35%)

460

(40%)

300

(45%)

Oligonucleotide Probe Preparation
Probes were thawed and centrifuged at 3000 rpm for 1 minute. Probes were removed (10
µl) and placed in sterile Eppendorf tubes (stock). Stock probes were then further
distributed (1 µl) into sterile Eppendorf tubes and stored at -20˚C until required.

169

Whole cell hybridisation


Strips of fitter paper were soaked in the appropriate hybridisation solutions and
placed in polypropylene chambers.



The hybridization chamber were prepared by inserting filter paper in into 50ml
falcon tube and pour the remaining buffer in the tube for it to soak, cover tube
with foil to protect from light.



Immediately slide were transferred into hybridisation chambers and incubated
for overnight at 46˚C.



Probe/buffer mixture (10 µl) were placed on each well.



Slide were then placed in the pre-warmed chamber and incubated to allow
hybridisation at 46˚C for 2 h.



Slides from the oven were gently wash twice using pre-warmed (48°C) wash
buffer and the slide were inserted into the remaining wash buffer and incubate at
48°C for 2 h.



Slides were washed twice with ddH2O and air dried. DAPI solution (10 µl) was
placed over each well and allowed to stain for 10 minutes in the dark.



Slides were subsequently wash with ddH2O and air dried.



Vectashield (1 drop) was added to each well, covered with a cover-slip and sealed
with clear varnish around the edges to prevent movement of the cover-slip and
escape of the Vectashield.

170

APPENDIX FOUR: Publications

171

172

1
Picture Gesture Authentication: Empirical Analysis, Automated
Attacks, and Scheme Evaluation
ZIMING ZHAO, Arizona State University
GAIL-JOON AHN, Arizona State University
HONGXIN HU, Clemson University

Picture gesture authentication has been recently introduced as an alternative login experience to text-based
password on touch-screen devices. In particular, the newly on market Microsoft Windows 8TM operating
system adopts such an alternative authentication to complement its traditional text-based authentication.
We present an empirical analysis of picture gesture authentication on more than 10,000 picture passwords
collected from over 800 subjects through online user studies. Based on the findings of our user studies, we
propose a novel attack framework that is capable of cracking passwords on previously unseen pictures in
a picture gesture authentication system. Our approach is based on the concept of selection function that
models users’ thought processes in selecting picture passwords. Our evaluation results show the proposed
approach could crack a considerable portion of picture passwords under different settings. Based on the
empirical analysis and attack results, we comparatively evaluate picture gesture authentication using a set
of criteria for a better understanding of its advantages and limitations.
Categories and Subject Descriptors: D.4.6 [Operating Systems]: Security and Protection
General Terms: Security
Additional Key Words and Phrases: Picture gesture authentication, empirical analysis, automated attacks,
scheme evaluation
ACM Reference Format:
ACM Trans. Info. Syst. Sec. 1, 1, Article 1 (January 1), 39 pages.
DOI:http://dx.doi.org/10.1145/0000000.0000000

1. INTRODUCTION

Using text-based passwords that include alphanumerics and symbols on touch-screen
devices is unwieldy and time-consuming due to small-sized screens and the absence
of physical keyboards. Consequently, mobile operating systems, such as iOS and Android, integrate a numeric Personal Identification Number (PIN) and a draw pattern
as alternative authentication schemes to provide user-friendly login services. However,
the password spaces of these schemes are significantly smaller than text-based passwords, rendering them less secure and easy to break with some knowledge of device
owners [Bonneau et al. 2012d].
Many graphical password schemes–including DAS [Jermyn et al. 1999],
Face [Brostoff and Sasse 2000], Story [Davis et al. 2004], PassPoints [Wiedenbeck et al.
2005a] and BDAS [Dunphy and Yan 2007]–have been proposed in the past decade (for
more, please refer to [Dhamija and Perrig 2000; Thorpe and Van Oorschot 2004; Suo
Authors’ addresses: Z. Zhao, Arizona State University, Tempe, USA; G.-J. Ahn (corresponding author), Arizona State University, Tempe, USA; H. Hu, Clemson University, Clemson, USA.
A preliminary version of this paper appears in Proceedings of the 22nd Usenix Security Symposium, 2013.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for profit or commercial advantage and that
copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights
for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component
of this work in other works requires prior specific permission and/or a fee. Permissions may be requested
from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212)
869-0481, or permissions@acm.org.
c 1 ACM 1094-9224/1/01-ART1 $15.00
⃝
DOI:http://dx.doi.org/10.1145/0000000.0000000
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:2

Z. Zhao, G.-J. Ahn and H. Hu

et al. 2005; Chiasson et al. 2007; Gao et al. 2008; Bicakci et al. 2009; Biddle et al.
2011; Chiasson et al. 2012]). As an outcome of these research efforts, the Windows
8TM operating system comes with a picture password authentication system, namely
picture gesture authentication (PGA) [Johnson et al. 2012], which is an instance of
background draw-a-secret (BDAS) schemes [Dunphy and Yan 2007]. This new authentication mechanism hit the market with miscellaneous computing devices including
personal computers and tablets [Microsoft 2013]. Consequently, it is imperative to examine the user experiences and potential attacks of this new scheme to understand its
advantages and limitations.
To understand user experiences in PGA, we collect more than 10,000 PGA passwords
from over 800 subjects through online user studies with a span of several months. We
provide an empirical analysis of the collected passwords. In particular, we are interested in how subjects choose background pictures, where they prefer to draw gestures,
and what gesture orders and types they like to use. Our findings from user-chosen
passwords show interesting patterns which are consistent with previous research investments on click-based scheme passwords [Chiasson et al. 2009; Van Oorschot et al.
2010; van Oorschot and Thorpe 2011], in which password composition patterns and
predictable characteristics were found. In addition, we present memorability analysis
results on passwords that were collected over months.
Harvesting characteristics from passwords of a target picture and exploiting hotspots and geometric patterns on the target picture have been proven effective for attacking click-based schemes [Dirik et al. 2007; Thorpe and Van Oorschot 2007; SalehiAbari et al. 2008]. However, PGA allows complex gestures other than a simple click.
Moreover, a new feature in PGA, autonomous picture selection by users, makes it unrealistic to harvest passwords from the target pictures for learning. In other words,
the target picture is previously unseen to any attack models. All existing attack approaches lack a generic knowledge representation of user choice in password selection
that should be abstracted from specific pictures. The absence of this abstraction makes
existing attack approaches impossible or abysmal (if possible) to work on previously
unseen target pictures.
To attack PGA passwords, we propose a new attack framework that represents and
learns users’ password selection patterns from training datasets and generates ranked
password dictionaries for previously unseen target pictures. To achieve this, we build
generic knowledge of user choices from the abstraction of hot-spots in pictures. The
core of our framework is the concept of a selection function that simulates users’ selection processes in choosing their picture passwords. Our approach is not coupled with
any specific pictures. Hence, the generation of a ranked password list is then transformed into the generation of a ranked selection function list which is then executed
on the target pictures. We present two algorithms for generating the selection function list: one algorithm is to appropriately develop an optimal guessing strategy for a
large-scale training dataset and the other deals with the construction of high-quality
dictionaries even when the size of the training dataset is small. We also discuss the
implementation of our attack framework over PGA, and evaluate the efficacy of our
proposed approach with the collected datasets.
To further examine the benefits and limitations of PGA, we evaluate if it also provides benefits that other authentication schemes offer based on results from user experience studies and attack evaluations. We consider four categories of criteria, which are
usability, deployability, security, and privacy (UDSP). Our evaluation criteria are extended from the usability-deployability-security evaluation framework [Bonneau et al.
2012b], which was designed to evaluate web authentication schemes. To explain the
newly introduced benefits, we evaluate four legacy authentication schemes, which consists of text-based passwords, Persuasive Cued Click-Points (PCCP) [Chiasson et al.
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation 1:3
Choose Picture

Draw Gestures

Record Password

Compare Passwords

User chooses a picture as
background image

User draws three gestures
on the picture

The order, size, position, and
direction of the gestures
become the password

The input password is
compared with the registered
one in login attempt

a

b

c

d

Fig. 1: Key Steps in Picture Gesture Authentication
2012], Fingerprint, and RSA SecurID. We also evaluate and compare the other two
popular authentication schemes on touch-screens, namely draw pattern and PIN using our extended evaluation framework.
The contributions of this paper are summarized as follows:
— We compile two datasets of PGA usage from user studies1 and perform an empirical
analysis on collected data to understand user choice in background picture, gesture
location, gesture order, and gesture type;
— We introduce the concept of a selection function that abstracts and models users’
selection processes when selecting their picture passwords. We demonstrate how selection functions can be automatically identified from training datasets;
— We propose and implement a novel attack framework based on selection functions.
We evaluate our attack framework using two attack models, namely nontargeted
attack and targeted attack; and
— We comparatively evaluate PGA using a new UDSP evaluation framework that is
extended from the UDS authentication evaluation framework by considering more
usability, security, and privacy benefits.
The rest of this paper is organized as follows. Section 2 gives an overview of picture gesture authentication. Section 3 discusses our empirical analysis on passwords
of picture gesture authentication that were collected from two online studies. In Section 4, we illustrate the idea of using selection functions to model users’ password
creation processes and build an attack framework based on it. Section 5 presents the
implementation details of our proposed attack framework. Section 6 presents the evaluation results of nontargeted attacks. Section 7 presents the evaluation results of targeted attacks. Section 8 presents a usability-deployability-security-privacy evaluation
framework and comparative evaluation results of picture gesture authentication. We
discuss several research issues in Section 9 followed by the related work in Section 10.
Section 11 concludes the paper.
2. AN OVERVIEW OF PICTURE GESTURE AUTHENTICATION

Figure 1 shows the key steps of using picture gesture authentication. Like other login
systems, Windows 8TM PGA has two independent phases, namely registration and authentication. In the registration stage, a user chooses a picture from his or her local
storage as the background as shown in Figure 1(a). PGA does not force users to choose
pictures from a predefined repository. Even though users may choose pictures from
common folders, such as the Picture Library folder in Windows 8TM , the probability
for different users to choose an identical picture as the background for their passwords
is low. This phenomenon requires potential attack approaches to have the ability to
perform attacks on previously unseen pictures. PGA then asks the user to draw ex1 These

datasets with the detailed information is available at http://sefcom.asu.edu/pga/.

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:4

Z. Zhao, G.-J. Ahn and H. Hu

Table I: Password Space Comparison with Different Schemes
Length
1
2
3
4
5

Draw Pattern∗
9
56
360
2,280
14,544

4-digit PINs∗⋆•
10
100
1,000
10,000
100,000

Text-based Password∗⋆•
90
8,100
729,000
65,610,000
5,904,900,000

Used in ∗ Android, ⋆ iOS, • Windows 8.

Table II: Password Space Comparison with PGA
Length
1
2
3
4
5

tap
270
23,535
2,743,206
178,832,265
15,344,276,658

Picture Password• [Pace 2011a]
line
circle
335
1,949
34,001
846,183
4,509,567
412,096,718
381,311,037
156,687,051,477
44,084,945,533 70,441,983,603,740

combined
2,554
1,581,773
1,155,509,083=230.1
612,157,353,732
398,046,621,309,172

actly three gestures on the picture with his or her finger, mouse, stylus, or other input
devices depending on the equipment he or she is using as illustrated in Figure 1(b). A
gesture could be viewed as the cursor movements between a pair of ‘finger-down’ and
‘finger-up’ events. PGA does not allow free-style gestures, but only accepts tap (indicating a location), line (connecting areas or highlighting paths), and circle (enclosing
areas) [Pace 2011a]. If the user draws a free-style gesture, PGA will convert it to one
of the three recognized gestures. For instance, a curve would be converted to a line and
a triangle or oval will be stored as a circle. To record these gestures, PGA divides the
longest dimension of the background image into 100 segments and the short dimension
on the same scale to create a grid, then stores the coordinates of the gestures. The line
and circle gestures are also associated with additional information such as directions
of the finger movements as shown in Figure 1(c).
Once a picture password is successfully registered, the user may login the system by
drawing corresponding gestures instead of typing his or her text-based password. PGA
first brings the background image on the screen that the user chose in the registration
stage. Then, the user should reproduce the drawings he or she set up as his or her
password. PGA compares the input gestures with the previously stored ones from the
registration stage as shown in Figure 1(d). The comparison is not strictly rigid but
shows tolerance to some extent. If any of gesture type, ordering, or directionality is
wrong, the authentication fails. When they are all correct, an operation is further taken
to measure the distance between the input password and the stored one. For tapping,
the gesture passes authentication if the predicate 12 − d2 ≥ 0 satisfies, where d denotes
the distance between the tap coordinates and the stored coordinates. The starting and
ending points of line gestures and the center of circle gestures are measured with the
same predicate [Pace 2011a].
The differences between PGA and the first BDAS scheme proposed in [Dunphy and
Yan 2007] include: i) in PGA, a user uploads his or her picture as the background
instead of choosing one from a predefined picture repository; ii) a user is only allowed to draw three specific types of gestures in PGA, while BDAS takes any form
of strokes. The first difference makes PGA more secure than the previous scheme, because a password dictionary could only be generated after the background picture is
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation 1:5

acquired. However, the second characteristic reduces the theoretical password space
from its counterpart.
Accurate estimation of the password space of PGA needs some detailed information, such as the circle radius tolerance, that is not disclosed. Therefore, the password
space calculation presented here is taken from [Pace 2011a], where Pace et al. quantified the size of theoretical password space of PGA and compared it with other password schemes. As shown in Table I, the password space for PGA is much bigger than
other schemes given the same password length. Pace et al. also considered the cases
in which users only draw on some point-of-interests in the picture. Table II shows the
password space with different number of point-of-interests. If a picture has twenty
point-of-interests, its password space is 227.7 which is larger than text-based password
with the length four.
3. AN EMPIRICAL ANALYSIS OF PICTURE GESTURE AUTHENTICATION PASSWORDS

In this section, we present an empirical analysis on user choice in PGA by analyzing
data collected from our user studies. Our empirical study is based on human cognitive
capabilities. Since human cognition of pictures is limited in a similar way to their cognition of texts, the picture passwords selected by users are probably constrained by human cognitive limits which would be similar to the ones in text-based passwords [Yuille
1983].
3.1. Experiment Design

For the empirical study, we developed a web-based PGA system for conducting user
studies. The developed system resembles Windows 8TM PGA in terms of its workflow
and appearance. The differences between our implementation and Windows 8TM PGA
include: i) our system works with major browsers in desktop PCs and tablets whereas
Windows 8TM PGA is a stand-alone program; ii) some information, such as the criterion for circle radius comparison, is not disclosed. In other words, our implementation
and Windows 8TM PGA differ in some criteria (we regard radiuses the same if their
difference is smaller than 6 segments in grid). In addition, our developed system has
a tutorial page that includes a video clip educating how to use the system and a test
page on which users can practice gesture drawings.
Our study protocol, including the type of data we plan to collect and the questionnaire we plan to use, was reviewed by our institution’s IRB. The questionnaire consisted of four sections: i) general information of the subject (gender, age, level of education received, and race); ii) general feeling toward PGA (is it easier to remember,
faster to input, harder to guess, and easier to observe than text-based password); iii)
selection of background picture (preferred picture type); and iv) selection of password
(preferred gesture location and type).
We started user studies after receiving the IRB approval letter in August 2012 and
compiled two datasets from August 2012 to January 2013 using this system. Dataset-1
was acquired from a testbed of picture password used by an undergraduate computer
science class. Dataset-2 was produced by advertising our studies in schools of engineering and business in two universities and Amazon’s Mechanical Turk crowdsourcing
service that has been used in security-related research work [Kelley et al. 2012]. Turkers who had finished more than 50 tasks and had an approval rate greater than 60%
were qualified for our user study.
For registration, subjects in Dataset-1 were asked to provide their student IDs for a
simple verification after which they were guided to upload a picture, register a password and then use the password to access class materials including slides, homework,
assignments, and projects. Subjects used this system for the Fall 2012 semester which
lasted three and a half months at our university. If subjects forgot their passwords
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:6

Z. Zhao, G.-J. Ahn and H. Hu
243.jpg

316.jpg

1116.jpg

1358.jpg

2057.jpg

2080.jpg

2840.jpg

3026.jpg

3721.jpg

4054.jpg

5570.jpg

6412.jpg

6467.jpg

7628.jpg

9899.jpg

Fig. 2: Background Pictures Used in Dataset-2
during the semester, they would inform the teaching assistant who reset their passwords. Subjects were allowed to change their passwords by clicking a change password
link after login. There were 56 subjects involved in Dataset-1 resulting in 58 unique
pictures, 86 registered passwords, and 2,536 login attempts.
Instead of asking subjects to upload pictures for Dataset-2, we chose 15 pictures as
shown in Figure 2. in advance from the PASCAL Visual Object Classes Challenge 2007
dataset2 . We chose these pictures because they represent a diverse range of pictures
in terms of category (portrait, wedding, party, bicycle, train, airplane and car) and
complexity (pictures with few and plentiful stand-out regions). Subjects were asked to
choose one password for each picture by pretending that it was protecting their bank
information. The 15 pictures were presented to subjects in a random order to reduce
the dependency of password selection upon the picture presentation order. 762 subjects
participated in the Dataset-2 collection resulting in 10,039 passwords. The number of
passwords for each picture in the Dataset-2 varies slightly, with an average of 669,
because some subjects quit the study without setting up passwords for all pictures.
For both datasets, subjects were asked to finish the aforementioned questionnaire
to help us understand their experiences. We collected 685 (33 for Dataset-1, 652 for
Dataset-2) copies of survey answers in total. According to the demographic-related inquiries in the exit survey, 81.8% subjects in Dataset-1 are self-reported male and 63.6%
are between 18 and 24 years old. While participants in Dataset-2 are more diverse with
64.4% male, 37.2% among 18 to 24 years old, 45.4% among 25 - 34, and 15.0% among
35 - 50. Even though the subjects in our studies do not represent all possible demographics, the data collected from them represents the most comprehensive PGA usage
so far. Their tendencies could provide us with significant insights into the user choice
in PGA.
3.2. Findings

This section summarizes our empirical analysis on the above-mentioned datasets by
presenting five findings.
Finding 1. Relationship Between Background Picture and User’s Identity, Personality, or Interests.
2 http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation 1:7

Table III: Survey Question: Which of the following best describes what you are considering when you choose locations to perform gestures?
Multi-choice Answers
I try to find locations where special objects are,
such as head, eye, clock, car, badge, etc.
I try to find locations where some special shapes
are, such as circle and line, etc.
I try to find locations where colors are different
from their surroundings, such as a red apple in
a green lemon pile, etc.
I randomly choose a location to draw without
thinking about the background picture.

1
24
(72.7%)
8
(24.2%)
0 (0%)

Dataset
2
389
(59.6%)
143
(21.9%)
57
(8.7%)

Overall
413
(60.3%)
151
(22.1%)
57
(8.3%)

1
(3.0%)

66
(10.1%)

67
(9.8%)

We analyzed all unique pictures3 in Dataset-1, and the background pictures chosen by
subjects range from celebrity to system screenshot. We categorize them into six classes:
i) people (27/58), ii) civilization (7/58), iii) landscape (3/58), iv) computer-generated
picture (14/58), v) animals (6/58), and vi) others (1/58).
For the category of ‘people’, 6 pictures were categorized as ‘me’; 12 pictures were
subjects’ families; 4 were pictures of subjects’ friends; and 5 were celebrities. The analysis of answers to the survey question “Could you explain why you choose such types
of pictures?” revealed two opposite attitudes towards using picture of people. The advocates for such pictures considered: i) it is more friendly. e.g. “The image was special
to me so I enjoy seeing it when I log in”; ii) it is easier for remembering passwords. e.g.
“Marking points on a person is easier to remember”; and iii) it makes password more
secure. e.g. “The picture is personal so it should be much harder for someone to guess
the password”. However, other participants believed it may leak his or her identity or
privacy. e.g. “revealing myself or my family to anyone who picks up the device”. They
preferred other types of pictures because “less personal if someone gets my picture” and
“landscape usually doesn’t have any information about who you are”.
14 pictures in Dataset-1 could be categorized as computer-generated pictures including computer game posters, cartoons, and some geometrical graphs. 24.1% (14/58) of
such pictures were observed in Dataset-1 but the survey results indicated 6.4% (42/652)
of participants were in such a usage pattern in Dataset-2 based on the following survey
question: “Please indicate the type of pictures you prefer to use as the background”. We
concluded the population characteristics (male, age 18-24, college students) in Dataset1 were the major reason behind this phenomenon. The answers to “Could you explain
why you choose such types of pictures?” in Dataset-1 supported this conjecture: “computer game is something I am interested [in] it” and “computer games picture is personalized to my interests and enjoyable to look at”.
It is obvious that pictures with personally identifiable information may leak personal information. However, it is less obvious that even pictures with no personally
identifiable information may provide some clues which may reveal the identity or persona of a device owner. Traditional text-based password does not have this concern
as long as the password is kept secure. Previous graphical password schemes, such
as Face and PassPoints, do not have this concern either because pictures are selected
from a predefined repository.
Finding 2. Gestures on Points of Interest.
3 Due

to the confidentiality agreement with the subjects, we are not able to share pictures that are marked
having personally identifiable information.

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:8

Z. Zhao, G.-J. Ahn and H. Hu

Table IV: Attributes of Most Frequently Used PoIs
Attributes
Eye
Nose
Hand/Finger
Jaw
Face (Head)

# Gesture
36
21
6
5
4

# Password
20
13
5
3
2

# Subject
19
10
4
3
2

1

2

(a)

(b)

Fig. 3: Two Versions of Starry Night and Corresponding Passwords
The security of background draw-a-secret schemes mostly relies on the location distribution of users’ gestures. It is the most secure if the locations of users’ gestures
follow a uniform distribution on any picture. However, such passwords would be difficult to remember and may not be preferable by users. By analyzing the collected
passwords, we notice that subjects frequently chose standout regions (points of interest, PoIs) on which to draw. As shown in Table III, only 9.8% subjects claimed to choose
locations randomly without caring about the background picture. The observation is
supported by survey answers to “Could you explain the way you choose locations to perform gestures?”: “If I have to remember it; it [would] better stand out.” and “Something
that would make it easier to remember”.
Even though the theoretical password space of PGA is larger than text-based passwords with the same length, a background picture affects user choice in gesture location, reducing the feasible password space tremendously. We summarize three popular
ways that subjects used to identify standout regions: i) finding regions with objects.
e.g. “I chose eyes and other notable features” and “I chose locations such as nose, mouth
or whole face”; ii) finding regions with remarkable shapes. e.g. “if there is a circle there
I would draw a circle around that”; and iii) finding regions with outstanding colors.
The detailed distribution of these selection processes is shown in Table III. 60.3% of
subjects prefer to find locations where special objects catch their eyes while 22.1% of
subjects would rather draw on some special shapes.
Finding 3. Similarities Across Points of Interest.
We analyzed the attributes of PoIs that users preferred to draw on. We paid more
attention to the pictures of people because it was the most popular category. In the 31
registered passwords for the 27 pictures of people uploaded by 22 subjects in Dataset-1,
we analyzed the patterns of PoI choice. As shown in Table IV, 36 gestures were drawn
on eyes and 21 gestures were drawn on noses. Other locations that attracted subjects
to draw included hand/finger, jaw, face (head), and ear. Interestingly, 19 subjects out
of 22 (86.3%) drew on eyes at least once, while 10 subjects (45.4%) performed gestures
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation 1:9

Table V: Numbers of Gesture-order Patterns
Dataset1
Dataset2

H+
43
50.0%
3144
31.3%

H5
5.8%
1303
12.9%

V+
16
18.6%
1479
14.7%

V4
4.6%
887
8.8%

DIAG
22
25.5%
2621
26.1%

Others
18
20.9%
3326
33.1%

on noses. The tendencies to choose similar PoIs by different subjects are common in
other picture categories as well. Figure 3 shows another example where two subjects
uploaded two versions of Starry Night in Dataset-1. The passwords they chose show
strikingly similar patterns with three taps on stars, even if there is no single gesture
location overlap.
Finding 4. Directional Patterns in PGA Password.
Salehi-Abari et al. [Salehi-Abari et al. 2008] suggest many passwords in click-based
systems follow some directional patterns. We are interested in whether PGA passwords show similar characteristics. For simplicity, we consider the coordinates of tap
and circle gestures as their locations and the middle point of the starting and ending
points of line as its location. If the x or y coordinate of a gesture sequence follows a
consistent direction regardless of the other coordinate, we say the sequence follows
a LINE pattern. We divide LINE patterns into four categories: i) H+, denoting leftto-right (xi ≤ xi+1 ); ii) H-, denoting right-to-left (xi ≥ xi+1 ); iii) V+, denoting top-tobottom (yi ≤ yi+1 ); and iv) V-, denoting bottom-to-top (yi ≥ yi+1 ). If a sequence of
gestures follows a horizontal pattern and a vertical pattern at the same time, we say
it follows a DIAG pattern.
We examined the occurrence of each LINE and DIAG pattern in the collected data.
As shown in Table V, more than half passwords in both datasets exhibited some LINE
patterns, and a quarter of them exhibited some DIAG patterns. Among four LINE
patterns, H+ (drawing from left to right) was the most popular one with 50.0% and
31.3% occurrences in Dataset-1 and Dataset-2, respectively. And, V+ (drawing from
top to bottom) was the second most popular with 18.6% and 14.7% occurrences in two
datasets, respectively. This finding shows it is reasonable to use gesture-order patterns
as one heuristic factor to prioritize generated passwords.
Finding 5. Time Disparity among Different Combinations of Gesture Types.
We analyzed all registered passwords to understand the gesture patterns and the
relationship between gesture type and input time. For 86 registered passwords (258
gestures) in Dataset-1, 212 (82.1%) gesture types were taps, 39 (15.1%) were lines, and
only 7 (2.7%) were circles. However, the corresponding occurrences for 10,039 registered passwords (30,117 gestures) in Dataset-2 were 15,742 (52.2%), 10,292 (34.2%),
and 4,083 (13.5%), respectively. Obviously, subjects in Dataset-2 chose more diverse
gesture types than subjects in Dataset-1. As shown in Table VI, there was a strong
connection between the time subjects spent on reproducing passwords and the gesture
types they chose. Three taps, the most common gesture combination, appeared in both
datasets with the lowest average time (5.74 seconds and 4.33 seconds in corresponding dataset). On the other hand, the passwords with two circles and one line took the
longest average input time (10.19 seconds in Dataset-2). In the user studies, subjects
in Dataset-2 were asked to set up the passwords by pretending they were protecting
their bank information. However, subjects in Dataset-1 actually used these passwords
to access the class materials which they accessed more than four times a week on avACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:10

Z. Zhao, G.-J. Ahn and H. Hu

Table VI: Numbers of Gesture Type Combinations and Average Time Spent on Creating Them
#
Average Time (Seconds)
#
Average Time (Seconds)

Dataset-1
Dataset-2

#
Average Time (Seconds)
#
Average Time (Seconds)

Dataset-1
Dataset-2

3×t
60
5.74
3438
4.33
2×l+t
7
11.17
1000
7.72

3×l
3
12.39
1447
7.11
2×l+c
1
17.51
622
9.98

3×c
0
N/A
253
9.96
2×c+t
0
N/A
192
8.78

2×t+l
9
10.12
1211
6.02
2×c+l
0
N/A
442
10.19

2×t+c
1
21.56
380
6.14
t+l+c
5
11.22
1054
9.37

Average Time Spent (Seconds)

550

Number of Passwords

500
450
400
350
300
250
200
150
100
50
0

0

2

4

6

8

10

Password Distance (<10)

(a) Password Distance Histogram

12

10

8

6

4

2

0
0

2

4

6

8

10

12

Registration(1) Confirmation(2) Successful Logins(3−12)

(b) Average Time Spent (Seconds)

Fig. 4: Memorability and Usability
erage. This may be a reason why subjects in Dataset-1 prefer passwords with simpler
gesture type combinations that are easier to reproduce in a timely manner.
3.3. Memorability and Usability Analysis

The tolerance introduced in PGA is a trade-off between security and usability. In order
to quantify this tradeoff, we calculate the distance between input PGA passwords with
the registered ones. When the types or directions of gestures do not match, we regard
input passwords incomparable with the registered ones. Otherwise, the distance is
defined as the average distance of all gestures.
In the 2,536 login attempts collected in Dataset-1, 422 are unsuccessful in which 146
are type or direction errors and 276 are distance errors. Figure 4(a) shows the distance
distribution for the password whose distance is less than 10 and the red line denotes
the threshold for being classified as successful. The result shows the current setup in
our system is quite reasonable to capture most closely presented passwords.
Figure 4(b) shows the average time in seconds that subjects spent on registering,
confirming, and reproducing passwords. x = 1 denotes the registration, x = 2 denotes
the conformation, and all others denote the later login attempts. As we can notice, the
average time for the registration is 7.43 seconds while 4.53 seconds are taken for the
confirmation. With subjects getting used to the picture password system, the average
time spent for successful logins is reduced to as low as 2.51 seconds. On the other hand,
the average time spent on all unsuccessful login attempts is 5.86 seconds.
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:11
4. ATTACK FRAMEWORK

In this section, we present an attack framework on Windows 8TM picture gesture authentication, leveraging the findings addressed in Section 3. Our attack framework
takes the target picture’s PoIs, a set of learning pictures’ PoIs and corresponding password pairs as input, and produces a list of possible passwords, which is ranked in the
descending order of the password probabilities.
Next, we first discuss the attack models followed by the representations of picture
password and PoI. We then illustrate the idea of a selection function and its automatic
identification. We also present two algorithms for generating a selection function sequence list and describe how it can generate picture password dictionaries for previously unseen target pictures.
4.1. Attack Models

Depending on the resources an attacker possesses, we articulate three different attack
models: i) Pure Brute-force Attack: an attacker blindly guesses the picture password
without knowing any information of the background picture and the users’ tendencies. The password space in this model is 230.1 in PGA [Pace 2011a]. ii) PoI-assisted
Brute-force Attack: an attacker assumes the user only performs drawings on PoIs of
the background picture and this model randomly guesses passwords on identified PoIs.
The password space for a picture with 20 PoIs in this model is 227.7 [Pace 2011a].
Salehi-Abari et al. [Salehi-Abari et al. 2008] designed an approach to automatically
identify hot-spots in a picture and generate passwords on them. iii) Knowledge-based
PoI-assisted Attack: in addition to the assumption for PoI-assisted brute-force attack,
an attacker ought to have some knowledge about the password patterns learned from
collected picture and password pairs (not necessarily from the target user or picture).
The guessing space in this model is the same as the one in PoI-assisted brute-force
attack. However, the generated dictionaries in this model are ranked with the higher
possibility passwords on the top of the list.
Attack schemes could also be divided into two categories based on whether or not an
attacker has the ability to attack previously unseen pictures. The method presented
in [Salehi-Abari et al. 2008] is able to attack previously unseen pictures for click-based
graphical password. It uses click-order heuristics to generate partially ranked dictionaries. However, this approach can not be applied directly to background draw-a-secret
schemes because the gestures allowed in such schemes are much more complex and the
order-based heuristics could not capture users’ selection processes accurately. In contrast, our attack framework could abstract generic knowledge of user choice in picture
password schemes. In addition, as a working knowledge-based PoI-assisted model, it is
able to generate ranked dictionaries for previously unseen pictures.
Based on the data origin the attacker harvests from users, we categorize two attack
mode: in nontargeted attack mode, the training dataset does not consist of any picture
and password pair from the target user. The guessing path carried out for a nontargeted attack is not contingent on the knowledge of target user’s individual tendencies,
but based on the habits of users in training dataset; and, in targeted attack mode, the
attacker has possession of some picture and password pairs collected from the target user. Hence, the guessing path is more specific to the target user. Our algorithms
support both attack modes.
4.2. Password and PoI Representations

We first formalize the representation of a password in PGA with the definition of a
location-dependent gesture which represents a single gesture on some locations in a
picture.
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:12

Z. Zhao, G.-J. Ahn and H. Hu
Selection processes
[Pace 2011b]

1

2

3

Gesture 1:“Circle my father’s
head”

LdGSF 1: Circle a head
i.e., s(circle, {head}, Ф)

Gesture 2:“Connect my little
sister’s nose to my older sister’s
nose”

LdGSF 2: Line two noses
i.e., s(line, {nose}, {nose})

Gesture 3:“Tap my mother’s nose”
(a)

LdGSF

(b)

LdGSF 3: Tap a nose
i.e., s(tap, {nose}, Ф)
(c)

Fig. 5: (a) Background picture and password (b) User’s selection processes that were
taken from (c) Corresponding LdGSFs that simulate user’s selection processes
Definition 1. A location-dependent gesture (LdG) denoted as π is a 7-tuple
⟨g, x1 , y1 , x2 , y2 , r, d⟩ that consists of gesture’s type, location, and other attributes.
In this definition, g denotes the type of LdG that must be one of tap, line, and circle.
A tap LdG is further represented by the coordinates of a gesture ⟨x1 , y1 ⟩. A line LdG
is denoted by the coordinates of the starting and ending points of a gesture ⟨x1 , y1 ⟩
and ⟨x2 , y2 ⟩. A circle LdG is denoted by the coordinates of its center ⟨x1 , y1 ⟩, radius r,
and direction d ∈ {+, −} (clockwise
or∪not). We define the password space of location∪
dependent gesture as Π = Πtap Πline Πcircle . A valid PGA password is a length-three
⃗
sequence of LdGs denoted as ⃗π , and the PGA password space could be denoted as Π.
A point of interest is a standout region in a picture. PoIs could be regions with
semantic-rich meanings, such as face (head), eye, car, clock, etc. Also, they could stand
out in terms of their shapes (line, rectangle, circle, etc.) or colors (red, green, blue,
etc.). We denote a PoI by the coordinates of its circumscribed rectangle and some describing attributes. A PoI is a 5-tuple ⟨x1 , y1 , x2 , y2 , D⟩, where ⟨x1 , y1 ⟩ and ⟨x2 , y2 ⟩ are
the coordinates of the top-left and bottom-right points of the circumscribed rectangle,
and D ⊆ 2D is a set of attributes that describe this PoI. D has three sub-categories
Do , Ds and Dc and four wildcards ∗o , ∗s , ∗c , and ∗, where Do = {head, eye, nose, ...},
Ds = {line, rectangle, circle, ...}, and Dc = {red, blue, yellow, ...}. Wildcards are used
when no specific information is available. For example, if a PoI is identified with objectness measure [Alexe et al. 2012] that gives no semantics about the identified region,
we mark the PoI’s describing attribute as ∗.
4.3. Location-dependent Gesture Selection Functions

A key concept in our framework is the location-dependent gesture selection function
(LdGSF) which models and simulates the ways of thinking that users go through when
they select a gesture on a picture. The motivation behind this abstraction is that the set
of PoIs and their locations differ from picture to picture, but the ways that users think
to choose locations for drawing a gesture exhibit certain patterns. This conjecture is
supported by our observations from collected data and surveys discussed in Section 3.
With the help of LdGSF, the PoIs and corresponding passwords in training pictures
are used to generalize picture-independent knowledge that describes how users choose
passwords.
Definition 2. A location-dependent gesture selection function (LdGSF) is a mapping
s : G × 2D × 2D × Θ → 2Π which takes a gesture, two sets of PoI attributes, and a set of
PoIs in the learning picture as input to produce a set of location-dependent gestures.
The universal set of LdGSF is defined as S. A length-three sequence of LdGSF is
⃗ We use
denoted as ⃗s, and a set of length-three LdGSF sequences is denoted as S.
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:13
PoIs

1

2

3

(a)

PoI 1: <4, 23, 21, 46, {head}>
PoI 2: <23, 3, 43, 28, {head}>
PoI 3: <46, 19, 63, 43, {head}>
PoI 4: <71, 12, 90, 35, {head}>
PoI 5: <13, 33, 18, 37, {nose}>
PoI 6: <32, 17, 34, 19, {nose}>
PoI 7: <51, 31, 56, 35, {nose}>
PoI 8: <76, 24, 81, 28, {nose}>
$
$
...
(b)

Password

LdG 1: <circle, 33, 15, 0, 0, 9, - >
LdG 2: <line, 54, 34, 79, 27, 0, 0>
LdG 3: <tap, 16, 35, 0, 0, 0, 0>

(c)

Fig. 6: (a) Background picture and identified PoIs (b) Identified PoIs (c) Password representations (Colors are used to indicate the connections between the PoIs in (b) and
LdGs in (c))

Θ to denote the universal set of image PoIs and θk to denote the PoIs of picture
pk . s(tap, {red, apple}, ∅, θk ) is interpreted as ‘tap a red apple in the picture pk ’ and
s(circle, {head}, ∅, θk ) as ‘circle a head in pk ’. Note that, no specific information of the
locations of ‘red apple’ and ‘head’ is provided here which makes the representations
independent from actual locations of objects in the picture.
One challenge we face is some PoIs may be big enough to take several unique gestures. Let us consider a picture with a big car image in it. Simply saying ‘tap a car’
could result in lots of distinct tap gestures in the circumscribed rectangle of the car.
One solution to this problem is to divide the circumscribed rectangle into a grid with
the scale of toleration threshold. However, this solution would result in too many password entries in the generated dictionary. For simplicity, we introduce five inner points
for one PoI, namely center, top, bottom, left, and right that denote the center of the PoI
and four points of the center of two consecutive corners. Any gesture that falls into the
proximities of these five points of a PoI would be considered as an action on this PoI.
For some PoIs that are big enough to take an inner line gesture, we put ∅ as the input
of the second set of PoI attributes. s(line, {mouth}, ∅, θk ) denotes ‘line from the left(right)
to the right(left) on the same mouth’. While, s(line, {mouth}, {mouth}, θk ) means ‘connect
two different mouths’.
Figure 5 shows an example demonstrating how LdGSF simulates a user’s selection
processes that were taken from [Pace 2011b]. In reality, a user’s selection process on a
PoI and gesture selection may be determined by some subjective knowledge and cognition. For example, ‘circle my father’s head’ and ‘tap my mother’s nose’ may involve
some undecidable computing problems. One solution to handle this issue is to approximate subjective selection processes in objective ways by including some modifiers. ‘circle my father’s head’ may be transformed into ‘circle the uppermost head’ or ‘circle the
biggest head’. However, it is extremely difficult, if not impossible, to accurately approximate subjective selection processes in this way, and it may bring serious over-fitting
problems in the learning stage. Instead, we choose to ignore subjective information by
abstracting ‘circle my father’s head’ to ‘circle a head’. A drawback of this abstraction
is that an LdGSF may return more than one LdG and we have no knowledge to rank
them directly, as they come from the same LdGSF. Using Figure 5(a) as an example,
‘circle a head’ outputs four different LdGs on each head in the picture. The LdGSF
sequence shown in Figure 5(c) generates 4 × (4 × 3) × 4 = 192 passwords. To cope with
this issue, we use gesture-order to rank the passwords generated by the same LdGSF
sequence that will be detailed in Section 4.5. Next, we present an automated approach
to extract users’ selection processes from the collected data and represent them with
LdGSFs.
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:14

Z. Zhao, G.-J. Ahn and H. Hu

Definition 3. LdGSF identification is a process that can be denoted as a function
e : Θ × Π → 2S , where ∀s ∈ e(θk , π), π ∈ s(θk ). The function takes the PoIs of a picture
and one LdG in its corresponding password as input, and generates a set of LdGSFs
which could reproduce the same LdG on the picture.
Figure 6 shows an example demonstrating that how to extract users’ selection processes from PoIs automatically. First, PoIs in the background picture are identified
using mature computer vision techniques such as object detection, feature detection
and objectness measure. Then, each LdG in a password is compared with PoIs based
on their coordinates and sizes. If a match between PoIs and LdGs is found, a new
LdGSF is created as the combination of the LdG’s gesture type and PoI’s attributes.
For instance, the location and size of LdG 1 in Figure 6(c) matches PoI 2 in Figure 6(b)
(the locations of the circle gesture and PoI center are compared first; then, the radius of the circle is compared with 1/2 of PoI’s height and width). Then, an LdGSF
s(circle, {head}, ∅) is created which is equivalent to the LdG shown in Figure 5(c).
To choose a password in PGA, the user selects a length-three LdGSF sequence. With
the definition of LdGSF, the generation of ranked password list is simplified into the
⃗ → {1..|S|}
⃗ be a bijection
generation of the ranked LdGSF sequence list. Let order: S
which indicates the order LdGSF sequences should be performed. The objective of generating ranked LdGSF sequence list is to find such a bijection.
4.4. LdGSF Sequence List Generation and Ordering

Now we present our approach to find the aforementioned bijection that indicates the
order that the LdGSF sequences should be performed on a target picture for generating the password dictionary. Our framework is not dependent on certain rules, but
is adaptive to the tendencies shown by users who participate in the training set. The
characteristic of adaptiveness helps our framework generate dedicated guessing paths
for different training data. Next, we present two algorithms for obtaining such a feature.
4.4.1. BestCover LdGSF Sequence List Generation. We first propose an LdGSF sequence
list generation algorithm named BestCover that is derived from B mssc [Feige et al.
2004] and Bemts [Zhang et al. 2010]. The objective of BestCover LdGSF sequence list
generation is to optimize the guessing order for the sequences in the list by minimizing
the expected number of sequences that need to be tested on a random choice of picture
in the training dataset.
The problem is formalized as follows: Instance: The collection of LdGSF sequences
s⃗1 , ..., s⃗n and corresponding picture password π⃗1 ,...,π⃗n , for which s⃗i (θi ) ∋ π⃗i , i ∈ {1..n}
and θ1 , .., θn are the sets of PoIs in pictures p1 , .., pn . Question: Expected Min Selection
Search (emss): The objective is to find order so as to minimize E(min{i : ⃗si (θr ) ∋ π⃗r },
where s⃗i = order−1 (i) and the expectation is taken with respect to a random choice of
r ← {1..n}. We use coveremss (k) = min⃗s:⃗s(θk )∋π⃗k (orderemss (⃗s)) to compute the number
of required guesses to break π⃗k . Therefore, E(min{i : ⃗si (θr ) ∋ π⃗r } is equivalent to
E(coveremss (r)).
The hardness of this problem is that different LdGSFs and LdGSF sequences may
generate the same list of LdGs and passwords. For instance, ‘tap a red object’ and
‘tap an apple’ turn out the same result on a picture in which there is a red apple. An
overlap in different LdGSF results is similar to the coverage characteristics in the set
cover problem. We can prove the NP-hardness of emss by reducing from mssc [Feige
et al. 2004; Zhang et al. 2010]. Min Sum Set Cover (mssc)
∪ is formalized as follows:
Given a set U and a collection C of subsets of U where C∈C = U , let ordermssc :
C → {1..|C|} be a bijection, and let covermssc : U → {1..|C|} be defined by covermssc (j) =
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:15

min
∑ C∋j (ordermssc (C)). The problem is called min sum, because the object is to minimize
j∈U covermssc (j).
Given any instance (U, C) of mssc, denote U = {1..n}. We create a set of PoIs θj
and a picture password π⃗j for each j ∈ U . θj and π⃗j must be different from θk and π⃗k
respectively for any k ̸= j . For each C ∈ C, we create an LdGSF sequence s⃗C such
that s⃗C (θj ) ∋ π⃗j if j ∈ C and such that s⃗C (θj ) = ϕ if j ̸∈ C. We can always construct
such an LdGSF sequence for each C by combining all θj , j ∈ C as a new PoI type
⃗ consists of the set of s⃗C for different C. Set
in a wildcard representation. The set S
ordermssc (C) ←orderemss (s⃗C ), then
E(coveremss (r))
n
∑
=
i × P r(coveremss (r) = i)
i=1

=

n
∑

i×

|k ∈ {1..n} : coveremss (k) = i|
n

i×

|j ∈ U : covermssc (j) = i|
n

i=1

=

n
∑
i=1

The number of picture passwords that are
cracked for the first time at the ith guess divided by the total number of picture passwords

∑ covermssc (j)
=
n
j∈U

∑Therefore, orderemss minimizes E(coveremss (r)) if and only if ordermssc minimizes
j∈U covermssc (j). We give an approximation algorithm for emss in Algorithm 1 that
is a modification from B mssc [Feige et al. 2004] and B emts [Zhang et al. 2010]. The time
complexity of BestCover is O(n2 + |S⃗′ |log(|S⃗′ |)).
ALGORITHM 1: BestCover((s⃗1 , .., s⃗n ),(π⃗1 ,...,π⃗n ))
for i = 1..n do
Ts⃗i ← {k : s⃗i (θk ) ∋ π⃗k };
end
S⃗′ ← {⃗s : |T⃗s | > 0};
for i = 1..|S⃗′ | do
∪
order−1 (i)← s⃗k , that Ts⃗k has most elements that are not included in i′ <i order−1 (i′ );
end
return order

BestCover is good for a training dataset that consists of comprehensive and large
scale password samples, because it assumes the target passwords exhibit same or at
least very similar distributions to the training data. However, if the training dataset
is small and biased, the results from BestCover may over-fit the training data and fail
in testing data.
4.4.2. Unbiased LdGSF Sequence List Generation. The over-fitting problem in BestCover
is brought about by the biased PoI attribute distributions in training data. For example, we have a training set with 9 pictures of apples and 1 picture of a car, and 5
corresponding passwords have circles on apples and 1 has a circle on car. In the generated LdGSF sequence list, BestCover will put sequences with ‘circle an apple’ prior
to the ones with ‘circle a car’, because the former ones have an LdGSF that was used
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:16

Z. Zhao, G.-J. Ahn and H. Hu

in more passwords. However, we can see the probability for users to circle car (1/1) is
higher than apples (5/9) if we consider the occurrences of apple and car in pictures.
Unbiased LdGSF sequence list generation copes with this issue by considering the
PoI attribute distributions. It removes the biases from the training dataset by normalizing the occurrences of LdGSFs with the occurrences of their corresponding PoIs. Let
Ds⃗k ⊆ θ denote the event that θ contains enough PoIs that have attributes specified in
s⃗k . If a PoI with a specific type of attributes does not exist in a picture, the probability
that a user selects the PoI with such an attribute on this picture to draw a password
is 0, denoted as P r(s⃗k |Ds⃗k ⊆ θ) = 0, e.g. a user would not think and perform ‘tap a red
apple’ on a picture without the existence of the red apple. We assume each LdGSF in
a sequence is independent of each other and approximately compute P r(s⃗k |Ds⃗k ⊆ θ)
with Equation 1.
P r(s⃗k |Ds⃗k ⊆ θ)
= P r(s1 s2 s3 |Ds1 ⊆ θ ∧ Ds2 ⊆ θ ∧ Ds3 ⊆ θ)
= P r(s1 |Ds1 ⊆ θ) × P r(s2 |Ds2 ⊆ θ) × P r(s3 |Ds3 ⊆ θ)

(1)

For each si ∈ S, we compute P r(si |Dsi ⊆ θ) with Equation 2:
∑n
⃗j )
j=1 count(Dsi , π
P r(si |Dsi ⊆ θ) = ∑n
(2)
j=1 count(Dsi , θj )
∑n
where j=1 count(Dsi , π⃗j ) denotes the number of LdGs in passwords of the training set
∑n
that share the same attributes with si , and j=1 count(Dsi , θj ) denotes the number of
PoIs in the training set that share the same attributes with si . P r(si |Dsi ⊆ θ) describes
the probability of using a certain LdGSF when there are enough PoIs with the required
attributes.
The Unbiased algorithm generates an LdGSF sequence list by ranking P r(s⃗k |Ds⃗k ⊆
θ) instead of P r(s⃗k ) in descending order as shown in Algorithm 2. The time complexity
⃗
⃗
of Unbiased is O(n|S| + |S|log(|
S|)).
The Unbiased algorithm would be better for the
scenarios where fewer samples are available or samples are highly biased.
ALGORITHM 2: Unbiased(S)
for s ∈ S do
Compute P r(s|Ds ⊆ θ) with Equation 2;
end
⃗ do
for ⃗s ∈ S
Compute P r(⃗s|D⃗s ⊆ θ) with Equation 1;
end
⃗ do
for i = 1..|S|
order−1 (i)← s⃗k , that P r(s⃗k |Ds⃗k ⊆ θ) holds the i-th position in the descending ordered P r(⃗s|D⃗s ⊆ θ)
list;
end
return order

4.5. Password Dictionary Generation

The last step in our attack framework is to generate the password dictionary for a
previously unseen target picture. First, the PoIs in the previously unseen picture are
identified. Then, a dictionary is acquired by applying the LdGSF sequences on the
PoIs, following the order created by the BestCover or Unbiased algorithm. Obviously,
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:17

the passwords generated by an LdGSF sequence that holds a higher position in the
LdGSF sequence list will also be in higher positions in the dictionary. However, as
addressed earlier, BestCover and Unbiased algorithms do not provide extra information
to rank the passwords generated by the same LdGSF sequence. Inspired by using
the click-order patterns as the heuristics for dictionary generation [Salehi-Abari et al.
2008], we propose to rank such passwords generated by the same LdGSF sequence
with gesture-orders. In the training stage, we record the gesture-order occurrence of
each LINE and DIAG pattern and rank the patterns in descending order. In the attack
stage, for the passwords generated by the same LdGSF sequence, we reorder them
with their gesture-orders in the order of LINE and DIAG patterns. Passwords that do
not belong to any LINE or DIAG pattern hold lower positions.
5. IMPLEMENTATION AND LDGSF IDENTIFICATION

We adopted several computer vision techniques to identify sophisticated and salient
objects in the images. Some techniques were implemented in Matlab code, whereas
some were implemented under the OpenCV4 framework. The computer vision techniques we adopted include:
I) Object detection: the goal of object detection is to find the locations and sizes of
semantic objects of a certain class in a digital image. We used the method described in
object detection with discriminatively trained part based models [Felzenszwalb et al.
2010]. The latest version of its Matlab code release at the time of writing [Girshick
et al. 2010] include trained models for 21 object classes that are commonly found in
the images of the PASCAL Visual Object Classes Challenge 2007 dataset. These models are trained to detect aeroplane, bicycle, bird, boat, bottle, bus, car, cat, chair, cow,
dining table, dog, horse, motorbike, person, potted plant, sheep, sofa, train, and tv monitor objects. The actual detection is performed by calling function imgdetect of the code
release with parameters threshold=-0.6. To complement this effort, we also used the
Viola-Jones object detection framework [Viola and Jones 2004]. In the Viola-Jones object detection framework, each learned classifier is represented as a haar cascade. We
collected 30 proven haar cascades5 for 8 different object classes including face (head),
eye, nose, mouth, ear, forehead, body, and clock. The actual detection is performed by
calling OpenCV API cvHaarDetectObjects with parameters scaleFactor=1.1 and minNeighbors=4;
II) Salient object detection and objectness measure: since the PoIs in our attack
framework could be any local image regions that could be of interest to human users,
we also resort to visual saliency and salient object detection techniques, for which the
analyses and comparisons of models can be found in [Borji et al. 2012; Borji et al. 2013].
We used the discriminative regional feature integration approach described in [Jiang
et al. 2013] for its ease of use and outstanding performance recorded in the aforementioned two analyses reports. For complementary approach, we used objectness measure [Alexe et al. 2012] that deals with class-generic object detection. We used an objectness measure library6 that is able to locate objects and give numerical confidence
values with its results;
III) Low-level feature detection: due to the high positive and high negative rates
of object detection, we also resorted to some low-level feature detection algorithms
that identify standout regions without extracting semantics. To identify regions whose
colors are different from their surroundings, we first converted the color pictures to
black and white, then found the contours using algorithms in [Suzuki 1985]. For the
4 http://opencv.willowgarage.com
5 http://alereimondo.no-ip.org/OpenCV/34
6 http://groups.inf.ed.ac.uk/calvin/objectness/

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:18

Z. Zhao, G.-J. Ahn and H. Hu

(a)

(b)

(c)

(d)

(e)

Fig. 7: PoI Identification on Example Pictures in Dataset-2: (a) Original pictures (b)
Circle detection with Hough transform (c) Contour detection (d) Objectness measure
(e) Object detection
circle detection, we used Canny edge detector [Canny 1986] and Hough transform algorithms [Ballard 1981].
Figure 7 displays the PoI detection results on four example pictures in Dataset-2. As
we can see in Figure 7(b), circle detection could identify both bicycle wheels and car
badge, but its false positive rate is a little high. Contour detection is the most robust
algorithm with a low false positive rate which could locate regions whose colors are
different as shown in Figure 7(c). Objectness measure shown in Figure 7(d) could also
identify regions whose colors and textures are different from their surroundings. Since
most haar cascades we used are designed for facial landmarks, they work smoothly on
portraits as does the second picture in Figure 7(e). However, the results show relatively
high false positive rates on pictures from other categories. In order to identify more
PoIs as accurate as possible, our approach in PoI identification leveraged two steps.
In the first step, all possible PoIs were identified using different kinds of tools. In the
second step, we examined all identified PoIs and removed duplicates by comparing
their locations, sizes and attributes. Then, our approach generated a PoI set called
PA1 -50 and PA2 -50 for each picture in Dataset-1 and Dataset-2, respectively. Those PoI
sets consisted of at most 50 PoIs with the highest confidences. Compared with our
previous work [Zhao et al. 2013], we identified 9 more PoIs on average for each image
in Dataset-1 and 4 more PoIs on average for each image in Dataset-2.
Since our attack algorithms are independent from the PoI identification algorithms,
we are also interested in examining how our attack framework performs with ideal PoI
annotations for pictures. Besides using the automated PoI identification techniques,
we manually annotated pictures in Dataset-2 for some outstanding PoIs as well. To
annotate the pictures, we simply recorded the locations and attributes of at most fifteen most appealing regions in the pictures without referring to any password in the
collected dataset. We call this annotated PoI set PL2-15 .
We discuss the identified LdGSFs by linking PoIs and passwords in Dataset-2 with
the help of two PoI sets PL2-15 and PA2 -50 using our LdGSF identification algorithm
discussed in Section 4.3. The results from PL are closer to users’ actual selection processes, while the results from PA are the best approximations to users’ selection proACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:19

Table VII: Top 10 Identified LdGSFs using PL2-15
Rank
1
2
3
4
5
6
7
8
9
10

P r(sk )
(tap, {head}, ∅)
(tap, {∗c }, ∅)
(tap, {circle}, ∅)
(tap, {eye}, ∅)
(circle, {head}, ∅)
(tap, {nose}, ∅)
(circle, {circle}, ∅)
(circle, {eye}, ∅)
(line, {∗c }, {∗c })
(line, {eye}, {eye})

P r(sk |Dsk ⊆ θ)
(tap, {nose}, ∅)
(tap, {mouth}, ∅)
(tap, {circle}, ∅)
(tap, {eye}, ∅)
(tap, {∗c }, ∅)
(tap, {head}, ∅)
(circle, {circle}, ∅)
(tap, {ear}, ∅)
(line, {mouth}, {mouth})
(tap, {forehead}, ∅)

Table VIII: Top 10 Identified LdGSFs using PA2 -50
Rank
1
2
3
4
5
6
7
8
9
10

P r(sk )
(tap, {body}, ∅)
(tap, {circle}, ∅)
(tap, {mouth}, ∅)
(tap, {eye}, ∅)
(tap, {∗c }, ∅)
(tap, {head}, ∅)
(tap, {∗}, ∅)
(circle, {eye}, ∅)
(line, {∗c }, body)
(tap, {clock}, ∅)

P r(sk |Dsk ⊆ θ)
(tap, {clock}, ∅)
(circle, {clock}, ∅)
(tap, {shoulder}, ∅)
(tap, {eye}, ∅)
(tap, {head}, ∅)
(tap, {car}, ∅)
(tap, {mouth}, ∅)
(tap, {circle}, ∅)
(tap, {body}, ∅)
(tap, {∗}, ∅)

cesses we could get in a purely automated way with state-of-the-art computer vision
techniques.
The top ten identified LdGSFs using PL2-15 are shown in Table VII ordered by their
P r(sk ) and P r(sk |Dsk ⊆ θ). It also suggests that ‘tap a head’ is found the most times
in the passwords, while ‘tap a nose’ is the most popular one when there is a nose in
the picture. The result seems unreasonable at the first glance since there is always
a nose in a head. Actually, it is because if the head in the picture is really small, we
simply annotate the circumscribed rectangle as head instead of marking the inner
rectangles with more specific attributes. Table VII indicates that gestures on human
facial landmarks are the most popular selection functions adopted by subjects.
The top ten identified LdGSFs using PA2 -50 are shown in Table VIII. By comparing
Table VII and Table VIII, we could notice differences caused by using annotated PoI
set and automated detected PoI set. The fact that s(tap, {∗}, ∅) is among the top ten
LdGSFs is an indicator that the automatic PoI identification could not classify many
PoIs and simply mark them as ∗. It is surprising to find out there are 3 LdGs on clock
in top ten ordered by P r(sk |Dsk ⊆ θ) at first, because there is no clock in any picture
in Dataset-2. The closest guess is OpenCV falsely identified some circle shape objects
as clocks.
6. NONTARGETED ATTACK EVALUATION

In this section, we present the evaluation results of our framework for nontargeted
attacks. In order to attack passwords from a previously unseen picture, the training dataset excluded passwords from the target picture. More specifically, to evaluate
Dataset-1 (58 unique pictures), we used passwords from 57 pictures as the training
data and attacked the passwords for the last picture. To evaluate Dataset-2 (15 unique
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

50%

Z. Zhao, G.-J. Ahn and H. Hu

Percentage of LdGs Cracked

Percentage of Passwords Cracked

1:20

2
BestCover PA−50

45%

2
BestCover PL−15

40%

2
Unbiased PA−50

35%

2
Unbiased PL−15

30%
25%

1
BestCover PA−50

20%

1
Unbiased PA−50

15%
10%
5%
0%

0

2

4

6

8

10

12

14

Number of Password Guesses (Log−2 Scale)

(a)

16

18

70%

2
BestCover PA−40
2
BestCover PL−15

60%

2
Unbiased PA−40

50%

2
Unbiased PL−15

40%

1
BestCover PA−40

30%

1
Unbiased PA−40

20%
10%
0%

0

2

4

6

8

10

12

14

16

18

Number of Password Guesses (Log−2 Scale)

(b)

Fig. 8: Offline attacks with all available passwords. For Dataset-1, there are 86 passwords that include 258 LdGs. For Dataset-2, there are 10,039 passwords that have
30,117 LdGs. (a) Percentage of passwords cracked vs. number of password guesses,
per condition. (b) Percentage of LdGs cracked vs. number of password guesses, per
condition.
pictures), we used passwords for 14 pictures as training data, learned the patterns
exhibited in the training data, and generated a password dictionary for the last picture. The same process was carried out 58 and 15 times for Dataset-1 and Dataset-2,
respectively, in which the target picture was different in each round. The size of the
dictionary was set as 219 which is 11-bit smaller than the theoretical password space.
We compared all collected passwords for the target picture with the generated dictionary for the picture, and recorded the number of password guesses.
Nontargeted attacks also require that the training dataset does not include previous passwords from the targeted user. However, it turns out very time-consuming to
perform strict nontargeted attacks on our Dataset-2. Instead, in our analyses, training
password datasets include a very small number of passwords from the targeted subject. More specifically, in our experiment there were around 9,400 training passwords
for which only 14 came from the targeted user. Even though this may affect the results,
we believe it is less influential. Since all training passwords were treated equally, the
influence brought by the 0.14% training data is low.
6.1. Offline Attacks

Picture passwords may be hashable using discretization methods [Jean-Camille Birget and Memon 2006]. Even though the approach that Windows 8TM is adopting to
store picture passwords remains undisclosed, we could consider two attack scenarios
where picture passwords are prone to offline attacks. In the first scenario, all passwords which fall into the vicinity (defined by the threshold) of chosen passwords could
be stored in a file with salted hashes for comparison. An attacker who has access to this
file could perform offline dictionary attacks like cracking text-based password systems.
In the second scenario, picture passwords could be used for other purposes besides logging into Windows 8TM , where no constraint on the number of attempts is enforced.
For example, a registered picture password could be transformed and used as a key
to encrypt a file. An attacker who acquires the encrypted file would like to perform an
offline attack.
The offline attack results within 219 guesses in different settings are shown in Figure 8. There are 86 passwords in Dataset-1, which have a total of 258 LdGs. And
10,039 passwords were collected in Dataset-2, containing a total of 30,117 LdGs. For
Dataset-1, BestCover cracks 42 (48.8%) passwords out of 86 while Unbiased cracks 41
(47.7%) passwords for the same dataset with PA1 -50 . For Dataset-1, 179 LdGs (69.3%)
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

25%

Percentage of LdGs Cracked

Percentage of Passwords Cracked

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:21

2
BestCover PA−50
2
BestCover PL−15

20%

2
Unbiased PA−50
2
Unbiased PL−15

15%

10%

5%

0%

0

2

4

6

8

10

12

14

16

2
BestCover PL−15

40%

2
Unbiased PA−50
2
Unbiased PL−15

30%

20%

10%

0%

18

2
BestCover PA−50

50%

0

2

4

6

8

10

12

14

16

18

Number of Password Guesses (Log−2 Scale)

Number of Password Guesses (Log−2 Scale)

(a)

(b)

Percentage of LdGs Cracked

Percentage of Passwords Cracked

Fig. 9: Offline attacks with only the first chosen password by each subject in Dataset-2.
There are 762 passwords that have 2,286 LdGs. (a) Percentage of passwords cracked
vs. number of password guesses, per condition. (b) Percentage of LdGs cracked vs.
number of password guesses, per condition.

2
BestCover PA−50

25%

2
BestCover PL−15
2
Unbiased PA−50

20%

2
Unbiased PL−15

15%

10%

5%

0%

0

2

4

6

8

10

12

14

Number of Password Guesses (Log−2 Scale)

(a)

16

18

2
BestCover PA−50

50%

2
BestCover PL−15

40%

2
Unbiased PA−50
2
Unbiased PL−15

30%

20%

10%

0%

0

2

4

6

8

10

12

14

16

18

Number of Password Guesses (Log−2 Scale)

(b)

Fig. 10: Offline attacks with only passwords for pictures 243, 1116, 2057, 4054, 6467,
and 9899. There are 4,003 passwords that have 12,009 LdGs. (a) Percentage of passwords cracked vs. number of password guesses, per condition. (b) Percentage of LdGs
cracked vs. number of password guesses, per condition.
out of 258 are cracked with Unbiased and 173 (67.0%) are broken with BestCover. On
the other hand, Unbiased with PL2-15 breaks 2,953 passwords (29.4%) out of 10,039 for
Dataset-2. This implies BestCover with PA2 -50 cracking 2,434 passwords (24.2%) is the
best result for all purely automated attacks on Dataset-2. As Figure 8 suggests, BestCover outperforms Unbiased slightly when ample training data is available. The better
performance of both algorithms on Dataset-1 is because the password gesture combinations in Dataset-1 are relatively simpler than the ones in Dataset-2 as we discussed
in Section 3.2.
In Dataset-2, subjects may not choose all 15 passwords with the same care as they
were eager to finish the process. To reduce this effect, we ran another analysis in
which only the first chosen password by each subject was considered. There are 762
passwords that have 2,286 LdGs. Like previous analysis, the training dataset excluded
passwords from the target picture. As shown in Figure 9, results of this analysis are
not as good as previous ones. Unbiased with PL2-15 breaks 160 passwords (21.0%) out
of 762. Unbiased with PA2 -50 cracking 118 passwords (15.5%). BestCover cracks 108
(14.2%) and 116 (15.2%) with PL2-15 and PA2 -50 , respectively.
Since some pictures in Dataset-2 are similar, we ran an additional analysis in which
only passwords for pictures 243 (airplane), 1116 (portrait), 2057 (car), 4054 (wedding),
6467 (bicycle), and 9899 (dog) were considered. There are 4,003 passwords that have
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:22

Z. Zhao, G.-J. Ahn and H. Hu

15000

2000

1500

1000

500

0

60
600
~9400

BestCover

Unbiased

(a)

Average Number of LdGs Cracked

Average Number of Passwords Cracked

2500

10000

5000
60
600
~9400
0

Unbiased

BestCover

(b)

Fig. 11: Effects of training data size. (a) Average number of passwords cracked vs.
different training data sizes. (b) Average number of LdGs cracked vs. different training
data sizes. PA2 -50 is used for this analysis. Average over 3 analyses, with one standard
deviation shown.
12,009 LdGs. Unbiased with PL2-15 breaks 1,147 passwords (28.6%) while 703 passwords (17.6%) are cracked by Unbiased with PA2 -50 . BestCover cracks 829 (20.7%) and
863 (21.6%) with PL2-15 and PA2 -50 respectively. Results of this analysis are not as good
as results with passwords from all pictures.
6.2. Effects of Training Data Size

In Figure 11, we show the password and LdG cracking results with different sizes
of training datasets. For each algorithm, we used PA2 -50 as the PoI set and performed
three analyses with 60, 600, and all available passwords (about 9,400) as training data,
respectively. The sizes of 60 and 600 represent two cases: i) a training set (60) is ten
times smaller than the target set (about 669); and ii) a training set (600) is almost
the same size as the target set (about 669). For training datasets with the sizes of 60
and 600, we randomly selected these training passwords and performed each analysis
three times to get the averages and standard deviations. Same as the experiments
using all available training data, the training passwords in these experiments are
from different pictures of the target passwords. Therefore, there is no overlap between
the training passwords and the target passwords.
As Figure 11 shows, BestCover with 60 training samples could only break an average
of 803 passwords (8.0%) out of 10,039. And the standard deviation is as strong as 669.
While Unbiased with 60 training samples can crack 2,242 passwords (22.3%) that is almost the same as the results generated from all available training samples. Also, the
standard deviation for three trials is as low as 125. The results from BestCover with
600 training samples are much better than the counterparts with 60 training samples.
All these observations are expected as Unbiased could eliminate the biases considered
in BestCover. The results clearly demonstrate the benefit of using the Unbiased algorithm when a training dataset is small.
6.3. Effects on Different Picture Categories

We measured the attack results on different picture categories as shown in Figure 12
where each subfigure depicts the number of passwords cracked versus the number
of password guesses. Each curve in a subfigure corresponds to a picture as shown in
the legend. Our approach cracks more passwords for a picture, if the curve is skewed
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:23

300

243.jpg
316.jpg
250

200

150

100

50

0

0

2

4

6

8

10

12

14

16

Number of Passwords Cracked

Number of Passwords Cracked

300

1116.jpg
7628.jpg
250

200

150

100

50

0

18

0

Number of Password Guesses (Log−2 Scale)

2

4

6

(a)

12

14

16

18

300

1358.jpg
3026.jpg
3731.jpg
4054.jpg
5570.jpg

250

200

150

100

50

0

2

4

6

8

10

12

14

16

Number of Password Guesses (Log−2 Scale)

(c)

18

Number of Passwords Cracked

Number of Passwords Cracked

10

(b)

300

0

8

Number of Password Guesses (Log−2 Scale)

2057.jpg
2840.jpg
6412.jpg
6467.jpg

250

200

150

100

50

0

0

2

4

6

8

10

12

14

16

18

Number of Password Guesses (Log−2 Scale)

(d)

Fig. 12: Effects on different picture categories. (a) pictures with fewer PoIs (b) portraits
(c) pictures with people in them (d) pictures with lots of PoIs. Unbiased algorithm on
PA2 -50 is used for this analysis. (Please refer to Figure 2 for the pictures).

upward. And the cracking is faster (with fewer guesses), if the curve is leaned toward
the left.
Figure 12(a) provides a view of the attack results on target pictures 243 and 316,
each of which has only one airplane flying in the sky. Fewer PoIs in these two pictures
make subjects choose more similar passwords. Unbiased with PA2 -50 breaks 261 passwords (39.0%) for the picture 243 and 199 for the picture 316. The cracking success
rates are much higher than the average success rate in Dataset-2 under the same condition. Note that the size of generated dictionaries for these two pictures are smaller
than 219 due to the number of available PoIs.
In Figure 12(b), we show the results on two portrait pictures where Unbiased with
PA2 -50 cracks 388 passwords (29.0%) for both in total. The attack success rate is much
higher than the average success rate in Dataset-2. This is due to the fact that state-ofthe-art computer vision algorithms work well on facial landmarks and subjects’ tendencies of drawing on these features are high. The results show that passwords on
simple pictures with fewer PoIs or portraits, for which state-of-the-art computer vision
techniques could detect PoIs with high accuracy, are easier for attackers to break.
Figure 12(c) shows the attack results on 5 pictures of people. Some of these pictures
only have very small figures of people and others have larger figures but not big enough
to be considered as a portrait. Unbiased with PA2 -50 cracks 677 passwords (20.2%) for
these 5 pictures in total, which is lower than the average success rate in Dataset-2.
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Z. Zhao, G.-J. Ahn and H. Hu

500

7000

450

2
BestCover PA−50

400

2
BestCover PL−15

350

2
Unbiased PA−50

300

2
Unbiased PL−15

Number of LdGs Cracked

Number of Passwords Cracked

1:24

250
200
150
100
50
0

1

2

3

4

Number of Password Guesses

(a)

5

2
BestCover PA−50

6000

2
BestCover PL−15

5000

2
Unbiased PA−50
2
Unbiased PL−15

4000

3000

2000

1000

0

1

2

3

4

5

Number of Password Guesses

(b)

Fig. 13: Online attacks with all available passwords. There are 10,039 passwords that
have 30,117 LdGs in Dataset-2. (a) Number of passwords cracked within five guesses,
per condition. (b) Number of LdGs cracked within five guesses, per condition.
Figure 12(d) shows the attack results on 4 miscellaneous pictures, two of which are
bicycle pictures and the other two are car pictures. The picture, 6412.jpg, has a bicycle
leaning against the wall. Different colors on the bicycle and wall in this picture make
it cluttered and have lots of PoIs. Unbiased with PA2 -50 cracked 451 (17.0%) for all 4
pictures.
6.4. Online Attacks

The current Windows 8TM allows five failure attempts before it forces users to enter
their text-based passwords. Therefore, breaking a password under five guesses implies
the feasibility for launching an online attack. Figure 13 shows a refined view of the
number of passwords and LdGs cracked with the first five guesses per condition. Purely
automated attack Unbiased with PA2 -50 breaks 83 passwords (0.8%) with the first guess
and cracks 94 passwords (0.9%) within the first five guesses, while BestCover with
PA2 -50 cracked 20 passwords (0.2%) for the first guess and 38 passwords (0.4%) within
five guesses. Additionally, Unbiased with PA2 -50 breaks 1,723 LdGs (5.7%) with the first
guess. With the help of manually labeled PoI set PL2-15 , the results are even better.
For example, Unbiased breaks 195 passwords (1.9%) for the first guess and 266 (2.6%)
within the first five guesses. In the meantime, Unbiased with PL2-15 breaks 3,022 LdGs
(10.0%) with the first guess and 4,090 LdGs (13.5%) with five guesses.
6.5. Performance

Our analyses were carried out on a computer with dual-core processor and 4GB of
RAM. In Figure 14, we show the average runtime for our algorithms to order the
LdGSF sequences and generate dictionary for a picture in Dataset-2. Each bar represents the average time in seconds over 15 pictures with the standard deviation using different algorithms and PoI sets. The results show that BestCover is much faster
than Unbiased under the same condition. The average runtime for BestCover on PA2 -50
to order LdGSF sequences is only 0.06 seconds and to generate a dictionary is 2.68
seconds, while Unbiased spends 18.36 and 3.96 seconds, respectively. As we analyzed
in Section 4.4, such a difference is caused by the complexity of each algorithm. With
such a prompt response, BestCover could be used for online queries.
7. TARGETED ATTACK EVALUATION

In this section, we present the evaluation results of our framework for targeted attacks. In targeted attacks, an attacker has possession of some picture and password
pairs collected from the target user. Hence, the guessing path is more specific to the
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:25

20

4.5

Ordering LdGSF sequences
Generating password dictionary

18
16

3.5

Average Runtime

Average Runtime

4

3
2.5
2
1.5
1

14
12

Ordering LdGSF sequences
Generating password dictionary

10
8
6
4

0.5

2

0

0

PA2 -50

PL2-15

PA2 -50

PL2-15

(a) BestCover algorithm

(b) Unbiased algorithm

Percentage of Passwords Cracked

Fig. 14: Average runtime in seconds to order LdGSF sequences using BestCover and
Unbiased. Average over 15 pictures in Dataset-2 with one standard deviation shown.

25%

0
1
4
2
3
4
5
3
6
7
8
9
10 2
11
12
13
14 1
15

2
BestCover PA−50
2
BestCover PL−15

20%

2
Unbiased PA−50
2
Unbiased PL−15

15%

10%

5%

0%

0

2

4

6

8

10

12

14

Number of Password Guesses (Log−2 Scale)

(a)

16

18

2
Unbiased PL−15

2
Unbiased PA−50

2
BestCover PL−15

2
BestCover PA−50
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Fraction of Accounts

(b)

Fig. 15: Offline attacks. There are 9,974 passwords from 697 accounts in this experiment. The average size of training data sets is around 13. (a) Percentage of passwords
cracked vs. number of password guesses, per condition. (b) Passwords cracked per account. Each horizontal bar represents a condition. Regions within each bar show the
fraction of accounts for which the indicated number of passwords were cracked.
target user. This attack model is realistic when the user is using different passwords
and background images on multiple devices. The attacker may have acquired some
of the user’s passwords by shoulder-surfing or using password logger, and wants to
accelerate the guessing of the user’s passwords for other devices by taking acquired
passwords into account.
Because most subjects in Dataset-1 only chose one password, Dataset-1 was excluded
from these experiments. We only use the passwords of the subjects who chose two or
more passwords in Dataset-2 in these experiments. There are 697 subjects who fall into
this pattern resulting in 9,974 passwords. For each of the 697 subjects, we use one of
her passwords as the target and the rest of her passwords as training data set to build
the model. The average size of training data sets is around 13, which is significantly
smaller than the size used, which is around 9,400, in nontargeted attacks. A dictionary
is generated in this way for each target password per user. Since each subject only
chose one password for each picture, a training data set does not include passwords
for the target picture. We recorded the number of password guesses when a password
is cracked. Then, we cumulated the results for each user and each target password
together in a single figure as illustrated in Figure 15.
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:26

Z. Zhao, G.-J. Ahn and H. Hu

The offline attack results within 219 guesses in different settings are shown in Figure 15(a). Unbiased with PL2-15 breaks 2,233 passwords (22.4%) out of 9,974. Unbiased
with PA2 -50 breaks 2,083 passwords (20.9%) out of 9,974. Even though the results are
a little bit lower than nontargeted attacks, we should take the significantly smaller
training data set sizes into account. In nontargeted attack, the training data size is
around 9,400 passwords. However, in targeted attack, the training data sizes range
from at least 1 password to at most 14 passwords with an average of 13. In other word,
targeted attacks using Unbiased algorithms with around 100 times smaller training
data set could achieve almost the same results as nontargeted attacks. BestCover with
PL2-15 and PA2 -50 breaks 1,096 (10.9%) and 1057 (10.6%) passwords, respectively. Due
to the small training data size, the results from BestCover for nontargeted attacks are
quite lower than the counterparts for targeted attacks.
For online attacks within 5 guesses that are shown in the left-lower corner of Figure 15(a), Unbiased with PL2-15 breaks 434 passwords (4.4%) out of 9,974, and the first
guesses could even break 380 (3.8%) passwords. Unbiased with PA2 -50 breaks 77 passwords (0.7%) out of 9,974. BestCover with PL2-15 breaks 351 passwords (3.5%), and
BestCover with PA2 -50 breaks 70 passwords (0.7%).
Figure 15(b) shows the fractions of the accounts for which the indicated number of
passwords were cracked. Each bar represents one condition. Unbiased with PA2 -50 crack
at least one password for 60.5% accounts, while Unbiased with PL2-15 could crack 65.0%.
Even though BestCover with PL2-15 crack more passwords in total than with BestCover
with PL2-15 , BestCover with PL2-15 breaks more accounts for at least once. Both Unbiased
and BestCover with PL2-15 cracks all 15 passwords for 4 (5.7%) out of 697 accounts.
8. COMPARATIVE EVALUATION OF PGA USING UDSP FRAMEWORK

Bonneau et al. proposed a framework for comparative evaluation of web authentication schemes in [Bonneau et al. 2012b]. Their evaluation framework considers scheme
benefits from three different categories, which are usability, deployability, and security.
We refer to this evaluation framework UDS framework for short. Since the UDS framework is designed for web authentication schemes, it does not capture some scheme benefits that are brought by new devices. And, it does not include comprehensive privacy
benefits either. In this section, we extend the UDS framework by introducing 3 new
usability benefits, 1 new security benefits, and 5 new privacy benefits. These newly
introduced benefits are numbered after the original benefits in UDS framework, so
please refer to [Bonneau et al. 2012b] for the detailed explanations for the original
benefits. We call the extended framework as usability-deployability-security-privacy
(UDSP) framework. Same as [Bonneau et al. 2012b], if a scheme partially provides a
benefit, we use the Quasi- prefix to indicate that.
Even though some newly introduced benefits might have some correlations with the
original benefits, they describe some features that can not be covered by the UDS
framework. Similar with the UDS framework in which some benefits are subjective
(e.g., Efficient-to-Use and Infrequent-Errors), some benefits we introduce here are subjective and related to users’ individual choices. For instance, we introduce an usability benefit named Enjoyable-to-Use for which we conduct an informal survey to get
opinions on different schemes. A second example is a privacy benefit named Resilientto-Birthday-Disclosure that describes the possibility that the disclosure of users’ credentials leads to the disclosure of their birthdays. Technically, a user could use any
meaningless 4-digit number as a PIN. However, it is statistically significant that users’
PINs are related to their birthdays [Bonneau et al. 2012d]. So, we do not grant PINs
this benefit. Some people may argue that statistical significance has nothing to do with
a scheme itself. We do not agree with this argument and we believe it is the scheme
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:27

Table IX: Comparative Evaluation of Schemes in Terms of Usability Benefits















Enjoyable-to-Use*




Touchscreen-Friendly*




Assistance-to-Recall*









Easy-Recovery-from-Loss









Infrequent-Errors

Efficient-to-Use







Easy-to-Learn







Physically-Effortless

Nothing-to-Carry



Scalable-for-Users

Scheme
Text-based Passwords
PCCP
Fingerprint
RSA SecurID
Draw Pattern*
4-digit PINs*
PGA*

Memorywise-Effortless

Usability benefits










* represents new benefits in UDSP framework or schemes that were not evaluated before

designers’ responsibility to flatten the credentials’ probability distributions. This is
also one of the five password system design principles discussed in [Yan et al. 2012].
Some existing schemes have adopted this practice, such as presented in [Schechter
et al. 2010; Chiasson et al. 2012]. Thorpe et al. [Thorpe et al. 2014] also demonstrated
that the distribution of user chosen passwords for PassPoints can be manipulated by
merely changing the way to present background image.
8.1. UDSP framework

We explain each of the new benefits we consider by giving it a name, an actual definition, and its evaluation on four schemes. These four schemes are text-based passwords,
Persuasive Cued Click-Points (PCCP) [Chiasson et al. 2012], Fingerprint, and RSA SecurID. The descriptions of these schemes and the detailed evaluation of them on the
original UDS framework can be found in [Bonneau et al. 2012a; Bonneau et al. 2012b].
Table IX - Table XII list seven schemes, four of which were evaluated in [Bonneau
et al. 2012a] and the other three are new, and their evaluation in terms of each benefit in the UDSP framework. The detailed explanation of the evaluation of those three
new schemes, namely Draw Patten, PIN, and PGA, in these tables will be discussed in
Section 8.2 and Section 8.3.
U9. Assistance-to-Recall: Users of the scheme receive implicit or explicit assistance
to recall their passwords or credentials at the time of authentication. A scheme
is granted Assistance-to-Recall if it is Memorywise-Effortless or it provides visual,
acoustical, or any other built-in-scheme means to help users recall their credentials.
Note that Assistance-to-Recall is different from Quasi-Memorywise-Effortless in
UDS, which requires users only to remember one secret for everything.
Text-based passwords are not Assistance-to-Recall. Even though text-based password system are often accompanied by password reminders, such reminders are
not an inherent part of the authentication scheme. PCCP is Assistance-to-Recall,
because it leverages human ability to remember images to help them recall their
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:28

Z. Zhao, G.-J. Ahn and H. Hu

Table X: Comparative Evaluation of Schemes in Terms of Deployability Benefits






























Non-Proprietary

Mature

Browser-Compatible

Server-Compatible

Negligible-Cost-per-User

Scheme
Text-based Passwords
PCCP
Fingerprint
RSA SecurID
Draw Pattern*
4-digit PINs*
PGA*

Accessible

Deployability benefits






* represents new benefits in UDSP framework or schemes that were not evaluated before

passwords. We consider Fingerprint as Assistance-to-Recall, since it is MemorywiseEffortless. RSA SecurID is not Assistance-to-Recall. Even though the users of RSA
SecurID can read dynamic 6-digit code from hardware tokens, they still need to
memorize and recall their 4-digit PINs without help.
U10. Touchscreen-Friendly: Using the scheme on touch-screen devices is at least
as easy as inputting text-based password with keyboards. A scheme is not granted
Touchscreen-Friendly, if its credential input process requires special devices except
touch-screens.
Text-based passwords is not Touchscreen-Friendly, since users find typing alphanumerics and symbols on touch-screens very difficult. PCCP is Touchscreen-Friendly,
because it only requires users to click points on pictures that could occupy the whole
touch-screen. Fingerprint is not Touchscreen-Friendly, because it requires a fingerprint scanner. We grant RSA SecurID Touchscreen-Friendly, since typing only numerical digits is not a hard job on touch-screens with virtual numpads.
U11. Enjoyable-to-Use: Users of the scheme authenticate themselves to verifiers
in a fluid manner. In the meantime, the user experience of the credential input
process is enjoyable, which means users consider the scheme is fun or exciting to
use.
The metric of Enjoyable-to-Use is relatively subjective. A user’s perception towards
a scheme may change over time, location, and other factors. For example, a user
who is always curious about the new things may enjoy an authentication scheme at
first and get bored after using the scheme for a while. Even though it is difficult to
accurately model a scheme’s enjoyableness, it is necessary to consider this feature
as one of usability properties. To measure this subjective feature, we conducted an
informal pilot study to ask our participants’ opinions on this property. Our finding
on this property is preliminary and only tries to capture users’ coarse feelings. The
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:29

Table XI: Comparative Evaluation of Schemes in Terms of Security Benefits




































Resilient-to-Human-Choices-Guided-Guessing*




Unlinkable



Requiring-Explicit-Consent



No-Trusted-Third-Party

Resilient-to-Internal-Observation

Resilient-to-Unthrottled-Guessing

Resilient-to-Throttled-Guessing




Resilient-to-Theft








Resilient-to-Phishing




Resilient-to-Leaks-from-Other-Verifiers




Resilient-to-Targeted-Impersonation

Scheme
Text-based Passwords
PCCP
Fingerprint
RSA SecurID
Draw Pattern*
4-digit PINs*
PGA*

Resilient-to-Physical-Observation

Security benefits





* represents new benefits in UDSP framework or schemes that were not evaluated before

further analysis on this property remains for the future work. Twelve graduate and
undergraduate students participated in this survey. Each participant was asked to
give a binary answer. If a scheme received six positive votes for Enjoyable-to-Use,
we grant Enjoyable-to-Use to the scheme. Based on this survey, none of Text-based
passwords, PCCP, Fingerprint and RSA SecurID is granted Enjoyable-to-Use.

S12. Resilient-to-Human-Choices-Guided-Guessing: Users of the scheme do not
need to choose secrets as or as part of the credentials. It is statistically proved that
human-chosen secrets follow a skewed probability distribution [Bonneau 2012a;
Bonneau et al. 2012c]. Many methods have been proposed to use these patterns
to guess human-chosen secrets [Thorpe and Van Oorschot 2007; Bonneau 2012b;
Uellenbeck et al. 2013]. If human-chosen secrets are only used as part of the credentials in a scheme or a scheme has mechanisms to flatten user-chosen patterns,
we grant this scheme Quasi-Resilient-to-Human-Choices-Guided-Guessing.
Text-based passwords is not granted this benefit. Even if complicated password
composition policies are used in real-world websites, new password composition
patterns are continuously discovered [Rao et al. 2013]. PCCP and RSA SecurID
are granted Quasi-Resilient-to-Human-Choices-Guided-Guessing, because PCCP
requires users to click in a randomly selected portion of each image which flattens
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:30

Z. Zhao, G.-J. Ahn and H. Hu

Table XII: Comparative Evaluation of Schemes in Terms of Privacy Benefits

























Resilient-to-Physiological-Data-Disclosure*

Resilient-to-Birthday-Disclosure*

Resilient-to-Interests-Disclosure*

Resilient-to-Image-Disclosure*

Scheme
Text-based Passwords
PCCP
Fingerprint
RSA SecurID
Draw Pattern*
4-digit PINs*
PGA*

Resilient-to-Identity-Disclosure*

Privacy benefits








* represents new benefits in UDSP framework or schemes that were not evaluated before

the password distribution and RSA SecurID has 6-digit dynamic passcode that is
not chosen by human. We consider Fingerprint has this benefit.
P1. Resilient-to-Identity-Disclosure: Leak of the credentials of the scheme does not
disclose the identities of the credentials’ owners. In some cases, the credentials
have two parts, namely identifier (username) and secret (password), such as those
in web authentication schemes. In other cases, the identifier part is omitted. An
authentication scheme of a mobile operating system that supports only single user
does not need a username. Example schemes include Draw Pattern on Android and
PIN on iOS. A scheme is granted this benefit, if and only if the disclosure of any
part of the credential can not reveal the identity of the user. A scheme is given
Quasi-Resilient-to-Identity-Disclosure, if the disclosure of the secret part would not
give away the user’s identity.
Text-based passwords and RSA SecurID are granted Quasi-Resilient-to-IdentityDisclosure, since user-chosen usernames could easily reveal users’ identities. PCCP
is granted this benefit, because it does not require an overt username. Fingerprint
is not granted this benefit, since the disclosure of fingerprint, which is one of important identifiable information, may lead to identity theft.
P2. Resilient-to-Image-Disclosure: Leak of the credentials of the scheme does not
disclose the images of the credentials’ owners.

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:31

Text-based passwords, RSA SecurID, and Fingerprint are granted this benefit, since
no image is involved in these schemes. PCCP is also granted this benefit, because it
only uses pre-selected images.
P3. Resilient-to-Interests-Disclosure: Leak of the credentials of the scheme does not
disclose users interests.
Text-based passwords are not granted this benefit, because previous research effort
discovered password compositions are related to users’ interests [Castelluccia et al.
2012]. Disclosure of a password may reveal interests of the corresponding username.
PCCP is not granted this benefit, because users may be more likely to click objects
that draw their interest from a PCCP image. RSA SecurID and Fingerprint are
granted this benefit.
P4. Resilient-to-Birthday-Disclosure: Leak of the credentials of the scheme does
not disclose users’ birthdays.
Fingerprint and PCCP are granted this benefit. RSA SecurID are not, because it
is statistically significant that users’ PINs are related to their birthdays [Bonneau
et al. 2012d] and RSA SecurID uses a 4-digit PIN as part of the secret. Text-based
passwords are granted this benefit.
P5. Resilient-to-Physiological-Data-Disclosure: Leak of the credentials of the
scheme does not disclose users’ physiological information.
Fingerprint authentication may disclose users’ fingerprint information. As an example, the iPhone 5s introduces fingerprint which triggered discussions about privacy
issues in addition to identity theft. Some are worried that Apple may collect every iPhone 5s user’s fingerprint, and losing iPhone 5s may bring the disclosure of
one’s fingerprint information. Text-based passwords, PCCP, and RSA SecurID are
granted this benefits.
8.2. Evaluation of Draw Pattern and PINs

Draw Pattern and PINs are two commercially popular authentication schemes that
are used in Android and iOS respectively. In this section, we evaluate both of them
with UDSP framework.
8.2.1. Draw Pattern. Please refer to [Uellenbeck et al. 2013], if the reader is not familiar with Android Draw Pattern. Draw Pattern is neither Memorywise-Effortless,
nor Scalable-for-Users. It is Nothing-to-Carry, but not Physically-Effortless. However,
it offers advantages over text-based passwords, because users could use one hand and
one finger to unlock the devices. It is Easy-to-Learn and Efficient-to-Use. It is QuasiInfrequent-Errors due to inconsistent finger movements. It is Easy-Recovery-from-Loss
and Touchscreen-Friendly. It is not Assistance-to-Recall. It is Enjoyable-to-Use based
on our survey.
Draw Pattern is not Accessible for blind users and has Negligible-Cost-per-User. It
is Server-Compatible, as each dot could be mapped to an alphanumeric after which
a draw pattern could be stored and compared as a text-based password. It is also
Browser-Compatible. It is Mature and used in hundreds of millions of Android devices.
It is not Non-Proprietary.
Draw Pattern is not Resilient-to-Physical-Observation, since either shoulder surfing or smudge attack can reveal the secret. It is Resilient-to-Targeted-Impersonation,
since knowing the user’s personal details does not help attack the password. It is
neither Resilient-to-Throttled-Guessing nor Resilient-to-Unthrottled-Guessing due to
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:32

Z. Zhao, G.-J. Ahn and H. Hu

small password space and strong patterns shown in collected password set [Uellenbeck et al. 2013]. It is neither Resilient-to-Internal-Observation nor Resilient-to-Leaksfrom-Other-Verifiers due to password reuse across sites and devices. It is not Resilientto-Phishing but Resilient-to-Theft, since no physical token is used. It has No-TrustedThird-Party and Requiring-Explicit-Consent. It is Unlinkable. It is not Resilient-toHuman-Choices-Guided-Guessing, since feasible attacks have been presented [Uellenbeck et al. 2013].
This scheme is Quasi-Resilient-to-Identity-Disclosure, if a username is required. In
some context of use, such as in Android, Draw Pattern does not need any username,
hence it is Resilient-to-Identity-Disclosure. It is both Resilient-to-Image-Disclosure
and Resilient-to-Interests-Disclosure. It is both Resilient-to-Birthday-Disclosure and
Resilient-to-Physiological-Data-Disclosure as well.
8.2.2. Personal Identification Numbers. 4-digit PINs are widely used in ATMs and Apple iPhones. An empirical analysis of customer-chosen banking PINs was presented
in [Bonneau et al. 2012c]. PINs are neither Memorywise-Effortless, nor Scalable-forUsers. However, they are easier to remember and recall than text-based passwords
due to their short representations. They are Nothing-to-Carry, but not PhysicallyEffortless. They are Easy-to-Learn and Efficient-to-Use. They are Infrequent-Errors
and Easy-Recovery-from-Loss. They are also Touchscreen-Friendly, because normally
a numpad is displayed to assist the users to input. They are not Assistance-to-Recall.
They are not granted Enjoyable-to-Use based on our survey.
PINs are a simplified version of text-based passwords. Therefore, PINs provide the
same deployabilities as text-based passwords.
PINs are not Resilient-to-Physical-Observation, shoulder surfing and video recording are typical ways to steal PINs. They are not Resilient-to-Targeted-Impersonation,
since a considerable portion of users use their birthdays as their PINs. They are
neither Resilient-to-Throttled-Guessing nor Resilient-to-Unthrottled-Guessing due to
small password space and strong patterns [Bonneau et al. 2012c]. They are neither Resilient-to-Internal-Observation nor Resilient-to-Leaks-from-Other-Verifiers due
to PINs reuse. They are not Resilient-to-Phishing but Resilient-to-Theft. They do not
use No-Trusted-Third-Party, and they are Requiring-Explicit-Consent. They are Unlinkable. PINs are not Resilient-to-Human-Choices-Guided-Guessing.
PINs are Quasi-Resilient-to-Identity-Disclosure, if usernames are provided. In some
context of use, such as in iPhone, where usernames are not used, PINs are Resilientto-Identity-Disclosure. They are Resilient-to-Image-Disclosure, Resilient-to-InterestsDisclosure and Resilient-to-Physiological-Data-Disclosure. They are not Resilient-toBirthday-Disclosure.
8.3. Evaluation of PGA

We have presented an empirical analysis of human-chosen PGA passwords in Section 3
and nontargeted and targeted attack results on collected passwords in Section 6 and
Section 7 respectively. The results from both empirical analysis and attacks serve as
the basis for us to evaluate if PGA provides certain criterion.
PGA is not Memorywise-Effortless, since the size, location, and ordering of each
drawing must be remembered. It is not Scalable-for-Users, as a password has to be
chosen for each site per user. However, it is easier to recall than text-based passwords
due to human ability to remember images. We capture this characteristic by giving
it Assistance-to-Recall. It is obviously Nothing-to-Carry. It is not Physically-Effortless,
as users need to draw gestures on screens. However, it offers advantages over textbased passwords, because in most cases users could use one hand and one finger to
unlock the devices in a timely manner. It is Touchscreen-Friendly, as drawing gestures
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:33

on touch-screens is much easier than typing alphanumerics. It is Easy-to-Learn and
Efficient-to-Use according to our user studies. It is Quasi-Infrequent-Errors and EasyRecovery-from-Loss. It is Enjoyable-to-Use based on our survey.
PGA is not Accessible for blind users. It has Negligible-Cost-per-User, as no costly
physical token is involved. It is not Server-Compatible with text-based passwords,
as the format and comparison of passwords are not the same as those of text-based
passwords. It is Browser-Compatible, as developers could capture drawings using
JavaScript. It is Mature and used in hundreds of millions of Windows devices. It is
not Non-Proprietary, as a patent [Johnson et al. 2012] is issued to MicrosoftTM .
PGA is not Resilient-to-Physical-Observation. In fact, shoulder-surfing PGA on large
screen would be a serious problem [Honan 2012]. It is at best Quasi-Resilient-toTargeted-Impersonation, since knowing the user’s personal habit and inclination could
help guessing her drawings. It is at best Quasi-Resilient-to-Throttled-Guessing and not
Resilient-to-Unthrottled-Guessing based on our attack results in Section 6. It is neither Resilient-to-Internal-Observation nor Resilient-to-Leaks-from-Other-Verifiers due
to password reuse across sites and devices. It is Resilient-to-Phishing, because users
choose their own images as background. It is Resilient-to-Theft, since no physical token is used. It has No-Trusted-Third-Party and Requiring-Explicit-Consent. It is not
Unlinkable, because a user may use identical but personal images on different sites
and devices. It is not Resilient-to-Human-Choices-Guided-Guessing, as we will discuss
in Section 3 and 6.
PGA is not Resilient-to-Identity-Disclosure, since the background image disclose
the identity of the user. It is neither Resilient-to-Image-Disclosure nor Resilient-toInterests-Disclosure which we will discuss in Section 3. It is both Resilient-to-BirthdayDisclosure and Resilient-to-Physiological-Data-Disclosure.
In summary, PGA provides very good usability, especially on touch-screen devices.
As shown in Table IX, PGA offers more usability benefits than all other discussed
schemes. In particular, it is one of the only two schemes that are classified as
Enjoyable-to-Use and one of the only three schemes that offer Assistance-to-Recall.
The good user experience provided by PGA might be a major reason for it to be included in a commercially popular operating system. For deployability, PGA only offers
more benefits than Fingerprint and RSA SecurID, both of which require the addition
of some physical devices on either authenticator or authenticatee side. The proprietary
protection for PGA may prevent it from being deployed on more devices or websites.
On the security side, the size of password space is very important. As listed in Table I,
PGA offers larger password space than the other two popular touch-screen friendly
schemes. However, its space size with current setting is smaller than text-based passwords that are generated with strict composition rules. When it comes to the number
of security benefits in UDSP, PGA only offers the same number of security benefits
as Draw Pattern, PINs, and text-based passwords, all of which are considered not so
secure. Even though the security of a scheme can not be accurately measured by the
number of security benefits it offers, the number can tell how many attack methods
a scheme could be resilient to. Obviously, the security of PGA can not compete with
some more secure schemes, such as RSA SecurID. From the perspective of privacy,
PGA offers the least number of privacy benefits in all discussed schemes as shown in
Table XII. The introduction of using users own pictures makes PGA enjoyable to use at
the expense of exposing their images. Therefore, users may hesitate on using PGA-like
schemes on devices that do not belong to them. The good usability of PGA comes with
a price not only on its security features but also on its privacy protection.

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:34

Z. Zhao, G.-J. Ahn and H. Hu

9. DISCUSSION
9.1. Other Attacks on PGA

Besides keyloggers that record users’ finger movements, there are some other attack
methods that may affect the security of PGA and other background draw-a-secret
schemes. Shoulder surfing, an attack where attackers simply observe the user’s finger
movements, is one of them. In our survey, 54.3% participants believe the picture password scheme is easier for attackers to observe when they are providing their credentials than text-based password. Several new shoulder surfing resistant schemes [Forget et al. 2010; Zakaria et al. 2011] were proposed recently. However, the usability is always a major concern for these approaches. The smudge attack [Aviv et al. 2010] which
recovers passwords from the oily residues on a touch-screen has also been proven feasible to the background draw-a-secret schemes and could pose threats to PGA.
9.2. Limitations of Our Study

While we took great efforts to maintain our studies’ validity, some design aspects of
our studies and developed system may have caused subjects to behave differently from
what they do on Windows 8TM PGA. As previously mentioned, subjects in Dataset-1
used their passwords to access more than four times a week on average. However, the
data protected by the passwords in the web site is not sensitive. In this case, subjects preferred passwords with simpler gesture type combinations that were easier
to reproduce in a timely manner. These exists a lack of recall session for Dataset-2,
since subjects pretended to access their bank information but did not have anything
at risk. There is a lack of recall session for Dataset-2, since subjects chose passwords
in a relatively short time and never came back to use the chosen passwords. Schechter
et al. [Schechter et al. 2007] suggest that role playing like this affects subjects’ security behavior, so passwords in Dataset-2 may not be representative of real passwords
chosen by real users. Besides, we did not record whether a subject used a tablet with
touch-screen or a desktop with mouse. The different ways of input may affect the composition of passwords. Moreover, Dataset-2 includes multiple passwords per user and
this may have impacted the results.
10. RELATED WORK

Biddle et al. provided an excellent survey on the first twelve years of history of graphical passwords in [Biddle et al. 2011]. Most graphical password schemes proposed in
academia and those used in real-world products from 1999 to 2010 have been covered
in that paper. In all existing schemes, PGA is most similar to BDAS [Dunphy and
Yan 2007]. De Angeli et al. stated that the weakness of all knowledge-based authentication systems reflects a trade-off between security and human memory constraints
in [De Angeli et al. 2005]. Based on the memory tasks involved in remembering and
inputting the passwords, these two papers divided all then existing graphical password schemes into three categories: i) recall-based systems aka drawmetric systems
in which no password cue is given. Exemplary schemes include DAS [Jermyn et al.
1999], YAGP [Gao et al. 2008], Passdoodle [Varenhorst et al. 2004], PassShapes [Weiss
and De Luca 2008], and Pass-Go [Tao and Adams 2008]; ii) recognition-based systems
aka cognometric systems or searchmetric systems [Renaud 2009] in which users need
to memorize a portfolio of images during password creation and recognize them to
log in. Exemplary schemes include Face [Brostoff and Sasse 2000], Story [Davis et al.
2004], and Déjà Vu [Dhamija and Perrig 2000]; and iii) cued-recall systems aka locimetric systems in which users remember specific locations within an image. Exemplary
schemes include PassPoints [Wiedenbeck et al. 2005b], Cued Click-Points [Chiasson
et al. 2007], and Persuasive Cued Click-Points [Chiasson et al. 2012]. PGA is more like
ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:35

a cued-recall system, as users need to recall the locations of gestures and the chosen
background images could serve as cues for users. However, PGA also has some features
that were only previously observed in recall-based and recognition-based systems. For
example, different from previous cued-recall systems in which users only remember
locations, PGA also requires users to recall their gesture types associated with locations. The task to recall gesture types in PGA is similar to the tasks in recall-based
systems. According to our study, user-chosen gesture types are highly related to the attributes of user-chosen gesture locations. Therefore, background images provide users
with cues for both gesture locations and gesture types. In addition, to use PGA, users
need to recognize certain objects in background pictures and even recognize the full
pictures to counter phishing attacks. This recognition task makes PGA have some features of recognition-based systems. In a sense, PGA blurs the boundaries of the three
aforementioned graphical password categories.
The basic idea of attacking graphical password schemes is to generate dictionaries that consist of potential passwords [Thorpe and van Oorschot 2004]. However, the
lack of sophisticated mechanisms for dictionary construction affects the attack capabilities of existing approaches. Davis et al. [Davis et al. 2004] used the relations of
users’ demographic information and their passwords to guess Face passwords. Thorpe
et al. [Thorpe and Van Oorschot 2007] proposed a method to harvest the locations
of training subjects’ clicks on pictures in click-based passwords to attack other users’
passwords on the same pictures. In the same paper [Thorpe and Van Oorschot 2007],
they presented another approach which creates dictionaries by predicting hot-spots using image processing methods. Oorschot et al. [van Oorschot and Thorpe 2008] cracked
DAS using some password complexity factors, such as reflective symmetry and strokecount. Dirik et al. [Dirik et al. 2007] modeled user choice in PassPoints and proposed
automated dictionary attacks. Salehi-Abari et al. [Salehi-Abari et al. 2008] proposed
an automated attack on the PassPoints scheme by ranking passwords with click-order
patterns. However, the click-order patterns introduced in their approach could not capture users’ selection processes accurately, especially when a background image significantly affects user choice. To attack PGA passwords, there are at least three requirements an attack approach should meet: i) the approach should work on complex
gestures besides simple click; ii) the approach could learn patterns from harvested
passwords even if they are not collected from the target picture; and iii) the approach
could generate dictionaries for previously unseen pictures. Our attack framework differs from previous efforts by introducing the idea of selection function that abstracts
and models users’ password creation processes and therefore meets all three requirements.
The security and vulnerability of text-based password have attracted considerable
attention because of several infamous password leakage incidents in recent years.
The approaches for guessing text-based passwords influenced the design of our attack framework much. Zhang et al. [Zhang et al. 2010] studied the password choices
over time and proposed an approach to attack new passwords from old ones. Castelluccia et al. [Castelluccia et al. 2012] proposed an adaptive Markov-based password
strength meter by estimating the probability of password using training data. Kelley
et al. [Kelley et al. 2012] developed a distributed method to calculate how effectively
password-guessing algorithms could guess passwords. Even though the attack framework we presented is dedicated to cracking PGA passwords, the idea of abstracting
users’ selection processes of password construction introduced in this paper could also
be applicable to cracking and measuring text-based passwords. Veras et al. [Veras et al.
2014] presented such an approach to extract and understand semantic patterns in text
passwords.

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:36

Z. Zhao, G.-J. Ahn and H. Hu

11. CONCLUSION

We have described an empirical analysis of Windows 8TM picture gesture authentication passwords collected from our online user studies. The empirical analysis has
helped us understand user choice patterns in background picture, gesture location,
gesture order, and gesture type. We have presented a novel attack framework that
makes use of the extracted user choice patterns to guess Windows 8TM picture gesture authentication passwords. Using the proposed attack framework, we have demonstrated that our approach was able to crack a considerable portion of picture passwords in various situations. Based on the empirical analysis and attack results, we
have comparatively evaluated picture gesture authentication with a set of extended
benefits from four categories, namely usability, deployability, security, and privacy. We
also discovered that picture gesture authentication provides more usability benefits
than all other schemes we have analyzed. However, it has some limitations in deployability and security benefits than most of the schemes we have analyzed. Moreover,
it brought up some privacy concerns, such as disclosing users’ images. We believe the
findings discussed in this paper could advance the understanding of picture gesture
authentication and its advantages and limitations.
ACKNOWLEDGMENTS
The work of Ziming Zhao and Gail-Joon Ahn was partially supported by the grants from Global Research
Laboratory Project through National Research Foundation (NRF-2014K1A1A2043029).

REFERENCES
Bogdan Alexe, Thomas Deselaers, and Vittorio Ferrari. 2012. Measuring the objectness of image windows.
IEEE Transactions Pattern Analysis and Machine Intelligence (2012), 2189–2202.
Adam J Aviv, Katherine Gibson, Evan Mossop, Matt Blaze, and Jonathan M Smith. 2010. Smudge attacks
on smartphone touch screens. In Proceedings of the 4th USENIX conference on Offensive Technologies.
USENIX Association, 1–7.
Dana H Ballard. 1981. Generalizing the Hough transform to detect arbitrary shapes. Pattern Recognition
13, 2 (1981), 111–122.
Kemal Bicakci, Nart Bedin Atalay, Mustafa Yuceel, Hakan Gurbaslar, and Burak Erdeniz. 2009. Towards
usable solutions to graphical password hotspot problem. In Proceedings of the 33rd IEEE International
conference on Computer Software and Applications Conference, Vol. 2. IEEE, 318–323.
Robert Biddle, Sonia Chiasson, and Paul C Van Oorschot. 2011. Graphical passwords: Learning from the
first twelve years. Comput. Surveys 44, 4 (2011).
Joseph Bonneau. 2012a. Guessing human-chosen secrets. (May 2012).
Joseph Bonneau. 2012b. The science of guessing: analyzing an anonymized corpus of 70 million passwords.
In Proceedings of the 2012 IEEE Symposium on Security and Privacy. IEEE, 538–552.
Joseph Bonneau, Cormac Herley, Paul C. van Oorschot, and Frank Stajano. 2012a. The quest to replace
passwords: a framework for comparative evaluation of Web authentication schemes. Technical Report
UCAM-CL-TR-817. University of Cambridge, Computer Laboratory.
Joseph Bonneau, Cormac Herley, Paul C van Oorschot, and Frank Stajano. 2012b. The quest to replace
passwords: A framework for comparative evaluation of web authentication schemes. In Proceedings of
the 2012 IEEE Symposium on Security and Privacy. IEEE, 553–567.
Joseph Bonneau, Sören Preibusch, and Ross Anderson. 2012c. A birthday present every eleven wallets? The
security of customer-chosen banking PINs. In Proceedings of the the 16th International Conference on
Financial Cryptography.
Joseph Bonneau, Sören Preibusch, and Ross Anderson. 2012d. A birthday present every eleven wallets? The
security of customer-chosen banking PINs. Financial Cryptography and Data Security (2012), 25–40.
Ali Borji, Dicky N Sihite, and Laurent Itti. 2012. Salient object detection: A benchmark. In Proceedings of
the 2012 European Conference on Computer Vision. Springer, 414–429.
Ali Borji, Hamed R Tavakoli, Dicky N Sihite, and Laurent Itti. 2013. Analysis of scores, datasets, and models
in visual saliency prediction. In Proceedings of the 2013 IEEE International Conference on Computer
Vision. IEEE, 921–928.

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:37
Sacha Brostoff and M Angela Sasse. 2000. Are Passfaces more usable than passwords? A field trial investigation. People and Computers (2000), 405–424.
John Canny. 1986. A computational approach to edge detection. IEEE Transactions on Pattern Analysis and
Machine Intelligence 6 (1986), 679–698.
Claude Castelluccia, Markus Dürmuth, and Daniele Perito. 2012. Adaptive password-strength meters from
Markov models. In Proceedings of the 19th Network and Distributed System Security Symposium.
Sonia Chiasson, Alain Forget, Robert Biddle, and Paul C van Oorschot. 2009. User interface design affects
security: Patterns in click-based graphical passwords. International Journal of Information Security 8,
6 (2009), 387–398.
Sonia Chiasson, Elizabeth Stobert, Alain Forget, Robert Biddle, and Paul C Van Oorschot. 2012. Persuasive
cued click-points: Design, implementation, and evaluation of a knowledge-based authentication mechanism. IEEE Transactions on Dependable and Secure Computing 9, 2 (2012), 222–235.
Sonia Chiasson, Paul van Oorschot, and Robert Biddle. 2007. Graphical password authentication using
cued click points. In Proceedings of the 12th European Symposium on Research in Computer Security.
Springer, 359–374.
Darren Davis, Fabian Monrose, and Michael K Reiter. 2004. On user choice in graphical password schemes.
In Proceedings of the 13th conference on USENIX Security Symposium. USENIX Association, 11–23.
Antonella De Angeli, Lynne Coventry, Graham Johnson, and Karen Renaud. 2005. Is a picture really worth
a thousand words? Exploring the feasibility of graphical authentication systems. International Journal
of Human-Computer Studies 63, 1 (2005), 128–152.
Rachna Dhamija and Adrian Perrig. 2000. Déjà Vu: A user study using images for authentication. In Proceedings of the 9th conference on USENIX Security Symposium. USENIX Association.
Ahmet Emir Dirik, Nasir Memon, and Jean-Camille Birget. 2007. Modeling user choice in the PassPoints
graphical password scheme. In Proceedings of the 3rd Symposium on Usable Privacy and Security. ACM,
20–28.
Paul Dunphy and Jeff Yan. 2007. Do background images improve draw a secret graphical passwords?. In
Proceedings of the 14th ACM conference on Computer and Communications Security. ACM, 36–47.
Uriel Feige, László Lovász, and Prasad Tetali. 2004. Approximating min sum set cover. Algorithmica 40, 4
(2004), 219–234.
Pedro F Felzenszwalb, Ross B Girshick, David McAllester, and Deva Ramanan. 2010. Object detection with
discriminatively trained part-based models. IEEE Transactions on Pattern Analysis and Machine Intelligence 32, 9 (2010), 1627–1645.
Alain Forget, Sonia Chiasson, and Robert Biddle. 2010. Shoulder-surfing resistance with eye-gaze entry in
cued-recall graphical passwords. In Proceedings of the 28th International conference on Human Factors
in Computing Systems. ACM, 1107–1110.
Haichang Gao, Xuewu Guo, Xiaoping Chen, Liming Wang, and Xiyang Liu. 2008. Yagp: Yet another graphical password strategy. In Proceedings of the 24th Annual Computer Security Applications Conference.
IEEE, 121–129.
Ross B Girshick, Pedro F Felzenszwalb, and David McAllester. 2010. Discriminatively Trained Deformable
Part Models, Release 5. http://people.cs.uchicago.edu/ rbg/latent-release5/. (2010).
Brian Honan. 2012. Visual data security white paper. (2012). http://www.visualdatasecurity.eu/wp-content/
uploads/2012/07/Visual-Data-Security-White-Paper.pdf
Dawei Hong Jean-Camille Birget and Nasir Memon. 2006. Graphical passwords based on robust discretization. IEEE Transactions on Information Forensics and Security 1, 3 (2006), 395–399.
Ian Jermyn, Alain Mayer, Fabian Monrose, Michael K Reiter, and Aviel D Rubin. 1999. The design and
analysis of graphical passwords. In Proceedings of the 8th USENIX Security Symposium. USENIX Association, 1–14.
Huaizu Jiang, Jingdong Wang, Zejian Yuan, Yang Wu, Nanning Zheng, and Shipeng Li. 2013. Salient object
detection: A discriminative regional feature integration approach. In Proceedings of the 2013 IEEE
Conference on Computer Vision and Pattern Recognition. IEEE, 2083–2090.
Jeff Johnson, Steve Seixeiro, Zachary Pace, Giles Van der Bogert, Sean Gilmour, Levi Siebens, and Ken
Tubbs. US Patent 163201, 2012. Picture gesture authentication. (US Patent 163201, 2012).
Patrick Gage Kelley, Saranga Komanduri, Michelle L Mazurek, Richard Shay, Timothy Vidas, Lujo Bauer,
Nicolas Christin, Lorrie Faith Cranor, and Julio Lopez. 2012. Guess again (and again and again): Measuring password strength by simulating password-cracking algorithms. In Proceedings of the IEEE
Symposium on Security and Privacy. IEEE, 523–537.
Microsoft.
2013.
Microsoft
by
the
numbers.
http://www.microsoft.com/enus/news/bythenumbers/ms numbers.pdf. (2013).

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

1:38

Z. Zhao, G.-J. Ahn and H. Hu

Zach Pace. 2011a. Signing in with a picture password. http://blogs.msdn.com/b/b8/archive/2011/12/16/signingin-with-a-picture-password.aspx. (2011).
Zach
Pace.
2011b.
Signing
into
Windows
8
with
a
picture
password.
http://www.youtube.com/watch?v=Ek9N2tQzHOA. (2011).
Ashwini Rao, Birendra Jha, and Gananand Kini. 2013. Effect of grammar on security of long passwords. In
Proceedings of the third ACM conference on Data and Application Security and Privacy. ACM, 317–324.
Karen Renaud. 2009. Guidelines for designing graphical authentication mechanism interfaces. International
Journal of Information and Computer Security 3, 1 (2009), 60–85.
Amirali Salehi-Abari, Julie Thorpe, and Paul C van Oorschot. 2008. On purely automated attacks and clickbased graphical passwords. In Proceedings of the 24th Annual Computer Security Applications Conference. IEEE, 111–120.
Stuart Schechter, Cormac Herley, and Michael Mitzenmacher. 2010. Popularity is everything: A new approach to protecting passwords from statistical-guessing attacks. In Proceedings of the 5th USENIX
conference on Hot Topics in Security. USENIX Association, 1–8.
Stuart E Schechter, Rachna Dhamija, Andy Ozment, and Ian Fischer. 2007. The emperor’s new security
indicators. In Proceedings of the 2007 IEEE Symposium on Security and Privacy. IEEE, 51–65.
Xiaoyuan Suo, Ying Zhu, and G Scott Owen. 2005. Graphical passwords: A survey. In Proceedings of the 21st
Annual Computer Security Applications Conference. IEEE, 10–19.
Satoshi Suzuki. 1985. Topological structural analysis of digitized binary images by border following. Computer Vision, Graphics, and Image Processing 30, 1 (1985), 32–46.
Hai Tao and Carlisle Adams. 2008. Pass-Go: A proposal to improve the usability of graphical passwords.
International Journal of Network Security 7, 2 (2008), 273–292.
Julie Thorpe, Muath Al-Badawi, Brent MacRae, and Amirali Salehi-Abari. 2014. The presentation effect on
graphical passwords. In Proceedings of the 32nd annual ACM conference on Human factors in computing
systems. ACM, 2947–2950.
Julie Thorpe and Paul Van Oorschot. 2004. Towards secure design choices for implementing graphical passwords. In Proceedings of the 20th Annual Computer Security Applications Conference. IEEE, 50–60.
Julie Thorpe and Paul Van Oorschot. 2007. Human-seeded attacks and exploiting hot-spots in graphical
passwords. In Proceedings of 16th USENIX Security Symposium. USENIX Association, 8.
Julie Thorpe and Paul C van Oorschot. 2004. Graphical dictionaries and the memorable space of graphical
passwords. In Proceedings of the 13th conference on USENIX Security Symposium. USENIX Association, 135–150.
Sebastian Uellenbeck, Markus Dürmuth, Christopher Wolf, and Thorsten Holz. 2013. Quantifying the security of graphical passwords: The case of Android unlock patterns. In Proceedings of the 20th ACM
conference on Computer and Communications Security. ACM, 161–172.
Paul C Van Oorschot, Amirali Salehi-Abari, and Julie Thorpe. 2010. Purely automated attacks on
PassPoints-style graphical passwords. IEEE Transactions on Information Forensics and Security 5, 3
(2010), 393–405.
Paul C van Oorschot and Julie Thorpe. 2008. On predictive models and user-drawn graphical passwords.
ACM Transactions on Information and system Security 10, 4 (2008), 5.
Paul C van Oorschot and Julie Thorpe. 2011. Exploiting predictability in click-based graphical passwords.
Journal of Computer Security 19, 4 (2011), 669–702.
Christopher Varenhorst, MV Kleek, and Larry Rudolph. 2004. Passdoodles: A lightweight authentication
method. MIT Research Science Institute (2004).
Rafael Veras, Christopher Collins, and Julie Thorpe. 2014. On the semantic patterns of passwords and their
security impact. In Proceedings of the Network and Distributed System Security Symposium.
Paul Viola and Michael J Jones. 2004. Robust real-time face detection. International Journal of Computer
Vision 57, 2 (2004), 137–154.
Roman Weiss and Alexander De Luca. 2008. PassShapes: Utilizing stroke based authentication to increase
password memorability. In Proceedings of the 5th Nordic conference on Human-computer interaction:
building bridges. ACM, 383–392.
Susan Wiedenbeck, Jim Waters, Jean-Camille Birget, Alex Brodskiy, and Nasir Memon. 2005a. Authentication using graphical passwords: effects of tolerance and image choice. In Proceedings of the Symposium
on Usable Privacy and Security. ACM, 1–12.
Susan Wiedenbeck, Jim Waters, Jean-Camille Birget, Alex Brodskiy, and Nasir Memon. 2005b. PassPoints:
Design and longitudinal evaluation of a graphical password system. International Journal of HumanComputer Studies 63, 1 (2005), 102–127.

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Picture Gesture Authentication: Empirical Analysis, Automated Attacks, and Scheme Evaluation1:39
Qiang Yan, Jin Han, Yingjiu Li, and Robert H Deng. 2012. On limitations of designing leakage-resilient
password systems: Attacks, principles and usability. In Proceedings of the 19th Network and Distributed
System Security Symposium.
John C Yuille. 1983. Imagery, memory, and cognition. Lawrence Erlbaum Assoc Inc.
Nur Haryani Zakaria, David Griffiths, Sacha Brostoff, and Jeff Yan. 2011. Shoulder surfing defence for
recall-based graphical passwords. In Proceedings of the 7th Symposium on Usable Privacy and Security.
ACM, 6–17.
Yinqian Zhang, Fabian Monrose, and Michael K Reiter. 2010. The security of modern password expiration:
An algorithmic framework and empirical analysis. In Proceedings of the 17th ACM conference on Computer and Communications Security. ACM, 176–186.
Ziming Zhao, Gail-Joon Ahn, Jeongjin Seo, and Hongxin Hu. 2013. On the security of picture gesture authentication. In Proceedings of the 22nd USENIX Security Symposium. USENIX Association, 383–398.

ACM Transactions on Information and System Security, Vol. 1, No. 1, Article 1, Publication date: January 1.

Secure and Efficient Random Functions with
Variable-Length Output
Yan Zhua , Di Mab , Changjun Hua , Gail-Joon Ahnc , Hongxin Hud
a

University of Science and Technology Beijing, Beijing, China 100083
b
University of Michigan-Dearborn, Dearborn, Michigan 48128
c
Arizona State University, Tempe, Arizona, 85287
d
Delaware State University, Dover, Delaware, 19901

Abstract
Many random functions, like Hash, MAC, PRG, have been used in various
network applications for different security choices, however they either are
fast but insecure, or are cryptographic secure but slow. To integrate them
together, in this paper we present a new family of square random functions,
including SqHash, SqMAC and SqPRG, based on a specially truncated function (MSB or LSB), as well as circular convolution with carry bits. Provable security is provided by privacy property in hidden number problem and
Hard-core unpredication of one-way function. The experiment results show
that these schemes have better performance under different input and output
lengths. We perform four types of statistical tests for randomness. The experiments indicate that our construction has good average-case randomness
than SHA-2 and original Square algorithm.
Keywords: Algorithm, Randomness, Hash Function, Proformance
1. Introduction
Cryptographic primitives, such as Hash function, message authentication
code (MAC), and pseudorandom generator (PRG), have been widely as the
cornerstones of various cryptosystems for key/random number generation,
message authentication, key exchange, and so on. A common feature among
these functions is that their outputs are pseudo-random. So these functions
are collectively called random function. In cryptography, a random function
is essentially a one-way function, which is easy to compute on any input, but
hard to invert given an output value.
Preprint submitted to Nuclear Physics B

April 23, 2013

A (cryptographic) hash function is one of the most basic forms of random
function. It has security properties such as preimage resistance, secondpreimage resistance, and collision resistance. Based on the underlying building block, existing hash functions can be divided into two categories with
or without provable security. Hash functions in the first category have
provable security. They are usually built upon some computationally hard
problems and their security can be proved with rigorous security proofs.
These hash functions are commonly called as provable secure cryptographic
hash functions. However, these functions usually run too slow, especially
compared with their peers in the second category.
In contrary, hash functions in the second category do not have provable
security but have better performance. They are normally designed on a moreor-less Ad-Hoc basis, where bits of the input message are strategically mixed
and feedbacked over multiple rounds to produce the hash output. They are
believed to be secure, satisfying the security properties required by a hash
function. However, no formal proof can be given. Although lacking provable
security, hash functions in the second category have been largely used in the
real world due to their high performance. Standard hash functions such as
MD5, SHA-1 and SHA-2 belong to this category. The use of cryptographic
primitives with no provable security puts our systems at risk since we do not
know when and how they can be broken. Some of hash functions, including
MD5 and SHA-1, are already broken or found with much less level of security
Wang and Yu (2005). However, due to the importance of random functions in
building secure systems and their ubiquitous use on various platforms such as
phone or PDA, there is a need to have secure random functions with formal
security assurance.
A new cryptographic technique, hidden number problem (HNP) on lattice theory, provides us with a powerful tool for constructing a desired family
of random functions. For instance, it is well-known that the Square (Blum
Blum Shub) hash algorithm, is provably secure, based on the difficulty of
the quadratic residue problem (QRP). But only (log log N) lower-order bits Blum et al. (1986) is considered as random in the output of QRP modulo
a composite N, e.g., for a 1024-bit N, we can get a 10-bit random output. However, according to the new research result on HNP, we known that
(log N)/3 bits Boneh and Venkatesan (1997); Kiltz (2001) still remain random. This means that we can get about 341-bit random output. Therefore,
HNP should be an effective optimization technique to develop an efficient,
provably secure, variable-length random function. Variable-length output of
2

functions bring us great convenience in network applications.
In this paper, we first analyze the security and performance features of
the existing Square Hash function. We show several shortcomings of it. In response to these shortcomings, we present a new hash scheme (called SqHash)
based on a specially truncated function (most significant bits, MSB). We
further improve the performance of SqHash by using “circular convolution”
which makes variable-length output possible. Similarly, we present a new
MAC scheme (called SqMAC) and a new PRG scheme (called SqPRG). We
also prove that the security of these constructions based on privacy property
in hidden number problem and Hard-core unpredication of one-way function.
The experiment results show that these schemes have better performance under different input and output lengths. We also perform 4 types of statistical
tests for randomness. The experiments indicate that our construction has
good average-case randomness than SHA-2 and original Square algorithm.
The proposed schemes as well as their respective performance and security
parameters are summarized in Table 1.
Table 1: Summary of our proposed schemes.

Name
SqHash

SqMAC

SqPRG

Item
Equation
Performance
Security
Equation
Performance
Security
Equation
Performance
Security

Description
MSBk ((m||IV ) ∗′c (m||IV ))
O(n ∗ k)
Preimage resistance and Collision resistance
MSBk ((m + K) ∗′c (m + K))
O(n ∗ k)
Secret-key privacy on Hidden Number Problem
u
] 2l ((x + i + l) ∗′c (x + i + l))
LSB
O(n ∗ 2l)
Pseudorandom on Hard-core unpredictability

The remainder of this paper is organized as follows. In Section 2 and 3,
we review some preliminary background. In Section 4, 5 and 6, we present
the new Hash, MAC and PRG constructions. In Section 7, 8 and 9, we analyze the security and performance features of our schemes and the improved
schemes. Section 10 concludes the paper.

3

2. Related Work
Hash function is one of the most basic forms of random function. It
is related to (and often confused with) checksum, fingerprint, randomization function, and so on. Generally, hash functions can be divided into two
main categories: non-cryptographic hash functions and cryptographic hash
functions. The former neglects cryptographic security, so it is not cryptographically strong, but it offers these benefits: 1) it is extremely simple; 2)
it is performed on bitwise and bit shift operations; and 3) it executes quickly
on resource-limited processors. In Table 2 we show some non-cryptographic
hash functions, such as, Spooky, FNV, Lookup3, and Murmur Jenkins (2009);
Fowler et al. (1988); Appleby (2011). However, this high performance makes
it more feasible for a computer to find hash values (and thus collisions) by
brute-force.
Table 2: Hash Function Collection

Type

Hash Fct.
Invented by
Ref
Lookup3
Bob Jenkins
Jenkins (2009)
Non-Crypt.
Spooky
Bob Jenkins
Jenkins (2009)
FNV
Fowler, Noll, Vo
Fowler et al. (1988)
Hash
Murmur
Austin Appleby
Appleby (2011)
MD5
Ronald Rivest
Sasaki and Aoki (2009)
Crypt.
SHA
NSA
Sasaki and Aoki (2009)
Hash
FSB
Augot, Finiasz, etc Srinathan et al. (2007)
CBC-MAC
FIPS
Bellare et al. (2000)
MAC
HMAC
Bellare, Canetti, etc
Bellare et al. (1996)
∗
LCG
PRG
LFSR+
BBS
Blum, Shub, etc
Blum et al. (1986)
∗
+
Linear congruential generator. Linear feedback shift register.
A cryptographic hash function is a cryptographic algorithm which is able
to resist all types of attack. As a minimum, it must have the following
properties: preimage resistance, second-preimage resistance, and collision
resistance. Some existing schemes are designed on a mathematical problem
and thus their security follows from rigorous mathematical proofs for properties. Such a function is called provably secure cryptographic hash functions,
such as Square Blum et al. (1986). Another existing schemes are not based
4

on mathematical problems but on an Ad-Hoc basis, where the bits of the
message are mixed to produce the hash. They are then believed to be hard
to break, but no such formal proof is given. Almost all widely-spread hash
functions fall in this category. For example, we shown three common cryptographic hash functions: MD5, SHA, and FSB Sasaki and Aoki (2009);
Srinathan et al. (2007). Some of these functions are already broken and are
no longer in use.
A MAC function, called a keyed hash function, can protect both a message’s data integrity as well as its authenticity, so we requires that it must resist existential forgery under chosen-plaintext attacks (EF-CPA). This means
that even if an adversary obtains some MACs for messages chosen by himself,
it is unable to guess the MAC for a new message. The MAC is usually constructed from hash function (e.g. HMAC) or from block cipher algorithms
(e.g. CBC-MAC) Bellare et al. (2000, 1996), as described in Table 2.
Another important tool is pseudorandom generator (PRG), which is widely applied anywhere in cryptography and some applications (i.e., gambling).
Some simple methods, such as, linear feedback shift register (LFSR) and Linear congruential generators (LCG), have long been used as PRG for cryptosystem. Unfortunately, these methods are not secure for cryptographic
applications. For example, an LFSR is a linear system, leading to fairly easy
cryptanalysis; and LCG is not suitable for a Monte Carlo simulation because
of the serial correlation. There exists some cryptographically secure PRG
schemes, e.g., Blum Blum Shub (BBS) which has probable security under
assumption of Quadratic residuosity problem Blum et al. (1986). However,
this scheme is not appropriate for use in applications because it is very slow.
3. Background and Preliminaries
3.1. System and Construction Criteria
In this paper, we assume that a network device does not have a dedicated
cryptographic hardware. In particular, it does not have a true random number generator. We assume that the device only has a short length (32 bits)
accumulator and a 1-bit multiplication unit (it can be replaced by 1-bit accumulator), as well as a big enough memory. In addition, in MAC and PRG,
we assume that there exists a secure storage unit which can prevent the disclosure of stored information. It is used to store the user’s secret key and the
current value of counter. Variable-length random function means that the
output length of function can be changed in terms of user’s requirements:
5

Definition 1 (Variable length random function) A random function is
a family of functions VL-RF: D → R, where D is the message space with
variable length, R is the range with variable desired length, and |D| ≥ |R|.
The output length m = |R| is an important parameter which related to
the security of function. According to the birthday attack, the output length
is at least m = 2κ-bit to remain collision resilient for a given secure parameter
κ. In this case the security of random function is enhanced against collision
attack with the increase of κ. For example, the random function with 341bit output is more secure than that with 160-bit. Note that, we choose an
appropriate κ in terms of the security requirements of application.
In addition, the value λ = max{ |R|
} is called compression ratio. Typ|D|
ically λ is less than 1. When λ = 1, a random function is called random
permutation, which can be used to construct the encryption scheme. Given
a random function fk (x) with a certain λ, it is well-known that the output
with m ≤ λ · |R|-bit holds good randomness and privacy for the input secret
k in terms of HNP. For instance, when λ = 1/3 and |R| = 1024-bit, the output with m ≤ 1024/3 = 341-bit is random and secure against HNP attack.
Further, λ is not a strict limit, e.g., a 381-bit output is also secure in this
example if the ration is considered as λ + ǫ, where ǫ is enough small.
We define the following quality criteria for a family of Hash/MAC/PRG
functions intended for mobile devices and how they can be constructed:
Ease-of-realize: A family of Hash/MAC/PRG functions should be designed
on a unified framework for simplifying the program coding. Our design
principles are clear, so that anyone (for non-expert) can easily understand,
realize, and use them without cryptography expertise.
Performance: The function value has to be calculated on common mobile
devices which have a simple ALU and a modest memory. The performance
is very critical because an execution point like a anti-spam (unsolicited
commercial e-mail) filter has a limited amount of energy. Typically, only a
small contingent of the resources are need to allocate for non-cryptographic
algorithms and they has better performance than cryptographic algorithms.
Provable Security: It is required that the security of these functions follows from rigorous mathematical proofs, complexity theory and formal

6

reduction. Generally, those functions whose designs are based on a mathematical problem are called provably secure cryptographic functions. Moreover, these functions should have the basic security properties, e.g., the
Hash/MAC function satisfies pre-image resistance, second pre-image resistance and collision resistance; and the PRG function is indistinguishable
from truly random sequences.
Non-linearity and Unbiasedness: A good Hash/MAC/ PRG function should
map the expected inputs as evenly as possible over its output range. This
means that our construction must meet some basic cryptographic requirements, in which the non-linearity and unbiasedness properties are two
well-known cryptographic criterions. A non-linear function f has a linear independency between input values x and y to output values, e.g.
f (x + y) 6= f (x) + f (y). Similarly, an unbiased function’s output yields as many 0s as 1s over its input set. We follow these criterions in our
construction.
3.2. Basic Mathematic Problems
We refer to {0, 1}∗ as strings and {0, 1}l as l-length strings. If x is a string
or a number then |x| denotes its length in bits. For l ∈ N, we denote by 1l
the string of l “1” bits. Let || denote concatenation. For sets X and Y , if
f : X → Y is a function, then we call X the domain, Y the range, and the
set {f (x)|x ∈ X} the image of the function. An adversary is an algorithm.
By convention, all algorithms are required to be efficient, meaning run in
(expected) polynomial-time in the length of their inputs, and their runningtime includes that of any overlying experiment.
• Integer Factoring Problem. Integer factorization is the decomposition
of a composite number into smaller non-trivial divisors. That is, given
N = pq, for any polynomial time (in |N|), and algorithm A and any polynomial P (·), for sufficiently large |N|, the factoring assumption holds that
Pr[(p, q) = A] ≤ 1/P (|N|), where 1/P (|N|) denotes a negligible probability and |N| = 1024 is often chosen in practice.
• Quadratic Residue Problem. Let N = pq be the public key and p ≡
q ≡ 3 (mod 4). The Rabin function computes y = x2 (mod N) for x ∈
Z∗N . The square root problem says that given y ∈ ZN , without (p, q), to
find x such that y = x2 (mod N) is as hard as factoring N. Note that
there are four distinct roots x, including two group trivial roots (±x).
7

• Hidden Number Problem. The goal of square hidden number problem
(SqHNP) Boneh et al. (2001) is to find a hidden number s, when given N and access to an oracle that on query (x1 , · · · , xm ) returns a value
(MSBk ((x + s)2 (mod N)), · · · , MSBk ((xn + s)2 (mod N))), where the
operation MSBk (y) denotes the k most significant bits of y. The SqHNP assumption states that there is no polynomial time algorithm for this
problem whenever k = |N|/3.
Given a prime p ≡ 3 (mod 4), the square roots y modulo p can be computed by xp = y (p+1)/4 (mod p). Note that there is no square root for some
numbers. When xp and xq are known, the square root problem can be resolved by Chinese remainder theorem. It has been proven that decoding the
Rabin cryptosystem is equivalent to the integer factorization problem. This
cryptosystem is provably secure (in a strong sense) against chosen plaintext
attacks.
4. Construction of Hash Function
4.1. Square Hash and Its Shortcomings
A cryptographic hash function Hash : {0, 1}∗ → {0, 1}k is a function
that takes an arbitrary block of data and returns a fixed-size bit string. A
square hash function Etzel et al. (1999) is a cryptographic hash function
with ZN → ZN for an enough large N, where it is hard to factorize N.
Definition 2 (Basic Construction) The SQH family of hash functions
from ZN to ZN is defined as: {f : ZN → ZN } where the functions f are
defined as
f (m) = m2 (mod N),
where, N − N 1/2 > m > N 1/2 and |N| = n.
If m < 2n/2 , we have m2 < 2n < N, which means that m2 (mod N) =
m2 . In this case, given a hash value y ∈ ZN , we can use the split half
method (or logarithmic search) to find m such that m2 = y because m2 is a
monotone increasing function. Similarly, another trivial root of m2 (mod N)
is N − m < N 1/2 due to (N − m)2 = m2 < N.
This basic construction has the following shortcomings:

8

1. Assume that the length of N is n, the computation overhead of SQH
function are O(n2 ). When n is large, the factorization of N is hard. But
O(n2 ) is too large for frequent operations in mobile derives.
2. The output of SQH function is |N| bits. Since we use SQH function with
at less 1024-bits modulus size for secure integer factorization problem, the
hash output size is at less 1024 bits. But the output of SHA-512/384 is
just 512 or 384 bits with 1024-bit block size. Hence, the output of SQH
function is too large for applications. Also, this feature is contradictory to
the compression property of hash functions.
3. When m is too small (such as m < N 1/2 ), the output of SQH function is
predictable in terms of above discussion. This predictability is considered
as one such possible vulnerability that may be insecure for some applications.
We will focus on addressing these shortcomings by constructing more effective
schemes in the remaining of this section.
4.2. Hash Function for ZN → {0, 1}k
We present a new construction of square hash function to resolve the
shortcomings in the basic construction as follows:
Definition 3 (Square Hash Construction) Define a family of SqHash
functions from ZN to {0, 1}k as: SqHash = {fIV : ZN → {0, 1}k |IV ∈
{0, 1}l } where the function f is defined as
fIV (m) = MSBk ((m||IV )2

(mod N)),

where, IV denotes an initialization vector and MSBk (t) denotes k most
significant bits of an integer t.
Compared with the basic construction, SqHash has several advantages.
Firstly, the output of SqHash is k bits in that MSBk () can be considered
as a truncation function. For instance, k is 384 bits like SHA384. Next, let
m||IV = m · 2l + IV . The initial vector IV increases the randomness of the
output of SqHash function as a result of (m · 2l + IV )2 = m2 · 22l + IV 2 +
m · IV · 2l+1 (mod N), especially for the item m · IV · 2l+1 . Moreover, this
construction also helps avoid collision, that is, given a value y and a square
9

root m (m2 = y (mod N)), we can check IV to determine whether this value
is a valid pre-image of the four square roots of y.
Unfortunately, this construction does not reduce the computational complexity because we still need to perform the squaring operation. Hence, we
make use of “modulo-|N| circular convolution with carry bit” m ∗c m to replace the multiplication m·m. The notation ∗c for cyclic convolution denotes
convolution over the cyclic group of integers modulo |N| Shamir (2008), that
is,
n−1
X
f [i] · g[(k − i) mod n],
(f ∗c g)[k] =
i=0

where, n = |N| and a[k] denotes the k-th bit of integer a.
In order to simulate the multiplication operation, we define circular convolution with carry bit as follows:
r[k] = (f ∗c g)[k] + ck−1 (mod 2)
ck = ((f ∗c g)[k] + ck−1 − r[k])/2
where, r[k] is the k-th output bit, ck denotes the k-th carry bit, and c0 = 0. In
Fig. 1, we show the difference between multiplication operation and circular
convolution with carry bit. It is obvious that the latter is a more efficient
process. Let ∗′c denote above circular convolution with carry bit. The SqHash
function can be redefined as
fIV (m) = MSBk ((m||IV ) ∗′c (m||IV )).
Note that we do not need module operations in this construction. Furthermore, another advantage of this construction is that we only need to
calculate k most important bits without having to calculate other bits. For
example, when N = 1024 bits and k = 384 bits, the computational overheads
are 3/8 of those of multiplication operations. Note that the circular convolution does not change the nature of squaring operation in SqHash scheme.
Thus, this transformation from squaring to convolution does not affect the
security of SqHash scheme.
4.3. Hash Function for {0, 1}∗ → {0, 1}k
A hash function must be able to process an arbitrary-length message into
a fixed-length output. Usually, this can be achieved by breaking the input up
into a series of equal-sized blocks, and operating on them in sequence using a
10

an-1b1

an-1

an-2

ĂĂ

a1

a0

bn-1

bn-2

ĂĂ

b1

b0

an-1b0

an-2b0

ĂĂ

a1b0

a0b0

an-2b1

an-3b1

ĂĂ

a0b1

ĂĂ

ĂĂ

ĂĂ

an-1bn-2

ĂĂ

a2bn-2

a1bn-2

a0bn-2

an-1bn-2

an-2bn-1

ĂĂ

a1bn-1

a0bn-1

c2n-1

c2n-2

ĂĂ

cn

cn-1

cn-2

c1

an-1

an-2

an-3

ĂĂ

a1

a0

bn-1

bn-2

bn-3

ĂĂ

b1

b0

an-1b0

an-2b0

an-3b0

ĂĂ

a1b0

a0b0

an-2b1

an-3b1

an-4b1

ĂĂ

a0b1

an-1b1

ĂĂ

a0bn-2

an-1bn-2

ĂĂ

an-2bn-2

a2bn-2

a0bn-1

an-1bn-2

an-2bn-1

ĂĂ

an-3bn-1

a1bn-1

cn-1

cn-2

cn-3

c1

c0

an-1

an-2

an-3

a1

ĂĂ

a0

bn-1

bn-2

bn-3

b1

ĂĂ

b0

an-1b0

ĂĂ

an-3b0

a1b0

ĂĂ

a0b0

an-2b1

ĂĂ

an-4b1

a0b1

ĂĂ

an-1b1

a1bn-2

ĂĂ

an-1bn-2

an-2bn-2

ĂĂ

a2bn-2

a0bn-1

ĂĂ

an-2bn-1

an-3bn-1

ĂĂ

a1bn-1

cn-1

ĂĂ

cn-3

c1

ĂĂ

c0

ĂĂ

ĂĂ

ĂĂ

ĂĂ

ĂĂ

ĂĂ

ĂĂ

ĂĂ

ĂĂ
a1bn-2

c0

Computed MSB part

Figure 1: Multiplication and circular convolution.

11

one-way compression function. Hence, we define the hash function {0, 1}∗ →
{0, 1}k based on the SQH function as follows: given m = (mn , · · · , m1 , m0 ),
σ0 = MSBk ((m0 ||IV ) ∗′c (m0 ||IV ));
···
···
σi = MSBk ((mi ||σi−1 ) ∗′c (mi ||σi−1 ));
···
···
σn = MSBk ((mn ||σn−1 ) ∗′c (mn ||σn−1)).
The final output of hash function is σn . The last processed block should
also be unambiguously length padded. This is crucial to the security of our
construction. Fig. 2 depicts such a construction. This kind of construction
is also called Merkle-Damgärd construction Coron et al. (2005), in which any
collision for the full hash function can be traced back to a collision in the
compression function.
*c

M0

IV

σ1

*c

M1

σ0

σn-1

*c

Mn-2

σn-2

σn

*c

Mn-1

σn-1

ĂĂ

ĂĂ

σ0

Figure 2: Hash construction for arbitrary-length messages.

5. Construction of MAC Function
Message authentication code (MAC), sometimes called keyed (cryptographic) hash function, specifies that an authenticated tag between two parties that share a secret key in order to validate message transmitted between
these parties. The MAC value protects a message’s data integrity and its
authenticity by allowing verifiers (who also possess the secret key) to detect
any changes in the message content. Typically, MACs are built from hash
functions. Based on square function, we define the square MAC (in short
SqMAC) function as follows:
12

Definition 4 (Square MAC Construction) Let N be an integer to make
the factorization attack difficult and k ∈ N. A square MAC function from
M × K to {0, 1}k is defined as: {SqMACk : ZN × ZN → {0, 1}k } where
SqMACk (K, m) = MSBk ((m + K)2

(mod N)),

and K is a secret key with |K| = |N|.
In this construction, MSBk () is necessary for ensuring security because,
without this operation, the secret key K can be computed by
K=

σ2 − σ1
m1 + m2
−
2(m2 − m1 )
2

(mod N)

if we have two pairs (m1 , σ1 ) and (m2 , σ2 ), where σ1 = (m1 + k)2 and σ2 =
(m2 + x)2 (mod N). In addition, we prove that the secret key K cannot be
revealed in terms of Theorem 1 even if the adversary has observed a lot of
message-MAC pairs.
We also make use of circular convolution to replace the square operation
for obtaining higher efficiency, that is,
SqMACk (K, m) = MSBk ((m + K) ∗′c (m + K)).
Next, we focus on the MAC construction for arbitrary-length message to
be authenticated. HMAC is such a MAC. HMAC(K,m) is mathematically
defined by
HMAC(K, m) = H((K ⊕ opad)||H((K ⊕ ipad)||m)),
where H(·) denotes a hash function. Based on this construction, we present
a new MAC function by extending the function SqMACk (·) and abovementioned hash function for {0, 1}∗ → {0, 1}k , as follows:
1. To compute the hash value σn based on the algorithm in Section 4.3
but the initialization vector IV will be replaced by K; and
2. To output the MAC code by using SqMACk (K, m′ ) and m′ = K||σn .
In this construction, m′ = K||σn is used to expand the length of authenticated message.
13

6. Construction of Pseudorandom Generator
A pseudorandom generator, abbreviated as PRG, is an efficiently-computable
function which generates a sequence of {0, 1} that approximates the properties of random string. Strictly speaking, no efficient algorithm can distinguish
this sequence from a random sequence with significant advantage. Although
there exists some practical PRG algorithms, such as, linear congruential generators (LCG), lagged Fibonacci generators (LFG), and linear feedback shift
registers (LFSR), we present a fast PRG construction based on square problem with a simple counter.
6.1. Secure Square-PRG
In this subsection, we present a new PRG function on the modular square
root (MSR) problem. Although we have constructed secure Hash and MAC
scheme based on the MSR problem, it is still a challenging task for constructing secure PRG function due to its higher security requirements. Strictly
speaking, PRG function can be constructed on the Hard-core predicate of a
one-way function, but Hash/MAC function only needs the one-way property Berbain et al. (2006). Hence, we first focus on the Hard-core predicate of
MSR problem.
To generate pseudorandom number, we assume that a secret x is stored
in the device and a counter mi is used to produce different output of PRG
function for each PRG query, that is, mi+1 = mi + 1 should be updated
automatically. Note that the value mi should be kept secret. Based on these
assumptions, we define a one-way function as
fx (mi ) = (x + mi )2

(mod N).

Next, we find out the Hard-core predicate of this function according to
the following theorem:
Theorem 1 The two least significant bits (LSB) of next function output
MSBk (fx (mi )) can only be guessed with 1/3 probability if mi is an unknown
counter.
Proof. Let mi+1 = mi + 1.

Given two continuous values fx (mi ) and

14

fx (mi+1 ), we have the following equation
fx (mi+2 ) =
=
=
=

(x + mi + 2)2
(x + mi )2 + 4(x + mi ) + 4
2(x + mi + 1)2 − (x + mi )2 + 2
2fx (mi+1 ) − fx (mi ) + 2.

Assume that e and e′ are two l = |N| − k bits numbers. Let fx (mi+1 ) =
MSBk (fx (mi+1 )) · 2l + e (mod N) and fx (mi ) = MSBk (fx (mi )) · 2l + e′
(mod N), so that we have the following equation
MSBk (fx (mi+2 )) = MSBk (2fx (mi+1 ) − fx (mi ) + 2)
= 2 · MSBk (fx (mi+1 )) −
MSBk (fx (mi )) +
MSBk (2e − e′ + 2) (mod N).

In terms of 0 ≤ e, e′ < 2l , we have −2l < 2e − e′ + 2 < 2l+1 . This means
that

2e − e′ + 2 < 0
 −1
′
0
0 ≤ 2e − e′ + 2 < 2l
MSBk (2e − e + 2) =

+1
2l ≤ 2e − e′ + 2

Hence, MSBk (fx (mi+2 )) has three possible values and each value can
be guessed with the same probability 1/3 according to the difference of
LSB2 (MSBk (fx (mi+2 ))).

This theorem indicates the Hard-core predicate of fx (m) is LSB2 (MSBk (fx (m))).
Further, it means that we can guess 2l-bits in the l-th next value with the
probability 31l . Hence, in order to improve efficiency, the successive 2l bits
can be outputted LSB2l (MSBk (fx (mi + l))), where mi is the counter of previous output value. Thus, we define a new square PRG function as follows:
Definition 5 (Secure Square-PRG) Given a counter i, a family of square
PRG functions with 2l-bits output is defined as: {SqP RGx,i,k : 12l → {0, 1}2l |x, i ∈
ZN , k ∈ N}, where the function SqP RG is defined as
SqP RGx,i,k (12l ) = LSB2l (MSBk ((x + i ∗ l)2

(mod N))),

where, MSBk (t) and LSBk (t) denote k most and least significant bits of an
integer t, the counter is updated to i + l after this process, and N − N 1/2 >
x > N 1/2 .
15

6.2. Efficient Implementation
To implement SqP RG function, we can still use the “circular convolution
with carry bit” to reduce the computational overheads, but we must deal
with how to compute a particular bit (specially for LSB bits) correctly in
m2 (mod N). More precisely, in order to be certain about the effect of the
carry entering this bit (or LSBl ) position, we have to compute all earlier
bits in the worst case. Fortunately, it is easy to show that the carry into
each bit position in the computation of m2 can be at most 11 bits long 1 for
|N| between 1024 and 2048. Thus, if we add u = 32 additional low order
bits to the computed window, we have only a small (negligible) probability
of less than 211 /232 = 1/221 of computing an incorrect carry into the 33-th
u
] l ). We
bit we compute. We call it “least significant bits with window” (LSB
present this process in Fig. 3.
an

ĂĂ

an-k-2l+1

an-k-2l

ĂĂ

an-k

an-k-1

ĂĂ

an-k-u

an-k-u-1

ĂĂ

a0

bn

ĂĂ

bn-k-2l+1

bn-k-2l

ĂĂ

bn-k

bn-k-1

ĂĂ

bn-k-u

bn-k-u-1

ĂĂ

b0

anb0

ĂĂ

amb0

amb0

ĂĂ

ak-2b0

an-3b0

ĂĂ

aub0

a1b0

ĂĂ

a0b0

an-1b1

ĂĂ

am-1b1

am-1b1

ĂĂ

ak-3b1

an-4b1

ĂĂ

au-1b1

a0b1

ĂĂ

an-1b1

a2bn-2

ĂĂ

am+2bn-2

am+2bn-2

ĂĂ

ak+1bn-2

an+1bn-2

ĂĂ

au+2bn-2

an-2bn-2

ĂĂ

a2bn-2

a3bn-1

ĂĂ

am+1bn-1

am+1bn-1

ĂĂ

ak+2bn-2

au+1bn-1

ĂĂ

au+1bn-1

an-3bn-1

ĂĂ

a1bn-1

c1

ĂĂ

cm

cn-1

ĂĂ

ck+2

cn-3

ĂĂ

c1

c1

ĂĂ

c0

Additional Bits

Output Bits

Computation Window

Figure 3: Circular convolution for least significant bits with window.

So that we can replace the above SqP RG function by using
u

] 2l ((x + i ∗ l) ∗c (x + i ∗ l)).
SqP RGx,i,k (12l ) = LSB
This can guarantee an extremely small error probability while keeping
the average running time only slightly higher than always computing l + 32
bits.
1

The value of carry bit is at most 211 − 1, so it can effect at most log2 (211 − 1) ≈ 11
bits long.

16

7. Security Analysis
7.1. Security analysis of SqHash functions
The SQH function fIV (m) is a cryptographic hash function with preimage resistance and collision resistance Ouafi and Vaudenay (2009). The latter property also means that this function is second-preimage resistance.
The preimage resistance stems from the fact that Square function y = x2
(mod N) is a trap-door one-way function in that given y, without (p, q), to
find x such that y = x2 (mod N) is as hard as factoring N.
The collision resistance is based on the infeasibility of integer factoring
problem Dubois et al. (2007). Assume that given y, there exist two values x1
and x2 for (x1 ||IV )2 = (x2 ||IV )2 (mod N) and x1 6= x2 , such that we have
(x1 ||IV )2 − (x2 ||IV )2 = (x1 − x2 )((x1 + x2 )2l + 2 · IV ) · 2l = 0 (mod N). This
means that N|(x1 − x2 )((x1 + x2 )2l−1 + IV ). Thus, we can find a factor of
N by using gcd((x1 − x2 ), N) only if not N|((x1 + x2 )2l−1 + IV ). Otherwise,
we can repeat this process to find out the factor of N. Further, given a
fragment MSBk (y) of y, it is harder to find a valid x which includes IV ,
that is, y = (x||IV )2 (mod N). Even if with (p, q), it is hard to find a valid
e with y = MSBk (y)||e such that y = (x||IV )2 (mod N).
7.2. Security analysis of SqMAC functions
Given the function SqMACk (K, x), we prove that the secret key K cannot
be revealed even if the adversary obtains sufficient message-MAC pairs. In
this proof, we consider a hidden number problem: Let K be a random hidden
element of ZN . We are given N, k = |N|/3, |N| = n, and (xi , MSBk ((xi +K)2
(mod N))) for random values x1 , · · · , xt . The problem is to find K. That is,
we assume that MSBk ((xi + K)2 (mod N))) = yi , so that we have
x2i + K 2 + 2xi K = yi · 2k + ei

(mod N),

i = 1, · · · , t

where ei are variables that correspond to unknown low order bits and
|ei | ≤ 2n−k = 22|N |/3 . We are therefore forced to eliminate unknown K 2 from
the above relation by using the equation:
x2i − x21 + 2(xi − x1 )K = (yi − y1 )2k + (ei − e1 ) (mod N).

17

Next, we also eliminate K by the equation:
(x2i − x21 )(xi − x1 ) − (x2j − x21 )(xj − x1 )
= (xi − x1 )(xj − x1 )(xi − xj )
= (xi − x1 )(yi − y1 )2k − (xj − x1 )(yj − y1 )2k +
(xi − x1 )(ei − e1 ) − (xj − x1 )(ej − e1 ) (mod N).
Also, we rewrite this equation as a polynomial in the unknown ei , ej , e1 ,
namely:
fi (ei , ej , e1 ) := Ai,1 ei + Bj,1 ej + Ci,j e1 − Xi,j

(mod N).

where Ai = xi − x1 , Bj = x1 − xj , Cj = xj − xi , and Xi = ((xi − x1 )(yi − y1 ) −
(xj − x1 )(yj − y1 ))2k − (xi − x1 )(xj − x1 )(xi − xj ). Based on this function,
we setup a lattice of dimension 2t − 1 as a real matrix M:
















1
0
0
0
0 2k−n
0
0
0
0
2k−n
0
k−n
0
0
0
2
..
..
..
..
.
.
.
.
0
0
0
0
0
0
0
0
..
..
..
..
.
.
.
.
0
0
0
0

···
···
···
···
..
.

0
0
0
0
..
.

X3,2
C3,2
B2,1
A3,1
..
.

···
···
···
···
..
.

Xt,2
Ct,2
B2,1
0
..
.

···
···
..
.

2k−n
0
..
.

0
N
..
.

···
···
..
.

At,1
0
..
.

···

0

0

···

N















Next, we set v = (1, e1 , e2 , · · · , et , k2 , · · · , kt ). It follows that for this
integer vector v we get:
et
e1
v · M = (1, n−k , · · · , n−k , 0, · · · , 0).
2
2
Thus, the lattice point v · M has only t + 1 non-zero entries,
and each
√
of these is less than 1. And its Euclidean norm is less than t + 1. On the
other hand, it is easy to see that the determinant of the lattice L(M) equals
N t−2 · 2(k−n)t . In addition, making using of the Gaussian heuristic for short
lattices vectors, we
is the shortest point in this lattice
√expect that
√ our vector
t−2
L(M) as long as t + 1 ≪ 2t − 1(N
· 2(k−n)t )1/(2t−1) q
. Let N ≈ 2n and
ignoring low-order terms, this condition is simplified to

t+1
2t−1

≈ 2−1/2 ≪

2k/2−n/t < 2k/2 = 2n/6 . Therefore, the Lattice-based reduction methods
cannot find the secret K Boneh and Venkatesan (1997).
18

7.3. Security analysis for SqPRG function
The security requirement for PRG function is that the output of pseudorandom sequences should be computationally indistinguishable from truly
random sequences. For practicality, such pseudorandom generators can be
constructed easily on the hard-core predicates. In fact, we have proved that
our SqPRG function is constructed on the hard-core predicates with the
probability 1/3l for 2l-bits outputs in Theorem 1.
8. Improved Algorithms
We use two different approaches (i.e., the truncated function and circular
convolution) to improve the performance of all proposed schemes. Usually,
long-size cryptographic algorithms are not suitable for providing security on
wireless devices due to their limited computation and communication capabilities. In a cryptosystem, key length is usually much longer than the “word
size” of mobile devices, typically 16 or 32 bits. Using short ALU to deal
with long data often leads to more complex programs for cryptography algorithms. Moreover, traditional Hash/MAC/PRG functions do not contain
algebra operations thus ALU computing power would normally not be fully
utilized. However, the algorithms proposed in this paper are easy to implement, and can take advantage of ALU computing power. We will give basic
construction on MSB and convolution, on which SqHash/SqMAC/SqPRG
can be easily constructed.
First, our basic construction (called “Convol-MSB” algorithm in Fig.4)
can be implemented easily on mobile devices. We improve the computation
by replacing integer multiplication with circular convolution. The advantage
of this method is that each output bit is calculated from right to left, while
traditional multiplication is from top to bottom, then right to left (see Fig.
1). In addition, we also use MSB operation (with window) to further reduce computation overheads. Based on them, the computation complexity
of “Convol-MSB” is O(kn) instead of O(n2 ) in the traditional multiplication
way. This is equal to about k/n of the original overhead.
The basic “Convol-MSB” algorithm is constructed on bit-AND operator.
Thus, it does not take full advantage of the ALU computing resources. Taking
into account of bit-parallel processors in ALU hardware, we improve the
above-mentioned algorithm to a new “Convol-MSB-IMP” algorithm in Fig.
5. In this algorithm, we make use of the algorithm CyclicLef tShif t(x, k) to
cycles k positions to the left for the elements in x. Furthermore, we use a ∗ .b
19

Table 3: Comparisons among SqHash, SqMAC, SqPRG and their improved schemes.

Name
SqHash

SqMAC

SqPRG

Item
Equation
Performance
Improved Equation
Performance
Equation
Performance
Improved Equation
Performance
Equation
Performance
Improved Equation
Performance

Description
MSBk ((m||IV )2 (mod N))
O(n2 )
MSBk ((m||IV ) ∗′c (m||IV ))
O(n ∗ k)
MSBk ((m + K)2 (mod N))
O(n2 )
MSBk ((m + K) ∗′c (m + K))
O(n ∗ k)
LSB2l (MSBk ((x + i + l)2 (mod N)))
O(n2 )
u
] 2l ((x + i + l) ∗′c (x + i + l))
LSB
O(n ∗ (2l + u))

to give the bitwise AND of a and b, and Sum(x) to give the total number of
elements in list x. Based on these improvements, the computation overhead
is further reduced to O(kn/w) since the actual scale is the word size of mobile
devices w in each parallel processing. Note that above pseudo-codes are not
real ALU calls and we need to expand these calls according to actual input
length.
In Table 3, we give a summary of the performance estimate of SqHash,
SqMAC, and SqPRG compared with corresponding improved schemes. Obviously, the improved scheme achieves a computational overhead (O(nk))
smaller than the original schemes (O(n2 )). The ratio between them is about
k/n = O(nk)/O(n2). This result is benefited from the use of truncated function MSB or LSB, as well as circular convolution operation. In addition,
these truncated functions also increase the difficulty of attacks against the
improved schemes. Moreover, the overhead O(nk) means that the scheme
is less sensitive than the original scheme for data length n. For example,
when we want to double the length of processed message, the overhead of
improved schemes will increase by about 100% (from O(nk) to O(2nk)), but
in the original schemes those will increase by about 400% (from O(n2 ) to
O(4n2)).
To validate the efficiency of our approach, we implemented several algorithms in the Mathematica 7.0 environment. In Fig. 6, we show a compar20

Algorithm Convol-MSB(x, n, k)
Require: x is an input integer, n is the length of x, and k is the
length of output result.
s = 0;
for i = n − k + 1 to n do
for j = 1 to n do
r = x[j] · x[(i − j) (mod n)];
s = s + r;
end for
idx = i − n + k;
r[idx] = s (mod 2);
s = (s − r[idx])/2;
end for
Return r;
Figure 4: Basic convolution-MSB algorithm.

Algorithm Convol-MSB-IMP(x, n, k)
Require: x is an input integer, n is the length of x, and k is the
length of output result.
tx = CyclicLeftShift(x, n − k);
s = 0;
for i = 1 to k do
tx = CyclicLeftShift(x, 1);
t = x ∗ .tx ;
r[i] = sum(t + s) (mod 2);
s = (sum(t + s) − r[i])/2;
end for
Return r;
Figure 5: Improved convolution-MSB algorithm.

ison of experimental results among Square, convolution-MSB and improved
convolution-MSB algorithms. In this figure, the total length of N is changed
from 512 to 1024-bits and the size of output results is about 1/3 of length of
N. The computation cost is proportional to |N| for the square algorithm and
the convolution-MSB algorithm and the length of N has a greater impact on
the Square algorithm. However, the computation cost is independent to the
length of N in the improved convolution-MSB algorithm. In summary, the
21

0.5

0.4

Square

Computation Overheads (s)

Convol-MSB
Convol-MSB-IMP
0.3

0.2

0.1

0.0

500

600

700

800

900

1000

The length of N (bits)
(the output bits is 1/3 of |N|)

Figure 6: Comparison of experimental results among Square, convolution-MSB and improved convolution-MSB algorithms.

experimental results show that our improved convolution-MSB method has
better performance than general square algorithm.
Table 4: The result of variable length experiments

No.
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31

ratio
10/32
32/96
53/160
74/224
96/288
117/352
138/416
160/480
181/544
202/608
224/672
245/736
266/800
288/864
309/928
330/992

cycles
0.003
0.010
0.022
0.040
0.065
0.092
0.123
0.158
0.201
0.258
0.310
0.374
0.436
0.496
0.587
0.678

seconds
0.000001
0.000005
0.000010
0.000019
0.000032
0.000045
0.000061
0.000078
0.000100
0.000128
0.000154
0.000186
0.000218
0.000248
0.000293
0.000347

No.
2
4
6
8
10
12
14
16
18
20
22
24
26
28
30
32

ratio
21/64
42/128
64/192
85/256
106/320
128/384
149/448
170/512
192/576
213/640
234/704
256/768
256/832
298/896
320/960
341/1024

cycles
0.006
0.017
0.030
0.050
0.076
0.107
0.152
0.181
0.234
0.275
0.347
0.408
0.463
0.530
0.607
0.694

seconds
0.000002
0.000007
0.000015
0.000024
0.000037
0.000053
0.000075
0.000090
0.000117
0.000137
0.000174
0.000204
0.000231
0.000265
0.000295
0.000347

To evaluate the performance, we use Mathematica7 and C language to
realize our schemes. The median runtime of SqHash (—N—=1024 and
k=384) is 0.0065 seconds/operation for Mathematica 7 and 0.000381 second22

s/operation for VC 2005 in a 32-bit Window 7 system. The median number
of CPU cycle counting is about 0.79 Millicycles/operation. We find that our
SqHash, SqMAC, SqPRG schemes and some existing standards have the almost same overheads if the benefits of assembly language are not considered.
In addition, the SqHash has a concise and clear programm coding: 40 lines
for Mathematica and 150 lines for C language.
Further, we evaluate the performance of variable-length output for one
operation. In this experiment, the input length of SqHash is changed from
32 bits to 1024 bits, and it generates an output in accordance with the
ratio of 1/3, i.e., changed from 10 bits to 341 bits. The results, including
median CPU cycle counting and median runtime, are shown in Table 4. It
is easy to see that computational complexity appears to grow linearly with
the output length. The SqHash not only has similar performance with noncryptographic schemes for a shorter output, but also has good performance
with cryptographic schemes for a longer output.
9. Statistical Tests
The security proofs have shown that our schemes are able to resist some
common attacks, but this does not mean that they have excellent properties
to meet the requirements of various applications. To end it, a set of statistical
tests for randomness are described in this section. In our statistical tests,
the performance of our schemes and SHA-2 functions is measured by several
valuation tools written in Mathematica 7 and VC 2005. These tools are run
on a IBM desktop PC (2.0 GHz and 2 GB RAM) with Windows 7 OS.
9.1. Entropy Testing
Shannon entropy is a common measure of the uncertainty associated with
a random variable. In cryptanalysis, entropy is often roughly used as a
measure of the unpredictability of random sequences, e.g., a cryptographic
key. For a “true” random sequences, “0” and “1” both are statistically
independent and have equal probability 1/2, hence the entropy rate of the
sequence is 1 bit per character. In Figure 7(a), we show the measurement
results of one-bit entropy testings in three schemes: SHA-2 (SHA-256), SQH
and SqHash functions. The former has the 256-bit output size and the latter
two are 384 bits. In this experiment one can observe that the entropy rate
of sequence tends to 1 bit per character (0/1) when the length of three
sequences is increased from 1,024 to 10,240 bits. It is easy to find that the
23

one-bit randomness of SqHash function is basically the same as those of SQH
and SHA-2 functions. More accurately, Figure 8 (a) shows the measurement
results of 8-bit entropy testings: the entropy tends to 7.9 with increase of
sequence length, that is, the entropy rate tends to 0.98 bit per character
(0/1). This means that the 8-bit randomness of SqHash function is basically
the same as those of SQH and SHA-2 functions. To extend this result, a
n-bit key that is randomly generated has approximate n bits of entropy. It
takes (on average) 2n−1 guesses to break by brute force.
1.0002

2.0
SQH: Chi-square

1.0000

SHA2: Chi-square

0.9996

Test Statistic Values

Entropy Values

SqHash: Chi-square

1.5

0.9998
SQH:Entropy
SHA2: Entropy

0.9994

SqHash: Entropy

0.9992

1.0
0.5

0.9990
0.0

0.9988
0

2000

4000

6000

8000

10000

12000

0

6000
(b)

Monte-Carlo Values for Pi

40%
20%

4000

6000

12000

SHA2: Monte-Carlo-Pi

60%

2000

10000

3.8

SqHash: Statistically Significant

0

8000

Sequence length (bits)

SHA2: Statistically Significant

Statistically Significant Level (%)

4000

(a)
SQH: Statistically Significant

80%

0%

2000

Sequence length (bits)

100%

8000

10000

12000

3.6

SQH: Monte-Carlo-Pi
SqHash: Monte-Carlo-Pi

3.4
3.2
3.0
2.8

0

2000

4000

6000

8000

Sequence length (bits)

Sequence length (bits)

(c)

(d)

10000

12000

Figure 7: The comparison result of one-bit statistical tests for SHA-2 (256), SQH, SqHash
functions.

9.2. Chi-Squared Testing
The unbiasedness of random functions can be tested by Chi-Squared independence test. The Chi-Squared test is the most commonly used test for
the randomness of data, and is extremely sensitive to errors in pseudorandom
sequence generators. In essence, the Chi-Squared test, belongs to a statistical
hypothesis testing, is a conclusion-generation procedure that has two possible outcomes, either accept null hypothesis (H0 : the sequence is random) or
accept the alternative hypothesis (H1 the sequence is non-random). For each
applied test, a decision or conclusion is derived that accepts or rejects the
24

null hypothesis, i.e., whether the detected function is (or is not) producing
random values, based on the sequence that was produced.
For a m-bit block test on a n-block length sequence {X}, the test statistic
Sm is defined as the sum of deviations between expected (ei , asserted by the
null hypothesis) and observed simultaneous frequencies (oi ) of a detected
sequence:
m −1
m −1
2X
2X
(oi − ei )2
(oi − npi )2
Sm =
=
,
e
np
i
i
i=0
i=0
where ei = npi and pi = Pr[X = i] = 21m for null hypothesis. This equation tests a null hypothesis stating that the frequency distribution of certain
events observed in a sample is consistent with a theoretical uniform distribution.
In Figure 7 (b), we show the results of one-bit Chi-Squared tests (m=1)
where the length of SHA-2, SQH, SqHash sequences is increased from 1,024
to 10,240 bits. In this case, the expected probability is p0 = p1 = 1/2 in null
hypothesis. The test statistic of SHA-2 (SHA-256) is ranged from 0.06 to
1.82; that of SQH is from 0.01 to 1.83; and that of SqHash is from 0 to 1.01.
Further, Figure 8 (b) shows the similar results in 8-bit Chi-Squared tests
(m=8), where the expected probability is pi = 1/256 in null hypothesis for
i = 0, · · · , 255. Since the test statistic Sm is in essence a square cumulative of
deviations of ei and oi , this means that the smaller the value of Sm , the better
the randomness of the detected function. Hence, our experiments show that
the output of SqHash has good average-case randomness than those of SQH
and SHA-2.
9.3. Significance Testing
For each Chi-Squared test, a statistical significance testing has been used
to determine the acceptance or rejection of the randomness (null) hypothesis
H0 . In this test, the amount of evidence, required to accept that an event
is unlikely to have arisen by chance, is known as the significance level α. To
achieve the hypothesis testing, the test statistic value Sm on data, called P value, should be compared to the critical value α: if P -value does not exceed
the critical value α (P −value < α), the null hypothesis (H0 ) for randomness
is rejected. Otherwise (P − value ≥ α), the null hypothesis is not rejected
(i.e., H0 is accepted). Typically, α is chosen in 1%: A P −value ≥ 0.01 would
mean that the sequence would be considered to be random with a confidence
of 99%.
25

8.0

270

7.8

260

7.4
7.2

Test Statistic Values

Entropy Values

7.6

SQH:Entropy
SHA2: Entropy

7.0

SqHash: Entropy

6.8

200

400

600

800

1000

1200

210

1400

SQH: Chi-square

SqHash: Chi-square

0

200

400

600

800

Sequence length (bytes)

Sequence length (bytes)

(a)

(b)

1000

1200

1400

3.8

90%
80%

SQH: Monte-Carlo-Pi

70%

Monte-Carlo Values for Pi

Statistically Significant Level (%)

230

SHA2: Chi-square

0

100%

60%
50%
40%
30%
20%

SQH: Statistically Significant

10%
0%

240

220

6.6
6.4

250

3.6

SHA2: Monte-Carlo-Pi
SqHash: Monte-Carlo-Pi

3.4
3.2
3.0

SHA2: Statistically Significant
SqHash: Statistically Significant

0

200

400

600

800

1000

1200

1400

2.8

0

200

400

600

800

Sequence length (bytes)

Sequence length (bytes)

(c)

(d)

1000

1200

1400

Figure 8: The comparison result of one-byte statistical tests for SHA-2 (256), SQH, SqHash
functions.

In Figure 7 (c), we show the result of significance testings from the test
statistic values Sm on Figure 7 (b). Here, the P -value is calculated by comparing the statistic value Sm to a Chi-Squared distribution (χ2 ) 2 . The range
of P -value of SHA-2 is from 17.63% to 80.26%; the range of SQH is from
17.53% to 95.02%; and the range of SqHash is from 80.26% to 99.99%.
The similar results is also shown in Figure 8 (c). According to the criterion
P − value ≥ 0.01, three functions would be considered to be random. More
importantly, the randomness of SqHash has the better randomness than those
of SQH and SHA-2 due to the P -values of SqHash is much larger than those
of SQH and SHA-2.
9.4. Monte-Carlo Testing
Monte-Carlo simulation is one of the main applications involving the use
of random number generators. It is also one of the best methods of testing
2

Given a n-block
R ∞ sequence and the statistic value SmR, ∞we define P − value =
Q(n/2, Sm/2) = Sm /2 tn/2−1 e−t dt/Γ(n/2), where Γ(x) = 0 tx−1 e−t dt and Q(s, t) is
the incomplete gamma function.

26

the randomness properties of such generators, by comparing results of simulations using different generators with each other, or with analytic results.
One practical way to test a random number generator is to use it for MonteCarlo simulation of two dimensional applied to approximating the value of π.
1) consider a circle inscribed in a unit square, where the circle and the square
have a ratio of areas that is π/4; 2) each successive sequence of six bytes is
used as 24 bit X and Y co-ordinates within the square. If the distance of the
randomly-generated point is less than the radius of a circle inscribed within
the square, the six-byte sequence is considered a “hit”; 3) count the number
of points inside the circle and the total number of points; 4) the ratio of the
two counts is an estimate of the ratio of the two areas, which is π/4, and
multiply the result by 4 to estimate π.
The results of Monte-Carlo testing are shown in Figure 7 (d) and 8 (d).
We use the nonlinear (Gauss) curve fit methods (y = a0 + a1 xb ) to estimate
the curve parameters in 5. While the parameter a0 is closer to π, the function
is more suitable for simulation tests. Hence, the SqHash provides a good
approximation for π in Monte-Carlo simulation.
Table 5: Curve Fit for Monte Carlo Testing

SHA-2
SQH
SqHash

a0
a1
b
2.947
0.8546
-0.6805
3.368 -0.007675 1.525
3.224 -0.3865
-1.745

10. Conclusions
In this paper, we prompt the idea of constructing various basic cryptographic primitives (such as hash, MAC, and PRG) from a common core
algorithm to simplify the management and improve the efficiency of current
cryptographic implementation practices on mobile devices. For this purpose,
we present the design of a family of cryptographic primitives based on the
common core squaring operation. Our design takes advantage of the practical
construction in ALU hardware, such as parallel processing units or algebra
operation units, so that the proposed schemes can be efficiently realized on
resource-constrained mobile devices. Moreover, the proposed schemes are
provably secure under the hidden number problem and hard-core predicate.
27

References
Appleby,
A.,
2011.
com/site/murmurhash/.

Murmurhash.

hash.

https://sites.google.

Bellare, M., Canetti, R., Krawczyk, H., 1996. Keying hash functions for
message authentication. In: Koblitz, N. (Ed.), CRYPTO. Vol. 1109 of
Lecture Notes in Computer Science. Springer, pp. 1–15.
Bellare, M., Kilian, J., Rogaway, P., 2000. The security of the cipher block
chaining message authentication code. J. Comput. Syst. Sci. 61 (3), 362–
399.
Berbain, C., Gilbert, H., Patarin, J., 2006. Quad: A practical stream cipher
with provable security. In: Vaudenay, S. (Ed.), EUROCRYPT. Vol. 4004
of Lecture Notes in Computer Science. Springer, pp. 109–128.
Blum, L., Blum, M., Shub, M., 1986. A simple unpredictable pseudo-random
number generator. SIAM J. Comput. 15 (2), 364–383.
Boneh, D., Halevi, S., Howgrave-Graham, N., 2001. The modular inversion
hidden number problem. In: Boyd, C. (Ed.), ASIACRYPT. Vol. 2248 of
Lecture Notes in Computer Science. Springer, pp. 36–51.
Boneh, D., Venkatesan, R., 1997. Rounding in lattices and its cryptographic
applications. In: Saks, M. E. (Ed.), SODA. ACM/SIAM, pp. 675–681.
Coron, J.-S., Dodis, Y., Malinaud, C., Puniya, P., 2005. Merkle-damgård revisited: How to construct a hash function. In: Shoup, V. (Ed.), CRYPTO.
Vol. 3621 of Lecture Notes in Computer Science. Springer, pp. 430–448.
Dubois, V., Fouque, P.-A., Shamir, A., Stern, J., 2007. Practical cryptanalysis of sflash. In: Menezes, A. (Ed.), CRYPTO. Vol. 4622 of Lecture Notes
in Computer Science. Springer, pp. 1–12.
Etzel, M., Patel, S., Ramzan, Z., 1999. Square hash: Fast message authenication via optimized universal hash functions. In: Wiener, M. J. (Ed.),
CRYPTO. Vol. 1666 of Lecture Notes in Computer Science. Springer, pp.
234–251.
Fowler,
G.,
Vo,
P.,
Noll,
L. C.,
1988.
http://www.isthe.com/chongo/tech/comp/fnv/index.html.
28

Fnv

hash.

Jenkins,
B.,
2009.
bob/hash/doobs.html.

Jenkins

hash.

http://www.burtleburtle.net/

Kiltz, E., 2001. A primitive for proving the security of every bit and about
universal hash functions & hard core bits. In: Freivalds, R. (Ed.), FCT.
Vol. 2138 of Lecture Notes in Computer Science. Springer, pp. 388–391.
Ouafi, K., Vaudenay, S., 2009. Smashing squash-0. In: EUROCRYPT. pp.
300–312.
Sasaki, Y., Aoki, K., 2009. Finding preimages in full md5 faster than exhaustive search. In: EUROCRYPT. pp. 134–152.
Shamir, A., 2008. Squash - a new mac with provable security properties for
highly constrained devices such as rfid tags. In: Nyberg, K. (Ed.), FSE.
Vol. 5086 of Lecture Notes in Computer Science. Springer, pp. 144–157.
Srinathan, K., Rangan, C. P., Yung, M. (Eds.), 2007. Progress in Cryptology
- INDOCRYPT 2007. Vol. 4859 of Lecture Notes in Computer Science.
Springer.
Wang, X., Yu, H., 2005. How to break MD5 and other hash functions. In:
Eurocrypt 2005.

29

Achieving Security Assurance with
Assertion-based Application Construction
Carlos E. Rubio-Medrano and Gail-Joon Ahn

Karsten Sohr

Ira A. Fulton Schools of Engineering
Arizona State University
Tempe, Arizona, USA, 85282
{crubiome, gahn}@asu.edu

Center for Computing Technologies (TZI)
Universität Bremen
28359 Bremen, Germany
sohr@tzi.de

Abstract—Modern software applications are commonly built
by leveraging pre-fabricated modules, e.g. application programming interfaces (APIs), which are essential to implement the
desired functionalities of software applications, helping reduce
the overall development costs and time. When APIs deal with
security-related functionality, it is critical to ensure they comply
with their design requirements since otherwise unexpected flaws
and vulnerabilities may be consequently occurred. Often, such
APIs may lack sufficient specification details, or may implement
a semantically-different version of a desired security model to
enforce, thus possibly complicating the runtime enforcement of security properties and making it harder to minimize the existence
of serious vulnerabilities. This paper proposes a novel approach
to address such a critical challenge by leveraging the notion of
software assertions. We focus on security requirements in rolebased access control models and show how proper verification
at the source-code level can be performed with our proposed
approach as well as with automated state-of-the-art assertionbased techniques.

I.

I NTRODUCTION

In recent years, there has been an increasing interest
in leveraging heterogeneous pre-fabricated software modules,
e.g. application programming interfaces (APIs) and software
development kits (SDKs), in order to not only reduce the
overall development costs and time in producing high-quality
applications, but also minimize the number of incorrect behaviors (bugs) observed in the final product. However, recent
literature has shown that such modules often lack the proper
specification details (in the form of formal or informal specification) that are essential to guide how a given module can be
used correctly for implementing security-related functionality
[1] [2]. Such a problem may potentially become the source
of serious security vulnerabilities, as developers may not be
fully aware of the omissions and flaws they may introduce
into their applications by failing to implement a security model
in a proper way. In order to solve this problem, we propose
an assertion-based approach to capture security requirements
of security models and create well-defined representations of
those requirements. This way, the security features could be
effectively understood by all participants in the software development process so that they can leverage these features when
implementing security-related functionalities for multi-module
applications while being engaged in a highly-collaborative
environment at the same time. These assertion-based security
specifications would be used in conjunction with existing stateof-the-art methodologies and tools to verify security properties
COLLABORATECOM 2014, October 22-25, Miami, United States
Copyright © 2014 ICST
DOI 10.4108/icst.collaboratecom.2014.257691

at the source-code level. In this paper, we choose the wellknown role-based access control (RBAC) [3] as security model
to enforce access control requirements over an application that
is in turn composed of several heterogeneous modules. Also,
we utilize existing tools to verify a set of security properties,
thus providing a way to locate and possibly correct potential
security vulnerabilities in software applications.
This paper is organized as follows: we start by providing
some background in Section II. Next, we examine the general
problem, as well as the problem instance discussed in this
paper in Section III. We then present our approach in Section
IV, and a case study depicting three Java-based software
applications and an experimental process in Section V. In
Section VI, we provide some discussion on the benefits and
observed shortcomings of our approach as well as some related
work. Finally, Section VII presents directives for our future
work and concludes the paper.
II.

BACKGROUND

Software assertions are commonly described as formal
constraints intended to describe what a software system is
expected to do at runtime, and are commonly written as
annotations in the system’s source code [4]. Using assertions,
developers can specify what conditions are expected to be valid
before and after a certain portion of code gets executed, e.g.
the expected range of values intended for the parameter of
a given function. Design by contract (DBC) [5] is a software
development methodology based on assertions and the assumption that the developers and the prospective users (clients) of
a given software module establish a contract between each
other in order for the module to be used correctly. Commonly,
such a contract is defined in terms of assertions in the form
of pre and post conditions, among other related constructs.
Before using a DBC-based software module M, clients must
make sure that M’s preconditions hold. In a similar fashion,
developers must guarantee that M’s postconditions hold once
it has finished execution, assuming its corresponding preconditions were satisfied beforehand. The Java Modeling Language
(JML) [6], is a behavioral interface specification language
(BISL) for Java, with a rich support for DBC contracts. Using
JML, the behavior of Java modules can be specified using
pre and post conditions, as well as class invariants, which are
commonly expressed in the form of assertions, and are added
to Java source code as the form of comment such as //@
or /*@...@*/. Fig. 1 shows an excerpt of a Java interface

1 public interface Account{
2
3 //@ public instance model double balance;
4
5 //@ public invariant balance > 0.0;
6
7 /*@ public normal_behavior
8
@ requires amt > 0.0;
9
@ assignable balance;
10
@ ensures balance == (\old(balance) - amt);
11
@*/
12 public void withdraw(double amt)
13
throws SecurityException;
14
15 }

Fig. 1: An Excerpt of a JML-annotated Banking Application.
named Account, which belongs to a banking application and
has been annotated with JML specifications. A summary of the
JML features exercised in this paper can be found in [6] and
[7].
In recent years, the American National Institute of Standards (ANSI) released a standard document that provides welldefined descriptions of the main components and functions that
define RBAC [8], and it is mostly based on the well-known Z
specification language [9]. In addition, a dedicated profile has
been introduced to provide support for expressing RBAC policies by taking both the aforementioned ANSI RBAC standard
as a reference foundation as well as the well-known eXtensible
Access Control Markup Language (XACML), which is a
standard language for supporting the distributed definition and
storage & enforcement of rich access control policies [10],
[11].
III.

P ROBLEM D ESCRIPTION

As mentioned earlier, recent literature includes examples
showing that mission-critical applications, e.g. banking mobile
applications, have suffered from serious security vulnerabilities
derived from an incorrect use of their supporting security APIs
at the source-code level [1], [2]. Among the possible causes
of this problem, insufficient software specifications, including
the definition of prerequisites and hidden assumptions, as well
as the existence of multiple semantic variations of a given
security model, e.g., the lack of foundation on a standardized,
well-defined model serving as a reference, are cited as common
sources of incorrect implementations. Moreover, the problem
gets aggravated by the lack of effective software verification
procedures at the source-code level, which could affect the
chances of identifying and potentially correcting security vulnerabilities exhibited by applications before deploying in a
production system. In this paper, we address an instance of this
problem by choosing RBAC as the security model to enforce
access control requirements in a software application that is
in turn composed of several modules. Each of them possibly
implements a different version of RBAC whose semantics may
or may not strictly adhere to an existing RBAC reference
model such as the one described in [8]. We therefore aim
to verify that such heterogeneous modules, when used to
build a target application, correctly enforce a well-defined
and consistent high-level RBAC policy, despite the differences
they may exhibit with respect to their inner workings related
to RBAC features, which could eventually result in security
vulnerabilities.

Fig. 2 (a) and Fig. 2 (b) show a Java-based example where
a high-level RBAC policy is enforced at runtime by placing
authorization checks before performing security-sensitive operations. In both instances, a policy depicts a role manager
as a senior role to teller, and allows for users, who are
assigned to roles that happen to be senior to manager, to
execute both the transfer and withdraw operations, whereas
users holding teller role are allowed to execute the withdraw
operation only. Fig. 2 (a) shows a Java class BankAccount,
which leverages the Spring Framework API [12] for implementing an authorization check (lines 7-16). Similarly, Fig.
2 (b) shows another class DebitBankAccount depicting
an authorization check using the Apache Shiro API [13]
(lines 7-11). In such a setting, it is desirable to evaluate
the correct enforcement of the aforementioned RBAC policy
as follows: first, the authorization checks depicted in both
examples must correctly specify the roles that are allowed to
execute each of the security-sensitive operations. For instance,
the authorization check depicted in Fig. 2 (a) incorrectly allows
for another role agent to also execute the withdraw method,
which in turn represents a potential security vulnerability.
Second, the role hierarchy depicted in the high-level policy
must be correctly implemented at the source-code level by
leveraging both APIs. As roles that happen to be senior to role
manager should be allowed to execute both the transfer
and withdraw methods, the role hierarchy must be correctly
implemented by placing accurate authorization checks within
the source code. In addition, the role hierarchy must be also
defined correctly in the supporting API configuration files. as
an incorrect implementation, e.g. missing role names within
the XML files defined for the Spring API, may prevent users
with the role manager from executing the transfer method.
A more serious problem may be originated if users with the
role teller are allowed to execute the transfer method.
Finally, if users with the role manager are allowed to execute
the transfer method, but are disallowed from executing
the withdraw method (Fig. 2 (b)) by incorrectly configuring
the Spring API depicted in Fig. 2 (a), a given object of class
DebitBankAccount may be left in an inconsistent state,
thus also creating a serious security problem.
IV.

O UR A PPROACH : A SSERTION - BASED A PPLICATION
C ONSTRUCTION

In order to provide a solution to the problem described
in Section III, we propose an approach that combines the
concepts of specification modeling and software assertions for
describing security features at the source-code level. These socalled assertion-based security models are intended to provide
compact, well-defined and consistent descriptions that may
serve as a common reference for implementing security-related
functionality. Our approach strives to fill in the gap between
high-level descriptions of security features, which are mostly
abstract and implementation-agnostic, and supporting descriptions focused at the source-code level, which are intended to
cope with both security-related and behavioral-based specifications. As it will be described in Section VI, previous work
has also explored the use of software assertions and DBClike contracts for specifying access control policies. However,
our approach is intended to leverage the modeling capabilities
offered by software specification languages using a welldefined reference description of a security model as a source,

1 import org.springframework.security.core.*;
2 public class BankAccount implements Account{
3
4 public void withdraw(double amt)
5
throws SecurityException{
6
7
Iterator iter = SecurityContextHolder
8
.getAuthorities().iterator();
9
10
while(iter.hasNext()){
11
GrantedAuthority auth = iter.next();
if (!auth.getAuthority().equals("teller") ||
12
13
!auth.getAuthority().equals("agent")){
throw new SecurityException("Access Denied");
14
15
}
16
}
17
this.balance -= amt;
18 }
19 }

(a) Spring Framework API.

1 import org.apache.shiro.*;
2 public class DebitBankAccount{
3
4 public void transfer(double amt, BankAccount acc)
5
throws SecurityException{
6
if(!SecurityUtils.getSubject().hasRole("manager")){
7
8
9
throw new SecurityException("Access Denied");
10
11
}
12
13
acc.withdraw(amt);
this.balance += amt;
14
15
16 }
17
18
19 }

(b) Apache Shiro API.

Fig. 2: Enforcing an RBAC Policy by Leveraging Heterogeneous Security Modules.
in such a way it not only allows for the correct communication,
enforcement and verification of security-related functionality,
but it also becomes independent of any supporting APIs used
at the source-code level, thus potentially allowing for its deployment over applications composed of several heterogeneous
modules as shown in Fig. 3: an assertion-based security model
is intended to be enforced over a target application that is
in turn composed of two modules leveraging security APIs
and two modules whose security-related functionality has been
implemented from scratch. This way, the semantic differences
exhibited by such modules, as shown in Section III, can be
effectively mitigated. Moreover, by leveraging state-of-theart methodologies based on assertions, effective automated
verification of security properties at the source-code level
becomes feasible, thus providing a means for discovering and
possibly correcting potential security vulnerabilities.
To address the problem instance discussed in this paper,
we leverage the JML modeling capabilities, e.g. model classes
[7], to describe the ANSI RBAC standard described in Section
II. Later on, these model classes are used to create assertionbased constraints, which are in turn incorporated into the DBC
contracts devised for each module in an application. This way,
a high-level RBAC policy can be specified at the source-code
level by translating it into assertion-based constraints included
in DBC contracts. Following our running example, Fig. 4
shows an excerpt of a model class JMLRBACRole, which depicts the role component and some of its related functionalities
as devised in the ANSI RBAC standard, e.g. role hierarchies.
Such a model class is leveraged in Fig. 5 to augment the
JML-based contract depicted in Fig. 1 with security-related
assertions restricting the execution of the withdraw method
to users who activate a role senior to teller. We start by defining
a model variable role, of type JMLRBACRole (line 5),
which is later used for defining access control constraints in the
two specification cases depicted in Fig. 5: the first specification
case, depicted in lines 9-14, allows one to properly execute
the withdraw method, e.g. deducting from the balance of a
given account, only if the object stored in the role variable
represents a role senior to teller1 . The second specification
1 Following

the ANSI RBAC standard, a given role is always senior to itself.

Assertion-based Security Model

Module1
(API1)

Module2
(API2)

Module3

Own
Code

Software Application

Fig. 3: Deploying Assertion-based Security Models over a
Multi-module Application.
1 package edu.asu.sefcom.ac.rbac;
2 public class JMLRBACRole
3
extends JMLRBACAbstractRole{
4
5 public boolean isSeniorRoleOf(
6
JMLRBACAbstractRole role){
7
8
if(this.equals(role)){ return true; }
9
10
return getAllJuniorRoles().contains(role);
11 }
12 }

Fig. 4: An Excerpt of a JML Model Class Depicting an
ANSI RBAC Role Component.
case, shown in lines 16-20, allows for the withdraw method
to throw a runtime exception if the aforementioned constraint
is found to be false. In addition, such a specification case also
prevents any modification to the state (e.g. private fields) of a
given object of type BankAccount from taking place.
Fig. 7 depicts our approach: a high-level RBAC policy,
which is encoded by means of the dedicated RBAC profile
provided by XACML [11], is translated into a series of DBC
contracts. Later on, such contracts, along with the source code

1 //@ model import edu.asu.sefcom.ac.rbac.*;
2 public interface Account{
3
4 //@ public instance model double balance;
5 //@ public instance model JMLRBACRole role;
6
7 //@ public invariant balance > 0.0;
8
9 /*@ public normal_behavior
10
@ requires amt > 0.0;
11
@ assignable balance;
12
@ ensures role.isSeniorRoleOf(
13
@ new JMLRBACRole("teller")) ==>
14
@ (balance == \old(balance) - amt);
15
@ also
16
@ public exceptional_behavior
17
@ requires !role.isSeniorRoleOf(
18
@ new JMLRBACRole("teller"));
19
@ assignable \nothing;
20
@ signals_only SecurityException;
21
@*/
22 public void withdraw(double amt)
23
throws SecurityException;
24
25 }

Fig. 5: Enhancing a DBC contract with Access Control
Assertions.

1 import org.springframework.security.core.*;
2 public class BankAccount implements Account{
3
4 //@ public represents role <- mapRole();
5
6 /*@ public pure model JMLRBACRole mapRole(){
7
@
8
@ JMLRBACRole newRole = new JMLRBACRole("");
9
@ RBACMonitor monitor = new RBACMonitor();
10
@
11
@ Iterator iter = SecurityContextHolder
12
@
.getAuthorities().iterator();
13
@
14
@ while(iter.hasNext()){
15
@
GrantedAuthority auth = iter.next();
if (auth.getAuthority().equals("teller")){
16
@
17
@
newRole = new JMLRBACRole("teller");
18
@
}
19
@ }
20
@
21
@ return newRole;
22
@ }
23
@*/
24 ...
25 }

Fig. 6: An Excerpt Showing a JML Abstraction Function.

for a given software application, are fed into JML-based automated tools for verification purposes. Since such an application
may be in turn composed of heterogeneous modules and each
of them possibly represents a different API for implementing
security-related functionality, e.g. enforcing an RBAC policy,
the configuration files for such APIs must be also taken into
account when leveraging automated tools for verification, as
described in Section III. In order to automate the creation of
DBC contracts such as the ones depicted in Fig. 5, we designed
an automated tool that translates RBAC policies encoded in
the RBAC XACML profile into JML-based specifications, thus
relieving policy designers and software architects from crafting
such contracts manually and eliminating a potential source for
errors.

<xml ...>
<....>
<..../>

DBC/JML
Contracts

+
RBAC XACML
Policy Files

Java
Source
Code

JML-based
Verification
Tools

+
API
Config.
Files

Fig. 7: A Framework for Assertion-based Security Assurance.

As described in Section I, we aim to provide the verification
of security properties by leveraging an approach based on
automated unit testing [14] as well as the JML specifications
depicting the assertion-based models described above. For
such a purpose, we adopt JET [14], which is a dedicated
tool tailored for providing automated runtime testing of Java
modules with JML-based assertions, e.g. classes. Using JET,
testers can verify the correctness of a Java module by checking
the implementation of each method against their corresponding
JML specifications. In addition, we also aim to provide support
for finding possible security vulnerabilities by means of static
techniques. For such a purpose, we leverage the ESC/Java2 tool
[6], which is based on a theorem prover and internally builds
verification conditions (VCs) from the source code being analyzed, and its corresponding JML-based specifications, which
the theorem prover then attempts to prove, thus allowing for the
automated analysis of whole code modules without running the
applications. In particular, ESC/Java2 uses modular reasoning
[15], which is regarded as an effective technique when used
in combination with static checking since code sections can
be analyzed and their JML-based specifications can be proved
by inspecting the specification contracts of the methods they
call within their method bodies. Later, in Section V, we
present our findings on leveraging both techniques in a set
of case studies depicting mission-critical Java applications.
In order to support the verification process just described,
proper constructs are needed to map the modeling features
included in DBC contracts (as depicted in Fig. 5) and the
implementation source code of each heterogeneous module.
For such a purpose, we leverage the features offered by the
JML abstraction functions [7], which allow for JML model
features to be properly mapped to source-code level constructs,
thus providing a way to verify that each heterogeneous module
implements a given high-level policy correctly. As an example,
Fig. 6 shows an excerpt where a JML model method is
used to map the source code implementing security features
as provided by the Spring Framework API with the model
features depicted in Fig. 5.
In general, the correct enforcement of a security model may
involve the following cases: first, a high-level security policy,
which is based on a well-defined security model definition,
should be correctly defined and all policy conflicts must have
been resolved, e.g. evaluating a given RBAC policy by using
techniques such as the ones discussed in [16]. Second, access
to all protected resources within a given application, e.g. the
withdraw operation depicted in Fig. 5, is guarded by an

TABLE I: Distribution of Responsibilities for Enforcing an
Assertion-based Security Model In a Collaborative Setting.
Actor

Description of Tasks

Security Domain Experts

Develop an assertion-based security model by
using a precise definition as a reference, e.g. using
the ANSI RBAC standard. (See Fig. 4).

Security Policy Administrators

Instantiate the security model to be enforced, e.g.
specification of an RBAC policy based on the
ANSI RBAC standard.

Software Architects

Incorporate the security policy into DBC constructs by specifying assertion-based constraints
(See Fig. 5).

Code Developers

Correctly implement the DBC specifications defined by software architects (including security
checks). Provide a mapping between the security
model and the security APIs used for implementation purposes (See Fig. 6).

Code Testers

Verify both the functional and the security related
aspects of a given software application based on
their DBC specifications (See Section V).

authorization check (adhering to the well-known principle of
complete mediation). Following our example, authorization
checks should depict the RBAC constructs defined in the overall policy, e.g. checking for the correct roles and/or permissions
before executing any sensitive operation. Third, supporting
components for the security model features is implemented
correctly, e.g. RBAC role hierarchies. Finally, we also require
that the detection of runtime policy violations is implemented
properly, e.g. exception handling and data consistency. With
this in mind, for the problem instance addressed in this paper,
we make the following assumptions: first, the ANSI RBAC
model is well-understood by all participants in the software
development process, e.g. policy designers, software architects
and developers. Second, the assertion-based specification of the
security model is correct: in other words, it has been verified
beforehand. Third, any supporting RBAC modules, including
security APIs and SDKs, have been implemented correctly,
even though their semantics with respect to RBAC may differ,
as addressed in Section III.
Finally, our approach is intended to be carried out by
the different participants in the software development process,
in such a way that the process of constructing vulnerabilityfree software becomes a collaborative responsibility shared by
all involved actors, obviously including the source-code level
developers. Table I shows a summary of the tasks devised for
each participant.
V.

C ASE S TUDY

In order to provide a proof-of-concept implementation of
our approach, we developed a reference description of the
security model under study by using a set of JML model
classes based on the case illustrated in Fig. 4. Such a reference
model contains 960 lines of code grouped in 17 Java classes,
including 1,383 lines of JML specifications depicting the
functionality desired for RBAC as described in the ANSI
RBAC standard. For our case study, we leveraged a pair
of open-source Java applications: OSCAR EMR [17], which
is a rich web-based software platform tailored for handling
electronic health records (EMR). It consists of approximately
35,000 lines of code organized into 110 classes and 35
packages. In addition, we also leveraged JMoney [18], a

TABLE II: A Sample RBAC Policy for Evaluation Purposes.
Role
Employee
Teller
Agent
Manager

Junior Roles

Sample Allowed Operations

-

deposit

Employee

withdraw, deposit

Employee

close, deposit

Teller, Agent

transfer, withdraw, deposit, close

financial application consisting of 7,500 lines of code grouped
into 45 classes. Finally, we developed a banking application
depicting the running examples shown in this paper. Such an
application leverages the Apache Shiro and Spring Framework
Security APIs, as well as our own RBAC monitor developed
for implementing security-related functionality. It consists of
36 classes and contains 1,550 lines of code as well as 1,450
lines of JML specifications, which utilize our JML model
classes in DBC contracts, as shown in Fig. 5.

In order to verify the effectiveness of our approach for
detecting faulty implementations of the RBAC security model,
we followed an approach inspired in mutation testing [19]: we
inserted variations (also known as mutants) in both the source
code and the API configuration files of the applications considered in our study, in an effort to introduce inconsistencies
in the implementation of their corresponding RBAC Policies.
As an example, Fig. 8 shows different mutants introduced to
the RBAC policy shown in Table II: first, the original policy
is modified to add an unintended permission (transfer, (t))
to a role employee (Fig. 8 (a)). Such a modification creates
a potential security vulnerability as it allows employee, and
all other roles senior to it, e.g. agent and teller, to execute
an operation that was originally intended only for a role
manager. Similarly, Fig. 8 (b) shows a permission (deposit, (d))
being removed from the employee role. Such a modification
produces an inconvenience to such a role and all other roles
that happen to be senior to it, as execution of the deposit
operation will be denied at runtime. Fig. 8 (c) shows another
example where the original role hierarchy of the RBAC policy
is modified to introduce an unintended role (supervisor, (S)).
This way, the newly-introduced role creates a pair of security
vulnerabilities: first, it inherits the permissions from all junior
roles in the hierarchy, thus allowing for the execution of
unintended operations. Second, it also allows for a senior role
in the hierarchy to obtain an extra permission (audit, (a)), thus
possibly allowing them to perform unintended operations as
well. Fig. 9 shows an excerpt of an XML configuration file
depicting the role hierarchy modification shown in Fig. 8 (c)
(lines 6-8). Finally, Fig. 8 (d) shows a case when a role is
removed from a role hierarchy: teller is left aside by removing
the relationships with both the manager (senior) and the
employee (junior) roles. It expose an inappropriate permission
revocation to not only users holding the role teller, as such a
role is prevented from getting the permissions of its junior roles
(e.g. deposit, (d)), but also senior roles since it prevented from
getting the permissions assigned to teller (e.g., withdraw, (w))
including all other permissions that could be obtained from
junior roles to teller.

Following the automated testing approach described in
Section IV, we conducted a set of experiments to measure
the effectiveness of our assertion-based models, along with our
enhanced DBC contracts, in detecting the mutations introduced
into the applications tested in our case study. Such experiments
were carried out on a PC equipped with an Intel Core Duo
CPU running at 3.00 GHZ, with 4 GB of RAM, running
Microsoft Windows 7 64-Bit Enterprise Edition. First, we
measured the impact of our approach in the average execution
time of the applications. As described in [14], the JML-based
specifications depicting our model classes are translated into
runtime assertion checking (RAC) code, which is then executed along with the original application code for verification
purposes. In order to provide a mapping between the modeling
features included in JML contracts (as depicted in Fig. 5)
and the implementation code of each heterogeneous module,
we leveraged the features offered by the JML abstraction
functions [7]: we enhanced our supporting tool described
in Section IV to also produce abstraction functions for the
referred Spring Framework and Apache Shiro APIs. We then
executed a sample trace of the Java methods exposed by our
three applications and calculated the average execution time
over 1,000 repetitions. Such a trace was created to contain
representative operations for each application, e.g. the trace
created for the OSCAR EMR application that contains Java
methods used to update patient’s personal data as well as
information about medical appointments and prescriptions.
As shown in Table III, the introduction of RAC code has a
moderate impact on the performance, which is mostly due to
the overhead introduced by the RAC code generated to process
both the JML contracts as well as the abstraction functions. We
then recorded the results obtained by our tool while attempting
to detect (kill) the mutants introduced in both the configuration
of the Security APIs as well as the authorization checks
guarding each of the Java methods contained in our sample
traces, following the approach depicted in Fig. 8. Table III
shows a report on the number of generated test cases, including
the number of meaningful ones produced by the tool. 2 Our
meaningful test cases were able to kill all the mutants inserted
into our case study applications.
In an additional experiment, we compared the time taken by
our JML model classes to detect each of the mutant generation
techniques depicted in Fig. 8. Once again, we used a trace
of Java methods depicting the main functionality for each
application, and used the automated mutant-generation tool
described before to generate different variations to an original
RBAC policy. The results, as shown in Fig. 12, show that
adding/removing a role to a given hierarchy is the most costly
mutation to be detected by the RAC code through processing
our assertion-based JML classes. This is mostly due to the way
how role hierarchies are implemented in our JML classes, by
using a series of java.util.ArrayList objects to store
references to each senior/junior role in a given hierarchy, and
allowing for such references to be inspected recursively when
determining if there is a seniority relationship between two
given roles.
2 In JET, a test case T for a given method M is said to be meaningful if
the tool is able to randomly create values for M’s formal parameters in such
a way M’s preconditions involving such parameters are satisfied. Otherwise T
is said to be meaningless.

t

M

A. Assertion-based Verification
c

A

w

T

t

c

M

t

S

a

A

T

E

T

w

d

E

(a) Adding a Permission.

c

A

d

E

t

M

(b) Removing a Permission.

w

c

d

(c) Adding a Role.

M

t

A

T

E

d

w

(d) Removing a Role.

Fig. 8: Introducing Mutants in an RBAC Policy.
1 <?xml ...>
2 ...
3 <beans:bean id="roleHierarchy" ...>
4
<beans:property name="hierarchy">
5
<beans:value>
6
manager
> supervisor
7
supervisor > teller
8
supervisor > agent
9
teller
> employee
10
agent
> employee
11
</beans:value>
12
</beans:property>
13 </beans:bean>
14 ...

Fig. 9: Introducing Mutants in Spring Framework.
TABLE III: Experimental Data on Using JET and ESC/Java2.
Banking

JMoney

OSCAR

46

136

125

4.56

17.32

15.4

209.76

2355

1925

Total methods
JET
Analysis time per method /s
Total analysis time /s
Runtime overhead /s
Generated test cases
Meaningful test cases

0.97

2.34

1.78

1000

1000

1000

150

250

225

ESC/Java2
Analysis time per method /s
Total analysis time /s

0.43

2.07

0.5

19.66

281.41

63.00

As mentioned in previous sections, we also leverage the
ESC/Java2 tool for providing verification guarantees based on
static analysis techniques and our proposed approach. However, despite the support provided for JML-based constructs by
such a tool, some challenges must be addressed: first, in order
to prove the correctness of a certain source code C against
its corresponding JML contracts, the tool additionally requires
that the JML specifications of each library called within C are
available, including the specifications of additional libraries the
original ones may eventually call later on. In some cases, such
a requirement may notoriously increase the amount of VCs

1 public class Subject{
2
3 /*@ public normal_behavior
4
@ requires true;
5
@ ensures \result == true || \result == false;
6
@ also
7
@ public exceptional_behavior
8
@ requires false;
9
@ assignable \nothing;
10
@*/
public /*@ pure @*/ boolean hasRole(String r){
11
12
return true;
13
}
14 }

Fig. 10: Specifications Stubs for the Apache Shiro API.
1 public interface Account{
2
3 /*@ public normal_behavior
4
@ requires amt > 0.0;
5
@ assignable balance;
6
@ ensures
7
@
(SecurityUtils.getSubject()
8
@
.hasRole("teller") ||
9
@
SecurityUtils.getSubject()
10
@
.hasRole("manager"))
11
@
==>
12
@
...
13
@*/
14 public void withdraw(double amt)
15
throws SecurityException;
16 }

Fig. 11: Translating Model JML Classes.
6

Performance of JML Model CLasses against Mutation Techniques

10

ADD PERM

REM PERM

ADD ROLE

REM ROLE

5

Processing Time (ms)

10

creep problem. In particular, as described in Section IV,
we assumed the Security APIs leveraged within our case
study have been implemented correctly and previously verified
elsewhere. Therefore, there is no need to include their corresponding source code in our verification process. Based on
this observation, we provided specification stubs for the leveraged Security APIs whose JML-based annotations are trivially
satisfied. Fig. 10 shows the translated JML specifications for
the method hasRole of class Subject, which implements
an authorization check in the Apache Shiro API, as shown in
Fig. 2 (b). This process can be carried out by security domain
experts for the Security APIs and must only be revised when
new API versions are released. Second, as mentioned before,
the JML model classes, which are a core part of the approach
shown in Section IV, are beyond the current capabilities of
ESC/Java2. To overcome this limitation, we provided JML
specifications that do not employ the JML model classes and
use low-level JML concepts instead. For example, the role
hierarchy depicted in Table II and Fig. 5, which checks that the
current user is granted a role senior to teller (e.g. manager),
can be translated into the JML contracts shown in Fig. 11 (lines
7-10): the references to the model class JMLRBACRole have
been substituted for the hasRole method of class Subject
provided by the Apache Shiro API, and are integrated together
by using the operator || in JML, applied to all relevant senior
roles (e.g., the manager role in line 10).
After the preparation steps, we applied our analysis technique to the applications under our case study, by following
the mutation-based approach described before. We used a
conventional Lenovo Thinkpad T510 laptop (Intel Core i7620M Processor, 2.66GHz, 8 GB RAM). All mutants were
automatically detected by ESC/Java2 even if they were hidden
within the many methods of our case studies. The runtime of
the three applications under our case study is given in Table III.
VI.

4

10

3

10

2

10

Number of mutants introduced in RBAC Policy

Fig. 12: Runtime performance of a Dynamic Verification
Approach.
that need to be proved by the tool, so the verification process
becomes prohibitively expensive, resulting in the specification
creep problem [15]. Second, an additional problem arises from
the lack of support offered by the current tool for advanced
JML concepts, such as the JML model classes introduced in
Section IV and the JML abstraction functions also described
before, as the internally-produced VCs are too complex for the
tool to handle, which limits the applicability of our assertionbased models.
Subsequently, we present an approach that addresses these
challenges while still providing verification guarantees for our
assertion-based approach. First, we addressed the specification-

D ISCUSSION

AND

R ELATED W ORK

The experimental results depicted in Section V-A support
our claim that our approach can effectively expose the set of security vulnerabilities caused by the incorrect source-code level
implementations of security models. In our approach, we have
selected Java for our proof-of-concept implementation due to
its extensive use in practice. Moreover, we have also chosen
JML as the specification language for defining our assertionbased security models due to its enhanced tool support as
well as its language design paradigm, which supports rich
behavioral specifications. At the same time it strives to handle
the complexity of using complex specification constructs, in
such a way it becomes suitable for average developers to use
[6]. (see Table I). We believe our approach can be extended
to other programming languages/development platforms. For
instance, Spec# [20] provides rich DBC-based specifications
for the C# language, depicting an approach similar to JML.
Moreover, our approach can be also applied to other Javabased frameworks such as JEE [21] or Android [22], which
may help implement authorization checks for guarding access
to its core system services. Despite our success, some issues
still remain in the verification process. In particular, ESC/Java2
may produce false positives (in case the built-in theorem prover
cannot prove a VC) and false negatives (e.g., restrictions on
loop unrolling). To deal with this situation, a possible solution
may consider a runtime testing approach, like the one we have

described using the JET tool, for all methods raising warnings
by ESC/Java2, thus showing a way in which both techniques
can be to provide stronger guarantees for the verification.
Second, as shown in Table III, the number of meaningful
test cases produced by the JET tool is considerably less than
the number of test cases created, which may affect the test
coverage provided by the tool and could allow for potential
security vulnerabilities to remain hidden during the verification
process. This is mostly due to the limitations on the automated
testing technique [14]. A possible solution would adopt a static
approach for those methods whose test coverage is found to
be below a given threshold.
Our work is related to other efforts in software security:
Architectural risk analysis [23] attempts to identify security
flaws on the level of the software architecture and hence is
unrelated to the source-code level addressed in this approach.
Language-based security approaches in the sense of Jif [24]
allow software to be verified against information flow policies
rather than supporting specific security requirements for different Security APIs. Formal verification of RBAC properties has
been already discussed in the literature [16]. These approaches
are mostly focused on verifying the correctness of RBAC
models without addressing their corresponding verification
against an implementation at the source-code level. The work
closely related to ours involves the use of DBC, which was
explored by Dragoni, et al. [25]. In addition, Belhaouari et al.
introduced an approach for the verification of RBAC properties
based on DBC [26]. Both approaches, while using DBC for
checking RBAC properties, do not include the use of reference
models to better aid the specification of DBC constraints in
the security context. Moreover, no support is provided as APIindependent constructs, such as the JML model capabilities
discussed in our approach.
VII.

C ONCLUSIONS

AND

F UTURE W ORK

In this paper, we have addressed the problem originated
by the existence of security vulnerabilities in software applications. We have shown how such vulnerabilities, which may
exist due to the lack of proper specification and verification
of security checks at the source-code level, can be tackled
by using well-defined reference models with the help of
software assertions, thus providing a reference for the correct
enforcement of security properties over applications composed
of heterogeneous modules such as APIs and SDKs. Future
work would include the introduction of assertion-based models
to better accommodate other relevant security paradigms, e.g.,
the correct usage of cryptography APIs. Also, we plan to
refine our proposed RBAC model introduced in Section IV by
introducing an automated translation from the specifications
depicted in the ANSI RBAC standard, which are written in
the Z specification language, to our supporting language JML.
ACKNOWLEDGMENT
This work was partially supported by a grant from the US
Department of Energy (DE-SC0004308) .
R EFERENCES
[1]

M. Georgiev, S. Iyengar, S. Jana, R. Anubhai, D. Boneh, and
V. Shmatikov, “The most dangerous code in the world: validating SSL
certificates in non-browser software,” in Proc. of the ACM Conf. on
Computer and comm. security, 2012, pp. 38–49.

[2] S. Fahl, M. Harbach, T. Muders, L. Baumgärtner, B. Freisleben,
and M. Smith, “Why eve and mallory love Android: an analysis of
Android SSL (in)security,” in Proc. of the ACM Conf. on Computer
and communications security, 2012, pp. 50–61.
[3] R. S. Sandhu, E. J. Coyne, H. L. Feinstein, and C. E. Youman, “RoleBased Access Control Models,” IEEE Computer, vol. 29, no. 2, pp.
38–47, 1996.
[4] D. S. Rosenblum, “A practical approach to programming with assertions,” IEEE Trans. Softw. Eng., vol. 21, no. 1, pp. 19–31, Jan. 1995.
[5] C. A. R. Hoare, “An axiomatic basis for computer programming,”
Communications of the ACM, vol. 12, no. 10, pp. 576–580, Oct 1969.
[6] L. Burdy, Y. Cheon, D. Cok, M. Ernst, J. Kiniry, G.-T. Leavens,
K. Leino, and E. Poll, “An overview of JML tools and applications,”
in Proc. 8th Int’l Workshop on Formal Methods for Industrial Critical
Systems (FMICS 03), 2003, pp. 73–89.
[7] Y. Cheon, G. Leavens, M. Sitaraman, and S. Edwards, “Model variables:
cleanly supporting abstraction in design by contract: Research articles,”
Softw. Pract. Exper., vol. 35, no. 6, pp. 583–599, May 2005.
[8] American National Standards Institute Inc., “Role Based Access Control,” 2004, ANSI-INCITS 359-2004.
[9] J. M. Spivey, The Z notation: a reference manual. Upper Saddle River,
USA: Prentice-Hall, Inc., 1989.
[10] OASIS, “eXtensible Access Control Markup Language (XACML) TC,”
2014, https://www.oasis-open.org/committees/xacml/.
[11] OASIS, “XACML v3.0 Core and Hierarchical Role Based Access
Control (RBAC) Profile Version 1.0,” 2014, http://docs.oasis-open.org/
xacml/3.0/xacml-3.0-rbac-v1-spec-cd-03-en.html.
[12] Pivotal, Inc., “Spring security 3.1.2,” 2013, http://static.springsource.
org/spring-security/site/index.html.
[13] The Apache Software Foundation, “Apache shiro 1.2.1,” 2013, http:
//shiro.apache.org/.
[14] Y. Cheon, “Automated random testing to detect specification-code inconsistencies,” in Proc. of the 2007 Int’l Conf. on Software Engineering
Theory and Practice, Orlando, Florida, U.S.A., 2007.
[15] C. Flanagan, K. R. M. Leino, M. Lillibridge, G. Nelson, J. B. Saxe,
and R. Stata, “Extended static checking for Java,” in Proc. of the ACM
SIGPLAN Conf. on Prog. language design and implementation, 2002,
pp. 234–245.
[16] H. Hu and G.-J. Ahn, “Enabling verification and conformance testing
for access control model,” in Proc. of the 13th ACM Symp. on Access
Control Models and Technologies, 2008, pp. 195–204.
[17] OSCAR EMR, “OSCAR Electronic Medical Records System,” 2014,
http://oscar-emr.com/.
[18] J. Gyger and N.l Westbury, “JMoney Financial System,” 2014, http:
//jmoney.sourceforge.net/.
[19] Y. Jia and M. Harman, “An analysis and survey of the development of
mutation testing,” IEEE Transactions on Software Engineering, vol. 37,
no. 5, pp. 649 –678, 2011.
[20] M. Barnett, R. Leino, and W. Schulte, “The spec# programming system:
An overview,” in Proc. of the 2004 Int’l Conf. on Construction and
Analysis of Safe, Secure, and Interoperable Smart Devices. Berlin:
Springer-Verlag, 2005, pp. 49–69.
[21] Oracle
Inc., “Java Platform
Enterprise
Edition,”
2014,
urlhttp://www.oracle.com/technetwork/java/javaee/overview/index.html.
[22] Google Inc., “Android,” 2014, http://www.android.com.
[23] G. McGraw, Software Security: Building Security In. Addison-Wesley,
2006.
[24] A. Sabelfeld and A. C. Myers, “Language-based information-flow
security,” IEEE J. Selected Areas in Communications, vol. 21, no. 1,
pp. 5–19, Jan. 2003.
[25] N. Dragoni, F. Massacci, K. Naliuka, and I. Siahaan, “Security-bycontract: Toward a semantics for digital signatures on mobile code,”
in Public Key Infrastructure, ser. LNCS. Springer Berlin, 2007, vol.
4582, pp. 297–312.
[26] H. Belhaouari, P. Konopacki, R. Laleau, and M. Frappier, “A design by
contract approach to verify access control policies,” in 17th Int’l Conf.
on Engineering of Complex Computer Systems (ICECCS), july 2012,
pp. 263 –272.

