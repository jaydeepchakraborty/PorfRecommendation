Automatic Parallelization of Simulink Models for Multi-core Architectures
Cumhur Erkan Tuncali, Georgios Fainekos, Yann-Hang Lee
School of Computing, Informatics and Decision Systems Arizona State University Tempe, AZ, USA {etuncali, fainekos, yhlee}@asu.edu
Abstract-- This paper addresses the problem of parallelizing existing single-rate Simulink models for embedded control applications on multi-core architectures considering communication cost between blocks on different CPU cores. Utilizing the block diagram of the Simulink model, we derive the dependency graph between the different blocks. In order to solve the scheduling problem, we describe a Mixed Integer Linear Programming (MILP) formulation for optimally mapping the Simulink blocks to different CPU cores. Since the number of variables and constraints for MILP solver grows exponentially when model size increases, solving this problem in a reasonable time becomes harder. For addressing this issue, we introduce a set of techniques for reducing the number of constraints in the MILP formulation. By using the proposed techniques, the MILP solver finds solutions that are closer to the optimal solution within a given time bound. We study the scalability and efficiency of our consisting approach with synthetic benchmarks of randomly generated directed acyclic graphs. We also use the Fault-Tolerant Fuel Control System demo from Simulink and a Diesel engine controller from Toyota as case studies for demonstrating applicability of our approach to real world problems. Keywords--Multiprocessing, embedded systems, optimization, model based development, Simulink, task allocation.

of an embedded control algorithm, the worst case execution times of the blocks and a computation budget (deadline), can we automatically partition the blocks onto the different cores so that the real-time constraints are satisfied? In particular, we focus on control models built in the Simulink [2] MBD environment. Our goal is to produce a framework where non-determinism in the control algorithm is reduced or minimized to the extent possible. Especially in safety-critical systems, scheduling in a predictable and deterministic manner is highly important for verification and satisfying the certification requirements that are mandated by regulatory authorities. For example, multi-core architectures are classified as highly complex in the 2011/6 final report of European Aviation Safety Agency (EASA) [3] and in the Certification Authorities Software Team position paper CAST32 Multi-core processors [4]. These classifications highlight the difficulty of certifying safety-critical systems that are based on multi-core architectures. Our approach is based on keeping timing properties of parallelized software as simple as possible. For this purpose, we are aiming at having separate executables for each core while Simulink blocks are allocated in each core and executed in a predetermined order. In other words, we set the priorities of each block inside each core. The contributions of this paper are, · · providing a practical solution to the Simulink model parallelization problem, improving available Mixed Integer Linear Program (MILP) formulations in the literature for finding better solutions within a fixed and practically feasible time for industrial size models, solving the multi-core mapping problem while considering the timing predictability of the parallelized application for ease of verification and certification, and developing a toolbox for automating parallelization of Simulink models to multi-core architectures. II. R ELATED W ORK

I.

I NTRODUCTION

Model Based Development (MBD) has gained a lot of traction in the industries that develop safety critical systems. This is particularly true for industries that develop CyberPhysical Systems (CPS) where the software implements control algorithms for the physical system. Using MBD, system developers and control engineers can design the control algorithms on high-fidelity models. Most importantly, they can test and verify the system properties before having a prototype of the system. The autocode generation facility of MBD tools provides additional concrete benefit which helps in eliminating programming errors. However, currently, the autocode generation process of commercial tools focuses on single-core systems. Namely, at the model level, there is no automatic support for producing code that runs on a multi-core system. This is problematic since advanced control algorithms, e.g., Model Predictive Control algorithms [1], are computationally demanding and may not be executed within the limited computation budget of a single-core embedded system. In this paper, we address this problem at the model level. Namely, given a data flow diagram
This research was partly funded by the NSF awards CNS-1446730 and IIP-1361926, and the NSF I/UCRC Center for Embedded Systems.

·

·

There is a large amount of research being done on the optimization of scheduling multiple tasks on multi-core processors or multiple processors in the literature. In [5] Anderson

et al. propose a Pfair [6] based scheduling method for realtime scheduling on multi-core platforms where the system has multiple tasks and task migration is allowed. For optimal mapping of tasks to CPU cores, Yi et al. [7], Bender [8] and Ostler et al. [9] discuss integer linear programming techniques which constitute a base for our optimization formulation. Cotton et al. discuss the use of mapping programs to multi processors in [10]. Tendulkar et al. discuss the application of SMT solvers in many-core scheduling for data parallel applications in [11]. In [12], Feljan et al. propose heuristics for finding a good solution for task allocation problems in a short time instead of searching for an optimal solution. There are studies focusing on parallelization of Simulink models. In [13], Kumura et al. propose methods to flatten Simulink models for parallelization without giving a detailed description of the optimization formulation. In that work, Simulink blocks are considered as tasks. To achieve thread level parallelism in multi-core, Canedo et al. introduce the concepts of strands for breaking the data dependencies in the model. A strand is defined as a chain of blocks that are driven by Mealy blocks [14]. The proposed method searches for available strand split points in Simulink models and it is heavily relying on strand characteristics in target models. In [15], Cha et al. is focusing on automating code generation for multi-core systems where the parallel blocks are grouped by user-defined parallelization start and end S-functions into the model. There are studies on task parallelization as [9], [7], [8]. However, to apply the similar approaches, Simulink blocks must be considered as tasks. Given that most realistic models may consist of a significant number of blocks, either these methods fail to find an optimal solution in a reasonable amount of time or they rely on available loop level parallelism or functional pipelining as described in [9]. Deng et al. study model-based synthesis flow from Simulink models to AUTOSAR runnables [16] and runnables to tasks on multicore architectures in [17]. The authors extend the Firing Time Automation (FTA) [18] model to specify activations and requested execution time at activation points. They define modularity as a measure of number of generated runnables and reusability as a measure of false dependencies introduced by runnable generation. The authors use modularity, reusability and schedulability metrics for evaluation of runnable generations. They also propose different heuristics and compare their results with the results obtained by utilizing a simulated annealing algorithm. Although this work is targeting a similar problem to our target problem, they are providing experiment results for systems with less than 50 blocks and they are not considering inter-core communication and memory overhead. Our work mainly differs from the other works in literature by 1. 2. 3. 4. providing a complete flow for automatically parallelizing a single-rate Simulink model, incorporating the communication cost in the optimization problem, having total available shared memory constraints, and being able to handle large models with more than 100 blocks in a reasonably short time.

III.

P ROBLEM D ESCRIPTION

We are addressing the problem of automatically parallelizing existing Simulink models for embedded control applications on multi-core architectures in an optimal way and in a reasonable time. We are focusing on single-rate, single-task embedded control applications which are modeled in Simulink and in which the execution order of blocks is determined only by dependencies coming from connections between blocks. Our target models cannot start execution of next iteration before finishing the execution of the current iteration. Our target platform is Qorivva MPC5675K-based evaluation board [19]. The processor is a dual-core 32-bit MCU from Freescale targeting automotive applications. The µC/OSII from Micrium [20] is ported on the target and a library to support Simulink code generation is devised for the platform [21]. We handle inter-core data communications by utilizing available shared memory and inter-core semaphores which are used for synchronization between tasks across cores and protecting global critical sections as described by Bulusu in [21]. For the purpose of utilizing this approach in Simulink, we model transmission and reception of data between different cores with two separate S-function blocks which implement inter-core transmission and reception using inter-core semaphores and shared memory. We will refer to these Sfunction blocks as inter-core communication blocks. A. Solution Overview We approach the problem in five steps which are illustrated in Fig. 1. First, creating a directed acyclic graph which represents dependencies between blocks. Task-data graphs are discussed in [9]. We use a similar approach using blocks instead of tasks, worst case execution times of blocks instead of amount of work associated with tasks and using size of data communication between blocks. Here we will refer to this kind of graphs as "block dependency graphs". Our second step in approaching the problem is finding an optimal or near optimal mapping of blocks to different CPU cores by formulating a Mixed-Integer Linear Program (MILP) and solving the resulting optimization problem with off-the-shelf MILP solvers. The third step is automatically updating the original Simulink model by adding inter-core communication blocks where necessary in accordance with the most optimal solution. The next step is generating separate code for each target core by automatically commenting out the blocks that are not mapped to the core for which code is being generated. Finally, we compile the generated code and deploy it on the target platform. IV. M ILP F ORMULATION

In this section we present our MILP formulation for the parallelization problem. Our MILP formulation for optimal solution is based on the formulations proposed by [7], [8] and [9]. We introduce an extension to these formulations by dividing the cost of communication to the transmission and reception parts. In Subsection D, we describe our techniques for reducing the number of constraints for allowing the MILP solvers to find better solutions within a feasible time.

Step 1

· Reading Model Block Information · Creating Block Dependency Graph

is used in the program formulation to dominate other terms allowing constraints to be ignored under certain conditions. B. Variables bip : A Boolean variable indicating whether block Bi is mapped to core Pp or not. It is defined for all Bi  B and for all Pp  P . If Bi is mapped to core Pp , then bip takes value 1. If Bi is mapped to another core, then bip will takes value 0. dik : A Boolean variable indicating whether block Bi executes before or after Bk when both blocks are mapped to same core. It is defined for all Bi , Bk  B with i < k . If Bi executes before Bk , then dik takes value 1 and if Bi executes after Bk , then dik takes value 0. si : The start time for the execution of block Bi . It is defined for all Bi  B . The lower bound for the variable si (best case start time) is denoted by bsi . It is determined by the best case completion time for all of the blocks from which there is a path to Bi in G. In the best case, all of this workload before Bi is distributed equally on all of the cores. The best case start time of Bi is calculated as kKi wk /m where Ki = {Bk : Bk  B  there exists a path f rom Bk to Bi in G}. The upper bound for the variable si (worst case start time) is denoted by wsi . It is determined by the best case completion time for all of the blocks to which there is a path from Bi in G and the block Bi itself, subtracted from the deadline. The worst case start time of Bi is calculated as deadline - wi + kYi wk /m where Yi = {Bk : Bk  B  there exists a path f rom Bi to Bk in G}. For all i, k such that Bi , Bk  B and for all p such that Pp  P . f : The completion time after executing all blocks. The lower bound for variable f is 0 and the upper bound is the deadline. C. Objective Function and Constraints The objective function for the optimization problem is minimizing f while the constraints for the optimization problem are defined as follows: 1) Every block shall be assigned to a single core: i : Bi  B,
Pp P

Step 2

· Formulating and solving Mixed Integer Linear Programming problem for finding optimal mapping

Step 3

· Updating Simulink model for each core according to the solution found by MILP solver

Step 4

· Simulink code generation for each core

Step5

· Compilation and deployment onto target platform

Fig. 1. Steps of going from a single-core Simulink model to multi-core target

A. Notation and Constants The number of CPU cores available at the target architecture is denoted by m. The set of CPU cores is defined as P = {Pp : p  [1, m]}. The number of nodes in the dependency graph is denoted by n where each node corresponds to a block in the flattened and merged Simulink model. Merging of blocks is done on the flattened model as described in subsection D. We describe the dependencies between blocks with the block dependency graph. This is a directed acyclic graph G = (B, E), where B = {B1 , B2 , , Bn } is the set of nodes and E is the set of edges in G. Each node Bi corresponds to a Simulink block with a worst case execution time wi and each edge Eik represents a data dependency from block Bi to block Bk . The set of leaf nodes in B, i.e., set of blocks which do not have any output ports is denoted by L and the set of start blocks, i.e., the set of blocks which do not have any input ports is denoted by S. We use Z for the set of deleted connections from the blocks that introduce delays (e.g., Unit Delay, Memory, Integrator, etc) to successor blocks. These connections exist in the original model, but they are deleted when forming the directed acyclic graph for removing cycles from the model. Such a connection is represented by Zik  Z . The size of the data transfer from block Bi to Bk in bytes is defined as cik . When Bi and Bk are mapped on different cores there will be a communication cost for transferring cik bytes of data between the cores. The communication cost is divided into transmission and receiving parts where tik denotes the transmission part of the communication time for sending cik bytes of data from block Bi to block Bk when they are mapped on different cores and rik denotes the receiving part of the communication time for sending cik bytes of data from block Bi to block Bk when they are on different cores. The maximum allowed execution time for one iteration of the model on the target multi-core architecture is given by the deadline. It is either taken as a user input or calculated as the overall worst case execution time on a single-core architecture. The size of a global semaphore structure in bytes is denoted by sSize and the size of total available shared memory in bytes is defined as totMem. Data alignment size in bytes (word size) is denoted by aSize. A very large value (MAX)

bip = 1

(1)

2) Delay introducing blocks and their first successor blocks shall be assigned to the same core: i, k : Zik  Z and p : Pp  P, bip - bkp = 0 (2)

3) The finishing time of each leaf block shall be less than or equal to the completion time for executing all blocks: This constraint is serving for the purpose of being able to formulate the objective function minimize(maxBi L (si + wi ))) as minimize(f ). i : Bi  L, si + wi  f (3)

4) If there is a dependency from block Bi to Bk , block Bk shall not start execution until (i) Bi finishes execution and transmission of its output data to its successor blocks that are mapped on other cores (which we temporarily define as fi below) and (ii) Bk finishes receiving all of its input data that are sent by the blocks on other cores: Considering that Bi is mapped to core Pp and Bk is mapped to core Pq where p can be equal to q : i, k : Bi , Bk  B, Eik  E, p, q : Pp , Pq  P, fi  sk -
Bl  B

1) Partially ordering independent blocks: In order to reduce the execution time of a model by parallelization, the model must preferably have a large number of blocks that are independent to each other. If all blocks are dependent to each other, then there can be no multi-core mapping that will improve the execution time and, thus, the best solution will be mapping all blocks to the same core. Typically, in an industrial size model with a large number of blocks, both the number of blocks that are independent to each other and the number of blocks that are dependent to each other becomes large. In this case, when we consider all possible combinations of execution orders (priorities) between these independent blocks, the number of constraints introduced by inequalities (5) and (6) becomes very large. As a consequence, finding an optimal solution within a feasible time becomes harder. We address this problem by deciding the execution order between certain independent blocks in advance. That is, before formulating the optimization problem, we decide the values of the dik variables for these block pairs. Since our execution order decision is valid only when these blocks are mapped onto the same core, this should not prevent these blocks to be mapped on different cores and, hence, be executed in a different order than what we specify. Our partially ordering heuristic is based on comparing the execution start time frames of independent blocks. The execution start time frame of a block is defined as the time frame between its best and worst case start time values. The best and the worst case start time values of a block Bi  B are defined in the subsection IV-B as bsi and wsi respectively. For all independent block pairs Bi  B and Bk  B , if (bs(i)  bs(k ))  (ws(i) < ws(k ))  (bs(i) < bs(k ))  (ws(i)  ws(k )) then we decide Bi to execute before Bk and set dik to 1. Else if (bs(i)  bs(k ))  (ws(i) > ws(k ))  (bs(i) > bs(k ))(ws(i)  ws(k )) then we decide Bi to execute after Bk and set dik to 0. 2) Fully ordering independent blocks: Even though ordering independent blocks using the partially ordering heuristic improves the performance, this is not enough for models with very large number of blocks. For example we could not find a feasible solution to models with more than 100 blocks with this approach. For dealing with those large models we propose deciding the execution order of all the independent blocks when they are mapped on the same core. The logic in fully ordering heuristic is based on comparing the midpoints of the execution start time frames for these blocks. For independent blocks Bi  B and Bk  B we decide Bi to be executed before Bk if the average of bsi and wsi is smaller than the average of bsk and wsk . With this approach, dik variables of MILP formulation change to constant values. Our discussion on the case when these blocks are mapped to different cores in previous subsection is still valid. 3) Merging highly coupled blocks: In this heuristic we merge blocks Bi and Bk when block Bk is the only block connected to the output port(s) of block Bi and block Bi is the only block connected to the input port(s) of block Bk . The merging operation copies all incoming and outgoing edges of Bk to Bi except the edge Eik . Then it updates wi with wi + wk and finally deletes Bk .

[rlk (1 - blq )] + (2 - bip - bkq )M AX
Bl B [til (1

(4)

where fi = si + wi +

- blp )].

5) Execution of independent blocks that are mapped to same core cannot overlap: Considering Bi and Bk are mapped to core Pp , we have two different constraints for this requirement. i, k : i < k, Bi , Bk  B, Eik  / E, p : Pp  P, fi  sk -
Bl  B

[rlk (1 - blp )] + (3 - bip - bkp - dik )M AX (5)

fk  si -
Bl  B

[rli (1 - blp )] + (2 - bip - bkp + dik )M AX (6)

Where, fi = si + wi + and fk = sk + wk +

Bl B

[til (1 - blp )] [tkl (1 - blp )]

Bl B

Since M AX is a very large constant, (5) will be valid when block Bi executes before Bk i.e., when dik = 1 and (6) will be valid when block Bi executes after Bk i.e., when dik = 0. 6) Total memory needed for semaphores and communication buffers shall be less than or equal to total amount of available shared memory: i, k : Bi , Bk  B, Eik  E, p : Pp  P sSize+
Bi ,Bk B

Cik ·aSize ·|bip -bkp | < totM em aSize (7)

D. Improving Solver Time The number of variables and constraints in the MILP formulation grows exponentially as the number of blocks in the model increase. Consequently, the MILP solver starts failing in finding optimal or near optimal solutions for the problem in a reasonable time. In this section, we introduce our techniques for addressing this issue. We say two blocks are dependent to each other if there exists a directed path between corresponding nodes in the DAG representation of the model and we say that two blocks are independent if there is no directed path between these nodes.

4) Merging small blocks with large blocks: In this heuristic we merge blocks Bi and Bk based on their ratio of execution times. If block Bk is the only block connected to the output port(s) of block Bi and the WCET of block Bi is very small when compared to the WCET of block Bk , then block Bi is merged into block Bk . If block Bi is the only block connected to the output port(s) of block Bk and the WCET of block Bk is very small when compared to the WCET of block Bi , then block Bk is merged into block Bi . We find this technique useful for reducing the number of blocks of concern in a way that parallelization will be focused on blocks with higher impact on execution time. The ratio between the worst case execution times of the blocks for determining a merge operation can be defined depending on how much reduction is needed in the number of blocks. The merging methods described above can be used for decreasing the number of nodes in very large models where the MILP solver can no more find a good solution. These two techniques are also dependent on the structure of the model. Although, in general, they assist in finding better solutions, there can be cases where the number of nodes cannot be reduced to an acceptable level. V. I MPLEMENTATION

merged together without introducing cycles between blocks. An exception to this is a subsystem including a delay introducing block. In this case, the blocks inside such a subsystem are not merged into a single block since this can cause a cycle in the dependency graph. In such a subsystem, predecessor blocks of a delay introducing block are only merged with other predecessor blocks and successor blocks are only merged with other successor blocks. In other words, a predecessor and a successor of a delay introducing block are never merged. The flow of the process up to this point is illustrated in the simple model in Fig. 2. In the next step, the block dependency graph is annotated with estimates of WCET. Fig. 4 gives an illustration of a simple block dependency graph. The block dependency graph and the number of CPU cores on the target architecture are used in generating the MILP formulation presented in Section IV. The MILP solver returns the best solution found for mapping blocks to the available CPU cores and the execution order between these blocks. The solution from the MILP solver is used to add inter-core communication blocks between the blocks which are mapped on different CPU cores. The relevant outputs of a block which are sending data to a block on a different core are connected to inter-core data transmitting S-function blocks. Similarly, corresponding inter-core data receiving S-function blocks for each transmitter are connected to the relevant inputs of the block which is receiving data on a different core. The intercore communication blocks are added by setting unique IDs that set each pair of transmitting and receiving blocks to use a dedicated inter-core semaphore and a dedicated shared memory location. An example of the transformation is given in Fig. 3. The output of B1 is connected to the input of B2 in the original model. This connection is then replaced by inter-core communication blocks. After adding all needed communication blocks, we set the priority attributes of the blocks using the execution start time values obtained from the optimization solution. As the last step, a copy of the model is created for every CPU core. Each copy of the model corresponds to a CPU core and the blocks which are mapped on other cores are commented out. Code generated from each of these models can be compiled to create separate executables for each core. VI. E XPERIMENTS

In this section we describe the details of the implementation of our tool in MATLAB. Our tool accepts as an input a Simulink model that is ready to compile as well as the desired depth of blocks to be parallelized. It loads the model, reads specific block information, e.g., block type, parents, etc., and all the relations between blocks along with the width and size of the data on the ports. For data types that are not built-in, the user input is required to define the data size in bytes. Using this information the model is flattened by taking blocks inside sub-systems out of their parent blocks. The remaining blocks like input and output ports of subsystems, emptied subsystem container blocks and `Goto' - `From' pairs, which are converted to line connections, are discarded from the set of blocks. We represent all these dependencies in a directed graph where a directed edge represents a data communication from its source to its destination. Since determining Worst Case Execution Times (WCET) is not in scope of this paper, we assume that the WCET values for each of the blocks are already determined. If there exists a cycle in the directed graph, this means that there is a corresponding block in the cycle which creates a data dependency from a previous iteration of model execution. We will refer to these blocks as delay introducing blocks. In these cases we break the connection from delay introducing blocks to their successors for transforming a directed graph to a directed acyclic graph. Since the connection from delay introducing blocks to their successor blocks are deleted, our MILP solution can never introduce inter-core communication mechanism between these blocks even if they are mapped on different cores. For dealing with this issue we force the delay introducing blocks and their successor blocks to be mapped on the same core in the MILP formulation. After all of the cycles are cleared, the blocks that are originally inside subsystems up to the desired model depth are

For studying the scalability and efficiency of our approach, we utilize randomly generated directed acyclic graphs with different number of nodes. We present results of these experiments in subsection VI-A and results of our case studies in subsections VI-B and VI-C. We use SCIP [22] from Achterberg as MILP solver which is interfaced with MATLAB through the Opti Toolbox [23] by Currie and Wilson. Experiments are run on a 64-bit Windows 7 PC with Intel Xeon E5-2670 CPU and 64 GB RAM. A. Randomly Generated DAGs For evaluating performance of our approach, we generate DAGs in which the WCET, communication costs and connections between blocks are assigned randomly. Then we solve

1
In1

-1 Z
Delay Subtract Product

Node 1

Node 5 8 8

Node 2 4

Node 6 4

1
Out1

2
In2

10
Constant

Node 4 8

Node 9 8 8

1
In1

Node 10
In1 Out1 In2
Subsystem

Node 8 8

Node 3 32

Node 11 8

1
Constant

Add

1
Out1

Node 7 32

Node 12

2
In2

[Goto1] 5
Constant1 Product Goto

Node 13

[Goto1]
From

3
In3 Divide

2
Out2

Fig. 4.

Block dependency graph for a simple model

1
In1

MERGED
-1 Z
Add Delay

1
Constant

1
Subtract Product1 Out1

2
In2

10
Constant2

5
Constant1

Product

3
In3 Divide

2
Out2

Fig. 2.

Flattening models and merging blocks

the problem for a dual-core system with the basic MILP formulation which is given in Section IV and with the partially and fully ordering heuristics for deciding the execution order of independent blocks. We set five hours (18,000 sec) as an acceptable upper time limit for the solver run time. Here, we present a comparison of the performance of these three approaches in terms of the average speed-up achieved, the average solver time and the ability to find a solution in the given time limit. The speed-up is computed as the overall single-core worst case execution time of the model divided by the overall worst case execution time of the parallelized model. Given infinite solver time, the basic MILP formulation is expected to find more optimal solutions than the other approaches do for any problem size. However, when the solver time is limited (5 hours in our experiments), it fails to find satisfactory solutions for large problems. Table I gives a comparison of the performance of the used approaches. Average speedup achieved by basic MILP formulation, partially and fully

ordering heuristics (respectively denoted as basic, partial and full) and corresponding solver run-time values are presented in the table for different problem sizes. We also present the ratio of the solutions found over all the experiments. For a problem size, the lines corresponding to the approaches which could not return any solutions are discarded in the table. As it can be seen from the results presented in Table I, as the number of blocks in a model increases, any heuristic that (partially) sets the execution order performs better both in terms of solver run-time and optimality of solutions. According to our observations, for finding an optimal mapping, the basic MILP formulation performs best when there are less than 30 blocks. The partially ordering heuristic performs best when there are 30 to 50 blocks. For more than 50 blocks in the model, the fully ordering heuristic outperforms other approaches in terms of the achieved speed-up and the ability to return a solution. The basic MILP formulation fails to return any solution for models with 70 or more blocks. The partially ordering heuristic fails to return any solution for models with more than 110 blocks. Although this detail is not illustrated in Table I because of averaging, according to our experimental results, the fully ordering heuristic can occasionally achieve very low speedup values compared to the other approaches when there are less than 20 blocks in the model. However, this issue is not observed when there are large number of blocks. This behavior is parallel to our expectations since optimization can significantly reduce the effect of possible non-optimal execution order decisions by trying large number of different mapping of blocks to different cores. In Fig. 5, we illustrate the comparison between the two heuristics and the basic MILP formulation in terms of the achieved speed-up over the number of nodes. The solid lines in the plot represent how much average speed-up is achieved by each approach. The dashed lines represent the corresponding minimum and maximum speed-up for each approach. For very small number of nodes, the basic MILP formulation is better than the other approaches. However, when the number of nodes increases, first, the partially ordering heuristic and, then, the fully ordering heuristic perform best. In Fig. 6, we illustrate the comparison between the two heuristics and the basic MILP formulation in terms of the average solver time over the number of nodes. Each line in the graph represents the average solver time spent for each

In In Out In Out

Out

Inter Core Sender : 2

B1 B1 B2

Inter Core Sender System

Inter Core Receiver : 2

In

Inter Core Receiver System

Out B2

Fig. 3.

Inter-core communication blocks

TABLE I.

C OMPARISON OF DIFFERENT APPROACHES

18000

# Nodes 10-15

Approach Basic Partial Full Basic Partial Full Basic Partial Full Basic Partial Full Basic Partial Full Partial Full Partial Full Partial Full Partial Full Partial Full Full Full Full

30

40

50

60 70 80 90 100 110 130 150 170

Average speed-up 1.48 1.47 1.46 1.68 1.71 1.46 1.48 1.62 1.55 1.2 1.66 1.67 1.09 1.55 1.59 1.54 1.75 1.39 1.7 1.38 1.61 1.08 1.64 1.04 1.67 1.56 1.62 1.61

Average solver time 2 1 0.5 2620 1558 26 9256 2091 606 18000 12481 5174 18000 17400 11685 18000 18000 18000 18000 18000 18000 18000 18000 18000 18000 18000 18000 18000

% found Solutions 100% 100% 100% 100% 100% 100% 100% 100% 100% 100% 100% 100% 64% 100% 100% 100% 100% 100% 100% 60% 100% 50% 100% 30% 100% 100% 100% 100%

16000 14000
Solver Time (s)
12000 10000 8000 6000 4000 2000 Basic (Avg) Partial (Avg) Full (Avg)

0 10 - 15 30 40 50 60 70 80 90 100 110 130 150 170
Number of Nodes

Fig. 6.

Comparison of solver time between different approaches

model has 1 input port, 1 output port and 53 blocks after discarding the trivial blocks as described in Section V. We performed parallelization on a completely flattened graph. The obtained block dependency graph from this model is presented in Fig. 7 where the blocks mapped to core 1 and core 2 are illustrated as the nodes colored with red and blue, respectively. We achieved a speed-up value of 1.78 with the partially ordering heuristic within 5 hours of solver time. A speed-up value of 1.92 was achieved with the fully ordering heuristic. The basic MILP solution could only achieve a speed-up value 1.19 because it was unable to find the optimum solution within the given time limit of 5 hours. This result is parallel with the outcomes of the experiments carried on randomly generated DAGs. C. Case Study: Toyota Diesel Engine Controller We used the Diesel engine controller model from [1] as a case study from industry. The original model contains both controller and plant parts. The controller part of model has 1004 blocks when flattened as described in Section V, it has 7 inputs that are merged into a single input bus signal and 6 outputs that are merged into a single output bus signal. Since the model has cycles inside the subsystems, our tool flattens the model by searching all blocks inside subsystems, breaks
Node 1
24 24

approach. As it is expected, due to the time limit given to the solver, as the number of nodes increases, the solution times for all approaches converge. However, the experiments on models with less number of nodes suggests that the proposed heuristics can improve the solver time. In the graph it can be observed that the average solver time for proposed heuristics (as a function of node count) is smaller than the basic formulation. Combining the data in Fig. 5 and Fig. 6, we can see that the fully ordering heuristic returns better solutions within shorter solver run-time compared to the other approaches. B. Case Study: Fault-Tolerant Fuel Control System As a case study, we used the fuel rate control subsystem of the Simulink Fault-Tolerant Fuel Control System demo. This

Node 2
4

Node 31
4

Node 32
4 4

Node 30
16 8 8 24

Node 23
24 8 8 8 4 8 16

Node 8
16

2
Node 48

Node 28

Node 22
8

Node 3
8 8 4 4 4

Node 10
4

Node 16
8

1.9 1.8 1.7
Node 50
4 4

4

Node 40
8

Node 27

16

Node 24

Node 26
4

Node 20

Node 14
4

Node 17
8

Node 9

Node 49
4

4

Node 25

Node 15
4 4 4

Node 11

Node 4
4 4

Node 6

Speed-up

1.6 1.5 1.4 1.3 1.2 1.1 1 10 - 15 30 40 50 60 70 80 90 Number of Nodes 100 110 130 150 170
Node 44
8 4

Node 51
4

Node 46
8

Node 52

Node 13

Node 19
4

8

Node 43
8

Node 45
8 4

Node 18

Node 5
1

Node 12
4

Node 42
8 8 8

Node 34
8 8

Node 29
8 4 4

Node 21
4

Node 47

Node 41

Node 35
4

Node 36
4

Node 37

Node 39
4

Node 7

Node 33
4

Node 38

Basic (Avg) Full (Min)

Partial (Avg) Basic (Max)

Full (Avg) Partial (Max)

Basic (Min) Full (Max)

Partial (Min)

Node 53

Fig. 5.

Comparison of speed-up values between different approaches

Fig. 7. The block dependency graph and its partition onto two cores for the fuel control system case study

the cycles as described in Section V and merges blocks inside subsystems (when possible) without introducing new cycles. For parallelizing this model we set the target model depth as 2. After merging deep blocks of each subsystem, the block dependency graph is generated from the model with merged blocks. The generated block dependency graph contains 153 nodes and a total of 184 connections between these nodes. Our target platform for this case study is the dual-core architecture from Freescale which is described in Section III. In our target hardware setup we have a total of 3.8 KB shared memory available. For a model of this size, both the basic MILP formulation and the partially ordering heuristic fail in finding a solution in 10 hours. However, by merging blocks of subsystems with depth more than 2 and with our fully ordering heuristic, our tool returned a solution to the given problem within an average of 1.2 hours of solver time. Here the average is taken over different sets of worst case execution time assignments. The suggested multi-core mapping by the tool achieves 1.44x speed-up on average. This result is parallel with our expectations based on experiments carried on randomly generated DAGs and illustrates applicability of our approach to reasonably large problems in industry. VII. C ONCLUSION

[4]

[5]

[6]

[7]

[8]

[9]

[10]

[11]

[12]

In this paper we presented our approach for parallelizing a single-rate Simulink model on a multi-core architecture. We proposed a heuristic for partially deciding execution order of independent blocks when they are mapped to the same core. According to the experimental results with randomly generated DAGs and our case study with the fuel system controller, this proposed heuristic improves optimality of found solutions in a reasonable time for a realistic size of models with around 50 to 60 blocks in our experimental environment. For models with larger number of blocks, we proposed another heuristic in which the execution order of all the independent blocks is decided in advance. With this approach our tool could handle models with larger than 150 blocks. We also presented this heuristic together with block merging methods on a case study from the industry where our tool reduced 1004 blocks to 153 nodes on the dependency graph by merging blocks deeper than a specified value and solved the problem on this 153 nodes. The results from the case study illustrate how our approach can handle models which can contain more than 1000 blocks. For the future work, we consider extending this work by introducing heuristic methods for solving the optimization problem, studying multi-rate models and models with blocks that have priority assignments. Furthermore, we plan to incorporate worst case execution time (WCET) tools in our framework. R EFERENCES
M. Huang, H. Nakada, S. Polavarapu, R. Choroszucha, K. Butts, and I. Kolmanovsky, "Towards combining nonlinear and predictive control of diesel engines," in American Control Conference (ACC), 2013. IEEE, 2013, pp. 2846­2853. [2] Simulink, version 8.5 (R2015a). Natick, Massachusetts: The MathWorks Inc., 2015. [3] "EASA/2011/6 final report," European Aviation Safety Agency, Tech. Rep., 2012. [1]

[13]

[14]

[15]

[16] [17]

[18]

[19] [20] [21]

[22] [23]

Certification Authorities Software Team, "Position paper CAST-32 multi-core processors," Federal Aviation Administration, Tech. Rep., 2014. J. H. Anderson, J. M. Calandrino, and U. C. Devi, "Real-time scheduling on multicore platforms," in Real-Time and Embedded Technology and Applications Symposium, 2006. Proceedings of the 12th IEEE. IEEE, 2006, pp. 179­190. S. K. Baruah, N. K. Cohen, C. G. Plaxton, and D. A. Varvel, "Proportionate progress: A notion of fairness in resource allocation," Algorithmica, vol. 15, no. 6, pp. 600­625, 1996. Y. Yi, W. Han, X. Zhao, A. T. Erdogan, and T. Arslan, "An ILP formulation for task mapping and scheduling on multi-core architectures," in Design, Automation & Test in Europe Conference & Exhibition, 2009. DATE'09. IEEE, 2009, pp. 33­38. A. Bender, "Design of an optimal loosely coupled heterogeneous multiprocessor system," in European Design and Test Conference, 1996. ED&TC 96. Proceedings. IEEE, 1996, pp. 275­281. C. Ostler and K. S. Chatha, "An ILP formulation for system-level application mapping on network processor architectures," in Proceedings of the conference on Design, automation and test in Europe. EDA Consortium, 2007, pp. 99­104. S. Cotton, O. Maler, J. Legriel, and S. Saidi, "Multi-criteria optimization for mapping programs to multi-processors," in Industrial Embedded Systems (SIES), 2011 6th IEEE International Symposium on. IEEE, 2011, pp. 9­17. P. Tendulkar, P. Poplavko, I. Galanommatis, and O. Maler, "Many-core scheduling of data parallel applications using SMT solvers," in Digital System Design (DSD), 2014 17th Euromicro Conference on. IEEE, 2014, pp. 615­622. J. Feljan and J. Carlson, "Task allocation optimization for multicore embedded systems," in Software Engineering and Advanced Applications (SEAA), 2014 40th EUROMICRO Conference on. IEEE, 2014, pp. 237­244. T. Kumura, Y. Nakamura, N. Ishiura, Y. Takeuchi, and M. Imai, "Model based parallelization from the simulink models and their sequential C code," in Proceedings of the 17th Workshop on Synthesis And System Integration of Mixed Information Technologies (SASIMI 2012), 2012, pp. 186­191. A. Canedo, T. Yoshizawa, and H. Komatsu, "Automatic parallelization of simulink applications," in Proceedings of the 8th annual IEEE/ACM international symposium on Code generation and optimization. ACM, 2010, pp. 151­159. M. Cha, K. H. Kim, C. J. Lee, D. Ha, and B. S. Kim, "Deriving highperformance real-time multicore systems based on simulink applications," in Dependable, Autonomic and Secure Computing (DASC), 2011 IEEE Ninth International Conference on. IEEE, 2011, pp. 267­274. AUTOSAR. (2015) AUTOSAR specification. [Online]. Available: http://www.autosar.org P. Deng, F. Cremona, Q. Zhu, M. Di Natale, and H. Zeng, "A modelbased synthesis flow for automotive CPS," in Proceedings of the ACM/IEEE Sixth International Conference on Cyber-Physical Systems. ACM, 2015, pp. 198­207. R. Lublinerman and S. Tripakis, "Modular code generation from triggered and timed block diagrams," in Real-Time and Embedded Technology and Applications Symposium, 2008. RTAS'08. IEEE. IEEE, 2008, pp. 147­158. Freescale Semiconductor Inc. (2015) Qorivva MPC5675K. [Online]. Available: http://www.freescale.com/ Micrium Inc. (2015) µC/OS-II. [Online]. Available: http://micrium.com/rtos/ucosii/ G. R. Bulusu, "Asymmetric multiprocessing real time operating system on multicore platforms," Ph.D. dissertation, Arizona State University, 2014. T. Achterberg, "SCIP: solving constraint integer programs," Mathematical Programming Computation, vol. 1, no. 1, pp. 1­41, 2009. J. Currie and D. I. Wilson, "OPTI: lowering the barrier between open source optimizers and the industrial MATLAB user," Foundations of computer-aided process operations, Savannah, Georgia, USA, pp. 8­ 11, 2012.

